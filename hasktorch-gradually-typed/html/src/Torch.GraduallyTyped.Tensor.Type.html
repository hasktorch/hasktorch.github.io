<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><link rel="stylesheet" type="text/css" href="style.css" /><script type="text/javascript" src="highlight.js"></script></head><body><pre><span class="hs-pragma">{-# LANGUAGE AllowAmbiguousTypes #-}</span><span>
</span><span id="line-2"></span><span class="hs-pragma">{-# LANGUAGE ConstraintKinds #-}</span><span>
</span><span id="line-3"></span><span class="hs-pragma">{-# LANGUAGE DataKinds #-}</span><span>
</span><span id="line-4"></span><span class="hs-pragma">{-# LANGUAGE DerivingStrategies #-}</span><span>
</span><span id="line-5"></span><span class="hs-pragma">{-# LANGUAGE FlexibleContexts #-}</span><span>
</span><span id="line-6"></span><span class="hs-pragma">{-# LANGUAGE FlexibleInstances #-}</span><span>
</span><span id="line-7"></span><span class="hs-pragma">{-# LANGUAGE FunctionalDependencies #-}</span><span>
</span><span id="line-8"></span><span class="hs-pragma">{-# LANGUAGE GADTs #-}</span><span>
</span><span id="line-9"></span><span class="hs-pragma">{-# LANGUAGE InstanceSigs #-}</span><span>
</span><span id="line-10"></span><span class="hs-pragma">{-# LANGUAGE KindSignatures #-}</span><span>
</span><span id="line-11"></span><span class="hs-pragma">{-# LANGUAGE LambdaCase #-}</span><span>
</span><span id="line-12"></span><span class="hs-pragma">{-# LANGUAGE MultiParamTypeClasses #-}</span><span>
</span><span id="line-13"></span><span class="hs-pragma">{-# LANGUAGE PatternSynonyms #-}</span><span>
</span><span id="line-14"></span><span class="hs-pragma">{-# LANGUAGE PolyKinds #-}</span><span>
</span><span id="line-15"></span><span class="hs-pragma">{-# LANGUAGE RankNTypes #-}</span><span>
</span><span id="line-16"></span><span class="hs-pragma">{-# LANGUAGE RecordWildCards #-}</span><span>
</span><span id="line-17"></span><span class="hs-pragma">{-# LANGUAGE RoleAnnotations #-}</span><span>
</span><span id="line-18"></span><span class="hs-pragma">{-# LANGUAGE ScopedTypeVariables #-}</span><span>
</span><span id="line-19"></span><span class="hs-pragma">{-# LANGUAGE StandaloneKindSignatures #-}</span><span>
</span><span id="line-20"></span><span class="hs-pragma">{-# LANGUAGE TemplateHaskell #-}</span><span>
</span><span id="line-21"></span><span class="hs-pragma">{-# LANGUAGE TypeApplications #-}</span><span>
</span><span id="line-22"></span><span class="hs-pragma">{-# LANGUAGE TypeFamilies #-}</span><span>
</span><span id="line-23"></span><span class="hs-pragma">{-# LANGUAGE TypeOperators #-}</span><span>
</span><span id="line-24"></span><span class="hs-pragma">{-# LANGUAGE UndecidableInstances #-}</span><span>
</span><span id="line-25"></span><span class="hs-pragma">{-# LANGUAGE UndecidableSuperClasses #-}</span><span>
</span><span id="line-26"></span><span class="hs-pragma">{-# LANGUAGE ViewPatterns #-}</span><span>
</span><span id="line-27"></span><span class="hs-pragma">{-# OPTIONS_GHC -Wall #-}</span><span>
</span><span id="line-28"></span><span>
</span><span id="line-29"></span><span class="hs-keyword">module</span><span> </span><span class="hs-identifier">Torch.GraduallyTyped.Tensor.Type</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-30"></span><span>
</span><span id="line-31"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">Control.Applicative</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier">empty</span></span><span class="hs-special">)</span><span>
</span><span id="line-32"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">Control.Category</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-operator">(&gt;&gt;&gt;)</span></span><span class="hs-special">)</span><span>
</span><span id="line-33"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">Control.Exception</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier">Exception</span></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-34"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">Control.Monad</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier">forM</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier">forM_</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier">when</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-operator">(&lt;=&lt;)</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-operator">(&gt;=&gt;)</span></span><span class="hs-special">)</span><span>
</span><span id="line-35"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier">Control.Monad.Catch</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier">MonadThrow</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-36"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">Data.Bifunctor</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier">bimap</span></span><span class="hs-special">)</span><span>
</span><span id="line-37"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">Data.Coerce</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier">coerce</span></span><span class="hs-special">)</span><span>
</span><span id="line-38"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">Data.Foldable</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier">traverse_</span></span><span class="hs-special">)</span><span>
</span><span id="line-39"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">Data.Functor</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-operator">(&lt;&amp;&gt;)</span></span><span class="hs-special">)</span><span>
</span><span id="line-40"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">Data.Int</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier">Int16</span></span><span class="hs-special">)</span><span>
</span><span id="line-41"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">Data.List.NonEmpty</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier">NonEmpty</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-operator">(:|)</span></span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier">nonEmpty</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier">unzip</span></span><span class="hs-special">)</span><span>
</span><span id="line-42"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">Data.Maybe</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier">maybeToList</span></span><span class="hs-special">)</span><span>
</span><span id="line-43"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">Data.Proxy</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier">Proxy</span></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-44"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">Data.Singletons</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">SingI</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">sing</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">fromSing</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-45"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">Data.Singletons.Prelude.List</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">SList</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-46"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">Data.Typeable</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier">Typeable</span></span><span class="hs-special">)</span><span>
</span><span id="line-47"></span><span class="hs-keyword">import</span><span> </span><span class="hs-keyword">qualified</span><span> </span><span class="annot"><a href="../file:///nix/store/yynp70g2av7yww0d41962k85vnlb2qia-vector-lib-vector-0.12.2.0-haddock-doc/share/doc/vector/html/src"><span class="hs-identifier">Data.Vector</span></a></span><span> </span><span class="hs-keyword">as</span><span> </span><span class="annot"><span class="hs-identifier">V</span></span><span>
</span><span id="line-48"></span><span class="hs-keyword">import</span><span> </span><span class="hs-keyword">qualified</span><span> </span><span class="annot"><a href="../file:///nix/store/33j53czfh9iaqr8w1k6rjcna7zg8rw55-vector-sized-lib-vector-sized-1.4.3.1-haddock-doc/share/doc/vector-sized/html/src"><span class="hs-identifier">Data.Vector.Generic.Sized.Internal</span></a></span><span> </span><span class="hs-keyword">as</span><span> </span><span class="annot"><span class="hs-identifier">SVI</span></span><span>
</span><span id="line-49"></span><span class="hs-keyword">import</span><span> </span><span class="hs-keyword">qualified</span><span> </span><span class="annot"><a href="../file:///nix/store/33j53czfh9iaqr8w1k6rjcna7zg8rw55-vector-sized-lib-vector-sized-1.4.3.1-haddock-doc/share/doc/vector-sized/html/src"><span class="hs-identifier">Data.Vector.Sized</span></a></span><span> </span><span class="hs-keyword">as</span><span> </span><span class="annot"><span class="hs-identifier">SV</span></span><span>
</span><span id="line-50"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">Foreign</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier">Ptr</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier">Word8</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier">castPtr</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier">fromBool</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier">peekElemOff</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier">pokeElemOff</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier">withForeignPtr</span></span><span class="hs-special">)</span><span>
</span><span id="line-51"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">Foreign.ForeignPtr</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier">ForeignPtr</span></span><span class="hs-special">)</span><span>
</span><span id="line-52"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">GHC.TypeLits</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier">KnownNat</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier">KnownSymbol</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier">Nat</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier">Symbol</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier">natVal</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier">symbolVal</span></span><span class="hs-special">)</span><span>
</span><span id="line-53"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">System.IO.Unsafe</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier">unsafePerformIO</span></span><span class="hs-special">)</span><span>
</span><span id="line-54"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html"><span class="hs-identifier">Torch.GraduallyTyped.DType</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier">DType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier">DataType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier">SDataType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-55"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html"><span class="hs-identifier">Torch.GraduallyTyped.Device</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier">Device</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#DeviceType"><span class="hs-identifier">DeviceType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#SDevice"><span class="hs-identifier">SDevice</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#SDeviceType"><span class="hs-identifier">SDeviceType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-56"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Internal.TensorOptions.html"><span class="hs-identifier">Torch.GraduallyTyped.Internal.TensorOptions</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Internal.TensorOptions.html#tensorOptions"><span class="hs-identifier">tensorOptions</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-57"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html"><span class="hs-identifier">Torch.GraduallyTyped.Layout</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier">Layout</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#LayoutType"><span class="hs-identifier">LayoutType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#SLayout"><span class="hs-identifier">SLayout</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#SLayoutType"><span class="hs-identifier">SLayoutType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-58"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html"><span class="hs-identifier">Torch.GraduallyTyped.Prelude</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Seq"><span class="hs-identifier">Seq</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#forgetIsChecked"><span class="hs-identifier">forgetIsChecked</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#ifM"><span class="hs-identifier">ifM</span></a></span><span class="hs-special">,</span><span> </span><span class="hs-keyword">pattern</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#%3A%7C%3A"><span class="hs-operator">(:|:)</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-59"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html"><span class="hs-identifier">Torch.GraduallyTyped.RequiresGradient</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier">Gradient</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#RequiresGradient"><span class="hs-identifier">RequiresGradient</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier">SGradient</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#SRequiresGradient"><span class="hs-identifier">SRequiresGradient</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-60"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html"><span class="hs-identifier">Torch.GraduallyTyped.Shape.Class</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#InsertDimF"><span class="hs-identifier">InsertDimF</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#ReplaceDimF"><span class="hs-identifier">ReplaceDimF</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-61"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html"><span class="hs-identifier">Torch.GraduallyTyped.Shape.Type</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#By"><span class="hs-identifier">By</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier">ByIndex</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier">Name</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier">SDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier">SName</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier">SShape</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier">SSize</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier">Shape</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier">Size</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-62"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html"><span class="hs-identifier">Torch.GraduallyTyped.Unify</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-keyword">type</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator">(&lt;+&gt;)</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-63"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../../../../hasktorch/html/src"><span class="hs-identifier">Torch.HList</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../../../../hasktorch/html/src"><span class="hs-identifier">HList</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="hs-keyword">pattern</span><span> </span><span class="annot"><a href="../../../../hasktorch/html/src"><span class="hs-operator">(:.)</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-64"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier">Torch.Internal.Cast</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier">cast0</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier">cast1</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier">cast2</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier">cast4</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-65"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier">Torch.Internal.Class</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier">Castable</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-66"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier">Torch.Internal.GC</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier">unsafeThrowableIO</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-67"></span><span class="hs-keyword">import</span><span> </span><span class="hs-keyword">qualified</span><span> </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier">Torch.Internal.Managed.Native</span></a></span><span> </span><span class="hs-keyword">as</span><span> </span><span class="annot"><span class="hs-identifier">ATen</span></span><span>
</span><span id="line-68"></span><span class="hs-keyword">import</span><span> </span><span class="hs-keyword">qualified</span><span> </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier">Torch.Internal.Managed.Type.Context</span></a></span><span> </span><span class="hs-keyword">as</span><span> </span><span class="annot"><span class="hs-identifier">ATen</span></span><span>
</span><span id="line-69"></span><span class="hs-keyword">import</span><span> </span><span class="hs-keyword">qualified</span><span> </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier">Torch.Internal.Managed.Type.Extra</span></a></span><span> </span><span class="hs-keyword">as</span><span> </span><span class="annot"><span class="hs-identifier">ATen</span></span><span>
</span><span id="line-70"></span><span class="hs-keyword">import</span><span> </span><span class="hs-keyword">qualified</span><span> </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier">Torch.Internal.Managed.Type.Tensor</span></a></span><span> </span><span class="hs-keyword">as</span><span> </span><span class="annot"><span class="hs-identifier">ATen</span></span><span>
</span><span id="line-71"></span><span class="hs-keyword">import</span><span> </span><span class="hs-keyword">qualified</span><span> </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier">Torch.Internal.Managed.Type.TensorOptions</span></a></span><span> </span><span class="hs-keyword">as</span><span> </span><span class="annot"><span class="hs-identifier">ATen</span></span><span>
</span><span id="line-72"></span><span class="hs-keyword">import</span><span> </span><span class="hs-keyword">qualified</span><span> </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier">Torch.Internal.Type</span></a></span><span> </span><span class="hs-keyword">as</span><span> </span><span class="annot"><span class="hs-identifier">ATen</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier">Tensor</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier">TensorList</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier">TensorOptions</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-73"></span><span class="hs-keyword">import</span><span> </span><span class="hs-keyword">qualified</span><span> </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier">Torch.Internal.Unmanaged.Type.Tensor</span></a></span><span> </span><span class="hs-keyword">as</span><span> </span><span class="annot"><span class="hs-identifier">Unmanaged</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier">tensor_data_ptr</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-74"></span><span class="hs-keyword">import</span><span> </span><span class="hs-keyword">qualified</span><span> </span><span class="annot"><a href="../../../../hasktorch/html/src"><span class="hs-identifier">Torch.Tensor</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../../../../hasktorch/html/src"><span class="hs-identifier">Tensor</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../../../../hasktorch/html/src"><span class="hs-identifier">Unsafe</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-75"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">Prelude</span></span><span> </span><span class="hs-keyword">hiding</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier">unzip</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier">unzip3</span></span><span class="hs-special">)</span><span>
</span><span id="line-76"></span><span>
</span><span id="line-77"></span><span class="hs-comment">-- $setup</span><span>
</span><span id="line-78"></span><span class="hs-comment">-- &gt;&gt;&gt; import Data.Singletons.Prelude.List (SList (..))</span><span>
</span><span id="line-79"></span><span class="hs-comment">-- &gt;&gt;&gt; import Torch.GraduallyTyped</span><span>
</span><span id="line-80"></span><span>
</span><span id="line-81"></span><span class="hs-comment">-- | A gradually typed tensor.</span><span>
</span><span id="line-82"></span><span class="hs-comment">--</span><span>
</span><span id="line-83"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-84"></span><span class="hs-comment">--                          &#9484;&#9472;&#9658; Compute device, e.g. `'Device 'CPU`</span><span>
</span><span id="line-85"></span><span class="hs-comment">--                          &#9474;</span><span>
</span><span id="line-86"></span><span class="hs-comment">--                          &#9474;               &#9484;&#9472;&#9658; List of dimensions, e.g. `'Shape '[ 'Dim 'UncheckedName ('Size 8), 'Dim 'UncheckedName ('Size 1) ]`</span><span>
</span><span id="line-87"></span><span class="hs-comment">--                          &#9474;               &#9474;</span><span>
</span><span id="line-88"></span><span class="hs-comment">-- Tensor gradient layout device dataType shape</span><span>
</span><span id="line-89"></span><span class="hs-comment">--           &#9474;       &#9474;              &#9474;</span><span>
</span><span id="line-90"></span><span class="hs-comment">--           &#9474;       &#9474;              &#9492;&#9472;&#9658; Data type, e.g. `'DataType 'Float`</span><span>
</span><span id="line-91"></span><span class="hs-comment">--           &#9474;       &#9474;</span><span>
</span><span id="line-92"></span><span class="hs-comment">--           &#9474;       &#9492;&#9472;&#9658; Memory layout, e.g. `'Layout 'Dense`</span><span>
</span><span id="line-93"></span><span class="hs-comment">--           &#9474;</span><span>
</span><span id="line-94"></span><span class="hs-comment">--           &#9492;&#9472;&#9658; Whether or not the tensor requires a gradient, e.g. `'Gradient 'WithGradient` for one that does</span><span>
</span><span id="line-95"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-96"></span><span class="hs-keyword">newtype</span><span>
</span><span id="line-97"></span><span>  </span><span id="Tensor"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-var">Tensor</span></a></span></span><span>
</span><span id="line-98"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679540808"><span class="annot"><a href="#local-6989586621679540808"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#RequiresGradient"><span class="hs-identifier hs-type">RequiresGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-99"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679540807"><span class="annot"><a href="#local-6989586621679540807"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#LayoutType"><span class="hs-identifier hs-type">LayoutType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-100"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679540806"><span class="annot"><a href="#local-6989586621679540806"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier hs-type">Device</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#DeviceType"><span class="hs-identifier hs-type">DeviceType</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-101"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679540805"><span class="annot"><a href="#local-6989586621679540805"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier hs-type">DType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-102"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679540804"><span class="annot"><a href="#local-6989586621679540804"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">[</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-103"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-104"></span><span>  </span><span class="hs-comment">-- | Unsafe constructor for tensors.</span><span>
</span><span id="line-105"></span><span>  </span><span class="hs-comment">-- Do not call this constructor directly,</span><span>
</span><span id="line-106"></span><span>  </span><span class="hs-comment">-- use smart constructors like 'ones' or 'randn' instead.</span><span>
</span><span id="line-107"></span><span>  </span><span id="UnsafeTensor"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#UnsafeTensor"><span class="hs-identifier hs-var">UnsafeTensor</span></a></span></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-108"></span><span>    </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679541798"><span class="annot"><a href="#local-6989586621679541798"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679541797"><span class="annot"><a href="#local-6989586621679541797"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679541796"><span class="annot"><a href="#local-6989586621679541796"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679541795"><span class="annot"><a href="#local-6989586621679541795"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679541794"><span class="annot"><a href="#local-6989586621679541794"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-109"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">ForeignPtr</span></span><span> </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-type">ATen.Tensor</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-110"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541798"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541797"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541796"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541795"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541794"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-111"></span><span>
</span><span id="line-112"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">role</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><span class="hs-identifier">nominal</span></span><span> </span><span class="annot"><span class="hs-identifier">nominal</span></span><span> </span><span class="annot"><span class="hs-identifier">nominal</span></span><span> </span><span class="annot"><span class="hs-identifier">nominal</span></span><span> </span><span class="annot"><span class="hs-identifier">nominal</span></span><span>
</span><span id="line-113"></span><span>
</span><span id="line-114"></span><span id="local-6989586621679540798"><span id="local-6989586621679540799"><span id="local-6989586621679540800"><span id="local-6989586621679540801"><span id="local-6989586621679540802"><span class="hs-keyword">instance</span><span> </span><span id="local-6989586621679540793"><span id="local-6989586621679540796"><span class="annot"><span class="hs-identifier hs-type">Show</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540802"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540801"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540800"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540799"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540798"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">)</span></span></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-115"></span><span>  </span><span id="local-6989586621679540791"><span class="annot"><span class="annottext">show :: Tensor gradient layout device dataType shape -&gt; String
</span><span class="hs-identifier hs-var hs-var hs-var hs-var">show</span></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#UnsafeTensor"><span class="hs-identifier hs-type">UnsafeTensor</span></a></span><span> </span><span id="local-6989586621679540789"><span class="annot"><span class="annottext">ForeignPtr Tensor
</span><a href="#local-6989586621679540789"><span class="hs-identifier hs-var">t</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor -&gt; String
forall a. Show a =&gt; a -&gt; String
</span><span class="hs-identifier hs-var">show</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; Tensor
</span><a href="../../../../hasktorch/html/src"><span class="hs-identifier hs-var">Torch.Tensor.Unsafe</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
</span><a href="#local-6989586621679540789"><span class="hs-identifier hs-var">t</span></a></span><span class="hs-special">)</span></span></span></span></span></span><span>
</span><span id="line-116"></span><span>
</span><span id="line-117"></span><span class="hs-keyword">data</span><span>
</span><span id="line-118"></span><span>  </span><span id="TensorSpec"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorSpec"><span class="hs-identifier hs-var">TensorSpec</span></a></span></span><span>
</span><span id="line-119"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679540788"><span class="annot"><a href="#local-6989586621679540788"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#RequiresGradient"><span class="hs-identifier hs-type">RequiresGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-120"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679540787"><span class="annot"><a href="#local-6989586621679540787"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#LayoutType"><span class="hs-identifier hs-type">LayoutType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-121"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679540786"><span class="annot"><a href="#local-6989586621679540786"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier hs-type">Device</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#DeviceType"><span class="hs-identifier hs-type">DeviceType</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-122"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679540785"><span class="annot"><a href="#local-6989586621679540785"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier hs-type">DType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-123"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679540784"><span class="annot"><a href="#local-6989586621679540784"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">[</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-124"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-125"></span><span>  </span><span id="TensorSpec"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorSpec"><span class="hs-identifier hs-var">TensorSpec</span></a></span></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-126"></span><span>    </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679540782"><span class="annot"><a href="#local-6989586621679540782"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679540781"><span class="annot"><a href="#local-6989586621679540781"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679540780"><span class="annot"><a href="#local-6989586621679540780"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679540779"><span class="annot"><a href="#local-6989586621679540779"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679540778"><span class="annot"><a href="#local-6989586621679540778"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-127"></span><span>    </span><span class="hs-special">{</span><span> </span><span id="tsGradient"><span class="annot"><span class="annottext">TensorSpec gradient layout device dataType shape
-&gt; SGradient gradient
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#tsGradient"><span class="hs-identifier hs-var hs-var">tsGradient</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier hs-type">SGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540782"><span class="hs-identifier hs-type">gradient</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-128"></span><span>      </span><span id="tsLayout"><span class="annot"><span class="annottext">TensorSpec gradient layout device dataType shape -&gt; SLayout layout
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#tsLayout"><span class="hs-identifier hs-var hs-var">tsLayout</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#SLayout"><span class="hs-identifier hs-type">SLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540781"><span class="hs-identifier hs-type">layout</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-129"></span><span>      </span><span id="tsDevice"><span class="annot"><span class="annottext">TensorSpec gradient layout device dataType shape -&gt; SDevice device
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#tsDevice"><span class="hs-identifier hs-var hs-var">tsDevice</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#SDevice"><span class="hs-identifier hs-type">SDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540780"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-130"></span><span>      </span><span id="tsDataType"><span class="annot"><span class="annottext">TensorSpec gradient layout device dataType shape
-&gt; SDataType dataType
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#tsDataType"><span class="hs-identifier hs-var hs-var">tsDataType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier hs-type">SDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540779"><span class="hs-identifier hs-type">dataType</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-131"></span><span>      </span><span id="tsShape"><span class="annot"><span class="annottext">TensorSpec gradient layout device dataType shape -&gt; SShape shape
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#tsShape"><span class="hs-identifier hs-var hs-var">tsShape</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-type">SShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540778"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-132"></span><span>    </span><span class="hs-special">}</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-133"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorSpec"><span class="hs-identifier hs-type">TensorSpec</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540782"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540781"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540780"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540779"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540778"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-134"></span><span>
</span><span id="line-135"></span><span class="hs-comment">-- | Alias for an untyped tensor without gradients.</span><span>
</span><span id="line-136"></span><span class="hs-keyword">type</span><span> </span><span id="UncheckedTensor"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#UncheckedTensor"><span class="hs-identifier hs-var">UncheckedTensor</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#UncheckedGradient"><span class="hs-identifier hs-type">UncheckedGradient</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#UncheckedLayout"><span class="hs-identifier hs-type">UncheckedLayout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#UncheckedDevice"><span class="hs-identifier hs-type">UncheckedDevice</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#UncheckedDataType"><span class="hs-identifier hs-type">UncheckedDataType</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#UncheckedShape"><span class="hs-identifier hs-type">UncheckedShape</span></a></span><span>
</span><span id="line-137"></span><span>
</span><span id="line-138"></span><span class="hs-comment">-- | Alias for an untyped tensor with gradients.</span><span>
</span><span id="line-139"></span><span class="hs-keyword">type</span><span> </span><span id="UncheckedParameter"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#UncheckedParameter"><span class="hs-identifier hs-var">UncheckedParameter</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#WithGradient"><span class="hs-identifier hs-type">WithGradient</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#UncheckedLayout"><span class="hs-identifier hs-type">UncheckedLayout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#UncheckedDevice"><span class="hs-identifier hs-type">UncheckedDevice</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#UncheckedDataType"><span class="hs-identifier hs-type">UncheckedDataType</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#UncheckedShape"><span class="hs-identifier hs-type">UncheckedShape</span></a></span><span>
</span><span id="line-140"></span><span>
</span><span id="line-141"></span><span class="hs-comment">-- | Alias for a tensor on CPU memory without gradients.</span><span>
</span><span id="line-142"></span><span class="hs-keyword">type</span><span> </span><span id="CPUTensor"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#CPUTensor"><span class="hs-identifier hs-var">CPUTensor</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#WithoutGradient"><span class="hs-identifier hs-type">WithoutGradient</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Dense"><span class="hs-identifier hs-type">Dense</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier hs-type">Device</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#CPU"><span class="hs-identifier hs-type">CPU</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-143"></span><span>
</span><span id="line-144"></span><span class="hs-comment">-- | Alias for a tensor on CPU memory with gradients.</span><span>
</span><span id="line-145"></span><span class="hs-keyword">type</span><span> </span><span id="CPUParameter"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#CPUParameter"><span class="hs-identifier hs-var">CPUParameter</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#WithGradient"><span class="hs-identifier hs-type">WithGradient</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Dense"><span class="hs-identifier hs-type">Dense</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier hs-type">Device</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#CPU"><span class="hs-identifier hs-type">CPU</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-146"></span><span>
</span><span id="line-147"></span><span class="hs-comment">-- | Alias for a sparse tensor on CPU memory without gradients.</span><span>
</span><span id="line-148"></span><span class="hs-keyword">type</span><span> </span><span id="SparseCPUTensor"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SparseCPUTensor"><span class="hs-identifier hs-var">SparseCPUTensor</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#WithoutGradient"><span class="hs-identifier hs-type">WithoutGradient</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Sparse"><span class="hs-identifier hs-type">Sparse</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier hs-type">Device</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#CPU"><span class="hs-identifier hs-type">CPU</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-149"></span><span>
</span><span id="line-150"></span><span class="hs-comment">-- | Alias for a sparse tensor on CPU memory with gradients.</span><span>
</span><span id="line-151"></span><span class="hs-keyword">type</span><span> </span><span id="SparseCPUParameter"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SparseCPUParameter"><span class="hs-identifier hs-var">SparseCPUParameter</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#WithGradient"><span class="hs-identifier hs-type">WithGradient</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Sparse"><span class="hs-identifier hs-type">Sparse</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier hs-type">Device</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#CPU"><span class="hs-identifier hs-type">CPU</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-152"></span><span>
</span><span id="line-153"></span><span class="hs-comment">-- | Alias for a tensor on CUDA memory without gradients.</span><span>
</span><span id="line-154"></span><span class="hs-keyword">type</span><span> </span><span id="CUDATensor"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#CUDATensor"><span class="hs-identifier hs-var">CUDATensor</span></a></span></span><span> </span><span id="local-6989586621679540765"><span class="annot"><a href="#local-6989586621679540765"><span class="hs-identifier hs-type">deviceId</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#WithoutGradient"><span class="hs-identifier hs-type">WithoutGradient</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Dense"><span class="hs-identifier hs-type">Dense</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier hs-type">Device</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#CUDA"><span class="hs-identifier hs-type">CUDA</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540765"><span class="hs-identifier hs-type">deviceId</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-155"></span><span>
</span><span id="line-156"></span><span class="hs-comment">-- | Alias for a tensor on CUDA memory with gradients.</span><span>
</span><span id="line-157"></span><span class="hs-keyword">type</span><span> </span><span id="CUDAParameter"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#CUDAParameter"><span class="hs-identifier hs-var">CUDAParameter</span></a></span></span><span> </span><span id="local-6989586621679540763"><span class="annot"><a href="#local-6989586621679540763"><span class="hs-identifier hs-type">deviceId</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#WithGradient"><span class="hs-identifier hs-type">WithGradient</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Dense"><span class="hs-identifier hs-type">Dense</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier hs-type">Device</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#CUDA"><span class="hs-identifier hs-type">CUDA</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540763"><span class="hs-identifier hs-type">deviceId</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-158"></span><span>
</span><span id="line-159"></span><span class="hs-comment">-- | Alias for a sparse tensor on CUDA memory without gradients.</span><span>
</span><span id="line-160"></span><span class="hs-keyword">type</span><span> </span><span id="SparseCUDATensor"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SparseCUDATensor"><span class="hs-identifier hs-var">SparseCUDATensor</span></a></span></span><span> </span><span id="local-6989586621679540761"><span class="annot"><a href="#local-6989586621679540761"><span class="hs-identifier hs-type">deviceId</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#WithoutGradient"><span class="hs-identifier hs-type">WithoutGradient</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Sparse"><span class="hs-identifier hs-type">Sparse</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier hs-type">Device</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#CUDA"><span class="hs-identifier hs-type">CUDA</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540761"><span class="hs-identifier hs-type">deviceId</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-161"></span><span>
</span><span id="line-162"></span><span class="hs-comment">-- | Alias for a sparse tensor on CUDA memory with gradients.</span><span>
</span><span id="line-163"></span><span class="hs-keyword">type</span><span> </span><span id="SparseCUDAParameter"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SparseCUDAParameter"><span class="hs-identifier hs-var">SparseCUDAParameter</span></a></span></span><span> </span><span id="local-6989586621679540759"><span class="annot"><a href="#local-6989586621679540759"><span class="hs-identifier hs-type">deviceId</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#WithGradient"><span class="hs-identifier hs-type">WithGradient</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Sparse"><span class="hs-identifier hs-type">Sparse</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier hs-type">Device</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#CUDA"><span class="hs-identifier hs-type">CUDA</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540759"><span class="hs-identifier hs-type">deviceId</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-164"></span><span>
</span><span id="line-165"></span><span id="local-6989586621679540754"><span id="local-6989586621679540755"><span id="local-6989586621679540756"><span id="local-6989586621679540757"><span id="local-6989586621679540758"><span class="hs-keyword">instance</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Num</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540758"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540757"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540756"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540755"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540754"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-166"></span><span>  </span><span id="local-6989586621679540745"><span class="annot"><span class="annottext">+ :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><span class="hs-operator hs-var hs-var hs-var hs-var">(+)</span></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; (Tensor gradient layout device dataType shape
    -&gt; IO (Tensor gradient layout device dataType shape))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">((Tensor gradient layout device dataType shape
  -&gt; IO (Tensor gradient layout device dataType shape))
 -&gt; Tensor gradient layout device dataType shape
 -&gt; Tensor gradient layout device dataType shape)
-&gt; (Tensor gradient layout device dataType shape
    -&gt; Tensor gradient layout device dataType shape
    -&gt; IO (Tensor gradient layout device dataType shape))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.add_tt</span></a></span><span>
</span><span id="line-167"></span><span>  </span><span id="local-6989586621679540741"><span class="hs-special">(</span><span class="hs-glyph">-</span><span class="hs-special">)</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; (Tensor gradient layout device dataType shape
    -&gt; IO (Tensor gradient layout device dataType shape))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">((Tensor gradient layout device dataType shape
  -&gt; IO (Tensor gradient layout device dataType shape))
 -&gt; Tensor gradient layout device dataType shape
 -&gt; Tensor gradient layout device dataType shape)
-&gt; (Tensor gradient layout device dataType shape
    -&gt; Tensor gradient layout device dataType shape
    -&gt; IO (Tensor gradient layout device dataType shape))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.sub_tt</span></a></span><span>
</span><span id="line-168"></span><span>  </span><span id="local-6989586621679540739"><span class="annot"><span class="annottext">* :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><span class="hs-operator hs-var hs-var hs-var hs-var">(*)</span></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; (Tensor gradient layout device dataType shape
    -&gt; IO (Tensor gradient layout device dataType shape))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">((Tensor gradient layout device dataType shape
  -&gt; IO (Tensor gradient layout device dataType shape))
 -&gt; Tensor gradient layout device dataType shape
 -&gt; Tensor gradient layout device dataType shape)
-&gt; (Tensor gradient layout device dataType shape
    -&gt; Tensor gradient layout device dataType shape
    -&gt; IO (Tensor gradient layout device dataType shape))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.mul_tt</span></a></span><span>
</span><span id="line-169"></span><span>  </span><span id="local-6989586621679540736"><span class="annot"><span class="annottext">negate :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><span class="hs-identifier hs-var hs-var hs-var hs-var">negate</span></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; (Tensor gradient layout device dataType shape
    -&gt; IO (Tensor gradient layout device dataType shape))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.neg_t</span></a></span><span>
</span><span id="line-170"></span><span>  </span><span id="local-6989586621679540734"><span class="annot"><span class="annottext">abs :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><span class="hs-identifier hs-var hs-var hs-var hs-var">abs</span></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; (Tensor gradient layout device dataType shape
    -&gt; IO (Tensor gradient layout device dataType shape))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.abs_t</span></a></span><span>
</span><span id="line-171"></span><span>  </span><span id="local-6989586621679540731"><span class="annot"><span class="annottext">signum :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><span class="hs-identifier hs-var hs-var hs-var hs-var">signum</span></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; (Tensor gradient layout device dataType shape
    -&gt; IO (Tensor gradient layout device dataType shape))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.sign_t</span></a></span><span>
</span><span id="line-172"></span><span>  </span><span id="local-6989586621679540728"><span class="annot"><span class="annottext">fromInteger :: Integer -&gt; Tensor gradient layout device dataType shape
</span><span class="hs-identifier hs-var hs-var hs-var hs-var">fromInteger</span></span></span><span> </span><span id="local-6989586621679540727"><span class="annot"><span class="annottext">Integer
</span><a href="#local-6989586621679540727"><span class="hs-identifier hs-var">_a</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span></span></span></span></span></span><span>
</span><span id="line-173"></span><span>
</span><span id="line-174"></span><span id="local-6989586621679540721"><span id="local-6989586621679540722"><span id="local-6989586621679540723"><span id="local-6989586621679540724"><span id="local-6989586621679540725"><span class="hs-keyword">instance</span><span>
</span><span id="line-175"></span><span>  </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-type">Castable</span></a></span><span>
</span><span id="line-176"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540725"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540724"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540723"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540722"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540721"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-177"></span><span>    </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">ForeignPtr</span></span><span> </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-type">ATen.Tensor</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-178"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-179"></span><span>  </span><span id="local-6989586621679540717"><span class="annot"><span class="annottext">cast :: Tensor gradient layout device dataType shape
-&gt; (ForeignPtr Tensor -&gt; IO r) -&gt; IO r
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var hs-var hs-var hs-var">cast</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#UnsafeTensor"><span class="hs-identifier hs-type">UnsafeTensor</span></a></span><span> </span><span id="local-6989586621679540715"><span class="annot"><span class="annottext">ForeignPtr Tensor
</span><a href="#local-6989586621679540715"><span class="hs-identifier hs-var">atenTensor</span></a></span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679540714"><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO r
</span><a href="#local-6989586621679540714"><span class="hs-identifier hs-var">f</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO r
</span><a href="#local-6989586621679540714"><span class="hs-identifier hs-var">f</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
</span><a href="#local-6989586621679540715"><span class="hs-identifier hs-var">atenTensor</span></a></span><span>
</span><span id="line-180"></span><span>  </span><span id="local-6989586621679540713"><span class="annot"><span class="annottext">uncast :: ForeignPtr Tensor
-&gt; (Tensor gradient layout device dataType shape -&gt; IO r) -&gt; IO r
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var hs-var hs-var hs-var">uncast</span></a></span></span><span> </span><span id="local-6989586621679540711"><span class="annot"><span class="annottext">ForeignPtr Tensor
</span><a href="#local-6989586621679540711"><span class="hs-identifier hs-var">atenTensor</span></a></span></span><span> </span><span id="local-6989586621679540710"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape -&gt; IO r
</span><a href="#local-6989586621679540710"><span class="hs-identifier hs-var">f</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape -&gt; IO r
</span><a href="#local-6989586621679540710"><span class="hs-identifier hs-var">f</span></a></span><span> </span><span class="annot"><span class="annottext">(Tensor gradient layout device dataType shape -&gt; IO r)
-&gt; Tensor gradient layout device dataType shape -&gt; IO r
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; Tensor gradient layout device dataType shape
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
ForeignPtr Tensor -&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#UnsafeTensor"><span class="hs-identifier hs-var">UnsafeTensor</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
</span><a href="#local-6989586621679540711"><span class="hs-identifier hs-var">atenTensor</span></a></span></span></span></span></span></span><span>
</span><span id="line-181"></span><span>
</span><span id="line-182"></span><span id="local-6989586621679540705"><span id="local-6989586621679540706"><span id="local-6989586621679540707"><span id="local-6989586621679540708"><span id="local-6989586621679540709"><span class="hs-keyword">instance</span><span>
</span><span id="line-183"></span><span>  </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-type">Castable</span></a></span><span>
</span><span id="line-184"></span><span>    </span><span class="hs-special">[</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540709"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540708"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540707"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540706"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540705"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-185"></span><span>    </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">ForeignPtr</span></span><span> </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-type">ATen.TensorList</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-186"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-187"></span><span>  </span><span id="local-6989586621679540702"><span class="annot"><span class="annottext">cast :: [Tensor gradient layout device dataType shape]
-&gt; (ForeignPtr TensorList -&gt; IO r) -&gt; IO r
</span><a href="#local-6989586621679540702"><span class="hs-identifier hs-var hs-var hs-var hs-var">cast</span></a></span></span><span> </span><span id="local-6989586621679540701"><span class="annot"><span class="annottext">[Tensor gradient layout device dataType shape]
</span><a href="#local-6989586621679540701"><span class="hs-identifier hs-var">xs</span></a></span></span><span> </span><span id="local-6989586621679540700"><span class="annot"><span class="annottext">ForeignPtr TensorList -&gt; IO r
</span><a href="#local-6989586621679540700"><span class="hs-identifier hs-var">f</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-188"></span><span>    </span><span id="local-6989586621679540699"><span class="annot"><span class="annottext">[ForeignPtr Tensor]
</span><a href="#local-6989586621679540699"><span class="hs-identifier hs-var">ptrList</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">(Tensor gradient layout device dataType shape
 -&gt; IO (ForeignPtr Tensor))
-&gt; [Tensor gradient layout device dataType shape]
-&gt; IO [ForeignPtr Tensor]
forall (t :: * -&gt; *) (m :: * -&gt; *) a b.
(Traversable t, Monad m) =&gt;
(a -&gt; m b) -&gt; t a -&gt; m (t b)
</span><span class="hs-identifier hs-var">mapM</span></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">\</span><span id="local-6989586621679540697"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679540697"><span class="hs-identifier hs-var">x</span></a></span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
-&gt; (ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; IO (ForeignPtr Tensor)
forall a b r. Castable a b =&gt; a -&gt; (b -&gt; IO r) -&gt; IO r
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679540697"><span class="hs-identifier hs-var">x</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
forall (m :: * -&gt; *) a. Monad m =&gt; a -&gt; m a
</span><span class="hs-identifier hs-var">return</span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">IO</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">ForeignPtr</span></span><span> </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-type">ATen.Tensor</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">[Tensor gradient layout device dataType shape]
</span><a href="#local-6989586621679540701"><span class="hs-identifier hs-var">xs</span></a></span><span>
</span><span id="line-189"></span><span>    </span><span class="annot"><span class="annottext">[ForeignPtr Tensor] -&gt; (ForeignPtr TensorList -&gt; IO r) -&gt; IO r
forall a b r. Castable a b =&gt; a -&gt; (b -&gt; IO r) -&gt; IO r
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast</span></a></span><span> </span><span class="annot"><span class="annottext">[ForeignPtr Tensor]
</span><a href="#local-6989586621679540699"><span class="hs-identifier hs-var">ptrList</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr TensorList -&gt; IO r
</span><a href="#local-6989586621679540700"><span class="hs-identifier hs-var">f</span></a></span><span>
</span><span id="line-190"></span><span>  </span><span id="local-6989586621679540696"><span class="annot"><span class="annottext">uncast :: ForeignPtr TensorList
-&gt; ([Tensor gradient layout device dataType shape] -&gt; IO r) -&gt; IO r
</span><a href="#local-6989586621679540696"><span class="hs-identifier hs-var hs-var hs-var hs-var">uncast</span></a></span></span><span> </span><span id="local-6989586621679540695"><span class="annot"><span class="annottext">ForeignPtr TensorList
</span><a href="#local-6989586621679540695"><span class="hs-identifier hs-var">xs</span></a></span></span><span> </span><span id="local-6989586621679540694"><span class="annot"><span class="annottext">[Tensor gradient layout device dataType shape] -&gt; IO r
</span><a href="#local-6989586621679540694"><span class="hs-identifier hs-var">f</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ForeignPtr TensorList -&gt; ([ForeignPtr Tensor] -&gt; IO r) -&gt; IO r
forall a b r. Castable a b =&gt; b -&gt; (a -&gt; IO r) -&gt; IO r
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">uncast</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr TensorList
</span><a href="#local-6989586621679540695"><span class="hs-identifier hs-var">xs</span></a></span><span> </span><span class="annot"><span class="annottext">(([ForeignPtr Tensor] -&gt; IO r) -&gt; IO r)
-&gt; ([ForeignPtr Tensor] -&gt; IO r) -&gt; IO r
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-glyph">\</span><span id="local-6989586621679540693"><span class="annot"><span class="annottext">[ForeignPtr Tensor]
</span><a href="#local-6989586621679540693"><span class="hs-identifier hs-var">ptrList</span></a></span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-191"></span><span>    </span><span id="local-6989586621679540692"><span class="annot"><span class="annottext">[Tensor gradient layout device dataType shape]
</span><a href="#local-6989586621679540692"><span class="hs-identifier hs-var">tensorList</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; IO (Tensor gradient layout device dataType shape))
-&gt; [ForeignPtr Tensor]
-&gt; IO [Tensor gradient layout device dataType shape]
forall (t :: * -&gt; *) (m :: * -&gt; *) a b.
(Traversable t, Monad m) =&gt;
(a -&gt; m b) -&gt; t a -&gt; m (t b)
</span><span class="hs-identifier hs-var">mapM</span></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">\</span><span class="hs-special">(</span><span id="local-6989586621679540691"><span class="annot"><span class="annottext">ForeignPtr Tensor
</span><a href="#local-6989586621679540691"><span class="hs-identifier hs-var">x</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">ForeignPtr</span></span><span> </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-type">ATen.Tensor</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; (Tensor gradient layout device dataType shape
    -&gt; IO (Tensor gradient layout device dataType shape))
-&gt; IO (Tensor gradient layout device dataType shape)
forall a b r. Castable a b =&gt; b -&gt; (a -&gt; IO r) -&gt; IO r
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">uncast</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
</span><a href="#local-6989586621679540691"><span class="hs-identifier hs-var">x</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
-&gt; IO (Tensor gradient layout device dataType shape)
forall (m :: * -&gt; *) a. Monad m =&gt; a -&gt; m a
</span><span class="hs-identifier hs-var">return</span></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">[ForeignPtr Tensor]
</span><a href="#local-6989586621679540693"><span class="hs-identifier hs-var">ptrList</span></a></span><span>
</span><span id="line-192"></span><span>    </span><span class="annot"><span class="annottext">[Tensor gradient layout device dataType shape] -&gt; IO r
</span><a href="#local-6989586621679540694"><span class="hs-identifier hs-var">f</span></a></span><span> </span><span class="annot"><span class="annottext">[Tensor gradient layout device dataType shape]
</span><a href="#local-6989586621679540692"><span class="hs-identifier hs-var">tensorList</span></a></span></span></span></span></span></span><span>
</span><span id="line-193"></span><span>
</span><span id="line-194"></span><span class="hs-keyword">instance</span><span> </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-type">Castable</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../../../../hasktorch/html/src"><span class="hs-identifier hs-type">HList</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">ForeignPtr</span></span><span> </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-type">ATen.Tensor</span></a></span><span class="hs-special">]</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-195"></span><span>  </span><span id="local-6989586621679540688"><span class="annot"><span class="annottext">cast :: HList '[] -&gt; ([ForeignPtr Tensor] -&gt; IO r) -&gt; IO r
</span><a href="#local-6989586621679540688"><span class="hs-identifier hs-var hs-var hs-var hs-var">cast</span></a></span></span><span> </span><span class="annot"><span class="annottext">HList '[]
</span><a href="../../../../hasktorch/html/src"><span class="hs-identifier hs-var">HNil</span></a></span><span> </span><span id="local-6989586621679540686"><span class="annot"><span class="annottext">[ForeignPtr Tensor] -&gt; IO r
</span><a href="#local-6989586621679540686"><span class="hs-identifier hs-var">f</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">[ForeignPtr Tensor] -&gt; IO r
</span><a href="#local-6989586621679540686"><span class="hs-identifier hs-var">f</span></a></span><span> </span><span class="hs-special">[</span><span class="hs-special">]</span><span>
</span><span id="line-196"></span><span>  </span><span id="local-6989586621679540685"><span class="annot"><span class="annottext">uncast :: [ForeignPtr Tensor] -&gt; (HList '[] -&gt; IO r) -&gt; IO r
</span><a href="#local-6989586621679540685"><span class="hs-identifier hs-var hs-var hs-var hs-var">uncast</span></a></span></span><span> </span><span class="hs-special">[</span><span class="hs-special">]</span><span> </span><span id="local-6989586621679540684"><span class="annot"><span class="annottext">HList '[] -&gt; IO r
</span><a href="#local-6989586621679540684"><span class="hs-identifier hs-var">f</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">HList '[] -&gt; IO r
</span><a href="#local-6989586621679540684"><span class="hs-identifier hs-var">f</span></a></span><span> </span><span class="annot"><span class="annottext">HList '[]
forall k. HList '[]
</span><a href="../../../../hasktorch/html/src"><span class="hs-identifier hs-var">HNil</span></a></span><span>
</span><span id="line-197"></span><span>  </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">uncast</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">ForeignPtr Tensor
</span><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-glyph hs-type">:</span></span><span> </span><span class="annot"><span class="annottext">[ForeignPtr Tensor]
</span><span class="hs-identifier">_</span></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">HList '[] -&gt; IO r
</span><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">String -&gt; IO r
forall (m :: * -&gt; *) a. MonadFail m =&gt; String -&gt; m a
</span><span class="hs-identifier hs-var">fail</span></span><span> </span><span class="annot"><span class="annottext">String
</span><span class="hs-string">&quot;The list of tensors has more elements than expected. This means that the runtime length of the list exceeded its compile-time length.&quot;</span></span><span>
</span><span id="line-198"></span><span>
</span><span id="line-199"></span><span id="local-6989586621679540678"><span id="local-6989586621679540679"><span id="local-6989586621679540680"><span id="local-6989586621679540681"><span id="local-6989586621679540682"><span id="local-6989586621679540683"><span class="hs-keyword">instance</span><span>
</span><span id="line-200"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-type">Castable</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../../../../hasktorch/html/src"><span class="hs-identifier hs-type">HList</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540683"><span class="hs-identifier hs-type">tensors</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">ForeignPtr</span></span><span> </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-type">ATen.Tensor</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-201"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-202"></span><span>  </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-type">Castable</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../../../../hasktorch/html/src"><span class="hs-identifier hs-type">HList</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540682"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540681"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540680"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540679"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540678"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-glyph">:</span><span> </span><span class="annot"><a href="#local-6989586621679540683"><span class="hs-identifier hs-type">tensors</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">ForeignPtr</span></span><span> </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-type">ATen.Tensor</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-203"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-204"></span><span>  </span><span id="local-6989586621679540675"><span class="annot"><span class="annottext">cast :: HList (Tensor gradient layout device dataType shape : tensors)
-&gt; ([ForeignPtr Tensor] -&gt; IO r) -&gt; IO r
</span><a href="#local-6989586621679540675"><span class="hs-identifier hs-var hs-var hs-var hs-var">cast</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../../../../hasktorch/html/src"><span class="hs-identifier hs-type">HCons</span></a></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679540673"><span class="annot"><a href="#local-6989586621679540673"><span class="hs-identifier hs-var">tensor</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679540672"><span class="annot"><a href="#local-6989586621679540672"><span class="hs-identifier hs-var">tensors</span></a></span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span id="local-6989586621679540671"><span class="annot"><span class="annottext">[ForeignPtr Tensor] -&gt; IO r
</span><a href="#local-6989586621679540671"><span class="hs-identifier hs-var">f</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-205"></span><span>    </span><span id="local-6989586621679540670"><span class="annot"><span class="annottext">ForeignPtr Tensor
</span><a href="#local-6989586621679540670"><span class="hs-identifier hs-var">ptr</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
-&gt; (ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; IO (ForeignPtr Tensor)
forall a b r. Castable a b =&gt; a -&gt; (b -&gt; IO r) -&gt; IO r
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679540673"><span class="hs-identifier hs-var">tensor</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span>
</span><span id="line-206"></span><span>    </span><span id="local-6989586621679540669"><span class="annot"><span class="annottext">[ForeignPtr Tensor]
</span><a href="#local-6989586621679540669"><span class="hs-identifier hs-var">ptrList</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">HList tensors
-&gt; ([ForeignPtr Tensor] -&gt; IO [ForeignPtr Tensor])
-&gt; IO [ForeignPtr Tensor]
forall a b r. Castable a b =&gt; a -&gt; (b -&gt; IO r) -&gt; IO r
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast</span></a></span><span> </span><span class="annot"><span class="annottext">HList tensors
</span><a href="#local-6989586621679540672"><span class="hs-identifier hs-var">tensors</span></a></span><span> </span><span class="annot"><span class="annottext">[ForeignPtr Tensor] -&gt; IO [ForeignPtr Tensor]
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span>
</span><span id="line-207"></span><span>    </span><span class="annot"><span class="annottext">[ForeignPtr Tensor] -&gt; IO r
</span><a href="#local-6989586621679540671"><span class="hs-identifier hs-var">f</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">ForeignPtr Tensor
</span><a href="#local-6989586621679540670"><span class="hs-identifier hs-var">ptr</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; [ForeignPtr Tensor] -&gt; [ForeignPtr Tensor]
forall a. a -&gt; [a] -&gt; [a]
</span><span class="hs-glyph hs-var">:</span></span><span> </span><span class="annot"><span class="annottext">[ForeignPtr Tensor]
</span><a href="#local-6989586621679540669"><span class="hs-identifier hs-var">ptrList</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-208"></span><span>  </span><span id="local-6989586621679540668"><span class="annot"><span class="annottext">uncast :: [ForeignPtr Tensor]
-&gt; (HList (Tensor gradient layout device dataType shape : tensors)
    -&gt; IO r)
-&gt; IO r
</span><a href="#local-6989586621679540668"><span class="hs-identifier hs-var hs-var hs-var hs-var">uncast</span></a></span></span><span> </span><span class="hs-special">[</span><span class="hs-special">]</span><span> </span><span class="annot"><span class="annottext">HList (Tensor gradient layout device dataType shape : tensors)
-&gt; IO r
</span><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">String -&gt; IO r
forall (m :: * -&gt; *) a. MonadFail m =&gt; String -&gt; m a
</span><span class="hs-identifier hs-var">fail</span></span><span> </span><span class="annot"><span class="annottext">String
</span><span class="hs-string">&quot;The list of tensors ended prematurely. This means that the runtime length of the list was smaller than its compile-time length.&quot;</span></span><span>
</span><span id="line-209"></span><span>  </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">uncast</span></a></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679540667"><span class="annot"><span class="annottext">ForeignPtr Tensor
</span><a href="#local-6989586621679540667"><span class="hs-identifier hs-var">ptr</span></a></span></span><span> </span><span class="annot"><span class="hs-glyph hs-type">:</span></span><span> </span><span id="local-6989586621679540666"><span class="annot"><span class="annottext">[ForeignPtr Tensor]
</span><a href="#local-6989586621679540666"><span class="hs-identifier hs-var">ptrList</span></a></span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679540665"><span class="annot"><span class="annottext">HList (Tensor gradient layout device dataType shape : tensors)
-&gt; IO r
</span><a href="#local-6989586621679540665"><span class="hs-identifier hs-var">f</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-210"></span><span>    </span><span id="local-6989586621679540664"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679540664"><span class="hs-identifier hs-var">tensor</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; (Tensor gradient layout device dataType shape
    -&gt; IO (Tensor gradient layout device dataType shape))
-&gt; IO (Tensor gradient layout device dataType shape)
forall a b r. Castable a b =&gt; b -&gt; (a -&gt; IO r) -&gt; IO r
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">uncast</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
</span><a href="#local-6989586621679540667"><span class="hs-identifier hs-var">ptr</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
-&gt; IO (Tensor gradient layout device dataType shape)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span>
</span><span id="line-211"></span><span>    </span><span id="local-6989586621679540663"><span class="annot"><span class="annottext">HList tensors
</span><a href="#local-6989586621679540663"><span class="hs-identifier hs-var">tensors</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">[ForeignPtr Tensor]
-&gt; (HList tensors -&gt; IO (HList tensors)) -&gt; IO (HList tensors)
forall a b r. Castable a b =&gt; b -&gt; (a -&gt; IO r) -&gt; IO r
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">uncast</span></a></span><span> </span><span class="annot"><span class="annottext">[ForeignPtr Tensor]
</span><a href="#local-6989586621679540666"><span class="hs-identifier hs-var">ptrList</span></a></span><span> </span><span class="annot"><span class="annottext">HList tensors -&gt; IO (HList tensors)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span>
</span><span id="line-212"></span><span>    </span><span class="annot"><span class="annottext">HList (Tensor gradient layout device dataType shape : tensors)
-&gt; IO r
</span><a href="#local-6989586621679540665"><span class="hs-identifier hs-var">f</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679540664"><span class="hs-identifier hs-var">tensor</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
-&gt; HList tensors
-&gt; HList (Tensor gradient layout device dataType shape : tensors)
forall x (xs :: [*]). x -&gt; HList xs -&gt; HList (x : xs)
</span><a href="../../../../hasktorch/html/src"><span class="hs-operator hs-var">:.</span></a></span><span> </span><span class="annot"><span class="annottext">HList tensors
</span><a href="#local-6989586621679540663"><span class="hs-identifier hs-var">tensors</span></a></span><span class="hs-special">)</span></span></span></span></span></span></span><span>
</span><span id="line-213"></span><span>
</span><span id="line-214"></span><span id="local-6989586621679540662"><span class="hs-keyword">instance</span><span>
</span><span id="line-215"></span><span>  </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-type">Castable</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../../../../hasktorch/html/src"><span class="hs-identifier hs-type">HList</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540662"><span class="hs-identifier hs-type">l</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">ForeignPtr</span></span><span> </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-type">ATen.Tensor</span></a></span><span class="hs-special">]</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-216"></span><span>  </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-type">Castable</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../../../../hasktorch/html/src"><span class="hs-identifier hs-type">HList</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540662"><span class="hs-identifier hs-type">l</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">ForeignPtr</span></span><span> </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-type">ATen.TensorList</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-217"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-218"></span><span>  </span><span id="local-6989586621679540659"><span class="annot"><span class="annottext">cast :: HList l -&gt; (ForeignPtr TensorList -&gt; IO r) -&gt; IO r
</span><a href="#local-6989586621679540659"><span class="hs-identifier hs-var hs-var hs-var hs-var">cast</span></a></span></span><span> </span><span id="local-6989586621679540658"><span class="annot"><span class="annottext">HList l
</span><a href="#local-6989586621679540658"><span class="hs-identifier hs-var">xs</span></a></span></span><span> </span><span id="local-6989586621679540657"><span class="annot"><span class="annottext">ForeignPtr TensorList -&gt; IO r
</span><a href="#local-6989586621679540657"><span class="hs-identifier hs-var">f</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-219"></span><span>    </span><span id="local-6989586621679540656"><span class="annot"><span class="annottext">[ForeignPtr Tensor]
</span><a href="#local-6989586621679540656"><span class="hs-identifier hs-var">ts</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">HList l
-&gt; ([ForeignPtr Tensor] -&gt; IO [ForeignPtr Tensor])
-&gt; IO [ForeignPtr Tensor]
forall a b r. Castable a b =&gt; a -&gt; (b -&gt; IO r) -&gt; IO r
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast</span></a></span><span> </span><span class="annot"><span class="annottext">HList l
</span><a href="#local-6989586621679540658"><span class="hs-identifier hs-var">xs</span></a></span><span> </span><span class="annot"><span class="annottext">[ForeignPtr Tensor] -&gt; IO [ForeignPtr Tensor]
forall (m :: * -&gt; *) a. Monad m =&gt; a -&gt; m a
</span><span class="hs-identifier hs-var">return</span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">IO</span></span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">ForeignPtr</span></span><span> </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-type">ATen.Tensor</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-220"></span><span>    </span><span class="annot"><span class="annottext">[ForeignPtr Tensor] -&gt; (ForeignPtr TensorList -&gt; IO r) -&gt; IO r
forall a b r. Castable a b =&gt; a -&gt; (b -&gt; IO r) -&gt; IO r
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast</span></a></span><span> </span><span class="annot"><span class="annottext">[ForeignPtr Tensor]
</span><a href="#local-6989586621679540656"><span class="hs-identifier hs-var">ts</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr TensorList -&gt; IO r
</span><a href="#local-6989586621679540657"><span class="hs-identifier hs-var">f</span></a></span><span>
</span><span id="line-221"></span><span>  </span><span id="local-6989586621679540655"><span class="annot"><span class="annottext">uncast :: ForeignPtr TensorList -&gt; (HList l -&gt; IO r) -&gt; IO r
</span><a href="#local-6989586621679540655"><span class="hs-identifier hs-var hs-var hs-var hs-var">uncast</span></a></span></span><span> </span><span id="local-6989586621679540654"><span class="annot"><span class="annottext">ForeignPtr TensorList
</span><a href="#local-6989586621679540654"><span class="hs-identifier hs-var">xs</span></a></span></span><span> </span><span id="local-6989586621679540653"><span class="annot"><span class="annottext">HList l -&gt; IO r
</span><a href="#local-6989586621679540653"><span class="hs-identifier hs-var">f</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ForeignPtr TensorList -&gt; ([ForeignPtr Tensor] -&gt; IO r) -&gt; IO r
forall a b r. Castable a b =&gt; b -&gt; (a -&gt; IO r) -&gt; IO r
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">uncast</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr TensorList
</span><a href="#local-6989586621679540654"><span class="hs-identifier hs-var">xs</span></a></span><span> </span><span class="annot"><span class="annottext">(([ForeignPtr Tensor] -&gt; IO r) -&gt; IO r)
-&gt; ([ForeignPtr Tensor] -&gt; IO r) -&gt; IO r
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-glyph">\</span><span class="hs-special">(</span><span id="local-6989586621679540652"><span class="annot"><span class="annottext">[ForeignPtr Tensor]
</span><a href="#local-6989586621679540652"><span class="hs-identifier hs-var">ptrList</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">ForeignPtr</span></span><span> </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-type">ATen.Tensor</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-222"></span><span>    </span><span id="local-6989586621679540651"><span class="annot"><span class="annottext">HList l
</span><a href="#local-6989586621679540651"><span class="hs-identifier hs-var">ts</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">[ForeignPtr Tensor] -&gt; (HList l -&gt; IO (HList l)) -&gt; IO (HList l)
forall a b r. Castable a b =&gt; b -&gt; (a -&gt; IO r) -&gt; IO r
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">uncast</span></a></span><span> </span><span class="annot"><span class="annottext">[ForeignPtr Tensor]
</span><a href="#local-6989586621679540652"><span class="hs-identifier hs-var">ptrList</span></a></span><span> </span><span class="annot"><span class="annottext">HList l -&gt; IO (HList l)
forall (m :: * -&gt; *) a. Monad m =&gt; a -&gt; m a
</span><span class="hs-identifier hs-var">return</span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">IO</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../../../../hasktorch/html/src"><span class="hs-identifier hs-type">HList</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540662"><span class="hs-identifier hs-type">l</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-223"></span><span>    </span><span class="annot"><span class="annottext">HList l -&gt; IO r
</span><a href="#local-6989586621679540653"><span class="hs-identifier hs-var">f</span></a></span><span> </span><span class="annot"><span class="annottext">HList l
</span><a href="#local-6989586621679540651"><span class="hs-identifier hs-var">ts</span></a></span></span><span>
</span><span id="line-224"></span><span>
</span><span id="line-225"></span><span class="hs-comment">-- | Takes a tensor that may or may not require gradient computations</span><span>
</span><span id="line-226"></span><span class="hs-comment">-- and returns a copy that does not require them.</span><span>
</span><span id="line-227"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#withoutGradient"><span class="hs-identifier hs-type">withoutGradient</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-228"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679540649"><span class="annot"><a href="#local-6989586621679540649"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679540648"><span class="annot"><a href="#local-6989586621679540648"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679540647"><span class="annot"><a href="#local-6989586621679540647"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679540646"><span class="annot"><a href="#local-6989586621679540646"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679540645"><span class="annot"><a href="#local-6989586621679540645"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-229"></span><span>  </span><span class="hs-comment">-- | input tensor</span><span>
</span><span id="line-230"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540649"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540648"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540647"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540646"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540645"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-231"></span><span>  </span><span class="hs-comment">-- | copy of the input tensor without gradient computations turned off.</span><span>
</span><span id="line-232"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">IO</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#WithoutGradient"><span class="hs-identifier hs-type">WithoutGradient</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679540648"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540647"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540646"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540645"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-233"></span><span id="withoutGradient"><span class="annot"><span class="annottext">withoutGradient :: Tensor gradient layout device dataType shape
-&gt; IO
     (Tensor ('Gradient 'WithoutGradient) layout device dataType shape)
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#withoutGradient"><span class="hs-identifier hs-var hs-var">withoutGradient</span></a></span></span><span> </span><span id="local-6989586621679540644"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679540644"><span class="hs-identifier hs-var">tensor</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; CBool -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; Bool
-&gt; IO
     (Tensor ('Gradient 'WithoutGradient) layout device dataType shape)
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; CBool -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.tensor_set_requires_grad_b</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679540644"><span class="hs-identifier hs-var">tensor</span></a></span><span> </span><span class="annot"><span class="annottext">Bool
</span><span class="hs-identifier hs-var">False</span></span><span>
</span><span id="line-234"></span><span>
</span><span id="line-235"></span><span class="hs-comment">-- | Takes a tensor that does not requires gradient computations</span><span>
</span><span id="line-236"></span><span class="hs-comment">-- and returns a copy that requires them.</span><span>
</span><span id="line-237"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#withGradient"><span class="hs-identifier hs-type">withGradient</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-238"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679540641"><span class="annot"><a href="#local-6989586621679540641"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679540640"><span class="annot"><a href="#local-6989586621679540640"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679540639"><span class="annot"><a href="#local-6989586621679540639"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679540638"><span class="annot"><a href="#local-6989586621679540638"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679540637"><span class="annot"><a href="#local-6989586621679540637"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-239"></span><span>  </span><span class="hs-comment">-- | input tensor</span><span>
</span><span id="line-240"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540641"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540640"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540639"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540638"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540637"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-241"></span><span>  </span><span class="hs-comment">-- | copy of the input tensor with gradient computations turned on.</span><span>
</span><span id="line-242"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">IO</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#WithGradient"><span class="hs-identifier hs-type">WithGradient</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679540640"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540639"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540638"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540637"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-243"></span><span id="withGradient"><span class="annot"><span class="annottext">withGradient :: Tensor gradient layout device dataType shape
-&gt; IO
     (Tensor ('Gradient 'WithGradient) layout device dataType shape)
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#withGradient"><span class="hs-identifier hs-var hs-var">withGradient</span></a></span></span><span> </span><span id="local-6989586621679540636"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679540636"><span class="hs-identifier hs-var">tensor</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; CBool -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; Bool
-&gt; IO
     (Tensor ('Gradient 'WithGradient) layout device dataType shape)
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; CBool -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.tensor_set_requires_grad_b</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679540636"><span class="hs-identifier hs-var">tensor</span></a></span><span> </span><span class="annot"><span class="annottext">Bool
</span><span class="hs-identifier hs-var">True</span></span><span>
</span><span id="line-244"></span><span>
</span><span id="line-245"></span><span class="hs-comment">-- | Turn gradient computations off or on for a tensor.</span><span>
</span><span id="line-246"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#sSetGradient"><span class="hs-identifier hs-type">sSetGradient</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-247"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679540634"><span class="annot"><a href="#local-6989586621679540634"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679540633"><span class="annot"><a href="#local-6989586621679540633"><span class="hs-identifier hs-type">gradient'</span></a></span></span><span> </span><span id="local-6989586621679540632"><span class="annot"><a href="#local-6989586621679540632"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679540631"><span class="annot"><a href="#local-6989586621679540631"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679540630"><span class="annot"><a href="#local-6989586621679540630"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679540629"><span class="annot"><a href="#local-6989586621679540629"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-248"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier hs-type">SGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540634"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-249"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540633"><span class="hs-identifier hs-type">gradient'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540632"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540631"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540630"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540629"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-250"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">IO</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540634"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540632"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540631"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540630"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540629"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-251"></span><span id="sSetGradient"><span class="annot"><span class="annottext">sSetGradient :: SGradient gradient
-&gt; Tensor gradient' layout device dataType shape
-&gt; IO (Tensor gradient layout device dataType shape)
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sSetGradient"><span class="hs-identifier hs-var hs-var">sSetGradient</span></a></span></span><span> </span><span id="local-6989586621679540628"><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679540628"><span class="hs-identifier hs-var">gradient</span></a></span></span><span> </span><span id="local-6989586621679540627"><span class="annot"><span class="annottext">Tensor gradient' layout device dataType shape
</span><a href="#local-6989586621679540627"><span class="hs-identifier hs-var">tensor</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-252"></span><span>  </span><span class="hs-keyword">case</span><span> </span><span class="annot"><span class="annottext">IsChecked RequiresGradient -&gt; RequiresGradient
forall a. IsChecked a -&gt; a
</span><a href="Torch.GraduallyTyped.Prelude.html#forgetIsChecked"><span class="hs-identifier hs-var">forgetIsChecked</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Sing gradient -&gt; Demote (Gradient RequiresGradient)
forall k (a :: k). SingKind k =&gt; Sing a -&gt; Demote k
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">fromSing</span></a></span><span> </span><span class="annot"><span class="annottext">Sing gradient
SGradient gradient
</span><a href="#local-6989586621679540628"><span class="hs-identifier hs-var">gradient</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-keyword">of</span><span>
</span><span id="line-253"></span><span>    </span><span class="annot"><span class="annottext">RequiresGradient
</span><a href="Torch.GraduallyTyped.RequiresGradient.html#WithoutGradient"><span class="hs-identifier hs-var">WithoutGradient</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; CBool -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient' layout device dataType shape
-&gt; Bool
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; CBool -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.tensor_set_requires_grad_b</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient' layout device dataType shape
</span><a href="#local-6989586621679540627"><span class="hs-identifier hs-var">tensor</span></a></span><span> </span><span class="annot"><span class="annottext">Bool
</span><span class="hs-identifier hs-var">False</span></span><span>
</span><span id="line-254"></span><span>    </span><span class="annot"><span class="annottext">RequiresGradient
</span><a href="Torch.GraduallyTyped.RequiresGradient.html#WithGradient"><span class="hs-identifier hs-var">WithGradient</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; CBool -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient' layout device dataType shape
-&gt; Bool
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; CBool -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.tensor_set_requires_grad_b</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient' layout device dataType shape
</span><a href="#local-6989586621679540627"><span class="hs-identifier hs-var">tensor</span></a></span><span> </span><span class="annot"><span class="annottext">Bool
</span><span class="hs-identifier hs-var">True</span></span><span>
</span><span id="line-255"></span><span>
</span><span id="line-256"></span><span class="hs-keyword">class</span><span> </span><span id="SGetGradient"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetGradient"><span class="hs-identifier hs-var">SGetGradient</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679541728"><span class="annot"><a href="#local-6989586621679541728"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#RequiresGradient"><span class="hs-identifier hs-type">RequiresGradient</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-257"></span><span>  </span><span class="hs-comment">-- | Returns the gradually typed information for whether or not gradient computations for the tensor are turned on.</span><span>
</span><span id="line-258"></span><span>  </span><span class="hs-comment">--</span><span>
</span><span id="line-259"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; sOnes' gradient = sOnes $ TensorSpec gradient (SLayout SDense) (SDevice SCPU) (SDataType SFloat) (SShape $ SName @&quot;batch&quot; :&amp;: SSize @32 :|: SName @&quot;feature&quot; :&amp;: SSize @8 :|: SNil)</span><span>
</span><span id="line-260"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; t = sOnes' $ SGradient SWithGradient</span><span>
</span><span id="line-261"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; sGetGradient t</span><span>
</span><span id="line-262"></span><span>  </span><span class="hs-comment">-- SGradient SWithGradient</span><span>
</span><span id="line-263"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; t = sOnes' $ SUncheckedGradient WithoutGradient</span><span>
</span><span id="line-264"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; sGetGradient t</span><span>
</span><span id="line-265"></span><span>  </span><span class="hs-comment">-- SUncheckedGradient WithoutGradient</span><span>
</span><span id="line-266"></span><span>  </span><span id="sGetGradient"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#sGetGradient"><span class="hs-identifier hs-type">sGetGradient</span></a></span></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-267"></span><span>    </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679541722"><span class="annot"><a href="#local-6989586621679541722"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679541721"><span class="annot"><a href="#local-6989586621679541721"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679541720"><span class="annot"><a href="#local-6989586621679541720"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679541719"><span class="annot"><a href="#local-6989586621679541719"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-268"></span><span>    </span><span class="hs-comment">-- | input tensor</span><span>
</span><span id="line-269"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541728"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541722"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541721"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541720"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541719"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-270"></span><span>    </span><span class="hs-comment">-- | information about whether or not gradient computations are required</span><span>
</span><span id="line-271"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier hs-type">SGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541728"><span class="hs-identifier hs-type">gradient</span></a></span><span>
</span><span id="line-272"></span><span>
</span><span id="line-273"></span><span>  </span><span class="hs-comment">-- | Returns the untyped memory layout of the input tensor.</span><span>
</span><span id="line-274"></span><span>  </span><span class="hs-comment">--</span><span>
</span><span id="line-275"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; sOnes' gradient = sOnes $ TensorSpec gradient (SLayout SDense) (SDevice SCPU) (SDataType SFloat) (SShape $ SName @&quot;batch&quot; :&amp;: SSize @32 :|: SName @&quot;feature&quot; :&amp;: SSize @8 :|: SNil)</span><span>
</span><span id="line-276"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; t = sOnes' $ SGradient SWithGradient</span><span>
</span><span id="line-277"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; getRequiresGradient t</span><span>
</span><span id="line-278"></span><span>  </span><span class="hs-comment">-- WithGradient</span><span>
</span><span id="line-279"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; t = sOnes' $ SUncheckedGradient WithoutGradient</span><span>
</span><span id="line-280"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; getRequiresGradient t</span><span>
</span><span id="line-281"></span><span>  </span><span class="hs-comment">-- WithoutGradient</span><span>
</span><span id="line-282"></span><span>  </span><span id="getRequiresGradient"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#getRequiresGradient"><span class="hs-identifier hs-type">getRequiresGradient</span></a></span></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-283"></span><span>    </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679541717"><span class="annot"><a href="#local-6989586621679541717"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679541716"><span class="annot"><a href="#local-6989586621679541716"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679541715"><span class="annot"><a href="#local-6989586621679541715"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679541714"><span class="annot"><a href="#local-6989586621679541714"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-284"></span><span>    </span><span class="hs-comment">-- | input tensor</span><span>
</span><span id="line-285"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541728"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541717"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541716"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541715"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541714"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-286"></span><span>    </span><span class="hs-comment">-- | information about whether or not gradient computations are required</span><span>
</span><span id="line-287"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#RequiresGradient"><span class="hs-identifier hs-type">RequiresGradient</span></a></span><span>
</span><span id="line-288"></span><span>  </span><span id="local-6989586621679540624"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#getRequiresGradient"><span class="hs-identifier hs-var hs-var">getRequiresGradient</span></a></span><span> </span><span id="local-6989586621679540623"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679540623"><span class="hs-identifier hs-var">tensor</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IsChecked RequiresGradient -&gt; RequiresGradient
forall a. IsChecked a -&gt; a
</span><a href="Torch.GraduallyTyped.Prelude.html#forgetIsChecked"><span class="hs-identifier hs-var">forgetIsChecked</span></a></span><span> </span><span class="annot"><span class="annottext">(IsChecked RequiresGradient -&gt; RequiresGradient)
-&gt; (SGradient gradient -&gt; IsChecked RequiresGradient)
-&gt; SGradient gradient
-&gt; RequiresGradient
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">SGradient gradient -&gt; IsChecked RequiresGradient
forall k (a :: k). SingKind k =&gt; Sing a -&gt; Demote k
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">fromSing</span></a></span><span> </span><span class="annot"><span class="annottext">(SGradient gradient -&gt; RequiresGradient)
-&gt; SGradient gradient -&gt; RequiresGradient
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape -&gt; SGradient gradient
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SGetGradient gradient =&gt;
Tensor gradient layout device dataType shape -&gt; SGradient gradient
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sGetGradient"><span class="hs-identifier hs-var">sGetGradient</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679540623"><span class="hs-identifier hs-var">tensor</span></a></span></span><span>
</span><span id="line-289"></span><span>
</span><span id="line-290"></span><span class="hs-keyword">instance</span><span> </span><span id="local-6989586621679540620"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetGradient"><span class="hs-identifier hs-type">SGetGradient</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#UncheckedGradient"><span class="hs-identifier hs-type">UncheckedGradient</span></a></span></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-291"></span><span>  </span><span id="local-6989586621679540618"><span class="annot"><span class="annottext">sGetGradient :: Tensor 'UncheckedGradient layout device dataType shape
-&gt; SGradient 'UncheckedGradient
</span><a href="#local-6989586621679540618"><span class="hs-identifier hs-var hs-var hs-var hs-var">sGetGradient</span></a></span></span><span> </span><span id="local-6989586621679540617"><span class="annot"><span class="annottext">Tensor 'UncheckedGradient layout device dataType shape
</span><a href="#local-6989586621679540617"><span class="hs-identifier hs-var">tensor</span></a></span></span><span>
</span><span id="line-292"></span><span>    </span><span class="hs-glyph">|</span><span> </span><span class="annot"><span class="annottext">IO Bool -&gt; Bool
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO CBool)
-&gt; Tensor 'UncheckedGradient layout device dataType shape
-&gt; IO Bool
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO CBool
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.tensor_requires_grad</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor 'UncheckedGradient layout device dataType shape
</span><a href="#local-6989586621679540617"><span class="hs-identifier hs-var">tensor</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">RequiresGradient -&gt; SGradient 'UncheckedGradient
</span><a href="Torch.GraduallyTyped.RequiresGradient.html#SUncheckedGradient"><span class="hs-identifier hs-var">SUncheckedGradient</span></a></span><span> </span><span class="annot"><span class="annottext">RequiresGradient
</span><a href="Torch.GraduallyTyped.RequiresGradient.html#WithGradient"><span class="hs-identifier hs-var">WithGradient</span></a></span><span>
</span><span id="line-293"></span><span>    </span><span class="hs-glyph">|</span><span> </span><span class="annot"><span class="annottext">Bool
</span><span class="hs-identifier hs-var">otherwise</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">RequiresGradient -&gt; SGradient 'UncheckedGradient
</span><a href="Torch.GraduallyTyped.RequiresGradient.html#SUncheckedGradient"><span class="hs-identifier hs-var">SUncheckedGradient</span></a></span><span> </span><span class="annot"><span class="annottext">RequiresGradient
</span><a href="Torch.GraduallyTyped.RequiresGradient.html#WithoutGradient"><span class="hs-identifier hs-var">WithoutGradient</span></a></span><span>
</span><span id="line-294"></span><span>
</span><span id="line-295"></span><span class="hs-keyword">instance</span><span> </span><span id="local-6989586621679540612"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetGradient"><span class="hs-identifier hs-type">SGetGradient</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#WithGradient"><span class="hs-identifier hs-type">WithGradient</span></a></span><span class="hs-special">)</span></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-296"></span><span>  </span><span id="local-6989586621679540611"><span class="annot"><span class="annottext">sGetGradient :: Tensor ('Gradient 'WithGradient) layout device dataType shape
-&gt; SGradient ('Gradient 'WithGradient)
</span><a href="#local-6989586621679540611"><span class="hs-identifier hs-var hs-var hs-var hs-var">sGetGradient</span></a></span></span><span> </span><span id="local-6989586621679540610"><span class="annot"><span class="annottext">Tensor ('Gradient 'WithGradient) layout device dataType shape
</span><a href="#local-6989586621679540610"><span class="hs-identifier hs-var">tensor</span></a></span></span><span>
</span><span id="line-297"></span><span>    </span><span class="hs-glyph">|</span><span> </span><span class="annot"><span class="annottext">IO Bool -&gt; Bool
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO CBool)
-&gt; Tensor ('Gradient 'WithGradient) layout device dataType shape
-&gt; IO Bool
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO CBool
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.tensor_requires_grad</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor ('Gradient 'WithGradient) layout device dataType shape
</span><a href="#local-6989586621679540610"><span class="hs-identifier hs-var">tensor</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SRequiresGradient 'WithGradient
-&gt; SGradient ('Gradient 'WithGradient)
forall (requiresGradient :: RequiresGradient).
SRequiresGradient requiresGradient
-&gt; SGradient ('Gradient requiresGradient)
</span><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier hs-var">SGradient</span></a></span><span> </span><span class="annot"><span class="annottext">SRequiresGradient 'WithGradient
</span><a href="Torch.GraduallyTyped.RequiresGradient.html#SWithGradient"><span class="hs-identifier hs-var">SWithGradient</span></a></span><span>
</span><span id="line-298"></span><span>    </span><span class="hs-glyph">|</span><span> </span><span class="annot"><span class="annottext">Bool
</span><span class="hs-identifier hs-var">otherwise</span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-299"></span><span>      </span><span class="annot"><span class="annottext">String -&gt; SGradient ('Gradient 'WithGradient)
forall a. HasCallStack =&gt; String -&gt; a
</span><span class="hs-identifier hs-var">error</span></span><span> </span><span class="annot"><span class="annottext">(String -&gt; SGradient ('Gradient 'WithGradient))
-&gt; String -&gt; SGradient ('Gradient 'WithGradient)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-300"></span><span>        </span><span class="annot"><span class="annottext">String
</span><span class="hs-string">&quot;The tensor should require gradient computations but doesn't. &quot;</span></span><span>
</span><span id="line-301"></span><span>          </span><span class="annot"><span class="annottext">String -&gt; ShowS
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">String
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#gitHubErrorMsg"><span class="hs-identifier hs-var">gitHubErrorMsg</span></a></span><span>
</span><span id="line-302"></span><span>
</span><span id="line-303"></span><span class="hs-keyword">instance</span><span> </span><span id="local-6989586621679540603"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetGradient"><span class="hs-identifier hs-type">SGetGradient</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#WithoutGradient"><span class="hs-identifier hs-type">WithoutGradient</span></a></span><span class="hs-special">)</span></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-304"></span><span>  </span><span id="local-6989586621679540602"><span class="annot"><span class="annottext">sGetGradient :: Tensor ('Gradient 'WithoutGradient) layout device dataType shape
-&gt; SGradient ('Gradient 'WithoutGradient)
</span><a href="#local-6989586621679540602"><span class="hs-identifier hs-var hs-var hs-var hs-var">sGetGradient</span></a></span></span><span> </span><span id="local-6989586621679540601"><span class="annot"><span class="annottext">Tensor ('Gradient 'WithoutGradient) layout device dataType shape
</span><a href="#local-6989586621679540601"><span class="hs-identifier hs-var">tensor</span></a></span></span><span>
</span><span id="line-305"></span><span>    </span><span class="hs-glyph">|</span><span> </span><span class="annot"><span class="annottext">IO Bool -&gt; Bool
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO CBool)
-&gt; Tensor ('Gradient 'WithoutGradient) layout device dataType shape
-&gt; IO Bool
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO CBool
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.tensor_requires_grad</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor ('Gradient 'WithoutGradient) layout device dataType shape
</span><a href="#local-6989586621679540601"><span class="hs-identifier hs-var">tensor</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-306"></span><span>      </span><span class="annot"><span class="annottext">String -&gt; SGradient ('Gradient 'WithoutGradient)
forall a. HasCallStack =&gt; String -&gt; a
</span><span class="hs-identifier hs-var">error</span></span><span> </span><span class="annot"><span class="annottext">(String -&gt; SGradient ('Gradient 'WithoutGradient))
-&gt; String -&gt; SGradient ('Gradient 'WithoutGradient)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-307"></span><span>        </span><span class="annot"><span class="annottext">String
</span><span class="hs-string">&quot;The tensor should not require gradient computations but does. &quot;</span></span><span>
</span><span id="line-308"></span><span>          </span><span class="annot"><span class="annottext">String -&gt; ShowS
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">String
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#gitHubErrorMsg"><span class="hs-identifier hs-var">gitHubErrorMsg</span></a></span><span>
</span><span id="line-309"></span><span>    </span><span class="hs-glyph">|</span><span> </span><span class="annot"><span class="annottext">Bool
</span><span class="hs-identifier hs-var">otherwise</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SRequiresGradient 'WithoutGradient
-&gt; SGradient ('Gradient 'WithoutGradient)
forall (requiresGradient :: RequiresGradient).
SRequiresGradient requiresGradient
-&gt; SGradient ('Gradient requiresGradient)
</span><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier hs-var">SGradient</span></a></span><span> </span><span class="annot"><span class="annottext">SRequiresGradient 'WithoutGradient
</span><a href="Torch.GraduallyTyped.RequiresGradient.html#SWithoutGradient"><span class="hs-identifier hs-var">SWithoutGradient</span></a></span><span>
</span><span id="line-310"></span><span>
</span><span id="line-311"></span><span class="hs-keyword">data</span><span> </span><span id="GradientError"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#GradientError"><span class="hs-identifier hs-var">GradientError</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span id="GradientError"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#GradientError"><span class="hs-identifier hs-var">GradientError</span></a></span></span><span> </span><span class="hs-special">{</span><span id="geExpected"><span class="annot"><span class="annottext">GradientError -&gt; RequiresGradient
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#geExpected"><span class="hs-identifier hs-var hs-var">geExpected</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#RequiresGradient"><span class="hs-identifier hs-type">RequiresGradient</span></a></span><span class="hs-special">,</span><span> </span><span id="geActual"><span class="annot"><span class="annottext">GradientError -&gt; RequiresGradient
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#geActual"><span class="hs-identifier hs-var hs-var">geActual</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#RequiresGradient"><span class="hs-identifier hs-type">RequiresGradient</span></a></span><span class="hs-special">}</span><span>
</span><span id="line-312"></span><span>  </span><span class="hs-keyword">deriving</span><span> </span><span class="annot"><span class="hs-keyword">stock</span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679540591"><span id="local-6989586621679540593"><span id="local-6989586621679540595"><span class="annot"><span class="annottext">Int -&gt; GradientError -&gt; ShowS
[GradientError] -&gt; ShowS
GradientError -&gt; String
(Int -&gt; GradientError -&gt; ShowS)
-&gt; (GradientError -&gt; String)
-&gt; ([GradientError] -&gt; ShowS)
-&gt; Show GradientError
forall a.
(Int -&gt; a -&gt; ShowS) -&gt; (a -&gt; String) -&gt; ([a] -&gt; ShowS) -&gt; Show a
showList :: [GradientError] -&gt; ShowS
$cshowList :: [GradientError] -&gt; ShowS
show :: GradientError -&gt; String
$cshow :: GradientError -&gt; String
showsPrec :: Int -&gt; GradientError -&gt; ShowS
$cshowsPrec :: Int -&gt; GradientError -&gt; ShowS
</span><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">Show</span></span></span></span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Typeable</span></span><span class="hs-special">)</span><span>
</span><span id="line-313"></span><span>
</span><span id="line-314"></span><span class="hs-keyword">instance</span><span> </span><span id="local-6989586621679540585"><span id="local-6989586621679540587"><span class="annot"><span class="hs-identifier hs-type">Exception</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#GradientError"><span class="hs-identifier hs-type">GradientError</span></a></span></span></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-315"></span><span>  </span><span id="local-6989586621679540582"><span class="annot"><span class="annottext">displayException :: GradientError -&gt; String
</span><span class="hs-identifier hs-var hs-var hs-var hs-var">displayException</span></span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#GradientError"><span class="hs-identifier hs-type">GradientError</span></a></span><span> </span><span class="hs-special">{</span><span id="local-6989586621679540579"><span id="local-6989586621679540580"><span class="annot"><span class="annottext">RequiresGradient
geActual :: RequiresGradient
geExpected :: RequiresGradient
geActual :: GradientError -&gt; RequiresGradient
geExpected :: GradientError -&gt; RequiresGradient
</span><a href="#local-6989586621679540579"><span class="hs-glyph hs-var hs-var hs-var hs-var">..</span></a></span></span></span><span class="hs-special">}</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-316"></span><span>    </span><span class="annot"><span class="annottext">String
</span><span class="hs-string">&quot;The tensor's information about whether or not gradient computations are required reads `&quot;</span></span><span>
</span><span id="line-317"></span><span>      </span><span class="annot"><span class="annottext">String -&gt; ShowS
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">RequiresGradient -&gt; String
forall a. Show a =&gt; a -&gt; String
</span><span class="hs-identifier hs-var">show</span></span><span> </span><span class="annot"><span class="annottext">RequiresGradient
</span><a href="#local-6989586621679540579"><span class="hs-identifier hs-var">geActual</span></a></span><span>
</span><span id="line-318"></span><span>      </span><span class="annot"><span class="annottext">String -&gt; ShowS
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">String
</span><span class="hs-string">&quot;` instead of `&quot;</span></span><span>
</span><span id="line-319"></span><span>      </span><span class="annot"><span class="annottext">String -&gt; ShowS
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">RequiresGradient -&gt; String
forall a. Show a =&gt; a -&gt; String
</span><span class="hs-identifier hs-var">show</span></span><span> </span><span class="annot"><span class="annottext">RequiresGradient
</span><a href="#local-6989586621679540580"><span class="hs-identifier hs-var">geExpected</span></a></span><span>
</span><span id="line-320"></span><span>      </span><span class="annot"><span class="annottext">String -&gt; ShowS
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">String
</span><span class="hs-string">&quot;`.&quot;</span></span><span>
</span><span id="line-321"></span><span>
</span><span id="line-322"></span><span class="hs-comment">-- | Checks whether or not the input tensor has the memory layout 'layout'</span><span>
</span><span id="line-323"></span><span class="hs-comment">-- and returns a statically annotated copy of it wrapped in a 'MonadThrow' 'm'.</span><span>
</span><span id="line-324"></span><span class="hs-comment">--</span><span>
</span><span id="line-325"></span><span class="hs-comment">-- For instance, if 'm' is 'Maybe', then the result will be wrapped in 'Just' if and only if the tensor has indeed the memory layout 'layout'.</span><span>
</span><span id="line-326"></span><span class="hs-comment">-- If it does not have it, then the result will be 'Nothing'.</span><span>
</span><span id="line-327"></span><span class="hs-comment">--</span><span>
</span><span id="line-328"></span><span class="hs-comment">-- In the REPL, 'm' will default to 'IO':</span><span>
</span><span id="line-329"></span><span class="hs-comment">-- &gt;&gt;&gt; t = sOnes $ TensorSpec (SGradient SWithGradient) (SUncheckedLayout Dense) (SDevice SCPU) (SDataType SFloat) (SShape $ SName @&quot;batch&quot; :&amp;: SSize @32 :|: SName @&quot;feature&quot; :&amp;: SSize @8 :|: SNil)</span><span>
</span><span id="line-330"></span><span class="hs-comment">-- &gt;&gt;&gt; t' &lt;- sCheckedLayout (SLayout SDense) t</span><span>
</span><span id="line-331"></span><span class="hs-comment">-- &gt;&gt;&gt; :type t'</span><span>
</span><span id="line-332"></span><span class="hs-comment">-- t'</span><span>
</span><span id="line-333"></span><span class="hs-comment">--   :: Tensor</span><span>
</span><span id="line-334"></span><span class="hs-comment">--        ('Gradient 'WithGradient)</span><span>
</span><span id="line-335"></span><span class="hs-comment">--        ('Layout 'Dense)</span><span>
</span><span id="line-336"></span><span class="hs-comment">--        ('Device 'CPU)</span><span>
</span><span id="line-337"></span><span class="hs-comment">--        ('DataType 'Float)</span><span>
</span><span id="line-338"></span><span class="hs-comment">--        ('Shape</span><span>
</span><span id="line-339"></span><span class="hs-comment">--           '[ 'Dim ('Name &quot;batch&quot;) ('Size 32),</span><span>
</span><span id="line-340"></span><span class="hs-comment">--              'Dim ('Name &quot;feature&quot;) ('Size 8)])</span><span>
</span><span id="line-341"></span><span class="hs-comment">-- &gt;&gt;&gt; t' &lt;- sCheckedLayout (SLayout SSparse) t</span><span>
</span><span id="line-342"></span><span class="hs-comment">-- *** Exception: LayoutError {leExpected = Sparse, leActual = Dense}</span><span>
</span><span id="line-343"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#sCheckedGradient"><span class="hs-identifier hs-type">sCheckedGradient</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-344"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679541654"><span class="annot"><a href="#local-6989586621679541654"><span class="hs-identifier hs-type">gradient'</span></a></span></span><span> </span><span id="local-6989586621679541655"><span class="annot"><a href="#local-6989586621679541655"><span class="hs-identifier hs-type">m</span></a></span></span><span> </span><span id="local-6989586621679541656"><span class="annot"><a href="#local-6989586621679541656"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679541653"><span class="annot"><a href="#local-6989586621679541653"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679541652"><span class="annot"><a href="#local-6989586621679541652"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679541651"><span class="annot"><a href="#local-6989586621679541651"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679541650"><span class="annot"><a href="#local-6989586621679541650"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-345"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetGradient"><span class="hs-identifier hs-type">SGetGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541656"><span class="hs-identifier hs-type">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier hs-type">MonadThrow</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541655"><span class="hs-identifier hs-type">m</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-346"></span><span>  </span><span class="hs-comment">-- | layout</span><span>
</span><span id="line-347"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier hs-type">SGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541654"><span class="hs-identifier hs-type">gradient'</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-348"></span><span>  </span><span class="hs-comment">-- | input tensor</span><span>
</span><span id="line-349"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541656"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541653"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541652"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541651"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541650"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-350"></span><span>  </span><span class="hs-comment">-- | annotated output tensor wrapped in 'm'</span><span>
</span><span id="line-351"></span><span>  </span><span class="annot"><a href="#local-6989586621679541655"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Seq"><span class="hs-identifier hs-type">Seq</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679541656"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541654"><span class="hs-identifier hs-type">gradient'</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679541654"><span class="hs-identifier hs-type">gradient'</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679541653"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541652"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541651"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541650"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-352"></span><span id="sCheckedGradient"><span class="annot"><span class="annottext">sCheckedGradient :: SGradient gradient'
-&gt; Tensor gradient layout device dataType shape
-&gt; m (Tensor
        (Seq (gradient &lt;+&gt; gradient') gradient')
        layout
        device
        dataType
        shape)
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sCheckedGradient"><span class="hs-identifier hs-var hs-var">sCheckedGradient</span></a></span></span><span> </span><span id="local-6989586621679540577"><span class="annot"><span class="annottext">SGradient gradient'
</span><a href="#local-6989586621679540577"><span class="hs-identifier hs-var">gradient'</span></a></span></span><span> </span><span id="local-6989586621679540576"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679540576"><span class="hs-identifier hs-var">tensor</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-353"></span><span>  </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679540575"><span class="annot"><span class="annottext">actualGradient :: RequiresGradient
</span><a href="#local-6989586621679540575"><span class="hs-identifier hs-var hs-var">actualGradient</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IsChecked RequiresGradient -&gt; RequiresGradient
forall a. IsChecked a -&gt; a
</span><a href="Torch.GraduallyTyped.Prelude.html#forgetIsChecked"><span class="hs-identifier hs-var">forgetIsChecked</span></a></span><span> </span><span class="annot"><span class="annottext">(IsChecked RequiresGradient -&gt; RequiresGradient)
-&gt; (SGradient gradient -&gt; IsChecked RequiresGradient)
-&gt; SGradient gradient
-&gt; RequiresGradient
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">SGradient gradient -&gt; IsChecked RequiresGradient
forall k (a :: k). SingKind k =&gt; Sing a -&gt; Demote k
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">fromSing</span></a></span><span> </span><span class="annot"><span class="annottext">(SGradient gradient -&gt; RequiresGradient)
-&gt; SGradient gradient -&gt; RequiresGradient
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape -&gt; SGradient gradient
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SGetGradient gradient =&gt;
Tensor gradient layout device dataType shape -&gt; SGradient gradient
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sGetGradient"><span class="hs-identifier hs-var">sGetGradient</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679540576"><span class="hs-identifier hs-var">tensor</span></a></span><span>
</span><span id="line-354"></span><span>      </span><span id="local-6989586621679540574"><span class="annot"><span class="annottext">expectedGradient :: RequiresGradient
</span><a href="#local-6989586621679540574"><span class="hs-identifier hs-var hs-var">expectedGradient</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IsChecked RequiresGradient -&gt; RequiresGradient
forall a. IsChecked a -&gt; a
</span><a href="Torch.GraduallyTyped.Prelude.html#forgetIsChecked"><span class="hs-identifier hs-var">forgetIsChecked</span></a></span><span> </span><span class="annot"><span class="annottext">(IsChecked RequiresGradient -&gt; RequiresGradient)
-&gt; (SGradient gradient' -&gt; IsChecked RequiresGradient)
-&gt; SGradient gradient'
-&gt; RequiresGradient
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">SGradient gradient' -&gt; IsChecked RequiresGradient
forall k (a :: k). SingKind k =&gt; Sing a -&gt; Demote k
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">fromSing</span></a></span><span> </span><span class="annot"><span class="annottext">(SGradient gradient' -&gt; RequiresGradient)
-&gt; SGradient gradient' -&gt; RequiresGradient
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SGradient gradient'
</span><a href="#local-6989586621679540577"><span class="hs-identifier hs-var">gradient'</span></a></span><span>
</span><span id="line-355"></span><span>   </span><span class="hs-keyword">in</span><span> </span><span class="hs-keyword">if</span><span> </span><span class="annot"><span class="annottext">RequiresGradient
</span><a href="#local-6989586621679540575"><span class="hs-identifier hs-var">actualGradient</span></a></span><span> </span><span class="annot"><span class="annottext">RequiresGradient -&gt; RequiresGradient -&gt; Bool
forall a. Eq a =&gt; a -&gt; a -&gt; Bool
</span><span class="hs-operator hs-var">==</span></span><span> </span><span class="annot"><span class="annottext">RequiresGradient
</span><a href="#local-6989586621679540574"><span class="hs-identifier hs-var">expectedGradient</span></a></span><span>
</span><span id="line-356"></span><span>        </span><span class="hs-keyword">then</span><span> </span><span class="annot"><span class="annottext">Tensor
  (Seq
     (Unify (Gradient RequiresGradient) gradient gradient') gradient')
  layout
  device
  dataType
  shape
-&gt; m (Tensor
        (Seq
           (Unify (Gradient RequiresGradient) gradient gradient') gradient')
        layout
        device
        dataType
        shape)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">(Tensor
   (Seq
      (Unify (Gradient RequiresGradient) gradient gradient') gradient')
   layout
   device
   dataType
   shape
 -&gt; m (Tensor
         (Seq
            (Unify (Gradient RequiresGradient) gradient gradient') gradient')
         layout
         device
         dataType
         shape))
-&gt; (Tensor gradient layout device dataType shape
    -&gt; Tensor
         (Seq
            (Unify (Gradient RequiresGradient) gradient gradient') gradient')
         layout
         device
         dataType
         shape)
-&gt; Tensor gradient layout device dataType shape
-&gt; m (Tensor
        (Seq
           (Unify (Gradient RequiresGradient) gradient gradient') gradient')
        layout
        device
        dataType
        shape)
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
-&gt; Tensor
     (Seq
        (Unify (Gradient RequiresGradient) gradient gradient') gradient')
     layout
     device
     dataType
     shape
</span><span class="hs-identifier hs-var">coerce</span></span><span> </span><span class="annot"><span class="annottext">(Tensor gradient layout device dataType shape
 -&gt; m (Tensor
         (Seq
            (Unify (Gradient RequiresGradient) gradient gradient') gradient')
         layout
         device
         dataType
         shape))
-&gt; Tensor gradient layout device dataType shape
-&gt; m (Tensor
        (Seq
           (Unify (Gradient RequiresGradient) gradient gradient') gradient')
        layout
        device
        dataType
        shape)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679540576"><span class="hs-identifier hs-var">tensor</span></a></span><span>
</span><span id="line-357"></span><span>        </span><span class="hs-keyword">else</span><span> </span><span class="annot"><span class="annottext">GradientError
-&gt; m (Tensor
        (Seq
           (Unify (Gradient RequiresGradient) gradient gradient') gradient')
        layout
        device
        dataType
        shape)
forall (m :: * -&gt; *) e a. (MonadThrow m, Exception e) =&gt; e -&gt; m a
</span><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier hs-var">throwM</span></a></span><span> </span><span class="annot"><span class="annottext">(GradientError
 -&gt; m (Tensor
         (Seq
            (Unify (Gradient RequiresGradient) gradient gradient') gradient')
         layout
         device
         dataType
         shape))
-&gt; GradientError
-&gt; m (Tensor
        (Seq
           (Unify (Gradient RequiresGradient) gradient gradient') gradient')
        layout
        device
        dataType
        shape)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">RequiresGradient -&gt; RequiresGradient -&gt; GradientError
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#GradientError"><span class="hs-identifier hs-var">GradientError</span></a></span><span> </span><span class="annot"><span class="annottext">RequiresGradient
</span><a href="#local-6989586621679540574"><span class="hs-identifier hs-var">expectedGradient</span></a></span><span> </span><span class="annot"><span class="annottext">RequiresGradient
</span><a href="#local-6989586621679540575"><span class="hs-identifier hs-var">actualGradient</span></a></span><span>
</span><span id="line-358"></span><span>
</span><span id="line-359"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#checkedGradient"><span class="hs-identifier hs-type">checkedGradient</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-360"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679540571"><span class="annot"><a href="#local-6989586621679540571"><span class="hs-identifier hs-type">gradient'</span></a></span></span><span> </span><span id="local-6989586621679540570"><span class="annot"><a href="#local-6989586621679540570"><span class="hs-identifier hs-type">m</span></a></span></span><span> </span><span id="local-6989586621679540569"><span class="annot"><a href="#local-6989586621679540569"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679540568"><span class="annot"><a href="#local-6989586621679540568"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679540567"><span class="annot"><a href="#local-6989586621679540567"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679540566"><span class="annot"><a href="#local-6989586621679540566"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679540565"><span class="annot"><a href="#local-6989586621679540565"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-361"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-type">SingI</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540571"><span class="hs-identifier hs-type">gradient'</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetGradient"><span class="hs-identifier hs-type">SGetGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540569"><span class="hs-identifier hs-type">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier hs-type">MonadThrow</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540570"><span class="hs-identifier hs-type">m</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-362"></span><span>  </span><span class="hs-comment">-- | input tensor</span><span>
</span><span id="line-363"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540569"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540568"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540567"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540566"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540565"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-364"></span><span>  </span><span class="hs-comment">-- | annotated output tensor wrapped in 'm'</span><span>
</span><span id="line-365"></span><span>  </span><span class="annot"><a href="#local-6989586621679540570"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Seq"><span class="hs-identifier hs-type">Seq</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679540569"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540571"><span class="hs-identifier hs-type">gradient'</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679540571"><span class="hs-identifier hs-type">gradient'</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679540568"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540567"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540566"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540565"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-366"></span><span id="checkedGradient"><span class="annot"><span class="annottext">checkedGradient :: Tensor gradient layout device dataType shape
-&gt; m (Tensor
        (Seq (gradient &lt;+&gt; gradient') gradient')
        layout
        device
        dataType
        shape)
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#checkedGradient"><span class="hs-identifier hs-var hs-var">checkedGradient</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SGradient gradient'
-&gt; Tensor gradient layout device dataType shape
-&gt; m (Tensor
        (Seq (gradient &lt;+&gt; gradient') gradient')
        layout
        device
        dataType
        shape)
forall (gradient' :: Gradient RequiresGradient) (m :: * -&gt; *)
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
(SGetGradient gradient, MonadThrow m) =&gt;
SGradient gradient'
-&gt; Tensor gradient layout device dataType shape
-&gt; m (Tensor
        (Seq (gradient &lt;+&gt; gradient') gradient')
        layout
        device
        dataType
        shape)
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sCheckedGradient"><span class="hs-identifier hs-var">sCheckedGradient</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SingI gradient' =&gt; Sing gradient'
forall k (a :: k). SingI a =&gt; Sing a
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">sing</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679540571"><span class="hs-identifier hs-type">gradient'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-367"></span><span>
</span><span id="line-368"></span><span class="hs-comment">-- | Returns the input tensor but with 'UncheckedLayout' as memory layout type annotation.</span><span>
</span><span id="line-369"></span><span class="hs-comment">-- Any static information about the tensor's memory layout is thus erased.</span><span>
</span><span id="line-370"></span><span class="hs-comment">-- However, the tensor's underlying data structure is not changed.</span><span>
</span><span id="line-371"></span><span class="hs-comment">--</span><span>
</span><span id="line-372"></span><span class="hs-comment">-- &gt;&gt;&gt; t = ones @('Gradient 'WithGradient) @('Layout 'Dense) @('Device 'CPU) @('DataType 'Float) @('Shape '[ 'Dim ('Name &quot;batch&quot;) ('Size 32), 'Dim ('Name &quot;feature&quot;) ('Size 8)])</span><span>
</span><span id="line-373"></span><span class="hs-comment">-- &gt;&gt;&gt; :type uncheckedLayout t</span><span>
</span><span id="line-374"></span><span class="hs-comment">-- uncheckedLayout t</span><span>
</span><span id="line-375"></span><span class="hs-comment">--   :: Tensor</span><span>
</span><span id="line-376"></span><span class="hs-comment">--        ('Gradient 'WithGradient)</span><span>
</span><span id="line-377"></span><span class="hs-comment">--        'UncheckedLayout</span><span>
</span><span id="line-378"></span><span class="hs-comment">--        ('Device 'CPU)</span><span>
</span><span id="line-379"></span><span class="hs-comment">--        ('DataType 'Float)</span><span>
</span><span id="line-380"></span><span class="hs-comment">--        ('Shape</span><span>
</span><span id="line-381"></span><span class="hs-comment">--           '[ 'Dim ('Name &quot;batch&quot;) ('Size 32),</span><span>
</span><span id="line-382"></span><span class="hs-comment">--              'Dim ('Name &quot;feature&quot;) ('Size 8)])</span><span>
</span><span id="line-383"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#uncheckedGradient"><span class="hs-identifier hs-type">uncheckedGradient</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-384"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679540563"><span class="annot"><a href="#local-6989586621679540563"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679540562"><span class="annot"><a href="#local-6989586621679540562"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679540561"><span class="annot"><a href="#local-6989586621679540561"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679540560"><span class="annot"><a href="#local-6989586621679540560"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679540559"><span class="annot"><a href="#local-6989586621679540559"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-385"></span><span>  </span><span class="hs-comment">-- | input tensor</span><span>
</span><span id="line-386"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540563"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540562"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540561"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540560"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540559"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-387"></span><span>  </span><span class="hs-comment">-- | tensor without checked layout</span><span>
</span><span id="line-388"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#UncheckedGradient"><span class="hs-identifier hs-type">UncheckedGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540562"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540561"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540560"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540559"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-389"></span><span id="uncheckedGradient"><span class="annot"><span class="annottext">uncheckedGradient :: Tensor gradient layout device dataType shape
-&gt; Tensor 'UncheckedGradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#uncheckedGradient"><span class="hs-identifier hs-var hs-var">uncheckedGradient</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
-&gt; Tensor 'UncheckedGradient layout device dataType shape
</span><span class="hs-identifier hs-var">coerce</span></span><span>
</span><span id="line-390"></span><span>
</span><span id="line-391"></span><span class="hs-comment">-- | Returns a dense copy of the tensor.</span><span>
</span><span id="line-392"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#toDense"><span class="hs-identifier hs-type">toDense</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-393"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679540557"><span class="annot"><a href="#local-6989586621679540557"><span class="hs-identifier hs-type">m</span></a></span></span><span> </span><span id="local-6989586621679540556"><span class="annot"><a href="#local-6989586621679540556"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679540555"><span class="annot"><a href="#local-6989586621679540555"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679540554"><span class="annot"><a href="#local-6989586621679540554"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679540553"><span class="annot"><a href="#local-6989586621679540553"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679540552"><span class="annot"><a href="#local-6989586621679540552"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-394"></span><span>  </span><span class="annot"><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier hs-type">MonadThrow</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540557"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-395"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-396"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540556"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540555"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540554"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540553"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540552"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-397"></span><span>  </span><span class="hs-comment">-- | dense copy</span><span>
</span><span id="line-398"></span><span>  </span><span class="annot"><a href="#local-6989586621679540557"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540556"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Dense"><span class="hs-identifier hs-type">Dense</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679540554"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540553"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540552"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-399"></span><span id="toDense"><span class="annot"><span class="annottext">toDense :: Tensor gradient layout device dataType shape
-&gt; m (Tensor gradient ('Layout 'Dense) device dataType shape)
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#toDense"><span class="hs-identifier hs-var hs-var">toDense</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient ('Layout 'Dense) device dataType shape)
-&gt; m (Tensor gradient ('Layout 'Dense) device dataType shape)
forall a (m :: * -&gt; *). MonadThrow m =&gt; IO a -&gt; m a
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">unsafeThrowableIO</span></a></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient ('Layout 'Dense) device dataType shape)
 -&gt; m (Tensor gradient ('Layout 'Dense) device dataType shape))
-&gt; (Tensor gradient layout device dataType shape
    -&gt; IO (Tensor gradient ('Layout 'Dense) device dataType shape))
-&gt; Tensor gradient layout device dataType shape
-&gt; m (Tensor gradient ('Layout 'Dense) device dataType shape)
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; IO (Tensor gradient ('Layout 'Dense) device dataType shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.tensor_to_dense</span></a></span><span>
</span><span id="line-400"></span><span>
</span><span id="line-401"></span><span class="hs-comment">-- | Returns a sparse copy of the tensor.</span><span>
</span><span id="line-402"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#toSparse"><span class="hs-identifier hs-type">toSparse</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-403"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679540549"><span class="annot"><a href="#local-6989586621679540549"><span class="hs-identifier hs-type">m</span></a></span></span><span> </span><span id="local-6989586621679540548"><span class="annot"><a href="#local-6989586621679540548"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679540547"><span class="annot"><a href="#local-6989586621679540547"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679540546"><span class="annot"><a href="#local-6989586621679540546"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679540545"><span class="annot"><a href="#local-6989586621679540545"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679540544"><span class="annot"><a href="#local-6989586621679540544"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-404"></span><span>  </span><span class="annot"><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier hs-type">MonadThrow</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540549"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-405"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-406"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540548"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540547"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540546"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540545"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540544"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-407"></span><span>  </span><span class="hs-comment">-- | sparse copy</span><span>
</span><span id="line-408"></span><span>  </span><span class="annot"><a href="#local-6989586621679540549"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540548"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Sparse"><span class="hs-identifier hs-type">Sparse</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679540546"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540545"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540544"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-409"></span><span id="toSparse"><span class="annot"><span class="annottext">toSparse :: Tensor gradient layout device dataType shape
-&gt; m (Tensor gradient ('Layout 'Sparse) device dataType shape)
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#toSparse"><span class="hs-identifier hs-var hs-var">toSparse</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient ('Layout 'Sparse) device dataType shape)
-&gt; m (Tensor gradient ('Layout 'Sparse) device dataType shape)
forall a (m :: * -&gt; *). MonadThrow m =&gt; IO a -&gt; m a
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">unsafeThrowableIO</span></a></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient ('Layout 'Sparse) device dataType shape)
 -&gt; m (Tensor gradient ('Layout 'Sparse) device dataType shape))
-&gt; (Tensor gradient layout device dataType shape
    -&gt; IO (Tensor gradient ('Layout 'Sparse) device dataType shape))
-&gt; Tensor gradient layout device dataType shape
-&gt; m (Tensor gradient ('Layout 'Sparse) device dataType shape)
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; IO (Tensor gradient ('Layout 'Sparse) device dataType shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.tensor_to_sparse</span></a></span><span>
</span><span id="line-410"></span><span>
</span><span id="line-411"></span><span class="hs-comment">-- | Set the memory layout of a tensor to a given layout.</span><span>
</span><span id="line-412"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#sSetLayout"><span class="hs-identifier hs-type">sSetLayout</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-413"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679540541"><span class="annot"><a href="#local-6989586621679540541"><span class="hs-identifier hs-type">m</span></a></span></span><span> </span><span id="local-6989586621679540540"><span class="annot"><a href="#local-6989586621679540540"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679540539"><span class="annot"><a href="#local-6989586621679540539"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679540538"><span class="annot"><a href="#local-6989586621679540538"><span class="hs-identifier hs-type">layout'</span></a></span></span><span> </span><span id="local-6989586621679540537"><span class="annot"><a href="#local-6989586621679540537"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679540536"><span class="annot"><a href="#local-6989586621679540536"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679540535"><span class="annot"><a href="#local-6989586621679540535"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-414"></span><span>  </span><span class="annot"><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier hs-type">MonadThrow</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540541"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-415"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#SLayout"><span class="hs-identifier hs-type">SLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540539"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-416"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540540"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540538"><span class="hs-identifier hs-type">layout'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540537"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540536"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540535"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-417"></span><span>  </span><span class="annot"><a href="#local-6989586621679540541"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540540"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540539"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540537"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540536"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540535"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-418"></span><span id="sSetLayout"><span class="annot"><span class="annottext">sSetLayout :: SLayout layout
-&gt; Tensor gradient layout' device dataType shape
-&gt; m (Tensor gradient layout device dataType shape)
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sSetLayout"><span class="hs-identifier hs-var hs-var">sSetLayout</span></a></span></span><span> </span><span id="local-6989586621679540534"><span class="annot"><span class="annottext">SLayout layout
</span><a href="#local-6989586621679540534"><span class="hs-identifier hs-var">layout</span></a></span></span><span> </span><span id="local-6989586621679540533"><span class="annot"><span class="annottext">Tensor gradient layout' device dataType shape
</span><a href="#local-6989586621679540533"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-419"></span><span>  </span><span class="hs-keyword">case</span><span> </span><span class="annot"><span class="annottext">IsChecked LayoutType -&gt; LayoutType
forall a. IsChecked a -&gt; a
</span><a href="Torch.GraduallyTyped.Prelude.html#forgetIsChecked"><span class="hs-identifier hs-var">forgetIsChecked</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Sing layout -&gt; Demote (Layout LayoutType)
forall k (a :: k). SingKind k =&gt; Sing a -&gt; Demote k
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">fromSing</span></a></span><span> </span><span class="annot"><span class="annottext">Sing layout
SLayout layout
</span><a href="#local-6989586621679540534"><span class="hs-identifier hs-var">layout</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-keyword">of</span><span>
</span><span id="line-420"></span><span>    </span><span class="annot"><span class="annottext">LayoutType
</span><a href="Torch.GraduallyTyped.Layout.html#Dense"><span class="hs-identifier hs-var">Dense</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; m (Tensor gradient layout device dataType shape)
forall a (m :: * -&gt; *). MonadThrow m =&gt; IO a -&gt; m a
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">unsafeThrowableIO</span></a></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; m (Tensor gradient layout device dataType shape))
-&gt; (Tensor gradient layout' device dataType shape
    -&gt; IO (Tensor gradient layout device dataType shape))
-&gt; Tensor gradient layout' device dataType shape
-&gt; m (Tensor gradient layout device dataType shape)
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout' device dataType shape
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.tensor_to_dense</span></a></span><span> </span><span class="annot"><span class="annottext">(Tensor gradient layout' device dataType shape
 -&gt; m (Tensor gradient layout device dataType shape))
-&gt; Tensor gradient layout' device dataType shape
-&gt; m (Tensor gradient layout device dataType shape)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout' device dataType shape
</span><a href="#local-6989586621679540533"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-421"></span><span>    </span><span class="annot"><span class="annottext">LayoutType
</span><a href="Torch.GraduallyTyped.Layout.html#Sparse"><span class="hs-identifier hs-var">Sparse</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; m (Tensor gradient layout device dataType shape)
forall a (m :: * -&gt; *). MonadThrow m =&gt; IO a -&gt; m a
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">unsafeThrowableIO</span></a></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; m (Tensor gradient layout device dataType shape))
-&gt; (Tensor gradient layout' device dataType shape
    -&gt; IO (Tensor gradient layout device dataType shape))
-&gt; Tensor gradient layout' device dataType shape
-&gt; m (Tensor gradient layout device dataType shape)
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout' device dataType shape
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.tensor_to_sparse</span></a></span><span> </span><span class="annot"><span class="annottext">(Tensor gradient layout' device dataType shape
 -&gt; m (Tensor gradient layout device dataType shape))
-&gt; Tensor gradient layout' device dataType shape
-&gt; m (Tensor gradient layout device dataType shape)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout' device dataType shape
</span><a href="#local-6989586621679540533"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-422"></span><span>
</span><span id="line-423"></span><span class="hs-keyword">class</span><span> </span><span id="SGetLayout"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetLayout"><span class="hs-identifier hs-var">SGetLayout</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679541616"><span class="annot"><a href="#local-6989586621679541616"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#LayoutType"><span class="hs-identifier hs-type">LayoutType</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-424"></span><span>  </span><span class="hs-comment">-- | Returns the gradually typed memory layout of the input tensor.</span><span>
</span><span id="line-425"></span><span>  </span><span class="hs-comment">--</span><span>
</span><span id="line-426"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; sOnes' layout = sOnes $ TensorSpec (SGradient SWithGradient) layout (SDevice SCPU) (SDataType SFloat) (SShape $ SName @&quot;batch&quot; :&amp;: SSize @32 :|: SName @&quot;feature&quot; :&amp;: SSize @8 :|: SNil)</span><span>
</span><span id="line-427"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; t = sOnes' $ SLayout SDense</span><span>
</span><span id="line-428"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; sGetLayout t</span><span>
</span><span id="line-429"></span><span>  </span><span class="hs-comment">-- SLayout SDense</span><span>
</span><span id="line-430"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; t = sOnes' $ SUncheckedLayout Dense</span><span>
</span><span id="line-431"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; sGetLayout t</span><span>
</span><span id="line-432"></span><span>  </span><span class="hs-comment">-- SUncheckedLayout Dense</span><span>
</span><span id="line-433"></span><span>  </span><span id="sGetLayout"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#sGetLayout"><span class="hs-identifier hs-type">sGetLayout</span></a></span></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-434"></span><span>    </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679541611"><span class="annot"><a href="#local-6989586621679541611"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679541610"><span class="annot"><a href="#local-6989586621679541610"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679541609"><span class="annot"><a href="#local-6989586621679541609"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679541608"><span class="annot"><a href="#local-6989586621679541608"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-435"></span><span>    </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-436"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541611"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541616"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541610"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541609"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541608"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-437"></span><span>    </span><span class="hs-comment">-- | memory layout</span><span>
</span><span id="line-438"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#SLayout"><span class="hs-identifier hs-type">SLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541616"><span class="hs-identifier hs-type">layout</span></a></span><span>
</span><span id="line-439"></span><span>
</span><span id="line-440"></span><span>  </span><span class="hs-comment">-- | Returns the untyped memory layout of the input tensor.</span><span>
</span><span id="line-441"></span><span>  </span><span class="hs-comment">--</span><span>
</span><span id="line-442"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; sOnes' layout = sOnes $ TensorSpec (SGradient SWithGradient) layout (SDevice SCPU) (SDataType SFloat) (SShape $ SName @&quot;batch&quot; :&amp;: SSize @32 :|: SName @&quot;feature&quot; :&amp;: SSize @8 :|: SNil)</span><span>
</span><span id="line-443"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; t = sOnes' $ SLayout SDense</span><span>
</span><span id="line-444"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; getLayoutType t</span><span>
</span><span id="line-445"></span><span>  </span><span class="hs-comment">-- Dense</span><span>
</span><span id="line-446"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; t = sOnes' $ SUncheckedLayout Dense</span><span>
</span><span id="line-447"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; getLayoutType t</span><span>
</span><span id="line-448"></span><span>  </span><span class="hs-comment">-- Dense</span><span>
</span><span id="line-449"></span><span>  </span><span id="getLayoutType"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#getLayoutType"><span class="hs-identifier hs-type">getLayoutType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-450"></span><span>    </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679541606"><span class="annot"><a href="#local-6989586621679541606"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679541605"><span class="annot"><a href="#local-6989586621679541605"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679541604"><span class="annot"><a href="#local-6989586621679541604"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679541603"><span class="annot"><a href="#local-6989586621679541603"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-451"></span><span>    </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-452"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541606"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541616"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541605"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541604"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541603"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-453"></span><span>    </span><span class="hs-comment">-- | memory layout</span><span>
</span><span id="line-454"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#LayoutType"><span class="hs-identifier hs-type">LayoutType</span></a></span><span>
</span><span id="line-455"></span><span>  </span><span id="local-6989586621679540530"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#getLayoutType"><span class="hs-identifier hs-var hs-var">getLayoutType</span></a></span><span> </span><span id="local-6989586621679540529"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679540529"><span class="hs-identifier hs-var">tensor</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IsChecked LayoutType -&gt; LayoutType
forall a. IsChecked a -&gt; a
</span><a href="Torch.GraduallyTyped.Prelude.html#forgetIsChecked"><span class="hs-identifier hs-var">forgetIsChecked</span></a></span><span> </span><span class="annot"><span class="annottext">(IsChecked LayoutType -&gt; LayoutType)
-&gt; (SLayout layout -&gt; IsChecked LayoutType)
-&gt; SLayout layout
-&gt; LayoutType
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">SLayout layout -&gt; IsChecked LayoutType
forall k (a :: k). SingKind k =&gt; Sing a -&gt; Demote k
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">fromSing</span></a></span><span> </span><span class="annot"><span class="annottext">(SLayout layout -&gt; LayoutType) -&gt; SLayout layout -&gt; LayoutType
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape -&gt; SLayout layout
forall (layout :: Layout LayoutType)
       (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SGetLayout layout =&gt;
Tensor gradient layout device dataType shape -&gt; SLayout layout
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sGetLayout"><span class="hs-identifier hs-var">sGetLayout</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679540529"><span class="hs-identifier hs-var">tensor</span></a></span></span><span>
</span><span id="line-456"></span><span>
</span><span id="line-457"></span><span class="hs-keyword">instance</span><span> </span><span id="local-6989586621679540526"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetLayout"><span class="hs-identifier hs-type">SGetLayout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#UncheckedLayout"><span class="hs-identifier hs-type">UncheckedLayout</span></a></span></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-458"></span><span>  </span><span id="local-6989586621679540524"><span class="annot"><span class="annottext">sGetLayout :: Tensor gradient 'UncheckedLayout device dataType shape
-&gt; SLayout 'UncheckedLayout
</span><a href="#local-6989586621679540524"><span class="hs-identifier hs-var hs-var hs-var hs-var">sGetLayout</span></a></span></span><span> </span><span id="local-6989586621679540523"><span class="annot"><span class="annottext">Tensor gradient 'UncheckedLayout device dataType shape
</span><a href="#local-6989586621679540523"><span class="hs-identifier hs-var">tensor</span></a></span></span><span>
</span><span id="line-459"></span><span>    </span><span class="hs-glyph">|</span><span> </span><span class="annot"><span class="annottext">IO Bool -&gt; Bool
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO CBool)
-&gt; Tensor gradient 'UncheckedLayout device dataType shape
-&gt; IO Bool
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO CBool
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.tensor_is_sparse</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient 'UncheckedLayout device dataType shape
</span><a href="#local-6989586621679540523"><span class="hs-identifier hs-var">tensor</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">LayoutType -&gt; SLayout 'UncheckedLayout
</span><a href="Torch.GraduallyTyped.Layout.html#SUncheckedLayout"><span class="hs-identifier hs-var">SUncheckedLayout</span></a></span><span> </span><span class="annot"><span class="annottext">LayoutType
</span><a href="Torch.GraduallyTyped.Layout.html#Sparse"><span class="hs-identifier hs-var">Sparse</span></a></span><span>
</span><span id="line-460"></span><span>    </span><span class="hs-glyph">|</span><span> </span><span class="annot"><span class="annottext">Bool
</span><span class="hs-identifier hs-var">otherwise</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">LayoutType -&gt; SLayout 'UncheckedLayout
</span><a href="Torch.GraduallyTyped.Layout.html#SUncheckedLayout"><span class="hs-identifier hs-var">SUncheckedLayout</span></a></span><span> </span><span class="annot"><span class="annottext">LayoutType
</span><a href="Torch.GraduallyTyped.Layout.html#Dense"><span class="hs-identifier hs-var">Dense</span></a></span><span>
</span><span id="line-461"></span><span>
</span><span id="line-462"></span><span class="hs-keyword">instance</span><span> </span><span id="local-6989586621679540518"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetLayout"><span class="hs-identifier hs-type">SGetLayout</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Sparse"><span class="hs-identifier hs-type">Sparse</span></a></span><span class="hs-special">)</span></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-463"></span><span>  </span><span id="local-6989586621679540517"><span class="annot"><span class="annottext">sGetLayout :: Tensor gradient ('Layout 'Sparse) device dataType shape
-&gt; SLayout ('Layout 'Sparse)
</span><a href="#local-6989586621679540517"><span class="hs-identifier hs-var hs-var hs-var hs-var">sGetLayout</span></a></span></span><span> </span><span id="local-6989586621679540516"><span class="annot"><span class="annottext">Tensor gradient ('Layout 'Sparse) device dataType shape
</span><a href="#local-6989586621679540516"><span class="hs-identifier hs-var">tensor</span></a></span></span><span>
</span><span id="line-464"></span><span>    </span><span class="hs-glyph">|</span><span> </span><span class="annot"><span class="annottext">IO Bool -&gt; Bool
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO CBool)
-&gt; Tensor gradient ('Layout 'Sparse) device dataType shape
-&gt; IO Bool
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO CBool
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.tensor_is_sparse</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient ('Layout 'Sparse) device dataType shape
</span><a href="#local-6989586621679540516"><span class="hs-identifier hs-var">tensor</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SLayoutType 'Sparse -&gt; SLayout ('Layout 'Sparse)
forall (layoutType :: LayoutType).
SLayoutType layoutType -&gt; SLayout ('Layout layoutType)
</span><a href="Torch.GraduallyTyped.Layout.html#SLayout"><span class="hs-identifier hs-var">SLayout</span></a></span><span> </span><span class="annot"><span class="annottext">SLayoutType 'Sparse
</span><a href="Torch.GraduallyTyped.Layout.html#SSparse"><span class="hs-identifier hs-var">SSparse</span></a></span><span>
</span><span id="line-465"></span><span>    </span><span class="hs-glyph">|</span><span> </span><span class="annot"><span class="annottext">Bool
</span><span class="hs-identifier hs-var">otherwise</span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-466"></span><span>      </span><span class="annot"><span class="annottext">String -&gt; SLayout ('Layout 'Sparse)
forall a. HasCallStack =&gt; String -&gt; a
</span><span class="hs-identifier hs-var">error</span></span><span> </span><span class="annot"><span class="annottext">(String -&gt; SLayout ('Layout 'Sparse))
-&gt; String -&gt; SLayout ('Layout 'Sparse)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-467"></span><span>        </span><span class="annot"><span class="annottext">String
</span><span class="hs-string">&quot;The tensor should be sparse but isn't. &quot;</span></span><span>
</span><span id="line-468"></span><span>          </span><span class="annot"><span class="annottext">String -&gt; ShowS
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">String
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#gitHubErrorMsg"><span class="hs-identifier hs-var">gitHubErrorMsg</span></a></span><span>
</span><span id="line-469"></span><span>
</span><span id="line-470"></span><span class="hs-keyword">instance</span><span> </span><span id="local-6989586621679540511"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetLayout"><span class="hs-identifier hs-type">SGetLayout</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Dense"><span class="hs-identifier hs-type">Dense</span></a></span><span class="hs-special">)</span></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-471"></span><span>  </span><span id="local-6989586621679540510"><span class="annot"><span class="annottext">sGetLayout :: Tensor gradient ('Layout 'Dense) device dataType shape
-&gt; SLayout ('Layout 'Dense)
</span><a href="#local-6989586621679540510"><span class="hs-identifier hs-var hs-var hs-var hs-var">sGetLayout</span></a></span></span><span> </span><span id="local-6989586621679540509"><span class="annot"><span class="annottext">Tensor gradient ('Layout 'Dense) device dataType shape
</span><a href="#local-6989586621679540509"><span class="hs-identifier hs-var">tensor</span></a></span></span><span>
</span><span id="line-472"></span><span>    </span><span class="hs-glyph">|</span><span> </span><span class="annot"><span class="annottext">IO Bool -&gt; Bool
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO CBool)
-&gt; Tensor gradient ('Layout 'Dense) device dataType shape
-&gt; IO Bool
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO CBool
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.tensor_is_sparse</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient ('Layout 'Dense) device dataType shape
</span><a href="#local-6989586621679540509"><span class="hs-identifier hs-var">tensor</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-473"></span><span>      </span><span class="annot"><span class="annottext">String -&gt; SLayout ('Layout 'Dense)
forall a. HasCallStack =&gt; String -&gt; a
</span><span class="hs-identifier hs-var">error</span></span><span> </span><span class="annot"><span class="annottext">(String -&gt; SLayout ('Layout 'Dense))
-&gt; String -&gt; SLayout ('Layout 'Dense)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-474"></span><span>        </span><span class="annot"><span class="annottext">String
</span><span class="hs-string">&quot;The tensor should be dense but isn't. &quot;</span></span><span>
</span><span id="line-475"></span><span>          </span><span class="annot"><span class="annottext">String -&gt; ShowS
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">String
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#gitHubErrorMsg"><span class="hs-identifier hs-var">gitHubErrorMsg</span></a></span><span>
</span><span id="line-476"></span><span>    </span><span class="hs-glyph">|</span><span> </span><span class="annot"><span class="annottext">Bool
</span><span class="hs-identifier hs-var">otherwise</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SLayoutType 'Dense -&gt; SLayout ('Layout 'Dense)
forall (layoutType :: LayoutType).
SLayoutType layoutType -&gt; SLayout ('Layout layoutType)
</span><a href="Torch.GraduallyTyped.Layout.html#SLayout"><span class="hs-identifier hs-var">SLayout</span></a></span><span> </span><span class="annot"><span class="annottext">SLayoutType 'Dense
</span><a href="Torch.GraduallyTyped.Layout.html#SDense"><span class="hs-identifier hs-var">SDense</span></a></span><span>
</span><span id="line-477"></span><span>
</span><span id="line-478"></span><span class="hs-keyword">data</span><span> </span><span id="LayoutError"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#LayoutError"><span class="hs-identifier hs-var">LayoutError</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span id="LayoutError"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#LayoutError"><span class="hs-identifier hs-var">LayoutError</span></a></span></span><span> </span><span class="hs-special">{</span><span id="leExpected"><span class="annot"><span class="annottext">LayoutError -&gt; LayoutType
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#leExpected"><span class="hs-identifier hs-var hs-var">leExpected</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#LayoutType"><span class="hs-identifier hs-type">LayoutType</span></a></span><span class="hs-special">,</span><span> </span><span id="leActual"><span class="annot"><span class="annottext">LayoutError -&gt; LayoutType
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#leActual"><span class="hs-identifier hs-var hs-var">leActual</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#LayoutType"><span class="hs-identifier hs-type">LayoutType</span></a></span><span class="hs-special">}</span><span>
</span><span id="line-479"></span><span>  </span><span class="hs-keyword">deriving</span><span> </span><span class="annot"><span class="hs-keyword">stock</span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679540499"><span id="local-6989586621679540501"><span id="local-6989586621679540503"><span class="annot"><span class="annottext">Int -&gt; LayoutError -&gt; ShowS
[LayoutError] -&gt; ShowS
LayoutError -&gt; String
(Int -&gt; LayoutError -&gt; ShowS)
-&gt; (LayoutError -&gt; String)
-&gt; ([LayoutError] -&gt; ShowS)
-&gt; Show LayoutError
forall a.
(Int -&gt; a -&gt; ShowS) -&gt; (a -&gt; String) -&gt; ([a] -&gt; ShowS) -&gt; Show a
showList :: [LayoutError] -&gt; ShowS
$cshowList :: [LayoutError] -&gt; ShowS
show :: LayoutError -&gt; String
$cshow :: LayoutError -&gt; String
showsPrec :: Int -&gt; LayoutError -&gt; ShowS
$cshowsPrec :: Int -&gt; LayoutError -&gt; ShowS
</span><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">Show</span></span></span></span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Typeable</span></span><span class="hs-special">)</span><span>
</span><span id="line-480"></span><span>
</span><span id="line-481"></span><span class="hs-keyword">instance</span><span> </span><span id="local-6989586621679540493"><span id="local-6989586621679540495"><span class="annot"><span class="hs-identifier hs-type">Exception</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#LayoutError"><span class="hs-identifier hs-type">LayoutError</span></a></span></span></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-482"></span><span>  </span><span id="local-6989586621679540491"><span class="annot"><span class="annottext">displayException :: LayoutError -&gt; String
</span><a href="#local-6989586621679540491"><span class="hs-identifier hs-var hs-var hs-var hs-var">displayException</span></a></span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#LayoutError"><span class="hs-identifier hs-type">LayoutError</span></a></span><span> </span><span class="hs-special">{</span><span id="local-6989586621679540489"><span id="local-6989586621679540490"><span class="annot"><span class="annottext">LayoutType
leActual :: LayoutType
leExpected :: LayoutType
leActual :: LayoutError -&gt; LayoutType
leExpected :: LayoutError -&gt; LayoutType
</span><a href="#local-6989586621679540489"><span class="hs-glyph hs-var hs-var hs-var hs-var">..</span></a></span></span></span><span class="hs-special">}</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-483"></span><span>    </span><span class="annot"><span class="annottext">String
</span><span class="hs-string">&quot;The tensor does not have the memory layout `&quot;</span></span><span>
</span><span id="line-484"></span><span>      </span><span class="annot"><span class="annottext">String -&gt; ShowS
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">LayoutType -&gt; String
forall a. Show a =&gt; a -&gt; String
</span><span class="hs-identifier hs-var">show</span></span><span> </span><span class="annot"><span class="annottext">LayoutType
</span><a href="#local-6989586621679540490"><span class="hs-identifier hs-var">leExpected</span></a></span><span>
</span><span id="line-485"></span><span>      </span><span class="annot"><span class="annottext">String -&gt; ShowS
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">String
</span><span class="hs-string">&quot;` but `&quot;</span></span><span>
</span><span id="line-486"></span><span>      </span><span class="annot"><span class="annottext">String -&gt; ShowS
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">LayoutType -&gt; String
forall a. Show a =&gt; a -&gt; String
</span><span class="hs-identifier hs-var">show</span></span><span> </span><span class="annot"><span class="annottext">LayoutType
</span><a href="#local-6989586621679540489"><span class="hs-identifier hs-var">leActual</span></a></span><span>
</span><span id="line-487"></span><span>      </span><span class="annot"><span class="annottext">String -&gt; ShowS
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">String
</span><span class="hs-string">&quot;`.&quot;</span></span><span>
</span><span id="line-488"></span><span>
</span><span id="line-489"></span><span class="hs-comment">-- | Checks whether or not the input tensor has the memory layout 'layout'</span><span>
</span><span id="line-490"></span><span class="hs-comment">-- and returns a statically annotated copy of it wrapped in a 'MonadThrow' 'm'.</span><span>
</span><span id="line-491"></span><span class="hs-comment">--</span><span>
</span><span id="line-492"></span><span class="hs-comment">-- For instance, if 'm' is 'Maybe', then the result will be wrapped in 'Just' if and only if the tensor has indeed the memory layout 'layout'.</span><span>
</span><span id="line-493"></span><span class="hs-comment">-- If it does not have it, then the result will be 'Nothing'.</span><span>
</span><span id="line-494"></span><span class="hs-comment">--</span><span>
</span><span id="line-495"></span><span class="hs-comment">-- In the REPL, 'm' will default to 'IO':</span><span>
</span><span id="line-496"></span><span class="hs-comment">-- &gt;&gt;&gt; t = sOnes $ TensorSpec (SGradient SWithGradient) (SUncheckedLayout Dense) (SDevice SCPU) (SDataType SFloat) (SShape $ SName @&quot;batch&quot; :&amp;: SSize @32 :|: SName @&quot;feature&quot; :&amp;: SSize @8 :|: SNil)</span><span>
</span><span id="line-497"></span><span class="hs-comment">-- &gt;&gt;&gt; t' &lt;- sCheckedLayout (SLayout SDense) t</span><span>
</span><span id="line-498"></span><span class="hs-comment">-- &gt;&gt;&gt; :type t'</span><span>
</span><span id="line-499"></span><span class="hs-comment">-- t'</span><span>
</span><span id="line-500"></span><span class="hs-comment">--   :: Tensor</span><span>
</span><span id="line-501"></span><span class="hs-comment">--        ('Gradient 'WithGradient)</span><span>
</span><span id="line-502"></span><span class="hs-comment">--        ('Layout 'Dense)</span><span>
</span><span id="line-503"></span><span class="hs-comment">--        ('Device 'CPU)</span><span>
</span><span id="line-504"></span><span class="hs-comment">--        ('DataType 'Float)</span><span>
</span><span id="line-505"></span><span class="hs-comment">--        ('Shape</span><span>
</span><span id="line-506"></span><span class="hs-comment">--           '[ 'Dim ('Name &quot;batch&quot;) ('Size 32),</span><span>
</span><span id="line-507"></span><span class="hs-comment">--              'Dim ('Name &quot;feature&quot;) ('Size 8)])</span><span>
</span><span id="line-508"></span><span class="hs-comment">-- &gt;&gt;&gt; t' &lt;- sCheckedLayout (SLayout SSparse) t</span><span>
</span><span id="line-509"></span><span class="hs-comment">-- *** Exception: LayoutError {leExpected = Sparse, leActual = Dense}</span><span>
</span><span id="line-510"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#sCheckedLayout"><span class="hs-identifier hs-type">sCheckedLayout</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-511"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679541559"><span class="annot"><a href="#local-6989586621679541559"><span class="hs-identifier hs-type">layout'</span></a></span></span><span> </span><span id="local-6989586621679541560"><span class="annot"><a href="#local-6989586621679541560"><span class="hs-identifier hs-type">m</span></a></span></span><span> </span><span id="local-6989586621679541558"><span class="annot"><a href="#local-6989586621679541558"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679541561"><span class="annot"><a href="#local-6989586621679541561"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679541557"><span class="annot"><a href="#local-6989586621679541557"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679541556"><span class="annot"><a href="#local-6989586621679541556"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679541555"><span class="annot"><a href="#local-6989586621679541555"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-512"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetLayout"><span class="hs-identifier hs-type">SGetLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541561"><span class="hs-identifier hs-type">layout</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier hs-type">MonadThrow</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541560"><span class="hs-identifier hs-type">m</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-513"></span><span>  </span><span class="hs-comment">-- | layout</span><span>
</span><span id="line-514"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#SLayout"><span class="hs-identifier hs-type">SLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541559"><span class="hs-identifier hs-type">layout'</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-515"></span><span>  </span><span class="hs-comment">-- | input tensor</span><span>
</span><span id="line-516"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541558"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541561"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541557"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541556"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541555"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-517"></span><span>  </span><span class="hs-comment">-- | annotated output tensor wrapped in 'm'</span><span>
</span><span id="line-518"></span><span>  </span><span class="annot"><a href="#local-6989586621679541560"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541558"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Seq"><span class="hs-identifier hs-type">Seq</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679541561"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541559"><span class="hs-identifier hs-type">layout'</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679541559"><span class="hs-identifier hs-type">layout'</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679541557"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541556"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541555"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-519"></span><span id="sCheckedLayout"><span class="annot"><span class="annottext">sCheckedLayout :: SLayout layout'
-&gt; Tensor gradient layout device dataType shape
-&gt; m (Tensor
        gradient (Seq (layout &lt;+&gt; layout') layout') device dataType shape)
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sCheckedLayout"><span class="hs-identifier hs-var hs-var">sCheckedLayout</span></a></span></span><span> </span><span id="local-6989586621679540487"><span class="annot"><span class="annottext">SLayout layout'
</span><a href="#local-6989586621679540487"><span class="hs-identifier hs-var">layout'</span></a></span></span><span> </span><span id="local-6989586621679540486"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679540486"><span class="hs-identifier hs-var">tensor</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-520"></span><span>  </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679540485"><span class="annot"><span class="annottext">actualLayout :: LayoutType
</span><a href="#local-6989586621679540485"><span class="hs-identifier hs-var hs-var">actualLayout</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IsChecked LayoutType -&gt; LayoutType
forall a. IsChecked a -&gt; a
</span><a href="Torch.GraduallyTyped.Prelude.html#forgetIsChecked"><span class="hs-identifier hs-var">forgetIsChecked</span></a></span><span> </span><span class="annot"><span class="annottext">(IsChecked LayoutType -&gt; LayoutType)
-&gt; (SLayout layout -&gt; IsChecked LayoutType)
-&gt; SLayout layout
-&gt; LayoutType
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">SLayout layout -&gt; IsChecked LayoutType
forall k (a :: k). SingKind k =&gt; Sing a -&gt; Demote k
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">fromSing</span></a></span><span> </span><span class="annot"><span class="annottext">(SLayout layout -&gt; LayoutType) -&gt; SLayout layout -&gt; LayoutType
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape -&gt; SLayout layout
forall (layout :: Layout LayoutType)
       (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SGetLayout layout =&gt;
Tensor gradient layout device dataType shape -&gt; SLayout layout
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sGetLayout"><span class="hs-identifier hs-var">sGetLayout</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679540486"><span class="hs-identifier hs-var">tensor</span></a></span><span>
</span><span id="line-521"></span><span>      </span><span id="local-6989586621679540484"><span class="annot"><span class="annottext">expectedLayout :: LayoutType
</span><a href="#local-6989586621679540484"><span class="hs-identifier hs-var hs-var">expectedLayout</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IsChecked LayoutType -&gt; LayoutType
forall a. IsChecked a -&gt; a
</span><a href="Torch.GraduallyTyped.Prelude.html#forgetIsChecked"><span class="hs-identifier hs-var">forgetIsChecked</span></a></span><span> </span><span class="annot"><span class="annottext">(IsChecked LayoutType -&gt; LayoutType)
-&gt; (SLayout layout' -&gt; IsChecked LayoutType)
-&gt; SLayout layout'
-&gt; LayoutType
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">SLayout layout' -&gt; IsChecked LayoutType
forall k (a :: k). SingKind k =&gt; Sing a -&gt; Demote k
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">fromSing</span></a></span><span> </span><span class="annot"><span class="annottext">(SLayout layout' -&gt; LayoutType) -&gt; SLayout layout' -&gt; LayoutType
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SLayout layout'
</span><a href="#local-6989586621679540487"><span class="hs-identifier hs-var">layout'</span></a></span><span>
</span><span id="line-522"></span><span>   </span><span class="hs-keyword">in</span><span> </span><span class="hs-keyword">if</span><span> </span><span class="annot"><span class="annottext">LayoutType
</span><a href="#local-6989586621679540485"><span class="hs-identifier hs-var">actualLayout</span></a></span><span> </span><span class="annot"><span class="annottext">LayoutType -&gt; LayoutType -&gt; Bool
forall a. Eq a =&gt; a -&gt; a -&gt; Bool
</span><span class="hs-operator hs-var">==</span></span><span> </span><span class="annot"><span class="annottext">LayoutType
</span><a href="#local-6989586621679540484"><span class="hs-identifier hs-var">expectedLayout</span></a></span><span>
</span><span id="line-523"></span><span>        </span><span class="hs-keyword">then</span><span> </span><span class="annot"><span class="annottext">Tensor
  gradient
  (Seq (Unify (Layout LayoutType) layout layout') layout')
  device
  dataType
  shape
-&gt; m (Tensor
        gradient
        (Seq (Unify (Layout LayoutType) layout layout') layout')
        device
        dataType
        shape)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">(Tensor
   gradient
   (Seq (Unify (Layout LayoutType) layout layout') layout')
   device
   dataType
   shape
 -&gt; m (Tensor
         gradient
         (Seq (Unify (Layout LayoutType) layout layout') layout')
         device
         dataType
         shape))
-&gt; (Tensor gradient layout device dataType shape
    -&gt; Tensor
         gradient
         (Seq (Unify (Layout LayoutType) layout layout') layout')
         device
         dataType
         shape)
-&gt; Tensor gradient layout device dataType shape
-&gt; m (Tensor
        gradient
        (Seq (Unify (Layout LayoutType) layout layout') layout')
        device
        dataType
        shape)
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
-&gt; Tensor
     gradient
     (Seq (Unify (Layout LayoutType) layout layout') layout')
     device
     dataType
     shape
</span><span class="hs-identifier hs-var">coerce</span></span><span> </span><span class="annot"><span class="annottext">(Tensor gradient layout device dataType shape
 -&gt; m (Tensor
         gradient
         (Seq (Unify (Layout LayoutType) layout layout') layout')
         device
         dataType
         shape))
-&gt; Tensor gradient layout device dataType shape
-&gt; m (Tensor
        gradient
        (Seq (Unify (Layout LayoutType) layout layout') layout')
        device
        dataType
        shape)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679540486"><span class="hs-identifier hs-var">tensor</span></a></span><span>
</span><span id="line-524"></span><span>        </span><span class="hs-keyword">else</span><span> </span><span class="annot"><span class="annottext">LayoutError
-&gt; m (Tensor
        gradient
        (Seq (Unify (Layout LayoutType) layout layout') layout')
        device
        dataType
        shape)
forall (m :: * -&gt; *) e a. (MonadThrow m, Exception e) =&gt; e -&gt; m a
</span><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier hs-var">throwM</span></a></span><span> </span><span class="annot"><span class="annottext">(LayoutError
 -&gt; m (Tensor
         gradient
         (Seq (Unify (Layout LayoutType) layout layout') layout')
         device
         dataType
         shape))
-&gt; LayoutError
-&gt; m (Tensor
        gradient
        (Seq (Unify (Layout LayoutType) layout layout') layout')
        device
        dataType
        shape)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">LayoutType -&gt; LayoutType -&gt; LayoutError
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#LayoutError"><span class="hs-identifier hs-var">LayoutError</span></a></span><span> </span><span class="annot"><span class="annottext">LayoutType
</span><a href="#local-6989586621679540484"><span class="hs-identifier hs-var">expectedLayout</span></a></span><span> </span><span class="annot"><span class="annottext">LayoutType
</span><a href="#local-6989586621679540485"><span class="hs-identifier hs-var">actualLayout</span></a></span><span>
</span><span id="line-525"></span><span>
</span><span id="line-526"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#checkedLayout"><span class="hs-identifier hs-type">checkedLayout</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-527"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679540482"><span class="annot"><a href="#local-6989586621679540482"><span class="hs-identifier hs-type">layout'</span></a></span></span><span> </span><span id="local-6989586621679540481"><span class="annot"><a href="#local-6989586621679540481"><span class="hs-identifier hs-type">m</span></a></span></span><span> </span><span id="local-6989586621679540480"><span class="annot"><a href="#local-6989586621679540480"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679540479"><span class="annot"><a href="#local-6989586621679540479"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679540478"><span class="annot"><a href="#local-6989586621679540478"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679540477"><span class="annot"><a href="#local-6989586621679540477"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679540476"><span class="annot"><a href="#local-6989586621679540476"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-528"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-type">SingI</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540482"><span class="hs-identifier hs-type">layout'</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetLayout"><span class="hs-identifier hs-type">SGetLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540479"><span class="hs-identifier hs-type">layout</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier hs-type">MonadThrow</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540481"><span class="hs-identifier hs-type">m</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-529"></span><span>  </span><span class="hs-comment">-- | input tensor</span><span>
</span><span id="line-530"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540480"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540479"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540478"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540477"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540476"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-531"></span><span>  </span><span class="hs-comment">-- | annotated output tensor wrapped in 'm'</span><span>
</span><span id="line-532"></span><span>  </span><span class="annot"><a href="#local-6989586621679540481"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540480"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Seq"><span class="hs-identifier hs-type">Seq</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679540479"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540482"><span class="hs-identifier hs-type">layout'</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679540482"><span class="hs-identifier hs-type">layout'</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679540478"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540477"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540476"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-533"></span><span id="checkedLayout"><span class="annot"><span class="annottext">checkedLayout :: Tensor gradient layout device dataType shape
-&gt; m (Tensor
        gradient (Seq (layout &lt;+&gt; layout') layout') device dataType shape)
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#checkedLayout"><span class="hs-identifier hs-var hs-var">checkedLayout</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SLayout layout'
-&gt; Tensor gradient layout device dataType shape
-&gt; m (Tensor
        gradient (Seq (layout &lt;+&gt; layout') layout') device dataType shape)
forall (layout' :: Layout LayoutType) (m :: * -&gt; *)
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
(SGetLayout layout, MonadThrow m) =&gt;
SLayout layout'
-&gt; Tensor gradient layout device dataType shape
-&gt; m (Tensor
        gradient (Seq (layout &lt;+&gt; layout') layout') device dataType shape)
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sCheckedLayout"><span class="hs-identifier hs-var">sCheckedLayout</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SingI layout' =&gt; Sing layout'
forall k (a :: k). SingI a =&gt; Sing a
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">sing</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679540482"><span class="hs-identifier hs-type">layout'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-534"></span><span>
</span><span id="line-535"></span><span class="hs-comment">-- | Returns the input tensor but with 'UncheckedLayout' as memory layout type annotation.</span><span>
</span><span id="line-536"></span><span class="hs-comment">-- Any static information about the tensor's memory layout is thus erased.</span><span>
</span><span id="line-537"></span><span class="hs-comment">-- However, the tensor's underlying data structure is not changed.</span><span>
</span><span id="line-538"></span><span class="hs-comment">--</span><span>
</span><span id="line-539"></span><span class="hs-comment">-- &gt;&gt;&gt; t = ones @('Gradient 'WithGradient) @('Layout 'Dense) @('Device 'CPU) @('DataType 'Float) @('Shape '[ 'Dim ('Name &quot;batch&quot;) ('Size 32), 'Dim ('Name &quot;feature&quot;) ('Size 8)])</span><span>
</span><span id="line-540"></span><span class="hs-comment">-- &gt;&gt;&gt; :type uncheckedLayout t</span><span>
</span><span id="line-541"></span><span class="hs-comment">-- uncheckedLayout t</span><span>
</span><span id="line-542"></span><span class="hs-comment">--   :: Tensor</span><span>
</span><span id="line-543"></span><span class="hs-comment">--        ('Gradient 'WithGradient)</span><span>
</span><span id="line-544"></span><span class="hs-comment">--        'UncheckedLayout</span><span>
</span><span id="line-545"></span><span class="hs-comment">--        ('Device 'CPU)</span><span>
</span><span id="line-546"></span><span class="hs-comment">--        ('DataType 'Float)</span><span>
</span><span id="line-547"></span><span class="hs-comment">--        ('Shape</span><span>
</span><span id="line-548"></span><span class="hs-comment">--           '[ 'Dim ('Name &quot;batch&quot;) ('Size 32),</span><span>
</span><span id="line-549"></span><span class="hs-comment">--              'Dim ('Name &quot;feature&quot;) ('Size 8)])</span><span>
</span><span id="line-550"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#uncheckedLayout"><span class="hs-identifier hs-type">uncheckedLayout</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-551"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679540474"><span class="annot"><a href="#local-6989586621679540474"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679540473"><span class="annot"><a href="#local-6989586621679540473"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679540472"><span class="annot"><a href="#local-6989586621679540472"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679540471"><span class="annot"><a href="#local-6989586621679540471"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679540470"><span class="annot"><a href="#local-6989586621679540470"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-552"></span><span>  </span><span class="hs-comment">-- | input tensor</span><span>
</span><span id="line-553"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540474"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540473"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540472"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540471"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540470"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-554"></span><span>  </span><span class="hs-comment">-- | tensor without checked layout</span><span>
</span><span id="line-555"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540474"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#UncheckedLayout"><span class="hs-identifier hs-type">UncheckedLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540472"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540471"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540470"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-556"></span><span id="uncheckedLayout"><span class="annot"><span class="annottext">uncheckedLayout :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient 'UncheckedLayout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#uncheckedLayout"><span class="hs-identifier hs-var hs-var">uncheckedLayout</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
-&gt; Tensor gradient 'UncheckedLayout device dataType shape
</span><span class="hs-identifier hs-var">coerce</span></span><span>
</span><span id="line-557"></span><span>
</span><span id="line-558"></span><span class="hs-comment">-- | Returns a copy of the tensor in CPU memory.</span><span>
</span><span id="line-559"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#cpu"><span class="hs-identifier hs-type">cpu</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-560"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679540468"><span class="annot"><a href="#local-6989586621679540468"><span class="hs-identifier hs-type">m</span></a></span></span><span> </span><span id="local-6989586621679540467"><span class="annot"><a href="#local-6989586621679540467"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679540466"><span class="annot"><a href="#local-6989586621679540466"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679540465"><span class="annot"><a href="#local-6989586621679540465"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679540464"><span class="annot"><a href="#local-6989586621679540464"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679540463"><span class="annot"><a href="#local-6989586621679540463"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-561"></span><span>  </span><span class="annot"><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier hs-type">MonadThrow</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540468"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-562"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-563"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540467"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540466"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540465"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540464"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540463"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-564"></span><span>  </span><span class="hs-comment">-- | copy in CPU memory</span><span>
</span><span id="line-565"></span><span>  </span><span class="annot"><a href="#local-6989586621679540468"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540467"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540466"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier hs-type">Device</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#CPU"><span class="hs-identifier hs-type">CPU</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679540464"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540463"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-566"></span><span id="cpu"><span class="annot"><span class="annottext">cpu :: Tensor gradient layout device dataType shape
-&gt; m (Tensor gradient layout ('Device 'CPU) dataType shape)
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#cpu"><span class="hs-identifier hs-var hs-var">cpu</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout ('Device 'CPU) dataType shape)
-&gt; m (Tensor gradient layout ('Device 'CPU) dataType shape)
forall a (m :: * -&gt; *). MonadThrow m =&gt; IO a -&gt; m a
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">unsafeThrowableIO</span></a></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout ('Device 'CPU) dataType shape)
 -&gt; m (Tensor gradient layout ('Device 'CPU) dataType shape))
-&gt; (Tensor gradient layout device dataType shape
    -&gt; IO (Tensor gradient layout ('Device 'CPU) dataType shape))
-&gt; Tensor gradient layout device dataType shape
-&gt; m (Tensor gradient layout ('Device 'CPU) dataType shape)
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; IO (Tensor gradient layout ('Device 'CPU) dataType shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.tensor_cpu</span></a></span><span>
</span><span id="line-567"></span><span>
</span><span id="line-568"></span><span class="hs-comment">-- | Returns a copy of the tensor in CUDA memory.</span><span>
</span><span id="line-569"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#cuda"><span class="hs-identifier hs-type">cuda</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-570"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679540460"><span class="annot"><a href="#local-6989586621679540460"><span class="hs-identifier hs-type">m</span></a></span></span><span> </span><span id="local-6989586621679540459"><span class="annot"><a href="#local-6989586621679540459"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679540458"><span class="annot"><a href="#local-6989586621679540458"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679540457"><span class="annot"><a href="#local-6989586621679540457"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679540456"><span class="annot"><a href="#local-6989586621679540456"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679540455"><span class="annot"><a href="#local-6989586621679540455"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-571"></span><span>  </span><span class="annot"><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier hs-type">MonadThrow</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540460"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-572"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-573"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540459"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540458"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540457"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540456"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540455"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-574"></span><span>  </span><span class="hs-comment">-- | copy in CUDA memory</span><span>
</span><span id="line-575"></span><span>  </span><span class="annot"><a href="#local-6989586621679540460"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540459"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540458"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier hs-type">Device</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#CUDA"><span class="hs-identifier hs-type">CUDA</span></a></span><span> </span><span class="annot"><span class="hs-number">0</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679540456"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540455"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-576"></span><span id="cuda"><span class="annot"><span class="annottext">cuda :: Tensor gradient layout device dataType shape
-&gt; m (Tensor gradient layout ('Device ('CUDA 0)) dataType shape)
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#cuda"><span class="hs-identifier hs-var hs-var">cuda</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout ('Device ('CUDA 0)) dataType shape)
-&gt; m (Tensor gradient layout ('Device ('CUDA 0)) dataType shape)
forall a (m :: * -&gt; *). MonadThrow m =&gt; IO a -&gt; m a
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">unsafeThrowableIO</span></a></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout ('Device ('CUDA 0)) dataType shape)
 -&gt; m (Tensor gradient layout ('Device ('CUDA 0)) dataType shape))
-&gt; (Tensor gradient layout device dataType shape
    -&gt; IO (Tensor gradient layout ('Device ('CUDA 0)) dataType shape))
-&gt; Tensor gradient layout device dataType shape
-&gt; m (Tensor gradient layout ('Device ('CUDA 0)) dataType shape)
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; IO (Tensor gradient layout ('Device ('CUDA 0)) dataType shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.tensor_cuda</span></a></span><span>
</span><span id="line-577"></span><span>
</span><span id="line-578"></span><span class="hs-comment">-- | Reallocates a tensor on the specified device.</span><span>
</span><span id="line-579"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#sSetDevice"><span class="hs-identifier hs-type">sSetDevice</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-580"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679541099"><span class="annot"><a href="#local-6989586621679541099"><span class="hs-identifier hs-type">m</span></a></span></span><span> </span><span id="local-6989586621679541097"><span class="annot"><a href="#local-6989586621679541097"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679541096"><span class="annot"><a href="#local-6989586621679541096"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679541098"><span class="annot"><a href="#local-6989586621679541098"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679541095"><span class="annot"><a href="#local-6989586621679541095"><span class="hs-identifier hs-type">device'</span></a></span></span><span> </span><span id="local-6989586621679541094"><span class="annot"><a href="#local-6989586621679541094"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679541093"><span class="annot"><a href="#local-6989586621679541093"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-581"></span><span>  </span><span class="annot"><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier hs-type">MonadThrow</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541099"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-582"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#SDevice"><span class="hs-identifier hs-type">SDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541098"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-583"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541097"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541096"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541095"><span class="hs-identifier hs-type">device'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541094"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541093"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-584"></span><span>  </span><span class="annot"><a href="#local-6989586621679541099"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541097"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541096"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541098"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541094"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541093"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-585"></span><span id="sSetDevice"><span class="annot"><span class="annottext">sSetDevice :: SDevice device
-&gt; Tensor gradient layout device' dataType shape
-&gt; m (Tensor gradient layout device dataType shape)
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sSetDevice"><span class="hs-identifier hs-var hs-var">sSetDevice</span></a></span></span><span> </span><span id="local-6989586621679540452"><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679540452"><span class="hs-identifier hs-var">device</span></a></span></span><span> </span><span id="local-6989586621679540451"><span class="annot"><span class="annottext">Tensor gradient layout device' dataType shape
</span><a href="#local-6989586621679540451"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-586"></span><span>  </span><span class="hs-keyword">case</span><span> </span><span class="annot"><span class="annottext">IsChecked (DeviceType Int16) -&gt; DeviceType Int16
forall a. IsChecked a -&gt; a
</span><a href="Torch.GraduallyTyped.Prelude.html#forgetIsChecked"><span class="hs-identifier hs-var">forgetIsChecked</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Sing device -&gt; Demote (Device (DeviceType Nat))
forall k (a :: k). SingKind k =&gt; Sing a -&gt; Demote k
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">fromSing</span></a></span><span> </span><span class="annot"><span class="annottext">Sing device
SDevice device
</span><a href="#local-6989586621679540452"><span class="hs-identifier hs-var">device</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-keyword">of</span><span>
</span><span id="line-587"></span><span>    </span><span class="annot"><span class="annottext">DeviceType Int16
</span><a href="Torch.GraduallyTyped.Device.html#CPU"><span class="hs-identifier hs-var">CPU</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-588"></span><span>      </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; m (Tensor gradient layout device dataType shape)
forall a (m :: * -&gt; *). MonadThrow m =&gt; IO a -&gt; m a
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">unsafeThrowableIO</span></a></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; m (Tensor gradient layout device dataType shape))
-&gt; (Tensor gradient layout device' dataType shape
    -&gt; IO (Tensor gradient layout device dataType shape))
-&gt; Tensor gradient layout device' dataType shape
-&gt; m (Tensor gradient layout device dataType shape)
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device' dataType shape
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.tensor_cpu</span></a></span><span> </span><span class="annot"><span class="annottext">(Tensor gradient layout device' dataType shape
 -&gt; m (Tensor gradient layout device dataType shape))
-&gt; Tensor gradient layout device' dataType shape
-&gt; m (Tensor gradient layout device dataType shape)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device' dataType shape
</span><a href="#local-6989586621679540451"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-589"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#CUDA"><span class="hs-identifier hs-type">CUDA</span></a></span><span> </span><span class="annot"><span class="annottext">Int16
</span><span class="hs-number">0</span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-590"></span><span>      </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; m (Tensor gradient layout device dataType shape)
forall a (m :: * -&gt; *). MonadThrow m =&gt; IO a -&gt; m a
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">unsafeThrowableIO</span></a></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; m (Tensor gradient layout device dataType shape))
-&gt; (Tensor gradient layout device' dataType shape
    -&gt; IO (Tensor gradient layout device dataType shape))
-&gt; Tensor gradient layout device' dataType shape
-&gt; m (Tensor gradient layout device dataType shape)
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device' dataType shape
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.tensor_cuda</span></a></span><span> </span><span class="annot"><span class="annottext">(Tensor gradient layout device' dataType shape
 -&gt; m (Tensor gradient layout device dataType shape))
-&gt; Tensor gradient layout device' dataType shape
-&gt; m (Tensor gradient layout device dataType shape)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device' dataType shape
</span><a href="#local-6989586621679540451"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-591"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#CUDA"><span class="hs-identifier hs-type">CUDA</span></a></span><span> </span><span id="local-6989586621679540450"><span class="annot"><span class="annottext">Int16
</span><a href="#local-6989586621679540450"><span class="hs-identifier hs-var">idx</span></a></span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-592"></span><span>      </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; m (Tensor gradient layout device dataType shape)
forall a (m :: * -&gt; *). MonadThrow m =&gt; IO a -&gt; m a
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">unsafeThrowableIO</span></a></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; m (Tensor gradient layout device dataType shape))
-&gt; IO (Tensor gradient layout device dataType shape)
-&gt; m (Tensor gradient layout device dataType shape)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-593"></span><span>        </span><span id="local-6989586621679540449"><span class="annot"><span class="annottext">ForeignPtr TensorOptions
</span><a href="#local-6989586621679540449"><span class="hs-identifier hs-var">opts</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">ForeignPtr</span></span><span> </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-type">ATen.TensorOptions</span></a></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr TensorOptions))
-&gt; Tensor gradient layout device' dataType shape
-&gt; IO (ForeignPtr TensorOptions)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr TensorOptions)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.tensor_options</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device' dataType shape
</span><a href="#local-6989586621679540451"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-594"></span><span>        </span><span id="local-6989586621679540447"><span class="annot"><span class="annottext">ForeignPtr TensorOptions
</span><a href="#local-6989586621679540447"><span class="hs-identifier hs-var">opts'</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">ForeignPtr</span></span><span> </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-type">ATen.TensorOptions</span></a></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">(ForeignPtr TensorOptions
 -&gt; Int16 -&gt; IO (ForeignPtr TensorOptions))
-&gt; ForeignPtr TensorOptions
-&gt; Int16
-&gt; IO (ForeignPtr TensorOptions)
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr TensorOptions -&gt; Int16 -&gt; IO (ForeignPtr TensorOptions)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.tensorOptions_device_index_s</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr TensorOptions
</span><a href="#local-6989586621679540449"><span class="hs-identifier hs-var">opts</span></a></span><span> </span><span class="annot"><span class="annottext">Int16
</span><a href="#local-6989586621679540450"><span class="hs-identifier hs-var">idx</span></a></span><span>
</span><span id="line-595"></span><span>        </span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr TensorOptions
 -&gt; CBool
 -&gt; CBool
 -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device' dataType shape
-&gt; ForeignPtr TensorOptions
-&gt; Bool
-&gt; Bool
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca x1 cx1 x2 cx2 x3 cx3 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable x3 cx3,
 Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; cx3 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; x2 -&gt; x3 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast4</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; ForeignPtr TensorOptions
-&gt; CBool
-&gt; CBool
-&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.tensor_to_obb</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device' dataType shape
</span><a href="#local-6989586621679540451"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr TensorOptions
</span><a href="#local-6989586621679540447"><span class="hs-identifier hs-var">opts'</span></a></span><span> </span><span class="annot"><span class="annottext">Bool
</span><a href="#local-6989586621679540444"><span class="hs-identifier hs-var">nonBlocking</span></a></span><span> </span><span class="annot"><span class="annottext">Bool
</span><a href="#local-6989586621679540443"><span class="hs-identifier hs-var">copy</span></a></span><span>
</span><span id="line-596"></span><span>      </span><span class="hs-keyword">where</span><span>
</span><span id="line-597"></span><span>        </span><span id="local-6989586621679540444"><span class="annot"><span class="annottext">nonBlocking :: Bool
</span><a href="#local-6989586621679540444"><span class="hs-identifier hs-var hs-var">nonBlocking</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Bool
</span><span class="hs-identifier hs-var">False</span></span><span>
</span><span id="line-598"></span><span>        </span><span id="local-6989586621679540443"><span class="annot"><span class="annottext">copy :: Bool
</span><a href="#local-6989586621679540443"><span class="hs-identifier hs-var hs-var">copy</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Bool
</span><span class="hs-identifier hs-var">False</span></span><span>
</span><span id="line-599"></span><span>
</span><span id="line-600"></span><span class="hs-keyword">class</span><span> </span><span id="SGetDevice"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetDevice"><span class="hs-identifier hs-var">SGetDevice</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679541514"><span class="annot"><a href="#local-6989586621679541514"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier hs-type">Device</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#DeviceType"><span class="hs-identifier hs-type">DeviceType</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-601"></span><span>  </span><span class="hs-comment">-- | Returns the gradually typed compute device of the input tensor.</span><span>
</span><span id="line-602"></span><span>  </span><span class="hs-comment">--</span><span>
</span><span id="line-603"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; ones' device = sOnes $ TensorSpec (SGradient SWithGradient) (SLayout SDense) device (SDataType SFloat) (SShape $ SName @&quot;batch&quot; :&amp;: SSize @32 :|: SName @&quot;feature&quot; :&amp;: SSize @8 :|: SNil)</span><span>
</span><span id="line-604"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; t = ones' $ SDevice SCPU</span><span>
</span><span id="line-605"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; sGetDevice t</span><span>
</span><span id="line-606"></span><span>  </span><span class="hs-comment">-- SDevice SCPU</span><span>
</span><span id="line-607"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; t = ones' $ SUncheckedDevice CPU</span><span>
</span><span id="line-608"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; sGetDevice t</span><span>
</span><span id="line-609"></span><span>  </span><span class="hs-comment">-- SUncheckedDevice CPU</span><span>
</span><span id="line-610"></span><span>  </span><span id="sGetDevice"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#sGetDevice"><span class="hs-identifier hs-type">sGetDevice</span></a></span></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-611"></span><span>    </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679541510"><span class="annot"><a href="#local-6989586621679541510"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679541509"><span class="annot"><a href="#local-6989586621679541509"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679541508"><span class="annot"><a href="#local-6989586621679541508"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679541507"><span class="annot"><a href="#local-6989586621679541507"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-612"></span><span>    </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-613"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541510"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541509"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541514"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541508"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541507"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-614"></span><span>    </span><span class="hs-comment">-- | compute device of the input tensor</span><span>
</span><span id="line-615"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#SDevice"><span class="hs-identifier hs-type">SDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541514"><span class="hs-identifier hs-type">device</span></a></span><span>
</span><span id="line-616"></span><span>
</span><span id="line-617"></span><span>  </span><span class="hs-comment">-- | Returns the untyped compute device of the input tensor.</span><span>
</span><span id="line-618"></span><span>  </span><span class="hs-comment">--</span><span>
</span><span id="line-619"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; ones' device = sOnes $ TensorSpec (SGradient SWithGradient) (SLayout SDense) device (SDataType SFloat) (SShape $ SName @&quot;batch&quot; :&amp;: SSize @32 :|: SName @&quot;feature&quot; :&amp;: SSize @8 :|: SNil)</span><span>
</span><span id="line-620"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; t = ones' $ SDevice SCPU</span><span>
</span><span id="line-621"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; getDeviceType t</span><span>
</span><span id="line-622"></span><span>  </span><span class="hs-comment">-- CPU</span><span>
</span><span id="line-623"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; t = ones' $ SUncheckedDevice CPU</span><span>
</span><span id="line-624"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; getDeviceType t</span><span>
</span><span id="line-625"></span><span>  </span><span class="hs-comment">-- CPU</span><span>
</span><span id="line-626"></span><span>  </span><span id="getDeviceType"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#getDeviceType"><span class="hs-identifier hs-type">getDeviceType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-627"></span><span>    </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679541505"><span class="annot"><a href="#local-6989586621679541505"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679541504"><span class="annot"><a href="#local-6989586621679541504"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679541503"><span class="annot"><a href="#local-6989586621679541503"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679541502"><span class="annot"><a href="#local-6989586621679541502"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-628"></span><span>    </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-629"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541505"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541504"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541514"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541503"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541502"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-630"></span><span>    </span><span class="hs-comment">-- | compute device of the input tensor</span><span>
</span><span id="line-631"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#DeviceType"><span class="hs-identifier hs-type">DeviceType</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int16</span></span><span>
</span><span id="line-632"></span><span>  </span><span id="local-6989586621679540440"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#getDeviceType"><span class="hs-identifier hs-var hs-var">getDeviceType</span></a></span><span> </span><span id="local-6989586621679540439"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679540439"><span class="hs-identifier hs-var">tensor</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IsChecked (DeviceType Int16) -&gt; DeviceType Int16
forall a. IsChecked a -&gt; a
</span><a href="Torch.GraduallyTyped.Prelude.html#forgetIsChecked"><span class="hs-identifier hs-var">forgetIsChecked</span></a></span><span> </span><span class="annot"><span class="annottext">(IsChecked (DeviceType Int16) -&gt; DeviceType Int16)
-&gt; (SDevice device -&gt; IsChecked (DeviceType Int16))
-&gt; SDevice device
-&gt; DeviceType Int16
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">SDevice device -&gt; IsChecked (DeviceType Int16)
forall k (a :: k). SingKind k =&gt; Sing a -&gt; Demote k
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">fromSing</span></a></span><span> </span><span class="annot"><span class="annottext">(SDevice device -&gt; DeviceType Int16)
-&gt; SDevice device -&gt; DeviceType Int16
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape -&gt; SDevice device
forall (device :: Device (DeviceType Nat))
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SGetDevice device =&gt;
Tensor gradient layout device dataType shape -&gt; SDevice device
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sGetDevice"><span class="hs-identifier hs-var">sGetDevice</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679540439"><span class="hs-identifier hs-var">tensor</span></a></span></span><span>
</span><span id="line-633"></span><span>
</span><span id="line-634"></span><span class="hs-keyword">instance</span><span> </span><span id="local-6989586621679540436"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetDevice"><span class="hs-identifier hs-type">SGetDevice</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#UncheckedDevice"><span class="hs-identifier hs-type">UncheckedDevice</span></a></span></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-635"></span><span>  </span><span id="local-6989586621679540434"><span class="annot"><span class="annottext">sGetDevice :: Tensor gradient layout 'UncheckedDevice dataType shape
-&gt; SDevice 'UncheckedDevice
</span><a href="#local-6989586621679540434"><span class="hs-identifier hs-var hs-var hs-var hs-var">sGetDevice</span></a></span></span><span> </span><span id="local-6989586621679540433"><span class="annot"><span class="annottext">Tensor gradient layout 'UncheckedDevice dataType shape
</span><a href="#local-6989586621679540433"><span class="hs-identifier hs-var">tensor</span></a></span></span><span>
</span><span id="line-636"></span><span>    </span><span class="hs-glyph">|</span><span> </span><span class="annot"><span class="annottext">IO Bool -&gt; Bool
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">IO CBool -&gt; IO Bool
forall a ca. Castable a ca =&gt; IO ca -&gt; IO a
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast0</span></a></span><span> </span><span class="annot"><span class="annottext">IO CBool
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.hasCUDA</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Bool -&gt; Bool -&gt; Bool
</span><span class="hs-operator hs-var">&amp;&amp;</span></span><span> </span><span class="annot"><span class="annottext">IO Bool -&gt; Bool
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO CBool)
-&gt; Tensor gradient layout 'UncheckedDevice dataType shape
-&gt; IO Bool
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO CBool
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.tensor_is_cuda</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout 'UncheckedDevice dataType shape
</span><a href="#local-6989586621679540433"><span class="hs-identifier hs-var">tensor</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-637"></span><span>      </span><span class="hs-keyword">case</span><span> </span><span class="annot"><span class="annottext">IO Int -&gt; Int
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO Int64)
-&gt; Tensor gradient layout 'UncheckedDevice dataType shape -&gt; IO Int
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO Int64
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.tensor_get_device</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout 'UncheckedDevice dataType shape
</span><a href="#local-6989586621679540433"><span class="hs-identifier hs-var">tensor</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span> </span><span class="hs-keyword">of</span><span>
</span><span id="line-638"></span><span>        </span><span id="local-6989586621679540428"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679540428"><span class="hs-identifier hs-var">deviceIndex</span></a></span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">DeviceType Int16 -&gt; SDevice 'UncheckedDevice
</span><a href="Torch.GraduallyTyped.Device.html#SUncheckedDevice"><span class="hs-identifier hs-var">SUncheckedDevice</span></a></span><span> </span><span class="annot"><span class="annottext">(DeviceType Int16 -&gt; SDevice 'UncheckedDevice)
-&gt; (Int -&gt; DeviceType Int16) -&gt; Int -&gt; SDevice 'UncheckedDevice
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Int16 -&gt; DeviceType Int16
forall deviceId. deviceId -&gt; DeviceType deviceId
</span><a href="Torch.GraduallyTyped.Device.html#CUDA"><span class="hs-identifier hs-var">CUDA</span></a></span><span> </span><span class="annot"><span class="annottext">(Int16 -&gt; DeviceType Int16)
-&gt; (Int -&gt; Int16) -&gt; Int -&gt; DeviceType Int16
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int16
forall a b. (Integral a, Num b) =&gt; a -&gt; b
</span><span class="hs-identifier hs-var">fromIntegral</span></span><span> </span><span class="annot"><span class="annottext">(Int -&gt; SDevice 'UncheckedDevice)
-&gt; Int -&gt; SDevice 'UncheckedDevice
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679540428"><span class="hs-identifier hs-var">deviceIndex</span></a></span><span>
</span><span id="line-639"></span><span>    </span><span class="hs-glyph">|</span><span> </span><span class="annot"><span class="annottext">Bool
</span><span class="hs-identifier hs-var">otherwise</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">DeviceType Int16 -&gt; SDevice 'UncheckedDevice
</span><a href="Torch.GraduallyTyped.Device.html#SUncheckedDevice"><span class="hs-identifier hs-var">SUncheckedDevice</span></a></span><span> </span><span class="annot"><span class="annottext">DeviceType Int16
forall deviceId. DeviceType deviceId
</span><a href="Torch.GraduallyTyped.Device.html#CPU"><span class="hs-identifier hs-var">CPU</span></a></span><span>
</span><span id="line-640"></span><span>
</span><span id="line-641"></span><span class="hs-keyword">instance</span><span> </span><span id="local-6989586621679540424"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetDevice"><span class="hs-identifier hs-type">SGetDevice</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier hs-type">Device</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#CPU"><span class="hs-identifier hs-type">CPU</span></a></span><span class="hs-special">)</span></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-642"></span><span>  </span><span id="local-6989586621679540423"><span class="annot"><span class="annottext">sGetDevice :: Tensor gradient layout ('Device 'CPU) dataType shape
-&gt; SDevice ('Device 'CPU)
</span><a href="#local-6989586621679540423"><span class="hs-identifier hs-var hs-var hs-var hs-var">sGetDevice</span></a></span></span><span> </span><span id="local-6989586621679540422"><span class="annot"><span class="annottext">Tensor gradient layout ('Device 'CPU) dataType shape
</span><a href="#local-6989586621679540422"><span class="hs-identifier hs-var">tensor</span></a></span></span><span>
</span><span id="line-643"></span><span>    </span><span class="hs-glyph">|</span><span> </span><span class="annot"><span class="annottext">IO Bool -&gt; Bool
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">IO CBool -&gt; IO Bool
forall a ca. Castable a ca =&gt; IO ca -&gt; IO a
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast0</span></a></span><span> </span><span class="annot"><span class="annottext">IO CBool
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.hasCUDA</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Bool -&gt; Bool -&gt; Bool
</span><span class="hs-operator hs-var">&amp;&amp;</span></span><span> </span><span class="annot"><span class="annottext">IO Bool -&gt; Bool
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO CBool)
-&gt; Tensor gradient layout ('Device 'CPU) dataType shape -&gt; IO Bool
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO CBool
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.tensor_is_cuda</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout ('Device 'CPU) dataType shape
</span><a href="#local-6989586621679540422"><span class="hs-identifier hs-var">tensor</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-644"></span><span>      </span><span class="annot"><span class="annottext">String -&gt; SDevice ('Device 'CPU)
forall a. HasCallStack =&gt; String -&gt; a
</span><span class="hs-identifier hs-var">error</span></span><span> </span><span class="annot"><span class="annottext">(String -&gt; SDevice ('Device 'CPU))
-&gt; String -&gt; SDevice ('Device 'CPU)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-645"></span><span>        </span><span class="annot"><span class="annottext">String
</span><span class="hs-string">&quot;The tensor should be on CPU but is on CUDA. &quot;</span></span><span>
</span><span id="line-646"></span><span>          </span><span class="annot"><span class="annottext">String -&gt; ShowS
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">String
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#gitHubErrorMsg"><span class="hs-identifier hs-var">gitHubErrorMsg</span></a></span><span>
</span><span id="line-647"></span><span>    </span><span class="hs-glyph">|</span><span> </span><span class="annot"><span class="annottext">Bool
</span><span class="hs-identifier hs-var">otherwise</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SDeviceType 'CPU -&gt; SDevice ('Device 'CPU)
forall (deviceType :: DeviceType Nat).
SDeviceType deviceType -&gt; SDevice ('Device deviceType)
</span><a href="Torch.GraduallyTyped.Device.html#SDevice"><span class="hs-identifier hs-var">SDevice</span></a></span><span> </span><span class="annot"><span class="annottext">SDeviceType 'CPU
</span><a href="Torch.GraduallyTyped.Device.html#SCPU"><span class="hs-identifier hs-var">SCPU</span></a></span><span>
</span><span id="line-648"></span><span>
</span><span id="line-649"></span><span id="local-6989586621679540419"><span class="hs-keyword">instance</span><span> </span><span id="local-6989586621679540416"><span class="annot"><span class="hs-identifier hs-type">KnownNat</span></span><span> </span><span class="annot"><a href="#local-6989586621679540419"><span class="hs-identifier hs-type">deviceIndex</span></a></span><span> </span><span class="hs-glyph">=&gt;</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetDevice"><span class="hs-identifier hs-type">SGetDevice</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier hs-type">Device</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#CUDA"><span class="hs-identifier hs-type">CUDA</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540419"><span class="hs-identifier hs-type">deviceIndex</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-650"></span><span>  </span><span id="local-6989586621679540415"><span class="annot"><span class="annottext">sGetDevice :: Tensor gradient layout ('Device ('CUDA deviceIndex)) dataType shape
-&gt; SDevice ('Device ('CUDA deviceIndex))
</span><a href="#local-6989586621679540415"><span class="hs-identifier hs-var hs-var hs-var hs-var">sGetDevice</span></a></span></span><span> </span><span id="local-6989586621679540414"><span class="annot"><span class="annottext">Tensor gradient layout ('Device ('CUDA deviceIndex)) dataType shape
</span><a href="#local-6989586621679540414"><span class="hs-identifier hs-var">tensor</span></a></span></span><span>
</span><span id="line-651"></span><span>    </span><span class="hs-glyph">|</span><span> </span><span class="annot"><span class="annottext">IO Bool -&gt; Bool
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">IO CBool -&gt; IO Bool
forall a ca. Castable a ca =&gt; IO ca -&gt; IO a
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast0</span></a></span><span> </span><span class="annot"><span class="annottext">IO CBool
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.hasCUDA</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Bool -&gt; Bool -&gt; Bool
</span><span class="hs-operator hs-var">&amp;&amp;</span></span><span> </span><span class="annot"><span class="annottext">IO Bool -&gt; Bool
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO CBool)
-&gt; Tensor
     gradient layout ('Device ('CUDA deviceIndex)) dataType shape
-&gt; IO Bool
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO CBool
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.tensor_is_cuda</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout ('Device ('CUDA deviceIndex)) dataType shape
</span><a href="#local-6989586621679540414"><span class="hs-identifier hs-var">tensor</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-652"></span><span>      </span><span class="hs-keyword">case</span><span> </span><span class="annot"><span class="annottext">IO Int -&gt; Int
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO Int64)
-&gt; Tensor
     gradient layout ('Device ('CUDA deviceIndex)) dataType shape
-&gt; IO Int
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO Int64
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.tensor_get_device</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout ('Device ('CUDA deviceIndex)) dataType shape
</span><a href="#local-6989586621679540414"><span class="hs-identifier hs-var">tensor</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span> </span><span class="hs-keyword">of</span><span>
</span><span id="line-653"></span><span>        </span><span id="local-6989586621679540413"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679540413"><span class="hs-identifier hs-var">deviceIndex</span></a></span></span><span>
</span><span id="line-654"></span><span>          </span><span class="hs-glyph">|</span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679540413"><span class="hs-identifier hs-var">deviceIndex</span></a></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Bool
forall a. Eq a =&gt; a -&gt; a -&gt; Bool
</span><span class="hs-operator hs-var">==</span></span><span> </span><span class="annot"><span class="annottext">Integer -&gt; Int
forall a b. (Integral a, Num b) =&gt; a -&gt; b
</span><span class="hs-identifier hs-var">fromIntegral</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Proxy deviceIndex -&gt; Integer
forall (n :: Nat) (proxy :: Nat -&gt; *).
KnownNat n =&gt;
proxy n -&gt; Integer
</span><span class="hs-identifier hs-var">natVal</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Proxy deviceIndex
forall k (t :: k). Proxy t
</span><span class="hs-identifier hs-var">Proxy</span></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679540419"><span class="hs-identifier hs-type">deviceIndex</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">SDeviceType ('CUDA deviceIndex)
-&gt; SDevice ('Device ('CUDA deviceIndex))
forall (deviceType :: DeviceType Nat).
SDeviceType deviceType -&gt; SDevice ('Device deviceType)
</span><a href="Torch.GraduallyTyped.Device.html#SDevice"><span class="hs-identifier hs-var">SDevice</span></a></span><span> </span><span class="annot"><span class="annottext">SDeviceType ('CUDA deviceIndex)
forall (deviceId :: Nat).
KnownNat deviceId =&gt;
SDeviceType ('CUDA deviceId)
</span><a href="Torch.GraduallyTyped.Device.html#SCUDA"><span class="hs-identifier hs-var">SCUDA</span></a></span><span>
</span><span id="line-655"></span><span>          </span><span class="hs-glyph">|</span><span> </span><span class="annot"><span class="annottext">Bool
</span><span class="hs-identifier hs-var">otherwise</span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-656"></span><span>            </span><span class="annot"><span class="annottext">String -&gt; SDevice ('Device ('CUDA deviceIndex))
forall a. HasCallStack =&gt; String -&gt; a
</span><span class="hs-identifier hs-var">error</span></span><span> </span><span class="annot"><span class="annottext">(String -&gt; SDevice ('Device ('CUDA deviceIndex)))
-&gt; String -&gt; SDevice ('Device ('CUDA deviceIndex))
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-657"></span><span>              </span><span class="annot"><span class="annottext">String
</span><span class="hs-string">&quot;The tensor should be on CUDA device &quot;</span></span><span>
</span><span id="line-658"></span><span>                </span><span class="annot"><span class="annottext">String -&gt; ShowS
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">Integer -&gt; String
forall a. Show a =&gt; a -&gt; String
</span><span class="hs-identifier hs-var">show</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Proxy deviceIndex -&gt; Integer
forall (n :: Nat) (proxy :: Nat -&gt; *).
KnownNat n =&gt;
proxy n -&gt; Integer
</span><span class="hs-identifier hs-var">natVal</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Proxy deviceIndex
forall k (t :: k). Proxy t
</span><span class="hs-identifier hs-var">Proxy</span></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679540419"><span class="hs-identifier hs-type">deviceIndex</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-659"></span><span>                </span><span class="annot"><span class="annottext">String -&gt; ShowS
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">String
</span><span class="hs-string">&quot; but is on device &quot;</span></span><span>
</span><span id="line-660"></span><span>                </span><span class="annot"><span class="annottext">String -&gt; ShowS
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">Int -&gt; String
forall a. Show a =&gt; a -&gt; String
</span><span class="hs-identifier hs-var">show</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679540413"><span class="hs-identifier hs-var">deviceIndex</span></a></span><span>
</span><span id="line-661"></span><span>                </span><span class="annot"><span class="annottext">String -&gt; ShowS
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">String
</span><span class="hs-string">&quot;. &quot;</span></span><span>
</span><span id="line-662"></span><span>                </span><span class="annot"><span class="annottext">String -&gt; ShowS
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">String
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#gitHubErrorMsg"><span class="hs-identifier hs-var">gitHubErrorMsg</span></a></span><span>
</span><span id="line-663"></span><span>    </span><span class="hs-glyph">|</span><span> </span><span class="annot"><span class="annottext">Bool
</span><span class="hs-identifier hs-var">otherwise</span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-664"></span><span>      </span><span class="annot"><span class="annottext">String -&gt; SDevice ('Device ('CUDA deviceIndex))
forall a. HasCallStack =&gt; String -&gt; a
</span><span class="hs-identifier hs-var">error</span></span><span> </span><span class="annot"><span class="annottext">(String -&gt; SDevice ('Device ('CUDA deviceIndex)))
-&gt; String -&gt; SDevice ('Device ('CUDA deviceIndex))
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-665"></span><span>        </span><span class="annot"><span class="annottext">String
</span><span class="hs-string">&quot;The tensor should be on CUDA but is on CPU. &quot;</span></span><span>
</span><span id="line-666"></span><span>          </span><span class="annot"><span class="annottext">String -&gt; ShowS
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">String
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#gitHubErrorMsg"><span class="hs-identifier hs-var">gitHubErrorMsg</span></a></span></span><span>
</span><span id="line-667"></span><span>
</span><span id="line-668"></span><span class="hs-keyword">data</span><span> </span><span id="DeviceError"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#DeviceError"><span class="hs-identifier hs-var">DeviceError</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span id="DeviceError"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#DeviceError"><span class="hs-identifier hs-var">DeviceError</span></a></span></span><span> </span><span class="hs-special">{</span><span id="deExpected"><span class="annot"><span class="annottext">DeviceError -&gt; DeviceType Int16
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#deExpected"><span class="hs-identifier hs-var hs-var">deExpected</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#DeviceType"><span class="hs-identifier hs-type">DeviceType</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int16</span></span><span class="hs-special">,</span><span> </span><span id="deActual"><span class="annot"><span class="annottext">DeviceError -&gt; DeviceType Int16
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#deActual"><span class="hs-identifier hs-var hs-var">deActual</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#DeviceType"><span class="hs-identifier hs-type">DeviceType</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int16</span></span><span class="hs-special">}</span><span>
</span><span id="line-669"></span><span>  </span><span class="hs-keyword">deriving</span><span> </span><span class="annot"><span class="hs-keyword">stock</span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679540402"><span id="local-6989586621679540404"><span id="local-6989586621679540406"><span class="annot"><span class="annottext">Int -&gt; DeviceError -&gt; ShowS
[DeviceError] -&gt; ShowS
DeviceError -&gt; String
(Int -&gt; DeviceError -&gt; ShowS)
-&gt; (DeviceError -&gt; String)
-&gt; ([DeviceError] -&gt; ShowS)
-&gt; Show DeviceError
forall a.
(Int -&gt; a -&gt; ShowS) -&gt; (a -&gt; String) -&gt; ([a] -&gt; ShowS) -&gt; Show a
showList :: [DeviceError] -&gt; ShowS
$cshowList :: [DeviceError] -&gt; ShowS
show :: DeviceError -&gt; String
$cshow :: DeviceError -&gt; String
showsPrec :: Int -&gt; DeviceError -&gt; ShowS
$cshowsPrec :: Int -&gt; DeviceError -&gt; ShowS
</span><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">Show</span></span></span></span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Typeable</span></span><span class="hs-special">)</span><span>
</span><span id="line-670"></span><span>
</span><span id="line-671"></span><span class="hs-keyword">instance</span><span> </span><span id="local-6989586621679540396"><span id="local-6989586621679540398"><span class="annot"><span class="hs-identifier hs-type">Exception</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#DeviceError"><span class="hs-identifier hs-type">DeviceError</span></a></span></span></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-672"></span><span>  </span><span id="local-6989586621679540394"><span class="annot"><span class="annottext">displayException :: DeviceError -&gt; String
</span><a href="#local-6989586621679540394"><span class="hs-identifier hs-var hs-var hs-var hs-var">displayException</span></a></span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#DeviceError"><span class="hs-identifier hs-type">DeviceError</span></a></span><span> </span><span class="hs-special">{</span><span id="local-6989586621679540392"><span id="local-6989586621679540393"><span class="annot"><span class="annottext">DeviceType Int16
deActual :: DeviceType Int16
deExpected :: DeviceType Int16
deActual :: DeviceError -&gt; DeviceType Int16
deExpected :: DeviceError -&gt; DeviceType Int16
</span><a href="#local-6989586621679540392"><span class="hs-glyph hs-var hs-var hs-var hs-var">..</span></a></span></span></span><span class="hs-special">}</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-673"></span><span>    </span><span class="annot"><span class="annottext">String
</span><span class="hs-string">&quot;The tensor is not in the memory of the device `&quot;</span></span><span>
</span><span id="line-674"></span><span>      </span><span class="annot"><span class="annottext">String -&gt; ShowS
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">DeviceType Int16 -&gt; String
forall a. Show a =&gt; a -&gt; String
</span><span class="hs-identifier hs-var">show</span></span><span> </span><span class="annot"><span class="annottext">DeviceType Int16
</span><a href="#local-6989586621679540393"><span class="hs-identifier hs-var">deExpected</span></a></span><span>
</span><span id="line-675"></span><span>      </span><span class="annot"><span class="annottext">String -&gt; ShowS
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">String
</span><span class="hs-string">&quot;` but `&quot;</span></span><span>
</span><span id="line-676"></span><span>      </span><span class="annot"><span class="annottext">String -&gt; ShowS
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">DeviceType Int16 -&gt; String
forall a. Show a =&gt; a -&gt; String
</span><span class="hs-identifier hs-var">show</span></span><span> </span><span class="annot"><span class="annottext">DeviceType Int16
</span><a href="#local-6989586621679540392"><span class="hs-identifier hs-var">deActual</span></a></span><span>
</span><span id="line-677"></span><span>      </span><span class="annot"><span class="annottext">String -&gt; ShowS
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">String
</span><span class="hs-string">&quot;`.&quot;</span></span><span>
</span><span id="line-678"></span><span>
</span><span id="line-679"></span><span class="hs-comment">-- | Checks whether or not the input tensor is in the memory of 'device'</span><span>
</span><span id="line-680"></span><span class="hs-comment">-- and returns a statically annotated copy of it wrapped in a 'MonadThrow' 'm'.</span><span>
</span><span id="line-681"></span><span class="hs-comment">--</span><span>
</span><span id="line-682"></span><span class="hs-comment">-- For instance, if 'm' is 'Maybe', then the result will be wrapped in 'Just' if and only if the tensor is indeed on 'device'.</span><span>
</span><span id="line-683"></span><span class="hs-comment">-- If it is not, then the result will be 'Nothing'.</span><span>
</span><span id="line-684"></span><span class="hs-comment">--</span><span>
</span><span id="line-685"></span><span class="hs-comment">-- In the REPL, 'm' will default to 'IO':</span><span>
</span><span id="line-686"></span><span class="hs-comment">-- &gt;&gt;&gt; t = sOnes $ TensorSpec (SGradient SWithGradient) (SLayout SDense) (SUncheckedDevice CPU) (SDataType SFloat) (SShape $ SName @&quot;batch&quot; :&amp;: SSize @32 :|: SName @&quot;feature&quot; :&amp;: SSize @8 :|: SNil)</span><span>
</span><span id="line-687"></span><span class="hs-comment">-- &gt;&gt;&gt; t' &lt;- sCheckedDevice (SDevice SCPU) t</span><span>
</span><span id="line-688"></span><span class="hs-comment">-- &gt;&gt;&gt; :type t'</span><span>
</span><span id="line-689"></span><span class="hs-comment">-- t'</span><span>
</span><span id="line-690"></span><span class="hs-comment">--   :: Tensor</span><span>
</span><span id="line-691"></span><span class="hs-comment">--        ('Gradient 'WithGradient)</span><span>
</span><span id="line-692"></span><span class="hs-comment">--        ('Layout 'Dense)</span><span>
</span><span id="line-693"></span><span class="hs-comment">--        ('Device 'CPU)</span><span>
</span><span id="line-694"></span><span class="hs-comment">--        ('DataType 'Float)</span><span>
</span><span id="line-695"></span><span class="hs-comment">--        ('Shape</span><span>
</span><span id="line-696"></span><span class="hs-comment">--           '[ 'Dim ('Name &quot;batch&quot;) ('Size 32),</span><span>
</span><span id="line-697"></span><span class="hs-comment">--              'Dim ('Name &quot;feature&quot;) ('Size 8)])</span><span>
</span><span id="line-698"></span><span class="hs-comment">-- &gt;&gt;&gt; t' &lt;- sCheckedDevice (SDevice (SCUDA @0)) t</span><span>
</span><span id="line-699"></span><span class="hs-comment">-- *** Exception: DeviceError {deExpected = CUDA 0, deActual = CPU}</span><span>
</span><span id="line-700"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#sCheckedDevice"><span class="hs-identifier hs-type">sCheckedDevice</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-701"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679541445"><span class="annot"><a href="#local-6989586621679541445"><span class="hs-identifier hs-type">device'</span></a></span></span><span> </span><span id="local-6989586621679541446"><span class="annot"><a href="#local-6989586621679541446"><span class="hs-identifier hs-type">m</span></a></span></span><span> </span><span id="local-6989586621679541444"><span class="annot"><a href="#local-6989586621679541444"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679541443"><span class="annot"><a href="#local-6989586621679541443"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679541447"><span class="annot"><a href="#local-6989586621679541447"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679541442"><span class="annot"><a href="#local-6989586621679541442"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679541441"><span class="annot"><a href="#local-6989586621679541441"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-702"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetDevice"><span class="hs-identifier hs-type">SGetDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541447"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier hs-type">MonadThrow</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541446"><span class="hs-identifier hs-type">m</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-703"></span><span>  </span><span class="hs-comment">-- | device</span><span>
</span><span id="line-704"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#SDevice"><span class="hs-identifier hs-type">SDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541445"><span class="hs-identifier hs-type">device'</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-705"></span><span>  </span><span class="hs-comment">-- | input tensor</span><span>
</span><span id="line-706"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541444"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541443"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541447"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541442"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541441"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-707"></span><span>  </span><span class="hs-comment">-- | annotated output tensor wrapped in 'm'</span><span>
</span><span id="line-708"></span><span>  </span><span class="annot"><a href="#local-6989586621679541446"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541444"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541443"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Seq"><span class="hs-identifier hs-type">Seq</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679541447"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541445"><span class="hs-identifier hs-type">device'</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679541445"><span class="hs-identifier hs-type">device'</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679541442"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541441"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-709"></span><span id="sCheckedDevice"><span class="annot"><span class="annottext">sCheckedDevice :: SDevice device'
-&gt; Tensor gradient layout device dataType shape
-&gt; m (Tensor
        gradient layout (Seq (device &lt;+&gt; device') device') dataType shape)
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sCheckedDevice"><span class="hs-identifier hs-var hs-var">sCheckedDevice</span></a></span></span><span> </span><span id="local-6989586621679540390"><span class="annot"><span class="annottext">SDevice device'
</span><a href="#local-6989586621679540390"><span class="hs-identifier hs-var">device'</span></a></span></span><span> </span><span id="local-6989586621679540389"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679540389"><span class="hs-identifier hs-var">tensor</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-710"></span><span>  </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679540388"><span class="annot"><span class="annottext">actualDevice :: DeviceType Int16
</span><a href="#local-6989586621679540388"><span class="hs-identifier hs-var hs-var">actualDevice</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IsChecked (DeviceType Int16) -&gt; DeviceType Int16
forall a. IsChecked a -&gt; a
</span><a href="Torch.GraduallyTyped.Prelude.html#forgetIsChecked"><span class="hs-identifier hs-var">forgetIsChecked</span></a></span><span> </span><span class="annot"><span class="annottext">(IsChecked (DeviceType Int16) -&gt; DeviceType Int16)
-&gt; (SDevice device -&gt; IsChecked (DeviceType Int16))
-&gt; SDevice device
-&gt; DeviceType Int16
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">SDevice device -&gt; IsChecked (DeviceType Int16)
forall k (a :: k). SingKind k =&gt; Sing a -&gt; Demote k
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">fromSing</span></a></span><span> </span><span class="annot"><span class="annottext">(SDevice device -&gt; DeviceType Int16)
-&gt; SDevice device -&gt; DeviceType Int16
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape -&gt; SDevice device
forall (device :: Device (DeviceType Nat))
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SGetDevice device =&gt;
Tensor gradient layout device dataType shape -&gt; SDevice device
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sGetDevice"><span class="hs-identifier hs-var">sGetDevice</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679540389"><span class="hs-identifier hs-var">tensor</span></a></span><span>
</span><span id="line-711"></span><span>      </span><span id="local-6989586621679540387"><span class="annot"><span class="annottext">expectedDevice :: DeviceType Int16
</span><a href="#local-6989586621679540387"><span class="hs-identifier hs-var hs-var">expectedDevice</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IsChecked (DeviceType Int16) -&gt; DeviceType Int16
forall a. IsChecked a -&gt; a
</span><a href="Torch.GraduallyTyped.Prelude.html#forgetIsChecked"><span class="hs-identifier hs-var">forgetIsChecked</span></a></span><span> </span><span class="annot"><span class="annottext">(IsChecked (DeviceType Int16) -&gt; DeviceType Int16)
-&gt; (SDevice device' -&gt; IsChecked (DeviceType Int16))
-&gt; SDevice device'
-&gt; DeviceType Int16
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">SDevice device' -&gt; IsChecked (DeviceType Int16)
forall k (a :: k). SingKind k =&gt; Sing a -&gt; Demote k
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">fromSing</span></a></span><span> </span><span class="annot"><span class="annottext">(SDevice device' -&gt; DeviceType Int16)
-&gt; SDevice device' -&gt; DeviceType Int16
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SDevice device'
</span><a href="#local-6989586621679540390"><span class="hs-identifier hs-var">device'</span></a></span><span>
</span><span id="line-712"></span><span>   </span><span class="hs-keyword">in</span><span> </span><span class="hs-keyword">if</span><span> </span><span class="annot"><span class="annottext">DeviceType Int16
</span><a href="#local-6989586621679540388"><span class="hs-identifier hs-var">actualDevice</span></a></span><span> </span><span class="annot"><span class="annottext">DeviceType Int16 -&gt; DeviceType Int16 -&gt; Bool
forall a. Eq a =&gt; a -&gt; a -&gt; Bool
</span><span class="hs-operator hs-var">==</span></span><span> </span><span class="annot"><span class="annottext">DeviceType Int16
</span><a href="#local-6989586621679540387"><span class="hs-identifier hs-var">expectedDevice</span></a></span><span>
</span><span id="line-713"></span><span>        </span><span class="hs-keyword">then</span><span> </span><span class="annot"><span class="annottext">Tensor
  gradient
  layout
  (Seq (Unify (Device (DeviceType Nat)) device device') device')
  dataType
  shape
-&gt; m (Tensor
        gradient
        layout
        (Seq (Unify (Device (DeviceType Nat)) device device') device')
        dataType
        shape)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">(Tensor
   gradient
   layout
   (Seq (Unify (Device (DeviceType Nat)) device device') device')
   dataType
   shape
 -&gt; m (Tensor
         gradient
         layout
         (Seq (Unify (Device (DeviceType Nat)) device device') device')
         dataType
         shape))
-&gt; (Tensor gradient layout device dataType shape
    -&gt; Tensor
         gradient
         layout
         (Seq (Unify (Device (DeviceType Nat)) device device') device')
         dataType
         shape)
-&gt; Tensor gradient layout device dataType shape
-&gt; m (Tensor
        gradient
        layout
        (Seq (Unify (Device (DeviceType Nat)) device device') device')
        dataType
        shape)
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
-&gt; Tensor
     gradient
     layout
     (Seq (Unify (Device (DeviceType Nat)) device device') device')
     dataType
     shape
</span><span class="hs-identifier hs-var">coerce</span></span><span> </span><span class="annot"><span class="annottext">(Tensor gradient layout device dataType shape
 -&gt; m (Tensor
         gradient
         layout
         (Seq (Unify (Device (DeviceType Nat)) device device') device')
         dataType
         shape))
-&gt; Tensor gradient layout device dataType shape
-&gt; m (Tensor
        gradient
        layout
        (Seq (Unify (Device (DeviceType Nat)) device device') device')
        dataType
        shape)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679540389"><span class="hs-identifier hs-var">tensor</span></a></span><span>
</span><span id="line-714"></span><span>        </span><span class="hs-keyword">else</span><span> </span><span class="annot"><span class="annottext">DeviceError
-&gt; m (Tensor
        gradient
        layout
        (Seq (Unify (Device (DeviceType Nat)) device device') device')
        dataType
        shape)
forall (m :: * -&gt; *) e a. (MonadThrow m, Exception e) =&gt; e -&gt; m a
</span><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier hs-var">throwM</span></a></span><span> </span><span class="annot"><span class="annottext">(DeviceError
 -&gt; m (Tensor
         gradient
         layout
         (Seq (Unify (Device (DeviceType Nat)) device device') device')
         dataType
         shape))
-&gt; DeviceError
-&gt; m (Tensor
        gradient
        layout
        (Seq (Unify (Device (DeviceType Nat)) device device') device')
        dataType
        shape)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">DeviceType Int16 -&gt; DeviceType Int16 -&gt; DeviceError
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#DeviceError"><span class="hs-identifier hs-var">DeviceError</span></a></span><span> </span><span class="annot"><span class="annottext">DeviceType Int16
</span><a href="#local-6989586621679540387"><span class="hs-identifier hs-var">expectedDevice</span></a></span><span> </span><span class="annot"><span class="annottext">DeviceType Int16
</span><a href="#local-6989586621679540388"><span class="hs-identifier hs-var">actualDevice</span></a></span><span>
</span><span id="line-715"></span><span>
</span><span id="line-716"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#checkedDevice"><span class="hs-identifier hs-type">checkedDevice</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-717"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679540385"><span class="annot"><a href="#local-6989586621679540385"><span class="hs-identifier hs-type">device'</span></a></span></span><span> </span><span id="local-6989586621679540384"><span class="annot"><a href="#local-6989586621679540384"><span class="hs-identifier hs-type">m</span></a></span></span><span> </span><span id="local-6989586621679540383"><span class="annot"><a href="#local-6989586621679540383"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679540382"><span class="annot"><a href="#local-6989586621679540382"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679540381"><span class="annot"><a href="#local-6989586621679540381"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679540380"><span class="annot"><a href="#local-6989586621679540380"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679540379"><span class="annot"><a href="#local-6989586621679540379"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-718"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-type">SingI</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540385"><span class="hs-identifier hs-type">device'</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetDevice"><span class="hs-identifier hs-type">SGetDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540381"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier hs-type">MonadThrow</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540384"><span class="hs-identifier hs-type">m</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-719"></span><span>  </span><span class="hs-comment">-- | input tensor</span><span>
</span><span id="line-720"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540383"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540382"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540381"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540380"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540379"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-721"></span><span>  </span><span class="hs-comment">-- | annotated output tensor wrapped in 'm'</span><span>
</span><span id="line-722"></span><span>  </span><span class="annot"><a href="#local-6989586621679540384"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540383"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540382"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Seq"><span class="hs-identifier hs-type">Seq</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679540381"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540385"><span class="hs-identifier hs-type">device'</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679540385"><span class="hs-identifier hs-type">device'</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679540380"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540379"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-723"></span><span id="checkedDevice"><span class="annot"><span class="annottext">checkedDevice :: Tensor gradient layout device dataType shape
-&gt; m (Tensor
        gradient layout (Seq (device &lt;+&gt; device') device') dataType shape)
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#checkedDevice"><span class="hs-identifier hs-var hs-var">checkedDevice</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SDevice device'
-&gt; Tensor gradient layout device dataType shape
-&gt; m (Tensor
        gradient layout (Seq (device &lt;+&gt; device') device') dataType shape)
forall (device' :: Device (DeviceType Nat)) (m :: * -&gt; *)
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
(SGetDevice device, MonadThrow m) =&gt;
SDevice device'
-&gt; Tensor gradient layout device dataType shape
-&gt; m (Tensor
        gradient layout (Seq (device &lt;+&gt; device') device') dataType shape)
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sCheckedDevice"><span class="hs-identifier hs-var">sCheckedDevice</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SingI device' =&gt; Sing device'
forall k (a :: k). SingI a =&gt; Sing a
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">sing</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679540385"><span class="hs-identifier hs-type">device'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-724"></span><span>
</span><span id="line-725"></span><span class="hs-comment">-- | Returns the input tensor but with 'UncheckedDevice' as device type annotation.</span><span>
</span><span id="line-726"></span><span class="hs-comment">-- Any static information about the tensor's device is thus erased.</span><span>
</span><span id="line-727"></span><span class="hs-comment">-- However, the tensor's underlying data structure is not changed.</span><span>
</span><span id="line-728"></span><span class="hs-comment">--</span><span>
</span><span id="line-729"></span><span class="hs-comment">-- &gt;&gt;&gt; t = ones @('Gradient 'WithGradient) @('Layout 'Dense) @('Device 'CPU) @('DataType 'Float) @('Shape '[ 'Dim ('Name &quot;batch&quot;) ('Size 32), 'Dim ('Name &quot;feature&quot;) ('Size 8)])</span><span>
</span><span id="line-730"></span><span class="hs-comment">-- &gt;&gt;&gt; :type uncheckedDevice t</span><span>
</span><span id="line-731"></span><span class="hs-comment">-- uncheckedDevice t</span><span>
</span><span id="line-732"></span><span class="hs-comment">--   :: Tensor</span><span>
</span><span id="line-733"></span><span class="hs-comment">--        ('Gradient 'WithGradient)</span><span>
</span><span id="line-734"></span><span class="hs-comment">--        ('Layout 'Dense)</span><span>
</span><span id="line-735"></span><span class="hs-comment">--        'UncheckedDevice</span><span>
</span><span id="line-736"></span><span class="hs-comment">--        ('DataType 'Float)</span><span>
</span><span id="line-737"></span><span class="hs-comment">--        ('Shape</span><span>
</span><span id="line-738"></span><span class="hs-comment">--           '[ 'Dim ('Name &quot;batch&quot;) ('Size 32),</span><span>
</span><span id="line-739"></span><span class="hs-comment">--              'Dim ('Name &quot;feature&quot;) ('Size 8)])</span><span>
</span><span id="line-740"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#uncheckedDevice"><span class="hs-identifier hs-type">uncheckedDevice</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-741"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679540377"><span class="annot"><a href="#local-6989586621679540377"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679540376"><span class="annot"><a href="#local-6989586621679540376"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679540375"><span class="annot"><a href="#local-6989586621679540375"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679540374"><span class="annot"><a href="#local-6989586621679540374"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679540373"><span class="annot"><a href="#local-6989586621679540373"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-742"></span><span>  </span><span class="hs-comment">-- | input tensor</span><span>
</span><span id="line-743"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540377"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540376"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540375"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540374"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540373"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-744"></span><span>  </span><span class="hs-comment">-- | tensor without checked device</span><span>
</span><span id="line-745"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540377"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540376"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#UncheckedDevice"><span class="hs-identifier hs-type">UncheckedDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540374"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540373"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-746"></span><span id="uncheckedDevice"><span class="annot"><span class="annottext">uncheckedDevice :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout 'UncheckedDevice dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#uncheckedDevice"><span class="hs-identifier hs-var hs-var">uncheckedDevice</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout 'UncheckedDevice dataType shape
</span><span class="hs-identifier hs-var">coerce</span></span><span>
</span><span id="line-747"></span><span>
</span><span id="line-748"></span><span class="hs-comment">-- | Returns a copy of the tensor converted to 'Bool'.</span><span>
</span><span id="line-749"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#bool"><span class="hs-identifier hs-type">bool</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-750"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679540371"><span class="annot"><a href="#local-6989586621679540371"><span class="hs-identifier hs-type">m</span></a></span></span><span> </span><span id="local-6989586621679540370"><span class="annot"><a href="#local-6989586621679540370"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679540369"><span class="annot"><a href="#local-6989586621679540369"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679540368"><span class="annot"><a href="#local-6989586621679540368"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679540367"><span class="annot"><a href="#local-6989586621679540367"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679540366"><span class="annot"><a href="#local-6989586621679540366"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-751"></span><span>  </span><span class="annot"><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier hs-type">MonadThrow</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540371"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-752"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-753"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540370"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540369"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540368"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540367"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540366"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-754"></span><span>  </span><span class="hs-comment">-- | 'Bool' copy</span><span>
</span><span id="line-755"></span><span>  </span><span class="annot"><a href="#local-6989586621679540371"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#WithoutGradient"><span class="hs-identifier hs-type">WithoutGradient</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679540369"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540368"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#Bool"><span class="hs-identifier hs-type">Bool</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679540366"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-756"></span><span id="bool"><span class="annot"><span class="annottext">bool :: Tensor gradient layout device dataType shape
-&gt; m (Tensor
        ('Gradient 'WithoutGradient) layout device ('DataType 'Bool) shape)
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#bool"><span class="hs-identifier hs-var hs-var">bool</span></a></span></span><span> </span><span id="local-6989586621679540365"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679540365"><span class="hs-identifier hs-var">tensor</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO
  (Tensor
     ('Gradient 'WithoutGradient) layout device ('DataType 'Bool) shape)
-&gt; m (Tensor
        ('Gradient 'WithoutGradient) layout device ('DataType 'Bool) shape)
forall a (m :: * -&gt; *). MonadThrow m =&gt; IO a -&gt; m a
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">unsafeThrowableIO</span></a></span><span> </span><span class="annot"><span class="annottext">(IO
   (Tensor
      ('Gradient 'WithoutGradient) layout device ('DataType 'Bool) shape)
 -&gt; m (Tensor
         ('Gradient 'WithoutGradient)
         layout
         device
         ('DataType 'Bool)
         shape))
-&gt; IO
     (Tensor
        ('Gradient 'WithoutGradient) layout device ('DataType 'Bool) shape)
-&gt; m (Tensor
        ('Gradient 'WithoutGradient) layout device ('DataType 'Bool) shape)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ScalarType -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; DType
-&gt; IO
     (Tensor
        ('Gradient 'WithoutGradient) layout device ('DataType 'Bool) shape)
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ScalarType -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.tensor_toType_s</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679540365"><span class="hs-identifier hs-var">tensor</span></a></span><span> </span><span class="annot"><span class="annottext">DType
</span><a href="Torch.GraduallyTyped.DType.html#Bool"><span class="hs-identifier hs-var">Bool</span></a></span><span>
</span><span id="line-757"></span><span>
</span><span id="line-758"></span><span class="hs-comment">-- | Returns a copy of the tensor converted to 'UInt8'.</span><span>
</span><span id="line-759"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#byte"><span class="hs-identifier hs-type">byte</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-760"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679540362"><span class="annot"><a href="#local-6989586621679540362"><span class="hs-identifier hs-type">m</span></a></span></span><span> </span><span id="local-6989586621679540361"><span class="annot"><a href="#local-6989586621679540361"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679540360"><span class="annot"><a href="#local-6989586621679540360"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679540359"><span class="annot"><a href="#local-6989586621679540359"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679540358"><span class="annot"><a href="#local-6989586621679540358"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679540357"><span class="annot"><a href="#local-6989586621679540357"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-761"></span><span>  </span><span class="annot"><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier hs-type">MonadThrow</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540362"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-762"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-763"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540361"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540360"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540359"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540358"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540357"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-764"></span><span>  </span><span class="hs-comment">-- | 'UInt8' copy</span><span>
</span><span id="line-765"></span><span>  </span><span class="annot"><a href="#local-6989586621679540362"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#WithoutGradient"><span class="hs-identifier hs-type">WithoutGradient</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679540360"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540359"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#UInt8"><span class="hs-identifier hs-type">UInt8</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679540357"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-766"></span><span id="byte"><span class="annot"><span class="annottext">byte :: Tensor gradient layout device dataType shape
-&gt; m (Tensor
        ('Gradient 'WithoutGradient)
        layout
        device
        ('DataType 'UInt8)
        shape)
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#byte"><span class="hs-identifier hs-var hs-var">byte</span></a></span></span><span> </span><span id="local-6989586621679540356"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679540356"><span class="hs-identifier hs-var">tensor</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO
  (Tensor
     ('Gradient 'WithoutGradient)
     layout
     device
     ('DataType 'UInt8)
     shape)
-&gt; m (Tensor
        ('Gradient 'WithoutGradient)
        layout
        device
        ('DataType 'UInt8)
        shape)
forall a (m :: * -&gt; *). MonadThrow m =&gt; IO a -&gt; m a
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">unsafeThrowableIO</span></a></span><span> </span><span class="annot"><span class="annottext">(IO
   (Tensor
      ('Gradient 'WithoutGradient)
      layout
      device
      ('DataType 'UInt8)
      shape)
 -&gt; m (Tensor
         ('Gradient 'WithoutGradient)
         layout
         device
         ('DataType 'UInt8)
         shape))
-&gt; IO
     (Tensor
        ('Gradient 'WithoutGradient)
        layout
        device
        ('DataType 'UInt8)
        shape)
-&gt; m (Tensor
        ('Gradient 'WithoutGradient)
        layout
        device
        ('DataType 'UInt8)
        shape)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ScalarType -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; DType
-&gt; IO
     (Tensor
        ('Gradient 'WithoutGradient)
        layout
        device
        ('DataType 'UInt8)
        shape)
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ScalarType -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.tensor_toType_s</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679540356"><span class="hs-identifier hs-var">tensor</span></a></span><span> </span><span class="annot"><span class="annottext">DType
</span><a href="Torch.GraduallyTyped.DType.html#UInt8"><span class="hs-identifier hs-var">UInt8</span></a></span><span>
</span><span id="line-767"></span><span>
</span><span id="line-768"></span><span class="hs-comment">-- | Returns a copy of the tensor converted to 'Int8'.</span><span>
</span><span id="line-769"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#char"><span class="hs-identifier hs-type">char</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-770"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679540354"><span class="annot"><a href="#local-6989586621679540354"><span class="hs-identifier hs-type">m</span></a></span></span><span> </span><span id="local-6989586621679540353"><span class="annot"><a href="#local-6989586621679540353"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679540352"><span class="annot"><a href="#local-6989586621679540352"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679540351"><span class="annot"><a href="#local-6989586621679540351"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679540350"><span class="annot"><a href="#local-6989586621679540350"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679540349"><span class="annot"><a href="#local-6989586621679540349"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-771"></span><span>  </span><span class="annot"><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier hs-type">MonadThrow</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540354"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-772"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-773"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540353"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540352"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540351"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540350"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540349"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-774"></span><span>  </span><span class="hs-comment">-- | 'Int8' copy</span><span>
</span><span id="line-775"></span><span>  </span><span class="annot"><a href="#local-6989586621679540354"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#WithoutGradient"><span class="hs-identifier hs-type">WithoutGradient</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679540352"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540351"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#Int8"><span class="hs-identifier hs-type">Int8</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679540349"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-776"></span><span id="char"><span class="annot"><span class="annottext">char :: Tensor gradient layout device dataType shape
-&gt; m (Tensor
        ('Gradient 'WithoutGradient) layout device ('DataType 'Int8) shape)
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#char"><span class="hs-identifier hs-var hs-var">char</span></a></span></span><span> </span><span id="local-6989586621679540348"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679540348"><span class="hs-identifier hs-var">tensor</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO
  (Tensor
     ('Gradient 'WithoutGradient) layout device ('DataType 'Int8) shape)
-&gt; m (Tensor
        ('Gradient 'WithoutGradient) layout device ('DataType 'Int8) shape)
forall a (m :: * -&gt; *). MonadThrow m =&gt; IO a -&gt; m a
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">unsafeThrowableIO</span></a></span><span> </span><span class="annot"><span class="annottext">(IO
   (Tensor
      ('Gradient 'WithoutGradient) layout device ('DataType 'Int8) shape)
 -&gt; m (Tensor
         ('Gradient 'WithoutGradient)
         layout
         device
         ('DataType 'Int8)
         shape))
-&gt; IO
     (Tensor
        ('Gradient 'WithoutGradient) layout device ('DataType 'Int8) shape)
-&gt; m (Tensor
        ('Gradient 'WithoutGradient) layout device ('DataType 'Int8) shape)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ScalarType -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; DType
-&gt; IO
     (Tensor
        ('Gradient 'WithoutGradient) layout device ('DataType 'Int8) shape)
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ScalarType -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.tensor_toType_s</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679540348"><span class="hs-identifier hs-var">tensor</span></a></span><span> </span><span class="annot"><span class="annottext">DType
</span><a href="Torch.GraduallyTyped.DType.html#Int8"><span class="hs-identifier hs-var">Int8</span></a></span><span>
</span><span id="line-777"></span><span>
</span><span id="line-778"></span><span class="hs-comment">-- | Returns a copy of the tensor converted to 'Int16'.</span><span>
</span><span id="line-779"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#short"><span class="hs-identifier hs-type">short</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-780"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679540346"><span class="annot"><a href="#local-6989586621679540346"><span class="hs-identifier hs-type">m</span></a></span></span><span> </span><span id="local-6989586621679540345"><span class="annot"><a href="#local-6989586621679540345"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679540344"><span class="annot"><a href="#local-6989586621679540344"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679540343"><span class="annot"><a href="#local-6989586621679540343"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679540342"><span class="annot"><a href="#local-6989586621679540342"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679540341"><span class="annot"><a href="#local-6989586621679540341"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-781"></span><span>  </span><span class="annot"><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier hs-type">MonadThrow</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540346"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-782"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-783"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540345"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540344"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540343"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540342"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540341"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-784"></span><span>  </span><span class="hs-comment">-- | 'Int16' copy</span><span>
</span><span id="line-785"></span><span>  </span><span class="annot"><a href="#local-6989586621679540346"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#WithoutGradient"><span class="hs-identifier hs-type">WithoutGradient</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679540344"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540343"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#Int16"><span class="hs-identifier hs-type">Int16</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679540341"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-786"></span><span id="short"><span class="annot"><span class="annottext">short :: Tensor gradient layout device dataType shape
-&gt; m (Tensor
        ('Gradient 'WithoutGradient)
        layout
        device
        ('DataType 'Int16)
        shape)
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#short"><span class="hs-identifier hs-var hs-var">short</span></a></span></span><span> </span><span id="local-6989586621679540340"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679540340"><span class="hs-identifier hs-var">tensor</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO
  (Tensor
     ('Gradient 'WithoutGradient)
     layout
     device
     ('DataType 'Int16)
     shape)
-&gt; m (Tensor
        ('Gradient 'WithoutGradient)
        layout
        device
        ('DataType 'Int16)
        shape)
forall a (m :: * -&gt; *). MonadThrow m =&gt; IO a -&gt; m a
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">unsafeThrowableIO</span></a></span><span> </span><span class="annot"><span class="annottext">(IO
   (Tensor
      ('Gradient 'WithoutGradient)
      layout
      device
      ('DataType 'Int16)
      shape)
 -&gt; m (Tensor
         ('Gradient 'WithoutGradient)
         layout
         device
         ('DataType 'Int16)
         shape))
-&gt; IO
     (Tensor
        ('Gradient 'WithoutGradient)
        layout
        device
        ('DataType 'Int16)
        shape)
-&gt; m (Tensor
        ('Gradient 'WithoutGradient)
        layout
        device
        ('DataType 'Int16)
        shape)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ScalarType -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; DType
-&gt; IO
     (Tensor
        ('Gradient 'WithoutGradient)
        layout
        device
        ('DataType 'Int16)
        shape)
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ScalarType -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.tensor_toType_s</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679540340"><span class="hs-identifier hs-var">tensor</span></a></span><span> </span><span class="annot"><span class="annottext">DType
</span><a href="Torch.GraduallyTyped.DType.html#Int16"><span class="hs-identifier hs-var">Int16</span></a></span><span>
</span><span id="line-787"></span><span>
</span><span id="line-788"></span><span class="hs-comment">-- | Returns a copy of the tensor converted to 'Int32'.</span><span>
</span><span id="line-789"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#int"><span class="hs-identifier hs-type">int</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-790"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679540338"><span class="annot"><a href="#local-6989586621679540338"><span class="hs-identifier hs-type">m</span></a></span></span><span> </span><span id="local-6989586621679540337"><span class="annot"><a href="#local-6989586621679540337"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679540336"><span class="annot"><a href="#local-6989586621679540336"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679540335"><span class="annot"><a href="#local-6989586621679540335"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679540334"><span class="annot"><a href="#local-6989586621679540334"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679540333"><span class="annot"><a href="#local-6989586621679540333"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-791"></span><span>  </span><span class="annot"><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier hs-type">MonadThrow</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540338"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-792"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-793"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540337"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540336"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540335"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540334"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540333"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-794"></span><span>  </span><span class="hs-comment">-- | 'Int32' copy</span><span>
</span><span id="line-795"></span><span>  </span><span class="annot"><a href="#local-6989586621679540338"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#WithoutGradient"><span class="hs-identifier hs-type">WithoutGradient</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679540336"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540335"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#Int32"><span class="hs-identifier hs-type">Int32</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679540333"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-796"></span><span id="int"><span class="annot"><span class="annottext">int :: Tensor gradient layout device dataType shape
-&gt; m (Tensor
        ('Gradient 'WithoutGradient)
        layout
        device
        ('DataType 'Int32)
        shape)
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#int"><span class="hs-identifier hs-var hs-var">int</span></a></span></span><span> </span><span id="local-6989586621679540332"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679540332"><span class="hs-identifier hs-var">tensor</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO
  (Tensor
     ('Gradient 'WithoutGradient)
     layout
     device
     ('DataType 'Int32)
     shape)
-&gt; m (Tensor
        ('Gradient 'WithoutGradient)
        layout
        device
        ('DataType 'Int32)
        shape)
forall a (m :: * -&gt; *). MonadThrow m =&gt; IO a -&gt; m a
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">unsafeThrowableIO</span></a></span><span> </span><span class="annot"><span class="annottext">(IO
   (Tensor
      ('Gradient 'WithoutGradient)
      layout
      device
      ('DataType 'Int32)
      shape)
 -&gt; m (Tensor
         ('Gradient 'WithoutGradient)
         layout
         device
         ('DataType 'Int32)
         shape))
-&gt; IO
     (Tensor
        ('Gradient 'WithoutGradient)
        layout
        device
        ('DataType 'Int32)
        shape)
-&gt; m (Tensor
        ('Gradient 'WithoutGradient)
        layout
        device
        ('DataType 'Int32)
        shape)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ScalarType -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; DType
-&gt; IO
     (Tensor
        ('Gradient 'WithoutGradient)
        layout
        device
        ('DataType 'Int32)
        shape)
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ScalarType -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.tensor_toType_s</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679540332"><span class="hs-identifier hs-var">tensor</span></a></span><span> </span><span class="annot"><span class="annottext">DType
</span><a href="Torch.GraduallyTyped.DType.html#Int32"><span class="hs-identifier hs-var">Int32</span></a></span><span>
</span><span id="line-797"></span><span>
</span><span id="line-798"></span><span class="hs-comment">-- | Returns a copy of the tensor converted to 'Int64'.</span><span>
</span><span id="line-799"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#long"><span class="hs-identifier hs-type">long</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-800"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679540330"><span class="annot"><a href="#local-6989586621679540330"><span class="hs-identifier hs-type">m</span></a></span></span><span> </span><span id="local-6989586621679540329"><span class="annot"><a href="#local-6989586621679540329"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679540328"><span class="annot"><a href="#local-6989586621679540328"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679540327"><span class="annot"><a href="#local-6989586621679540327"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679540326"><span class="annot"><a href="#local-6989586621679540326"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679540325"><span class="annot"><a href="#local-6989586621679540325"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-801"></span><span>  </span><span class="annot"><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier hs-type">MonadThrow</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540330"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-802"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-803"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540329"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540328"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540327"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540326"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540325"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-804"></span><span>  </span><span class="hs-comment">-- | 'Int64' copy</span><span>
</span><span id="line-805"></span><span>  </span><span class="annot"><a href="#local-6989586621679540330"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#WithoutGradient"><span class="hs-identifier hs-type">WithoutGradient</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679540328"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540327"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#Int64"><span class="hs-identifier hs-type">Int64</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679540325"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-806"></span><span id="long"><span class="annot"><span class="annottext">long :: Tensor gradient layout device dataType shape
-&gt; m (Tensor
        ('Gradient 'WithoutGradient)
        layout
        device
        ('DataType 'Int64)
        shape)
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#long"><span class="hs-identifier hs-var hs-var">long</span></a></span></span><span> </span><span id="local-6989586621679540324"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679540324"><span class="hs-identifier hs-var">tensor</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO
  (Tensor
     ('Gradient 'WithoutGradient)
     layout
     device
     ('DataType 'Int64)
     shape)
-&gt; m (Tensor
        ('Gradient 'WithoutGradient)
        layout
        device
        ('DataType 'Int64)
        shape)
forall a (m :: * -&gt; *). MonadThrow m =&gt; IO a -&gt; m a
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">unsafeThrowableIO</span></a></span><span> </span><span class="annot"><span class="annottext">(IO
   (Tensor
      ('Gradient 'WithoutGradient)
      layout
      device
      ('DataType 'Int64)
      shape)
 -&gt; m (Tensor
         ('Gradient 'WithoutGradient)
         layout
         device
         ('DataType 'Int64)
         shape))
-&gt; IO
     (Tensor
        ('Gradient 'WithoutGradient)
        layout
        device
        ('DataType 'Int64)
        shape)
-&gt; m (Tensor
        ('Gradient 'WithoutGradient)
        layout
        device
        ('DataType 'Int64)
        shape)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ScalarType -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; DType
-&gt; IO
     (Tensor
        ('Gradient 'WithoutGradient)
        layout
        device
        ('DataType 'Int64)
        shape)
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ScalarType -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.tensor_toType_s</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679540324"><span class="hs-identifier hs-var">tensor</span></a></span><span> </span><span class="annot"><span class="annottext">DType
</span><a href="Torch.GraduallyTyped.DType.html#Int64"><span class="hs-identifier hs-var">Int64</span></a></span><span>
</span><span id="line-807"></span><span>
</span><span id="line-808"></span><span class="hs-comment">-- | Returns a copy of the tensor converted to the 16-bit floating point format 'Half'.</span><span>
</span><span id="line-809"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#half"><span class="hs-identifier hs-type">half</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-810"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679540322"><span class="annot"><a href="#local-6989586621679540322"><span class="hs-identifier hs-type">m</span></a></span></span><span> </span><span id="local-6989586621679540321"><span class="annot"><a href="#local-6989586621679540321"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679540320"><span class="annot"><a href="#local-6989586621679540320"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679540319"><span class="annot"><a href="#local-6989586621679540319"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679540318"><span class="annot"><a href="#local-6989586621679540318"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679540317"><span class="annot"><a href="#local-6989586621679540317"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-811"></span><span>  </span><span class="annot"><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier hs-type">MonadThrow</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540322"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-812"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-813"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540321"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540320"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540319"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540318"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540317"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-814"></span><span>  </span><span class="hs-comment">-- | 'Half' copy</span><span>
</span><span id="line-815"></span><span>  </span><span class="annot"><a href="#local-6989586621679540322"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540321"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540320"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540319"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#Half"><span class="hs-identifier hs-type">Half</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679540317"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-816"></span><span id="half"><span class="annot"><span class="annottext">half :: Tensor gradient layout device dataType shape
-&gt; m (Tensor gradient layout device ('DataType 'Half) shape)
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#half"><span class="hs-identifier hs-var hs-var">half</span></a></span></span><span> </span><span id="local-6989586621679540316"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679540316"><span class="hs-identifier hs-var">tensor</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device ('DataType 'Half) shape)
-&gt; m (Tensor gradient layout device ('DataType 'Half) shape)
forall a (m :: * -&gt; *). MonadThrow m =&gt; IO a -&gt; m a
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">unsafeThrowableIO</span></a></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device ('DataType 'Half) shape)
 -&gt; m (Tensor gradient layout device ('DataType 'Half) shape))
-&gt; IO (Tensor gradient layout device ('DataType 'Half) shape)
-&gt; m (Tensor gradient layout device ('DataType 'Half) shape)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ScalarType -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; DType
-&gt; IO (Tensor gradient layout device ('DataType 'Half) shape)
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ScalarType -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.tensor_toType_s</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679540316"><span class="hs-identifier hs-var">tensor</span></a></span><span> </span><span class="annot"><span class="annottext">DType
</span><a href="Torch.GraduallyTyped.DType.html#Half"><span class="hs-identifier hs-var">Half</span></a></span><span>
</span><span id="line-817"></span><span>
</span><span id="line-818"></span><span class="hs-comment">-- | Returns a copy of the tensor converted to the 32-bit floating point format 'Float'.</span><span>
</span><span id="line-819"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#float"><span class="hs-identifier hs-type">float</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-820"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679540314"><span class="annot"><a href="#local-6989586621679540314"><span class="hs-identifier hs-type">m</span></a></span></span><span> </span><span id="local-6989586621679540313"><span class="annot"><a href="#local-6989586621679540313"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679540312"><span class="annot"><a href="#local-6989586621679540312"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679540311"><span class="annot"><a href="#local-6989586621679540311"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679540310"><span class="annot"><a href="#local-6989586621679540310"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679540309"><span class="annot"><a href="#local-6989586621679540309"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-821"></span><span>  </span><span class="annot"><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier hs-type">MonadThrow</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540314"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-822"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-823"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540313"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540312"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540311"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540310"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540309"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-824"></span><span>  </span><span class="hs-comment">-- | 'Float' copy</span><span>
</span><span id="line-825"></span><span>  </span><span class="annot"><a href="#local-6989586621679540314"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540313"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540312"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540311"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#Float"><span class="hs-identifier hs-type">Float</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679540309"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-826"></span><span id="float"><span class="annot"><span class="annottext">float :: Tensor gradient layout device dataType shape
-&gt; m (Tensor gradient layout device ('DataType 'Float) shape)
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#float"><span class="hs-identifier hs-var hs-var">float</span></a></span></span><span> </span><span id="local-6989586621679540308"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679540308"><span class="hs-identifier hs-var">tensor</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device ('DataType 'Float) shape)
-&gt; m (Tensor gradient layout device ('DataType 'Float) shape)
forall a (m :: * -&gt; *). MonadThrow m =&gt; IO a -&gt; m a
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">unsafeThrowableIO</span></a></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device ('DataType 'Float) shape)
 -&gt; m (Tensor gradient layout device ('DataType 'Float) shape))
-&gt; IO (Tensor gradient layout device ('DataType 'Float) shape)
-&gt; m (Tensor gradient layout device ('DataType 'Float) shape)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ScalarType -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; DType
-&gt; IO (Tensor gradient layout device ('DataType 'Float) shape)
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ScalarType -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.tensor_toType_s</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679540308"><span class="hs-identifier hs-var">tensor</span></a></span><span> </span><span class="annot"><span class="annottext">DType
</span><a href="Torch.GraduallyTyped.DType.html#Float"><span class="hs-identifier hs-var">Float</span></a></span><span>
</span><span id="line-827"></span><span>
</span><span id="line-828"></span><span class="hs-comment">-- | Returns a copy of the tensor converted to the 32-bit floating point format 'Double'.</span><span>
</span><span id="line-829"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#double"><span class="hs-identifier hs-type">double</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-830"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679540306"><span class="annot"><a href="#local-6989586621679540306"><span class="hs-identifier hs-type">m</span></a></span></span><span> </span><span id="local-6989586621679540305"><span class="annot"><a href="#local-6989586621679540305"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679540304"><span class="annot"><a href="#local-6989586621679540304"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679540303"><span class="annot"><a href="#local-6989586621679540303"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679540302"><span class="annot"><a href="#local-6989586621679540302"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679540301"><span class="annot"><a href="#local-6989586621679540301"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-831"></span><span>  </span><span class="annot"><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier hs-type">MonadThrow</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540306"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-832"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-833"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540305"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540304"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540303"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540302"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540301"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-834"></span><span>  </span><span class="hs-comment">-- | 'Double' copy</span><span>
</span><span id="line-835"></span><span>  </span><span class="annot"><a href="#local-6989586621679540306"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540305"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540304"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540303"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#Double"><span class="hs-identifier hs-type">Double</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679540301"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-836"></span><span id="double"><span class="annot"><span class="annottext">double :: Tensor gradient layout device dataType shape
-&gt; m (Tensor gradient layout device ('DataType 'Double) shape)
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#double"><span class="hs-identifier hs-var hs-var">double</span></a></span></span><span> </span><span id="local-6989586621679540300"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679540300"><span class="hs-identifier hs-var">tensor</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device ('DataType 'Double) shape)
-&gt; m (Tensor gradient layout device ('DataType 'Double) shape)
forall a (m :: * -&gt; *). MonadThrow m =&gt; IO a -&gt; m a
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">unsafeThrowableIO</span></a></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device ('DataType 'Double) shape)
 -&gt; m (Tensor gradient layout device ('DataType 'Double) shape))
-&gt; IO (Tensor gradient layout device ('DataType 'Double) shape)
-&gt; m (Tensor gradient layout device ('DataType 'Double) shape)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ScalarType -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; DType
-&gt; IO (Tensor gradient layout device ('DataType 'Double) shape)
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ScalarType -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.tensor_toType_s</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679540300"><span class="hs-identifier hs-var">tensor</span></a></span><span> </span><span class="annot"><span class="annottext">DType
</span><a href="Torch.GraduallyTyped.DType.html#Double"><span class="hs-identifier hs-var">Double</span></a></span><span>
</span><span id="line-837"></span><span>
</span><span id="line-838"></span><span class="hs-comment">-- | Set the data type of a tensor to the specified data type.</span><span>
</span><span id="line-839"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#sSetDataType"><span class="hs-identifier hs-type">sSetDataType</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-840"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679540298"><span class="annot"><a href="#local-6989586621679540298"><span class="hs-identifier hs-type">m</span></a></span></span><span> </span><span id="local-6989586621679540297"><span class="annot"><a href="#local-6989586621679540297"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679540296"><span class="annot"><a href="#local-6989586621679540296"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679540295"><span class="annot"><a href="#local-6989586621679540295"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679540294"><span class="annot"><a href="#local-6989586621679540294"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679540293"><span class="annot"><a href="#local-6989586621679540293"><span class="hs-identifier hs-type">dataType'</span></a></span></span><span> </span><span id="local-6989586621679540292"><span class="annot"><a href="#local-6989586621679540292"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-841"></span><span>  </span><span class="annot"><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier hs-type">MonadThrow</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540298"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-842"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier hs-type">SDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540294"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-843"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540297"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540296"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540295"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540293"><span class="hs-identifier hs-type">dataType'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540292"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-844"></span><span>  </span><span class="annot"><a href="#local-6989586621679540298"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540297"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540296"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540295"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540294"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540292"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-845"></span><span id="sSetDataType"><span class="annot"><span class="annottext">sSetDataType :: SDataType dataType
-&gt; Tensor gradient layout device dataType' shape
-&gt; m (Tensor gradient layout device dataType shape)
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sSetDataType"><span class="hs-identifier hs-var hs-var">sSetDataType</span></a></span></span><span> </span><span id="local-6989586621679540291"><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679540291"><span class="hs-identifier hs-var">dataType</span></a></span></span><span> </span><span id="local-6989586621679540290"><span class="annot"><span class="annottext">Tensor gradient layout device dataType' shape
</span><a href="#local-6989586621679540290"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-846"></span><span>  </span><span class="hs-keyword">case</span><span> </span><span class="annot"><span class="annottext">IsChecked DType -&gt; DType
forall a. IsChecked a -&gt; a
</span><a href="Torch.GraduallyTyped.Prelude.html#forgetIsChecked"><span class="hs-identifier hs-var">forgetIsChecked</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Sing dataType -&gt; Demote (DataType DType)
forall k (a :: k). SingKind k =&gt; Sing a -&gt; Demote k
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">fromSing</span></a></span><span> </span><span class="annot"><span class="annottext">Sing dataType
SDataType dataType
</span><a href="#local-6989586621679540291"><span class="hs-identifier hs-var">dataType</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-keyword">of</span><span>
</span><span id="line-847"></span><span>    </span><span id="local-6989586621679540289"><span class="annot"><span class="annottext">DType
</span><a href="#local-6989586621679540289"><span class="hs-identifier hs-var">dType</span></a></span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; m (Tensor gradient layout device dataType shape)
forall a (m :: * -&gt; *). MonadThrow m =&gt; IO a -&gt; m a
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">unsafeThrowableIO</span></a></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; m (Tensor gradient layout device dataType shape))
-&gt; IO (Tensor gradient layout device dataType shape)
-&gt; m (Tensor gradient layout device dataType shape)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-848"></span><span>      </span><span id="local-6989586621679540288"><span class="annot"><span class="annottext">ForeignPtr TensorOptions
</span><a href="#local-6989586621679540288"><span class="hs-identifier hs-var">opts</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">ForeignPtr</span></span><span> </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-type">ATen.TensorOptions</span></a></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr TensorOptions))
-&gt; Tensor gradient layout device dataType' shape
-&gt; IO (ForeignPtr TensorOptions)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr TensorOptions)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.tensor_options</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType' shape
</span><a href="#local-6989586621679540290"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-849"></span><span>      </span><span id="local-6989586621679540287"><span class="annot"><span class="annottext">ForeignPtr TensorOptions
</span><a href="#local-6989586621679540287"><span class="hs-identifier hs-var">opts'</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">ForeignPtr</span></span><span> </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-type">ATen.TensorOptions</span></a></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">(ForeignPtr TensorOptions
 -&gt; ScalarType -&gt; IO (ForeignPtr TensorOptions))
-&gt; ForeignPtr TensorOptions
-&gt; DType
-&gt; IO (ForeignPtr TensorOptions)
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr TensorOptions
-&gt; ScalarType -&gt; IO (ForeignPtr TensorOptions)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.tensorOptions_dtype_s</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr TensorOptions
</span><a href="#local-6989586621679540288"><span class="hs-identifier hs-var">opts</span></a></span><span> </span><span class="annot"><span class="annottext">DType
</span><a href="#local-6989586621679540289"><span class="hs-identifier hs-var">dType</span></a></span><span>
</span><span id="line-850"></span><span>      </span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr TensorOptions
 -&gt; CBool
 -&gt; CBool
 -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType' shape
-&gt; ForeignPtr TensorOptions
-&gt; Bool
-&gt; Bool
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca x1 cx1 x2 cx2 x3 cx3 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable x3 cx3,
 Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; cx3 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; x2 -&gt; x3 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast4</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; ForeignPtr TensorOptions
-&gt; CBool
-&gt; CBool
-&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.tensor_to_obb</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType' shape
</span><a href="#local-6989586621679540290"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr TensorOptions
</span><a href="#local-6989586621679540287"><span class="hs-identifier hs-var">opts'</span></a></span><span> </span><span class="annot"><span class="annottext">Bool
</span><a href="#local-6989586621679540285"><span class="hs-identifier hs-var">nonBlocking</span></a></span><span> </span><span class="annot"><span class="annottext">Bool
</span><a href="#local-6989586621679540284"><span class="hs-identifier hs-var">copy</span></a></span><span>
</span><span id="line-851"></span><span>      </span><span class="hs-keyword">where</span><span>
</span><span id="line-852"></span><span>        </span><span id="local-6989586621679540285"><span class="annot"><span class="annottext">nonBlocking :: Bool
</span><a href="#local-6989586621679540285"><span class="hs-identifier hs-var hs-var">nonBlocking</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Bool
</span><span class="hs-identifier hs-var">False</span></span><span>
</span><span id="line-853"></span><span>        </span><span id="local-6989586621679540284"><span class="annot"><span class="annottext">copy :: Bool
</span><a href="#local-6989586621679540284"><span class="hs-identifier hs-var hs-var">copy</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Bool
</span><span class="hs-identifier hs-var">False</span></span><span>
</span><span id="line-854"></span><span>
</span><span id="line-855"></span><span class="hs-keyword">class</span><span> </span><span id="SGetDataType"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetDataType"><span class="hs-identifier hs-var">SGetDataType</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679541360"><span class="annot"><a href="#local-6989586621679541360"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier hs-type">DType</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-856"></span><span>  </span><span class="hs-comment">-- | Returns the gradually typed compute data type of the input tensor.</span><span>
</span><span id="line-857"></span><span>  </span><span class="hs-comment">--</span><span>
</span><span id="line-858"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; sOnes' dataType = sOnes $ TensorSpec (SGradient SWithGradient) (SLayout SDense) (SDevice SCPU) dataType (SShape $ SName @&quot;batch&quot; :&amp;: SSize @32 :|: SName @&quot;feature&quot; :&amp;: SSize @8 :|: SNil)</span><span>
</span><span id="line-859"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; t = sOnes' $ SDataType SFloat</span><span>
</span><span id="line-860"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; sGetDataType t</span><span>
</span><span id="line-861"></span><span>  </span><span class="hs-comment">-- SDataType SFloat</span><span>
</span><span id="line-862"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; t = sOnes' $ SUncheckedDataType Float</span><span>
</span><span id="line-863"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; sGetDataType t</span><span>
</span><span id="line-864"></span><span>  </span><span class="hs-comment">-- SUncheckedDataType Float</span><span>
</span><span id="line-865"></span><span>  </span><span id="sGetDataType"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#sGetDataType"><span class="hs-identifier hs-type">sGetDataType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-866"></span><span>    </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679541357"><span class="annot"><a href="#local-6989586621679541357"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679541356"><span class="annot"><a href="#local-6989586621679541356"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679541355"><span class="annot"><a href="#local-6989586621679541355"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679541354"><span class="annot"><a href="#local-6989586621679541354"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-867"></span><span>    </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-868"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541357"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541356"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541355"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541360"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541354"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-869"></span><span>    </span><span class="hs-comment">-- | data type of the input tensor</span><span>
</span><span id="line-870"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier hs-type">SDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541360"><span class="hs-identifier hs-type">dataType</span></a></span><span>
</span><span id="line-871"></span><span>
</span><span id="line-872"></span><span>  </span><span class="hs-comment">-- | Returns the untyped compute data type of the input tensor.</span><span>
</span><span id="line-873"></span><span>  </span><span class="hs-comment">--</span><span>
</span><span id="line-874"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; sOnes' dataType = sOnes $ TensorSpec (SGradient SWithGradient) (SLayout SDense) (SDevice SCPU) dataType (SShape $ SName @&quot;batch&quot; :&amp;: SSize @32 :|: SName @&quot;feature&quot; :&amp;: SSize @8 :|: SNil)</span><span>
</span><span id="line-875"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; t = sOnes' $ SDataType SFloat</span><span>
</span><span id="line-876"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; getDType t</span><span>
</span><span id="line-877"></span><span>  </span><span class="hs-comment">-- Float</span><span>
</span><span id="line-878"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; t = sOnes' $ SUncheckedDataType Float</span><span>
</span><span id="line-879"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; getDType t</span><span>
</span><span id="line-880"></span><span>  </span><span class="hs-comment">-- Float</span><span>
</span><span id="line-881"></span><span>  </span><span id="getDType"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#getDType"><span class="hs-identifier hs-type">getDType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-882"></span><span>    </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679541352"><span class="annot"><a href="#local-6989586621679541352"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679541351"><span class="annot"><a href="#local-6989586621679541351"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679541350"><span class="annot"><a href="#local-6989586621679541350"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679541349"><span class="annot"><a href="#local-6989586621679541349"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-883"></span><span>    </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-884"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541352"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541351"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541350"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541360"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541349"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-885"></span><span>    </span><span class="hs-comment">-- | data type of the input tensor</span><span>
</span><span id="line-886"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier hs-type">DType</span></a></span><span>
</span><span id="line-887"></span><span>  </span><span id="local-6989586621679540281"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#getDType"><span class="hs-identifier hs-var hs-var">getDType</span></a></span><span> </span><span id="local-6989586621679540280"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679540280"><span class="hs-identifier hs-var">tensor</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IsChecked DType -&gt; DType
forall a. IsChecked a -&gt; a
</span><a href="Torch.GraduallyTyped.Prelude.html#forgetIsChecked"><span class="hs-identifier hs-var">forgetIsChecked</span></a></span><span> </span><span class="annot"><span class="annottext">(IsChecked DType -&gt; DType)
-&gt; (SDataType dataType -&gt; IsChecked DType)
-&gt; SDataType dataType
-&gt; DType
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">SDataType dataType -&gt; IsChecked DType
forall k (a :: k). SingKind k =&gt; Sing a -&gt; Demote k
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">fromSing</span></a></span><span> </span><span class="annot"><span class="annottext">(SDataType dataType -&gt; DType) -&gt; SDataType dataType -&gt; DType
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape -&gt; SDataType dataType
forall (dataType :: DataType DType)
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SGetDataType dataType =&gt;
Tensor gradient layout device dataType shape -&gt; SDataType dataType
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sGetDataType"><span class="hs-identifier hs-var">sGetDataType</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679540280"><span class="hs-identifier hs-var">tensor</span></a></span></span><span>
</span><span id="line-888"></span><span>
</span><span id="line-889"></span><span class="hs-keyword">instance</span><span> </span><span id="local-6989586621679540277"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetDataType"><span class="hs-identifier hs-type">SGetDataType</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#UncheckedDataType"><span class="hs-identifier hs-type">UncheckedDataType</span></a></span></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-890"></span><span>  </span><span id="local-6989586621679540275"><span class="annot"><span class="annottext">sGetDataType :: Tensor gradient layout device 'UncheckedDataType shape
-&gt; SDataType 'UncheckedDataType
</span><a href="#local-6989586621679540275"><span class="hs-identifier hs-var hs-var hs-var hs-var">sGetDataType</span></a></span></span><span> </span><span id="local-6989586621679540274"><span class="annot"><span class="annottext">Tensor gradient layout device 'UncheckedDataType shape
</span><a href="#local-6989586621679540274"><span class="hs-identifier hs-var">tensor</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">DType -&gt; SDataType 'UncheckedDataType
</span><a href="Torch.GraduallyTyped.DType.html#SUncheckedDataType"><span class="hs-identifier hs-var">SUncheckedDataType</span></a></span><span> </span><span class="annot"><span class="annottext">(DType -&gt; SDataType 'UncheckedDataType)
-&gt; (IO DType -&gt; DType) -&gt; IO DType -&gt; SDataType 'UncheckedDataType
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">IO DType -&gt; DType
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO DType -&gt; SDataType 'UncheckedDataType)
-&gt; IO DType -&gt; SDataType 'UncheckedDataType
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO ScalarType)
-&gt; Tensor gradient layout device 'UncheckedDataType shape
-&gt; IO DType
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO ScalarType
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.tensor_scalar_type</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device 'UncheckedDataType shape
</span><a href="#local-6989586621679540274"><span class="hs-identifier hs-var">tensor</span></a></span><span>
</span><span id="line-891"></span><span>
</span><span id="line-892"></span><span id="local-6989586621679540271"><span class="hs-keyword">instance</span><span> </span><span id="local-6989586621679540268"><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-type">SingI</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540271"><span class="hs-identifier hs-type">dType</span></a></span><span> </span><span class="hs-glyph">=&gt;</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetDataType"><span class="hs-identifier hs-type">SGetDataType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540271"><span class="hs-identifier hs-type">dType</span></a></span><span class="hs-special">)</span></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-893"></span><span>  </span><span id="local-6989586621679540267"><span class="annot"><span class="annottext">sGetDataType :: Tensor gradient layout device ('DataType dType) shape
-&gt; SDataType ('DataType dType)
</span><a href="#local-6989586621679540267"><span class="hs-identifier hs-var hs-var hs-var hs-var">sGetDataType</span></a></span></span><span> </span><span id="local-6989586621679540266"><span class="annot"><span class="annottext">Tensor gradient layout device ('DataType dType) shape
</span><a href="#local-6989586621679540266"><span class="hs-identifier hs-var">tensor</span></a></span></span><span>
</span><span id="line-894"></span><span>    </span><span class="hs-glyph">|</span><span> </span><span class="annot"><span class="annottext">IO DType -&gt; DType
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO ScalarType)
-&gt; Tensor gradient layout device ('DataType dType) shape
-&gt; IO DType
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO ScalarType
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.tensor_scalar_type</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device ('DataType dType) shape
</span><a href="#local-6989586621679540266"><span class="hs-identifier hs-var">tensor</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">DType -&gt; DType -&gt; Bool
forall a. Eq a =&gt; a -&gt; a -&gt; Bool
</span><span class="hs-operator hs-var">==</span></span><span> </span><span class="annot"><span class="annottext">Sing dType -&gt; Demote DType
forall k (a :: k). SingKind k =&gt; Sing a -&gt; Demote k
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">fromSing</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SingI dType =&gt; Sing dType
forall k (a :: k). SingI a =&gt; Sing a
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">sing</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679540271"><span class="hs-identifier hs-type">dType</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SDType dType -&gt; SDataType ('DataType dType)
forall (dType :: DType).
SDType dType -&gt; SDataType ('DataType dType)
</span><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier hs-var">SDataType</span></a></span><span> </span><span class="annot"><span class="annottext">(SDType dType -&gt; SDataType ('DataType dType))
-&gt; SDType dType -&gt; SDataType ('DataType dType)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SingI dType =&gt; Sing dType
forall k (a :: k). SingI a =&gt; Sing a
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">sing</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679540271"><span class="hs-identifier hs-type">dType</span></a></span><span>
</span><span id="line-895"></span><span>    </span><span class="hs-glyph">|</span><span> </span><span class="annot"><span class="annottext">Bool
</span><span class="hs-identifier hs-var">otherwise</span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-896"></span><span>      </span><span class="annot"><span class="annottext">String -&gt; SDataType ('DataType dType)
forall a. HasCallStack =&gt; String -&gt; a
</span><span class="hs-identifier hs-var">error</span></span><span> </span><span class="annot"><span class="annottext">(String -&gt; SDataType ('DataType dType))
-&gt; String -&gt; SDataType ('DataType dType)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-897"></span><span>        </span><span class="annot"><span class="annottext">String
</span><span class="hs-string">&quot;The tensor should have data type &quot;</span></span><span>
</span><span id="line-898"></span><span>          </span><span class="annot"><span class="annottext">String -&gt; ShowS
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">DType -&gt; String
forall a. Show a =&gt; a -&gt; String
</span><span class="hs-identifier hs-var">show</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Sing dType -&gt; Demote DType
forall k (a :: k). SingKind k =&gt; Sing a -&gt; Demote k
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">fromSing</span></a></span><span> </span><span class="annot"><span class="annottext">(Sing dType -&gt; Demote DType) -&gt; Sing dType -&gt; Demote DType
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SingI dType =&gt; Sing dType
forall k (a :: k). SingI a =&gt; Sing a
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">sing</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679540271"><span class="hs-identifier hs-type">dType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-899"></span><span>          </span><span class="annot"><span class="annottext">String -&gt; ShowS
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">String
</span><span class="hs-string">&quot; but hasn't. &quot;</span></span><span>
</span><span id="line-900"></span><span>          </span><span class="annot"><span class="annottext">String -&gt; ShowS
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">String
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#gitHubErrorMsg"><span class="hs-identifier hs-var">gitHubErrorMsg</span></a></span></span><span>
</span><span id="line-901"></span><span>
</span><span id="line-902"></span><span class="hs-keyword">data</span><span> </span><span id="DataTypeError"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#DataTypeError"><span class="hs-identifier hs-var">DataTypeError</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span id="DataTypeError"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#DataTypeError"><span class="hs-identifier hs-var">DataTypeError</span></a></span></span><span> </span><span class="hs-special">{</span><span id="dtExpected"><span class="annot"><span class="annottext">DataTypeError -&gt; DType
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#dtExpected"><span class="hs-identifier hs-var hs-var">dtExpected</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier hs-type">DType</span></a></span><span class="hs-special">,</span><span> </span><span id="dtActual"><span class="annot"><span class="annottext">DataTypeError -&gt; DType
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#dtActual"><span class="hs-identifier hs-var hs-var">dtActual</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier hs-type">DType</span></a></span><span class="hs-special">}</span><span>
</span><span id="line-903"></span><span>  </span><span class="hs-keyword">deriving</span><span> </span><span class="annot"><span class="hs-keyword">stock</span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679540256"><span id="local-6989586621679540258"><span id="local-6989586621679540260"><span class="annot"><span class="annottext">Int -&gt; DataTypeError -&gt; ShowS
[DataTypeError] -&gt; ShowS
DataTypeError -&gt; String
(Int -&gt; DataTypeError -&gt; ShowS)
-&gt; (DataTypeError -&gt; String)
-&gt; ([DataTypeError] -&gt; ShowS)
-&gt; Show DataTypeError
forall a.
(Int -&gt; a -&gt; ShowS) -&gt; (a -&gt; String) -&gt; ([a] -&gt; ShowS) -&gt; Show a
showList :: [DataTypeError] -&gt; ShowS
$cshowList :: [DataTypeError] -&gt; ShowS
show :: DataTypeError -&gt; String
$cshow :: DataTypeError -&gt; String
showsPrec :: Int -&gt; DataTypeError -&gt; ShowS
$cshowsPrec :: Int -&gt; DataTypeError -&gt; ShowS
</span><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">Show</span></span></span></span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Typeable</span></span><span class="hs-special">)</span><span>
</span><span id="line-904"></span><span>
</span><span id="line-905"></span><span class="hs-keyword">instance</span><span> </span><span id="local-6989586621679540250"><span id="local-6989586621679540252"><span class="annot"><span class="hs-identifier hs-type">Exception</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#DataTypeError"><span class="hs-identifier hs-type">DataTypeError</span></a></span></span></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-906"></span><span>  </span><span id="local-6989586621679540248"><span class="annot"><span class="annottext">displayException :: DataTypeError -&gt; String
</span><a href="#local-6989586621679540248"><span class="hs-identifier hs-var hs-var hs-var hs-var">displayException</span></a></span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#DataTypeError"><span class="hs-identifier hs-type">DataTypeError</span></a></span><span> </span><span class="hs-special">{</span><span id="local-6989586621679540246"><span id="local-6989586621679540247"><span class="annot"><span class="annottext">DType
dtActual :: DType
dtExpected :: DType
dtActual :: DataTypeError -&gt; DType
dtExpected :: DataTypeError -&gt; DType
</span><a href="#local-6989586621679540246"><span class="hs-glyph hs-var hs-var hs-var hs-var">..</span></a></span></span></span><span class="hs-special">}</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-907"></span><span>    </span><span class="annot"><span class="annottext">String
</span><span class="hs-string">&quot;The tensor does not have the data type `&quot;</span></span><span>
</span><span id="line-908"></span><span>      </span><span class="annot"><span class="annottext">String -&gt; ShowS
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">DType -&gt; String
forall a. Show a =&gt; a -&gt; String
</span><span class="hs-identifier hs-var">show</span></span><span> </span><span class="annot"><span class="annottext">DType
</span><a href="#local-6989586621679540247"><span class="hs-identifier hs-var">dtExpected</span></a></span><span>
</span><span id="line-909"></span><span>      </span><span class="annot"><span class="annottext">String -&gt; ShowS
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">String
</span><span class="hs-string">&quot;` but `&quot;</span></span><span>
</span><span id="line-910"></span><span>      </span><span class="annot"><span class="annottext">String -&gt; ShowS
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">DType -&gt; String
forall a. Show a =&gt; a -&gt; String
</span><span class="hs-identifier hs-var">show</span></span><span> </span><span class="annot"><span class="annottext">DType
</span><a href="#local-6989586621679540246"><span class="hs-identifier hs-var">dtActual</span></a></span><span>
</span><span id="line-911"></span><span>      </span><span class="annot"><span class="annottext">String -&gt; ShowS
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">String
</span><span class="hs-string">&quot;`.&quot;</span></span><span>
</span><span id="line-912"></span><span>
</span><span id="line-913"></span><span class="hs-comment">-- | Checks whether or not the input tensor has the data type 'dataType'</span><span>
</span><span id="line-914"></span><span class="hs-comment">-- and returns a statically annotated copy of it wrapped in a 'MonadThrow' 'm'.</span><span>
</span><span id="line-915"></span><span class="hs-comment">--</span><span>
</span><span id="line-916"></span><span class="hs-comment">-- For instance, if 'm' is 'Maybe', then the result will be wrapped in 'Just' if and only if the tensor has indeed the data type 'dataType'.</span><span>
</span><span id="line-917"></span><span class="hs-comment">-- If it does not have it, then the result will be 'Nothing'.</span><span>
</span><span id="line-918"></span><span class="hs-comment">--</span><span>
</span><span id="line-919"></span><span class="hs-comment">-- In the REPL, 'm' will default to 'IO':</span><span>
</span><span id="line-920"></span><span class="hs-comment">-- &gt;&gt;&gt; t = sOnes $ TensorSpec (SGradient SWithGradient) (SLayout SDense) (SDevice SCPU) (SUncheckedDataType Float) (SShape $ SName @&quot;batch&quot; :&amp;: SSize @32 :|: SName @&quot;feature&quot; :&amp;: SSize @8 :|: SNil)</span><span>
</span><span id="line-921"></span><span class="hs-comment">-- &gt;&gt;&gt; t' &lt;- checkedDataType @('DataType 'Float) t</span><span>
</span><span id="line-922"></span><span class="hs-comment">-- &gt;&gt;&gt; :type t'</span><span>
</span><span id="line-923"></span><span class="hs-comment">-- t'</span><span>
</span><span id="line-924"></span><span class="hs-comment">--   :: Tensor</span><span>
</span><span id="line-925"></span><span class="hs-comment">--        ('Gradient 'WithGradient)</span><span>
</span><span id="line-926"></span><span class="hs-comment">--        ('Layout 'Dense)</span><span>
</span><span id="line-927"></span><span class="hs-comment">--        ('Device 'CPU)</span><span>
</span><span id="line-928"></span><span class="hs-comment">--        ('DataType 'Float)</span><span>
</span><span id="line-929"></span><span class="hs-comment">--        ('Shape</span><span>
</span><span id="line-930"></span><span class="hs-comment">--           '[ 'Dim ('Name &quot;batch&quot;) ('Size 32),</span><span>
</span><span id="line-931"></span><span class="hs-comment">--              'Dim ('Name &quot;feature&quot;) ('Size 8)])</span><span>
</span><span id="line-932"></span><span class="hs-comment">-- &gt;&gt;&gt; t' &lt;- checkedDataType @('DataType 'Double) t</span><span>
</span><span id="line-933"></span><span class="hs-comment">-- *** Exception: DataTypeError {dtExpected = Double, dtActual = Float}</span><span>
</span><span id="line-934"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#sCheckedDataType"><span class="hs-identifier hs-type">sCheckedDataType</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-935"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679541312"><span class="annot"><a href="#local-6989586621679541312"><span class="hs-identifier hs-type">dataType'</span></a></span></span><span> </span><span id="local-6989586621679541313"><span class="annot"><a href="#local-6989586621679541313"><span class="hs-identifier hs-type">m</span></a></span></span><span> </span><span id="local-6989586621679541311"><span class="annot"><a href="#local-6989586621679541311"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679541310"><span class="annot"><a href="#local-6989586621679541310"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679541309"><span class="annot"><a href="#local-6989586621679541309"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679541314"><span class="annot"><a href="#local-6989586621679541314"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679541308"><span class="annot"><a href="#local-6989586621679541308"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-936"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetDataType"><span class="hs-identifier hs-type">SGetDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541314"><span class="hs-identifier hs-type">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier hs-type">MonadThrow</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541313"><span class="hs-identifier hs-type">m</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-937"></span><span>  </span><span class="hs-comment">-- | data type</span><span>
</span><span id="line-938"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier hs-type">SDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541312"><span class="hs-identifier hs-type">dataType'</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-939"></span><span>  </span><span class="hs-comment">-- | input tensor</span><span>
</span><span id="line-940"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541311"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541310"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541309"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541314"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541308"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-941"></span><span>  </span><span class="hs-comment">-- | annotated output tensor wrapped in 'm'</span><span>
</span><span id="line-942"></span><span>  </span><span class="annot"><a href="#local-6989586621679541313"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541311"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541310"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541309"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Seq"><span class="hs-identifier hs-type">Seq</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679541314"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541312"><span class="hs-identifier hs-type">dataType'</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679541312"><span class="hs-identifier hs-type">dataType'</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679541308"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-943"></span><span id="sCheckedDataType"><span class="annot"><span class="annottext">sCheckedDataType :: SDataType dataType'
-&gt; Tensor gradient layout device dataType shape
-&gt; m (Tensor
        gradient
        layout
        device
        (Seq (dataType &lt;+&gt; dataType') dataType')
        shape)
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sCheckedDataType"><span class="hs-identifier hs-var hs-var">sCheckedDataType</span></a></span></span><span> </span><span id="local-6989586621679540244"><span class="annot"><span class="annottext">SDataType dataType'
</span><a href="#local-6989586621679540244"><span class="hs-identifier hs-var">dataType'</span></a></span></span><span> </span><span id="local-6989586621679540243"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679540243"><span class="hs-identifier hs-var">tensor</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-944"></span><span>  </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679540242"><span class="annot"><span class="annottext">actualDataType :: DType
</span><a href="#local-6989586621679540242"><span class="hs-identifier hs-var hs-var">actualDataType</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IsChecked DType -&gt; DType
forall a. IsChecked a -&gt; a
</span><a href="Torch.GraduallyTyped.Prelude.html#forgetIsChecked"><span class="hs-identifier hs-var">forgetIsChecked</span></a></span><span> </span><span class="annot"><span class="annottext">(IsChecked DType -&gt; DType)
-&gt; (SDataType dataType -&gt; IsChecked DType)
-&gt; SDataType dataType
-&gt; DType
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">SDataType dataType -&gt; IsChecked DType
forall k (a :: k). SingKind k =&gt; Sing a -&gt; Demote k
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">fromSing</span></a></span><span> </span><span class="annot"><span class="annottext">(SDataType dataType -&gt; DType) -&gt; SDataType dataType -&gt; DType
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape -&gt; SDataType dataType
forall (dataType :: DataType DType)
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SGetDataType dataType =&gt;
Tensor gradient layout device dataType shape -&gt; SDataType dataType
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sGetDataType"><span class="hs-identifier hs-var">sGetDataType</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679540243"><span class="hs-identifier hs-var">tensor</span></a></span><span>
</span><span id="line-945"></span><span>      </span><span id="local-6989586621679540241"><span class="annot"><span class="annottext">expectedDataType :: DType
</span><a href="#local-6989586621679540241"><span class="hs-identifier hs-var hs-var">expectedDataType</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IsChecked DType -&gt; DType
forall a. IsChecked a -&gt; a
</span><a href="Torch.GraduallyTyped.Prelude.html#forgetIsChecked"><span class="hs-identifier hs-var">forgetIsChecked</span></a></span><span> </span><span class="annot"><span class="annottext">(IsChecked DType -&gt; DType)
-&gt; (SDataType dataType' -&gt; IsChecked DType)
-&gt; SDataType dataType'
-&gt; DType
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">SDataType dataType' -&gt; IsChecked DType
forall k (a :: k). SingKind k =&gt; Sing a -&gt; Demote k
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">fromSing</span></a></span><span> </span><span class="annot"><span class="annottext">(SDataType dataType' -&gt; DType) -&gt; SDataType dataType' -&gt; DType
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SDataType dataType'
</span><a href="#local-6989586621679540244"><span class="hs-identifier hs-var">dataType'</span></a></span><span>
</span><span id="line-946"></span><span>   </span><span class="hs-keyword">in</span><span> </span><span class="hs-keyword">if</span><span> </span><span class="annot"><span class="annottext">DType
</span><a href="#local-6989586621679540242"><span class="hs-identifier hs-var">actualDataType</span></a></span><span> </span><span class="annot"><span class="annottext">DType -&gt; DType -&gt; Bool
forall a. Eq a =&gt; a -&gt; a -&gt; Bool
</span><span class="hs-operator hs-var">==</span></span><span> </span><span class="annot"><span class="annottext">DType
</span><a href="#local-6989586621679540241"><span class="hs-identifier hs-var">expectedDataType</span></a></span><span>
</span><span id="line-947"></span><span>        </span><span class="hs-keyword">then</span><span> </span><span class="annot"><span class="annottext">Tensor
  gradient
  layout
  device
  (Seq (Unify (DataType DType) dataType dataType') dataType')
  shape
-&gt; m (Tensor
        gradient
        layout
        device
        (Seq (Unify (DataType DType) dataType dataType') dataType')
        shape)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">(Tensor
   gradient
   layout
   device
   (Seq (Unify (DataType DType) dataType dataType') dataType')
   shape
 -&gt; m (Tensor
         gradient
         layout
         device
         (Seq (Unify (DataType DType) dataType dataType') dataType')
         shape))
-&gt; (Tensor gradient layout device dataType shape
    -&gt; Tensor
         gradient
         layout
         device
         (Seq (Unify (DataType DType) dataType dataType') dataType')
         shape)
-&gt; Tensor gradient layout device dataType shape
-&gt; m (Tensor
        gradient
        layout
        device
        (Seq (Unify (DataType DType) dataType dataType') dataType')
        shape)
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
-&gt; Tensor
     gradient
     layout
     device
     (Seq (Unify (DataType DType) dataType dataType') dataType')
     shape
</span><span class="hs-identifier hs-var">coerce</span></span><span> </span><span class="annot"><span class="annottext">(Tensor gradient layout device dataType shape
 -&gt; m (Tensor
         gradient
         layout
         device
         (Seq (Unify (DataType DType) dataType dataType') dataType')
         shape))
-&gt; Tensor gradient layout device dataType shape
-&gt; m (Tensor
        gradient
        layout
        device
        (Seq (Unify (DataType DType) dataType dataType') dataType')
        shape)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679540243"><span class="hs-identifier hs-var">tensor</span></a></span><span>
</span><span id="line-948"></span><span>        </span><span class="hs-keyword">else</span><span> </span><span class="annot"><span class="annottext">DataTypeError
-&gt; m (Tensor
        gradient
        layout
        device
        (Seq (Unify (DataType DType) dataType dataType') dataType')
        shape)
forall (m :: * -&gt; *) e a. (MonadThrow m, Exception e) =&gt; e -&gt; m a
</span><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier hs-var">throwM</span></a></span><span> </span><span class="annot"><span class="annottext">(DataTypeError
 -&gt; m (Tensor
         gradient
         layout
         device
         (Seq (Unify (DataType DType) dataType dataType') dataType')
         shape))
-&gt; DataTypeError
-&gt; m (Tensor
        gradient
        layout
        device
        (Seq (Unify (DataType DType) dataType dataType') dataType')
        shape)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">DType -&gt; DType -&gt; DataTypeError
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#DataTypeError"><span class="hs-identifier hs-var">DataTypeError</span></a></span><span> </span><span class="annot"><span class="annottext">DType
</span><a href="#local-6989586621679540241"><span class="hs-identifier hs-var">expectedDataType</span></a></span><span> </span><span class="annot"><span class="annottext">DType
</span><a href="#local-6989586621679540242"><span class="hs-identifier hs-var">actualDataType</span></a></span><span>
</span><span id="line-949"></span><span>
</span><span id="line-950"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#checkedDataType"><span class="hs-identifier hs-type">checkedDataType</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-951"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679540239"><span class="annot"><a href="#local-6989586621679540239"><span class="hs-identifier hs-type">dataType'</span></a></span></span><span> </span><span id="local-6989586621679540238"><span class="annot"><a href="#local-6989586621679540238"><span class="hs-identifier hs-type">m</span></a></span></span><span> </span><span id="local-6989586621679540237"><span class="annot"><a href="#local-6989586621679540237"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679540236"><span class="annot"><a href="#local-6989586621679540236"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679540235"><span class="annot"><a href="#local-6989586621679540235"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679540234"><span class="annot"><a href="#local-6989586621679540234"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679540233"><span class="annot"><a href="#local-6989586621679540233"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-952"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-type">SingI</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540239"><span class="hs-identifier hs-type">dataType'</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetDataType"><span class="hs-identifier hs-type">SGetDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540234"><span class="hs-identifier hs-type">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier hs-type">MonadThrow</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540238"><span class="hs-identifier hs-type">m</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-953"></span><span>  </span><span class="hs-comment">-- | input tensor</span><span>
</span><span id="line-954"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540237"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540236"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540235"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540234"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540233"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-955"></span><span>  </span><span class="hs-comment">-- | annotated output tensor wrapped in 'm'</span><span>
</span><span id="line-956"></span><span>  </span><span class="annot"><a href="#local-6989586621679540238"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540237"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540236"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540235"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Seq"><span class="hs-identifier hs-type">Seq</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679540234"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540239"><span class="hs-identifier hs-type">dataType'</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679540239"><span class="hs-identifier hs-type">dataType'</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679540233"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-957"></span><span id="checkedDataType"><span class="annot"><span class="annottext">checkedDataType :: Tensor gradient layout device dataType shape
-&gt; m (Tensor
        gradient
        layout
        device
        (Seq (dataType &lt;+&gt; dataType') dataType')
        shape)
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#checkedDataType"><span class="hs-identifier hs-var hs-var">checkedDataType</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SDataType dataType'
-&gt; Tensor gradient layout device dataType shape
-&gt; m (Tensor
        gradient
        layout
        device
        (Seq (dataType &lt;+&gt; dataType') dataType')
        shape)
forall (dataType' :: DataType DType) (m :: * -&gt; *)
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
(SGetDataType dataType, MonadThrow m) =&gt;
SDataType dataType'
-&gt; Tensor gradient layout device dataType shape
-&gt; m (Tensor
        gradient
        layout
        device
        (Seq (dataType &lt;+&gt; dataType') dataType')
        shape)
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sCheckedDataType"><span class="hs-identifier hs-var">sCheckedDataType</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SingI dataType' =&gt; Sing dataType'
forall k (a :: k). SingI a =&gt; Sing a
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">sing</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679540239"><span class="hs-identifier hs-type">dataType'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-958"></span><span>
</span><span id="line-959"></span><span class="hs-comment">-- | Returns the input tensor but with 'UncheckedDataType' as data-type type annotation.</span><span>
</span><span id="line-960"></span><span class="hs-comment">-- Any static information about the tensor's data type is thus erased.</span><span>
</span><span id="line-961"></span><span class="hs-comment">-- However, the tensor's underlying data structure is not changed.</span><span>
</span><span id="line-962"></span><span class="hs-comment">--</span><span>
</span><span id="line-963"></span><span class="hs-comment">-- &gt;&gt;&gt; t = ones @('Gradient 'WithGradient) @('Layout 'Dense) @('Device 'CPU) @('DataType 'Float) @('Shape '[ 'Dim ('Name &quot;batch&quot;) ('Size 32), 'Dim ('Name &quot;feature&quot;) ('Size 8)])</span><span>
</span><span id="line-964"></span><span class="hs-comment">-- &gt;&gt;&gt; :type uncheckedDataType t</span><span>
</span><span id="line-965"></span><span class="hs-comment">-- uncheckedDataType t</span><span>
</span><span id="line-966"></span><span class="hs-comment">--   :: Tensor</span><span>
</span><span id="line-967"></span><span class="hs-comment">--        ('Gradient 'WithGradient)</span><span>
</span><span id="line-968"></span><span class="hs-comment">--        ('Layout 'Dense)</span><span>
</span><span id="line-969"></span><span class="hs-comment">--        ('Device 'CPU)</span><span>
</span><span id="line-970"></span><span class="hs-comment">--        'UncheckedDataType</span><span>
</span><span id="line-971"></span><span class="hs-comment">--        ('Shape</span><span>
</span><span id="line-972"></span><span class="hs-comment">--           '[ 'Dim ('Name &quot;batch&quot;) ('Size 32),</span><span>
</span><span id="line-973"></span><span class="hs-comment">--              'Dim ('Name &quot;feature&quot;) ('Size 8)])</span><span>
</span><span id="line-974"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#uncheckedDataType"><span class="hs-identifier hs-type">uncheckedDataType</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-975"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679540231"><span class="annot"><a href="#local-6989586621679540231"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679540230"><span class="annot"><a href="#local-6989586621679540230"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679540229"><span class="annot"><a href="#local-6989586621679540229"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679540228"><span class="annot"><a href="#local-6989586621679540228"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679540227"><span class="annot"><a href="#local-6989586621679540227"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-976"></span><span>  </span><span class="hs-comment">-- | input tensor</span><span>
</span><span id="line-977"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540231"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540230"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540229"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540228"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540227"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-978"></span><span>  </span><span class="hs-comment">-- | tensor without checked data type</span><span>
</span><span id="line-979"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540231"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540230"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540229"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#UncheckedDataType"><span class="hs-identifier hs-type">UncheckedDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540227"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-980"></span><span id="uncheckedDataType"><span class="annot"><span class="annottext">uncheckedDataType :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device 'UncheckedDataType shape
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#uncheckedDataType"><span class="hs-identifier hs-var hs-var">uncheckedDataType</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device 'UncheckedDataType shape
</span><span class="hs-identifier hs-var">coerce</span></span><span>
</span><span id="line-981"></span><span>
</span><span id="line-982"></span><span class="hs-keyword">class</span><span> </span><span id="SGetShape"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetShape"><span class="hs-identifier hs-var">SGetShape</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679541298"><span class="annot"><a href="#local-6989586621679541298"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">[</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-983"></span><span>  </span><span class="hs-comment">-- | Returns the gradually typed shape of the input tensor.</span><span>
</span><span id="line-984"></span><span>  </span><span class="hs-comment">--</span><span>
</span><span id="line-985"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; sOnes' = sOnes . TensorSpec (SGradient SWithGradient) (SLayout SDense) (SDevice SCPU) (SDataType SFloat)</span><span>
</span><span id="line-986"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; t = sOnes' . SShape $ SName @&quot;batch&quot; :&amp;: SSize @32 :|: SName @&quot;feature&quot; :&amp;: SSize @8 :|: SNil</span><span>
</span><span id="line-987"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; sGetShape t</span><span>
</span><span id="line-988"></span><span>  </span><span class="hs-comment">-- SShape (SCons (SDim {sDimName = SName, sDimSize = SSize}) (SCons (SDim {sDimName = SName, sDimSize = SSize}) SNil))</span><span>
</span><span id="line-989"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; t = sOnes' . SUncheckedShape $ [Dim &quot;batch&quot; 32, Dim &quot;feature&quot; 8]</span><span>
</span><span id="line-990"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; sGetShape t</span><span>
</span><span id="line-991"></span><span>  </span><span class="hs-comment">-- SUncheckedShape [Dim {dimName = &quot;batch&quot;, dimSize = 32},Dim {dimName = &quot;feature&quot;, dimSize = 8}]</span><span>
</span><span id="line-992"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; t = sOnes' . SShape $ SUncheckedName &quot;batch&quot; :&amp;: SUncheckedSize 32 :|: SUncheckedName &quot;feature&quot; :&amp;: SSize @32 :|: SNil</span><span>
</span><span id="line-993"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; sGetShape t</span><span>
</span><span id="line-994"></span><span>  </span><span class="hs-comment">-- SShape (SCons (SDim {sDimName = SUncheckedName &quot;batch&quot;, sDimSize = SUncheckedSize 32}) (SCons (SDim {sDimName = SUncheckedName &quot;feature&quot;, sDimSize = SSize}) SNil))</span><span>
</span><span id="line-995"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; t = sOnes' . SShape $ SName @&quot;batch&quot; :&amp;: SUncheckedSize 32 :|: SName @&quot;feature&quot; :&amp;: SUncheckedSize 8 :|: SNil</span><span>
</span><span id="line-996"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; sGetShape t</span><span>
</span><span id="line-997"></span><span>  </span><span class="hs-comment">-- SShape (SCons (SDim {sDimName = SName, sDimSize = SUncheckedSize 32}) (SCons (SDim {sDimName = SName, sDimSize = SUncheckedSize 8}) SNil))</span><span>
</span><span id="line-998"></span><span>  </span><span id="sGetShape"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#sGetShape"><span class="hs-identifier hs-type">sGetShape</span></a></span></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-999"></span><span>    </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679541287"><span class="annot"><a href="#local-6989586621679541287"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679541286"><span class="annot"><a href="#local-6989586621679541286"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679541285"><span class="annot"><a href="#local-6989586621679541285"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679541284"><span class="annot"><a href="#local-6989586621679541284"><span class="hs-identifier hs-type">dataType</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-1000"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541287"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541286"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541285"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541284"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541298"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1001"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-type">SShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541298"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-1002"></span><span>
</span><span id="line-1003"></span><span>  </span><span class="hs-comment">-- | Returns the untyped shape of the input tensor.</span><span>
</span><span id="line-1004"></span><span>  </span><span class="hs-comment">--</span><span>
</span><span id="line-1005"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; sOnes' = sOnes . TensorSpec (SGradient SWithGradient) (SLayout SDense) (SDevice SCPU) (SDataType SFloat)</span><span>
</span><span id="line-1006"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; t = sOnes' . SShape $ SName @&quot;batch&quot; :&amp;: SSize @32 :|: SName @&quot;feature&quot; :&amp;: SSize @8 :|: SNil</span><span>
</span><span id="line-1007"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; getDims t</span><span>
</span><span id="line-1008"></span><span>  </span><span class="hs-comment">-- [Dim {dimName = &quot;batch&quot;, dimSize = 32},Dim {dimName = &quot;feature&quot;, dimSize = 8}]</span><span>
</span><span id="line-1009"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; t = sOnes' . SUncheckedShape $ [Dim &quot;batch&quot; 32, Dim &quot;feature&quot; 8]</span><span>
</span><span id="line-1010"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; getDims t</span><span>
</span><span id="line-1011"></span><span>  </span><span class="hs-comment">-- [Dim {dimName = &quot;batch&quot;, dimSize = 32},Dim {dimName = &quot;feature&quot;, dimSize = 8}]</span><span>
</span><span id="line-1012"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; t = sOnes' . SShape $ SUncheckedName &quot;batch&quot; :&amp;: SUncheckedSize 32 :|: SUncheckedName &quot;feature&quot; :&amp;: SSize @32 :|: SNil</span><span>
</span><span id="line-1013"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; getDims t</span><span>
</span><span id="line-1014"></span><span>  </span><span class="hs-comment">-- [Dim {dimName = &quot;batch&quot;, dimSize = 32},Dim {dimName = &quot;feature&quot;, dimSize = 32}]</span><span>
</span><span id="line-1015"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; t = sOnes' . SShape $ SName @&quot;batch&quot; :&amp;: SUncheckedSize 32 :|: SName @&quot;feature&quot; :&amp;: SUncheckedSize 8 :|: SNil</span><span>
</span><span id="line-1016"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; getDims t</span><span>
</span><span id="line-1017"></span><span>  </span><span class="hs-comment">-- [Dim {dimName = &quot;batch&quot;, dimSize = 32},Dim {dimName = &quot;feature&quot;, dimSize = 8}]</span><span>
</span><span id="line-1018"></span><span>  </span><span id="getDims"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#getDims"><span class="hs-identifier hs-type">getDims</span></a></span></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-1019"></span><span>    </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679541282"><span class="annot"><a href="#local-6989586621679541282"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679541281"><span class="annot"><a href="#local-6989586621679541281"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679541280"><span class="annot"><a href="#local-6989586621679541280"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679541279"><span class="annot"><a href="#local-6989586621679541279"><span class="hs-identifier hs-type">dataType</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-1020"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541282"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541281"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541280"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541279"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541298"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1021"></span><span>    </span><span class="hs-special">[</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">String</span></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Integer</span></span><span class="hs-special">]</span><span>
</span><span id="line-1022"></span><span>  </span><span id="local-6989586621679540224"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#getDims"><span class="hs-identifier hs-var hs-var">getDims</span></a></span><span> </span><span id="local-6989586621679540223"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679540223"><span class="hs-identifier hs-var">tensor</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(Dim (IsChecked String) (IsChecked Integer) -&gt; Dim String Integer)
-&gt; [Dim (IsChecked String) (IsChecked Integer)]
-&gt; [Dim String Integer]
forall (f :: * -&gt; *) a b. Functor f =&gt; (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-identifier hs-var">fmap</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(IsChecked String -&gt; String)
-&gt; (IsChecked Integer -&gt; Integer)
-&gt; Dim (IsChecked String) (IsChecked Integer)
-&gt; Dim String Integer
forall (p :: * -&gt; * -&gt; *) a b c d.
Bifunctor p =&gt;
(a -&gt; b) -&gt; (c -&gt; d) -&gt; p a c -&gt; p b d
</span><span class="hs-identifier hs-var">bimap</span></span><span> </span><span class="annot"><span class="annottext">IsChecked String -&gt; String
forall a. IsChecked a -&gt; a
</span><a href="Torch.GraduallyTyped.Prelude.html#forgetIsChecked"><span class="hs-identifier hs-var">forgetIsChecked</span></a></span><span> </span><span class="annot"><span class="annottext">IsChecked Integer -&gt; Integer
forall a. IsChecked a -&gt; a
</span><a href="Torch.GraduallyTyped.Prelude.html#forgetIsChecked"><span class="hs-identifier hs-var">forgetIsChecked</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">([Dim (IsChecked String) (IsChecked Integer)]
 -&gt; [Dim String Integer])
-&gt; (SShape shape -&gt; [Dim (IsChecked String) (IsChecked Integer)])
-&gt; SShape shape
-&gt; [Dim String Integer]
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">IsChecked [Dim (IsChecked String) (IsChecked Integer)]
-&gt; [Dim (IsChecked String) (IsChecked Integer)]
forall a. IsChecked a -&gt; a
</span><a href="Torch.GraduallyTyped.Prelude.html#forgetIsChecked"><span class="hs-identifier hs-var">forgetIsChecked</span></a></span><span> </span><span class="annot"><span class="annottext">(IsChecked [Dim (IsChecked String) (IsChecked Integer)]
 -&gt; [Dim (IsChecked String) (IsChecked Integer)])
-&gt; (SShape shape
    -&gt; IsChecked [Dim (IsChecked String) (IsChecked Integer)])
-&gt; SShape shape
-&gt; [Dim (IsChecked String) (IsChecked Integer)]
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">SShape shape
-&gt; IsChecked [Dim (IsChecked String) (IsChecked Integer)]
forall k (a :: k). SingKind k =&gt; Sing a -&gt; Demote k
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">fromSing</span></a></span><span> </span><span class="annot"><span class="annottext">(SShape shape -&gt; [Dim String Integer])
-&gt; SShape shape -&gt; [Dim String Integer]
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape -&gt; SShape shape
forall (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType).
SGetShape shape =&gt;
Tensor gradient layout device dataType shape -&gt; SShape shape
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sGetShape"><span class="hs-identifier hs-var">sGetShape</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679540223"><span class="hs-identifier hs-var">tensor</span></a></span></span><span>
</span><span id="line-1023"></span><span>
</span><span id="line-1024"></span><span class="hs-keyword">instance</span><span> </span><span id="local-6989586621679540220"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetShape"><span class="hs-identifier hs-type">SGetShape</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#UncheckedShape"><span class="hs-identifier hs-type">UncheckedShape</span></a></span></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-1025"></span><span>  </span><span id="local-6989586621679540218"><span class="annot"><span class="annottext">sGetShape :: Tensor gradient layout device dataType 'UncheckedShape
-&gt; SShape 'UncheckedShape
</span><a href="#local-6989586621679540218"><span class="hs-identifier hs-var hs-var hs-var hs-var">sGetShape</span></a></span></span><span> </span><span id="local-6989586621679540217"><span class="annot"><span class="annottext">Tensor gradient layout device dataType 'UncheckedShape
</span><a href="#local-6989586621679540217"><span class="hs-identifier hs-var">tensor</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">[Dim String Integer] -&gt; SShape 'UncheckedShape
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SUncheckedShape"><span class="hs-identifier hs-var">SUncheckedShape</span></a></span><span> </span><span class="annot"><span class="annottext">([Dim String Integer] -&gt; SShape 'UncheckedShape)
-&gt; (IO [Dim String Integer] -&gt; [Dim String Integer])
-&gt; IO [Dim String Integer]
-&gt; SShape 'UncheckedShape
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">IO [Dim String Integer] -&gt; [Dim String Integer]
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO [Dim String Integer] -&gt; SShape 'UncheckedShape)
-&gt; IO [Dim String Integer] -&gt; SShape 'UncheckedShape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-1026"></span><span>    </span><span id="local-6989586621679540215"><span class="annot"><span class="annottext">[Integer]
</span><a href="#local-6989586621679540215"><span class="hs-identifier hs-var">sizes</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr IntArray))
-&gt; Tensor gradient layout device dataType 'UncheckedShape
-&gt; IO [Integer]
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr IntArray)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.tensor_sizes</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType 'UncheckedShape
</span><a href="#local-6989586621679540217"><span class="hs-identifier hs-var">tensor</span></a></span><span>
</span><span id="line-1027"></span><span>    </span><span class="annot"><span class="annottext">IO Bool
-&gt; IO [Dim String Integer]
-&gt; IO [Dim String Integer]
-&gt; IO [Dim String Integer]
forall (m :: * -&gt; *) a. Monad m =&gt; m Bool -&gt; m a -&gt; m a -&gt; m a
</span><a href="Torch.GraduallyTyped.Prelude.html#ifM"><span class="hs-identifier hs-var">ifM</span></a></span><span>
</span><span id="line-1028"></span><span>      </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO CBool)
-&gt; Tensor gradient layout device dataType 'UncheckedShape
-&gt; IO Bool
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO CBool
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.tensor_has_names</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType 'UncheckedShape
</span><a href="#local-6989586621679540217"><span class="hs-identifier hs-var">tensor</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-1029"></span><span>      </span><span class="hs-special">(</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-1030"></span><span>          </span><span id="local-6989586621679540212"><span class="annot"><span class="annottext">[String]
</span><a href="#local-6989586621679540212"><span class="hs-identifier hs-var">names</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr DimnameList))
-&gt; Tensor gradient layout device dataType 'UncheckedShape
-&gt; IO [String]
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr DimnameList)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.tensor_names</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType 'UncheckedShape
</span><a href="#local-6989586621679540217"><span class="hs-identifier hs-var">tensor</span></a></span><span>
</span><span id="line-1031"></span><span>          </span><span class="annot"><span class="annottext">[Dim String Integer] -&gt; IO [Dim String Integer]
forall (m :: * -&gt; *) a. Monad m =&gt; a -&gt; m a
</span><span class="hs-identifier hs-var">return</span></span><span> </span><span class="annot"><span class="annottext">([Dim String Integer] -&gt; IO [Dim String Integer])
-&gt; [Dim String Integer] -&gt; IO [Dim String Integer]
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(String -&gt; Integer -&gt; Dim String Integer)
-&gt; [String] -&gt; [Integer] -&gt; [Dim String Integer]
forall a b c. (a -&gt; b -&gt; c) -&gt; [a] -&gt; [b] -&gt; [c]
</span><span class="hs-identifier hs-var">zipWith</span></span><span> </span><span class="annot"><span class="annottext">String -&gt; Integer -&gt; Dim String Integer
forall name size. name -&gt; size -&gt; Dim name size
</span><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-var">Dim</span></a></span><span> </span><span class="annot"><span class="annottext">[String]
</span><a href="#local-6989586621679540212"><span class="hs-identifier hs-var">names</span></a></span><span> </span><span class="annot"><span class="annottext">[Integer]
</span><a href="#local-6989586621679540215"><span class="hs-identifier hs-var">sizes</span></a></span><span>
</span><span id="line-1032"></span><span>      </span><span class="hs-special">)</span><span>
</span><span id="line-1033"></span><span>      </span><span class="hs-special">(</span><span class="annot"><span class="annottext">[Dim String Integer] -&gt; IO [Dim String Integer]
forall (m :: * -&gt; *) a. Monad m =&gt; a -&gt; m a
</span><span class="hs-identifier hs-var">return</span></span><span> </span><span class="annot"><span class="annottext">([Dim String Integer] -&gt; IO [Dim String Integer])
-&gt; [Dim String Integer] -&gt; IO [Dim String Integer]
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">String -&gt; Integer -&gt; Dim String Integer
forall name size. name -&gt; size -&gt; Dim name size
</span><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-var">Dim</span></a></span><span> </span><span class="annot"><span class="annottext">String
</span><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">(Integer -&gt; Dim String Integer)
-&gt; [Integer] -&gt; [Dim String Integer]
forall (f :: * -&gt; *) a b. Functor f =&gt; (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;$&gt;</span></span><span> </span><span class="annot"><span class="annottext">[Integer]
</span><a href="#local-6989586621679540215"><span class="hs-identifier hs-var">sizes</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-1034"></span><span>
</span><span id="line-1035"></span><span id="local-6989586621679540208"><span class="hs-keyword">instance</span><span> </span><span id="local-6989586621679540205"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetDims"><span class="hs-identifier hs-type">SGetDims</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540208"><span class="hs-identifier hs-type">dims</span></a></span><span> </span><span class="hs-glyph">=&gt;</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetShape"><span class="hs-identifier hs-type">SGetShape</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540208"><span class="hs-identifier hs-type">dims</span></a></span><span class="hs-special">)</span></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-1036"></span><span>  </span><span id="local-6989586621679540204"><span class="annot"><span class="annottext">sGetShape :: Tensor gradient layout device dataType ('Shape dims)
-&gt; SShape ('Shape dims)
</span><a href="#local-6989586621679540204"><span class="hs-identifier hs-var hs-var hs-var hs-var">sGetShape</span></a></span></span><span> </span><span id="local-6989586621679540203"><span class="annot"><span class="annottext">Tensor gradient layout device dataType ('Shape dims)
</span><a href="#local-6989586621679540203"><span class="hs-identifier hs-var">tensor</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-1037"></span><span>    </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679540202"><span class="annot"><span class="annottext">sizes :: [Integer]
</span><a href="#local-6989586621679540202"><span class="hs-identifier hs-var hs-var">sizes</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-1038"></span><span>          </span><span class="annot"><span class="annottext">IO [Integer] -&gt; [Integer]
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO [Integer] -&gt; [Integer]) -&gt; IO [Integer] -&gt; [Integer]
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-1039"></span><span>            </span><span class="annot"><span class="annottext">IO Bool -&gt; IO [Integer] -&gt; IO [Integer] -&gt; IO [Integer]
forall (m :: * -&gt; *) a. Monad m =&gt; m Bool -&gt; m a -&gt; m a -&gt; m a
</span><a href="Torch.GraduallyTyped.Prelude.html#ifM"><span class="hs-identifier hs-var">ifM</span></a></span><span>
</span><span id="line-1040"></span><span>              </span><span class="hs-special">(</span><span class="hs-special">(</span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Bool
forall a. Ord a =&gt; a -&gt; a -&gt; Bool
</span><span class="hs-operator hs-var">&gt;</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">0</span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">(Int -&gt; Bool) -&gt; IO Int -&gt; IO Bool
forall (f :: * -&gt; *) a b. Functor f =&gt; (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;$&gt;</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO Int64)
-&gt; Tensor gradient layout device dataType ('Shape dims) -&gt; IO Int
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO Int64
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.tensor_dim</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType ('Shape dims)
</span><a href="#local-6989586621679540203"><span class="hs-identifier hs-var">tensor</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-1041"></span><span>              </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr IntArray))
-&gt; Tensor gradient layout device dataType ('Shape dims)
-&gt; IO [Integer]
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr IntArray)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.tensor_sizes</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType ('Shape dims)
</span><a href="#local-6989586621679540203"><span class="hs-identifier hs-var">tensor</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-1042"></span><span>              </span><span class="hs-special">(</span><span class="annot"><span class="annottext">[Integer] -&gt; IO [Integer]
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">[</span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-1043"></span><span>        </span><span id="local-6989586621679540199"><span class="annot"><span class="annottext">names :: [String]
</span><a href="#local-6989586621679540199"><span class="hs-identifier hs-var hs-var">names</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-1044"></span><span>          </span><span class="annot"><span class="annottext">IO [String] -&gt; [String]
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO [String] -&gt; [String]) -&gt; IO [String] -&gt; [String]
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-1045"></span><span>            </span><span class="annot"><span class="annottext">IO Bool -&gt; IO [String] -&gt; IO [String] -&gt; IO [String]
forall (m :: * -&gt; *) a. Monad m =&gt; m Bool -&gt; m a -&gt; m a -&gt; m a
</span><a href="Torch.GraduallyTyped.Prelude.html#ifM"><span class="hs-identifier hs-var">ifM</span></a></span><span>
</span><span id="line-1046"></span><span>              </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO CBool)
-&gt; Tensor gradient layout device dataType ('Shape dims) -&gt; IO Bool
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO CBool
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.tensor_has_names</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType ('Shape dims)
</span><a href="#local-6989586621679540203"><span class="hs-identifier hs-var">tensor</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-1047"></span><span>              </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr DimnameList))
-&gt; Tensor gradient layout device dataType ('Shape dims)
-&gt; IO [String]
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr DimnameList)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.tensor_names</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType ('Shape dims)
</span><a href="#local-6989586621679540203"><span class="hs-identifier hs-var">tensor</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-1048"></span><span>              </span><span class="hs-special">(</span><span class="annot"><span class="annottext">[String] -&gt; IO [String]
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">([String] -&gt; IO [String]) -&gt; [String] -&gt; IO [String]
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(Integer -&gt; String) -&gt; [Integer] -&gt; [String]
forall a b. (a -&gt; b) -&gt; [a] -&gt; [b]
</span><span class="hs-identifier hs-var">map</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">String -&gt; Integer -&gt; String
forall a b. a -&gt; b -&gt; a
</span><span class="hs-identifier hs-var">const</span></span><span> </span><span class="annot"><span class="annottext">String
</span><span class="hs-string">&quot;*&quot;</span></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">[Integer]
</span><a href="#local-6989586621679540202"><span class="hs-identifier hs-var">sizes</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-1049"></span><span>     </span><span class="hs-keyword">in</span><span> </span><span class="annot"><span class="annottext">SList dims -&gt; SShape ('Shape dims)
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList dims -&gt; SShape ('Shape dims))
-&gt; SList dims -&gt; SShape ('Shape dims)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">[String] -&gt; [Integer] -&gt; SList dims
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SGetDims dims =&gt;
[String] -&gt; [Integer] -&gt; SList dims
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sGetDims"><span class="hs-identifier hs-var">sGetDims</span></a></span><span> </span><span class="annot"><span class="annottext">[String]
</span><a href="#local-6989586621679540199"><span class="hs-identifier hs-var">names</span></a></span><span> </span><span class="annot"><span class="annottext">[Integer]
</span><a href="#local-6989586621679540202"><span class="hs-identifier hs-var">sizes</span></a></span></span><span>
</span><span id="line-1050"></span><span>
</span><span id="line-1051"></span><span class="hs-keyword">class</span><span> </span><span id="SGetDims"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetDims"><span class="hs-identifier hs-var">SGetDims</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679541240"><span class="annot"><a href="#local-6989586621679541240"><span class="hs-identifier hs-type">dims</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-1052"></span><span>  </span><span id="sGetDims"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#sGetDims"><span class="hs-identifier hs-type">sGetDims</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">String</span></span><span class="hs-special">]</span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Integer</span></span><span class="hs-special">]</span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-type">SList</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541240"><span class="hs-identifier hs-type">dims</span></a></span><span>
</span><span id="line-1053"></span><span>
</span><span id="line-1054"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#dimsError"><span class="hs-identifier hs-type">dimsError</span></a></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679541232"><span class="annot"><a href="#local-6989586621679541232"><span class="hs-identifier hs-type">a</span></a></span></span><span class="hs-operator">.</span><span> </span><span class="annot"><a href="#local-6989586621679541232"><span class="hs-identifier hs-type">a</span></a></span><span>
</span><span id="line-1055"></span><span id="dimsError"><span class="annot"><span class="annottext">dimsError :: a
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#dimsError"><span class="hs-identifier hs-var hs-var">dimsError</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">String -&gt; a
forall a. HasCallStack =&gt; String -&gt; a
</span><span class="hs-identifier hs-var">error</span></span><span> </span><span class="annot"><span class="annottext">(String -&gt; a) -&gt; String -&gt; a
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">String
</span><span class="hs-string">&quot;The numbers of compile- and runtime dimensions are not the same. &quot;</span></span><span> </span><span class="annot"><span class="annottext">String -&gt; ShowS
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">String
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#gitHubErrorMsg"><span class="hs-identifier hs-var">gitHubErrorMsg</span></a></span><span>
</span><span id="line-1056"></span><span>
</span><span id="line-1057"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#dimNameError"><span class="hs-identifier hs-type">dimNameError</span></a></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679541211"><span class="annot"><a href="#local-6989586621679541211"><span class="hs-identifier hs-type">a</span></a></span></span><span class="hs-operator">.</span><span> </span><span class="annot"><span class="hs-identifier hs-type">String</span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="hs-identifier hs-type">String</span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="#local-6989586621679541211"><span class="hs-identifier hs-type">a</span></a></span><span>
</span><span id="line-1058"></span><span id="dimNameError"><span class="annot"><span class="annottext">dimNameError :: String -&gt; String -&gt; a
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#dimNameError"><span class="hs-identifier hs-var hs-var">dimNameError</span></a></span></span><span> </span><span id="local-6989586621679540193"><span class="annot"><span class="annottext">String
</span><a href="#local-6989586621679540193"><span class="hs-identifier hs-var">name</span></a></span></span><span> </span><span id="local-6989586621679540192"><span class="annot"><span class="annottext">String
</span><a href="#local-6989586621679540192"><span class="hs-identifier hs-var">name'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-1059"></span><span>  </span><span class="annot"><span class="annottext">String -&gt; a
forall a. HasCallStack =&gt; String -&gt; a
</span><span class="hs-identifier hs-var">error</span></span><span> </span><span class="annot"><span class="annottext">(String -&gt; a) -&gt; String -&gt; a
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-1060"></span><span>    </span><span class="annot"><span class="annottext">String
</span><span class="hs-string">&quot;The compile- and runtime dimension names are not the same, '&quot;</span></span><span>
</span><span id="line-1061"></span><span>      </span><span class="annot"><span class="annottext">String -&gt; ShowS
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">String
</span><a href="#local-6989586621679540193"><span class="hs-identifier hs-var">name</span></a></span><span>
</span><span id="line-1062"></span><span>      </span><span class="annot"><span class="annottext">String -&gt; ShowS
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">String
</span><span class="hs-string">&quot;' != '&quot;</span></span><span>
</span><span id="line-1063"></span><span>      </span><span class="annot"><span class="annottext">String -&gt; ShowS
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">String
</span><a href="#local-6989586621679540192"><span class="hs-identifier hs-var">name'</span></a></span><span>
</span><span id="line-1064"></span><span>      </span><span class="annot"><span class="annottext">String -&gt; ShowS
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">String
</span><span class="hs-string">&quot;'. &quot;</span></span><span>
</span><span id="line-1065"></span><span>      </span><span class="annot"><span class="annottext">String -&gt; ShowS
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">String
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#gitHubErrorMsg"><span class="hs-identifier hs-var">gitHubErrorMsg</span></a></span><span>
</span><span id="line-1066"></span><span>
</span><span id="line-1067"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#dimSizeError"><span class="hs-identifier hs-type">dimSizeError</span></a></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679541207"><span class="annot"><a href="#local-6989586621679541207"><span class="hs-identifier hs-type">a</span></a></span></span><span> </span><span id="local-6989586621679541206"><span class="annot"><a href="#local-6989586621679541206"><span class="hs-identifier hs-type">b</span></a></span></span><span class="hs-operator">.</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Show</span></span><span> </span><span class="annot"><a href="#local-6989586621679541207"><span class="hs-identifier hs-type">a</span></a></span><span> </span><span class="hs-glyph">=&gt;</span><span> </span><span class="annot"><a href="#local-6989586621679541207"><span class="hs-identifier hs-type">a</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="#local-6989586621679541207"><span class="hs-identifier hs-type">a</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="#local-6989586621679541206"><span class="hs-identifier hs-type">b</span></a></span><span>
</span><span id="line-1068"></span><span id="dimSizeError"><span class="annot"><span class="annottext">dimSizeError :: a -&gt; a -&gt; b
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#dimSizeError"><span class="hs-identifier hs-var hs-var">dimSizeError</span></a></span></span><span> </span><span id="local-6989586621679540190"><span class="annot"><span class="annottext">a
</span><a href="#local-6989586621679540190"><span class="hs-identifier hs-var">size</span></a></span></span><span> </span><span id="local-6989586621679540189"><span class="annot"><span class="annottext">a
</span><a href="#local-6989586621679540189"><span class="hs-identifier hs-var">size'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-1069"></span><span>  </span><span class="annot"><span class="annottext">String -&gt; b
forall a. HasCallStack =&gt; String -&gt; a
</span><span class="hs-identifier hs-var">error</span></span><span> </span><span class="annot"><span class="annottext">(String -&gt; b) -&gt; String -&gt; b
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-1070"></span><span>    </span><span class="annot"><span class="annottext">String
</span><span class="hs-string">&quot;The compile- and runtime dimension sizes are not the same, '&quot;</span></span><span>
</span><span id="line-1071"></span><span>      </span><span class="annot"><span class="annottext">String -&gt; ShowS
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">a -&gt; String
forall a. Show a =&gt; a -&gt; String
</span><span class="hs-identifier hs-var">show</span></span><span> </span><span class="annot"><span class="annottext">a
</span><a href="#local-6989586621679540190"><span class="hs-identifier hs-var">size</span></a></span><span>
</span><span id="line-1072"></span><span>      </span><span class="annot"><span class="annottext">String -&gt; ShowS
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">String
</span><span class="hs-string">&quot;' != '&quot;</span></span><span>
</span><span id="line-1073"></span><span>      </span><span class="annot"><span class="annottext">String -&gt; ShowS
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">a -&gt; String
forall a. Show a =&gt; a -&gt; String
</span><span class="hs-identifier hs-var">show</span></span><span> </span><span class="annot"><span class="annottext">a
</span><a href="#local-6989586621679540189"><span class="hs-identifier hs-var">size'</span></a></span><span>
</span><span id="line-1074"></span><span>      </span><span class="annot"><span class="annottext">String -&gt; ShowS
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">String
</span><span class="hs-string">&quot;'. &quot;</span></span><span>
</span><span id="line-1075"></span><span>      </span><span class="annot"><span class="annottext">String -&gt; ShowS
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">String
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#gitHubErrorMsg"><span class="hs-identifier hs-var">gitHubErrorMsg</span></a></span><span>
</span><span id="line-1076"></span><span>
</span><span id="line-1077"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#dimNameSizeError"><span class="hs-identifier hs-type">dimNameSizeError</span></a></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679541203"><span class="annot"><a href="#local-6989586621679541203"><span class="hs-identifier hs-type">a</span></a></span></span><span> </span><span id="local-6989586621679541202"><span class="annot"><a href="#local-6989586621679541202"><span class="hs-identifier hs-type">b</span></a></span></span><span class="hs-operator">.</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Show</span></span><span> </span><span class="annot"><a href="#local-6989586621679541203"><span class="hs-identifier hs-type">a</span></a></span><span> </span><span class="hs-glyph">=&gt;</span><span> </span><span class="annot"><span class="hs-identifier hs-type">String</span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="hs-identifier hs-type">String</span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="#local-6989586621679541203"><span class="hs-identifier hs-type">a</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="#local-6989586621679541203"><span class="hs-identifier hs-type">a</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="#local-6989586621679541202"><span class="hs-identifier hs-type">b</span></a></span><span>
</span><span id="line-1078"></span><span id="dimNameSizeError"><span class="annot"><span class="annottext">dimNameSizeError :: String -&gt; String -&gt; a -&gt; a -&gt; b
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#dimNameSizeError"><span class="hs-identifier hs-var hs-var">dimNameSizeError</span></a></span></span><span> </span><span id="local-6989586621679540187"><span class="annot"><span class="annottext">String
</span><a href="#local-6989586621679540187"><span class="hs-identifier hs-var">name</span></a></span></span><span> </span><span id="local-6989586621679540186"><span class="annot"><span class="annottext">String
</span><a href="#local-6989586621679540186"><span class="hs-identifier hs-var">name'</span></a></span></span><span> </span><span id="local-6989586621679540185"><span class="annot"><span class="annottext">a
</span><a href="#local-6989586621679540185"><span class="hs-identifier hs-var">size</span></a></span></span><span> </span><span id="local-6989586621679540184"><span class="annot"><span class="annottext">a
</span><a href="#local-6989586621679540184"><span class="hs-identifier hs-var">size'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-1079"></span><span>  </span><span class="annot"><span class="annottext">String -&gt; b
forall a. HasCallStack =&gt; String -&gt; a
</span><span class="hs-identifier hs-var">error</span></span><span> </span><span class="annot"><span class="annottext">(String -&gt; b) -&gt; String -&gt; b
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-1080"></span><span>    </span><span class="annot"><span class="annottext">String
</span><span class="hs-string">&quot;The compile- and runtime dimension names and sizes are not the same, '&quot;</span></span><span>
</span><span id="line-1081"></span><span>      </span><span class="annot"><span class="annottext">String -&gt; ShowS
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">String
</span><a href="#local-6989586621679540187"><span class="hs-identifier hs-var">name</span></a></span><span>
</span><span id="line-1082"></span><span>      </span><span class="annot"><span class="annottext">String -&gt; ShowS
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">String
</span><span class="hs-string">&quot;' != '&quot;</span></span><span>
</span><span id="line-1083"></span><span>      </span><span class="annot"><span class="annottext">String -&gt; ShowS
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">String
</span><a href="#local-6989586621679540186"><span class="hs-identifier hs-var">name'</span></a></span><span>
</span><span id="line-1084"></span><span>      </span><span class="annot"><span class="annottext">String -&gt; ShowS
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">String
</span><span class="hs-string">&quot;' and '&quot;</span></span><span>
</span><span id="line-1085"></span><span>      </span><span class="annot"><span class="annottext">String -&gt; ShowS
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">a -&gt; String
forall a. Show a =&gt; a -&gt; String
</span><span class="hs-identifier hs-var">show</span></span><span> </span><span class="annot"><span class="annottext">a
</span><a href="#local-6989586621679540185"><span class="hs-identifier hs-var">size</span></a></span><span>
</span><span id="line-1086"></span><span>      </span><span class="annot"><span class="annottext">String -&gt; ShowS
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">String
</span><span class="hs-string">&quot;' != '&quot;</span></span><span>
</span><span id="line-1087"></span><span>      </span><span class="annot"><span class="annottext">String -&gt; ShowS
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">a -&gt; String
forall a. Show a =&gt; a -&gt; String
</span><span class="hs-identifier hs-var">show</span></span><span> </span><span class="annot"><span class="annottext">a
</span><a href="#local-6989586621679540184"><span class="hs-identifier hs-var">size'</span></a></span><span>
</span><span id="line-1088"></span><span>      </span><span class="annot"><span class="annottext">String -&gt; ShowS
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">String
</span><span class="hs-string">&quot;'. &quot;</span></span><span>
</span><span id="line-1089"></span><span>      </span><span class="annot"><span class="annottext">String -&gt; ShowS
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">String
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#gitHubErrorMsg"><span class="hs-identifier hs-var">gitHubErrorMsg</span></a></span><span>
</span><span id="line-1090"></span><span>
</span><span id="line-1091"></span><span class="hs-keyword">instance</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetDims"><span class="hs-identifier hs-type">SGetDims</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="hs-special">]</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-1092"></span><span>  </span><span id="local-6989586621679540181"><span class="annot"><span class="annottext">sGetDims :: [String] -&gt; [Integer] -&gt; SList '[]
</span><a href="#local-6989586621679540181"><span class="hs-identifier hs-var hs-var hs-var hs-var">sGetDims</span></a></span></span><span> </span><span class="hs-special">[</span><span class="hs-special">]</span><span> </span><span class="hs-special">[</span><span class="hs-special">]</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span>
</span><span id="line-1093"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#sGetDims"><span class="hs-identifier hs-var">sGetDims</span></a></span><span> </span><span class="annot"><span class="annottext">[String]
</span><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="annottext">[Integer]
</span><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. a
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#dimsError"><span class="hs-identifier hs-var">dimsError</span></a></span><span>
</span><span id="line-1094"></span><span>
</span><span id="line-1095"></span><span id="local-6989586621679540178"><span id="local-6989586621679540179"><span class="hs-keyword">instance</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetDim"><span class="hs-identifier hs-type">SGetDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540179"><span class="hs-identifier hs-type">dim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetDims"><span class="hs-identifier hs-type">SGetDims</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540178"><span class="hs-identifier hs-type">dims</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetDims"><span class="hs-identifier hs-type">SGetDims</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679540179"><span class="hs-identifier hs-type">dim</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">:</span></span><span> </span><span class="annot"><a href="#local-6989586621679540178"><span class="hs-identifier hs-type">dims</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-1096"></span><span>  </span><span id="local-6989586621679540176"><span class="annot"><span class="annottext">sGetDims :: [String] -&gt; [Integer] -&gt; SList (dim : dims)
</span><a href="#local-6989586621679540176"><span class="hs-identifier hs-var hs-var hs-var hs-var">sGetDims</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679540175"><span class="annot"><span class="annottext">String
</span><a href="#local-6989586621679540175"><span class="hs-identifier hs-var">name</span></a></span></span><span> </span><span class="annot"><span class="hs-glyph hs-type">:</span></span><span> </span><span id="local-6989586621679540174"><span class="annot"><span class="annottext">[String]
</span><a href="#local-6989586621679540174"><span class="hs-identifier hs-var">names</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679540173"><span class="annot"><span class="annottext">Integer
</span><a href="#local-6989586621679540173"><span class="hs-identifier hs-var">size</span></a></span></span><span> </span><span class="annot"><span class="hs-glyph hs-type">:</span></span><span> </span><span id="local-6989586621679540172"><span class="annot"><span class="annottext">[Integer]
</span><a href="#local-6989586621679540172"><span class="hs-identifier hs-var">sizes</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">String -&gt; Integer -&gt; SDim dim
forall (dim :: Dim (Name Symbol) (Size Nat)).
SGetDim dim =&gt;
String -&gt; Integer -&gt; SDim dim
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sGetDim"><span class="hs-identifier hs-var">sGetDim</span></a></span><span> </span><span class="annot"><span class="annottext">String
</span><a href="#local-6989586621679540175"><span class="hs-identifier hs-var">name</span></a></span><span> </span><span class="annot"><span class="annottext">Integer
</span><a href="#local-6989586621679540173"><span class="hs-identifier hs-var">size</span></a></span><span> </span><span class="annot"><span class="annottext">Sing dim -&gt; SList dims -&gt; SList (dim : dims)
forall a1 (a2 :: a1) (as :: [a1]).
Sing a2 -&gt; SList as -&gt; SList (a2 : as)
</span><a href="Torch.GraduallyTyped.Prelude.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">[String] -&gt; [Integer] -&gt; SList dims
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SGetDims dims =&gt;
[String] -&gt; [Integer] -&gt; SList dims
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sGetDims"><span class="hs-identifier hs-var">sGetDims</span></a></span><span> </span><span class="annot"><span class="annottext">[String]
</span><a href="#local-6989586621679540174"><span class="hs-identifier hs-var">names</span></a></span><span> </span><span class="annot"><span class="annottext">[Integer]
</span><a href="#local-6989586621679540172"><span class="hs-identifier hs-var">sizes</span></a></span><span>
</span><span id="line-1097"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#sGetDims"><span class="hs-identifier hs-var">sGetDims</span></a></span><span> </span><span class="annot"><span class="annottext">[String]
</span><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="annottext">[Integer]
</span><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SList (dim : dims)
forall a. a
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#dimsError"><span class="hs-identifier hs-var">dimsError</span></a></span></span></span><span>
</span><span id="line-1098"></span><span>
</span><span id="line-1099"></span><span class="hs-keyword">class</span><span> </span><span id="SGetDim"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetDim"><span class="hs-identifier hs-var">SGetDim</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679541227"><span class="annot"><a href="#local-6989586621679541227"><span class="hs-identifier hs-type">dim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-1100"></span><span>  </span><span id="sGetDim"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#sGetDim"><span class="hs-identifier hs-type">sGetDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">String</span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Integer</span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541227"><span class="hs-identifier hs-type">dim</span></a></span><span>
</span><span id="line-1101"></span><span>
</span><span id="line-1102"></span><span class="hs-keyword">instance</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetDim"><span class="hs-identifier hs-type">SGetDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#UncheckedName"><span class="hs-identifier hs-type">UncheckedName</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#UncheckedSize"><span class="hs-identifier hs-type">UncheckedSize</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-1103"></span><span>  </span><span id="local-6989586621679540168"><span class="annot"><span class="annottext">sGetDim :: String -&gt; Integer -&gt; SDim ('Dim 'UncheckedName 'UncheckedSize)
</span><a href="#local-6989586621679540168"><span class="hs-identifier hs-var hs-var hs-var hs-var">sGetDim</span></a></span></span><span> </span><span id="local-6989586621679540167"><span class="annot"><span class="annottext">String
</span><a href="#local-6989586621679540167"><span class="hs-identifier hs-var">name</span></a></span></span><span> </span><span id="local-6989586621679540166"><span class="annot"><span class="annottext">Integer
</span><a href="#local-6989586621679540166"><span class="hs-identifier hs-var">size</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SName 'UncheckedName
-&gt; SSize 'UncheckedSize
-&gt; SDim ('Dim 'UncheckedName 'UncheckedSize)
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-var">SDim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">String -&gt; SName 'UncheckedName
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SUncheckedName"><span class="hs-identifier hs-var">SUncheckedName</span></a></span><span> </span><span class="annot"><span class="annottext">String
</span><a href="#local-6989586621679540167"><span class="hs-identifier hs-var">name</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Integer -&gt; SSize 'UncheckedSize
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SUncheckedSize"><span class="hs-identifier hs-var">SUncheckedSize</span></a></span><span> </span><span class="annot"><span class="annottext">Integer
</span><a href="#local-6989586621679540166"><span class="hs-identifier hs-var">size</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-1104"></span><span>
</span><span id="line-1105"></span><span id="local-6989586621679540162"><span class="hs-keyword">instance</span><span> </span><span class="annot"><span class="hs-identifier hs-type">KnownSymbol</span></span><span> </span><span class="annot"><a href="#local-6989586621679540162"><span class="hs-identifier hs-type">name</span></a></span><span> </span><span class="hs-glyph">=&gt;</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetDim"><span class="hs-identifier hs-type">SGetDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540162"><span class="hs-identifier hs-type">name</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#UncheckedSize"><span class="hs-identifier hs-type">UncheckedSize</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-1106"></span><span>  </span><span id="local-6989586621679540160"><span class="annot"><span class="annottext">sGetDim :: String -&gt; Integer -&gt; SDim ('Dim ('Name name) 'UncheckedSize)
</span><a href="#local-6989586621679540160"><span class="hs-identifier hs-var hs-var hs-var hs-var">sGetDim</span></a></span></span><span> </span><span id="local-6989586621679540159"><span class="annot"><span class="annottext">String
</span><a href="#local-6989586621679540159"><span class="hs-identifier hs-var">name</span></a></span></span><span> </span><span id="local-6989586621679540158"><span class="annot"><span class="annottext">Integer
</span><a href="#local-6989586621679540158"><span class="hs-identifier hs-var">size</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">case</span><span> </span><span class="annot"><span class="annottext">Proxy name -&gt; String
forall (n :: Symbol) (proxy :: Symbol -&gt; *).
KnownSymbol n =&gt;
proxy n -&gt; String
</span><span class="hs-identifier hs-var">symbolVal</span></span><span> </span><span class="annot"><span class="annottext">(Proxy name -&gt; String) -&gt; Proxy name -&gt; String
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">Proxy name
forall k (t :: k). Proxy t
</span><span class="hs-identifier hs-var">Proxy</span></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679540162"><span class="hs-identifier hs-type">name</span></a></span><span> </span><span class="hs-keyword">of</span><span>
</span><span id="line-1107"></span><span>    </span><span id="local-6989586621679540157"><span class="annot"><span class="annottext">String
</span><a href="#local-6989586621679540157"><span class="hs-identifier hs-var">name'</span></a></span></span><span>
</span><span id="line-1108"></span><span>      </span><span class="hs-glyph">|</span><span> </span><span class="annot"><span class="annottext">String
</span><a href="#local-6989586621679540159"><span class="hs-identifier hs-var">name</span></a></span><span> </span><span class="annot"><span class="annottext">String -&gt; String -&gt; Bool
forall a. Eq a =&gt; a -&gt; a -&gt; Bool
</span><span class="hs-operator hs-var">==</span></span><span> </span><span class="annot"><span class="annottext">String
</span><a href="#local-6989586621679540157"><span class="hs-identifier hs-var">name'</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">SName ('Name name)
-&gt; SSize 'UncheckedSize -&gt; SDim ('Dim ('Name name) 'UncheckedSize)
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-var">SDim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">KnownSymbol name =&gt; SName ('Name name)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679540162"><span class="hs-identifier hs-type">name</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Integer -&gt; SSize 'UncheckedSize
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SUncheckedSize"><span class="hs-identifier hs-var">SUncheckedSize</span></a></span><span> </span><span class="annot"><span class="annottext">Integer
</span><a href="#local-6989586621679540158"><span class="hs-identifier hs-var">size</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-1109"></span><span>      </span><span class="hs-glyph">|</span><span> </span><span class="annot"><span class="annottext">Bool
</span><span class="hs-identifier hs-var">otherwise</span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">String -&gt; String -&gt; SDim ('Dim ('Name name) 'UncheckedSize)
forall a. String -&gt; String -&gt; a
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#dimNameError"><span class="hs-identifier hs-var">dimNameError</span></a></span><span> </span><span class="annot"><span class="annottext">String
</span><a href="#local-6989586621679540159"><span class="hs-identifier hs-var">name</span></a></span><span> </span><span class="annot"><span class="annottext">String
</span><a href="#local-6989586621679540157"><span class="hs-identifier hs-var">name'</span></a></span></span><span>
</span><span id="line-1110"></span><span>
</span><span id="line-1111"></span><span id="local-6989586621679540155"><span class="hs-keyword">instance</span><span> </span><span class="annot"><span class="hs-identifier hs-type">KnownNat</span></span><span> </span><span class="annot"><a href="#local-6989586621679540155"><span class="hs-identifier hs-type">size</span></a></span><span> </span><span class="hs-glyph">=&gt;</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetDim"><span class="hs-identifier hs-type">SGetDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#UncheckedName"><span class="hs-identifier hs-type">UncheckedName</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540155"><span class="hs-identifier hs-type">size</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-1112"></span><span>  </span><span id="local-6989586621679540153"><span class="annot"><span class="annottext">sGetDim :: String -&gt; Integer -&gt; SDim ('Dim 'UncheckedName ('Size size))
</span><a href="#local-6989586621679540153"><span class="hs-identifier hs-var hs-var hs-var hs-var">sGetDim</span></a></span></span><span> </span><span id="local-6989586621679540152"><span class="annot"><span class="annottext">String
</span><a href="#local-6989586621679540152"><span class="hs-identifier hs-var">name</span></a></span></span><span> </span><span id="local-6989586621679540151"><span class="annot"><span class="annottext">Integer
</span><a href="#local-6989586621679540151"><span class="hs-identifier hs-var">size</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">case</span><span> </span><span class="annot"><span class="annottext">Proxy size -&gt; Integer
forall (n :: Nat) (proxy :: Nat -&gt; *).
KnownNat n =&gt;
proxy n -&gt; Integer
</span><span class="hs-identifier hs-var">natVal</span></span><span> </span><span class="annot"><span class="annottext">(Proxy size -&gt; Integer) -&gt; Proxy size -&gt; Integer
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">Proxy size
forall k (t :: k). Proxy t
</span><span class="hs-identifier hs-var">Proxy</span></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679540155"><span class="hs-identifier hs-type">size</span></a></span><span> </span><span class="hs-keyword">of</span><span>
</span><span id="line-1113"></span><span>    </span><span id="local-6989586621679540150"><span class="annot"><span class="annottext">Integer
</span><a href="#local-6989586621679540150"><span class="hs-identifier hs-var">size'</span></a></span></span><span>
</span><span id="line-1114"></span><span>      </span><span class="hs-glyph">|</span><span> </span><span class="annot"><span class="annottext">Integer
</span><a href="#local-6989586621679540151"><span class="hs-identifier hs-var">size</span></a></span><span> </span><span class="annot"><span class="annottext">Integer -&gt; Integer -&gt; Bool
forall a. Eq a =&gt; a -&gt; a -&gt; Bool
</span><span class="hs-operator hs-var">==</span></span><span> </span><span class="annot"><span class="annottext">Integer
</span><a href="#local-6989586621679540150"><span class="hs-identifier hs-var">size'</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">SName 'UncheckedName
-&gt; SSize ('Size size) -&gt; SDim ('Dim 'UncheckedName ('Size size))
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-var">SDim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">String -&gt; SName 'UncheckedName
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SUncheckedName"><span class="hs-identifier hs-var">SUncheckedName</span></a></span><span> </span><span class="annot"><span class="annottext">String
</span><a href="#local-6989586621679540152"><span class="hs-identifier hs-var">name</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">KnownNat size =&gt; SSize ('Size size)
forall (size :: Nat). KnownNat size =&gt; SSize ('Size size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier hs-var">SSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679540155"><span class="hs-identifier hs-type">size</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-1115"></span><span>      </span><span class="hs-glyph">|</span><span> </span><span class="annot"><span class="annottext">Bool
</span><span class="hs-identifier hs-var">otherwise</span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">Integer -&gt; Integer -&gt; SDim ('Dim 'UncheckedName ('Size size))
forall a b. Show a =&gt; a -&gt; a -&gt; b
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#dimSizeError"><span class="hs-identifier hs-var">dimSizeError</span></a></span><span> </span><span class="annot"><span class="annottext">Integer
</span><a href="#local-6989586621679540151"><span class="hs-identifier hs-var">size</span></a></span><span> </span><span class="annot"><span class="annottext">Integer
</span><a href="#local-6989586621679540150"><span class="hs-identifier hs-var">size'</span></a></span></span><span>
</span><span id="line-1116"></span><span>
</span><span id="line-1117"></span><span id="local-6989586621679540147"><span id="local-6989586621679540148"><span class="hs-keyword">instance</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">KnownSymbol</span></span><span> </span><span class="annot"><a href="#local-6989586621679540148"><span class="hs-identifier hs-type">name</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">KnownNat</span></span><span> </span><span class="annot"><a href="#local-6989586621679540147"><span class="hs-identifier hs-type">size</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetDim"><span class="hs-identifier hs-type">SGetDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540148"><span class="hs-identifier hs-type">name</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540147"><span class="hs-identifier hs-type">size</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-1118"></span><span>  </span><span id="local-6989586621679540145"><span class="annot"><span class="annottext">sGetDim :: String -&gt; Integer -&gt; SDim ('Dim ('Name name) ('Size size))
</span><a href="#local-6989586621679540145"><span class="hs-identifier hs-var hs-var hs-var hs-var">sGetDim</span></a></span></span><span> </span><span id="local-6989586621679540144"><span class="annot"><span class="annottext">String
</span><a href="#local-6989586621679540144"><span class="hs-identifier hs-var">name</span></a></span></span><span> </span><span id="local-6989586621679540143"><span class="annot"><span class="annottext">Integer
</span><a href="#local-6989586621679540143"><span class="hs-identifier hs-var">size</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">case</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Proxy name -&gt; String
forall (n :: Symbol) (proxy :: Symbol -&gt; *).
KnownSymbol n =&gt;
proxy n -&gt; String
</span><span class="hs-identifier hs-var">symbolVal</span></span><span> </span><span class="annot"><span class="annottext">(Proxy name -&gt; String) -&gt; Proxy name -&gt; String
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">Proxy name
forall k (t :: k). Proxy t
</span><span class="hs-identifier hs-var">Proxy</span></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679540148"><span class="hs-identifier hs-type">name</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Proxy size -&gt; Integer
forall (n :: Nat) (proxy :: Nat -&gt; *).
KnownNat n =&gt;
proxy n -&gt; Integer
</span><span class="hs-identifier hs-var">natVal</span></span><span> </span><span class="annot"><span class="annottext">(Proxy size -&gt; Integer) -&gt; Proxy size -&gt; Integer
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">Proxy size
forall k (t :: k). Proxy t
</span><span class="hs-identifier hs-var">Proxy</span></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679540147"><span class="hs-identifier hs-type">size</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-keyword">of</span><span>
</span><span id="line-1119"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679540142"><span class="annot"><span class="annottext">String
</span><a href="#local-6989586621679540142"><span class="hs-identifier hs-var">name'</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679540141"><span class="annot"><span class="annottext">Integer
</span><a href="#local-6989586621679540141"><span class="hs-identifier hs-var">size'</span></a></span></span><span class="hs-special">)</span><span>
</span><span id="line-1120"></span><span>      </span><span class="hs-glyph">|</span><span> </span><span class="annot"><span class="annottext">String
</span><a href="#local-6989586621679540144"><span class="hs-identifier hs-var">name</span></a></span><span> </span><span class="annot"><span class="annottext">String -&gt; String -&gt; Bool
forall a. Eq a =&gt; a -&gt; a -&gt; Bool
</span><span class="hs-operator hs-var">==</span></span><span> </span><span class="annot"><span class="annottext">String
</span><a href="#local-6989586621679540142"><span class="hs-identifier hs-var">name'</span></a></span><span> </span><span class="annot"><span class="annottext">Bool -&gt; Bool -&gt; Bool
</span><span class="hs-operator hs-var">&amp;&amp;</span></span><span> </span><span class="annot"><span class="annottext">Integer
</span><a href="#local-6989586621679540143"><span class="hs-identifier hs-var">size</span></a></span><span> </span><span class="annot"><span class="annottext">Integer -&gt; Integer -&gt; Bool
forall a. Eq a =&gt; a -&gt; a -&gt; Bool
</span><span class="hs-operator hs-var">==</span></span><span> </span><span class="annot"><span class="annottext">Integer
</span><a href="#local-6989586621679540141"><span class="hs-identifier hs-var">size'</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">SName ('Name name)
-&gt; SSize ('Size size) -&gt; SDim ('Dim ('Name name) ('Size size))
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-var">SDim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">KnownSymbol name =&gt; SName ('Name name)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679540148"><span class="hs-identifier hs-type">name</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">KnownNat size =&gt; SSize ('Size size)
forall (size :: Nat). KnownNat size =&gt; SSize ('Size size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier hs-var">SSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679540147"><span class="hs-identifier hs-type">size</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-1121"></span><span>      </span><span class="hs-glyph">|</span><span> </span><span class="annot"><span class="annottext">String
</span><a href="#local-6989586621679540144"><span class="hs-identifier hs-var">name</span></a></span><span> </span><span class="annot"><span class="annottext">String -&gt; String -&gt; Bool
forall a. Eq a =&gt; a -&gt; a -&gt; Bool
</span><span class="hs-operator hs-var">/=</span></span><span> </span><span class="annot"><span class="annottext">String
</span><a href="#local-6989586621679540142"><span class="hs-identifier hs-var">name'</span></a></span><span> </span><span class="annot"><span class="annottext">Bool -&gt; Bool -&gt; Bool
</span><span class="hs-operator hs-var">&amp;&amp;</span></span><span> </span><span class="annot"><span class="annottext">Integer
</span><a href="#local-6989586621679540143"><span class="hs-identifier hs-var">size</span></a></span><span> </span><span class="annot"><span class="annottext">Integer -&gt; Integer -&gt; Bool
forall a. Eq a =&gt; a -&gt; a -&gt; Bool
</span><span class="hs-operator hs-var">==</span></span><span> </span><span class="annot"><span class="annottext">Integer
</span><a href="#local-6989586621679540141"><span class="hs-identifier hs-var">size'</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">String -&gt; String -&gt; SDim ('Dim ('Name name) ('Size size))
forall a. String -&gt; String -&gt; a
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#dimNameError"><span class="hs-identifier hs-var">dimNameError</span></a></span><span> </span><span class="annot"><span class="annottext">String
</span><a href="#local-6989586621679540144"><span class="hs-identifier hs-var">name</span></a></span><span> </span><span class="annot"><span class="annottext">String
</span><a href="#local-6989586621679540142"><span class="hs-identifier hs-var">name'</span></a></span><span>
</span><span id="line-1122"></span><span>      </span><span class="hs-glyph">|</span><span> </span><span class="annot"><span class="annottext">String
</span><a href="#local-6989586621679540144"><span class="hs-identifier hs-var">name</span></a></span><span> </span><span class="annot"><span class="annottext">String -&gt; String -&gt; Bool
forall a. Eq a =&gt; a -&gt; a -&gt; Bool
</span><span class="hs-operator hs-var">==</span></span><span> </span><span class="annot"><span class="annottext">String
</span><a href="#local-6989586621679540142"><span class="hs-identifier hs-var">name'</span></a></span><span> </span><span class="annot"><span class="annottext">Bool -&gt; Bool -&gt; Bool
</span><span class="hs-operator hs-var">&amp;&amp;</span></span><span> </span><span class="annot"><span class="annottext">Integer
</span><a href="#local-6989586621679540143"><span class="hs-identifier hs-var">size</span></a></span><span> </span><span class="annot"><span class="annottext">Integer -&gt; Integer -&gt; Bool
forall a. Eq a =&gt; a -&gt; a -&gt; Bool
</span><span class="hs-operator hs-var">/=</span></span><span> </span><span class="annot"><span class="annottext">Integer
</span><a href="#local-6989586621679540141"><span class="hs-identifier hs-var">size'</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">Integer -&gt; Integer -&gt; SDim ('Dim ('Name name) ('Size size))
forall a b. Show a =&gt; a -&gt; a -&gt; b
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#dimSizeError"><span class="hs-identifier hs-var">dimSizeError</span></a></span><span> </span><span class="annot"><span class="annottext">Integer
</span><a href="#local-6989586621679540143"><span class="hs-identifier hs-var">size</span></a></span><span> </span><span class="annot"><span class="annottext">Integer
</span><a href="#local-6989586621679540141"><span class="hs-identifier hs-var">size'</span></a></span><span>
</span><span id="line-1123"></span><span>      </span><span class="hs-glyph">|</span><span> </span><span class="annot"><span class="annottext">Bool
</span><span class="hs-identifier hs-var">otherwise</span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">String
-&gt; String
-&gt; Integer
-&gt; Integer
-&gt; SDim ('Dim ('Name name) ('Size size))
forall a b. Show a =&gt; String -&gt; String -&gt; a -&gt; a -&gt; b
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#dimNameSizeError"><span class="hs-identifier hs-var">dimNameSizeError</span></a></span><span> </span><span class="annot"><span class="annottext">String
</span><a href="#local-6989586621679540144"><span class="hs-identifier hs-var">name</span></a></span><span> </span><span class="annot"><span class="annottext">String
</span><a href="#local-6989586621679540142"><span class="hs-identifier hs-var">name'</span></a></span><span> </span><span class="annot"><span class="annottext">Integer
</span><a href="#local-6989586621679540143"><span class="hs-identifier hs-var">size</span></a></span><span> </span><span class="annot"><span class="annottext">Integer
</span><a href="#local-6989586621679540141"><span class="hs-identifier hs-var">size'</span></a></span></span></span><span>
</span><span id="line-1124"></span><span>
</span><span id="line-1125"></span><span class="hs-keyword">data</span><span> </span><span id="ShapeError"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#ShapeError"><span class="hs-identifier hs-var">ShapeError</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span id="ShapeError"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#ShapeError"><span class="hs-identifier hs-var">ShapeError</span></a></span></span><span> </span><span class="hs-special">{</span><span id="seExpected"><span class="annot"><span class="annottext">ShapeError -&gt; [Dim String Integer]
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#seExpected"><span class="hs-identifier hs-var hs-var">seExpected</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">String</span></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Integer</span></span><span class="hs-special">]</span><span class="hs-special">,</span><span> </span><span id="seActual"><span class="annot"><span class="annottext">ShapeError -&gt; [Dim String Integer]
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#seActual"><span class="hs-identifier hs-var hs-var">seActual</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">String</span></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Integer</span></span><span class="hs-special">]</span><span class="hs-special">}</span><span>
</span><span id="line-1126"></span><span>  </span><span class="hs-keyword">deriving</span><span> </span><span class="annot"><span class="hs-keyword">stock</span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679540131"><span id="local-6989586621679540133"><span id="local-6989586621679540135"><span class="annot"><span class="annottext">Int -&gt; ShapeError -&gt; ShowS
[ShapeError] -&gt; ShowS
ShapeError -&gt; String
(Int -&gt; ShapeError -&gt; ShowS)
-&gt; (ShapeError -&gt; String)
-&gt; ([ShapeError] -&gt; ShowS)
-&gt; Show ShapeError
forall a.
(Int -&gt; a -&gt; ShowS) -&gt; (a -&gt; String) -&gt; ([a] -&gt; ShowS) -&gt; Show a
showList :: [ShapeError] -&gt; ShowS
$cshowList :: [ShapeError] -&gt; ShowS
show :: ShapeError -&gt; String
$cshow :: ShapeError -&gt; String
showsPrec :: Int -&gt; ShapeError -&gt; ShowS
$cshowsPrec :: Int -&gt; ShapeError -&gt; ShowS
</span><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">Show</span></span></span></span></span><span class="hs-special">)</span><span>
</span><span id="line-1127"></span><span>
</span><span id="line-1128"></span><span class="hs-keyword">instance</span><span> </span><span id="local-6989586621679540125"><span id="local-6989586621679540127"><span class="annot"><span class="hs-identifier hs-type">Exception</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#ShapeError"><span class="hs-identifier hs-type">ShapeError</span></a></span></span></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-1129"></span><span>  </span><span id="local-6989586621679540123"><span class="annot"><span class="annottext">displayException :: ShapeError -&gt; String
</span><a href="#local-6989586621679540123"><span class="hs-identifier hs-var hs-var hs-var hs-var">displayException</span></a></span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#ShapeError"><span class="hs-identifier hs-type">ShapeError</span></a></span><span> </span><span class="hs-special">{</span><span id="local-6989586621679540121"><span id="local-6989586621679540122"><span class="annot"><span class="annottext">[Dim String Integer]
seActual :: [Dim String Integer]
seExpected :: [Dim String Integer]
seActual :: ShapeError -&gt; [Dim String Integer]
seExpected :: ShapeError -&gt; [Dim String Integer]
</span><a href="#local-6989586621679540121"><span class="hs-glyph hs-var hs-var hs-var hs-var">..</span></a></span></span></span><span class="hs-special">}</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-1130"></span><span>    </span><span class="annot"><span class="annottext">String
</span><span class="hs-string">&quot;The tensor does not have the shape `&quot;</span></span><span>
</span><span id="line-1131"></span><span>      </span><span class="annot"><span class="annottext">String -&gt; ShowS
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">[Dim String Integer] -&gt; String
forall a. Show a =&gt; a -&gt; String
</span><span class="hs-identifier hs-var">show</span></span><span> </span><span class="annot"><span class="annottext">[Dim String Integer]
</span><a href="#local-6989586621679540122"><span class="hs-identifier hs-var">seExpected</span></a></span><span>
</span><span id="line-1132"></span><span>      </span><span class="annot"><span class="annottext">String -&gt; ShowS
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">String
</span><span class="hs-string">&quot;` but `&quot;</span></span><span>
</span><span id="line-1133"></span><span>      </span><span class="annot"><span class="annottext">String -&gt; ShowS
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">[Dim String Integer] -&gt; String
forall a. Show a =&gt; a -&gt; String
</span><span class="hs-identifier hs-var">show</span></span><span> </span><span class="annot"><span class="annottext">[Dim String Integer]
</span><a href="#local-6989586621679540121"><span class="hs-identifier hs-var">seActual</span></a></span><span>
</span><span id="line-1134"></span><span>      </span><span class="annot"><span class="annottext">String -&gt; ShowS
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">String
</span><span class="hs-string">&quot;`.&quot;</span></span><span>
</span><span id="line-1135"></span><span>
</span><span id="line-1136"></span><span class="hs-comment">-- | Checks whether or not the input tensor has the shape 'shape'</span><span>
</span><span id="line-1137"></span><span class="hs-comment">-- and returns a statically annotated copy of it wrapped in a 'MonadThrow' 'm'.</span><span>
</span><span id="line-1138"></span><span class="hs-comment">--</span><span>
</span><span id="line-1139"></span><span class="hs-comment">-- For instance, if 'm' is 'Maybe', then the result will be wrapped in 'Just' if and only if the tensor has indeed the shape 'shape'.</span><span>
</span><span id="line-1140"></span><span class="hs-comment">-- If it is not, then the result will be 'Nothing'.</span><span>
</span><span id="line-1141"></span><span class="hs-comment">--</span><span>
</span><span id="line-1142"></span><span class="hs-comment">-- In the REPL, 'm' will default to 'IO':</span><span>
</span><span id="line-1143"></span><span class="hs-comment">-- &gt;&gt;&gt; t = sOnes $ TensorSpec (SGradient SWithGradient) (SLayout SDense) (SDevice SCPU) (SDataType SFloat) (SUncheckedShape [Dim &quot;batch&quot; 32, Dim &quot;feature&quot; 8])</span><span>
</span><span id="line-1144"></span><span class="hs-comment">-- &gt;&gt;&gt; t' &lt;- sCheckedShape (SShape $ SName @&quot;batch&quot; :&amp;: SSize @32 :|: SName @&quot;feature&quot; :&amp;: SSize @8 :|: SNil) t</span><span>
</span><span id="line-1145"></span><span class="hs-comment">-- &gt;&gt;&gt; :type t'</span><span>
</span><span id="line-1146"></span><span class="hs-comment">-- t'</span><span>
</span><span id="line-1147"></span><span class="hs-comment">--   :: Tensor</span><span>
</span><span id="line-1148"></span><span class="hs-comment">--        ('Gradient 'WithGradient)</span><span>
</span><span id="line-1149"></span><span class="hs-comment">--        ('Layout 'Dense)</span><span>
</span><span id="line-1150"></span><span class="hs-comment">--        ('Device 'CPU)</span><span>
</span><span id="line-1151"></span><span class="hs-comment">--        ('DataType 'Float)</span><span>
</span><span id="line-1152"></span><span class="hs-comment">--        ('Shape</span><span>
</span><span id="line-1153"></span><span class="hs-comment">--           '[ 'Dim ('Name &quot;batch&quot;) ('Size 32),</span><span>
</span><span id="line-1154"></span><span class="hs-comment">--              'Dim ('Name &quot;feature&quot;) ('Size 8)])</span><span>
</span><span id="line-1155"></span><span class="hs-comment">-- &gt;&gt;&gt; t' &lt;- sCheckedShape (SShape $ SUncheckedName &quot;batch&quot; :&amp;: SSize @32 :|: SName @&quot;feature&quot; :&amp;: SUncheckedSize 8 :|: SNil) t</span><span>
</span><span id="line-1156"></span><span class="hs-comment">-- &gt;&gt;&gt; :type t'</span><span>
</span><span id="line-1157"></span><span class="hs-comment">-- t'</span><span>
</span><span id="line-1158"></span><span class="hs-comment">--   :: Tensor</span><span>
</span><span id="line-1159"></span><span class="hs-comment">--        ('Gradient 'WithGradient)</span><span>
</span><span id="line-1160"></span><span class="hs-comment">--        ('Layout 'Dense)</span><span>
</span><span id="line-1161"></span><span class="hs-comment">--        ('Device 'CPU)</span><span>
</span><span id="line-1162"></span><span class="hs-comment">--        ('DataType 'Float)</span><span>
</span><span id="line-1163"></span><span class="hs-comment">--        ('Shape</span><span>
</span><span id="line-1164"></span><span class="hs-comment">--           '[ 'Dim 'UncheckedName ('Size 32),</span><span>
</span><span id="line-1165"></span><span class="hs-comment">--              'Dim ('Name &quot;feature&quot;) 'UncheckedSize])</span><span>
</span><span id="line-1166"></span><span class="hs-comment">-- &gt;&gt;&gt; t' &lt;- sCheckedShape (SShape $ SName @&quot;batch&quot; :&amp;: SSize @32 :|: SName @&quot;feature&quot; :&amp;: SUncheckedSize 32 :|: SNil) t</span><span>
</span><span id="line-1167"></span><span class="hs-comment">-- *** Exception: ShapeError {seExpected = [Dim {dimName = &quot;batch&quot;, dimSize = 32},Dim {dimName = &quot;feature&quot;, dimSize = 32}], seActual = [Dim {dimName = &quot;batch&quot;, dimSize = 32},Dim {dimName = &quot;feature&quot;, dimSize = 8}]}</span><span>
</span><span id="line-1168"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#sCheckedShape"><span class="hs-identifier hs-type">sCheckedShape</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-1169"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679541183"><span class="annot"><a href="#local-6989586621679541183"><span class="hs-identifier hs-type">shape'</span></a></span></span><span> </span><span id="local-6989586621679541184"><span class="annot"><a href="#local-6989586621679541184"><span class="hs-identifier hs-type">m</span></a></span></span><span> </span><span id="local-6989586621679541182"><span class="annot"><a href="#local-6989586621679541182"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679541181"><span class="annot"><a href="#local-6989586621679541181"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679541180"><span class="annot"><a href="#local-6989586621679541180"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679541179"><span class="annot"><a href="#local-6989586621679541179"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679541185"><span class="annot"><a href="#local-6989586621679541185"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-1170"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetShape"><span class="hs-identifier hs-type">SGetShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541185"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier hs-type">MonadThrow</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541184"><span class="hs-identifier hs-type">m</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-1171"></span><span>  </span><span class="hs-comment">-- | shape</span><span>
</span><span id="line-1172"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-type">SShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541183"><span class="hs-identifier hs-type">shape'</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1173"></span><span>  </span><span class="hs-comment">-- | input tensor</span><span>
</span><span id="line-1174"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541182"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541181"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541180"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541179"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541185"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1175"></span><span>  </span><span class="hs-comment">-- | annotated output tensor wrapped in 'm'</span><span>
</span><span id="line-1176"></span><span>  </span><span class="annot"><a href="#local-6989586621679541184"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541182"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541181"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541180"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541179"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Seq"><span class="hs-identifier hs-type">Seq</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679541185"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541183"><span class="hs-identifier hs-type">shape'</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679541183"><span class="hs-identifier hs-type">shape'</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-1177"></span><span id="sCheckedShape"><span class="annot"><span class="annottext">sCheckedShape :: SShape shape'
-&gt; Tensor gradient layout device dataType shape
-&gt; m (Tensor
        gradient layout device dataType (Seq (shape &lt;+&gt; shape') shape'))
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sCheckedShape"><span class="hs-identifier hs-var hs-var">sCheckedShape</span></a></span></span><span> </span><span id="local-6989586621679540119"><span class="annot"><span class="annottext">SShape shape'
</span><a href="#local-6989586621679540119"><span class="hs-identifier hs-var">shape'</span></a></span></span><span> </span><span id="local-6989586621679540118"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679540118"><span class="hs-identifier hs-var">tensor</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-1178"></span><span>  </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679540117"><span class="annot"><span class="annottext">f :: Sing a -&gt; [Dim String Integer]
</span><a href="#local-6989586621679540117"><span class="hs-identifier hs-var hs-var">f</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(Dim (IsChecked String) (IsChecked Integer) -&gt; Dim String Integer)
-&gt; [Dim (IsChecked String) (IsChecked Integer)]
-&gt; [Dim String Integer]
forall (f :: * -&gt; *) a b. Functor f =&gt; (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-identifier hs-var">fmap</span></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">\</span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span id="local-6989586621679540116"><span class="annot"><span class="annottext">IsChecked String
</span><a href="#local-6989586621679540116"><span class="hs-identifier hs-var">name</span></a></span></span><span> </span><span id="local-6989586621679540115"><span class="annot"><span class="annottext">IsChecked Integer
</span><a href="#local-6989586621679540115"><span class="hs-identifier hs-var">size</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">String -&gt; Integer -&gt; Dim String Integer
forall name size. name -&gt; size -&gt; Dim name size
</span><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-var">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">IsChecked String -&gt; String
forall a. IsChecked a -&gt; a
</span><a href="Torch.GraduallyTyped.Prelude.html#forgetIsChecked"><span class="hs-identifier hs-var">forgetIsChecked</span></a></span><span> </span><span class="annot"><span class="annottext">IsChecked String
</span><a href="#local-6989586621679540116"><span class="hs-identifier hs-var">name</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">IsChecked Integer -&gt; Integer
forall a. IsChecked a -&gt; a
</span><a href="Torch.GraduallyTyped.Prelude.html#forgetIsChecked"><span class="hs-identifier hs-var">forgetIsChecked</span></a></span><span> </span><span class="annot"><span class="annottext">IsChecked Integer
</span><a href="#local-6989586621679540115"><span class="hs-identifier hs-var">size</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">([Dim (IsChecked String) (IsChecked Integer)]
 -&gt; [Dim String Integer])
-&gt; (Sing a -&gt; [Dim (IsChecked String) (IsChecked Integer)])
-&gt; Sing a
-&gt; [Dim String Integer]
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">IsChecked [Dim (IsChecked String) (IsChecked Integer)]
-&gt; [Dim (IsChecked String) (IsChecked Integer)]
forall a. IsChecked a -&gt; a
</span><a href="Torch.GraduallyTyped.Prelude.html#forgetIsChecked"><span class="hs-identifier hs-var">forgetIsChecked</span></a></span><span> </span><span class="annot"><span class="annottext">(IsChecked [Dim (IsChecked String) (IsChecked Integer)]
 -&gt; [Dim (IsChecked String) (IsChecked Integer)])
-&gt; (Sing a
    -&gt; IsChecked [Dim (IsChecked String) (IsChecked Integer)])
-&gt; Sing a
-&gt; [Dim (IsChecked String) (IsChecked Integer)]
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Sing a -&gt; IsChecked [Dim (IsChecked String) (IsChecked Integer)]
forall k (a :: k). SingKind k =&gt; Sing a -&gt; Demote k
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">fromSing</span></a></span><span>
</span><span id="line-1179"></span><span>      </span><span id="local-6989586621679540114"><span class="annot"><span class="annottext">actualShape :: [Dim String Integer]
</span><a href="#local-6989586621679540114"><span class="hs-identifier hs-var hs-var">actualShape</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Sing shape -&gt; [Dim String Integer]
forall (a :: Shape [Dim (Name Symbol) (Size Nat)]).
Sing a -&gt; [Dim String Integer]
</span><a href="#local-6989586621679540117"><span class="hs-identifier hs-var">f</span></a></span><span> </span><span class="annot"><span class="annottext">(Sing shape -&gt; [Dim String Integer])
-&gt; Sing shape -&gt; [Dim String Integer]
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape -&gt; SShape shape
forall (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType).
SGetShape shape =&gt;
Tensor gradient layout device dataType shape -&gt; SShape shape
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sGetShape"><span class="hs-identifier hs-var">sGetShape</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679540118"><span class="hs-identifier hs-var">tensor</span></a></span><span>
</span><span id="line-1180"></span><span>      </span><span id="local-6989586621679540113"><span class="annot"><span class="annottext">expectedShape :: [Dim String Integer]
</span><a href="#local-6989586621679540113"><span class="hs-identifier hs-var hs-var">expectedShape</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Sing shape' -&gt; [Dim String Integer]
forall (a :: Shape [Dim (Name Symbol) (Size Nat)]).
Sing a -&gt; [Dim String Integer]
</span><a href="#local-6989586621679540117"><span class="hs-identifier hs-var">f</span></a></span><span> </span><span class="annot"><span class="annottext">Sing shape'
SShape shape'
</span><a href="#local-6989586621679540119"><span class="hs-identifier hs-var">shape'</span></a></span><span>
</span><span id="line-1181"></span><span>   </span><span class="hs-keyword">in</span><span> </span><span class="hs-keyword">if</span><span> </span><span class="annot"><span class="annottext">[Dim String Integer]
</span><a href="#local-6989586621679540114"><span class="hs-identifier hs-var">actualShape</span></a></span><span> </span><span class="annot"><span class="annottext">[Dim String Integer] -&gt; [Dim String Integer] -&gt; Bool
forall a. Eq a =&gt; a -&gt; a -&gt; Bool
</span><span class="hs-operator hs-var">==</span></span><span> </span><span class="annot"><span class="annottext">[Dim String Integer]
</span><a href="#local-6989586621679540113"><span class="hs-identifier hs-var">expectedShape</span></a></span><span>
</span><span id="line-1182"></span><span>        </span><span class="hs-keyword">then</span><span> </span><span class="annot"><span class="annottext">Tensor
  gradient
  layout
  device
  dataType
  (Seq
     (Unify (Shape [Dim (Name Symbol) (Size Nat)]) shape shape') shape')
-&gt; m (Tensor
        gradient
        layout
        device
        dataType
        (Seq
           (Unify (Shape [Dim (Name Symbol) (Size Nat)]) shape shape')
           shape'))
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">(Tensor
   gradient
   layout
   device
   dataType
   (Seq
      (Unify (Shape [Dim (Name Symbol) (Size Nat)]) shape shape') shape')
 -&gt; m (Tensor
         gradient
         layout
         device
         dataType
         (Seq
            (Unify (Shape [Dim (Name Symbol) (Size Nat)]) shape shape')
            shape')))
-&gt; (Tensor gradient layout device dataType shape
    -&gt; Tensor
         gradient
         layout
         device
         dataType
         (Seq
            (Unify (Shape [Dim (Name Symbol) (Size Nat)]) shape shape')
            shape'))
-&gt; Tensor gradient layout device dataType shape
-&gt; m (Tensor
        gradient
        layout
        device
        dataType
        (Seq
           (Unify (Shape [Dim (Name Symbol) (Size Nat)]) shape shape')
           shape'))
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
-&gt; Tensor
     gradient
     layout
     device
     dataType
     (Seq
        (Unify (Shape [Dim (Name Symbol) (Size Nat)]) shape shape') shape')
</span><span class="hs-identifier hs-var">coerce</span></span><span> </span><span class="annot"><span class="annottext">(Tensor gradient layout device dataType shape
 -&gt; m (Tensor
         gradient
         layout
         device
         dataType
         (Seq
            (Unify (Shape [Dim (Name Symbol) (Size Nat)]) shape shape')
            shape')))
-&gt; Tensor gradient layout device dataType shape
-&gt; m (Tensor
        gradient
        layout
        device
        dataType
        (Seq
           (Unify (Shape [Dim (Name Symbol) (Size Nat)]) shape shape')
           shape'))
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679540118"><span class="hs-identifier hs-var">tensor</span></a></span><span>
</span><span id="line-1183"></span><span>        </span><span class="hs-keyword">else</span><span> </span><span class="annot"><span class="annottext">ShapeError
-&gt; m (Tensor
        gradient
        layout
        device
        dataType
        (Seq
           (Unify (Shape [Dim (Name Symbol) (Size Nat)]) shape shape')
           shape'))
forall (m :: * -&gt; *) e a. (MonadThrow m, Exception e) =&gt; e -&gt; m a
</span><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier hs-var">throwM</span></a></span><span> </span><span class="annot"><span class="annottext">(ShapeError
 -&gt; m (Tensor
         gradient
         layout
         device
         dataType
         (Seq
            (Unify (Shape [Dim (Name Symbol) (Size Nat)]) shape shape')
            shape')))
-&gt; ShapeError
-&gt; m (Tensor
        gradient
        layout
        device
        dataType
        (Seq
           (Unify (Shape [Dim (Name Symbol) (Size Nat)]) shape shape')
           shape'))
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">[Dim String Integer] -&gt; [Dim String Integer] -&gt; ShapeError
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#ShapeError"><span class="hs-identifier hs-var">ShapeError</span></a></span><span> </span><span class="annot"><span class="annottext">[Dim String Integer]
</span><a href="#local-6989586621679540113"><span class="hs-identifier hs-var">expectedShape</span></a></span><span> </span><span class="annot"><span class="annottext">[Dim String Integer]
</span><a href="#local-6989586621679540114"><span class="hs-identifier hs-var">actualShape</span></a></span><span>
</span><span id="line-1184"></span><span>
</span><span id="line-1185"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#checkedShape"><span class="hs-identifier hs-type">checkedShape</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-1186"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679540111"><span class="annot"><a href="#local-6989586621679540111"><span class="hs-identifier hs-type">shape'</span></a></span></span><span> </span><span id="local-6989586621679540110"><span class="annot"><a href="#local-6989586621679540110"><span class="hs-identifier hs-type">m</span></a></span></span><span> </span><span id="local-6989586621679540109"><span class="annot"><a href="#local-6989586621679540109"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679540108"><span class="annot"><a href="#local-6989586621679540108"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679540107"><span class="annot"><a href="#local-6989586621679540107"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679540106"><span class="annot"><a href="#local-6989586621679540106"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679540105"><span class="annot"><a href="#local-6989586621679540105"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-1187"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-type">SingI</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540111"><span class="hs-identifier hs-type">shape'</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetShape"><span class="hs-identifier hs-type">SGetShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540105"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier hs-type">MonadThrow</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540110"><span class="hs-identifier hs-type">m</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-1188"></span><span>  </span><span class="hs-comment">-- | input tensor</span><span>
</span><span id="line-1189"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540109"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540108"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540107"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540106"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540105"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1190"></span><span>  </span><span class="hs-comment">-- | annotated output tensor wrapped in 'm'</span><span>
</span><span id="line-1191"></span><span>  </span><span class="annot"><a href="#local-6989586621679540110"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540109"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540108"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540107"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540106"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Seq"><span class="hs-identifier hs-type">Seq</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679540105"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540111"><span class="hs-identifier hs-type">shape'</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679540111"><span class="hs-identifier hs-type">shape'</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-1192"></span><span id="checkedShape"><span class="annot"><span class="annottext">checkedShape :: Tensor gradient layout device dataType shape
-&gt; m (Tensor
        gradient layout device dataType (Seq (shape &lt;+&gt; shape') shape'))
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#checkedShape"><span class="hs-identifier hs-var hs-var">checkedShape</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SShape shape'
-&gt; Tensor gradient layout device dataType shape
-&gt; m (Tensor
        gradient layout device dataType (Seq (shape &lt;+&gt; shape') shape'))
forall (shape' :: Shape [Dim (Name Symbol) (Size Nat)])
       (m :: * -&gt; *) (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
(SGetShape shape, MonadThrow m) =&gt;
SShape shape'
-&gt; Tensor gradient layout device dataType shape
-&gt; m (Tensor
        gradient layout device dataType (Seq (shape &lt;+&gt; shape') shape'))
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sCheckedShape"><span class="hs-identifier hs-var">sCheckedShape</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SingI shape' =&gt; Sing shape'
forall k (a :: k). SingI a =&gt; Sing a
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">sing</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679540111"><span class="hs-identifier hs-type">shape'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-1193"></span><span>
</span><span id="line-1194"></span><span class="hs-comment">-- | Returns the input tensor but with the selected dimension replaces with 'UncheckedDim' as dimension type annotation.</span><span>
</span><span id="line-1195"></span><span class="hs-comment">-- The static information about the selected tensor dimension is thus erased.</span><span>
</span><span id="line-1196"></span><span class="hs-comment">-- However, the tensor's underlying data structure is not changed.</span><span>
</span><span id="line-1197"></span><span class="hs-comment">--</span><span>
</span><span id="line-1198"></span><span class="hs-comment">-- &gt;&gt;&gt; t = ones @('Gradient 'WithGradient) @('Layout 'Dense) @('Device 'CPU) @('DataType 'Float) @('Shape '[ 'Dim ('Name &quot;batch&quot;) ('Size 32), 'Dim ('Name &quot;feature&quot;) ('Size 8)])</span><span>
</span><span id="line-1199"></span><span class="hs-comment">-- &gt;&gt;&gt; :type uncheckedDim @('SelectDim ('ByName &quot;batch&quot;)) t</span><span>
</span><span id="line-1200"></span><span class="hs-comment">-- uncheckedDim @('SelectDim ('ByName &quot;batch&quot;)) t</span><span>
</span><span id="line-1201"></span><span class="hs-comment">--   :: Tensor</span><span>
</span><span id="line-1202"></span><span class="hs-comment">--        ('Gradient 'WithGradient)</span><span>
</span><span id="line-1203"></span><span class="hs-comment">--        ('Layout 'Dense)</span><span>
</span><span id="line-1204"></span><span class="hs-comment">--        ('Device 'CPU)</span><span>
</span><span id="line-1205"></span><span class="hs-comment">--        ('DataType 'Float)</span><span>
</span><span id="line-1206"></span><span class="hs-comment">--        ('Shape</span><span>
</span><span id="line-1207"></span><span class="hs-comment">--           '[ 'Dim 'UncheckedName 'UncheckedSize,</span><span>
</span><span id="line-1208"></span><span class="hs-comment">--              'Dim ('Name &quot;feature&quot;) ('Size 8)])</span><span>
</span><span id="line-1209"></span><span class="hs-comment">-- &gt;&gt;&gt; t = ones @('Gradient 'WithGradient) @('Layout 'Dense) @('Device 'CPU) @('DataType 'Float) @('Shape '[ 'Dim ('Name &quot;batch&quot;) ('Size 32), 'Dim ('Name &quot;feature&quot;) ('Size 8)])</span><span>
</span><span id="line-1210"></span><span class="hs-comment">-- &gt;&gt;&gt; :type uncheckedDim @('SelectDim ('ByIndex 1)) t</span><span>
</span><span id="line-1211"></span><span class="hs-comment">-- uncheckedDim @('SelectDim ('ByIndex 1)) t</span><span>
</span><span id="line-1212"></span><span class="hs-comment">--   :: Tensor</span><span>
</span><span id="line-1213"></span><span class="hs-comment">--        ('Gradient 'WithGradient)</span><span>
</span><span id="line-1214"></span><span class="hs-comment">--        ('Layout 'Dense)</span><span>
</span><span id="line-1215"></span><span class="hs-comment">--        ('Device 'CPU)</span><span>
</span><span id="line-1216"></span><span class="hs-comment">--        ('DataType 'Float)</span><span>
</span><span id="line-1217"></span><span class="hs-comment">--        ('Shape</span><span>
</span><span id="line-1218"></span><span class="hs-comment">--           '[ 'Dim ('Name &quot;batch&quot;) ('Size 32),</span><span>
</span><span id="line-1219"></span><span class="hs-comment">--              'Dim 'UncheckedName 'UncheckedSize])</span><span>
</span><span id="line-1220"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#uncheckedDim"><span class="hs-identifier hs-type">uncheckedDim</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-1221"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679540103"><span class="annot"><a href="#local-6989586621679540103"><span class="hs-identifier hs-type">selectDim</span></a></span></span><span> </span><span id="local-6989586621679540102"><span class="annot"><a href="#local-6989586621679540102"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679540101"><span class="annot"><a href="#local-6989586621679540101"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679540100"><span class="annot"><a href="#local-6989586621679540100"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679540099"><span class="annot"><a href="#local-6989586621679540099"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679540098"><span class="annot"><a href="#local-6989586621679540098"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-1222"></span><span>  </span><span class="hs-comment">-- | input tensor</span><span>
</span><span id="line-1223"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540102"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540101"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540100"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540099"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540098"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1224"></span><span>  </span><span class="hs-comment">-- | tensor with the selected dimensions unchecked</span><span>
</span><span id="line-1225"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540102"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540101"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540100"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540099"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#ReplaceDimF"><span class="hs-identifier hs-type">ReplaceDimF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540103"><span class="hs-identifier hs-type">selectDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540098"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#UncheckedName"><span class="hs-identifier hs-type">UncheckedName</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#UncheckedSize"><span class="hs-identifier hs-type">UncheckedSize</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-1226"></span><span id="uncheckedDim"><span class="annot"><span class="annottext">uncheckedDim :: Tensor gradient layout device dataType shape
-&gt; Tensor
     gradient
     layout
     device
     dataType
     (ReplaceDimF selectDim shape ('Dim 'UncheckedName 'UncheckedSize))
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#uncheckedDim"><span class="hs-identifier hs-var hs-var">uncheckedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
-&gt; Tensor
     gradient
     layout
     device
     dataType
     (ReplaceDimF selectDim shape ('Dim 'UncheckedName 'UncheckedSize))
</span><span class="hs-identifier hs-var">coerce</span></span><span>
</span><span id="line-1227"></span><span>
</span><span id="line-1228"></span><span class="hs-comment">-- | Returns the input tensor but with 'UncheckedShape' as shape type annotation.</span><span>
</span><span id="line-1229"></span><span class="hs-comment">-- Any static information about the tensor's shape is thus erased.</span><span>
</span><span id="line-1230"></span><span class="hs-comment">-- However, the tensor's underlying data structure is not changed.</span><span>
</span><span id="line-1231"></span><span class="hs-comment">--</span><span>
</span><span id="line-1232"></span><span class="hs-comment">-- &gt;&gt;&gt; t = ones @('Gradient 'WithGradient) @('Layout 'Dense) @('Device 'CPU) @('DataType 'Float) @('Shape '[ 'Dim ('Name &quot;batch&quot;) ('Size 32), 'Dim ('Name &quot;feature&quot;) ('Size 8)])</span><span>
</span><span id="line-1233"></span><span class="hs-comment">-- &gt;&gt;&gt; :type uncheckedShape t</span><span>
</span><span id="line-1234"></span><span class="hs-comment">-- uncheckedShape t</span><span>
</span><span id="line-1235"></span><span class="hs-comment">--   :: Tensor</span><span>
</span><span id="line-1236"></span><span class="hs-comment">--        ('Gradient 'WithGradient)</span><span>
</span><span id="line-1237"></span><span class="hs-comment">--        ('Layout 'Dense)</span><span>
</span><span id="line-1238"></span><span class="hs-comment">--        ('Device 'CPU)</span><span>
</span><span id="line-1239"></span><span class="hs-comment">--        ('DataType 'Float)</span><span>
</span><span id="line-1240"></span><span class="hs-comment">--        'UncheckedShape</span><span>
</span><span id="line-1241"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#uncheckedShape"><span class="hs-identifier hs-type">uncheckedShape</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-1242"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679540096"><span class="annot"><a href="#local-6989586621679540096"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679540095"><span class="annot"><a href="#local-6989586621679540095"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679540094"><span class="annot"><a href="#local-6989586621679540094"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679540093"><span class="annot"><a href="#local-6989586621679540093"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679540092"><span class="annot"><a href="#local-6989586621679540092"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-1243"></span><span>  </span><span class="hs-comment">-- | input tensor</span><span>
</span><span id="line-1244"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540096"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540095"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540094"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540093"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540092"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1245"></span><span>  </span><span class="hs-comment">-- | tensor without checked shape</span><span>
</span><span id="line-1246"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540096"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540095"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540094"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540093"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#UncheckedShape"><span class="hs-identifier hs-type">UncheckedShape</span></a></span><span>
</span><span id="line-1247"></span><span id="uncheckedShape"><span class="annot"><span class="annottext">uncheckedShape :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType 'UncheckedShape
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#uncheckedShape"><span class="hs-identifier hs-var hs-var">uncheckedShape</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType 'UncheckedShape
</span><span class="hs-identifier hs-var">coerce</span></span><span>
</span><span id="line-1248"></span><span>
</span><span id="line-1249"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#gitHubErrorMsg"><span class="hs-identifier hs-type">gitHubErrorMsg</span></a></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">String</span></span><span>
</span><span id="line-1250"></span><span id="gitHubErrorMsg"><span class="annot"><span class="annottext">gitHubErrorMsg :: String
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#gitHubErrorMsg"><span class="hs-identifier hs-var hs-var">gitHubErrorMsg</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">String
</span><span class="hs-string">&quot;Please open a ticket on GitHub.&quot;</span></span><span>
</span><span id="line-1251"></span><span>
</span><span id="line-1252"></span><span id="local-6989586621679541146"><span id="local-6989586621679541147"><span id="local-6989586621679541148"><span id="local-6989586621679541149"><span id="local-6989586621679541150"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#isContiguous"><span class="hs-identifier hs-type">isContiguous</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-1253"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541150"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541149"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541148"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541147"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541146"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1254"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">Bool</span></span></span></span></span></span></span><span>
</span><span id="line-1255"></span><span id="isContiguous"><span class="annot"><span class="annottext">isContiguous :: Tensor gradient layout device dataType shape -&gt; Bool
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#isContiguous"><span class="hs-identifier hs-var hs-var">isContiguous</span></a></span></span><span> </span><span id="local-6989586621679540090"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679540090"><span class="hs-identifier hs-var">t</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO Bool -&gt; Bool
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO Bool -&gt; Bool) -&gt; IO Bool -&gt; Bool
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO CBool)
-&gt; Tensor gradient layout device dataType shape -&gt; IO Bool
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO CBool
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.tensor_is_contiguous</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679540090"><span class="hs-identifier hs-var">t</span></a></span><span>
</span><span id="line-1256"></span><span>
</span><span id="line-1257"></span><span id="local-6989586621679540084"><span id="local-6989586621679540085"><span id="local-6989586621679540086"><span id="local-6989586621679540087"><span id="local-6989586621679540088"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#contiguous"><span class="hs-identifier hs-type">contiguous</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-1258"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540088"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540087"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540086"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540085"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540084"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1259"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540088"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540087"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540086"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540085"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540084"><span class="hs-identifier hs-type">shape</span></a></span></span></span></span></span></span><span>
</span><span id="line-1260"></span><span id="contiguous"><span class="annot"><span class="annottext">contiguous :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#contiguous"><span class="hs-identifier hs-var hs-var">contiguous</span></a></span></span><span> </span><span id="local-6989586621679540082"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679540082"><span class="hs-identifier hs-var">t</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.tensor_contiguous</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679540082"><span class="hs-identifier hs-var">t</span></a></span><span>
</span><span id="line-1261"></span><span>
</span><span id="line-1262"></span><span id="local-6989586621679541100"><span id="local-6989586621679541101"><span id="local-6989586621679541102"><span id="local-6989586621679541103"><span id="local-6989586621679541104"><span id="local-6989586621679541105"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#withTensor"><span class="hs-identifier hs-type">withTensor</span></a></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541105"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541104"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541103"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541102"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541101"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">Ptr</span></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="hs-identifier hs-type">IO</span></span><span> </span><span class="annot"><a href="#local-6989586621679541100"><span class="hs-identifier hs-type">a</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="hs-identifier hs-type">IO</span></span><span> </span><span class="annot"><a href="#local-6989586621679541100"><span class="hs-identifier hs-type">a</span></a></span></span></span></span></span></span></span><span>
</span><span id="line-1263"></span><span id="withTensor"><span class="annot"><span class="annottext">withTensor :: Tensor gradient layout device dataType shape
-&gt; (Ptr () -&gt; IO a) -&gt; IO a
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#withTensor"><span class="hs-identifier hs-var hs-var">withTensor</span></a></span></span><span> </span><span id="local-6989586621679540079"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679540079"><span class="hs-identifier hs-var">t</span></a></span></span><span> </span><span id="local-6989586621679540078"><span class="annot"><span class="annottext">Ptr () -&gt; IO a
</span><a href="#local-6989586621679540078"><span class="hs-identifier hs-var">fn</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-1264"></span><span>  </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679540077"><span class="annot"><span class="annottext">contiguousTensor :: Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679540077"><span class="hs-identifier hs-var hs-var">contiguousTensor</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">if</span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape -&gt; Bool
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
Tensor gradient layout device dataType shape -&gt; Bool
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#isContiguous"><span class="hs-identifier hs-var">isContiguous</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679540079"><span class="hs-identifier hs-var">t</span></a></span><span> </span><span class="hs-keyword">then</span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679540079"><span class="hs-identifier hs-var">t</span></a></span><span> </span><span class="hs-keyword">else</span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#contiguous"><span class="hs-identifier hs-var">contiguous</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679540079"><span class="hs-identifier hs-var">t</span></a></span><span>
</span><span id="line-1265"></span><span>   </span><span class="hs-keyword">in</span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
-&gt; (ForeignPtr Tensor -&gt; IO a) -&gt; IO a
forall a b r. Castable a b =&gt; a -&gt; (b -&gt; IO r) -&gt; IO r
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679540077"><span class="hs-identifier hs-var">contiguousTensor</span></a></span><span> </span><span class="annot"><span class="annottext">((ForeignPtr Tensor -&gt; IO a) -&gt; IO a)
-&gt; (ForeignPtr Tensor -&gt; IO a) -&gt; IO a
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-glyph">\</span><span id="local-6989586621679540076"><span class="annot"><span class="annottext">ForeignPtr Tensor
</span><a href="#local-6989586621679540076"><span class="hs-identifier hs-var">ct</span></a></span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; (Ptr Tensor -&gt; IO a) -&gt; IO a
forall a b. ForeignPtr a -&gt; (Ptr a -&gt; IO b) -&gt; IO b
</span><span class="hs-identifier hs-var">withForeignPtr</span></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
</span><a href="#local-6989586621679540076"><span class="hs-identifier hs-var">ct</span></a></span><span> </span><span class="annot"><span class="annottext">((Ptr Tensor -&gt; IO a) -&gt; IO a) -&gt; (Ptr Tensor -&gt; IO a) -&gt; IO a
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">Ptr Tensor -&gt; IO (Ptr ())
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">Unmanaged.tensor_data_ptr</span></a></span><span> </span><span class="annot"><span class="annottext">(Ptr Tensor -&gt; IO (Ptr ()))
-&gt; (Ptr () -&gt; IO a) -&gt; Ptr Tensor -&gt; IO a
forall (m :: * -&gt; *) a b c.
Monad m =&gt;
(a -&gt; m b) -&gt; (b -&gt; m c) -&gt; a -&gt; m c
</span><span class="hs-operator hs-var">&gt;=&gt;</span></span><span> </span><span class="annot"><span class="annottext">Ptr () -&gt; IO a
</span><a href="#local-6989586621679540078"><span class="hs-identifier hs-var">fn</span></a></span><span>
</span><span id="line-1266"></span><span>
</span><span id="line-1267"></span><span class="hs-keyword">class</span><span> </span><span id="TensorLikeRaw"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorLikeRaw"><span class="hs-identifier hs-var">TensorLikeRaw</span></a></span></span><span> </span><span id="local-6989586621679541137"><span class="annot"><a href="#local-6989586621679541137"><span class="hs-identifier hs-type">a</span></a></span></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-1268"></span><span>  </span><span class="hs-comment">-- | Guesses outer dim.</span><span>
</span><span id="line-1269"></span><span>  </span><span class="hs-comment">--</span><span>
</span><span id="line-1270"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; guessDim @[[Int]] $ pure [[1, 2], [3, 4], [5, 6]]</span><span>
</span><span id="line-1271"></span><span>  </span><span class="hs-comment">-- Just 3</span><span>
</span><span id="line-1272"></span><span>  </span><span id="guessDim"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#guessDim"><span class="hs-identifier hs-type">guessDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-1273"></span><span>    </span><span class="hs-comment">-- | value</span><span>
</span><span id="line-1274"></span><span>    </span><span class="hs-comment">-- 'Nothing' if the data type wrapping 'a' is empty.</span><span>
</span><span id="line-1275"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Maybe</span></span><span> </span><span class="annot"><a href="#local-6989586621679541137"><span class="hs-identifier hs-type">a</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1276"></span><span>    </span><span class="hs-comment">-- | dimension</span><span>
</span><span id="line-1277"></span><span>    </span><span class="hs-comment">-- 'Nothing' if 'a' is a scalar.</span><span>
</span><span id="line-1278"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Maybe</span></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span>
</span><span id="line-1279"></span><span>
</span><span id="line-1280"></span><span>  </span><span class="hs-comment">-- | Guesses inner dims.</span><span>
</span><span id="line-1281"></span><span>  </span><span class="hs-comment">--</span><span>
</span><span id="line-1282"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; guessInnerDims @[[Int]] $ pure [[1, 2], [3, 4], [5, 6]]</span><span>
</span><span id="line-1283"></span><span>  </span><span class="hs-comment">-- [2]</span><span>
</span><span id="line-1284"></span><span>  </span><span id="local-6989586621679541135"><span id="guessInnerDims"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#guessInnerDims"><span class="hs-identifier hs-type">guessInnerDims</span></a></span></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-1285"></span><span>    </span><span class="annot"><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier hs-type">MonadThrow</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541135"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-1286"></span><span>    </span><span class="hs-comment">-- | value</span><span>
</span><span id="line-1287"></span><span>    </span><span class="hs-comment">-- 'Nothing' if the data type wrapping 'a' is empty.</span><span>
</span><span id="line-1288"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Maybe</span></span><span> </span><span class="annot"><a href="#local-6989586621679541137"><span class="hs-identifier hs-type">a</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1289"></span><span>    </span><span class="hs-comment">-- | inner dimensions</span><span>
</span><span id="line-1290"></span><span>    </span><span class="annot"><a href="#local-6989586621679541135"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">]</span></span><span>
</span><span id="line-1291"></span><span>
</span><span id="line-1292"></span><span>  </span><span class="hs-comment">-- | Reads a value from a tensor.</span><span>
</span><span id="line-1293"></span><span>  </span><span id="tensorPeekElemOff"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#tensorPeekElemOff"><span class="hs-identifier hs-type">tensorPeekElemOff</span></a></span></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-1294"></span><span>    </span><span class="hs-comment">-- | pointer to tensor</span><span>
</span><span id="line-1295"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Ptr</span></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1296"></span><span>    </span><span class="hs-comment">-- | offset</span><span>
</span><span id="line-1297"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1298"></span><span>    </span><span class="hs-comment">-- | tensor dimensions</span><span>
</span><span id="line-1299"></span><span>    </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">]</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1300"></span><span>    </span><span class="hs-comment">-- | value</span><span>
</span><span id="line-1301"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">IO</span></span><span> </span><span class="annot"><a href="#local-6989586621679541137"><span class="hs-identifier hs-type">a</span></a></span><span>
</span><span id="line-1302"></span><span>
</span><span id="line-1303"></span><span>  </span><span class="hs-comment">-- | Writes a value to a tensor.</span><span>
</span><span id="line-1304"></span><span>  </span><span id="tensorPokeElemOff"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#tensorPokeElemOff"><span class="hs-identifier hs-type">tensorPokeElemOff</span></a></span></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-1305"></span><span>    </span><span class="hs-comment">-- | pointer to tensor</span><span>
</span><span id="line-1306"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Ptr</span></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1307"></span><span>    </span><span class="hs-comment">-- | offset</span><span>
</span><span id="line-1308"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1309"></span><span>    </span><span class="hs-comment">-- | tensor dimensions</span><span>
</span><span id="line-1310"></span><span>    </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">]</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1311"></span><span>    </span><span class="hs-comment">-- | value</span><span>
</span><span id="line-1312"></span><span>    </span><span class="annot"><a href="#local-6989586621679541137"><span class="hs-identifier hs-type">a</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1313"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">IO</span></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-1314"></span><span>
</span><span id="line-1315"></span><span class="hs-comment">-- | Guesses dims: concatenates 'guessDim' with 'guessInnerDims'.</span><span>
</span><span id="line-1316"></span><span class="hs-comment">--</span><span>
</span><span id="line-1317"></span><span class="hs-comment">-- &gt;&gt;&gt; guessDims @[[Int]] $ pure [[1, 2], [3, 4], [5, 6]]</span><span>
</span><span id="line-1318"></span><span class="hs-comment">-- [3,2]</span><span>
</span><span id="line-1319"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#guessDims"><span class="hs-identifier hs-type">guessDims</span></a></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679541130"><span class="annot"><a href="#local-6989586621679541130"><span class="hs-identifier hs-type">a</span></a></span></span><span> </span><span id="local-6989586621679541129"><span class="annot"><a href="#local-6989586621679541129"><span class="hs-identifier hs-type">m</span></a></span></span><span class="hs-operator">.</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorLikeRaw"><span class="hs-identifier hs-type">TensorLikeRaw</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541130"><span class="hs-identifier hs-type">a</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier hs-type">MonadThrow</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541129"><span class="hs-identifier hs-type">m</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Maybe</span></span><span> </span><span class="annot"><a href="#local-6989586621679541130"><span class="hs-identifier hs-type">a</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="#local-6989586621679541129"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">]</span><span>
</span><span id="line-1320"></span><span id="guessDims"><span class="annot"><span class="annottext">guessDims :: Maybe a -&gt; m [Int]
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#guessDims"><span class="hs-identifier hs-var hs-var">guessDims</span></a></span></span><span> </span><span id="local-6989586621679540070"><span class="annot"><span class="annottext">Maybe a
</span><a href="#local-6989586621679540070"><span class="hs-identifier hs-var">x</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679540069"><span class="hs-identifier hs-var">outerDim</span></a></span><span> </span><span class="annot"><span class="annottext">[Int] -&gt; [Int] -&gt; [Int]
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">([Int] -&gt; [Int]) -&gt; m [Int] -&gt; m [Int]
forall (f :: * -&gt; *) a b. Functor f =&gt; (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;$&gt;</span></span><span> </span><span class="annot"><span class="annottext">Maybe a -&gt; m [Int]
forall a (m :: * -&gt; *).
(TensorLikeRaw a, MonadThrow m) =&gt;
Maybe a -&gt; m [Int]
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#guessInnerDims"><span class="hs-identifier hs-var">guessInnerDims</span></a></span><span> </span><span class="annot"><span class="annottext">Maybe a
</span><a href="#local-6989586621679540070"><span class="hs-identifier hs-var">x</span></a></span><span>
</span><span id="line-1321"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-1322"></span><span>    </span><span id="local-6989586621679540069"><span class="annot"><span class="annottext">outerDim :: [Int]
</span><a href="#local-6989586621679540069"><span class="hs-identifier hs-var hs-var">outerDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Maybe Int -&gt; [Int]
forall a. Maybe a -&gt; [a]
</span><span class="hs-identifier hs-var">maybeToList</span></span><span> </span><span class="annot"><span class="annottext">(Maybe Int -&gt; [Int]) -&gt; Maybe Int -&gt; [Int]
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">Maybe a -&gt; Maybe Int
forall a. TensorLikeRaw a =&gt; Maybe a -&gt; Maybe Int
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#guessDim"><span class="hs-identifier hs-var">guessDim</span></a></span><span> </span><span class="annot"><span class="annottext">Maybe a
</span><a href="#local-6989586621679540070"><span class="hs-identifier hs-var">x</span></a></span><span>
</span><span id="line-1323"></span><span>
</span><span id="line-1324"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#unexpectedDimsError"><span class="hs-identifier hs-type">unexpectedDimsError</span></a></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679541042"><span class="annot"><a href="#local-6989586621679541042"><span class="hs-identifier hs-type">a</span></a></span></span><span> </span><span id="local-6989586621679541041"><span class="annot"><a href="#local-6989586621679541041"><span class="hs-identifier hs-type">m</span></a></span></span><span> </span><span id="local-6989586621679541040"><span class="annot"><a href="#local-6989586621679541040"><span class="hs-identifier hs-type">b</span></a></span></span><span class="hs-operator">.</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorLikeRaw"><span class="hs-identifier hs-type">TensorLikeRaw</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541042"><span class="hs-identifier hs-type">a</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier hs-type">MonadThrow</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541041"><span class="hs-identifier hs-type">m</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">]</span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Maybe</span></span><span> </span><span class="annot"><a href="#local-6989586621679541042"><span class="hs-identifier hs-type">a</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="#local-6989586621679541041"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541040"><span class="hs-identifier hs-type">b</span></a></span><span>
</span><span id="line-1325"></span><span id="unexpectedDimsError"><span class="annot"><span class="annottext">unexpectedDimsError :: [Int] -&gt; Maybe a -&gt; m b
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#unexpectedDimsError"><span class="hs-identifier hs-var hs-var">unexpectedDimsError</span></a></span></span><span> </span><span id="local-6989586621679540067"><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679540067"><span class="hs-identifier hs-var">dims'</span></a></span></span><span> </span><span id="local-6989586621679540066"><span class="annot"><span class="annottext">Maybe a
</span><a href="#local-6989586621679540066"><span class="hs-identifier hs-var">x</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-1326"></span><span>  </span><span id="local-6989586621679540065"><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679540065"><span class="hs-identifier hs-var">expected</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">Maybe a -&gt; m [Int]
forall a (m :: * -&gt; *).
(TensorLikeRaw a, MonadThrow m) =&gt;
Maybe a -&gt; m [Int]
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#guessDims"><span class="hs-identifier hs-var">guessDims</span></a></span><span> </span><span class="annot"><span class="annottext">Maybe a
</span><a href="#local-6989586621679540066"><span class="hs-identifier hs-var">x</span></a></span><span>
</span><span id="line-1327"></span><span>  </span><span class="annot"><span class="annottext">String -&gt; m b
forall a. HasCallStack =&gt; String -&gt; a
</span><span class="hs-identifier hs-var">error</span></span><span> </span><span class="annot"><span class="annottext">(String -&gt; m b) -&gt; String -&gt; m b
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">String
</span><span class="hs-string">&quot;Expected shape to be &quot;</span></span><span> </span><span class="annot"><span class="annottext">String -&gt; ShowS
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">[Int] -&gt; String
forall a. Show a =&gt; a -&gt; String
</span><span class="hs-identifier hs-var">show</span></span><span> </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679540065"><span class="hs-identifier hs-var">expected</span></a></span><span> </span><span class="annot"><span class="annottext">String -&gt; ShowS
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">String
</span><span class="hs-string">&quot; got: &quot;</span></span><span> </span><span class="annot"><span class="annottext">String -&gt; ShowS
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">[Int] -&gt; String
forall a. Show a =&gt; a -&gt; String
</span><span class="hs-identifier hs-var">show</span></span><span> </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679540067"><span class="hs-identifier hs-var">dims'</span></a></span><span>
</span><span id="line-1328"></span><span>
</span><span id="line-1329"></span><span class="hs-keyword">class</span><span> </span><span id="TensorLike"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorLike"><span class="hs-identifier hs-var">TensorLike</span></a></span></span><span> </span><span id="local-6989586621679541121"><span class="annot"><a href="#local-6989586621679541121"><span class="hs-identifier hs-type">a</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679541120"><span class="annot"><a href="#local-6989586621679541120"><span class="hs-identifier hs-type">dType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier hs-type">DType</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679541119"><span class="annot"><a href="#local-6989586621679541119"><span class="hs-identifier hs-type">dims</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">|</span><span> </span><span class="annot"><a href="#local-6989586621679541121"><span class="hs-identifier hs-type">a</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="#local-6989586621679541119"><span class="hs-identifier hs-type">dims</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679541121"><span class="hs-identifier hs-type">a</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="#local-6989586621679541120"><span class="hs-identifier hs-type">dType</span></a></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-1330"></span><span>  </span><span class="hs-comment">-- | Creates a tensor from a 'TensorLike' value.</span><span>
</span><span id="line-1331"></span><span>  </span><span class="hs-comment">--</span><span>
</span><span id="line-1332"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; t &lt;- sToTensor (SGradient SWithoutGradient) (SLayout SDense) (SDevice SCPU) ([(1, 2), (3, 4), (5, 6)] :: [(Int, Int)])</span><span>
</span><span id="line-1333"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; t</span><span>
</span><span id="line-1334"></span><span>  </span><span class="hs-comment">-- Tensor Int64 [3,2] [[ 1,  2],</span><span>
</span><span id="line-1335"></span><span>  </span><span class="hs-comment">--                     [ 3,  4],</span><span>
</span><span id="line-1336"></span><span>  </span><span class="hs-comment">--                     [ 5,  6]]</span><span>
</span><span id="line-1337"></span><span>  </span><span class="hs-comment">-- &gt;&gt;&gt; :type t</span><span>
</span><span id="line-1338"></span><span>  </span><span class="hs-comment">-- t :: Tensor</span><span>
</span><span id="line-1339"></span><span>  </span><span class="hs-comment">--        ('Gradient 'WithoutGradient)</span><span>
</span><span id="line-1340"></span><span>  </span><span class="hs-comment">--        ('Layout 'Dense)</span><span>
</span><span id="line-1341"></span><span>  </span><span class="hs-comment">--        ('Device 'CPU)</span><span>
</span><span id="line-1342"></span><span>  </span><span class="hs-comment">--        ('DataType 'Int64)</span><span>
</span><span id="line-1343"></span><span>  </span><span class="hs-comment">--        ('Shape</span><span>
</span><span id="line-1344"></span><span>  </span><span class="hs-comment">--           '[ 'Dim ('Name &quot;*&quot;) 'UncheckedSize, 'Dim ('Name &quot;*&quot;) ('Size 2)])</span><span>
</span><span id="line-1345"></span><span>  </span><span id="sToTensor"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#sToTensor"><span class="hs-identifier hs-type">sToTensor</span></a></span></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-1346"></span><span>    </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679541116"><span class="annot"><a href="#local-6989586621679541116"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679541115"><span class="annot"><a href="#local-6989586621679541115"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679541114"><span class="annot"><a href="#local-6989586621679541114"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679541117"><span class="annot"><a href="#local-6989586621679541117"><span class="hs-identifier hs-type">m</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-1347"></span><span>    </span><span class="annot"><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier hs-type">MonadThrow</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541117"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-1348"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier hs-type">SGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541116"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1349"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#SLayout"><span class="hs-identifier hs-type">SLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541115"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1350"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#SDevice"><span class="hs-identifier hs-type">SDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541114"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1351"></span><span>    </span><span class="annot"><a href="#local-6989586621679541121"><span class="hs-identifier hs-type">a</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1352"></span><span>    </span><span class="annot"><a href="#local-6989586621679541117"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541116"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541115"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541114"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541120"><span class="hs-identifier hs-type">dType</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541119"><span class="hs-identifier hs-type">dims</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-1353"></span><span>
</span><span id="line-1354"></span><span>  </span><span class="hs-comment">-- | Creates a 'TensorLike' from a tensor.</span><span>
</span><span id="line-1355"></span><span>  </span><span id="fromTensor"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#fromTensor"><span class="hs-identifier hs-type">fromTensor</span></a></span></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-1356"></span><span>    </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679541077"><span class="annot"><a href="#local-6989586621679541077"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679541076"><span class="annot"><a href="#local-6989586621679541076"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679541075"><span class="annot"><a href="#local-6989586621679541075"><span class="hs-identifier hs-type">device</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-1357"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541077"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541076"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541075"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541120"><span class="hs-identifier hs-type">dType</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541119"><span class="hs-identifier hs-type">dims</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1358"></span><span>    </span><span class="annot"><a href="#local-6989586621679541121"><span class="hs-identifier hs-type">a</span></a></span><span>
</span><span id="line-1359"></span><span>
</span><span id="line-1360"></span><span class="hs-comment">-- | Non-singleton version of 'sToTensor'.</span><span>
</span><span id="line-1361"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#toTensor"><span class="hs-identifier hs-type">toTensor</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-1362"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679540061"><span class="annot"><a href="#local-6989586621679540061"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679540060"><span class="annot"><a href="#local-6989586621679540060"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679540059"><span class="annot"><a href="#local-6989586621679540059"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679540058"><span class="annot"><a href="#local-6989586621679540058"><span class="hs-identifier hs-type">a</span></a></span></span><span> </span><span id="local-6989586621679540057"><span class="annot"><a href="#local-6989586621679540057"><span class="hs-identifier hs-type">dType</span></a></span></span><span> </span><span id="local-6989586621679540056"><span class="annot"><a href="#local-6989586621679540056"><span class="hs-identifier hs-type">dims</span></a></span></span><span> </span><span id="local-6989586621679540055"><span class="annot"><a href="#local-6989586621679540055"><span class="hs-identifier hs-type">m</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-1363"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorLike"><span class="hs-identifier hs-type">TensorLike</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540058"><span class="hs-identifier hs-type">a</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540057"><span class="hs-identifier hs-type">dType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540056"><span class="hs-identifier hs-type">dims</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-1364"></span><span>    </span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-type">SingI</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540061"><span class="hs-identifier hs-type">gradient</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-1365"></span><span>    </span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-type">SingI</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540060"><span class="hs-identifier hs-type">layout</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-1366"></span><span>    </span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-type">SingI</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540059"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-1367"></span><span>    </span><span class="annot"><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier hs-type">MonadThrow</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540055"><span class="hs-identifier hs-type">m</span></a></span><span>
</span><span id="line-1368"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-1369"></span><span>  </span><span class="annot"><a href="#local-6989586621679540058"><span class="hs-identifier hs-type">a</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1370"></span><span>  </span><span class="annot"><a href="#local-6989586621679540055"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540061"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540060"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540059"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540057"><span class="hs-identifier hs-type">dType</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540056"><span class="hs-identifier hs-type">dims</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-1371"></span><span id="toTensor"><span class="annot"><span class="annottext">toTensor :: a
-&gt; m (Tensor
        gradient layout device ('DataType dType) ('Shape dims))
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#toTensor"><span class="hs-identifier hs-var hs-var">toTensor</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; a
-&gt; m (Tensor
        gradient layout device ('DataType dType) ('Shape dims))
forall a (dType :: DType) (dims :: [Dim (Name Symbol) (Size Nat)])
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (m :: * -&gt; *).
(TensorLike a dType dims, MonadThrow m) =&gt;
SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; a
-&gt; m (Tensor
        gradient layout device ('DataType dType) ('Shape dims))
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sToTensor"><span class="hs-identifier hs-var">sToTensor</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SingI gradient =&gt; Sing gradient
forall k (a :: k). SingI a =&gt; Sing a
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">sing</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679540061"><span class="hs-identifier hs-type">gradient</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SingI layout =&gt; Sing layout
forall k (a :: k). SingI a =&gt; Sing a
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">sing</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679540060"><span class="hs-identifier hs-type">layout</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SingI device =&gt; Sing device
forall k (a :: k). SingI a =&gt; Sing a
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">sing</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679540059"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-1372"></span><span>
</span><span id="line-1373"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#sToTensorRaw"><span class="hs-identifier hs-type">sToTensorRaw</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-1374"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679541066"><span class="annot"><a href="#local-6989586621679541066"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679541065"><span class="annot"><a href="#local-6989586621679541065"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679541064"><span class="annot"><a href="#local-6989586621679541064"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679541070"><span class="annot"><a href="#local-6989586621679541070"><span class="hs-identifier hs-type">a</span></a></span></span><span> </span><span id="local-6989586621679541069"><span class="annot"><a href="#local-6989586621679541069"><span class="hs-identifier hs-type">dType</span></a></span></span><span> </span><span id="local-6989586621679541068"><span class="annot"><a href="#local-6989586621679541068"><span class="hs-identifier hs-type">dims</span></a></span></span><span> </span><span id="local-6989586621679541067"><span class="annot"><a href="#local-6989586621679541067"><span class="hs-identifier hs-type">m</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-1375"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorLike"><span class="hs-identifier hs-type">TensorLike</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541070"><span class="hs-identifier hs-type">a</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541069"><span class="hs-identifier hs-type">dType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541068"><span class="hs-identifier hs-type">dims</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorLikeRaw"><span class="hs-identifier hs-type">TensorLikeRaw</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541070"><span class="hs-identifier hs-type">a</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-type">SingI</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541069"><span class="hs-identifier hs-type">dType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier hs-type">MonadThrow</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541067"><span class="hs-identifier hs-type">m</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-1376"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier hs-type">SGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541066"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1377"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#SLayout"><span class="hs-identifier hs-type">SLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541065"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1378"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#SDevice"><span class="hs-identifier hs-type">SDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541064"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1379"></span><span>  </span><span class="annot"><a href="#local-6989586621679541070"><span class="hs-identifier hs-type">a</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1380"></span><span>  </span><span class="annot"><a href="#local-6989586621679541067"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541066"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541065"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541064"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541069"><span class="hs-identifier hs-type">dType</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541068"><span class="hs-identifier hs-type">dims</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-1381"></span><span id="sToTensorRaw"><span class="annot"><span class="annottext">sToTensorRaw :: SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; a
-&gt; m (Tensor
        gradient layout device ('DataType dType) ('Shape dims))
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sToTensorRaw"><span class="hs-identifier hs-var hs-var">sToTensorRaw</span></a></span></span><span> </span><span id="local-6989586621679540053"><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679540053"><span class="hs-identifier hs-var">gradient'</span></a></span></span><span> </span><span id="local-6989586621679540052"><span class="annot"><span class="annottext">SLayout layout
</span><a href="#local-6989586621679540052"><span class="hs-identifier hs-var">layout</span></a></span></span><span> </span><span id="local-6989586621679540051"><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679540051"><span class="hs-identifier hs-var">device</span></a></span></span><span> </span><span id="local-6989586621679540050"><span class="annot"><span class="annottext">a
</span><a href="#local-6989586621679540050"><span class="hs-identifier hs-var">x</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-1382"></span><span>  </span><span id="local-6989586621679540049"><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679540049"><span class="hs-identifier hs-var">dims'</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">Maybe a -&gt; m [Int]
forall a (m :: * -&gt; *).
(TensorLikeRaw a, MonadThrow m) =&gt;
Maybe a -&gt; m [Int]
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#guessDims"><span class="hs-identifier hs-var">guessDims</span></a></span><span> </span><span class="annot"><span class="annottext">(Maybe a -&gt; m [Int]) -&gt; Maybe a -&gt; m [Int]
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">a -&gt; Maybe a
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">a
</span><a href="#local-6989586621679540050"><span class="hs-identifier hs-var">x</span></a></span><span>
</span><span id="line-1383"></span><span>
</span><span id="line-1384"></span><span>  </span><span class="annot"><span class="annottext">Tensor gradient layout device ('DataType dType) ('Shape dims)
-&gt; m (Tensor
        gradient layout device ('DataType dType) ('Shape dims))
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">(Tensor gradient layout device ('DataType dType) ('Shape dims)
 -&gt; m (Tensor
         gradient layout device ('DataType dType) ('Shape dims)))
-&gt; Tensor gradient layout device ('DataType dType) ('Shape dims)
-&gt; m (Tensor
        gradient layout device ('DataType dType) ('Shape dims))
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-1385"></span><span>    </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device ('DataType dType) ('Shape dims))
-&gt; Tensor gradient layout device ('DataType dType) ('Shape dims)
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device ('DataType dType) ('Shape dims))
 -&gt; Tensor gradient layout device ('DataType dType) ('Shape dims))
-&gt; IO
     (Tensor gradient layout device ('DataType dType) ('Shape dims))
-&gt; Tensor gradient layout device ('DataType dType) ('Shape dims)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-1386"></span><span>      </span><span id="local-6989586621679540048"><span class="annot"><span class="annottext">Tensor gradient layout Any ('DataType dType) ('Shape dims)
</span><a href="#local-6989586621679540048"><span class="hs-identifier hs-var">t</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; Tensor gradient layout Any ('DataType dType) ('Shape dims)
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
ForeignPtr Tensor -&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#UnsafeTensor"><span class="hs-identifier hs-var">UnsafeTensor</span></a></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; Tensor gradient layout Any ('DataType dType) ('Shape dims))
-&gt; IO (ForeignPtr Tensor)
-&gt; IO (Tensor gradient layout Any ('DataType dType) ('Shape dims))
forall (f :: * -&gt; *) a b. Functor f =&gt; (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;$&gt;</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr IntArray
 -&gt; ForeignPtr TensorOptions -&gt; IO (ForeignPtr Tensor))
-&gt; [Int] -&gt; TensorOptions -&gt; IO (ForeignPtr Tensor)
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr IntArray
-&gt; ForeignPtr TensorOptions -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.empty_lo</span></a></span><span> </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679540049"><span class="hs-identifier hs-var">dims'</span></a></span><span> </span><span class="annot"><span class="annottext">TensorOptions
</span><a href="#local-6989586621679540046"><span class="hs-identifier hs-var">opts</span></a></span><span>
</span><span id="line-1387"></span><span>      </span><span class="annot"><span class="annottext">Tensor gradient layout Any ('DataType dType) ('Shape dims)
-&gt; (Ptr () -&gt; IO ()) -&gt; IO ()
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]) a.
Tensor gradient layout device dataType shape
-&gt; (Ptr () -&gt; IO a) -&gt; IO a
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#withTensor"><span class="hs-identifier hs-var">withTensor</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout Any ('DataType dType) ('Shape dims)
</span><a href="#local-6989586621679540048"><span class="hs-identifier hs-var">t</span></a></span><span> </span><span class="annot"><span class="annottext">((Ptr () -&gt; IO ()) -&gt; IO ()) -&gt; (Ptr () -&gt; IO ()) -&gt; IO ()
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-glyph">\</span><span id="local-6989586621679540045"><span class="annot"><span class="annottext">Ptr ()
</span><a href="#local-6989586621679540045"><span class="hs-identifier hs-var">ptr</span></a></span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1388"></span><span>        </span><span class="annot"><span class="annottext">Ptr () -&gt; Int -&gt; [Int] -&gt; a -&gt; IO ()
forall a. TensorLikeRaw a =&gt; Ptr () -&gt; Int -&gt; [Int] -&gt; a -&gt; IO ()
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#tensorPokeElemOff"><span class="hs-identifier hs-var">tensorPokeElemOff</span></a></span><span> </span><span class="annot"><span class="annottext">Ptr ()
</span><a href="#local-6989586621679540045"><span class="hs-identifier hs-var">ptr</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">0</span></span><span> </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679540049"><span class="hs-identifier hs-var">dims'</span></a></span><span> </span><span class="annot"><span class="annottext">a
</span><a href="#local-6989586621679540050"><span class="hs-identifier hs-var">x</span></a></span><span>
</span><span id="line-1389"></span><span>      </span><span class="annot"><span class="annottext">SDevice device
-&gt; Tensor gradient layout Any ('DataType dType) ('Shape dims)
-&gt; IO
     (Tensor gradient layout device ('DataType dType) ('Shape dims))
forall (m :: * -&gt; *) (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (device' :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
MonadThrow m =&gt;
SDevice device
-&gt; Tensor gradient layout device' dataType shape
-&gt; m (Tensor gradient layout device dataType shape)
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sSetDevice"><span class="hs-identifier hs-var">sSetDevice</span></a></span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679540051"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout Any ('DataType dType) ('Shape dims)
</span><a href="#local-6989586621679540048"><span class="hs-identifier hs-var">t</span></a></span><span>
</span><span id="line-1390"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-1391"></span><span>    </span><span id="local-6989586621679540046"><span class="annot"><span class="annottext">opts :: TensorOptions
</span><a href="#local-6989586621679540046"><span class="hs-identifier hs-var hs-var">opts</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SGradient gradient
-&gt; SLayout layout
-&gt; SDevice ('Device 'CPU)
-&gt; SDataType ('DataType dType)
-&gt; TensorOptions
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType).
SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; TensorOptions
</span><a href="Torch.GraduallyTyped.Internal.TensorOptions.html#tensorOptions"><span class="hs-identifier hs-var">tensorOptions</span></a></span><span> </span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679540053"><span class="hs-identifier hs-var">gradient'</span></a></span><span> </span><span class="annot"><span class="annottext">SLayout layout
</span><a href="#local-6989586621679540052"><span class="hs-identifier hs-var">layout</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SDeviceType 'CPU -&gt; SDevice ('Device 'CPU)
forall (deviceType :: DeviceType Nat).
SDeviceType deviceType -&gt; SDevice ('Device deviceType)
</span><a href="Torch.GraduallyTyped.Device.html#SDevice"><span class="hs-identifier hs-var">SDevice</span></a></span><span> </span><span class="annot"><span class="annottext">SDeviceType 'CPU
</span><a href="Torch.GraduallyTyped.Device.html#SCPU"><span class="hs-identifier hs-var">SCPU</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SingI ('DataType dType) =&gt; Sing ('DataType dType)
forall k (a :: k). SingI a =&gt; Sing a
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">sing</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541069"><span class="hs-identifier hs-type">dType</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-1392"></span><span>
</span><span id="line-1393"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#fromTensorRaw"><span class="hs-identifier hs-type">fromTensorRaw</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-1394"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679541057"><span class="annot"><a href="#local-6989586621679541057"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679541056"><span class="annot"><a href="#local-6989586621679541056"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679541055"><span class="annot"><a href="#local-6989586621679541055"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679541060"><span class="annot"><a href="#local-6989586621679541060"><span class="hs-identifier hs-type">a</span></a></span></span><span> </span><span id="local-6989586621679541059"><span class="annot"><a href="#local-6989586621679541059"><span class="hs-identifier hs-type">dType</span></a></span></span><span> </span><span id="local-6989586621679541058"><span class="annot"><a href="#local-6989586621679541058"><span class="hs-identifier hs-type">dims</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-1395"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorLike"><span class="hs-identifier hs-type">TensorLike</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541060"><span class="hs-identifier hs-type">a</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541059"><span class="hs-identifier hs-type">dType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541058"><span class="hs-identifier hs-type">dims</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorLikeRaw"><span class="hs-identifier hs-type">TensorLikeRaw</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541060"><span class="hs-identifier hs-type">a</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetDims"><span class="hs-identifier hs-type">SGetDims</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541058"><span class="hs-identifier hs-type">dims</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-1396"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541057"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541056"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541055"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541059"><span class="hs-identifier hs-type">dType</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679541058"><span class="hs-identifier hs-type">dims</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1397"></span><span>  </span><span class="annot"><a href="#local-6989586621679541060"><span class="hs-identifier hs-type">a</span></a></span><span>
</span><span id="line-1398"></span><span id="fromTensorRaw"><span class="annot"><span class="annottext">fromTensorRaw :: Tensor gradient layout device ('DataType dType) ('Shape dims) -&gt; a
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#fromTensorRaw"><span class="hs-identifier hs-var hs-var">fromTensorRaw</span></a></span></span><span> </span><span id="local-6989586621679540043"><span class="annot"><span class="annottext">Tensor gradient layout device ('DataType dType) ('Shape dims)
</span><a href="#local-6989586621679540043"><span class="hs-identifier hs-var">t</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-1399"></span><span>  </span><span class="annot"><span class="annottext">IO a -&gt; a
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO a -&gt; a) -&gt; IO a -&gt; a
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-1400"></span><span>    </span><span class="annot"><span class="annottext">SDevice ('Device 'CPU)
-&gt; Tensor gradient layout device ('DataType dType) ('Shape dims)
-&gt; IO
     (Tensor
        gradient layout ('Device 'CPU) ('DataType dType) ('Shape dims))
forall (m :: * -&gt; *) (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (device' :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
MonadThrow m =&gt;
SDevice device
-&gt; Tensor gradient layout device' dataType shape
-&gt; m (Tensor gradient layout device dataType shape)
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sSetDevice"><span class="hs-identifier hs-var">sSetDevice</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SDeviceType 'CPU -&gt; SDevice ('Device 'CPU)
forall (deviceType :: DeviceType Nat).
SDeviceType deviceType -&gt; SDevice ('Device deviceType)
</span><a href="Torch.GraduallyTyped.Device.html#SDevice"><span class="hs-identifier hs-var">SDevice</span></a></span><span> </span><span class="annot"><span class="annottext">SDeviceType 'CPU
</span><a href="Torch.GraduallyTyped.Device.html#SCPU"><span class="hs-identifier hs-var">SCPU</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device ('DataType dType) ('Shape dims)
</span><a href="#local-6989586621679540043"><span class="hs-identifier hs-var">t</span></a></span><span>
</span><span id="line-1401"></span><span>      </span><span class="annot"><span class="annottext">IO
  (Tensor
     gradient layout ('Device 'CPU) ('DataType dType) ('Shape dims))
-&gt; (Tensor
      gradient layout ('Device 'CPU) ('DataType dType) ('Shape dims)
    -&gt; IO a)
-&gt; IO a
forall (m :: * -&gt; *) a b. Monad m =&gt; m a -&gt; (a -&gt; m b) -&gt; m b
</span><span class="hs-operator hs-var">&gt;&gt;=</span></span><span> </span><span class="annot"><span class="annottext">(Tensor
   gradient layout ('Device 'CPU) ('DataType dType) ('Shape dims)
 -&gt; (Ptr () -&gt; IO a) -&gt; IO a)
-&gt; (Ptr () -&gt; IO a)
-&gt; Tensor
     gradient layout ('Device 'CPU) ('DataType dType) ('Shape dims)
-&gt; IO a
forall a b c. (a -&gt; b -&gt; c) -&gt; b -&gt; a -&gt; c
</span><span class="hs-identifier hs-var">flip</span></span><span> </span><span class="annot"><span class="annottext">Tensor
  gradient layout ('Device 'CPU) ('DataType dType) ('Shape dims)
-&gt; (Ptr () -&gt; IO a) -&gt; IO a
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]) a.
Tensor gradient layout device dataType shape
-&gt; (Ptr () -&gt; IO a) -&gt; IO a
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#withTensor"><span class="hs-identifier hs-var">withTensor</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">\</span><span id="local-6989586621679540041"><span class="annot"><span class="annottext">Ptr ()
</span><a href="#local-6989586621679540041"><span class="hs-identifier hs-var">ptr</span></a></span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">Ptr () -&gt; Int -&gt; [Int] -&gt; IO a
forall a. TensorLikeRaw a =&gt; Ptr () -&gt; Int -&gt; [Int] -&gt; IO a
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#tensorPeekElemOff"><span class="hs-identifier hs-var">tensorPeekElemOff</span></a></span><span> </span><span class="annot"><span class="annottext">Ptr ()
</span><a href="#local-6989586621679540041"><span class="hs-identifier hs-var">ptr</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">0</span></span><span> </span><span class="annot"><span class="annottext">([Int] -&gt; IO a) -&gt; [Int] -&gt; IO a
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">Integer -&gt; Int
forall a. Num a =&gt; Integer -&gt; a
</span><span class="hs-identifier hs-var">fromInteger</span></span><span> </span><span class="annot"><span class="annottext">(Integer -&gt; Int)
-&gt; (Dim String Integer -&gt; Integer) -&gt; Dim String Integer -&gt; Int
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Dim String Integer -&gt; Integer
forall name size. Dim name size -&gt; size
</span><a href="Torch.GraduallyTyped.Shape.Type.html#dimSize"><span class="hs-identifier hs-var hs-var">dimSize</span></a></span><span> </span><span class="annot"><span class="annottext">(Dim String Integer -&gt; Int) -&gt; [Dim String Integer] -&gt; [Int]
forall (f :: * -&gt; *) a b. Functor f =&gt; (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;$&gt;</span></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device ('DataType dType) ('Shape dims)
-&gt; [Dim String Integer]
forall (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType).
SGetShape shape =&gt;
Tensor gradient layout device dataType shape
-&gt; [Dim String Integer]
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#getDims"><span class="hs-identifier hs-var">getDims</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device ('DataType dType) ('Shape dims)
</span><a href="#local-6989586621679540043"><span class="hs-identifier hs-var">t</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-1402"></span><span>
</span><span id="line-1403"></span><span class="hs-keyword">instance</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorLike"><span class="hs-identifier hs-type">TensorLike</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Bool</span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#Bool"><span class="hs-identifier hs-type">Bool</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="hs-special">]</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-1404"></span><span>  </span><span id="local-6989586621679540036"><span class="annot"><span class="annottext">sToTensor :: SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; Bool
-&gt; m (Tensor gradient layout device ('DataType 'Bool) ('Shape '[]))
</span><a href="#local-6989586621679540036"><span class="hs-identifier hs-var hs-var hs-var hs-var">sToTensor</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; Bool
-&gt; m (Tensor gradient layout device ('DataType 'Bool) ('Shape '[]))
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat)) a
       (dType :: DType) (dims :: [Dim (Name Symbol) (Size Nat)])
       (m :: * -&gt; *).
(TensorLike a dType dims, TensorLikeRaw a, SingI dType,
 MonadThrow m) =&gt;
SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; a
-&gt; m (Tensor
        gradient layout device ('DataType dType) ('Shape dims))
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sToTensorRaw"><span class="hs-identifier hs-var">sToTensorRaw</span></a></span><span>
</span><span id="line-1405"></span><span>  </span><span id="local-6989586621679540035"><span class="annot"><span class="annottext">fromTensor :: Tensor gradient layout device ('DataType 'Bool) ('Shape '[])
-&gt; Bool
</span><a href="#local-6989586621679540035"><span class="hs-identifier hs-var hs-var hs-var hs-var">fromTensor</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device ('DataType 'Bool) ('Shape '[])
-&gt; Bool
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat)) a
       (dType :: DType) (dims :: [Dim (Name Symbol) (Size Nat)]).
(TensorLike a dType dims, TensorLikeRaw a, SGetDims dims) =&gt;
Tensor gradient layout device ('DataType dType) ('Shape dims) -&gt; a
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#fromTensorRaw"><span class="hs-identifier hs-var">fromTensorRaw</span></a></span><span>
</span><span id="line-1406"></span><span>
</span><span id="line-1407"></span><span class="hs-keyword">instance</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorLikeRaw"><span class="hs-identifier hs-type">TensorLikeRaw</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Bool</span></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-1408"></span><span>  </span><span id="local-6989586621679540029"><span class="annot"><span class="annottext">guessDim :: Maybe Bool -&gt; Maybe Int
</span><a href="#local-6989586621679540029"><span class="hs-identifier hs-var hs-var hs-var hs-var">guessDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Maybe Int -&gt; Maybe Bool -&gt; Maybe Int
forall a b. a -&gt; b -&gt; a
</span><span class="hs-identifier hs-var">const</span></span><span> </span><span class="annot"><span class="annottext">Maybe Int
forall (f :: * -&gt; *) a. Alternative f =&gt; f a
</span><span class="hs-identifier hs-var">empty</span></span><span>
</span><span id="line-1409"></span><span>
</span><span id="line-1410"></span><span>  </span><span id="local-6989586621679540028"><span class="annot"><span class="annottext">guessInnerDims :: Maybe Bool -&gt; m [Int]
</span><a href="#local-6989586621679540028"><span class="hs-identifier hs-var hs-var hs-var hs-var">guessInnerDims</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">m [Int] -&gt; Maybe Bool -&gt; m [Int]
forall a b. a -&gt; b -&gt; a
</span><span class="hs-identifier hs-var">const</span></span><span> </span><span class="annot"><span class="annottext">(m [Int] -&gt; Maybe Bool -&gt; m [Int])
-&gt; m [Int] -&gt; Maybe Bool -&gt; m [Int]
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">[Int] -&gt; m [Int]
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">[Int]
forall a. Monoid a =&gt; a
</span><span class="hs-identifier hs-var">mempty</span></span><span>
</span><span id="line-1411"></span><span>
</span><span id="line-1412"></span><span>  </span><span id="local-6989586621679540027"><span class="annot"><span class="annottext">tensorPeekElemOff :: Ptr () -&gt; Int -&gt; [Int] -&gt; IO Bool
</span><a href="#local-6989586621679540027"><span class="hs-identifier hs-var hs-var hs-var hs-var">tensorPeekElemOff</span></a></span></span><span> </span><span id="local-6989586621679540026"><span class="annot"><span class="annottext">Ptr ()
</span><a href="#local-6989586621679540026"><span class="hs-identifier hs-var">ptr</span></a></span></span><span> </span><span id="local-6989586621679540025"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679540025"><span class="hs-identifier hs-var">offset</span></a></span></span><span> </span><span class="hs-special">[</span><span class="hs-special">]</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Ptr Word8 -&gt; Int -&gt; IO Word8
forall a. Storable a =&gt; Ptr a -&gt; Int -&gt; IO a
</span><span class="hs-identifier hs-var">peekElemOff</span></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-identifier hs-type">Word8</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Ptr () -&gt; Ptr Word8
forall a b. Ptr a -&gt; Ptr b
</span><span class="hs-identifier hs-var">castPtr</span></span><span> </span><span class="annot"><span class="annottext">Ptr ()
</span><a href="#local-6989586621679540026"><span class="hs-identifier hs-var">ptr</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679540025"><span class="hs-identifier hs-var">offset</span></a></span><span> </span><span class="annot"><span class="annottext">IO Word8 -&gt; (Word8 -&gt; Bool) -&gt; IO Bool
forall (f :: * -&gt; *) a b. Functor f =&gt; f a -&gt; (a -&gt; b) -&gt; f b
</span><span class="hs-operator hs-var">&lt;&amp;&gt;</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Word8 -&gt; Word8 -&gt; Bool
forall a. Eq a =&gt; a -&gt; a -&gt; Bool
</span><span class="hs-operator hs-var">==</span></span><span> </span><span class="annot"><span class="annottext">Word8
</span><span class="hs-number">1</span></span><span class="hs-special">)</span><span>
</span><span id="line-1413"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#tensorPeekElemOff"><span class="hs-identifier hs-var">tensorPeekElemOff</span></a></span><span> </span><span class="annot"><span class="annottext">Ptr ()
</span><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-identifier">_</span></span><span> </span><span id="local-6989586621679540024"><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679540024"><span class="hs-identifier hs-var">dims'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">[Int] -&gt; Maybe Bool -&gt; IO Bool
forall a (m :: * -&gt; *) b.
(TensorLikeRaw a, MonadThrow m) =&gt;
[Int] -&gt; Maybe a -&gt; m b
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#unexpectedDimsError"><span class="hs-identifier hs-var">unexpectedDimsError</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-identifier hs-type">Bool</span></span><span> </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679540024"><span class="hs-identifier hs-var">dims'</span></a></span><span> </span><span class="annot"><span class="annottext">Maybe Bool
forall (f :: * -&gt; *) a. Alternative f =&gt; f a
</span><span class="hs-identifier hs-var">empty</span></span><span>
</span><span id="line-1414"></span><span>
</span><span id="line-1415"></span><span>  </span><span id="local-6989586621679540023"><span class="annot"><span class="annottext">tensorPokeElemOff :: Ptr () -&gt; Int -&gt; [Int] -&gt; Bool -&gt; IO ()
</span><a href="#local-6989586621679540023"><span class="hs-identifier hs-var hs-var hs-var hs-var">tensorPokeElemOff</span></a></span></span><span> </span><span id="local-6989586621679540022"><span class="annot"><span class="annottext">Ptr ()
</span><a href="#local-6989586621679540022"><span class="hs-identifier hs-var">ptr</span></a></span></span><span> </span><span id="local-6989586621679540021"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679540021"><span class="hs-identifier hs-var">offset</span></a></span></span><span> </span><span class="hs-special">[</span><span class="hs-special">]</span><span> </span><span id="local-6989586621679540020"><span class="annot"><span class="annottext">Bool
</span><a href="#local-6989586621679540020"><span class="hs-identifier hs-var">x</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Ptr Word8 -&gt; Int -&gt; Word8 -&gt; IO ()
forall a. Storable a =&gt; Ptr a -&gt; Int -&gt; a -&gt; IO ()
</span><span class="hs-identifier hs-var">pokeElemOff</span></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-identifier hs-type">Word8</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Ptr () -&gt; Ptr Word8
forall a b. Ptr a -&gt; Ptr b
</span><span class="hs-identifier hs-var">castPtr</span></span><span> </span><span class="annot"><span class="annottext">Ptr ()
</span><a href="#local-6989586621679540022"><span class="hs-identifier hs-var">ptr</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679540021"><span class="hs-identifier hs-var">offset</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Bool -&gt; Word8
forall a. Num a =&gt; Bool -&gt; a
</span><span class="hs-identifier hs-var">fromBool</span></span><span> </span><span class="annot"><span class="annottext">Bool
</span><a href="#local-6989586621679540020"><span class="hs-identifier hs-var">x</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-1416"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#tensorPokeElemOff"><span class="hs-identifier hs-var">tensorPokeElemOff</span></a></span><span> </span><span class="annot"><span class="annottext">Ptr ()
</span><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-identifier">_</span></span><span> </span><span id="local-6989586621679540019"><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679540019"><span class="hs-identifier hs-var">dims'</span></a></span></span><span> </span><span id="local-6989586621679540018"><span class="annot"><span class="annottext">Bool
</span><a href="#local-6989586621679540018"><span class="hs-identifier hs-var">x</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">[Int] -&gt; Maybe Bool -&gt; IO ()
forall a (m :: * -&gt; *) b.
(TensorLikeRaw a, MonadThrow m) =&gt;
[Int] -&gt; Maybe a -&gt; m b
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#unexpectedDimsError"><span class="hs-identifier hs-var">unexpectedDimsError</span></a></span><span> </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679540019"><span class="hs-identifier hs-var">dims'</span></a></span><span> </span><span class="annot"><span class="annottext">(Maybe Bool -&gt; IO ()) -&gt; Maybe Bool -&gt; IO ()
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">Bool -&gt; Maybe Bool
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">Bool
</span><a href="#local-6989586621679540018"><span class="hs-identifier hs-var">x</span></a></span><span>
</span><span id="line-1417"></span><span>
</span><span id="line-1418"></span><span class="hs-keyword">instance</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorLike"><span class="hs-identifier hs-type">TensorLike</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#Int64"><span class="hs-identifier hs-type">Int64</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="hs-special">]</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-1419"></span><span>  </span><span id="local-6989586621679540015"><span class="annot"><span class="annottext">sToTensor :: SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; Int
-&gt; m (Tensor
        gradient layout device ('DataType 'Int64) ('Shape '[]))
</span><a href="#local-6989586621679540015"><span class="hs-identifier hs-var hs-var hs-var hs-var">sToTensor</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; Int
-&gt; m (Tensor
        gradient layout device ('DataType 'Int64) ('Shape '[]))
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat)) a
       (dType :: DType) (dims :: [Dim (Name Symbol) (Size Nat)])
       (m :: * -&gt; *).
(TensorLike a dType dims, TensorLikeRaw a, SingI dType,
 MonadThrow m) =&gt;
SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; a
-&gt; m (Tensor
        gradient layout device ('DataType dType) ('Shape dims))
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sToTensorRaw"><span class="hs-identifier hs-var">sToTensorRaw</span></a></span><span>
</span><span id="line-1420"></span><span>  </span><span id="local-6989586621679540014"><span class="annot"><span class="annottext">fromTensor :: Tensor gradient layout device ('DataType 'Int64) ('Shape '[])
-&gt; Int
</span><a href="#local-6989586621679540014"><span class="hs-identifier hs-var hs-var hs-var hs-var">fromTensor</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device ('DataType 'Int64) ('Shape '[])
-&gt; Int
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat)) a
       (dType :: DType) (dims :: [Dim (Name Symbol) (Size Nat)]).
(TensorLike a dType dims, TensorLikeRaw a, SGetDims dims) =&gt;
Tensor gradient layout device ('DataType dType) ('Shape dims) -&gt; a
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#fromTensorRaw"><span class="hs-identifier hs-var">fromTensorRaw</span></a></span><span>
</span><span id="line-1421"></span><span>
</span><span id="line-1422"></span><span class="hs-keyword">instance</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorLikeRaw"><span class="hs-identifier hs-type">TensorLikeRaw</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-1423"></span><span>  </span><span id="local-6989586621679540009"><span class="annot"><span class="annottext">guessDim :: Maybe Int -&gt; Maybe Int
</span><a href="#local-6989586621679540009"><span class="hs-identifier hs-var hs-var hs-var hs-var">guessDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Maybe Int -&gt; Maybe Int -&gt; Maybe Int
forall a b. a -&gt; b -&gt; a
</span><span class="hs-identifier hs-var">const</span></span><span> </span><span class="annot"><span class="annottext">Maybe Int
forall (f :: * -&gt; *) a. Alternative f =&gt; f a
</span><span class="hs-identifier hs-var">empty</span></span><span>
</span><span id="line-1424"></span><span>
</span><span id="line-1425"></span><span>  </span><span id="local-6989586621679540008"><span class="annot"><span class="annottext">guessInnerDims :: Maybe Int -&gt; m [Int]
</span><a href="#local-6989586621679540008"><span class="hs-identifier hs-var hs-var hs-var hs-var">guessInnerDims</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">m [Int] -&gt; Maybe Int -&gt; m [Int]
forall a b. a -&gt; b -&gt; a
</span><span class="hs-identifier hs-var">const</span></span><span> </span><span class="annot"><span class="annottext">(m [Int] -&gt; Maybe Int -&gt; m [Int])
-&gt; m [Int] -&gt; Maybe Int -&gt; m [Int]
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">[Int] -&gt; m [Int]
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">[Int]
forall (f :: * -&gt; *) a. Alternative f =&gt; f a
</span><span class="hs-identifier hs-var">empty</span></span><span>
</span><span id="line-1426"></span><span>
</span><span id="line-1427"></span><span>  </span><span id="local-6989586621679540007"><span class="annot"><span class="annottext">tensorPeekElemOff :: Ptr () -&gt; Int -&gt; [Int] -&gt; IO Int
</span><a href="#local-6989586621679540007"><span class="hs-identifier hs-var hs-var hs-var hs-var">tensorPeekElemOff</span></a></span></span><span> </span><span id="local-6989586621679540006"><span class="annot"><span class="annottext">Ptr ()
</span><a href="#local-6989586621679540006"><span class="hs-identifier hs-var">ptr</span></a></span></span><span> </span><span id="local-6989586621679540005"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679540005"><span class="hs-identifier hs-var">offset</span></a></span></span><span> </span><span class="hs-special">[</span><span class="hs-special">]</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Ptr Int -&gt; Int -&gt; IO Int
forall a. Storable a =&gt; Ptr a -&gt; Int -&gt; IO a
</span><span class="hs-identifier hs-var">peekElemOff</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Ptr () -&gt; Ptr Int
forall a b. Ptr a -&gt; Ptr b
</span><span class="hs-identifier hs-var">castPtr</span></span><span> </span><span class="annot"><span class="annottext">Ptr ()
</span><a href="#local-6989586621679540006"><span class="hs-identifier hs-var">ptr</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679540005"><span class="hs-identifier hs-var">offset</span></a></span><span>
</span><span id="line-1428"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#tensorPeekElemOff"><span class="hs-identifier hs-var">tensorPeekElemOff</span></a></span><span> </span><span class="annot"><span class="annottext">Ptr ()
</span><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-identifier">_</span></span><span> </span><span id="local-6989586621679540004"><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679540004"><span class="hs-identifier hs-var">dims'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">[Int] -&gt; Maybe Int -&gt; IO Int
forall a (m :: * -&gt; *) b.
(TensorLikeRaw a, MonadThrow m) =&gt;
[Int] -&gt; Maybe a -&gt; m b
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#unexpectedDimsError"><span class="hs-identifier hs-var">unexpectedDimsError</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span> </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679540004"><span class="hs-identifier hs-var">dims'</span></a></span><span> </span><span class="annot"><span class="annottext">Maybe Int
forall (f :: * -&gt; *) a. Alternative f =&gt; f a
</span><span class="hs-identifier hs-var">empty</span></span><span>
</span><span id="line-1429"></span><span>
</span><span id="line-1430"></span><span>  </span><span id="local-6989586621679540003"><span class="annot"><span class="annottext">tensorPokeElemOff :: Ptr () -&gt; Int -&gt; [Int] -&gt; Int -&gt; IO ()
</span><a href="#local-6989586621679540003"><span class="hs-identifier hs-var hs-var hs-var hs-var">tensorPokeElemOff</span></a></span></span><span> </span><span id="local-6989586621679540002"><span class="annot"><span class="annottext">Ptr ()
</span><a href="#local-6989586621679540002"><span class="hs-identifier hs-var">ptr</span></a></span></span><span> </span><span id="local-6989586621679540001"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679540001"><span class="hs-identifier hs-var">offset</span></a></span></span><span> </span><span class="hs-special">[</span><span class="hs-special">]</span><span> </span><span id="local-6989586621679540000"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679540000"><span class="hs-identifier hs-var">x</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Ptr Int -&gt; Int -&gt; Int -&gt; IO ()
forall a. Storable a =&gt; Ptr a -&gt; Int -&gt; a -&gt; IO ()
</span><span class="hs-identifier hs-var">pokeElemOff</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Ptr () -&gt; Ptr Int
forall a b. Ptr a -&gt; Ptr b
</span><span class="hs-identifier hs-var">castPtr</span></span><span> </span><span class="annot"><span class="annottext">Ptr ()
</span><a href="#local-6989586621679540002"><span class="hs-identifier hs-var">ptr</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679540001"><span class="hs-identifier hs-var">offset</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679540000"><span class="hs-identifier hs-var">x</span></a></span><span>
</span><span id="line-1431"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#tensorPokeElemOff"><span class="hs-identifier hs-var">tensorPokeElemOff</span></a></span><span> </span><span class="annot"><span class="annottext">Ptr ()
</span><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-identifier">_</span></span><span> </span><span id="local-6989586621679539999"><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679539999"><span class="hs-identifier hs-var">dims'</span></a></span></span><span> </span><span id="local-6989586621679539998"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679539998"><span class="hs-identifier hs-var">x</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">[Int] -&gt; Maybe Int -&gt; IO ()
forall a (m :: * -&gt; *) b.
(TensorLikeRaw a, MonadThrow m) =&gt;
[Int] -&gt; Maybe a -&gt; m b
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#unexpectedDimsError"><span class="hs-identifier hs-var">unexpectedDimsError</span></a></span><span> </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679539999"><span class="hs-identifier hs-var">dims'</span></a></span><span> </span><span class="annot"><span class="annottext">(Maybe Int -&gt; IO ()) -&gt; Maybe Int -&gt; IO ()
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Maybe Int
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679539998"><span class="hs-identifier hs-var">x</span></a></span><span>
</span><span id="line-1432"></span><span>
</span><span id="line-1433"></span><span class="hs-keyword">instance</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorLike"><span class="hs-identifier hs-type">TensorLike</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Float</span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#Float"><span class="hs-identifier hs-type">Float</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="hs-special">]</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-1434"></span><span>  </span><span id="local-6989586621679539995"><span class="annot"><span class="annottext">sToTensor :: SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; Float
-&gt; m (Tensor
        gradient layout device ('DataType 'Float) ('Shape '[]))
</span><a href="#local-6989586621679539995"><span class="hs-identifier hs-var hs-var hs-var hs-var">sToTensor</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; Float
-&gt; m (Tensor
        gradient layout device ('DataType 'Float) ('Shape '[]))
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat)) a
       (dType :: DType) (dims :: [Dim (Name Symbol) (Size Nat)])
       (m :: * -&gt; *).
(TensorLike a dType dims, TensorLikeRaw a, SingI dType,
 MonadThrow m) =&gt;
SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; a
-&gt; m (Tensor
        gradient layout device ('DataType dType) ('Shape dims))
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sToTensorRaw"><span class="hs-identifier hs-var">sToTensorRaw</span></a></span><span>
</span><span id="line-1435"></span><span>  </span><span id="local-6989586621679539994"><span class="annot"><span class="annottext">fromTensor :: Tensor gradient layout device ('DataType 'Float) ('Shape '[])
-&gt; Float
</span><a href="#local-6989586621679539994"><span class="hs-identifier hs-var hs-var hs-var hs-var">fromTensor</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device ('DataType 'Float) ('Shape '[])
-&gt; Float
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat)) a
       (dType :: DType) (dims :: [Dim (Name Symbol) (Size Nat)]).
(TensorLike a dType dims, TensorLikeRaw a, SGetDims dims) =&gt;
Tensor gradient layout device ('DataType dType) ('Shape dims) -&gt; a
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#fromTensorRaw"><span class="hs-identifier hs-var">fromTensorRaw</span></a></span><span>
</span><span id="line-1436"></span><span>
</span><span id="line-1437"></span><span class="hs-keyword">instance</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorLikeRaw"><span class="hs-identifier hs-type">TensorLikeRaw</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Float</span></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-1438"></span><span>  </span><span id="local-6989586621679539989"><span class="annot"><span class="annottext">guessDim :: Maybe Float -&gt; Maybe Int
</span><a href="#local-6989586621679539989"><span class="hs-identifier hs-var hs-var hs-var hs-var">guessDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Maybe Int -&gt; Maybe Float -&gt; Maybe Int
forall a b. a -&gt; b -&gt; a
</span><span class="hs-identifier hs-var">const</span></span><span> </span><span class="annot"><span class="annottext">Maybe Int
forall (f :: * -&gt; *) a. Alternative f =&gt; f a
</span><span class="hs-identifier hs-var">empty</span></span><span>
</span><span id="line-1439"></span><span>
</span><span id="line-1440"></span><span>  </span><span id="local-6989586621679539988"><span class="annot"><span class="annottext">guessInnerDims :: Maybe Float -&gt; m [Int]
</span><a href="#local-6989586621679539988"><span class="hs-identifier hs-var hs-var hs-var hs-var">guessInnerDims</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">m [Int] -&gt; Maybe Float -&gt; m [Int]
forall a b. a -&gt; b -&gt; a
</span><span class="hs-identifier hs-var">const</span></span><span> </span><span class="annot"><span class="annottext">(m [Int] -&gt; Maybe Float -&gt; m [Int])
-&gt; m [Int] -&gt; Maybe Float -&gt; m [Int]
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">[Int] -&gt; m [Int]
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">[Int]
forall (f :: * -&gt; *) a. Alternative f =&gt; f a
</span><span class="hs-identifier hs-var">empty</span></span><span>
</span><span id="line-1441"></span><span>
</span><span id="line-1442"></span><span>  </span><span id="local-6989586621679539987"><span class="annot"><span class="annottext">tensorPeekElemOff :: Ptr () -&gt; Int -&gt; [Int] -&gt; IO Float
</span><a href="#local-6989586621679539987"><span class="hs-identifier hs-var hs-var hs-var hs-var">tensorPeekElemOff</span></a></span></span><span> </span><span id="local-6989586621679539986"><span class="annot"><span class="annottext">Ptr ()
</span><a href="#local-6989586621679539986"><span class="hs-identifier hs-var">ptr</span></a></span></span><span> </span><span id="local-6989586621679539985"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679539985"><span class="hs-identifier hs-var">offset</span></a></span></span><span> </span><span class="hs-special">[</span><span class="hs-special">]</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Ptr Float -&gt; Int -&gt; IO Float
forall a. Storable a =&gt; Ptr a -&gt; Int -&gt; IO a
</span><span class="hs-identifier hs-var">peekElemOff</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Ptr () -&gt; Ptr Float
forall a b. Ptr a -&gt; Ptr b
</span><span class="hs-identifier hs-var">castPtr</span></span><span> </span><span class="annot"><span class="annottext">Ptr ()
</span><a href="#local-6989586621679539986"><span class="hs-identifier hs-var">ptr</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679539985"><span class="hs-identifier hs-var">offset</span></a></span><span>
</span><span id="line-1443"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#tensorPeekElemOff"><span class="hs-identifier hs-var">tensorPeekElemOff</span></a></span><span> </span><span class="annot"><span class="annottext">Ptr ()
</span><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-identifier">_</span></span><span> </span><span id="local-6989586621679539984"><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679539984"><span class="hs-identifier hs-var">dims'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">[Int] -&gt; Maybe Float -&gt; IO Float
forall a (m :: * -&gt; *) b.
(TensorLikeRaw a, MonadThrow m) =&gt;
[Int] -&gt; Maybe a -&gt; m b
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#unexpectedDimsError"><span class="hs-identifier hs-var">unexpectedDimsError</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-identifier hs-type">Float</span></span><span> </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679539984"><span class="hs-identifier hs-var">dims'</span></a></span><span> </span><span class="annot"><span class="annottext">Maybe Float
forall (f :: * -&gt; *) a. Alternative f =&gt; f a
</span><span class="hs-identifier hs-var">empty</span></span><span>
</span><span id="line-1444"></span><span>
</span><span id="line-1445"></span><span>  </span><span id="local-6989586621679539983"><span class="annot"><span class="annottext">tensorPokeElemOff :: Ptr () -&gt; Int -&gt; [Int] -&gt; Float -&gt; IO ()
</span><a href="#local-6989586621679539983"><span class="hs-identifier hs-var hs-var hs-var hs-var">tensorPokeElemOff</span></a></span></span><span> </span><span id="local-6989586621679539982"><span class="annot"><span class="annottext">Ptr ()
</span><a href="#local-6989586621679539982"><span class="hs-identifier hs-var">ptr</span></a></span></span><span> </span><span id="local-6989586621679539981"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679539981"><span class="hs-identifier hs-var">offset</span></a></span></span><span> </span><span class="hs-special">[</span><span class="hs-special">]</span><span> </span><span id="local-6989586621679539980"><span class="annot"><span class="annottext">Float
</span><a href="#local-6989586621679539980"><span class="hs-identifier hs-var">x</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Ptr Float -&gt; Int -&gt; Float -&gt; IO ()
forall a. Storable a =&gt; Ptr a -&gt; Int -&gt; a -&gt; IO ()
</span><span class="hs-identifier hs-var">pokeElemOff</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Ptr () -&gt; Ptr Float
forall a b. Ptr a -&gt; Ptr b
</span><span class="hs-identifier hs-var">castPtr</span></span><span> </span><span class="annot"><span class="annottext">Ptr ()
</span><a href="#local-6989586621679539982"><span class="hs-identifier hs-var">ptr</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679539981"><span class="hs-identifier hs-var">offset</span></a></span><span> </span><span class="annot"><span class="annottext">Float
</span><a href="#local-6989586621679539980"><span class="hs-identifier hs-var">x</span></a></span><span>
</span><span id="line-1446"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#tensorPokeElemOff"><span class="hs-identifier hs-var">tensorPokeElemOff</span></a></span><span> </span><span class="annot"><span class="annottext">Ptr ()
</span><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-identifier">_</span></span><span> </span><span id="local-6989586621679539979"><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679539979"><span class="hs-identifier hs-var">dims'</span></a></span></span><span> </span><span id="local-6989586621679539978"><span class="annot"><span class="annottext">Float
</span><a href="#local-6989586621679539978"><span class="hs-identifier hs-var">x</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">[Int] -&gt; Maybe Float -&gt; IO ()
forall a (m :: * -&gt; *) b.
(TensorLikeRaw a, MonadThrow m) =&gt;
[Int] -&gt; Maybe a -&gt; m b
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#unexpectedDimsError"><span class="hs-identifier hs-var">unexpectedDimsError</span></a></span><span> </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679539979"><span class="hs-identifier hs-var">dims'</span></a></span><span> </span><span class="annot"><span class="annottext">(Maybe Float -&gt; IO ()) -&gt; Maybe Float -&gt; IO ()
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">Float -&gt; Maybe Float
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">Float
</span><a href="#local-6989586621679539978"><span class="hs-identifier hs-var">x</span></a></span><span>
</span><span id="line-1447"></span><span>
</span><span id="line-1448"></span><span class="hs-keyword">instance</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorLike"><span class="hs-identifier hs-type">TensorLike</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#Double"><span class="hs-identifier hs-type">Double</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="hs-special">]</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-1449"></span><span>  </span><span id="local-6989586621679539975"><span class="annot"><span class="annottext">sToTensor :: SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; Double
-&gt; m (Tensor
        gradient layout device ('DataType 'Double) ('Shape '[]))
</span><a href="#local-6989586621679539975"><span class="hs-identifier hs-var hs-var hs-var hs-var">sToTensor</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; Double
-&gt; m (Tensor
        gradient layout device ('DataType 'Double) ('Shape '[]))
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat)) a
       (dType :: DType) (dims :: [Dim (Name Symbol) (Size Nat)])
       (m :: * -&gt; *).
(TensorLike a dType dims, TensorLikeRaw a, SingI dType,
 MonadThrow m) =&gt;
SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; a
-&gt; m (Tensor
        gradient layout device ('DataType dType) ('Shape dims))
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sToTensorRaw"><span class="hs-identifier hs-var">sToTensorRaw</span></a></span><span>
</span><span id="line-1450"></span><span>  </span><span id="local-6989586621679539974"><span class="annot"><span class="annottext">fromTensor :: Tensor gradient layout device ('DataType 'Double) ('Shape '[])
-&gt; Double
</span><a href="#local-6989586621679539974"><span class="hs-identifier hs-var hs-var hs-var hs-var">fromTensor</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device ('DataType 'Double) ('Shape '[])
-&gt; Double
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat)) a
       (dType :: DType) (dims :: [Dim (Name Symbol) (Size Nat)]).
(TensorLike a dType dims, TensorLikeRaw a, SGetDims dims) =&gt;
Tensor gradient layout device ('DataType dType) ('Shape dims) -&gt; a
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#fromTensorRaw"><span class="hs-identifier hs-var">fromTensorRaw</span></a></span><span>
</span><span id="line-1451"></span><span>
</span><span id="line-1452"></span><span class="hs-keyword">instance</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorLikeRaw"><span class="hs-identifier hs-type">TensorLikeRaw</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-1453"></span><span>  </span><span id="local-6989586621679539969"><span class="annot"><span class="annottext">guessDim :: Maybe Double -&gt; Maybe Int
</span><a href="#local-6989586621679539969"><span class="hs-identifier hs-var hs-var hs-var hs-var">guessDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Maybe Int -&gt; Maybe Double -&gt; Maybe Int
forall a b. a -&gt; b -&gt; a
</span><span class="hs-identifier hs-var">const</span></span><span> </span><span class="annot"><span class="annottext">Maybe Int
forall (f :: * -&gt; *) a. Alternative f =&gt; f a
</span><span class="hs-identifier hs-var">empty</span></span><span>
</span><span id="line-1454"></span><span>
</span><span id="line-1455"></span><span>  </span><span id="local-6989586621679539968"><span class="annot"><span class="annottext">guessInnerDims :: Maybe Double -&gt; m [Int]
</span><a href="#local-6989586621679539968"><span class="hs-identifier hs-var hs-var hs-var hs-var">guessInnerDims</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">m [Int] -&gt; Maybe Double -&gt; m [Int]
forall a b. a -&gt; b -&gt; a
</span><span class="hs-identifier hs-var">const</span></span><span> </span><span class="annot"><span class="annottext">(m [Int] -&gt; Maybe Double -&gt; m [Int])
-&gt; m [Int] -&gt; Maybe Double -&gt; m [Int]
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">[Int] -&gt; m [Int]
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">[Int]
forall (f :: * -&gt; *) a. Alternative f =&gt; f a
</span><span class="hs-identifier hs-var">empty</span></span><span>
</span><span id="line-1456"></span><span>
</span><span id="line-1457"></span><span>  </span><span id="local-6989586621679539967"><span class="annot"><span class="annottext">tensorPeekElemOff :: Ptr () -&gt; Int -&gt; [Int] -&gt; IO Double
</span><a href="#local-6989586621679539967"><span class="hs-identifier hs-var hs-var hs-var hs-var">tensorPeekElemOff</span></a></span></span><span> </span><span id="local-6989586621679539966"><span class="annot"><span class="annottext">Ptr ()
</span><a href="#local-6989586621679539966"><span class="hs-identifier hs-var">ptr</span></a></span></span><span> </span><span id="local-6989586621679539965"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679539965"><span class="hs-identifier hs-var">offset</span></a></span></span><span> </span><span class="hs-special">[</span><span class="hs-special">]</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Ptr Double -&gt; Int -&gt; IO Double
forall a. Storable a =&gt; Ptr a -&gt; Int -&gt; IO a
</span><span class="hs-identifier hs-var">peekElemOff</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Ptr () -&gt; Ptr Double
forall a b. Ptr a -&gt; Ptr b
</span><span class="hs-identifier hs-var">castPtr</span></span><span> </span><span class="annot"><span class="annottext">Ptr ()
</span><a href="#local-6989586621679539966"><span class="hs-identifier hs-var">ptr</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679539965"><span class="hs-identifier hs-var">offset</span></a></span><span>
</span><span id="line-1458"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#tensorPeekElemOff"><span class="hs-identifier hs-var">tensorPeekElemOff</span></a></span><span> </span><span class="annot"><span class="annottext">Ptr ()
</span><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-identifier">_</span></span><span> </span><span id="local-6989586621679539964"><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679539964"><span class="hs-identifier hs-var">dims'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">[Int] -&gt; Maybe Double -&gt; IO Double
forall a (m :: * -&gt; *) b.
(TensorLikeRaw a, MonadThrow m) =&gt;
[Int] -&gt; Maybe a -&gt; m b
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#unexpectedDimsError"><span class="hs-identifier hs-var">unexpectedDimsError</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span> </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679539964"><span class="hs-identifier hs-var">dims'</span></a></span><span> </span><span class="annot"><span class="annottext">Maybe Double
forall (f :: * -&gt; *) a. Alternative f =&gt; f a
</span><span class="hs-identifier hs-var">empty</span></span><span>
</span><span id="line-1459"></span><span>
</span><span id="line-1460"></span><span>  </span><span id="local-6989586621679539963"><span class="annot"><span class="annottext">tensorPokeElemOff :: Ptr () -&gt; Int -&gt; [Int] -&gt; Double -&gt; IO ()
</span><a href="#local-6989586621679539963"><span class="hs-identifier hs-var hs-var hs-var hs-var">tensorPokeElemOff</span></a></span></span><span> </span><span id="local-6989586621679539962"><span class="annot"><span class="annottext">Ptr ()
</span><a href="#local-6989586621679539962"><span class="hs-identifier hs-var">ptr</span></a></span></span><span> </span><span id="local-6989586621679539961"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679539961"><span class="hs-identifier hs-var">offset</span></a></span></span><span> </span><span class="hs-special">[</span><span class="hs-special">]</span><span> </span><span id="local-6989586621679539960"><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679539960"><span class="hs-identifier hs-var">x</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Ptr Double -&gt; Int -&gt; Double -&gt; IO ()
forall a. Storable a =&gt; Ptr a -&gt; Int -&gt; a -&gt; IO ()
</span><span class="hs-identifier hs-var">pokeElemOff</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Ptr () -&gt; Ptr Double
forall a b. Ptr a -&gt; Ptr b
</span><span class="hs-identifier hs-var">castPtr</span></span><span> </span><span class="annot"><span class="annottext">Ptr ()
</span><a href="#local-6989586621679539962"><span class="hs-identifier hs-var">ptr</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679539961"><span class="hs-identifier hs-var">offset</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679539960"><span class="hs-identifier hs-var">x</span></a></span><span>
</span><span id="line-1461"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#tensorPokeElemOff"><span class="hs-identifier hs-var">tensorPokeElemOff</span></a></span><span> </span><span class="annot"><span class="annottext">Ptr ()
</span><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-identifier">_</span></span><span> </span><span id="local-6989586621679539959"><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679539959"><span class="hs-identifier hs-var">dims'</span></a></span></span><span> </span><span id="local-6989586621679539958"><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679539958"><span class="hs-identifier hs-var">x</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">[Int] -&gt; Maybe Double -&gt; IO ()
forall a (m :: * -&gt; *) b.
(TensorLikeRaw a, MonadThrow m) =&gt;
[Int] -&gt; Maybe a -&gt; m b
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#unexpectedDimsError"><span class="hs-identifier hs-var">unexpectedDimsError</span></a></span><span> </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679539959"><span class="hs-identifier hs-var">dims'</span></a></span><span> </span><span class="annot"><span class="annottext">(Maybe Double -&gt; IO ()) -&gt; Maybe Double -&gt; IO ()
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">Double -&gt; Maybe Double
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679539958"><span class="hs-identifier hs-var">x</span></a></span><span>
</span><span id="line-1462"></span><span>
</span><span id="line-1463"></span><span class="hs-keyword">data</span><span> </span><span id="DimMismatchError"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#DimMismatchError"><span class="hs-identifier hs-var">DimMismatchError</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span id="DimMismatchError"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#DimMismatchError"><span class="hs-identifier hs-var">DimMismatchError</span></a></span></span><span> </span><span class="hs-special">{</span><span id="dmeFirst"><span class="annot"><span class="annottext">DimMismatchError -&gt; [Int]
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#dmeFirst"><span class="hs-identifier hs-var hs-var">dmeFirst</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">]</span><span class="hs-special">,</span><span> </span><span id="dmeOther"><span class="annot"><span class="annottext">DimMismatchError -&gt; [Int]
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#dmeOther"><span class="hs-identifier hs-var hs-var">dmeOther</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">]</span><span class="hs-special">}</span><span>
</span><span id="line-1464"></span><span>  </span><span class="hs-keyword">deriving</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679539949"><span id="local-6989586621679539951"><span id="local-6989586621679539953"><span class="annot"><span class="annottext">Int -&gt; DimMismatchError -&gt; ShowS
[DimMismatchError] -&gt; ShowS
DimMismatchError -&gt; String
(Int -&gt; DimMismatchError -&gt; ShowS)
-&gt; (DimMismatchError -&gt; String)
-&gt; ([DimMismatchError] -&gt; ShowS)
-&gt; Show DimMismatchError
forall a.
(Int -&gt; a -&gt; ShowS) -&gt; (a -&gt; String) -&gt; ([a] -&gt; ShowS) -&gt; Show a
showList :: [DimMismatchError] -&gt; ShowS
$cshowList :: [DimMismatchError] -&gt; ShowS
show :: DimMismatchError -&gt; String
$cshow :: DimMismatchError -&gt; String
showsPrec :: Int -&gt; DimMismatchError -&gt; ShowS
$cshowsPrec :: Int -&gt; DimMismatchError -&gt; ShowS
</span><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">Show</span></span></span></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679539945"><span id="local-6989586621679539947"><span class="annot"><span class="annottext">DimMismatchError -&gt; DimMismatchError -&gt; Bool
(DimMismatchError -&gt; DimMismatchError -&gt; Bool)
-&gt; (DimMismatchError -&gt; DimMismatchError -&gt; Bool)
-&gt; Eq DimMismatchError
forall a. (a -&gt; a -&gt; Bool) -&gt; (a -&gt; a -&gt; Bool) -&gt; Eq a
/= :: DimMismatchError -&gt; DimMismatchError -&gt; Bool
$c/= :: DimMismatchError -&gt; DimMismatchError -&gt; Bool
== :: DimMismatchError -&gt; DimMismatchError -&gt; Bool
$c== :: DimMismatchError -&gt; DimMismatchError -&gt; Bool
</span><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var">Eq</span></span></span></span><span class="hs-special">)</span><span>
</span><span id="line-1465"></span><span>
</span><span id="line-1466"></span><span class="hs-keyword">instance</span><span> </span><span id="local-6989586621679539938"><span id="local-6989586621679539940"><span class="annot"><span class="hs-identifier hs-type">Exception</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#DimMismatchError"><span class="hs-identifier hs-type">DimMismatchError</span></a></span></span></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-1467"></span><span>  </span><span id="local-6989586621679539936"><span class="annot"><span class="annottext">displayException :: DimMismatchError -&gt; String
</span><a href="#local-6989586621679539936"><span class="hs-identifier hs-var hs-var hs-var hs-var">displayException</span></a></span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#DimMismatchError"><span class="hs-identifier hs-type">DimMismatchError</span></a></span><span> </span><span class="hs-special">{</span><span id="local-6989586621679539934"><span id="local-6989586621679539935"><span class="annot"><span class="annottext">[Int]
dmeOther :: [Int]
dmeFirst :: [Int]
dmeOther :: DimMismatchError -&gt; [Int]
dmeFirst :: DimMismatchError -&gt; [Int]
</span><a href="#local-6989586621679539934"><span class="hs-glyph hs-var hs-var hs-var hs-var">..</span></a></span></span></span><span class="hs-special">}</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-1468"></span><span>    </span><span class="annot"><span class="annottext">String
</span><span class="hs-string">&quot;When converting to a tensor, all elements on the same dimension must have the same shape, &quot;</span></span><span>
</span><span id="line-1469"></span><span>      </span><span class="annot"><span class="annottext">String -&gt; ShowS
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">String
</span><span class="hs-string">&quot;but the first element has shape &quot;</span></span><span>
</span><span id="line-1470"></span><span>      </span><span class="annot"><span class="annottext">String -&gt; ShowS
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">[Int] -&gt; String
forall a. Show a =&gt; a -&gt; String
</span><span class="hs-identifier hs-var">show</span></span><span> </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679539935"><span class="hs-identifier hs-var">dmeFirst</span></a></span><span>
</span><span id="line-1471"></span><span>      </span><span class="annot"><span class="annottext">String -&gt; ShowS
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">String
</span><span class="hs-string">&quot; while another element has shape &quot;</span></span><span>
</span><span id="line-1472"></span><span>      </span><span class="annot"><span class="annottext">String -&gt; ShowS
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">[Int] -&gt; String
forall a. Show a =&gt; a -&gt; String
</span><span class="hs-identifier hs-var">show</span></span><span> </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679539934"><span class="hs-identifier hs-var">dmeOther</span></a></span><span>
</span><span id="line-1473"></span><span>      </span><span class="annot"><span class="annottext">String -&gt; ShowS
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">String
</span><span class="hs-string">&quot;.&quot;</span></span><span>
</span><span id="line-1474"></span><span>
</span><span id="line-1475"></span><span id="local-6989586621679540988"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#checkDims"><span class="hs-identifier hs-type">checkDims</span></a></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier hs-type">MonadThrow</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540988"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="hs-glyph">=&gt;</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">]</span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">]</span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="#local-6989586621679540988"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span></span><span>
</span><span id="line-1476"></span><span id="checkDims"><span class="annot"><span class="annottext">checkDims :: [Int] -&gt; [Int] -&gt; m ()
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#checkDims"><span class="hs-identifier hs-var hs-var">checkDims</span></a></span></span><span> </span><span id="local-6989586621679539932"><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679539932"><span class="hs-identifier hs-var">firstDims</span></a></span></span><span> </span><span id="local-6989586621679539931"><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679539931"><span class="hs-identifier hs-var">otherDims</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Bool -&gt; m () -&gt; m ()
forall (f :: * -&gt; *). Applicative f =&gt; Bool -&gt; f () -&gt; f ()
</span><span class="hs-identifier hs-var">when</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679539932"><span class="hs-identifier hs-var">firstDims</span></a></span><span> </span><span class="annot"><span class="annottext">[Int] -&gt; [Int] -&gt; Bool
forall a. Eq a =&gt; a -&gt; a -&gt; Bool
</span><span class="hs-operator hs-var">/=</span></span><span> </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679539931"><span class="hs-identifier hs-var">otherDims</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">(m () -&gt; m ()) -&gt; m () -&gt; m ()
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">DimMismatchError -&gt; m ()
forall (m :: * -&gt; *) e a. (MonadThrow m, Exception e) =&gt; e -&gt; m a
</span><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier hs-var">throwM</span></a></span><span> </span><span class="annot"><span class="annottext">(DimMismatchError -&gt; m ()) -&gt; DimMismatchError -&gt; m ()
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">[Int] -&gt; [Int] -&gt; DimMismatchError
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#DimMismatchError"><span class="hs-identifier hs-var">DimMismatchError</span></a></span><span> </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679539932"><span class="hs-identifier hs-var">firstDims</span></a></span><span> </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679539931"><span class="hs-identifier hs-var">otherDims</span></a></span><span>
</span><span id="line-1477"></span><span>
</span><span id="line-1478"></span><span id="local-6989586621679539925"><span id="local-6989586621679539926"><span id="local-6989586621679539927"><span id="local-6989586621679539928"><span id="local-6989586621679539929"><span id="local-6989586621679539930"><span class="hs-keyword">instance</span><span>
</span><span id="line-1479"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorLike"><span class="hs-identifier hs-type">TensorLike</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679539930"><span class="hs-identifier hs-type">a</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679539929"><span class="hs-identifier hs-type">dType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679539928"><span class="hs-identifier hs-type">dims</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-1480"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorLike"><span class="hs-identifier hs-type">TensorLike</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679539927"><span class="hs-identifier hs-type">b</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679539929"><span class="hs-identifier hs-type">dType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679539926"><span class="hs-identifier hs-type">dims'</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-1481"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorLikeRaw"><span class="hs-identifier hs-type">TensorLikeRaw</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679539930"><span class="hs-identifier hs-type">a</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-1482"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorLikeRaw"><span class="hs-identifier hs-type">TensorLikeRaw</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679539927"><span class="hs-identifier hs-type">b</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-1483"></span><span>    </span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-type">SingI</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679539929"><span class="hs-identifier hs-type">dType</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-1484"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetDims"><span class="hs-identifier hs-type">SGetDims</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679539925"><span class="hs-identifier hs-type">dimsOut</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-1485"></span><span>    </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679539925"><span class="hs-identifier hs-type">dimsOut</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#InsertDimF"><span class="hs-identifier hs-type">InsertDimF</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">0</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679539928"><span class="hs-identifier hs-type">dims</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679539926"><span class="hs-identifier hs-type">dims'</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-number">2</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-1486"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-1487"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorLike"><span class="hs-identifier hs-type">TensorLike</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679539930"><span class="hs-identifier hs-type">a</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679539927"><span class="hs-identifier hs-type">b</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679539929"><span class="hs-identifier hs-type">dType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679539925"><span class="hs-identifier hs-type">dimsOut</span></a></span><span>
</span><span id="line-1488"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-1489"></span><span>  </span><span id="local-6989586621679539922"><span class="annot"><span class="annottext">sToTensor :: SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; (a, b)
-&gt; m (Tensor
        gradient layout device ('DataType dType) ('Shape dimsOut))
</span><a href="#local-6989586621679539922"><span class="hs-identifier hs-var hs-var hs-var hs-var">sToTensor</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; (a, b)
-&gt; m (Tensor
        gradient layout device ('DataType dType) ('Shape dimsOut))
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat)) a
       (dType :: DType) (dims :: [Dim (Name Symbol) (Size Nat)])
       (m :: * -&gt; *).
(TensorLike a dType dims, TensorLikeRaw a, SingI dType,
 MonadThrow m) =&gt;
SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; a
-&gt; m (Tensor
        gradient layout device ('DataType dType) ('Shape dims))
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sToTensorRaw"><span class="hs-identifier hs-var">sToTensorRaw</span></a></span><span>
</span><span id="line-1490"></span><span>  </span><span id="local-6989586621679539921"><span class="annot"><span class="annottext">fromTensor :: Tensor gradient layout device ('DataType dType) ('Shape dimsOut)
-&gt; (a, b)
</span><a href="#local-6989586621679539921"><span class="hs-identifier hs-var hs-var hs-var hs-var">fromTensor</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device ('DataType dType) ('Shape dimsOut)
-&gt; (a, b)
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat)) a
       (dType :: DType) (dims :: [Dim (Name Symbol) (Size Nat)]).
(TensorLike a dType dims, TensorLikeRaw a, SGetDims dims) =&gt;
Tensor gradient layout device ('DataType dType) ('Shape dims) -&gt; a
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#fromTensorRaw"><span class="hs-identifier hs-var">fromTensorRaw</span></a></span></span></span></span></span></span></span><span>
</span><span id="line-1491"></span><span>
</span><span id="line-1492"></span><span id="local-6989586621679539919"><span id="local-6989586621679539920"><span class="hs-keyword">instance</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorLikeRaw"><span class="hs-identifier hs-type">TensorLikeRaw</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679539920"><span class="hs-identifier hs-type">a</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorLikeRaw"><span class="hs-identifier hs-type">TensorLikeRaw</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679539919"><span class="hs-identifier hs-type">b</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorLikeRaw"><span class="hs-identifier hs-type">TensorLikeRaw</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679539920"><span class="hs-identifier hs-type">a</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679539919"><span class="hs-identifier hs-type">b</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-1493"></span><span>  </span><span id="local-6989586621679539914"><span class="annot"><span class="annottext">guessDim :: Maybe (a, b) -&gt; Maybe Int
</span><a href="#local-6989586621679539914"><span class="hs-identifier hs-var hs-var hs-var hs-var">guessDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Maybe Int -&gt; Maybe (a, b) -&gt; Maybe Int
forall a b. a -&gt; b -&gt; a
</span><span class="hs-identifier hs-var">const</span></span><span> </span><span class="annot"><span class="annottext">(Maybe Int -&gt; Maybe (a, b) -&gt; Maybe Int)
-&gt; Maybe Int -&gt; Maybe (a, b) -&gt; Maybe Int
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Maybe Int
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">2</span></span><span>
</span><span id="line-1494"></span><span>
</span><span id="line-1495"></span><span>  </span><span id="local-6989586621679539913"><span class="annot"><span class="annottext">guessInnerDims :: Maybe (a, b) -&gt; m [Int]
</span><a href="#local-6989586621679539913"><span class="hs-identifier hs-var hs-var hs-var hs-var">guessInnerDims</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Maybe (a, b) -&gt; (Maybe a, Maybe b)
forall (f :: * -&gt; *) a b. Functor f =&gt; f (a, b) -&gt; (f a, f b)
</span><span class="hs-identifier hs-var">unzip</span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679539912"><span class="annot"><span class="annottext">Maybe a
</span><a href="#local-6989586621679539912"><span class="hs-identifier hs-var">x</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679539911"><span class="annot"><span class="annottext">Maybe b
</span><a href="#local-6989586621679539911"><span class="hs-identifier hs-var">y</span></a></span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-1496"></span><span>    </span><span id="local-6989586621679539910"><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679539910"><span class="hs-identifier hs-var">xDims</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">Maybe a -&gt; m [Int]
forall a (m :: * -&gt; *).
(TensorLikeRaw a, MonadThrow m) =&gt;
Maybe a -&gt; m [Int]
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#guessDims"><span class="hs-identifier hs-var">guessDims</span></a></span><span> </span><span class="annot"><span class="annottext">Maybe a
</span><a href="#local-6989586621679539912"><span class="hs-identifier hs-var">x</span></a></span><span>
</span><span id="line-1497"></span><span>    </span><span id="local-6989586621679539909"><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679539909"><span class="hs-identifier hs-var">yDims</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">Maybe b -&gt; m [Int]
forall a (m :: * -&gt; *).
(TensorLikeRaw a, MonadThrow m) =&gt;
Maybe a -&gt; m [Int]
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#guessDims"><span class="hs-identifier hs-var">guessDims</span></a></span><span> </span><span class="annot"><span class="annottext">Maybe b
</span><a href="#local-6989586621679539911"><span class="hs-identifier hs-var">y</span></a></span><span>
</span><span id="line-1498"></span><span>    </span><span class="annot"><span class="annottext">[Int] -&gt; [Int] -&gt; m ()
forall (m :: * -&gt; *). MonadThrow m =&gt; [Int] -&gt; [Int] -&gt; m ()
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#checkDims"><span class="hs-identifier hs-var">checkDims</span></a></span><span> </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679539910"><span class="hs-identifier hs-var">xDims</span></a></span><span> </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679539909"><span class="hs-identifier hs-var">yDims</span></a></span><span>
</span><span id="line-1499"></span><span>    </span><span class="annot"><span class="annottext">[Int] -&gt; m [Int]
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679539910"><span class="hs-identifier hs-var">xDims</span></a></span><span>
</span><span id="line-1500"></span><span>
</span><span id="line-1501"></span><span>  </span><span id="local-6989586621679539908"><span class="annot"><span class="annottext">tensorPeekElemOff :: Ptr () -&gt; Int -&gt; [Int] -&gt; IO (a, b)
</span><a href="#local-6989586621679539908"><span class="hs-identifier hs-var hs-var hs-var hs-var">tensorPeekElemOff</span></a></span></span><span> </span><span id="local-6989586621679539907"><span class="annot"><span class="annottext">Ptr ()
</span><a href="#local-6989586621679539907"><span class="hs-identifier hs-var">ptr</span></a></span></span><span> </span><span id="local-6989586621679539906"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679539906"><span class="hs-identifier hs-var">offset</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">2</span></span><span> </span><span class="annot"><span class="hs-glyph hs-type">:</span></span><span> </span><span id="local-6989586621679539905"><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679539905"><span class="hs-identifier hs-var">innerDims</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-1502"></span><span>    </span><span class="hs-special">(</span><span class="hs-special">,</span><span class="hs-special">)</span><span>
</span><span id="line-1503"></span><span>      </span><span class="annot"><span class="annottext">(a -&gt; b -&gt; (a, b)) -&gt; IO a -&gt; IO (b -&gt; (a, b))
forall (f :: * -&gt; *) a b. Functor f =&gt; (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;$&gt;</span></span><span> </span><span class="annot"><span class="annottext">Ptr () -&gt; Int -&gt; [Int] -&gt; IO a
forall a. TensorLikeRaw a =&gt; Ptr () -&gt; Int -&gt; [Int] -&gt; IO a
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#tensorPeekElemOff"><span class="hs-identifier hs-var">tensorPeekElemOff</span></a></span><span> </span><span class="annot"><span class="annottext">Ptr ()
</span><a href="#local-6989586621679539907"><span class="hs-identifier hs-var">ptr</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679539906"><span class="hs-identifier hs-var">offset</span></a></span><span> </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679539905"><span class="hs-identifier hs-var">innerDims</span></a></span><span>
</span><span id="line-1504"></span><span>      </span><span class="annot"><span class="annottext">IO (b -&gt; (a, b)) -&gt; IO b -&gt; IO (a, b)
forall (f :: * -&gt; *) a b. Applicative f =&gt; f (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;*&gt;</span></span><span> </span><span class="annot"><span class="annottext">Ptr () -&gt; Int -&gt; [Int] -&gt; IO b
forall a. TensorLikeRaw a =&gt; Ptr () -&gt; Int -&gt; [Int] -&gt; IO a
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#tensorPeekElemOff"><span class="hs-identifier hs-var">tensorPeekElemOff</span></a></span><span> </span><span class="annot"><span class="annottext">Ptr ()
</span><a href="#local-6989586621679539907"><span class="hs-identifier hs-var">ptr</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679539906"><span class="hs-identifier hs-var">offset</span></a></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Int
forall a. Num a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">+</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679539904"><span class="hs-identifier hs-var">width</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679539905"><span class="hs-identifier hs-var">innerDims</span></a></span><span>
</span><span id="line-1505"></span><span>    </span><span class="hs-keyword">where</span><span>
</span><span id="line-1506"></span><span>      </span><span id="local-6989586621679539904"><span class="annot"><span class="annottext">width :: Int
</span><a href="#local-6989586621679539904"><span class="hs-identifier hs-var hs-var">width</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">[Int] -&gt; Int
forall (t :: * -&gt; *) a. (Foldable t, Num a) =&gt; t a -&gt; a
</span><span class="hs-identifier hs-var">product</span></span><span> </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679539905"><span class="hs-identifier hs-var">innerDims</span></a></span><span>
</span><span id="line-1507"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#tensorPeekElemOff"><span class="hs-identifier hs-var">tensorPeekElemOff</span></a></span><span> </span><span class="annot"><span class="annottext">Ptr ()
</span><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-identifier">_</span></span><span> </span><span id="local-6989586621679539902"><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679539902"><span class="hs-identifier hs-var">dims'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">[Int] -&gt; Maybe (a, b) -&gt; IO (a, b)
forall a (m :: * -&gt; *) b.
(TensorLikeRaw a, MonadThrow m) =&gt;
[Int] -&gt; Maybe a -&gt; m b
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#unexpectedDimsError"><span class="hs-identifier hs-var">unexpectedDimsError</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679539920"><span class="hs-identifier hs-type">a</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679539919"><span class="hs-identifier hs-type">b</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679539902"><span class="hs-identifier hs-var">dims'</span></a></span><span> </span><span class="annot"><span class="annottext">Maybe (a, b)
forall (f :: * -&gt; *) a. Alternative f =&gt; f a
</span><span class="hs-identifier hs-var">empty</span></span><span>
</span><span id="line-1508"></span><span>
</span><span id="line-1509"></span><span>  </span><span id="local-6989586621679539901"><span class="annot"><span class="annottext">tensorPokeElemOff :: Ptr () -&gt; Int -&gt; [Int] -&gt; (a, b) -&gt; IO ()
</span><a href="#local-6989586621679539901"><span class="hs-identifier hs-var hs-var hs-var hs-var">tensorPokeElemOff</span></a></span></span><span> </span><span id="local-6989586621679539900"><span class="annot"><span class="annottext">Ptr ()
</span><a href="#local-6989586621679539900"><span class="hs-identifier hs-var">ptr</span></a></span></span><span> </span><span id="local-6989586621679539899"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679539899"><span class="hs-identifier hs-var">offset</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">2</span></span><span> </span><span class="annot"><span class="hs-glyph hs-type">:</span></span><span> </span><span id="local-6989586621679539898"><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679539898"><span class="hs-identifier hs-var">innerDims</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679539897"><span class="annot"><span class="annottext">a
</span><a href="#local-6989586621679539897"><span class="hs-identifier hs-var">x</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679539896"><span class="annot"><span class="annottext">b
</span><a href="#local-6989586621679539896"><span class="hs-identifier hs-var">y</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-1510"></span><span>    </span><span class="annot"><span class="annottext">Ptr () -&gt; Int -&gt; [Int] -&gt; a -&gt; IO ()
forall a. TensorLikeRaw a =&gt; Ptr () -&gt; Int -&gt; [Int] -&gt; a -&gt; IO ()
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#tensorPokeElemOff"><span class="hs-identifier hs-var">tensorPokeElemOff</span></a></span><span> </span><span class="annot"><span class="annottext">Ptr ()
</span><a href="#local-6989586621679539900"><span class="hs-identifier hs-var">ptr</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679539899"><span class="hs-identifier hs-var">offset</span></a></span><span> </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679539898"><span class="hs-identifier hs-var">innerDims</span></a></span><span> </span><span class="annot"><span class="annottext">a
</span><a href="#local-6989586621679539897"><span class="hs-identifier hs-var">x</span></a></span><span>
</span><span id="line-1511"></span><span>    </span><span class="annot"><span class="annottext">Ptr () -&gt; Int -&gt; [Int] -&gt; b -&gt; IO ()
forall a. TensorLikeRaw a =&gt; Ptr () -&gt; Int -&gt; [Int] -&gt; a -&gt; IO ()
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#tensorPokeElemOff"><span class="hs-identifier hs-var">tensorPokeElemOff</span></a></span><span> </span><span class="annot"><span class="annottext">Ptr ()
</span><a href="#local-6989586621679539900"><span class="hs-identifier hs-var">ptr</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679539899"><span class="hs-identifier hs-var">offset</span></a></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Int
forall a. Num a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">+</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679539895"><span class="hs-identifier hs-var">width</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679539898"><span class="hs-identifier hs-var">innerDims</span></a></span><span> </span><span class="annot"><span class="annottext">b
</span><a href="#local-6989586621679539896"><span class="hs-identifier hs-var">y</span></a></span><span>
</span><span id="line-1512"></span><span>    </span><span class="hs-keyword">where</span><span>
</span><span id="line-1513"></span><span>      </span><span id="local-6989586621679539895"><span class="annot"><span class="annottext">width :: Int
</span><a href="#local-6989586621679539895"><span class="hs-identifier hs-var hs-var">width</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">[Int] -&gt; Int
forall (t :: * -&gt; *) a. (Foldable t, Num a) =&gt; t a -&gt; a
</span><span class="hs-identifier hs-var">product</span></span><span> </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679539898"><span class="hs-identifier hs-var">innerDims</span></a></span><span>
</span><span id="line-1514"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#tensorPokeElemOff"><span class="hs-identifier hs-var">tensorPokeElemOff</span></a></span><span> </span><span class="annot"><span class="annottext">Ptr ()
</span><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-identifier">_</span></span><span> </span><span id="local-6989586621679539894"><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679539894"><span class="hs-identifier hs-var">dims'</span></a></span></span><span> </span><span id="local-6989586621679539893"><span class="annot"><span class="annottext">(a, b)
</span><a href="#local-6989586621679539893"><span class="hs-identifier hs-var">x</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">[Int] -&gt; Maybe (a, b) -&gt; IO ()
forall a (m :: * -&gt; *) b.
(TensorLikeRaw a, MonadThrow m) =&gt;
[Int] -&gt; Maybe a -&gt; m b
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#unexpectedDimsError"><span class="hs-identifier hs-var">unexpectedDimsError</span></a></span><span> </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679539894"><span class="hs-identifier hs-var">dims'</span></a></span><span> </span><span class="annot"><span class="annottext">(Maybe (a, b) -&gt; IO ()) -&gt; Maybe (a, b) -&gt; IO ()
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(a, b) -&gt; Maybe (a, b)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">(a, b)
</span><a href="#local-6989586621679539893"><span class="hs-identifier hs-var">x</span></a></span></span></span><span>
</span><span id="line-1515"></span><span>
</span><span id="line-1516"></span><span id="local-6989586621679539886"><span id="local-6989586621679539887"><span id="local-6989586621679539888"><span id="local-6989586621679539889"><span id="local-6989586621679539890"><span id="local-6989586621679539891"><span id="local-6989586621679539892"><span class="hs-keyword">instance</span><span>
</span><span id="line-1517"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorLike"><span class="hs-identifier hs-type">TensorLike</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679539892"><span class="hs-identifier hs-type">a</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679539891"><span class="hs-identifier hs-type">dType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679539890"><span class="hs-identifier hs-type">dims</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-1518"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorLike"><span class="hs-identifier hs-type">TensorLike</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679539889"><span class="hs-identifier hs-type">b</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679539891"><span class="hs-identifier hs-type">dType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679539888"><span class="hs-identifier hs-type">dims'</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-1519"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorLike"><span class="hs-identifier hs-type">TensorLike</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679539887"><span class="hs-identifier hs-type">c</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679539891"><span class="hs-identifier hs-type">dType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679539888"><span class="hs-identifier hs-type">dims'</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-1520"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorLikeRaw"><span class="hs-identifier hs-type">TensorLikeRaw</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679539892"><span class="hs-identifier hs-type">a</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-1521"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorLikeRaw"><span class="hs-identifier hs-type">TensorLikeRaw</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679539889"><span class="hs-identifier hs-type">b</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-1522"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorLikeRaw"><span class="hs-identifier hs-type">TensorLikeRaw</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679539887"><span class="hs-identifier hs-type">c</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-1523"></span><span>    </span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-type">SingI</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679539891"><span class="hs-identifier hs-type">dType</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-1524"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetDims"><span class="hs-identifier hs-type">SGetDims</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679539886"><span class="hs-identifier hs-type">dimsOut</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-1525"></span><span>    </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679539886"><span class="hs-identifier hs-type">dimsOut</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#InsertDimF"><span class="hs-identifier hs-type">InsertDimF</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">0</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679539890"><span class="hs-identifier hs-type">dims</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679539888"><span class="hs-identifier hs-type">dims'</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-number">3</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-1526"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-1527"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorLike"><span class="hs-identifier hs-type">TensorLike</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679539892"><span class="hs-identifier hs-type">a</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679539889"><span class="hs-identifier hs-type">b</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679539887"><span class="hs-identifier hs-type">c</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679539891"><span class="hs-identifier hs-type">dType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679539886"><span class="hs-identifier hs-type">dimsOut</span></a></span><span>
</span><span id="line-1528"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-1529"></span><span>  </span><span id="local-6989586621679539883"><span class="annot"><span class="annottext">sToTensor :: SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; (a, b, c)
-&gt; m (Tensor
        gradient layout device ('DataType dType) ('Shape dimsOut))
</span><a href="#local-6989586621679539883"><span class="hs-identifier hs-var hs-var hs-var hs-var">sToTensor</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; (a, b, c)
-&gt; m (Tensor
        gradient layout device ('DataType dType) ('Shape dimsOut))
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat)) a
       (dType :: DType) (dims :: [Dim (Name Symbol) (Size Nat)])
       (m :: * -&gt; *).
(TensorLike a dType dims, TensorLikeRaw a, SingI dType,
 MonadThrow m) =&gt;
SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; a
-&gt; m (Tensor
        gradient layout device ('DataType dType) ('Shape dims))
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sToTensorRaw"><span class="hs-identifier hs-var">sToTensorRaw</span></a></span><span>
</span><span id="line-1530"></span><span>  </span><span id="local-6989586621679539882"><span class="annot"><span class="annottext">fromTensor :: Tensor gradient layout device ('DataType dType) ('Shape dimsOut)
-&gt; (a, b, c)
</span><a href="#local-6989586621679539882"><span class="hs-identifier hs-var hs-var hs-var hs-var">fromTensor</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device ('DataType dType) ('Shape dimsOut)
-&gt; (a, b, c)
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat)) a
       (dType :: DType) (dims :: [Dim (Name Symbol) (Size Nat)]).
(TensorLike a dType dims, TensorLikeRaw a, SGetDims dims) =&gt;
Tensor gradient layout device ('DataType dType) ('Shape dims) -&gt; a
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#fromTensorRaw"><span class="hs-identifier hs-var">fromTensorRaw</span></a></span></span></span></span></span></span></span></span><span>
</span><span id="line-1531"></span><span>
</span><span id="line-1532"></span><span id="local-6989586621679540958"><span id="local-6989586621679540959"><span id="local-6989586621679540960"><span id="local-6989586621679540961"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#unzip3"><span class="hs-identifier hs-type">unzip3</span></a></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Functor</span></span><span> </span><span class="annot"><a href="#local-6989586621679540961"><span class="hs-identifier hs-type">f</span></a></span><span> </span><span class="hs-glyph">=&gt;</span><span> </span><span class="annot"><a href="#local-6989586621679540961"><span class="hs-identifier hs-type">f</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679540960"><span class="hs-identifier hs-type">a</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679540959"><span class="hs-identifier hs-type">b</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679540958"><span class="hs-identifier hs-type">c</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679540961"><span class="hs-identifier hs-type">f</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540960"><span class="hs-identifier hs-type">a</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679540961"><span class="hs-identifier hs-type">f</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540959"><span class="hs-identifier hs-type">b</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679540961"><span class="hs-identifier hs-type">f</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540958"><span class="hs-identifier hs-type">c</span></a></span><span class="hs-special">)</span></span></span></span></span><span>
</span><span id="line-1533"></span><span id="unzip3"><span class="annot"><span class="annottext">unzip3 :: f (a, b, c) -&gt; (f a, f b, f c)
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#unzip3"><span class="hs-identifier hs-var hs-var">unzip3</span></a></span></span><span> </span><span id="local-6989586621679539880"><span class="annot"><span class="annottext">f (a, b, c)
</span><a href="#local-6989586621679539880"><span class="hs-identifier hs-var">xyz</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-1534"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="hs-special">(</span><span class="hs-glyph">\</span><span class="hs-special">(</span><span id="local-6989586621679539879"><span class="annot"><span class="annottext">a
</span><a href="#local-6989586621679539879"><span class="hs-identifier hs-var">x</span></a></span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">b
</span><span class="hs-identifier">_</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">c
</span><span class="hs-identifier">_</span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">a
</span><a href="#local-6989586621679539879"><span class="hs-identifier hs-var">x</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">((a, b, c) -&gt; a) -&gt; f (a, b, c) -&gt; f a
forall (f :: * -&gt; *) a b. Functor f =&gt; (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;$&gt;</span></span><span> </span><span class="annot"><span class="annottext">f (a, b, c)
</span><a href="#local-6989586621679539880"><span class="hs-identifier hs-var">xyz</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-1535"></span><span>    </span><span class="hs-special">(</span><span class="hs-glyph">\</span><span class="hs-special">(</span><span class="annot"><span class="annottext">a
</span><span class="hs-identifier">_</span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679539878"><span class="annot"><span class="annottext">b
</span><a href="#local-6989586621679539878"><span class="hs-identifier hs-var">y</span></a></span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">c
</span><span class="hs-identifier">_</span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">b
</span><a href="#local-6989586621679539878"><span class="hs-identifier hs-var">y</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">((a, b, c) -&gt; b) -&gt; f (a, b, c) -&gt; f b
forall (f :: * -&gt; *) a b. Functor f =&gt; (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;$&gt;</span></span><span> </span><span class="annot"><span class="annottext">f (a, b, c)
</span><a href="#local-6989586621679539880"><span class="hs-identifier hs-var">xyz</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-1536"></span><span>    </span><span class="hs-special">(</span><span class="hs-glyph">\</span><span class="hs-special">(</span><span class="annot"><span class="annottext">a
</span><span class="hs-identifier">_</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">b
</span><span class="hs-identifier">_</span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679539877"><span class="annot"><span class="annottext">c
</span><a href="#local-6989586621679539877"><span class="hs-identifier hs-var">z</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">c
</span><a href="#local-6989586621679539877"><span class="hs-identifier hs-var">z</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">((a, b, c) -&gt; c) -&gt; f (a, b, c) -&gt; f c
forall (f :: * -&gt; *) a b. Functor f =&gt; (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;$&gt;</span></span><span> </span><span class="annot"><span class="annottext">f (a, b, c)
</span><a href="#local-6989586621679539880"><span class="hs-identifier hs-var">xyz</span></a></span><span>
</span><span id="line-1537"></span><span>  </span><span class="hs-special">)</span><span>
</span><span id="line-1538"></span><span>
</span><span id="line-1539"></span><span id="local-6989586621679539874"><span id="local-6989586621679539875"><span id="local-6989586621679539876"><span class="hs-keyword">instance</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorLikeRaw"><span class="hs-identifier hs-type">TensorLikeRaw</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679539876"><span class="hs-identifier hs-type">a</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorLikeRaw"><span class="hs-identifier hs-type">TensorLikeRaw</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679539875"><span class="hs-identifier hs-type">b</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorLikeRaw"><span class="hs-identifier hs-type">TensorLikeRaw</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679539874"><span class="hs-identifier hs-type">c</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorLikeRaw"><span class="hs-identifier hs-type">TensorLikeRaw</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679539876"><span class="hs-identifier hs-type">a</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679539875"><span class="hs-identifier hs-type">b</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679539874"><span class="hs-identifier hs-type">c</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-1540"></span><span>  </span><span id="local-6989586621679539869"><span class="annot"><span class="annottext">guessDim :: Maybe (a, b, c) -&gt; Maybe Int
</span><a href="#local-6989586621679539869"><span class="hs-identifier hs-var hs-var hs-var hs-var">guessDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Maybe Int -&gt; Maybe (a, b, c) -&gt; Maybe Int
forall a b. a -&gt; b -&gt; a
</span><span class="hs-identifier hs-var">const</span></span><span> </span><span class="annot"><span class="annottext">(Maybe Int -&gt; Maybe (a, b, c) -&gt; Maybe Int)
-&gt; Maybe Int -&gt; Maybe (a, b, c) -&gt; Maybe Int
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Maybe Int
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">2</span></span><span>
</span><span id="line-1541"></span><span>
</span><span id="line-1542"></span><span>  </span><span id="local-6989586621679539868"><span class="annot"><span class="annottext">guessInnerDims :: Maybe (a, b, c) -&gt; m [Int]
</span><a href="#local-6989586621679539868"><span class="hs-identifier hs-var hs-var hs-var hs-var">guessInnerDims</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Maybe (a, b, c) -&gt; (Maybe a, Maybe b, Maybe c)
forall (f :: * -&gt; *) a b c.
Functor f =&gt;
f (a, b, c) -&gt; (f a, f b, f c)
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#unzip3"><span class="hs-identifier hs-var">unzip3</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679539867"><span class="annot"><span class="annottext">Maybe a
</span><a href="#local-6989586621679539867"><span class="hs-identifier hs-var">x</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679539866"><span class="annot"><span class="annottext">Maybe b
</span><a href="#local-6989586621679539866"><span class="hs-identifier hs-var">y</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679539865"><span class="annot"><span class="annottext">Maybe c
</span><a href="#local-6989586621679539865"><span class="hs-identifier hs-var">z</span></a></span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-1543"></span><span>    </span><span id="local-6989586621679539864"><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679539864"><span class="hs-identifier hs-var">xDims</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">Maybe a -&gt; m [Int]
forall a (m :: * -&gt; *).
(TensorLikeRaw a, MonadThrow m) =&gt;
Maybe a -&gt; m [Int]
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#guessDims"><span class="hs-identifier hs-var">guessDims</span></a></span><span> </span><span class="annot"><span class="annottext">Maybe a
</span><a href="#local-6989586621679539867"><span class="hs-identifier hs-var">x</span></a></span><span>
</span><span id="line-1544"></span><span>    </span><span id="local-6989586621679539863"><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679539863"><span class="hs-identifier hs-var">yDims</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">Maybe b -&gt; m [Int]
forall a (m :: * -&gt; *).
(TensorLikeRaw a, MonadThrow m) =&gt;
Maybe a -&gt; m [Int]
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#guessDims"><span class="hs-identifier hs-var">guessDims</span></a></span><span> </span><span class="annot"><span class="annottext">Maybe b
</span><a href="#local-6989586621679539866"><span class="hs-identifier hs-var">y</span></a></span><span>
</span><span id="line-1545"></span><span>    </span><span id="local-6989586621679539862"><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679539862"><span class="hs-identifier hs-var">zDims</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">Maybe c -&gt; m [Int]
forall a (m :: * -&gt; *).
(TensorLikeRaw a, MonadThrow m) =&gt;
Maybe a -&gt; m [Int]
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#guessDims"><span class="hs-identifier hs-var">guessDims</span></a></span><span> </span><span class="annot"><span class="annottext">Maybe c
</span><a href="#local-6989586621679539865"><span class="hs-identifier hs-var">z</span></a></span><span>
</span><span id="line-1546"></span><span>    </span><span class="annot"><span class="annottext">([Int] -&gt; m ()) -&gt; [[Int]] -&gt; m ()
forall (t :: * -&gt; *) (f :: * -&gt; *) a b.
(Foldable t, Applicative f) =&gt;
(a -&gt; f b) -&gt; t a -&gt; f ()
</span><span class="hs-identifier hs-var">traverse_</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">[Int] -&gt; [Int] -&gt; m ()
forall (m :: * -&gt; *). MonadThrow m =&gt; [Int] -&gt; [Int] -&gt; m ()
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#checkDims"><span class="hs-identifier hs-var">checkDims</span></a></span><span> </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679539864"><span class="hs-identifier hs-var">xDims</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679539863"><span class="hs-identifier hs-var">yDims</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679539862"><span class="hs-identifier hs-var">zDims</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-1547"></span><span>    </span><span class="annot"><span class="annottext">[Int] -&gt; m [Int]
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679539864"><span class="hs-identifier hs-var">xDims</span></a></span><span>
</span><span id="line-1548"></span><span>
</span><span id="line-1549"></span><span>  </span><span id="local-6989586621679539861"><span class="annot"><span class="annottext">tensorPeekElemOff :: Ptr () -&gt; Int -&gt; [Int] -&gt; IO (a, b, c)
</span><a href="#local-6989586621679539861"><span class="hs-identifier hs-var hs-var hs-var hs-var">tensorPeekElemOff</span></a></span></span><span> </span><span id="local-6989586621679539860"><span class="annot"><span class="annottext">Ptr ()
</span><a href="#local-6989586621679539860"><span class="hs-identifier hs-var">ptr</span></a></span></span><span> </span><span id="local-6989586621679539859"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679539859"><span class="hs-identifier hs-var">offset</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">3</span></span><span> </span><span class="annot"><span class="hs-glyph hs-type">:</span></span><span> </span><span id="local-6989586621679539858"><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679539858"><span class="hs-identifier hs-var">innerDims</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-1550"></span><span>    </span><span class="hs-special">(</span><span class="hs-special">,</span><span class="hs-special">,</span><span class="hs-special">)</span><span>
</span><span id="line-1551"></span><span>      </span><span class="annot"><span class="annottext">(a -&gt; b -&gt; c -&gt; (a, b, c)) -&gt; IO a -&gt; IO (b -&gt; c -&gt; (a, b, c))
forall (f :: * -&gt; *) a b. Functor f =&gt; (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;$&gt;</span></span><span> </span><span class="annot"><span class="annottext">Ptr () -&gt; Int -&gt; [Int] -&gt; IO a
forall a. TensorLikeRaw a =&gt; Ptr () -&gt; Int -&gt; [Int] -&gt; IO a
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#tensorPeekElemOff"><span class="hs-identifier hs-var">tensorPeekElemOff</span></a></span><span> </span><span class="annot"><span class="annottext">Ptr ()
</span><a href="#local-6989586621679539860"><span class="hs-identifier hs-var">ptr</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679539859"><span class="hs-identifier hs-var">offset</span></a></span><span> </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679539858"><span class="hs-identifier hs-var">innerDims</span></a></span><span>
</span><span id="line-1552"></span><span>      </span><span class="annot"><span class="annottext">IO (b -&gt; c -&gt; (a, b, c)) -&gt; IO b -&gt; IO (c -&gt; (a, b, c))
forall (f :: * -&gt; *) a b. Applicative f =&gt; f (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;*&gt;</span></span><span> </span><span class="annot"><span class="annottext">Ptr () -&gt; Int -&gt; [Int] -&gt; IO b
forall a. TensorLikeRaw a =&gt; Ptr () -&gt; Int -&gt; [Int] -&gt; IO a
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#tensorPeekElemOff"><span class="hs-identifier hs-var">tensorPeekElemOff</span></a></span><span> </span><span class="annot"><span class="annottext">Ptr ()
</span><a href="#local-6989586621679539860"><span class="hs-identifier hs-var">ptr</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679539859"><span class="hs-identifier hs-var">offset</span></a></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Int
forall a. Num a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">+</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679539857"><span class="hs-identifier hs-var">width</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679539858"><span class="hs-identifier hs-var">innerDims</span></a></span><span>
</span><span id="line-1553"></span><span>      </span><span class="annot"><span class="annottext">IO (c -&gt; (a, b, c)) -&gt; IO c -&gt; IO (a, b, c)
forall (f :: * -&gt; *) a b. Applicative f =&gt; f (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;*&gt;</span></span><span> </span><span class="annot"><span class="annottext">Ptr () -&gt; Int -&gt; [Int] -&gt; IO c
forall a. TensorLikeRaw a =&gt; Ptr () -&gt; Int -&gt; [Int] -&gt; IO a
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#tensorPeekElemOff"><span class="hs-identifier hs-var">tensorPeekElemOff</span></a></span><span> </span><span class="annot"><span class="annottext">Ptr ()
</span><a href="#local-6989586621679539860"><span class="hs-identifier hs-var">ptr</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679539859"><span class="hs-identifier hs-var">offset</span></a></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Int
forall a. Num a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">+</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">2</span></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Int
forall a. Num a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">*</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679539857"><span class="hs-identifier hs-var">width</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679539858"><span class="hs-identifier hs-var">innerDims</span></a></span><span>
</span><span id="line-1554"></span><span>    </span><span class="hs-keyword">where</span><span>
</span><span id="line-1555"></span><span>      </span><span id="local-6989586621679539857"><span class="annot"><span class="annottext">width :: Int
</span><a href="#local-6989586621679539857"><span class="hs-identifier hs-var hs-var">width</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">[Int] -&gt; Int
forall (t :: * -&gt; *) a. (Foldable t, Num a) =&gt; t a -&gt; a
</span><span class="hs-identifier hs-var">product</span></span><span> </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679539858"><span class="hs-identifier hs-var">innerDims</span></a></span><span>
</span><span id="line-1556"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#tensorPeekElemOff"><span class="hs-identifier hs-var">tensorPeekElemOff</span></a></span><span> </span><span class="annot"><span class="annottext">Ptr ()
</span><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-identifier">_</span></span><span> </span><span id="local-6989586621679539856"><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679539856"><span class="hs-identifier hs-var">dims'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">[Int] -&gt; Maybe (a, b) -&gt; IO (a, b, c)
forall a (m :: * -&gt; *) b.
(TensorLikeRaw a, MonadThrow m) =&gt;
[Int] -&gt; Maybe a -&gt; m b
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#unexpectedDimsError"><span class="hs-identifier hs-var">unexpectedDimsError</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679539876"><span class="hs-identifier hs-type">a</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679539875"><span class="hs-identifier hs-type">b</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679539856"><span class="hs-identifier hs-var">dims'</span></a></span><span> </span><span class="annot"><span class="annottext">Maybe (a, b)
forall (f :: * -&gt; *) a. Alternative f =&gt; f a
</span><span class="hs-identifier hs-var">empty</span></span><span>
</span><span id="line-1557"></span><span>
</span><span id="line-1558"></span><span>  </span><span id="local-6989586621679539855"><span class="annot"><span class="annottext">tensorPokeElemOff :: Ptr () -&gt; Int -&gt; [Int] -&gt; (a, b, c) -&gt; IO ()
</span><a href="#local-6989586621679539855"><span class="hs-identifier hs-var hs-var hs-var hs-var">tensorPokeElemOff</span></a></span></span><span> </span><span id="local-6989586621679539854"><span class="annot"><span class="annottext">Ptr ()
</span><a href="#local-6989586621679539854"><span class="hs-identifier hs-var">ptr</span></a></span></span><span> </span><span id="local-6989586621679539853"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679539853"><span class="hs-identifier hs-var">offset</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">3</span></span><span> </span><span class="annot"><span class="hs-glyph hs-type">:</span></span><span> </span><span id="local-6989586621679539852"><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679539852"><span class="hs-identifier hs-var">innerDims</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679539851"><span class="annot"><span class="annottext">a
</span><a href="#local-6989586621679539851"><span class="hs-identifier hs-var">x</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679539850"><span class="annot"><span class="annottext">b
</span><a href="#local-6989586621679539850"><span class="hs-identifier hs-var">y</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679539849"><span class="annot"><span class="annottext">c
</span><a href="#local-6989586621679539849"><span class="hs-identifier hs-var">z</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-1559"></span><span>    </span><span class="annot"><span class="annottext">Ptr () -&gt; Int -&gt; [Int] -&gt; a -&gt; IO ()
forall a. TensorLikeRaw a =&gt; Ptr () -&gt; Int -&gt; [Int] -&gt; a -&gt; IO ()
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#tensorPokeElemOff"><span class="hs-identifier hs-var">tensorPokeElemOff</span></a></span><span> </span><span class="annot"><span class="annottext">Ptr ()
</span><a href="#local-6989586621679539854"><span class="hs-identifier hs-var">ptr</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679539853"><span class="hs-identifier hs-var">offset</span></a></span><span> </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679539852"><span class="hs-identifier hs-var">innerDims</span></a></span><span> </span><span class="annot"><span class="annottext">a
</span><a href="#local-6989586621679539851"><span class="hs-identifier hs-var">x</span></a></span><span>
</span><span id="line-1560"></span><span>    </span><span class="annot"><span class="annottext">Ptr () -&gt; Int -&gt; [Int] -&gt; b -&gt; IO ()
forall a. TensorLikeRaw a =&gt; Ptr () -&gt; Int -&gt; [Int] -&gt; a -&gt; IO ()
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#tensorPokeElemOff"><span class="hs-identifier hs-var">tensorPokeElemOff</span></a></span><span> </span><span class="annot"><span class="annottext">Ptr ()
</span><a href="#local-6989586621679539854"><span class="hs-identifier hs-var">ptr</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679539853"><span class="hs-identifier hs-var">offset</span></a></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Int
forall a. Num a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">+</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679539848"><span class="hs-identifier hs-var">width</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679539852"><span class="hs-identifier hs-var">innerDims</span></a></span><span> </span><span class="annot"><span class="annottext">b
</span><a href="#local-6989586621679539850"><span class="hs-identifier hs-var">y</span></a></span><span>
</span><span id="line-1561"></span><span>    </span><span class="annot"><span class="annottext">Ptr () -&gt; Int -&gt; [Int] -&gt; c -&gt; IO ()
forall a. TensorLikeRaw a =&gt; Ptr () -&gt; Int -&gt; [Int] -&gt; a -&gt; IO ()
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#tensorPokeElemOff"><span class="hs-identifier hs-var">tensorPokeElemOff</span></a></span><span> </span><span class="annot"><span class="annottext">Ptr ()
</span><a href="#local-6989586621679539854"><span class="hs-identifier hs-var">ptr</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679539853"><span class="hs-identifier hs-var">offset</span></a></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Int
forall a. Num a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">+</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">2</span></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Int
forall a. Num a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">*</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679539848"><span class="hs-identifier hs-var">width</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679539852"><span class="hs-identifier hs-var">innerDims</span></a></span><span> </span><span class="annot"><span class="annottext">c
</span><a href="#local-6989586621679539849"><span class="hs-identifier hs-var">z</span></a></span><span>
</span><span id="line-1562"></span><span>    </span><span class="hs-keyword">where</span><span>
</span><span id="line-1563"></span><span>      </span><span id="local-6989586621679539848"><span class="annot"><span class="annottext">width :: Int
</span><a href="#local-6989586621679539848"><span class="hs-identifier hs-var hs-var">width</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">[Int] -&gt; Int
forall (t :: * -&gt; *) a. (Foldable t, Num a) =&gt; t a -&gt; a
</span><span class="hs-identifier hs-var">product</span></span><span> </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679539852"><span class="hs-identifier hs-var">innerDims</span></a></span><span>
</span><span id="line-1564"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#tensorPokeElemOff"><span class="hs-identifier hs-var">tensorPokeElemOff</span></a></span><span> </span><span class="annot"><span class="annottext">Ptr ()
</span><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-identifier">_</span></span><span> </span><span id="local-6989586621679539847"><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679539847"><span class="hs-identifier hs-var">dims'</span></a></span></span><span> </span><span id="local-6989586621679539846"><span class="annot"><span class="annottext">(a, b, c)
</span><a href="#local-6989586621679539846"><span class="hs-identifier hs-var">x</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">[Int] -&gt; Maybe (a, b, c) -&gt; IO ()
forall a (m :: * -&gt; *) b.
(TensorLikeRaw a, MonadThrow m) =&gt;
[Int] -&gt; Maybe a -&gt; m b
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#unexpectedDimsError"><span class="hs-identifier hs-var">unexpectedDimsError</span></a></span><span> </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679539847"><span class="hs-identifier hs-var">dims'</span></a></span><span> </span><span class="annot"><span class="annottext">(Maybe (a, b, c) -&gt; IO ()) -&gt; Maybe (a, b, c) -&gt; IO ()
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(a, b, c) -&gt; Maybe (a, b, c)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">(a, b, c)
</span><a href="#local-6989586621679539846"><span class="hs-identifier hs-var">x</span></a></span></span></span></span><span>
</span><span id="line-1565"></span><span>
</span><span id="line-1566"></span><span id="local-6989586621679539842"><span id="local-6989586621679539843"><span id="local-6989586621679539844"><span id="local-6989586621679539845"><span class="hs-keyword">instance</span><span>
</span><span id="line-1567"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorLike"><span class="hs-identifier hs-type">TensorLike</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679539845"><span class="hs-identifier hs-type">a</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679539844"><span class="hs-identifier hs-type">dType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679539843"><span class="hs-identifier hs-type">dims</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-1568"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorLikeRaw"><span class="hs-identifier hs-type">TensorLikeRaw</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679539845"><span class="hs-identifier hs-type">a</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-1569"></span><span>    </span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-type">SingI</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679539844"><span class="hs-identifier hs-type">dType</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-1570"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetDims"><span class="hs-identifier hs-type">SGetDims</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679539842"><span class="hs-identifier hs-type">dimsOut</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-1571"></span><span>    </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679539842"><span class="hs-identifier hs-type">dimsOut</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#InsertDimF"><span class="hs-identifier hs-type">InsertDimF</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">0</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679539843"><span class="hs-identifier hs-type">dims</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#UncheckedSize"><span class="hs-identifier hs-type">UncheckedSize</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-1572"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-1573"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorLike"><span class="hs-identifier hs-type">TensorLike</span></a></span><span> </span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679539845"><span class="hs-identifier hs-type">a</span></a></span><span class="hs-special">]</span><span> </span><span class="annot"><a href="#local-6989586621679539844"><span class="hs-identifier hs-type">dType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679539842"><span class="hs-identifier hs-type">dimsOut</span></a></span><span>
</span><span id="line-1574"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-1575"></span><span>  </span><span id="local-6989586621679539839"><span class="annot"><span class="annottext">sToTensor :: SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; [a]
-&gt; m (Tensor
        gradient layout device ('DataType dType) ('Shape dimsOut))
</span><a href="#local-6989586621679539839"><span class="hs-identifier hs-var hs-var hs-var hs-var">sToTensor</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; [a]
-&gt; m (Tensor
        gradient layout device ('DataType dType) ('Shape dimsOut))
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat)) a
       (dType :: DType) (dims :: [Dim (Name Symbol) (Size Nat)])
       (m :: * -&gt; *).
(TensorLike a dType dims, TensorLikeRaw a, SingI dType,
 MonadThrow m) =&gt;
SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; a
-&gt; m (Tensor
        gradient layout device ('DataType dType) ('Shape dims))
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sToTensorRaw"><span class="hs-identifier hs-var">sToTensorRaw</span></a></span><span>
</span><span id="line-1576"></span><span>  </span><span id="local-6989586621679539838"><span class="annot"><span class="annottext">fromTensor :: Tensor gradient layout device ('DataType dType) ('Shape dimsOut)
-&gt; [a]
</span><a href="#local-6989586621679539838"><span class="hs-identifier hs-var hs-var hs-var hs-var">fromTensor</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device ('DataType dType) ('Shape dimsOut)
-&gt; [a]
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat)) a
       (dType :: DType) (dims :: [Dim (Name Symbol) (Size Nat)]).
(TensorLike a dType dims, TensorLikeRaw a, SGetDims dims) =&gt;
Tensor gradient layout device ('DataType dType) ('Shape dims) -&gt; a
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#fromTensorRaw"><span class="hs-identifier hs-var">fromTensorRaw</span></a></span></span></span></span></span><span>
</span><span id="line-1577"></span><span>
</span><span id="line-1578"></span><span id="local-6989586621679539837"><span class="hs-keyword">instance</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorLikeRaw"><span class="hs-identifier hs-type">TensorLikeRaw</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679539837"><span class="hs-identifier hs-type">a</span></a></span><span> </span><span class="hs-glyph">=&gt;</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorLikeRaw"><span class="hs-identifier hs-type">TensorLikeRaw</span></a></span><span> </span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679539837"><span class="hs-identifier hs-type">a</span></a></span><span class="hs-special">]</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-1579"></span><span>  </span><span id="local-6989586621679539832"><span class="annot"><span class="annottext">guessDim :: Maybe [a] -&gt; Maybe Int
</span><a href="#local-6989586621679539832"><span class="hs-identifier hs-var hs-var hs-var hs-var">guessDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Int -&gt; Maybe Int
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">(Int -&gt; Maybe Int) -&gt; (Maybe [a] -&gt; Int) -&gt; Maybe [a] -&gt; Maybe Int
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Int -&gt; ([a] -&gt; Int) -&gt; Maybe [a] -&gt; Int
forall b a. b -&gt; (a -&gt; b) -&gt; Maybe a -&gt; b
</span><span class="hs-identifier hs-var">maybe</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">0</span></span><span> </span><span class="annot"><span class="annottext">[a] -&gt; Int
forall (t :: * -&gt; *) a. Foldable t =&gt; t a -&gt; Int
</span><span class="hs-identifier hs-var">length</span></span><span>
</span><span id="line-1580"></span><span>
</span><span id="line-1581"></span><span>  </span><span id="local-6989586621679539829"><span class="annot"><span class="annottext">guessInnerDims :: Maybe [a] -&gt; m [Int]
</span><a href="#local-6989586621679539829"><span class="hs-identifier hs-var hs-var hs-var hs-var">guessInnerDims</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-1582"></span><span>    </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Maybe [a] -&gt; ([a] -&gt; Maybe (NonEmpty a)) -&gt; Maybe (NonEmpty a)
forall (m :: * -&gt; *) a b. Monad m =&gt; m a -&gt; (a -&gt; m b) -&gt; m b
</span><span class="hs-operator hs-var">&gt;&gt;=</span></span><span> </span><span class="annot"><span class="annottext">[a] -&gt; Maybe (NonEmpty a)
forall a. [a] -&gt; Maybe (NonEmpty a)
</span><span class="hs-identifier hs-var">nonEmpty</span></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">(Maybe [a] -&gt; Maybe (NonEmpty a))
-&gt; (Maybe (NonEmpty a) -&gt; m [Int]) -&gt; Maybe [a] -&gt; m [Int]
forall k (cat :: k -&gt; k -&gt; *) (a :: k) (b :: k) (c :: k).
Category cat =&gt;
cat a b -&gt; cat b c -&gt; cat a c
</span><span class="hs-operator hs-var">&gt;&gt;&gt;</span></span><span> </span><span class="hs-glyph">\</span><span class="hs-glyph">case</span><span>
</span><span id="line-1583"></span><span>      </span><span class="annot"><span class="annottext">Maybe (NonEmpty a)
</span><span class="hs-identifier hs-var">Nothing</span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">Maybe a -&gt; m [Int]
forall a (m :: * -&gt; *).
(TensorLikeRaw a, MonadThrow m) =&gt;
Maybe a -&gt; m [Int]
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#guessDims"><span class="hs-identifier hs-var">guessDims</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679539837"><span class="hs-identifier hs-type">a</span></a></span><span> </span><span class="annot"><span class="annottext">Maybe a
forall (f :: * -&gt; *) a. Alternative f =&gt; f a
</span><span class="hs-identifier hs-var">empty</span></span><span>
</span><span id="line-1584"></span><span>      </span><span class="annot"><span class="hs-identifier hs-type">Just</span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679539828"><span class="annot"><span class="annottext">a
</span><a href="#local-6989586621679539828"><span class="hs-identifier hs-var">x</span></a></span></span><span> </span><span class="annot"><span class="hs-operator hs-type">:|</span></span><span> </span><span id="local-6989586621679539827"><span class="annot"><span class="annottext">[a]
</span><a href="#local-6989586621679539827"><span class="hs-identifier hs-var">xs</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-1585"></span><span>        </span><span id="local-6989586621679539826"><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679539826"><span class="hs-identifier hs-var">xDims</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">Maybe a -&gt; m [Int]
forall a (m :: * -&gt; *).
(TensorLikeRaw a, MonadThrow m) =&gt;
Maybe a -&gt; m [Int]
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#guessDims"><span class="hs-identifier hs-var">guessDims</span></a></span><span> </span><span class="annot"><span class="annottext">(Maybe a -&gt; m [Int]) -&gt; Maybe a -&gt; m [Int]
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">a -&gt; Maybe a
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">a
</span><a href="#local-6989586621679539828"><span class="hs-identifier hs-var">x</span></a></span><span>
</span><span id="line-1586"></span><span>        </span><span class="annot"><span class="annottext">(a -&gt; m ()) -&gt; [a] -&gt; m ()
forall (t :: * -&gt; *) (f :: * -&gt; *) a b.
(Foldable t, Applicative f) =&gt;
(a -&gt; f b) -&gt; t a -&gt; f ()
</span><span class="hs-identifier hs-var">traverse_</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">[Int] -&gt; [Int] -&gt; m ()
forall (m :: * -&gt; *). MonadThrow m =&gt; [Int] -&gt; [Int] -&gt; m ()
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#checkDims"><span class="hs-identifier hs-var">checkDims</span></a></span><span> </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679539826"><span class="hs-identifier hs-var">xDims</span></a></span><span> </span><span class="annot"><span class="annottext">([Int] -&gt; m ()) -&gt; (a -&gt; m [Int]) -&gt; a -&gt; m ()
forall (m :: * -&gt; *) b c a.
Monad m =&gt;
(b -&gt; m c) -&gt; (a -&gt; m b) -&gt; a -&gt; m c
</span><span class="hs-operator hs-var">&lt;=&lt;</span></span><span> </span><span class="annot"><span class="annottext">Maybe a -&gt; m [Int]
forall a (m :: * -&gt; *).
(TensorLikeRaw a, MonadThrow m) =&gt;
Maybe a -&gt; m [Int]
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#guessDims"><span class="hs-identifier hs-var">guessDims</span></a></span><span> </span><span class="annot"><span class="annottext">(Maybe a -&gt; m [Int]) -&gt; (a -&gt; Maybe a) -&gt; a -&gt; m [Int]
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">a -&gt; Maybe a
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">[a]
</span><a href="#local-6989586621679539827"><span class="hs-identifier hs-var">xs</span></a></span><span>
</span><span id="line-1587"></span><span>        </span><span class="annot"><span class="annottext">[Int] -&gt; m [Int]
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679539826"><span class="hs-identifier hs-var">xDims</span></a></span><span>
</span><span id="line-1588"></span><span>
</span><span id="line-1589"></span><span>  </span><span id="local-6989586621679539825"><span class="annot"><span class="annottext">tensorPeekElemOff :: Ptr () -&gt; Int -&gt; [Int] -&gt; IO [a]
</span><a href="#local-6989586621679539825"><span class="hs-identifier hs-var hs-var hs-var hs-var">tensorPeekElemOff</span></a></span></span><span> </span><span id="local-6989586621679539824"><span class="annot"><span class="annottext">Ptr ()
</span><a href="#local-6989586621679539824"><span class="hs-identifier hs-var">ptr</span></a></span></span><span> </span><span id="local-6989586621679539823"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679539823"><span class="hs-identifier hs-var">offset</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679539822"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679539822"><span class="hs-identifier hs-var">d</span></a></span></span><span> </span><span class="annot"><span class="hs-glyph hs-type">:</span></span><span> </span><span id="local-6989586621679539821"><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679539821"><span class="hs-identifier hs-var">innerDims</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-1590"></span><span>    </span><span class="annot"><span class="annottext">[Int] -&gt; (Int -&gt; IO a) -&gt; IO [a]
forall (t :: * -&gt; *) (m :: * -&gt; *) a b.
(Traversable t, Monad m) =&gt;
t a -&gt; (a -&gt; m b) -&gt; m (t b)
</span><span class="hs-identifier hs-var">forM</span></span><span> </span><span class="hs-special">[</span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">0</span></span><span> </span><span class="hs-glyph">..</span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679539822"><span class="hs-identifier hs-var">d</span></a></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Int
forall a. Num a =&gt; a -&gt; a -&gt; a
</span><span class="hs-glyph hs-var">-</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">1</span></span><span class="hs-special">]</span><span> </span><span class="annot"><span class="annottext">((Int -&gt; IO a) -&gt; IO [a]) -&gt; (Int -&gt; IO a) -&gt; IO [a]
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-glyph">\</span><span id="local-6989586621679539820"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679539820"><span class="hs-identifier hs-var">i</span></a></span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-1591"></span><span>      </span><span class="annot"><span class="annottext">Ptr () -&gt; Int -&gt; [Int] -&gt; IO a
forall a. TensorLikeRaw a =&gt; Ptr () -&gt; Int -&gt; [Int] -&gt; IO a
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#tensorPeekElemOff"><span class="hs-identifier hs-var">tensorPeekElemOff</span></a></span><span> </span><span class="annot"><span class="annottext">Ptr ()
</span><a href="#local-6989586621679539824"><span class="hs-identifier hs-var">ptr</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679539823"><span class="hs-identifier hs-var">offset</span></a></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Int
forall a. Num a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">+</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679539820"><span class="hs-identifier hs-var">i</span></a></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Int
forall a. Num a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">*</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679539819"><span class="hs-identifier hs-var">width</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679539821"><span class="hs-identifier hs-var">innerDims</span></a></span><span>
</span><span id="line-1592"></span><span>    </span><span class="hs-keyword">where</span><span>
</span><span id="line-1593"></span><span>      </span><span id="local-6989586621679539819"><span class="annot"><span class="annottext">width :: Int
</span><a href="#local-6989586621679539819"><span class="hs-identifier hs-var hs-var">width</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">[Int] -&gt; Int
forall (t :: * -&gt; *) a. (Foldable t, Num a) =&gt; t a -&gt; a
</span><span class="hs-identifier hs-var">product</span></span><span> </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679539821"><span class="hs-identifier hs-var">innerDims</span></a></span><span>
</span><span id="line-1594"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#tensorPeekElemOff"><span class="hs-identifier hs-var">tensorPeekElemOff</span></a></span><span> </span><span class="annot"><span class="annottext">Ptr ()
</span><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-identifier">_</span></span><span> </span><span id="local-6989586621679539818"><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679539818"><span class="hs-identifier hs-var">dims'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">[Int] -&gt; Maybe [a] -&gt; IO [a]
forall a (m :: * -&gt; *) b.
(TensorLikeRaw a, MonadThrow m) =&gt;
[Int] -&gt; Maybe a -&gt; m b
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#unexpectedDimsError"><span class="hs-identifier hs-var">unexpectedDimsError</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679539837"><span class="hs-identifier hs-type">a</span></a></span><span class="hs-special">]</span><span> </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679539818"><span class="hs-identifier hs-var">dims'</span></a></span><span> </span><span class="annot"><span class="annottext">Maybe [a]
forall (f :: * -&gt; *) a. Alternative f =&gt; f a
</span><span class="hs-identifier hs-var">empty</span></span><span>
</span><span id="line-1595"></span><span>
</span><span id="line-1596"></span><span>  </span><span id="local-6989586621679539817"><span class="annot"><span class="annottext">tensorPokeElemOff :: Ptr () -&gt; Int -&gt; [Int] -&gt; [a] -&gt; IO ()
</span><a href="#local-6989586621679539817"><span class="hs-identifier hs-var hs-var hs-var hs-var">tensorPokeElemOff</span></a></span></span><span> </span><span id="local-6989586621679539816"><span class="annot"><span class="annottext">Ptr ()
</span><a href="#local-6989586621679539816"><span class="hs-identifier hs-var">ptr</span></a></span></span><span> </span><span id="local-6989586621679539815"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679539815"><span class="hs-identifier hs-var">offset</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679539814"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679539814"><span class="hs-identifier hs-var">d</span></a></span></span><span> </span><span class="annot"><span class="hs-glyph hs-type">:</span></span><span> </span><span id="local-6989586621679539813"><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679539813"><span class="hs-identifier hs-var">innerDims</span></a></span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679539812"><span class="annot"><span class="annottext">[a]
</span><a href="#local-6989586621679539812"><span class="hs-identifier hs-var">xs</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-1597"></span><span>    </span><span class="annot"><span class="annottext">[(Int, a)] -&gt; ((Int, a) -&gt; IO ()) -&gt; IO ()
forall (t :: * -&gt; *) (m :: * -&gt; *) a b.
(Foldable t, Monad m) =&gt;
t a -&gt; (a -&gt; m b) -&gt; m ()
</span><span class="hs-identifier hs-var">forM_</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">[Int] -&gt; [a] -&gt; [(Int, a)]
forall a b. [a] -&gt; [b] -&gt; [(a, b)]
</span><span class="hs-identifier hs-var">zip</span></span><span> </span><span class="hs-special">[</span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">0</span></span><span> </span><span class="hs-glyph">..</span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679539814"><span class="hs-identifier hs-var">d</span></a></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Int
forall a. Num a =&gt; a -&gt; a -&gt; a
</span><span class="hs-glyph hs-var">-</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">1</span></span><span class="hs-special">]</span><span> </span><span class="annot"><span class="annottext">[a]
</span><a href="#local-6989586621679539812"><span class="hs-identifier hs-var">xs</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">(((Int, a) -&gt; IO ()) -&gt; IO ()) -&gt; ((Int, a) -&gt; IO ()) -&gt; IO ()
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-glyph">\</span><span class="hs-special">(</span><span id="local-6989586621679539811"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679539811"><span class="hs-identifier hs-var">i</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679539810"><span class="annot"><span class="annottext">a
</span><a href="#local-6989586621679539810"><span class="hs-identifier hs-var">x</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1598"></span><span>      </span><span class="annot"><span class="annottext">Ptr () -&gt; Int -&gt; [Int] -&gt; a -&gt; IO ()
forall a. TensorLikeRaw a =&gt; Ptr () -&gt; Int -&gt; [Int] -&gt; a -&gt; IO ()
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#tensorPokeElemOff"><span class="hs-identifier hs-var">tensorPokeElemOff</span></a></span><span> </span><span class="annot"><span class="annottext">Ptr ()
</span><a href="#local-6989586621679539816"><span class="hs-identifier hs-var">ptr</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679539815"><span class="hs-identifier hs-var">offset</span></a></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Int
forall a. Num a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">+</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679539811"><span class="hs-identifier hs-var">i</span></a></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Int
forall a. Num a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">*</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679539809"><span class="hs-identifier hs-var">width</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679539813"><span class="hs-identifier hs-var">innerDims</span></a></span><span> </span><span class="annot"><span class="annottext">a
</span><a href="#local-6989586621679539810"><span class="hs-identifier hs-var">x</span></a></span><span>
</span><span id="line-1599"></span><span>    </span><span class="hs-keyword">where</span><span>
</span><span id="line-1600"></span><span>      </span><span id="local-6989586621679539809"><span class="annot"><span class="annottext">width :: Int
</span><a href="#local-6989586621679539809"><span class="hs-identifier hs-var hs-var">width</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">[Int] -&gt; Int
forall (t :: * -&gt; *) a. (Foldable t, Num a) =&gt; t a -&gt; a
</span><span class="hs-identifier hs-var">product</span></span><span> </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679539813"><span class="hs-identifier hs-var">innerDims</span></a></span><span>
</span><span id="line-1601"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#tensorPokeElemOff"><span class="hs-identifier hs-var">tensorPokeElemOff</span></a></span><span> </span><span class="annot"><span class="annottext">Ptr ()
</span><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-identifier">_</span></span><span> </span><span id="local-6989586621679539808"><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679539808"><span class="hs-identifier hs-var">dims'</span></a></span></span><span> </span><span id="local-6989586621679539807"><span class="annot"><span class="annottext">[a]
</span><a href="#local-6989586621679539807"><span class="hs-identifier hs-var">x</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">[Int] -&gt; Maybe [a] -&gt; IO ()
forall a (m :: * -&gt; *) b.
(TensorLikeRaw a, MonadThrow m) =&gt;
[Int] -&gt; Maybe a -&gt; m b
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#unexpectedDimsError"><span class="hs-identifier hs-var">unexpectedDimsError</span></a></span><span> </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679539808"><span class="hs-identifier hs-var">dims'</span></a></span><span> </span><span class="annot"><span class="annottext">(Maybe [a] -&gt; IO ()) -&gt; Maybe [a] -&gt; IO ()
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">[a] -&gt; Maybe [a]
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">[a]
</span><a href="#local-6989586621679539807"><span class="hs-identifier hs-var">x</span></a></span></span><span>
</span><span id="line-1602"></span><span>
</span><span id="line-1603"></span><span id="local-6989586621679539803"><span id="local-6989586621679539804"><span id="local-6989586621679539805"><span id="local-6989586621679539806"><span class="hs-keyword">instance</span><span>
</span><span id="line-1604"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorLike"><span class="hs-identifier hs-type">TensorLike</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679539806"><span class="hs-identifier hs-type">a</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679539805"><span class="hs-identifier hs-type">dType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679539804"><span class="hs-identifier hs-type">dims</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-1605"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorLikeRaw"><span class="hs-identifier hs-type">TensorLikeRaw</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679539806"><span class="hs-identifier hs-type">a</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-1606"></span><span>    </span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-type">SingI</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679539805"><span class="hs-identifier hs-type">dType</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-1607"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetDims"><span class="hs-identifier hs-type">SGetDims</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679539803"><span class="hs-identifier hs-type">dimsOut</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-1608"></span><span>    </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679539803"><span class="hs-identifier hs-type">dimsOut</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#InsertDimF"><span class="hs-identifier hs-type">InsertDimF</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">0</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679539804"><span class="hs-identifier hs-type">dims</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#UncheckedSize"><span class="hs-identifier hs-type">UncheckedSize</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-1609"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-1610"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorLike"><span class="hs-identifier hs-type">TensorLike</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/yynp70g2av7yww0d41962k85vnlb2qia-vector-lib-vector-0.12.2.0-haddock-doc/share/doc/vector/html/src"><span class="hs-identifier hs-type">V.Vector</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679539806"><span class="hs-identifier hs-type">a</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679539805"><span class="hs-identifier hs-type">dType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679539803"><span class="hs-identifier hs-type">dimsOut</span></a></span><span>
</span><span id="line-1611"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-1612"></span><span>  </span><span id="local-6989586621679539800"><span class="annot"><span class="annottext">sToTensor :: SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; Vector a
-&gt; m (Tensor
        gradient layout device ('DataType dType) ('Shape dimsOut))
</span><a href="#local-6989586621679539800"><span class="hs-identifier hs-var hs-var hs-var hs-var">sToTensor</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; Vector a
-&gt; m (Tensor
        gradient layout device ('DataType dType) ('Shape dimsOut))
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat)) a
       (dType :: DType) (dims :: [Dim (Name Symbol) (Size Nat)])
       (m :: * -&gt; *).
(TensorLike a dType dims, TensorLikeRaw a, SingI dType,
 MonadThrow m) =&gt;
SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; a
-&gt; m (Tensor
        gradient layout device ('DataType dType) ('Shape dims))
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sToTensorRaw"><span class="hs-identifier hs-var">sToTensorRaw</span></a></span><span>
</span><span id="line-1613"></span><span>  </span><span id="local-6989586621679539799"><span class="annot"><span class="annottext">fromTensor :: Tensor gradient layout device ('DataType dType) ('Shape dimsOut)
-&gt; Vector a
</span><a href="#local-6989586621679539799"><span class="hs-identifier hs-var hs-var hs-var hs-var">fromTensor</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device ('DataType dType) ('Shape dimsOut)
-&gt; Vector a
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat)) a
       (dType :: DType) (dims :: [Dim (Name Symbol) (Size Nat)]).
(TensorLike a dType dims, TensorLikeRaw a, SGetDims dims) =&gt;
Tensor gradient layout device ('DataType dType) ('Shape dims) -&gt; a
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#fromTensorRaw"><span class="hs-identifier hs-var">fromTensorRaw</span></a></span></span></span></span></span><span>
</span><span id="line-1614"></span><span>
</span><span id="line-1615"></span><span id="local-6989586621679539798"><span class="hs-keyword">instance</span><span>
</span><span id="line-1616"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorLikeRaw"><span class="hs-identifier hs-type">TensorLikeRaw</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679539798"><span class="hs-identifier hs-type">a</span></a></span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-1617"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorLikeRaw"><span class="hs-identifier hs-type">TensorLikeRaw</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/yynp70g2av7yww0d41962k85vnlb2qia-vector-lib-vector-0.12.2.0-haddock-doc/share/doc/vector/html/src"><span class="hs-identifier hs-type">V.Vector</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679539798"><span class="hs-identifier hs-type">a</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-1618"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-1619"></span><span>  </span><span id="local-6989586621679539793"><span class="annot"><span class="annottext">guessDim :: Maybe (Vector a) -&gt; Maybe Int
</span><a href="#local-6989586621679539793"><span class="hs-identifier hs-var hs-var hs-var hs-var">guessDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Int -&gt; Maybe Int
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">(Int -&gt; Maybe Int)
-&gt; (Maybe (Vector a) -&gt; Int) -&gt; Maybe (Vector a) -&gt; Maybe Int
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Int -&gt; (Vector a -&gt; Int) -&gt; Maybe (Vector a) -&gt; Int
forall b a. b -&gt; (a -&gt; b) -&gt; Maybe a -&gt; b
</span><span class="hs-identifier hs-var">maybe</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">0</span></span><span> </span><span class="annot"><span class="annottext">Vector a -&gt; Int
forall (t :: * -&gt; *) a. Foldable t =&gt; t a -&gt; Int
</span><span class="hs-identifier hs-var">length</span></span><span>
</span><span id="line-1620"></span><span>
</span><span id="line-1621"></span><span>  </span><span id="local-6989586621679539792"><span class="annot"><span class="annottext">guessInnerDims :: Maybe (Vector a) -&gt; m [Int]
</span><a href="#local-6989586621679539792"><span class="hs-identifier hs-var hs-var hs-var hs-var">guessInnerDims</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-1622"></span><span>    </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Maybe (Vector a)
-&gt; (Vector a -&gt; Maybe (a, Vector a)) -&gt; Maybe (a, Vector a)
forall (m :: * -&gt; *) a b. Monad m =&gt; m a -&gt; (a -&gt; m b) -&gt; m b
</span><span class="hs-operator hs-var">&gt;&gt;=</span></span><span> </span><span class="annot"><span class="annottext">Vector a -&gt; Maybe (a, Vector a)
forall a. Vector a -&gt; Maybe (a, Vector a)
</span><a href="../file:///nix/store/yynp70g2av7yww0d41962k85vnlb2qia-vector-lib-vector-0.12.2.0-haddock-doc/share/doc/vector/html/src"><span class="hs-identifier hs-var">V.uncons</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">(Maybe (Vector a) -&gt; Maybe (a, Vector a))
-&gt; (Maybe (a, Vector a) -&gt; m [Int]) -&gt; Maybe (Vector a) -&gt; m [Int]
forall k (cat :: k -&gt; k -&gt; *) (a :: k) (b :: k) (c :: k).
Category cat =&gt;
cat a b -&gt; cat b c -&gt; cat a c
</span><span class="hs-operator hs-var">&gt;&gt;&gt;</span></span><span> </span><span class="hs-glyph">\</span><span class="hs-glyph">case</span><span>
</span><span id="line-1623"></span><span>      </span><span class="annot"><span class="annottext">Maybe (a, Vector a)
</span><span class="hs-identifier hs-var">Nothing</span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">Maybe a -&gt; m [Int]
forall a (m :: * -&gt; *).
(TensorLikeRaw a, MonadThrow m) =&gt;
Maybe a -&gt; m [Int]
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#guessDims"><span class="hs-identifier hs-var">guessDims</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679539798"><span class="hs-identifier hs-type">a</span></a></span><span> </span><span class="annot"><span class="annottext">Maybe a
forall (f :: * -&gt; *) a. Alternative f =&gt; f a
</span><span class="hs-identifier hs-var">empty</span></span><span>
</span><span id="line-1624"></span><span>      </span><span class="annot"><span class="hs-identifier hs-type">Just</span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679539790"><span class="annot"><span class="annottext">a
</span><a href="#local-6989586621679539790"><span class="hs-identifier hs-var">x</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679539789"><span class="annot"><span class="annottext">Vector a
</span><a href="#local-6989586621679539789"><span class="hs-identifier hs-var">xs</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-1625"></span><span>        </span><span id="local-6989586621679539788"><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679539788"><span class="hs-identifier hs-var">xDims</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">Maybe a -&gt; m [Int]
forall a (m :: * -&gt; *).
(TensorLikeRaw a, MonadThrow m) =&gt;
Maybe a -&gt; m [Int]
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#guessDims"><span class="hs-identifier hs-var">guessDims</span></a></span><span> </span><span class="annot"><span class="annottext">(Maybe a -&gt; m [Int]) -&gt; Maybe a -&gt; m [Int]
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">a -&gt; Maybe a
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">a
</span><a href="#local-6989586621679539790"><span class="hs-identifier hs-var">x</span></a></span><span>
</span><span id="line-1626"></span><span>        </span><span class="annot"><span class="annottext">(a -&gt; m ()) -&gt; Vector a -&gt; m ()
forall (t :: * -&gt; *) (f :: * -&gt; *) a b.
(Foldable t, Applicative f) =&gt;
(a -&gt; f b) -&gt; t a -&gt; f ()
</span><span class="hs-identifier hs-var">traverse_</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">[Int] -&gt; [Int] -&gt; m ()
forall (m :: * -&gt; *). MonadThrow m =&gt; [Int] -&gt; [Int] -&gt; m ()
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#checkDims"><span class="hs-identifier hs-var">checkDims</span></a></span><span> </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679539788"><span class="hs-identifier hs-var">xDims</span></a></span><span> </span><span class="annot"><span class="annottext">([Int] -&gt; m ()) -&gt; (a -&gt; m [Int]) -&gt; a -&gt; m ()
forall (m :: * -&gt; *) b c a.
Monad m =&gt;
(b -&gt; m c) -&gt; (a -&gt; m b) -&gt; a -&gt; m c
</span><span class="hs-operator hs-var">&lt;=&lt;</span></span><span> </span><span class="annot"><span class="annottext">Maybe a -&gt; m [Int]
forall a (m :: * -&gt; *).
(TensorLikeRaw a, MonadThrow m) =&gt;
Maybe a -&gt; m [Int]
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#guessDims"><span class="hs-identifier hs-var">guessDims</span></a></span><span> </span><span class="annot"><span class="annottext">(Maybe a -&gt; m [Int]) -&gt; (a -&gt; Maybe a) -&gt; a -&gt; m [Int]
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">a -&gt; Maybe a
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Vector a
</span><a href="#local-6989586621679539789"><span class="hs-identifier hs-var">xs</span></a></span><span>
</span><span id="line-1627"></span><span>        </span><span class="annot"><span class="annottext">[Int] -&gt; m [Int]
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679539788"><span class="hs-identifier hs-var">xDims</span></a></span><span>
</span><span id="line-1628"></span><span>
</span><span id="line-1629"></span><span>  </span><span id="local-6989586621679539787"><span class="annot"><span class="annottext">tensorPeekElemOff :: Ptr () -&gt; Int -&gt; [Int] -&gt; IO (Vector a)
</span><a href="#local-6989586621679539787"><span class="hs-identifier hs-var hs-var hs-var hs-var">tensorPeekElemOff</span></a></span></span><span> </span><span id="local-6989586621679539786"><span class="annot"><span class="annottext">Ptr ()
</span><a href="#local-6989586621679539786"><span class="hs-identifier hs-var">ptr</span></a></span></span><span> </span><span id="local-6989586621679539785"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679539785"><span class="hs-identifier hs-var">offset</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679539784"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679539784"><span class="hs-identifier hs-var">d</span></a></span></span><span> </span><span class="annot"><span class="hs-glyph hs-type">:</span></span><span> </span><span id="local-6989586621679539783"><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679539783"><span class="hs-identifier hs-var">innerDims</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-1630"></span><span>    </span><span class="annot"><span class="annottext">Vector Int -&gt; (Int -&gt; IO a) -&gt; IO (Vector a)
forall (t :: * -&gt; *) (m :: * -&gt; *) a b.
(Traversable t, Monad m) =&gt;
t a -&gt; (a -&gt; m b) -&gt; m (t b)
</span><span class="hs-identifier hs-var">forM</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Vector Int
forall a. Enum a =&gt; a -&gt; a -&gt; Vector a
</span><a href="../file:///nix/store/yynp70g2av7yww0d41962k85vnlb2qia-vector-lib-vector-0.12.2.0-haddock-doc/share/doc/vector/html/src"><span class="hs-identifier hs-var">V.enumFromTo</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">0</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679539784"><span class="hs-identifier hs-var">d</span></a></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Int
forall a. Num a =&gt; a -&gt; a -&gt; a
</span><span class="hs-glyph hs-var">-</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">((Int -&gt; IO a) -&gt; IO (Vector a)) -&gt; (Int -&gt; IO a) -&gt; IO (Vector a)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-glyph">\</span><span id="local-6989586621679539781"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679539781"><span class="hs-identifier hs-var">i</span></a></span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-1631"></span><span>      </span><span class="annot"><span class="annottext">Ptr () -&gt; Int -&gt; [Int] -&gt; IO a
forall a. TensorLikeRaw a =&gt; Ptr () -&gt; Int -&gt; [Int] -&gt; IO a
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#tensorPeekElemOff"><span class="hs-identifier hs-var">tensorPeekElemOff</span></a></span><span> </span><span class="annot"><span class="annottext">Ptr ()
</span><a href="#local-6989586621679539786"><span class="hs-identifier hs-var">ptr</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679539785"><span class="hs-identifier hs-var">offset</span></a></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Int
forall a. Num a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">+</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679539781"><span class="hs-identifier hs-var">i</span></a></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Int
forall a. Num a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">*</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679539780"><span class="hs-identifier hs-var">width</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679539783"><span class="hs-identifier hs-var">innerDims</span></a></span><span>
</span><span id="line-1632"></span><span>    </span><span class="hs-keyword">where</span><span>
</span><span id="line-1633"></span><span>      </span><span id="local-6989586621679539780"><span class="annot"><span class="annottext">width :: Int
</span><a href="#local-6989586621679539780"><span class="hs-identifier hs-var hs-var">width</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">[Int] -&gt; Int
forall (t :: * -&gt; *) a. (Foldable t, Num a) =&gt; t a -&gt; a
</span><span class="hs-identifier hs-var">product</span></span><span> </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679539783"><span class="hs-identifier hs-var">innerDims</span></a></span><span>
</span><span id="line-1634"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#tensorPeekElemOff"><span class="hs-identifier hs-var">tensorPeekElemOff</span></a></span><span> </span><span class="annot"><span class="annottext">Ptr ()
</span><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-identifier">_</span></span><span> </span><span id="local-6989586621679539779"><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679539779"><span class="hs-identifier hs-var">dims'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">[Int] -&gt; Maybe (Vector a) -&gt; IO (Vector a)
forall a (m :: * -&gt; *) b.
(TensorLikeRaw a, MonadThrow m) =&gt;
[Int] -&gt; Maybe a -&gt; m b
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#unexpectedDimsError"><span class="hs-identifier hs-var">unexpectedDimsError</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/yynp70g2av7yww0d41962k85vnlb2qia-vector-lib-vector-0.12.2.0-haddock-doc/share/doc/vector/html/src"><span class="hs-identifier hs-type">V.Vector</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679539798"><span class="hs-identifier hs-type">a</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679539779"><span class="hs-identifier hs-var">dims'</span></a></span><span> </span><span class="annot"><span class="annottext">Maybe (Vector a)
forall (f :: * -&gt; *) a. Alternative f =&gt; f a
</span><span class="hs-identifier hs-var">empty</span></span><span>
</span><span id="line-1635"></span><span>
</span><span id="line-1636"></span><span>  </span><span id="local-6989586621679539778"><span class="annot"><span class="annottext">tensorPokeElemOff :: Ptr () -&gt; Int -&gt; [Int] -&gt; Vector a -&gt; IO ()
</span><a href="#local-6989586621679539778"><span class="hs-identifier hs-var hs-var hs-var hs-var">tensorPokeElemOff</span></a></span></span><span> </span><span id="local-6989586621679539777"><span class="annot"><span class="annottext">Ptr ()
</span><a href="#local-6989586621679539777"><span class="hs-identifier hs-var">ptr</span></a></span></span><span> </span><span id="local-6989586621679539776"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679539776"><span class="hs-identifier hs-var">offset</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679539775"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679539775"><span class="hs-identifier hs-var">d</span></a></span></span><span> </span><span class="annot"><span class="hs-glyph hs-type">:</span></span><span> </span><span id="local-6989586621679539774"><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679539774"><span class="hs-identifier hs-var">innerDims</span></a></span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679539773"><span class="annot"><span class="annottext">Vector a
</span><a href="#local-6989586621679539773"><span class="hs-identifier hs-var">xs</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-1637"></span><span>    </span><span class="annot"><span class="annottext">Vector (Int, a) -&gt; ((Int, a) -&gt; IO ()) -&gt; IO ()
forall (t :: * -&gt; *) (m :: * -&gt; *) a b.
(Foldable t, Monad m) =&gt;
t a -&gt; (a -&gt; m b) -&gt; m ()
</span><span class="hs-identifier hs-var">forM_</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Vector Int -&gt; Vector a -&gt; Vector (Int, a)
forall a b. Vector a -&gt; Vector b -&gt; Vector (a, b)
</span><a href="../file:///nix/store/yynp70g2av7yww0d41962k85vnlb2qia-vector-lib-vector-0.12.2.0-haddock-doc/share/doc/vector/html/src"><span class="hs-identifier hs-var">V.zip</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Vector Int
forall a. Enum a =&gt; a -&gt; a -&gt; Vector a
</span><a href="../file:///nix/store/yynp70g2av7yww0d41962k85vnlb2qia-vector-lib-vector-0.12.2.0-haddock-doc/share/doc/vector/html/src"><span class="hs-identifier hs-var">V.enumFromTo</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">0</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679539775"><span class="hs-identifier hs-var">d</span></a></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Int
forall a. Num a =&gt; a -&gt; a -&gt; a
</span><span class="hs-glyph hs-var">-</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Vector a
</span><a href="#local-6989586621679539773"><span class="hs-identifier hs-var">xs</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">(((Int, a) -&gt; IO ()) -&gt; IO ()) -&gt; ((Int, a) -&gt; IO ()) -&gt; IO ()
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-glyph">\</span><span class="hs-special">(</span><span id="local-6989586621679539771"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679539771"><span class="hs-identifier hs-var">i</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679539770"><span class="annot"><span class="annottext">a
</span><a href="#local-6989586621679539770"><span class="hs-identifier hs-var">x</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1638"></span><span>      </span><span class="annot"><span class="annottext">Ptr () -&gt; Int -&gt; [Int] -&gt; a -&gt; IO ()
forall a. TensorLikeRaw a =&gt; Ptr () -&gt; Int -&gt; [Int] -&gt; a -&gt; IO ()
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#tensorPokeElemOff"><span class="hs-identifier hs-var">tensorPokeElemOff</span></a></span><span> </span><span class="annot"><span class="annottext">Ptr ()
</span><a href="#local-6989586621679539777"><span class="hs-identifier hs-var">ptr</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679539776"><span class="hs-identifier hs-var">offset</span></a></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Int
forall a. Num a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">+</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679539771"><span class="hs-identifier hs-var">i</span></a></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Int
forall a. Num a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">*</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679539769"><span class="hs-identifier hs-var">width</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679539774"><span class="hs-identifier hs-var">innerDims</span></a></span><span> </span><span class="annot"><span class="annottext">a
</span><a href="#local-6989586621679539770"><span class="hs-identifier hs-var">x</span></a></span><span>
</span><span id="line-1639"></span><span>    </span><span class="hs-keyword">where</span><span>
</span><span id="line-1640"></span><span>      </span><span id="local-6989586621679539769"><span class="annot"><span class="annottext">width :: Int
</span><a href="#local-6989586621679539769"><span class="hs-identifier hs-var hs-var">width</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">[Int] -&gt; Int
forall (t :: * -&gt; *) a. (Foldable t, Num a) =&gt; t a -&gt; a
</span><span class="hs-identifier hs-var">product</span></span><span> </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679539774"><span class="hs-identifier hs-var">innerDims</span></a></span><span>
</span><span id="line-1641"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#tensorPokeElemOff"><span class="hs-identifier hs-var">tensorPokeElemOff</span></a></span><span> </span><span class="annot"><span class="annottext">Ptr ()
</span><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-identifier">_</span></span><span> </span><span id="local-6989586621679539768"><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679539768"><span class="hs-identifier hs-var">dims'</span></a></span></span><span> </span><span id="local-6989586621679539767"><span class="annot"><span class="annottext">Vector a
</span><a href="#local-6989586621679539767"><span class="hs-identifier hs-var">x</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">[Int] -&gt; Maybe (Vector a) -&gt; IO ()
forall a (m :: * -&gt; *) b.
(TensorLikeRaw a, MonadThrow m) =&gt;
[Int] -&gt; Maybe a -&gt; m b
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#unexpectedDimsError"><span class="hs-identifier hs-var">unexpectedDimsError</span></a></span><span> </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679539768"><span class="hs-identifier hs-var">dims'</span></a></span><span> </span><span class="annot"><span class="annottext">(Maybe (Vector a) -&gt; IO ()) -&gt; Maybe (Vector a) -&gt; IO ()
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">Vector a -&gt; Maybe (Vector a)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">Vector a
</span><a href="#local-6989586621679539767"><span class="hs-identifier hs-var">x</span></a></span></span><span>
</span><span id="line-1642"></span><span>
</span><span id="line-1643"></span><span id="local-6989586621679539762"><span id="local-6989586621679539763"><span id="local-6989586621679539764"><span id="local-6989586621679539765"><span id="local-6989586621679539766"><span class="hs-keyword">instance</span><span>
</span><span id="line-1644"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><span class="hs-identifier hs-type">KnownNat</span></span><span> </span><span class="annot"><a href="#local-6989586621679539766"><span class="hs-identifier hs-type">n</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-1645"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorLike"><span class="hs-identifier hs-type">TensorLike</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679539765"><span class="hs-identifier hs-type">a</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679539764"><span class="hs-identifier hs-type">dType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679539763"><span class="hs-identifier hs-type">dims</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-1646"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorLikeRaw"><span class="hs-identifier hs-type">TensorLikeRaw</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679539765"><span class="hs-identifier hs-type">a</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-1647"></span><span>    </span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-type">SingI</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679539764"><span class="hs-identifier hs-type">dType</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-1648"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetDims"><span class="hs-identifier hs-type">SGetDims</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679539762"><span class="hs-identifier hs-type">dimsOut</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-1649"></span><span>    </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679539762"><span class="hs-identifier hs-type">dimsOut</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#InsertDimF"><span class="hs-identifier hs-type">InsertDimF</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">0</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679539763"><span class="hs-identifier hs-type">dims</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679539766"><span class="hs-identifier hs-type">n</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-1650"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-1651"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorLike"><span class="hs-identifier hs-type">TensorLike</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/33j53czfh9iaqr8w1k6rjcna7zg8rw55-vector-sized-lib-vector-sized-1.4.3.1-haddock-doc/share/doc/vector-sized/html/src"><span class="hs-identifier hs-type">SV.Vector</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679539766"><span class="hs-identifier hs-type">n</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679539765"><span class="hs-identifier hs-type">a</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679539764"><span class="hs-identifier hs-type">dType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679539762"><span class="hs-identifier hs-type">dimsOut</span></a></span><span>
</span><span id="line-1652"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-1653"></span><span>  </span><span id="local-6989586621679539759"><span class="annot"><span class="annottext">sToTensor :: SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; Vector n a
-&gt; m (Tensor
        gradient layout device ('DataType dType) ('Shape dimsOut))
</span><a href="#local-6989586621679539759"><span class="hs-identifier hs-var hs-var hs-var hs-var">sToTensor</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; Vector n a
-&gt; m (Tensor
        gradient layout device ('DataType dType) ('Shape dimsOut))
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat)) a
       (dType :: DType) (dims :: [Dim (Name Symbol) (Size Nat)])
       (m :: * -&gt; *).
(TensorLike a dType dims, TensorLikeRaw a, SingI dType,
 MonadThrow m) =&gt;
SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; a
-&gt; m (Tensor
        gradient layout device ('DataType dType) ('Shape dims))
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sToTensorRaw"><span class="hs-identifier hs-var">sToTensorRaw</span></a></span><span>
</span><span id="line-1654"></span><span>  </span><span id="local-6989586621679539758"><span class="annot"><span class="annottext">fromTensor :: Tensor gradient layout device ('DataType dType) ('Shape dimsOut)
-&gt; Vector n a
</span><a href="#local-6989586621679539758"><span class="hs-identifier hs-var hs-var hs-var hs-var">fromTensor</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device ('DataType dType) ('Shape dimsOut)
-&gt; Vector n a
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat)) a
       (dType :: DType) (dims :: [Dim (Name Symbol) (Size Nat)]).
(TensorLike a dType dims, TensorLikeRaw a, SGetDims dims) =&gt;
Tensor gradient layout device ('DataType dType) ('Shape dims) -&gt; a
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#fromTensorRaw"><span class="hs-identifier hs-var">fromTensorRaw</span></a></span></span></span></span></span></span><span>
</span><span id="line-1655"></span><span>
</span><span id="line-1656"></span><span id="local-6989586621679539756"><span id="local-6989586621679539757"><span class="hs-keyword">instance</span><span>
</span><span id="line-1657"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><span class="hs-identifier hs-type">KnownNat</span></span><span> </span><span class="annot"><a href="#local-6989586621679539757"><span class="hs-identifier hs-type">n</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-1658"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorLikeRaw"><span class="hs-identifier hs-type">TensorLikeRaw</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679539756"><span class="hs-identifier hs-type">a</span></a></span><span>
</span><span id="line-1659"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-1660"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorLikeRaw"><span class="hs-identifier hs-type">TensorLikeRaw</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/33j53czfh9iaqr8w1k6rjcna7zg8rw55-vector-sized-lib-vector-sized-1.4.3.1-haddock-doc/share/doc/vector-sized/html/src"><span class="hs-identifier hs-type">SV.Vector</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679539757"><span class="hs-identifier hs-type">n</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679539756"><span class="hs-identifier hs-type">a</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-1661"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-1662"></span><span>  </span><span id="local-6989586621679539751"><span class="annot"><span class="annottext">guessDim :: Maybe (Vector n a) -&gt; Maybe Int
</span><a href="#local-6989586621679539751"><span class="hs-identifier hs-var hs-var hs-var hs-var">guessDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Int -&gt; Maybe Int
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">(Int -&gt; Maybe Int)
-&gt; (Maybe (Vector n a) -&gt; Int) -&gt; Maybe (Vector n a) -&gt; Maybe Int
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Int -&gt; (Vector n a -&gt; Int) -&gt; Maybe (Vector n a) -&gt; Int
forall b a. b -&gt; (a -&gt; b) -&gt; Maybe a -&gt; b
</span><span class="hs-identifier hs-var">maybe</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">0</span></span><span> </span><span class="annot"><span class="annottext">Vector n a -&gt; Int
forall (t :: * -&gt; *) a. Foldable t =&gt; t a -&gt; Int
</span><span class="hs-identifier hs-var">length</span></span><span>
</span><span id="line-1663"></span><span>
</span><span id="line-1664"></span><span>  </span><span id="local-6989586621679539750"><span class="annot"><span class="annottext">guessInnerDims :: Maybe (Vector n a) -&gt; m [Int]
</span><a href="#local-6989586621679539750"><span class="hs-identifier hs-var hs-var hs-var hs-var">guessInnerDims</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Maybe (Vector a) -&gt; m [Int]
forall a (m :: * -&gt; *).
(TensorLikeRaw a, MonadThrow m) =&gt;
Maybe a -&gt; m [Int]
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#guessInnerDims"><span class="hs-identifier hs-var">guessInnerDims</span></a></span><span> </span><span class="annot"><span class="annottext">(Maybe (Vector a) -&gt; m [Int])
-&gt; (Maybe (Vector n a) -&gt; Maybe (Vector a))
-&gt; Maybe (Vector n a)
-&gt; m [Int]
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">(Vector n a -&gt; Vector a) -&gt; Maybe (Vector n a) -&gt; Maybe (Vector a)
forall (f :: * -&gt; *) a b. Functor f =&gt; (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-identifier hs-var">fmap</span></span><span> </span><span class="annot"><span class="annottext">Vector n a -&gt; Vector a
forall a (n :: Nat). KnownNat n =&gt; Vector n a -&gt; Vector a
</span><a href="../file:///nix/store/33j53czfh9iaqr8w1k6rjcna7zg8rw55-vector-sized-lib-vector-sized-1.4.3.1-haddock-doc/share/doc/vector-sized/html/src"><span class="hs-identifier hs-var">SV.SomeSized</span></a></span><span>
</span><span id="line-1665"></span><span>
</span><span id="line-1666"></span><span>  </span><span id="local-6989586621679539748"><span class="annot"><span class="annottext">tensorPeekElemOff :: Ptr () -&gt; Int -&gt; [Int] -&gt; IO (Vector n a)
</span><a href="#local-6989586621679539748"><span class="hs-identifier hs-var hs-var hs-var hs-var">tensorPeekElemOff</span></a></span></span><span> </span><span id="local-6989586621679539747"><span class="annot"><span class="annottext">Ptr ()
</span><a href="#local-6989586621679539747"><span class="hs-identifier hs-var">ptr</span></a></span></span><span> </span><span id="local-6989586621679539746"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679539746"><span class="hs-identifier hs-var">offset</span></a></span></span><span> </span><span id="local-6989586621679539745"><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679539745"><span class="hs-identifier hs-var">dims'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Vector a -&gt; Vector n a
forall (v :: * -&gt; *) (n :: Nat) a. v a -&gt; Vector v n a
</span><a href="../file:///nix/store/33j53czfh9iaqr8w1k6rjcna7zg8rw55-vector-sized-lib-vector-sized-1.4.3.1-haddock-doc/share/doc/vector-sized/html/src"><span class="hs-identifier hs-var">SVI.Vector</span></a></span><span> </span><span class="annot"><span class="annottext">(Vector a -&gt; Vector n a) -&gt; IO (Vector a) -&gt; IO (Vector n a)
forall (f :: * -&gt; *) a b. Functor f =&gt; (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;$&gt;</span></span><span> </span><span class="annot"><span class="annottext">Ptr () -&gt; Int -&gt; [Int] -&gt; IO (Vector a)
forall a. TensorLikeRaw a =&gt; Ptr () -&gt; Int -&gt; [Int] -&gt; IO a
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#tensorPeekElemOff"><span class="hs-identifier hs-var">tensorPeekElemOff</span></a></span><span> </span><span class="annot"><span class="annottext">Ptr ()
</span><a href="#local-6989586621679539747"><span class="hs-identifier hs-var">ptr</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679539746"><span class="hs-identifier hs-var">offset</span></a></span><span> </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679539745"><span class="hs-identifier hs-var">dims'</span></a></span><span>
</span><span id="line-1667"></span><span>
</span><span id="line-1668"></span><span>  </span><span id="local-6989586621679539743"><span class="annot"><span class="annottext">tensorPokeElemOff :: Ptr () -&gt; Int -&gt; [Int] -&gt; Vector n a -&gt; IO ()
</span><a href="#local-6989586621679539743"><span class="hs-identifier hs-var hs-var hs-var hs-var">tensorPokeElemOff</span></a></span></span><span> </span><span id="local-6989586621679539742"><span class="annot"><span class="annottext">Ptr ()
</span><a href="#local-6989586621679539742"><span class="hs-identifier hs-var">ptr</span></a></span></span><span> </span><span id="local-6989586621679539741"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679539741"><span class="hs-identifier hs-var">offset</span></a></span></span><span> </span><span id="local-6989586621679539740"><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679539740"><span class="hs-identifier hs-var">dims'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Ptr () -&gt; Int -&gt; [Int] -&gt; Vector a -&gt; IO ()
forall a. TensorLikeRaw a =&gt; Ptr () -&gt; Int -&gt; [Int] -&gt; a -&gt; IO ()
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#tensorPokeElemOff"><span class="hs-identifier hs-var">tensorPokeElemOff</span></a></span><span> </span><span class="annot"><span class="annottext">Ptr ()
</span><a href="#local-6989586621679539742"><span class="hs-identifier hs-var">ptr</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679539741"><span class="hs-identifier hs-var">offset</span></a></span><span> </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679539740"><span class="hs-identifier hs-var">dims'</span></a></span><span> </span><span class="annot"><span class="annottext">(Vector a -&gt; IO ())
-&gt; (Vector n a -&gt; Vector a) -&gt; Vector n a -&gt; IO ()
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Vector n a -&gt; Vector a
forall a (n :: Nat). KnownNat n =&gt; Vector n a -&gt; Vector a
</span><a href="../file:///nix/store/33j53czfh9iaqr8w1k6rjcna7zg8rw55-vector-sized-lib-vector-sized-1.4.3.1-haddock-doc/share/doc/vector-sized/html/src"><span class="hs-identifier hs-var">SV.SomeSized</span></a></span></span></span><span>
</span><span id="line-1669"></span><span>
</span><span id="line-1670"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#sSetTensorOptions"><span class="hs-identifier hs-type">sSetTensorOptions</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-1671"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679540856"><span class="annot"><a href="#local-6989586621679540856"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679540855"><span class="annot"><a href="#local-6989586621679540855"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679540854"><span class="annot"><a href="#local-6989586621679540854"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679540853"><span class="annot"><a href="#local-6989586621679540853"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679540852"><span class="annot"><a href="#local-6989586621679540852"><span class="hs-identifier hs-type">gradientFrom</span></a></span></span><span> </span><span id="local-6989586621679540851"><span class="annot"><a href="#local-6989586621679540851"><span class="hs-identifier hs-type">layoutFrom</span></a></span></span><span> </span><span id="local-6989586621679540850"><span class="annot"><a href="#local-6989586621679540850"><span class="hs-identifier hs-type">deviceFrom</span></a></span></span><span> </span><span id="local-6989586621679540849"><span class="annot"><a href="#local-6989586621679540849"><span class="hs-identifier hs-type">dataTypeFrom</span></a></span></span><span> </span><span id="local-6989586621679540848"><span class="annot"><a href="#local-6989586621679540848"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-1672"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier hs-type">SGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540856"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1673"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#SLayout"><span class="hs-identifier hs-type">SLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540855"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1674"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#SDevice"><span class="hs-identifier hs-type">SDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540854"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1675"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier hs-type">SDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540853"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1676"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540852"><span class="hs-identifier hs-type">gradientFrom</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540851"><span class="hs-identifier hs-type">layoutFrom</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540850"><span class="hs-identifier hs-type">deviceFrom</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540849"><span class="hs-identifier hs-type">dataTypeFrom</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540848"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1677"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">IO</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540856"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540855"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540854"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540853"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679540848"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-1678"></span><span id="sSetTensorOptions"><span class="annot"><span class="annottext">sSetTensorOptions :: SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; Tensor gradientFrom layoutFrom deviceFrom dataTypeFrom shape
-&gt; IO (Tensor gradient layout device dataType shape)
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sSetTensorOptions"><span class="hs-identifier hs-var hs-var">sSetTensorOptions</span></a></span></span><span> </span><span id="local-6989586621679539738"><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679539738"><span class="hs-identifier hs-var">gradient'</span></a></span></span><span> </span><span id="local-6989586621679539737"><span class="annot"><span class="annottext">SLayout layout
</span><a href="#local-6989586621679539737"><span class="hs-identifier hs-var">layout</span></a></span></span><span> </span><span id="local-6989586621679539736"><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679539736"><span class="hs-identifier hs-var">device</span></a></span></span><span> </span><span id="local-6989586621679539735"><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679539735"><span class="hs-identifier hs-var">dataType</span></a></span></span><span> </span><span id="local-6989586621679539734"><span class="annot"><span class="annottext">Tensor gradientFrom layoutFrom deviceFrom dataTypeFrom shape
</span><a href="#local-6989586621679539734"><span class="hs-identifier hs-var">t</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-1679"></span><span>  </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; Tensor gradient layout device dataType shape
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
ForeignPtr Tensor -&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#UnsafeTensor"><span class="hs-identifier hs-var">UnsafeTensor</span></a></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; Tensor gradient layout device dataType shape)
-&gt; IO (ForeignPtr Tensor)
-&gt; IO (Tensor gradient layout device dataType shape)
forall (f :: * -&gt; *) a b. Functor f =&gt; (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;$&gt;</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr TensorOptions
 -&gt; CBool
 -&gt; CBool
 -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradientFrom layoutFrom deviceFrom dataTypeFrom shape
-&gt; TensorOptions
-&gt; Bool
-&gt; Bool
-&gt; IO (ForeignPtr Tensor)
forall a ca x1 cx1 x2 cx2 x3 cx3 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable x3 cx3,
 Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; cx3 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; x2 -&gt; x3 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast4</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; ForeignPtr TensorOptions
-&gt; CBool
-&gt; CBool
-&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.tensor_to_obb</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradientFrom layoutFrom deviceFrom dataTypeFrom shape
</span><a href="#local-6989586621679539734"><span class="hs-identifier hs-var">t</span></a></span><span> </span><span class="annot"><span class="annottext">TensorOptions
</span><a href="#local-6989586621679539733"><span class="hs-identifier hs-var">opts</span></a></span><span> </span><span class="annot"><span class="annottext">Bool
</span><a href="#local-6989586621679539732"><span class="hs-identifier hs-var">nonBlocking</span></a></span><span> </span><span class="annot"><span class="annottext">Bool
</span><a href="#local-6989586621679539731"><span class="hs-identifier hs-var">copy</span></a></span><span>
</span><span id="line-1680"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-1681"></span><span>    </span><span id="local-6989586621679539733"><span class="annot"><span class="annottext">opts :: TensorOptions
</span><a href="#local-6989586621679539733"><span class="hs-identifier hs-var hs-var">opts</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; TensorOptions
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType).
SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; TensorOptions
</span><a href="Torch.GraduallyTyped.Internal.TensorOptions.html#tensorOptions"><span class="hs-identifier hs-var">tensorOptions</span></a></span><span> </span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679539738"><span class="hs-identifier hs-var">gradient'</span></a></span><span> </span><span class="annot"><span class="annottext">SLayout layout
</span><a href="#local-6989586621679539737"><span class="hs-identifier hs-var">layout</span></a></span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679539736"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679539735"><span class="hs-identifier hs-var">dataType</span></a></span><span>
</span><span id="line-1682"></span><span>
</span><span id="line-1683"></span><span>    </span><span id="local-6989586621679539732"><span class="annot"><span class="annottext">nonBlocking :: Bool
</span><a href="#local-6989586621679539732"><span class="hs-identifier hs-var hs-var">nonBlocking</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Bool
</span><span class="hs-identifier hs-var">False</span></span><span>
</span><span id="line-1684"></span><span>    </span><span id="local-6989586621679539731"><span class="annot"><span class="annottext">copy :: Bool
</span><a href="#local-6989586621679539731"><span class="hs-identifier hs-var hs-var">copy</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Bool
</span><span class="hs-identifier hs-var">False</span></span><span>
</span><span id="line-1685"></span><span>
</span><span id="line-1686"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#setTensorOptions"><span class="hs-identifier hs-type">setTensorOptions</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-1687"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679539729"><span class="annot"><a href="#local-6989586621679539729"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679539728"><span class="annot"><a href="#local-6989586621679539728"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679539727"><span class="annot"><a href="#local-6989586621679539727"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679539726"><span class="annot"><a href="#local-6989586621679539726"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679539725"><span class="annot"><a href="#local-6989586621679539725"><span class="hs-identifier hs-type">gradientFrom</span></a></span></span><span> </span><span id="local-6989586621679539724"><span class="annot"><a href="#local-6989586621679539724"><span class="hs-identifier hs-type">layoutFrom</span></a></span></span><span> </span><span id="local-6989586621679539723"><span class="annot"><a href="#local-6989586621679539723"><span class="hs-identifier hs-type">deviceFrom</span></a></span></span><span> </span><span id="local-6989586621679539722"><span class="annot"><a href="#local-6989586621679539722"><span class="hs-identifier hs-type">dataTypeFrom</span></a></span></span><span> </span><span id="local-6989586621679539721"><span class="annot"><a href="#local-6989586621679539721"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-1688"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-type">SingI</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679539729"><span class="hs-identifier hs-type">gradient</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-1689"></span><span>    </span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-type">SingI</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679539728"><span class="hs-identifier hs-type">layout</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-1690"></span><span>    </span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-type">SingI</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679539727"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-1691"></span><span>    </span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-type">SingI</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679539726"><span class="hs-identifier hs-type">dataType</span></a></span><span>
</span><span id="line-1692"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-1693"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679539725"><span class="hs-identifier hs-type">gradientFrom</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679539724"><span class="hs-identifier hs-type">layoutFrom</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679539723"><span class="hs-identifier hs-type">deviceFrom</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679539722"><span class="hs-identifier hs-type">dataTypeFrom</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679539721"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1694"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">IO</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679539729"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679539728"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679539727"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679539726"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679539721"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-1695"></span><span id="setTensorOptions"><span class="annot"><span class="annottext">setTensorOptions :: Tensor gradientFrom layoutFrom deviceFrom dataTypeFrom shape
-&gt; IO (Tensor gradient layout device dataType shape)
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#setTensorOptions"><span class="hs-identifier hs-var hs-var">setTensorOptions</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; Tensor gradientFrom layoutFrom deviceFrom dataTypeFrom shape
-&gt; IO (Tensor gradient layout device dataType shape)
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (gradientFrom :: Gradient RequiresGradient)
       (layoutFrom :: Layout LayoutType)
       (deviceFrom :: Device (DeviceType Nat))
       (dataTypeFrom :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; Tensor gradientFrom layoutFrom deviceFrom dataTypeFrom shape
-&gt; IO (Tensor gradient layout device dataType shape)
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sSetTensorOptions"><span class="hs-identifier hs-var">sSetTensorOptions</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SingI gradient =&gt; Sing gradient
forall k (a :: k). SingI a =&gt; Sing a
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">sing</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679539729"><span class="hs-identifier hs-type">gradient</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SingI layout =&gt; Sing layout
forall k (a :: k). SingI a =&gt; Sing a
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">sing</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679539728"><span class="hs-identifier hs-type">layout</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SingI device =&gt; Sing device
forall k (a :: k). SingI a =&gt; Sing a
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">sing</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679539727"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SingI dataType =&gt; Sing dataType
forall k (a :: k). SingI a =&gt; Sing a
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">sing</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679539726"><span class="hs-identifier hs-type">dataType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-1696"></span><span>
</span><span id="line-1697"></span><span class="hs-comment">-- instance</span><span>
</span><span id="line-1698"></span><span class="hs-comment">--   ( SingI gradient,</span><span>
</span><span id="line-1699"></span><span class="hs-comment">--     SingI layout,</span><span>
</span><span id="line-1700"></span><span class="hs-comment">--     SingI device,</span><span>
</span><span id="line-1701"></span><span class="hs-comment">--     SingI dType</span><span>
</span><span id="line-1702"></span><span class="hs-comment">--   ) =&gt;</span><span>
</span><span id="line-1703"></span><span class="hs-comment">--   TensorLike (Tensor gradient layout device ('DataType dType) ('Shape dims)) dType dims</span><span>
</span><span id="line-1704"></span><span class="hs-comment">--   where</span><span>
</span><span id="line-1705"></span><span class="hs-comment">--   sToTensor gradient' layout device t = pure $ sSetTensorOptions gradient' layout device dataType t</span><span>
</span><span id="line-1706"></span><span class="hs-comment">--     where</span><span>
</span><span id="line-1707"></span><span class="hs-comment">--       dataType = SDataType $ sing @dType</span><span>
</span><span id="line-1708"></span><span>
</span><span id="line-1709"></span><span class="hs-comment">--   fromTensor = setTensorOptions @gradient @layout @device @('DataType dType)</span><span>
</span><span id="line-1710"></span></pre></body></html>