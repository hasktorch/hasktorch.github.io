<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><link rel="stylesheet" type="text/css" href="style.css" /><script type="text/javascript" src="highlight.js"></script></head><body><pre><span class="hs-pragma">{-# LANGUAGE DataKinds #-}</span><span>
</span><span id="line-2"></span><span class="hs-pragma">{-# LANGUAGE KindSignatures #-}</span><span>
</span><span id="line-3"></span><span class="hs-pragma">{-# LANGUAGE PolyKinds #-}</span><span>
</span><span id="line-4"></span><span class="hs-pragma">{-# LANGUAGE RankNTypes #-}</span><span>
</span><span id="line-5"></span><span class="hs-pragma">{-# LANGUAGE StandaloneKindSignatures #-}</span><span>
</span><span id="line-6"></span><span class="hs-pragma">{-# LANGUAGE TypeFamilies #-}</span><span>
</span><span id="line-7"></span><span class="hs-pragma">{-# LANGUAGE TypeOperators #-}</span><span>
</span><span id="line-8"></span><span class="hs-pragma">{-# LANGUAGE UndecidableInstances #-}</span><span>
</span><span id="line-9"></span><span>
</span><span id="line-10"></span><span class="hs-keyword">module</span><span> </span><span class="hs-identifier">Torch.GraduallyTyped.Tensor.MathOperations.BlasLapack</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-11"></span><span>
</span><span id="line-12"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">Control.Monad.Catch</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier">MonadThrow</span></span><span class="hs-special">)</span><span>
</span><span id="line-13"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">Data.Type.Bool</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier">If</span></span><span class="hs-special">)</span><span>
</span><span id="line-14"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">GHC.TypeLits</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier">Nat</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier">Symbol</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier">TypeError</span></span><span class="hs-special">)</span><span>
</span><span id="line-15"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html"><span class="hs-identifier">Torch.GraduallyTyped.Prelude</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Catch"><span class="hs-identifier">Catch</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#PrependMaybe"><span class="hs-identifier">PrependMaybe</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Reverse"><span class="hs-identifier">Reverse</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-16"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.html"><span class="hs-identifier">Torch.GraduallyTyped.Shape</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#BroadcastDimsImplF"><span class="hs-identifier">BroadcastDimsImplF</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier">Name</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier">Shape</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier">Size</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-17"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html"><span class="hs-identifier">Torch.GraduallyTyped.Tensor.Type</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier">Tensor</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-18"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html"><span class="hs-identifier">Torch.GraduallyTyped.Unify</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#UnifyCheck"><span class="hs-identifier">UnifyCheck</span></a></span><span class="hs-special">,</span><span> </span><span class="hs-keyword">type</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator">(&lt;+&gt;)</span></a></span><span class="hs-special">,</span><span> </span><span class="hs-keyword">type</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator">(&lt;|&gt;)</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-19"></span><span class="hs-keyword">import</span><span> </span><span class="hs-keyword">qualified</span><span> </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier">Torch.Internal.Cast</span></a></span><span> </span><span class="hs-keyword">as</span><span> </span><span class="annot"><span class="hs-identifier">ATen</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier">cast2</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-20"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier">Torch.Internal.GC</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier">unsafeThrowableIO</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-21"></span><span class="hs-keyword">import</span><span> </span><span class="hs-keyword">qualified</span><span> </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier">Torch.Internal.Managed.Native</span></a></span><span> </span><span class="hs-keyword">as</span><span> </span><span class="annot"><span class="hs-identifier">ATen</span></span><span>
</span><span id="line-22"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/r6jdzwafy5276v4j29nczdzrg130l9ff-type-errors-pretty-lib-type-errors-pretty-0.0.1.2-haddock-doc/share/doc/type-errors-pretty/html/src"><span class="hs-identifier">Type.Errors.Pretty</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-keyword">type</span><span> </span><span class="annot"><a href="../file:///nix/store/r6jdzwafy5276v4j29nczdzrg130l9ff-type-errors-pretty-lib-type-errors-pretty-0.0.1.2-haddock-doc/share/doc/type-errors-pretty/html/src"><span class="hs-operator">(%)</span></a></span><span class="hs-special">,</span><span> </span><span class="hs-keyword">type</span><span> </span><span class="annot"><a href="../file:///nix/store/r6jdzwafy5276v4j29nczdzrg130l9ff-type-errors-pretty-lib-type-errors-pretty-0.0.1.2-haddock-doc/share/doc/type-errors-pretty/html/src"><span class="hs-operator">(&lt;&gt;)</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-23"></span><span>
</span><span id="line-24"></span><span class="hs-comment">-- $setup</span><span>
</span><span id="line-25"></span><span class="hs-comment">-- &gt;&gt;&gt; import Torch.GraduallyTyped.Prelude.List (SList (..))</span><span>
</span><span id="line-26"></span><span class="hs-comment">-- &gt;&gt;&gt; import Torch.GraduallyTyped</span><span>
</span><span id="line-27"></span><span>
</span><span id="line-28"></span><span class="hs-keyword">type</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.BlasLapack.html#MatmulDimsImplF"><span class="hs-identifier hs-type">MatmulDimsImplF</span></a></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">]</span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">[</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">]</span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Maybe</span></span><span> </span><span class="hs-special">[</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">]</span><span>
</span><span id="line-29"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span> </span><span id="MatmulDimsImplF"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.BlasLapack.html#MatmulDimsImplF"><span class="hs-identifier hs-var">MatmulDimsImplF</span></a></span></span><span> </span><span id="local-6989586621679687707"><span class="annot"><a href="#local-6989586621679687707"><span class="hs-identifier hs-type">reversedDims</span></a></span></span><span> </span><span id="local-6989586621679687706"><span class="annot"><a href="#local-6989586621679687706"><span class="hs-identifier hs-type">reversedDims'</span></a></span></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-30"></span><span>  </span><span id="MatmulDimsImplF"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.BlasLapack.html#MatmulDimsImplF"><span class="hs-identifier hs-var">MatmulDimsImplF</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679687705"><span class="annot"><a href="#local-6989586621679687705"><span class="hs-identifier hs-type hs-type">k</span></a></span></span><span> </span><span class="hs-special">'</span><span class="hs-glyph">:</span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679687704"><span class="annot"><a href="#local-6989586621679687704"><span class="hs-identifier hs-type hs-type">k'</span></a></span></span><span> </span><span class="hs-special">'</span><span class="hs-glyph">:</span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-31"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">If</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#UnifyCheck"><span class="hs-identifier hs-type">UnifyCheck</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679687705"><span class="hs-identifier hs-type">k</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679687704"><span class="hs-identifier hs-type">k'</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><span class="hs-identifier hs-type">Just</span></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span class="hs-special">'</span><span class="annot"><span class="hs-identifier hs-type">Nothing</span></span><span>
</span><span id="line-32"></span><span>  </span><span id="MatmulDimsImplF"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.BlasLapack.html#MatmulDimsImplF"><span class="hs-identifier hs-var">MatmulDimsImplF</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679687703"><span class="annot"><a href="#local-6989586621679687703"><span class="hs-identifier hs-type hs-type">k</span></a></span></span><span> </span><span class="hs-special">'</span><span class="hs-glyph">:</span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679687702"><span class="annot"><a href="#local-6989586621679687702"><span class="hs-identifier hs-type hs-type">m</span></a></span></span><span> </span><span class="hs-special">'</span><span class="hs-glyph">:</span><span> </span><span id="local-6989586621679687701"><span class="annot"><a href="#local-6989586621679687701"><span class="hs-identifier hs-type hs-type">k'</span></a></span></span><span> </span><span class="hs-special">'</span><span class="hs-glyph">:</span><span> </span><span id="local-6989586621679687700"><span class="annot"><a href="#local-6989586621679687700"><span class="hs-identifier hs-type hs-type">reversedBroadcastDims'</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-33"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">If</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#UnifyCheck"><span class="hs-identifier hs-type">UnifyCheck</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679687703"><span class="hs-identifier hs-type">k</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679687701"><span class="hs-identifier hs-type">k'</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#PrependMaybe"><span class="hs-identifier hs-type">PrependMaybe</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><span class="hs-identifier hs-type">Just</span></span><span> </span><span class="annot"><a href="#local-6989586621679687702"><span class="hs-identifier hs-type">m</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#BroadcastDimsImplF"><span class="hs-identifier hs-type">BroadcastDimsImplF</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="hs-special">]</span><span> </span><span class="annot"><a href="#local-6989586621679687700"><span class="hs-identifier hs-type">reversedBroadcastDims'</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-special">'</span><span class="annot"><span class="hs-identifier hs-type">Nothing</span></span><span>
</span><span id="line-34"></span><span>  </span><span id="MatmulDimsImplF"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.BlasLapack.html#MatmulDimsImplF"><span class="hs-identifier hs-var">MatmulDimsImplF</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679687699"><span class="annot"><a href="#local-6989586621679687699"><span class="hs-identifier hs-type hs-type">k</span></a></span></span><span> </span><span class="hs-special">'</span><span class="hs-glyph">:</span><span> </span><span id="local-6989586621679687698"><span class="annot"><a href="#local-6989586621679687698"><span class="hs-identifier hs-type hs-type">n</span></a></span></span><span> </span><span class="hs-special">'</span><span class="hs-glyph">:</span><span> </span><span id="local-6989586621679687697"><span class="annot"><a href="#local-6989586621679687697"><span class="hs-identifier hs-type hs-type">reversedBroadcastDims</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679687696"><span class="annot"><a href="#local-6989586621679687696"><span class="hs-identifier hs-type hs-type">k'</span></a></span></span><span> </span><span class="hs-special">'</span><span class="hs-glyph">:</span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-35"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">If</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#UnifyCheck"><span class="hs-identifier hs-type">UnifyCheck</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679687699"><span class="hs-identifier hs-type">k</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679687696"><span class="hs-identifier hs-type">k'</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#PrependMaybe"><span class="hs-identifier hs-type">PrependMaybe</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><span class="hs-identifier hs-type">Just</span></span><span> </span><span class="annot"><a href="#local-6989586621679687698"><span class="hs-identifier hs-type">n</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#BroadcastDimsImplF"><span class="hs-identifier hs-type">BroadcastDimsImplF</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="hs-special">]</span><span> </span><span class="annot"><a href="#local-6989586621679687697"><span class="hs-identifier hs-type">reversedBroadcastDims</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-special">'</span><span class="annot"><span class="hs-identifier hs-type">Nothing</span></span><span>
</span><span id="line-36"></span><span>  </span><span id="MatmulDimsImplF"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.BlasLapack.html#MatmulDimsImplF"><span class="hs-identifier hs-var">MatmulDimsImplF</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679687695"><span class="annot"><a href="#local-6989586621679687695"><span class="hs-identifier hs-type hs-type">k</span></a></span></span><span> </span><span class="hs-special">'</span><span class="hs-glyph">:</span><span> </span><span id="local-6989586621679687694"><span class="annot"><a href="#local-6989586621679687694"><span class="hs-identifier hs-type hs-type">n</span></a></span></span><span> </span><span class="hs-special">'</span><span class="hs-glyph">:</span><span> </span><span id="local-6989586621679687693"><span class="annot"><a href="#local-6989586621679687693"><span class="hs-identifier hs-type hs-type">reversedBroadcastDims</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679687692"><span class="annot"><a href="#local-6989586621679687692"><span class="hs-identifier hs-type hs-type">m</span></a></span></span><span> </span><span class="hs-special">'</span><span class="hs-glyph">:</span><span> </span><span id="local-6989586621679687691"><span class="annot"><a href="#local-6989586621679687691"><span class="hs-identifier hs-type hs-type">k'</span></a></span></span><span> </span><span class="hs-special">'</span><span class="hs-glyph">:</span><span> </span><span id="local-6989586621679687690"><span class="annot"><a href="#local-6989586621679687690"><span class="hs-identifier hs-type hs-type">reversedBroadcastDims'</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-37"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">If</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#UnifyCheck"><span class="hs-identifier hs-type">UnifyCheck</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679687695"><span class="hs-identifier hs-type">k</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679687691"><span class="hs-identifier hs-type">k'</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#PrependMaybe"><span class="hs-identifier hs-type">PrependMaybe</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><span class="hs-identifier hs-type">Just</span></span><span> </span><span class="annot"><a href="#local-6989586621679687692"><span class="hs-identifier hs-type">m</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#PrependMaybe"><span class="hs-identifier hs-type">PrependMaybe</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><span class="hs-identifier hs-type">Just</span></span><span> </span><span class="annot"><a href="#local-6989586621679687694"><span class="hs-identifier hs-type">n</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#BroadcastDimsImplF"><span class="hs-identifier hs-type">BroadcastDimsImplF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679687693"><span class="hs-identifier hs-type">reversedBroadcastDims</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679687690"><span class="hs-identifier hs-type">reversedBroadcastDims'</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-special">'</span><span class="annot"><span class="hs-identifier hs-type">Nothing</span></span><span>
</span><span id="line-38"></span><span>  </span><span id="MatmulDimsImplF"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.BlasLapack.html#MatmulDimsImplF"><span class="hs-identifier hs-var">MatmulDimsImplF</span></a></span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">'</span><span class="annot"><span class="hs-identifier hs-type">Nothing</span></span><span>
</span><span id="line-39"></span><span>
</span><span id="line-40"></span><span class="hs-keyword">type</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.BlasLapack.html#MatmulDimsCheckF"><span class="hs-identifier hs-type">MatmulDimsCheckF</span></a></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">]</span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">[</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">]</span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Maybe</span></span><span> </span><span class="hs-special">[</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">]</span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">[</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">]</span><span>
</span><span id="line-41"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span> </span><span id="MatmulDimsCheckF"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.BlasLapack.html#MatmulDimsCheckF"><span class="hs-identifier hs-var">MatmulDimsCheckF</span></a></span></span><span> </span><span id="local-6989586621679687688"><span class="annot"><a href="#local-6989586621679687688"><span class="hs-identifier hs-type">dims</span></a></span></span><span> </span><span id="local-6989586621679687687"><span class="annot"><a href="#local-6989586621679687687"><span class="hs-identifier hs-type">dims'</span></a></span></span><span> </span><span id="local-6989586621679687686"><span class="annot"><a href="#local-6989586621679687686"><span class="hs-identifier hs-type">result</span></a></span></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-42"></span><span>  </span><span id="MatmulDimsCheckF"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.BlasLapack.html#MatmulDimsCheckF"><span class="hs-identifier hs-var">MatmulDimsCheckF</span></a></span></span><span> </span><span id="local-6989586621679687685"><span class="annot"><a href="#local-6989586621679687685"><span class="hs-identifier hs-type hs-type">dims</span></a></span></span><span> </span><span id="local-6989586621679687684"><span class="annot"><a href="#local-6989586621679687684"><span class="hs-identifier hs-type hs-type">dims'</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><span class="hs-identifier hs-type">Nothing</span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-43"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">TypeError</span></span><span>
</span><span id="line-44"></span><span>      </span><span class="hs-special">(</span><span> </span><span class="annot"><span class="hs-string">&quot;Cannot multiply the tensors since the dimensions&quot;</span></span><span>
</span><span id="line-45"></span><span>          </span><span class="annot"><a href="../file:///nix/store/r6jdzwafy5276v4j29nczdzrg130l9ff-type-errors-pretty-lib-type-errors-pretty-0.0.1.2-haddock-doc/share/doc/type-errors-pretty/html/src"><span class="hs-operator hs-type">%</span></a></span><span> </span><span class="annot"><span class="hs-string">&quot;&quot;</span></span><span>
</span><span id="line-46"></span><span>          </span><span class="annot"><a href="../file:///nix/store/r6jdzwafy5276v4j29nczdzrg130l9ff-type-errors-pretty-lib-type-errors-pretty-0.0.1.2-haddock-doc/share/doc/type-errors-pretty/html/src"><span class="hs-operator hs-type">%</span></a></span><span> </span><span class="annot"><span class="hs-string">&quot;    '&quot;</span></span><span> </span><span class="annot"><a href="../file:///nix/store/r6jdzwafy5276v4j29nczdzrg130l9ff-type-errors-pretty-lib-type-errors-pretty-0.0.1.2-haddock-doc/share/doc/type-errors-pretty/html/src"><span class="hs-operator hs-type">&lt;&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679687685"><span class="hs-identifier hs-type">dims</span></a></span><span> </span><span class="annot"><a href="../file:///nix/store/r6jdzwafy5276v4j29nczdzrg130l9ff-type-errors-pretty-lib-type-errors-pretty-0.0.1.2-haddock-doc/share/doc/type-errors-pretty/html/src"><span class="hs-operator hs-type">&lt;&gt;</span></a></span><span> </span><span class="annot"><span class="hs-string">&quot;' and '&quot;</span></span><span> </span><span class="annot"><a href="../file:///nix/store/r6jdzwafy5276v4j29nczdzrg130l9ff-type-errors-pretty-lib-type-errors-pretty-0.0.1.2-haddock-doc/share/doc/type-errors-pretty/html/src"><span class="hs-operator hs-type">&lt;&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679687684"><span class="hs-identifier hs-type">dims'</span></a></span><span> </span><span class="annot"><a href="../file:///nix/store/r6jdzwafy5276v4j29nczdzrg130l9ff-type-errors-pretty-lib-type-errors-pretty-0.0.1.2-haddock-doc/share/doc/type-errors-pretty/html/src"><span class="hs-operator hs-type">&lt;&gt;</span></a></span><span> </span><span class="annot"><span class="hs-string">&quot;'&quot;</span></span><span>
</span><span id="line-47"></span><span>          </span><span class="annot"><a href="../file:///nix/store/r6jdzwafy5276v4j29nczdzrg130l9ff-type-errors-pretty-lib-type-errors-pretty-0.0.1.2-haddock-doc/share/doc/type-errors-pretty/html/src"><span class="hs-operator hs-type">%</span></a></span><span> </span><span class="annot"><span class="hs-string">&quot;&quot;</span></span><span>
</span><span id="line-48"></span><span>          </span><span class="annot"><a href="../file:///nix/store/r6jdzwafy5276v4j29nczdzrg130l9ff-type-errors-pretty-lib-type-errors-pretty-0.0.1.2-haddock-doc/share/doc/type-errors-pretty/html/src"><span class="hs-operator hs-type">%</span></a></span><span> </span><span class="annot"><span class="hs-string">&quot;are not compatible for matrix multiplation.&quot;</span></span><span>
</span><span id="line-49"></span><span>          </span><span class="annot"><a href="../file:///nix/store/r6jdzwafy5276v4j29nczdzrg130l9ff-type-errors-pretty-lib-type-errors-pretty-0.0.1.2-haddock-doc/share/doc/type-errors-pretty/html/src"><span class="hs-operator hs-type">%</span></a></span><span> </span><span class="annot"><span class="hs-string">&quot;You may need to reshape the tensor(s) first.&quot;</span></span><span>
</span><span id="line-50"></span><span>      </span><span class="hs-special">)</span><span>
</span><span id="line-51"></span><span>  </span><span id="MatmulDimsCheckF"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.BlasLapack.html#MatmulDimsCheckF"><span class="hs-identifier hs-var">MatmulDimsCheckF</span></a></span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><span class="hs-identifier hs-type">Just</span></span><span> </span><span id="local-6989586621679687683"><span class="annot"><a href="#local-6989586621679687683"><span class="hs-identifier hs-type hs-type">result</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Reverse"><span class="hs-identifier hs-type">Reverse</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679687683"><span class="hs-identifier hs-type">result</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-52"></span><span>
</span><span id="line-53"></span><span class="hs-keyword">type</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.BlasLapack.html#MatmulDimsF"><span class="hs-identifier hs-type">MatmulDimsF</span></a></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">]</span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">[</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">]</span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">[</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">]</span><span>
</span><span id="line-54"></span><span>
</span><span id="line-55"></span><span class="hs-keyword">type</span><span> </span><span id="MatmulDimsF"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.BlasLapack.html#MatmulDimsF"><span class="hs-identifier hs-var">MatmulDimsF</span></a></span></span><span> </span><span id="local-6989586621679687681"><span class="annot"><a href="#local-6989586621679687681"><span class="hs-identifier hs-type">dims</span></a></span></span><span> </span><span id="local-6989586621679687680"><span class="annot"><a href="#local-6989586621679687680"><span class="hs-identifier hs-type">dims'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.BlasLapack.html#MatmulDimsCheckF"><span class="hs-identifier hs-type">MatmulDimsCheckF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679687681"><span class="hs-identifier hs-type">dims</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679687680"><span class="hs-identifier hs-type">dims'</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.BlasLapack.html#MatmulDimsImplF"><span class="hs-identifier hs-type">MatmulDimsImplF</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Reverse"><span class="hs-identifier hs-type">Reverse</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679687681"><span class="hs-identifier hs-type">dims</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Reverse"><span class="hs-identifier hs-type">Reverse</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679687680"><span class="hs-identifier hs-type">dims'</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-56"></span><span>
</span><span id="line-57"></span><span class="hs-keyword">type</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.BlasLapack.html#MatmulF"><span class="hs-identifier hs-type">MatmulF</span></a></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">[</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">]</span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">[</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">]</span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">[</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">]</span><span>
</span><span id="line-58"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span> </span><span id="MatmulF"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.BlasLapack.html#MatmulF"><span class="hs-identifier hs-var">MatmulF</span></a></span></span><span> </span><span id="local-6989586621679687678"><span class="annot"><a href="#local-6989586621679687678"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679687677"><span class="annot"><a href="#local-6989586621679687677"><span class="hs-identifier hs-type">shape'</span></a></span></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-59"></span><span>  </span><span id="MatmulF"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.BlasLapack.html#MatmulF"><span class="hs-identifier hs-var">MatmulF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#UncheckedShape"><span class="hs-identifier hs-type">UncheckedShape</span></a></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#UncheckedShape"><span class="hs-identifier hs-type">UncheckedShape</span></a></span><span>
</span><span id="line-60"></span><span>  </span><span id="MatmulF"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.BlasLapack.html#MatmulF"><span class="hs-identifier hs-var">MatmulF</span></a></span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#UncheckedShape"><span class="hs-identifier hs-type">UncheckedShape</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#UncheckedShape"><span class="hs-identifier hs-type">UncheckedShape</span></a></span><span>
</span><span id="line-61"></span><span>  </span><span id="MatmulF"><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.BlasLapack.html#MatmulF"><span class="hs-identifier hs-var">MatmulF</span></a></span></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span id="local-6989586621679687674"><span class="annot"><a href="#local-6989586621679687674"><span class="hs-identifier hs-type hs-type">dims</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span id="local-6989586621679687673"><span class="annot"><a href="#local-6989586621679687673"><span class="hs-identifier hs-type hs-type">dims'</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.BlasLapack.html#MatmulDimsF"><span class="hs-identifier hs-type">MatmulDimsF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679687674"><span class="hs-identifier hs-type">dims</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679687673"><span class="hs-identifier hs-type">dims'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-62"></span><span>
</span><span id="line-63"></span><span class="hs-comment">-- | Matrix product of two tensors.</span><span>
</span><span id="line-64"></span><span class="hs-comment">--</span><span>
</span><span id="line-65"></span><span class="hs-comment">-- The following code serves the examples of @matmul@ below:</span><span>
</span><span id="line-66"></span><span class="hs-comment">--</span><span>
</span><span id="line-67"></span><span class="hs-comment">-- &gt;&gt;&gt; g &lt;- sMkGenerator (SDevice SCPU) 0</span><span>
</span><span id="line-68"></span><span class="hs-comment">-- &gt;&gt;&gt; sRandn' = sRandn . TensorSpec (SGradient SWithGradient) (SLayout SDense) (SDevice SCPU) (SDataType SFloat)</span><span>
</span><span id="line-69"></span><span class="hs-comment">--</span><span>
</span><span id="line-70"></span><span class="hs-comment">-- In order to understand the behavior of @matmul@, consider the following cases:</span><span>
</span><span id="line-71"></span><span class="hs-comment">--</span><span>
</span><span id="line-72"></span><span class="hs-comment">--     (1) If both tensors are 1-dimensional, the dot product (scalar) is returned:</span><span>
</span><span id="line-73"></span><span class="hs-comment">--</span><span>
</span><span id="line-74"></span><span class="hs-comment">--         &gt;&gt;&gt; (tensor1, g') &lt;- sRandn' (SShape $ SName @&quot;*&quot; :&amp;: SSize @3 :|: SNil) g</span><span>
</span><span id="line-75"></span><span class="hs-comment">--         &gt;&gt;&gt; (tensor2, g'') &lt;- sRandn' (SShape $ SName @&quot;*&quot; :&amp;: SSize @3 :|: SNil) g'</span><span>
</span><span id="line-76"></span><span class="hs-comment">--         &gt;&gt;&gt; result = tensor1 `matmul` tensor2</span><span>
</span><span id="line-77"></span><span class="hs-comment">--         &gt;&gt;&gt; :type result</span><span>
</span><span id="line-78"></span><span class="hs-comment">--         result</span><span>
</span><span id="line-79"></span><span class="hs-comment">--           :: MonadThrow m =&gt;</span><span>
</span><span id="line-80"></span><span class="hs-comment">--              m (Tensor</span><span>
</span><span id="line-81"></span><span class="hs-comment">--                   ('Gradient 'WithGradient)</span><span>
</span><span id="line-82"></span><span class="hs-comment">--                   ('Layout 'Dense)</span><span>
</span><span id="line-83"></span><span class="hs-comment">--                   ('Device 'CPU)</span><span>
</span><span id="line-84"></span><span class="hs-comment">--                   ('DataType 'Float)</span><span>
</span><span id="line-85"></span><span class="hs-comment">--                   ('Shape '[]))</span><span>
</span><span id="line-86"></span><span class="hs-comment">--</span><span>
</span><span id="line-87"></span><span class="hs-comment">--</span><span>
</span><span id="line-88"></span><span class="hs-comment">--     (2) If both arguments are 2-dimensional, the matrix-matrix product is returned:</span><span>
</span><span id="line-89"></span><span class="hs-comment">--</span><span>
</span><span id="line-90"></span><span class="hs-comment">--         &gt;&gt;&gt; (tensor1, g') &lt;- sRandn' (SShape $ SName @&quot;*&quot; :&amp;: SSize @3 :|: SName @&quot;*&quot; :&amp;: SSize @4 :|: SNil) g</span><span>
</span><span id="line-91"></span><span class="hs-comment">--         &gt;&gt;&gt; (tensor2, g'') &lt;- sRandn' (SShape $ SName @&quot;*&quot; :&amp;: SSize @4 :|: SName @&quot;*&quot; :&amp;: SSize @7 :|: SNil) g'</span><span>
</span><span id="line-92"></span><span class="hs-comment">--         &gt;&gt;&gt; result = tensor1 `matmul` tensor2</span><span>
</span><span id="line-93"></span><span class="hs-comment">--         &gt;&gt;&gt; :type result</span><span>
</span><span id="line-94"></span><span class="hs-comment">--         result</span><span>
</span><span id="line-95"></span><span class="hs-comment">--           :: MonadThrow m =&gt;</span><span>
</span><span id="line-96"></span><span class="hs-comment">--              m (Tensor</span><span>
</span><span id="line-97"></span><span class="hs-comment">--                   ('Gradient 'WithGradient)</span><span>
</span><span id="line-98"></span><span class="hs-comment">--                   ('Layout 'Dense)</span><span>
</span><span id="line-99"></span><span class="hs-comment">--                   ('Device 'CPU)</span><span>
</span><span id="line-100"></span><span class="hs-comment">--                   ('DataType 'Float)</span><span>
</span><span id="line-101"></span><span class="hs-comment">--                   ('Shape</span><span>
</span><span id="line-102"></span><span class="hs-comment">--                      '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7)]))</span><span>
</span><span id="line-103"></span><span class="hs-comment">--</span><span>
</span><span id="line-104"></span><span class="hs-comment">--</span><span>
</span><span id="line-105"></span><span class="hs-comment">--     (3) If the first argument is 1-dimensional and the second argument is 2-dimensional,</span><span>
</span><span id="line-106"></span><span class="hs-comment">--     a 1 is prepended to its dimension for the purpose of the matrix multiply.</span><span>
</span><span id="line-107"></span><span class="hs-comment">--     After the matrix multiply, the prepended dimension is removed:</span><span>
</span><span id="line-108"></span><span class="hs-comment">--</span><span>
</span><span id="line-109"></span><span class="hs-comment">--         &gt;&gt;&gt; (tensor1, g') &lt;- sRandn' (SShape $ SName @&quot;*&quot; :&amp;: SSize @4 :|: SNil) g</span><span>
</span><span id="line-110"></span><span class="hs-comment">--         &gt;&gt;&gt; (tensor2, g'') &lt;- sRandn' (SShape $ SName @&quot;*&quot; :&amp;: SSize @4 :|: SName @&quot;*&quot; :&amp;: SSize @7 :|: SNil) g'</span><span>
</span><span id="line-111"></span><span class="hs-comment">--         &gt;&gt;&gt; result = tensor1 `matmul` tensor2</span><span>
</span><span id="line-112"></span><span class="hs-comment">--         &gt;&gt;&gt; :type result</span><span>
</span><span id="line-113"></span><span class="hs-comment">--         result</span><span>
</span><span id="line-114"></span><span class="hs-comment">--           :: MonadThrow m =&gt;</span><span>
</span><span id="line-115"></span><span class="hs-comment">--              m (Tensor</span><span>
</span><span id="line-116"></span><span class="hs-comment">--                   ('Gradient 'WithGradient)</span><span>
</span><span id="line-117"></span><span class="hs-comment">--                   ('Layout 'Dense)</span><span>
</span><span id="line-118"></span><span class="hs-comment">--                   ('Device 'CPU)</span><span>
</span><span id="line-119"></span><span class="hs-comment">--                   ('DataType 'Float)</span><span>
</span><span id="line-120"></span><span class="hs-comment">--                   ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 7)]))</span><span>
</span><span id="line-121"></span><span class="hs-comment">--</span><span>
</span><span id="line-122"></span><span class="hs-comment">--</span><span>
</span><span id="line-123"></span><span class="hs-comment">--     (4) If the first argument is 2-dimensional and the second argument is 1-dimensional,</span><span>
</span><span id="line-124"></span><span class="hs-comment">--     the matrix-vector product is returned:</span><span>
</span><span id="line-125"></span><span class="hs-comment">--</span><span>
</span><span id="line-126"></span><span class="hs-comment">--         &gt;&gt;&gt; (tensor1, g') &lt;- sRandn' (SShape $ SName @&quot;*&quot; :&amp;: SSize @3 :|: SName @&quot;*&quot; :&amp;: SSize @4 :|: SNil) g</span><span>
</span><span id="line-127"></span><span class="hs-comment">--         &gt;&gt;&gt; (tensor2, g'') &lt;- sRandn' (SShape $ SName @&quot;*&quot; :&amp;: SSize @4 :|: SNil) g'</span><span>
</span><span id="line-128"></span><span class="hs-comment">--         &gt;&gt;&gt; result = tensor1 `matmul` tensor2</span><span>
</span><span id="line-129"></span><span class="hs-comment">--         &gt;&gt;&gt; :type result</span><span>
</span><span id="line-130"></span><span class="hs-comment">--         result</span><span>
</span><span id="line-131"></span><span class="hs-comment">--           :: MonadThrow m =&gt;</span><span>
</span><span id="line-132"></span><span class="hs-comment">--              m (Tensor</span><span>
</span><span id="line-133"></span><span class="hs-comment">--                   ('Gradient 'WithGradient)</span><span>
</span><span id="line-134"></span><span class="hs-comment">--                   ('Layout 'Dense)</span><span>
</span><span id="line-135"></span><span class="hs-comment">--                   ('Device 'CPU)</span><span>
</span><span id="line-136"></span><span class="hs-comment">--                   ('DataType 'Float)</span><span>
</span><span id="line-137"></span><span class="hs-comment">--                   ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 3)]))</span><span>
</span><span id="line-138"></span><span class="hs-comment">--</span><span>
</span><span id="line-139"></span><span class="hs-comment">--</span><span>
</span><span id="line-140"></span><span class="hs-comment">--     (5) If both arguments are at least 1-dimensional and at least one argument is \(n\)-dimensional (where \(n &gt; 2\)),</span><span>
</span><span id="line-141"></span><span class="hs-comment">--     then a batched matrix multiply is returned.</span><span>
</span><span id="line-142"></span><span class="hs-comment">--</span><span>
</span><span id="line-143"></span><span class="hs-comment">--     The following is an example of a batched matrix multiplication:</span><span>
</span><span id="line-144"></span><span class="hs-comment">--</span><span>
</span><span id="line-145"></span><span class="hs-comment">--         &gt;&gt;&gt; (tensor1, g') &lt;- sRandn' (SShape $ SName @&quot;batch&quot; :&amp;: SSize @10 :|: SName @&quot;*&quot; :&amp;: SSize @3 :|: SName @&quot;*&quot; :&amp;: SSize @4 :|: SNil) g</span><span>
</span><span id="line-146"></span><span class="hs-comment">--         &gt;&gt;&gt; (tensor2, g'') &lt;- sRandn' (SShape $ SName @&quot;batch&quot; :&amp;: SSize @10 :|: SName @&quot;*&quot; :&amp;: SSize @4 :|: SName @&quot;*&quot; :&amp;: SSize @7 :|: SNil) g'</span><span>
</span><span id="line-147"></span><span class="hs-comment">--         &gt;&gt;&gt; result = tensor1 `matmul` tensor2</span><span>
</span><span id="line-148"></span><span class="hs-comment">--         &gt;&gt;&gt; :type result</span><span>
</span><span id="line-149"></span><span class="hs-comment">--         result</span><span>
</span><span id="line-150"></span><span class="hs-comment">--           :: MonadThrow m =&gt;</span><span>
</span><span id="line-151"></span><span class="hs-comment">--              m (Tensor</span><span>
</span><span id="line-152"></span><span class="hs-comment">--                   ('Gradient 'WithGradient)</span><span>
</span><span id="line-153"></span><span class="hs-comment">--                   ('Layout 'Dense)</span><span>
</span><span id="line-154"></span><span class="hs-comment">--                   ('Device 'CPU)</span><span>
</span><span id="line-155"></span><span class="hs-comment">--                   ('DataType 'Float)</span><span>
</span><span id="line-156"></span><span class="hs-comment">--                   ('Shape</span><span>
</span><span id="line-157"></span><span class="hs-comment">--                      '[ 'Dim ('Name &quot;batch&quot;) ('Size 10), 'Dim ('Name &quot;*&quot;) ('Size 3),</span><span>
</span><span id="line-158"></span><span class="hs-comment">--                         'Dim ('Name &quot;*&quot;) ('Size 7)]))</span><span>
</span><span id="line-159"></span><span class="hs-comment">--</span><span>
</span><span id="line-160"></span><span class="hs-comment">--</span><span>
</span><span id="line-161"></span><span class="hs-comment">--     If the first argument is 1-dimensional,</span><span>
</span><span id="line-162"></span><span class="hs-comment">--     a 1 is prepended to its dimension for the purpose of the batched matrix multiply and removed after:</span><span>
</span><span id="line-163"></span><span class="hs-comment">--</span><span>
</span><span id="line-164"></span><span class="hs-comment">--         &gt;&gt;&gt; (tensor1, g') &lt;- sRandn' (SShape $ SName @&quot;*&quot; :&amp;: SSize @4 :|: SNil) g</span><span>
</span><span id="line-165"></span><span class="hs-comment">--         &gt;&gt;&gt; (tensor2, g'') &lt;- sRandn' (SShape $ SName @&quot;batch&quot; :&amp;: SSize @10 :|: SName @&quot;*&quot; :&amp;: SSize @4 :|: SName @&quot;*&quot; :&amp;: SSize @7 :|: SNil) g'</span><span>
</span><span id="line-166"></span><span class="hs-comment">--         &gt;&gt;&gt; result = tensor1 `matmul` tensor2</span><span>
</span><span id="line-167"></span><span class="hs-comment">--         &gt;&gt;&gt; :type result</span><span>
</span><span id="line-168"></span><span class="hs-comment">--         result</span><span>
</span><span id="line-169"></span><span class="hs-comment">--           :: MonadThrow m =&gt;</span><span>
</span><span id="line-170"></span><span class="hs-comment">--              m (Tensor</span><span>
</span><span id="line-171"></span><span class="hs-comment">--                   ('Gradient 'WithGradient)</span><span>
</span><span id="line-172"></span><span class="hs-comment">--                   ('Layout 'Dense)</span><span>
</span><span id="line-173"></span><span class="hs-comment">--                   ('Device 'CPU)</span><span>
</span><span id="line-174"></span><span class="hs-comment">--                   ('DataType 'Float)</span><span>
</span><span id="line-175"></span><span class="hs-comment">--                   ('Shape</span><span>
</span><span id="line-176"></span><span class="hs-comment">--                      '[ 'Dim ('Name &quot;batch&quot;) ('Size 10), 'Dim ('Name &quot;*&quot;) ('Size 7)]))</span><span>
</span><span id="line-177"></span><span class="hs-comment">--</span><span>
</span><span id="line-178"></span><span class="hs-comment">--</span><span>
</span><span id="line-179"></span><span class="hs-comment">--     If the second argument is 1-dimensional,</span><span>
</span><span id="line-180"></span><span class="hs-comment">--     a 1 is appended to its dimension for the purpose of the batched matrix multiply and removed after:</span><span>
</span><span id="line-181"></span><span class="hs-comment">--</span><span>
</span><span id="line-182"></span><span class="hs-comment">--         &gt;&gt;&gt; (tensor1, g') &lt;- sRandn' (SShape $ SName @&quot;batch&quot; :&amp;: SSize @10 :|: SName @&quot;*&quot; :&amp;: SSize @3 :|: SName @&quot;*&quot; :&amp;: SSize @4 :|: SNil) g</span><span>
</span><span id="line-183"></span><span class="hs-comment">--         &gt;&gt;&gt; (tensor2, g'') &lt;- sRandn' (SShape $ SName @&quot;*&quot; :&amp;: SSize @4 :|: SNil) g'</span><span>
</span><span id="line-184"></span><span class="hs-comment">--         &gt;&gt;&gt; result = tensor1 `matmul` tensor2</span><span>
</span><span id="line-185"></span><span class="hs-comment">--         &gt;&gt;&gt; :type result</span><span>
</span><span id="line-186"></span><span class="hs-comment">--         result</span><span>
</span><span id="line-187"></span><span class="hs-comment">--           :: MonadThrow m =&gt;</span><span>
</span><span id="line-188"></span><span class="hs-comment">--              m (Tensor</span><span>
</span><span id="line-189"></span><span class="hs-comment">--                   ('Gradient 'WithGradient)</span><span>
</span><span id="line-190"></span><span class="hs-comment">--                   ('Layout 'Dense)</span><span>
</span><span id="line-191"></span><span class="hs-comment">--                   ('Device 'CPU)</span><span>
</span><span id="line-192"></span><span class="hs-comment">--                   ('DataType 'Float)</span><span>
</span><span id="line-193"></span><span class="hs-comment">--                   ('Shape</span><span>
</span><span id="line-194"></span><span class="hs-comment">--                      '[ 'Dim ('Name &quot;batch&quot;) ('Size 10), 'Dim ('Name &quot;*&quot;) ('Size 3)]))</span><span>
</span><span id="line-195"></span><span class="hs-comment">--</span><span>
</span><span id="line-196"></span><span class="hs-comment">--</span><span>
</span><span id="line-197"></span><span class="hs-comment">--     The non-matrix (i.e. batch) dimensions are broadcasted (and thus must be broadcastable).</span><span>
</span><span id="line-198"></span><span class="hs-comment">--     For example, if 'input' is a \(j \times 1 \times n \times m\) tensor and</span><span>
</span><span id="line-199"></span><span class="hs-comment">--     'other' is a \(k \times m \times p\) tensor, 'output' will be a \(j \times k \times n \times p\) tensor:</span><span>
</span><span id="line-200"></span><span class="hs-comment">--</span><span>
</span><span id="line-201"></span><span class="hs-comment">--         &gt;&gt;&gt; (tensor1, g') &lt;- sRandn' (SShape $ SName @&quot;batch&quot; :&amp;: SSize @10 :|: SName @&quot;*&quot; :&amp;: SSize @1 :|: SName @&quot;*&quot; :&amp;: SSize @3 :|: SName @&quot;*&quot; :&amp;: SSize @4 :|: SNil) g</span><span>
</span><span id="line-202"></span><span class="hs-comment">--         &gt;&gt;&gt; (tensor2, g'') &lt;- sRandn' (SShape $ SName @&quot;*&quot; :&amp;: SSize @5 :|: SName @&quot;*&quot; :&amp;: SSize @4 :|: SName @&quot;*&quot; :&amp;: SSize @7 :|: SNil) g'</span><span>
</span><span id="line-203"></span><span class="hs-comment">--         &gt;&gt;&gt; result = tensor1 `matmul` tensor2</span><span>
</span><span id="line-204"></span><span class="hs-comment">--         &gt;&gt;&gt; :type result</span><span>
</span><span id="line-205"></span><span class="hs-comment">--         result</span><span>
</span><span id="line-206"></span><span class="hs-comment">--           :: MonadThrow m =&gt;</span><span>
</span><span id="line-207"></span><span class="hs-comment">--              m (Tensor</span><span>
</span><span id="line-208"></span><span class="hs-comment">--                   ('Gradient 'WithGradient)</span><span>
</span><span id="line-209"></span><span class="hs-comment">--                   ('Layout 'Dense)</span><span>
</span><span id="line-210"></span><span class="hs-comment">--                   ('Device 'CPU)</span><span>
</span><span id="line-211"></span><span class="hs-comment">--                   ('DataType 'Float)</span><span>
</span><span id="line-212"></span><span class="hs-comment">--                   ('Shape</span><span>
</span><span id="line-213"></span><span class="hs-comment">--                      '[ 'Dim ('Name &quot;batch&quot;) ('Size 10), 'Dim ('Name &quot;*&quot;) ('Size 5),</span><span>
</span><span id="line-214"></span><span class="hs-comment">--                         'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7)]))</span><span>
</span><span id="line-215"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.BlasLapack.html#matmul"><span class="hs-identifier hs-type">matmul</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-216"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679687671"><span class="annot"><a href="#local-6989586621679687671"><span class="hs-identifier hs-type">m</span></a></span></span><span> </span><span id="local-6989586621679687670"><span class="annot"><a href="#local-6989586621679687670"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679687669"><span class="annot"><a href="#local-6989586621679687669"><span class="hs-identifier hs-type">gradient'</span></a></span></span><span> </span><span id="local-6989586621679687668"><span class="annot"><a href="#local-6989586621679687668"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679687667"><span class="annot"><a href="#local-6989586621679687667"><span class="hs-identifier hs-type">layout'</span></a></span></span><span> </span><span id="local-6989586621679687666"><span class="annot"><a href="#local-6989586621679687666"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679687665"><span class="annot"><a href="#local-6989586621679687665"><span class="hs-identifier hs-type">device'</span></a></span></span><span> </span><span id="local-6989586621679687664"><span class="annot"><a href="#local-6989586621679687664"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679687663"><span class="annot"><a href="#local-6989586621679687663"><span class="hs-identifier hs-type">dataType'</span></a></span></span><span> </span><span id="local-6989586621679687662"><span class="annot"><a href="#local-6989586621679687662"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679687661"><span class="annot"><a href="#local-6989586621679687661"><span class="hs-identifier hs-type">shape'</span></a></span></span><span> </span><span id="local-6989586621679687660"><span class="annot"><a href="#local-6989586621679687660"><span class="hs-identifier hs-type">shape''</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-217"></span><span>  </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">MonadThrow</span></span><span> </span><span class="annot"><a href="#local-6989586621679687671"><span class="hs-identifier hs-type">m</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679687660"><span class="hs-identifier hs-type">shape''</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.BlasLapack.html#MatmulF"><span class="hs-identifier hs-type">MatmulF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679687662"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679687661"><span class="hs-identifier hs-type">shape'</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Catch"><span class="hs-identifier hs-type">Catch</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679687660"><span class="hs-identifier hs-type">shape''</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-218"></span><span>  </span><span class="hs-comment">-- input</span><span>
</span><span id="line-219"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679687670"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679687668"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679687666"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679687664"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679687662"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-220"></span><span>  </span><span class="hs-comment">-- other</span><span>
</span><span id="line-221"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679687669"><span class="hs-identifier hs-type">gradient'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679687667"><span class="hs-identifier hs-type">layout'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679687665"><span class="hs-identifier hs-type">device'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679687663"><span class="hs-identifier hs-type">dataType'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679687661"><span class="hs-identifier hs-type">shape'</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-222"></span><span>  </span><span class="hs-comment">-- output</span><span>
</span><span id="line-223"></span><span>  </span><span class="annot"><a href="#local-6989586621679687671"><span class="hs-identifier hs-type">m</span></a></span><span>
</span><span id="line-224"></span><span>    </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-225"></span><span>        </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679687670"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679687669"><span class="hs-identifier hs-type">gradient'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-226"></span><span>        </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679687668"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679687667"><span class="hs-identifier hs-type">layout'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-227"></span><span>        </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679687666"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679687665"><span class="hs-identifier hs-type">device'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-228"></span><span>        </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679687664"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679687663"><span class="hs-identifier hs-type">dataType'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-229"></span><span>        </span><span class="annot"><a href="#local-6989586621679687660"><span class="hs-identifier hs-type">shape''</span></a></span><span>
</span><span id="line-230"></span><span>    </span><span class="hs-special">)</span><span>
</span><span id="line-231"></span><span id="local-6989586621679687659"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679687659"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span id="matmul"><span class="annot"><span class="annottext">matmul :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; m (Tensor
        (gradient &lt;|&gt; gradient')
        (layout &lt;+&gt; layout')
        (device &lt;+&gt; device')
        (dataType &lt;+&gt; dataType')
        shape'')
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.BlasLapack.html#matmul"><span class="hs-operator hs-var hs-var">`matmul`</span></a></span></span><span> </span><span id="local-6989586621679687658"><span class="annot"><span class="annottext">Tensor gradient' layout' device' dataType' shape'
</span><a href="#local-6989586621679687658"><span class="hs-identifier hs-var">other</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO
  (Tensor
     (Or (Gradient RequiresGradient) gradient gradient')
     (Unify (Layout LayoutType) layout layout')
     (Unify (Device (DeviceType Nat)) device device')
     (Unify (DataType DType) dataType dataType')
     shape'')
-&gt; m (Tensor
        (Or (Gradient RequiresGradient) gradient gradient')
        (Unify (Layout LayoutType) layout layout')
        (Unify (Device (DeviceType Nat)) device device')
        (Unify (DataType DType) dataType dataType')
        shape'')
forall a (m :: * -&gt; *). MonadThrow m =&gt; IO a -&gt; m a
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">unsafeThrowableIO</span></a></span><span> </span><span class="annot"><span class="annottext">(IO
   (Tensor
      (Or (Gradient RequiresGradient) gradient gradient')
      (Unify (Layout LayoutType) layout layout')
      (Unify (Device (DeviceType Nat)) device device')
      (Unify (DataType DType) dataType dataType')
      shape'')
 -&gt; m (Tensor
         (Or (Gradient RequiresGradient) gradient gradient')
         (Unify (Layout LayoutType) layout layout')
         (Unify (Device (DeviceType Nat)) device device')
         (Unify (DataType DType) dataType dataType')
         shape''))
-&gt; IO
     (Tensor
        (Or (Gradient RequiresGradient) gradient gradient')
        (Unify (Layout LayoutType) layout layout')
        (Unify (Device (DeviceType Nat)) device device')
        (Unify (DataType DType) dataType dataType')
        shape'')
-&gt; m (Tensor
        (Or (Gradient RequiresGradient) gradient gradient')
        (Unify (Layout LayoutType) layout layout')
        (Unify (Device (DeviceType Nat)) device device')
        (Unify (DataType DType) dataType dataType')
        shape'')
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; IO
     (Tensor
        (Or (Gradient RequiresGradient) gradient gradient')
        (Unify (Layout LayoutType) layout layout')
        (Unify (Device (DeviceType Nat)) device device')
        (Unify (DataType DType) dataType dataType')
        shape'')
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.matmul_tt</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679687659"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient' layout' device' dataType' shape'
</span><a href="#local-6989586621679687658"><span class="hs-identifier hs-var">other</span></a></span><span>
</span><span id="line-232"></span></pre></body></html>