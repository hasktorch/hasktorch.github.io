<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><link rel="stylesheet" type="text/css" href="style.css" /><script type="text/javascript" src="highlight.js"></script></head><body><pre><span class="hs-pragma">{-# LANGUAGE ConstraintKinds #-}</span><span>
</span><span id="line-2"></span><span class="hs-pragma">{-# LANGUAGE DataKinds #-}</span><span>
</span><span id="line-3"></span><span class="hs-pragma">{-# LANGUAGE FlexibleContexts #-}</span><span>
</span><span id="line-4"></span><span class="hs-pragma">{-# LANGUAGE FlexibleInstances #-}</span><span>
</span><span id="line-5"></span><span class="hs-pragma">{-# LANGUAGE GADTs #-}</span><span>
</span><span id="line-6"></span><span class="hs-pragma">{-# LANGUAGE MultiParamTypeClasses #-}</span><span>
</span><span id="line-7"></span><span class="hs-pragma">{-# LANGUAGE PatternSynonyms #-}</span><span>
</span><span id="line-8"></span><span class="hs-pragma">{-# LANGUAGE RecordWildCards #-}</span><span>
</span><span id="line-9"></span><span class="hs-pragma">{-# LANGUAGE ScopedTypeVariables #-}</span><span>
</span><span id="line-10"></span><span class="hs-pragma">{-# LANGUAGE TypeApplications #-}</span><span>
</span><span id="line-11"></span><span class="hs-pragma">{-# LANGUAGE TypeFamilies #-}</span><span>
</span><span id="line-12"></span><span class="hs-pragma">{-# LANGUAGE TypeOperators #-}</span><span>
</span><span id="line-13"></span><span class="hs-pragma">{-# LANGUAGE UndecidableInstances #-}</span><span>
</span><span id="line-14"></span><span class="hs-pragma">{-# OPTIONS_GHC -fplugin TypeLevel.Rewrite
                -fplugin-opt=TypeLevel.Rewrite:Torch.GraduallyTyped.Unify.UnifyRightAssociativeL
                -fplugin-opt=TypeLevel.Rewrite:Torch.GraduallyTyped.Unify.OrRightAssociativeL #-}</span><span>
</span><span id="line-17"></span><span class="hs-pragma">{-# OPTIONS_GHC -v2 -Wall #-}</span><span>
</span><span id="line-18"></span><span>
</span><span id="line-19"></span><span class="hs-keyword">module</span><span> </span><span class="hs-identifier">Torch.GraduallyTyped.NN.Transformer.Decoder</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-20"></span><span>
</span><span id="line-21"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier">Control.Monad.Indexed</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier">IxPointed</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier">ireturn</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator">(&gt;&gt;&gt;=)</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-22"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier">Control.Monad.Indexed.State</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier">IxState</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier">IxStateT</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-23"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier">Control.Monad.Indexed.Trans</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier">IxMonadTrans</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier">ilift</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-24"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier">Data.Functor.Indexed</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator">(&lt;&lt;$&gt;&gt;)</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator">(&lt;&lt;*&gt;&gt;)</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-25"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">Data.Kind</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier">Type</span></span><span class="hs-special">)</span><span>
</span><span id="line-26"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">Data.Singletons</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">SingI</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">sing</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-27"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">Data.Singletons.Prelude.List</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">SList</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">SNil</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-28"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">GHC.TypeLits</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier">KnownNat</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier">Nat</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier">Symbol</span></span><span class="hs-special">)</span><span>
</span><span id="line-29"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html"><span class="hs-identifier">Torch.GraduallyTyped.DType</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier">DType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier">DataType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#SDType"><span class="hs-identifier">SDType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier">SDataType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-30"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html"><span class="hs-identifier">Torch.GraduallyTyped.Device</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier">Device</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#DeviceType"><span class="hs-identifier">DeviceType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#SDevice"><span class="hs-identifier">SDevice</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#SDeviceType"><span class="hs-identifier">SDeviceType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-31"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html"><span class="hs-identifier">Torch.GraduallyTyped.Layout</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier">Layout</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#LayoutType"><span class="hs-identifier">LayoutType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#SLayout"><span class="hs-identifier">SLayout</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#SLayoutType"><span class="hs-identifier">SLayoutType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-32"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html"><span class="hs-identifier">Torch.GraduallyTyped.NN.Class</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier">HasForward</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier">HasInitialize</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasStateDict"><span class="hs-identifier">HasStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-33"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Dropout.html"><span class="hs-identifier">Torch.GraduallyTyped.NN.Dropout</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Dropout.html#Dropout"><span class="hs-identifier">Dropout</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-34"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Functional.Sparse.html"><span class="hs-identifier">Torch.GraduallyTyped.NN.Functional.Sparse</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Functional.Sparse.html#EmbeddingF"><span class="hs-identifier">EmbeddingF</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-35"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Normalization.html"><span class="hs-identifier">Torch.GraduallyTyped.NN.Normalization</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Normalization.html#LayerNorm"><span class="hs-identifier">LayerNorm</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-36"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Sparse.html"><span class="hs-identifier">Torch.GraduallyTyped.NN.Sparse</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Sparse.html#Embedding"><span class="hs-identifier">Embedding</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-37"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.DecoderStack.html"><span class="hs-identifier">Torch.GraduallyTyped.NN.Transformer.DecoderStack</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.DecoderStack.html#TransformerDecoderStack"><span class="hs-identifier">TransformerDecoderStack</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-38"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html"><span class="hs-identifier">Torch.GraduallyTyped.NN.Transformer.Type</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#STransformerStyle"><span class="hs-identifier">STransformerStyle</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerStyle"><span class="hs-identifier">TransformerStyle</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-39"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Type.html"><span class="hs-identifier">Torch.GraduallyTyped.NN.Type</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Type.html#HasBias"><span class="hs-identifier">HasBias</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-40"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html"><span class="hs-identifier">Torch.GraduallyTyped.Prelude</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Seq"><span class="hs-identifier">Seq</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-41"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Random.html"><span class="hs-identifier">Torch.GraduallyTyped.Random</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Random.html#sMkGenerator"><span class="hs-identifier">sMkGenerator</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-42"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html"><span class="hs-identifier">Torch.GraduallyTyped.RequiresGradient</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier">Gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#RequiresGradient"><span class="hs-identifier">RequiresGradient</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier">SGradient</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#SRequiresGradient"><span class="hs-identifier">SRequiresGradient</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-43"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.html"><span class="hs-identifier">Torch.GraduallyTyped.Shape</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier">Name</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier">SDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier">SName</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier">SShape</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier">SSize</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier">Shape</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier">Size</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-44"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html"><span class="hs-identifier">Torch.GraduallyTyped.Shape.Class</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#BroadcastShapesF"><span class="hs-identifier">BroadcastShapesF</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-45"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html"><span class="hs-identifier">Torch.GraduallyTyped.Shape.Type</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#By"><span class="hs-identifier">By</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="hs-keyword">pattern</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator">(:&amp;:)</span></a></span><span class="hs-special">,</span><span> </span><span class="hs-keyword">pattern</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator">(:|:)</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-46"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Creation.html"><span class="hs-identifier">Torch.GraduallyTyped.Tensor.Creation</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Creation.html#sOnes"><span class="hs-identifier">sOnes</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-47"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html"><span class="hs-identifier">Torch.GraduallyTyped.Tensor.IndexingSlicingJoining</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#TransposeF"><span class="hs-identifier">TransposeF</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#UnsqueezeF"><span class="hs-identifier">UnsqueezeF</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#transpose"><span class="hs-identifier">transpose</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#unsqueeze"><span class="hs-identifier">unsqueeze</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-48"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html"><span class="hs-identifier">Torch.GraduallyTyped.Tensor.MathOperations.Pointwise</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#add"><span class="hs-identifier">add</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-49"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html"><span class="hs-identifier">Torch.GraduallyTyped.Tensor.Type</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier">Tensor</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-50"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html"><span class="hs-identifier">Torch.GraduallyTyped.Unify</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-keyword">type</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator">(&lt;+&gt;)</span></a></span><span class="hs-special">,</span><span> </span><span class="hs-keyword">type</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator">(&lt;|&gt;)</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-51"></span><span>
</span><span id="line-52"></span><span class="hs-comment">-- | Generic transformer decoder.</span><span>
</span><span id="line-53"></span><span class="hs-comment">-- Needs to be specialized to a given transformer type, e.g. 'T5'.</span><span>
</span><span id="line-54"></span><span class="hs-comment">-- See 'TransformerDecoder'.</span><span>
</span><span id="line-55"></span><span class="hs-keyword">data</span><span>
</span><span id="line-56"></span><span>  </span><span id="GTransformerDecoder"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#GTransformerDecoder"><span class="hs-identifier hs-var">GTransformerDecoder</span></a></span></span><span>
</span><span id="line-57"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679775906"><span class="annot"><a href="#local-6989586621679775906"><span class="hs-identifier hs-type">stack</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span class="hs-special">)</span><span>
</span><span id="line-58"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679775905"><span class="annot"><a href="#local-6989586621679775905"><span class="hs-identifier hs-type">embedLayerNorm</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span class="hs-special">)</span><span>
</span><span id="line-59"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679775904"><span class="annot"><a href="#local-6989586621679775904"><span class="hs-identifier hs-type">layerNorm</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span class="hs-special">)</span><span>
</span><span id="line-60"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679775903"><span class="annot"><a href="#local-6989586621679775903"><span class="hs-identifier hs-type">dropout</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span class="hs-special">)</span><span>
</span><span id="line-61"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679775902"><span class="annot"><a href="#local-6989586621679775902"><span class="hs-identifier hs-type">posEnc</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span class="hs-special">)</span><span>
</span><span id="line-62"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-63"></span><span>  </span><span id="GTransformerDecoder"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#GTransformerDecoder"><span class="hs-identifier hs-var">GTransformerDecoder</span></a></span></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-64"></span><span>    </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679776264"><span class="annot"><a href="#local-6989586621679776264"><span class="hs-identifier hs-type">stack</span></a></span></span><span> </span><span id="local-6989586621679776263"><span class="annot"><a href="#local-6989586621679776263"><span class="hs-identifier hs-type">embedLayerNorm</span></a></span></span><span> </span><span id="local-6989586621679776262"><span class="annot"><a href="#local-6989586621679776262"><span class="hs-identifier hs-type">layerNorm</span></a></span></span><span> </span><span id="local-6989586621679776261"><span class="annot"><a href="#local-6989586621679776261"><span class="hs-identifier hs-type">dropout</span></a></span></span><span> </span><span id="local-6989586621679776260"><span class="annot"><a href="#local-6989586621679776260"><span class="hs-identifier hs-type">posEnc</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-65"></span><span>    </span><span class="hs-special">{</span><span> </span><span class="hs-comment">-- | decoder layer stack</span><span>
</span><span id="line-66"></span><span>      </span><span id="tdStack"><span class="annot"><span class="annottext">GTransformerDecoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; stack
</span><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#tdStack"><span class="hs-identifier hs-var hs-var">tdStack</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679776264"><span class="hs-identifier hs-type">stack</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-67"></span><span>      </span><span class="hs-comment">-- | decoder embedding layer norm</span><span>
</span><span id="line-68"></span><span>      </span><span id="tdEmbedLayerNorm"><span class="annot"><span class="annottext">GTransformerDecoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; embedLayerNorm
</span><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#tdEmbedLayerNorm"><span class="hs-identifier hs-var hs-var">tdEmbedLayerNorm</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679776263"><span class="hs-identifier hs-type">embedLayerNorm</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-69"></span><span>      </span><span class="hs-comment">-- | decoder layer norm</span><span>
</span><span id="line-70"></span><span>      </span><span id="tdLayerNorm"><span class="annot"><span class="annottext">GTransformerDecoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; layerNorm
</span><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#tdLayerNorm"><span class="hs-identifier hs-var hs-var">tdLayerNorm</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679776262"><span class="hs-identifier hs-type">layerNorm</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-71"></span><span>      </span><span class="hs-comment">-- | decoder dropout</span><span>
</span><span id="line-72"></span><span>      </span><span id="tdDropout"><span class="annot"><span class="annottext">GTransformerDecoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; dropout
</span><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#tdDropout"><span class="hs-identifier hs-var hs-var">tdDropout</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679776261"><span class="hs-identifier hs-type">dropout</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-73"></span><span>      </span><span class="hs-comment">-- | positional encoding</span><span>
</span><span id="line-74"></span><span>      </span><span id="tdPosEnc"><span class="annot"><span class="annottext">GTransformerDecoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; posEnc
</span><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#tdPosEnc"><span class="hs-identifier hs-var hs-var">tdPosEnc</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679776260"><span class="hs-identifier hs-type">posEnc</span></a></span><span>
</span><span id="line-75"></span><span>    </span><span class="hs-special">}</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-76"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#GTransformerDecoder"><span class="hs-identifier hs-type">GTransformerDecoder</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679776264"><span class="hs-identifier hs-type">stack</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679776263"><span class="hs-identifier hs-type">embedLayerNorm</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679776262"><span class="hs-identifier hs-type">layerNorm</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679776261"><span class="hs-identifier hs-type">dropout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679776260"><span class="hs-identifier hs-type">posEnc</span></a></span><span>
</span><span id="line-77"></span><span>
</span><span id="line-78"></span><span class="hs-comment">-- | Transformer decoder.</span><span>
</span><span id="line-79"></span><span class="hs-keyword">newtype</span><span>
</span><span id="line-80"></span><span>  </span><span id="TransformerDecoder"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TransformerDecoder"><span class="hs-identifier hs-var">TransformerDecoder</span></a></span></span><span>
</span><span id="line-81"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679775895"><span class="annot"><a href="#local-6989586621679775895"><span class="hs-identifier hs-type">style</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerStyle"><span class="hs-identifier hs-type">TransformerStyle</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-82"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679775894"><span class="annot"><a href="#local-6989586621679775894"><span class="hs-identifier hs-type">numLayers</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span>
</span><span id="line-83"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679775893"><span class="annot"><a href="#local-6989586621679775893"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#RequiresGradient"><span class="hs-identifier hs-type">RequiresGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-84"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679775892"><span class="annot"><a href="#local-6989586621679775892"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier hs-type">Device</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#DeviceType"><span class="hs-identifier hs-type">DeviceType</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-85"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679775891"><span class="annot"><a href="#local-6989586621679775891"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier hs-type">DType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-86"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679775890"><span class="annot"><a href="#local-6989586621679775890"><span class="hs-identifier hs-type">headDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-87"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679775889"><span class="annot"><a href="#local-6989586621679775889"><span class="hs-identifier hs-type">headEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-88"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679775888"><span class="annot"><a href="#local-6989586621679775888"><span class="hs-identifier hs-type">embedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-89"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679775887"><span class="annot"><a href="#local-6989586621679775887"><span class="hs-identifier hs-type">decoderInputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-90"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679775886"><span class="annot"><a href="#local-6989586621679775886"><span class="hs-identifier hs-type">encoderOutputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-91"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679775885"><span class="annot"><a href="#local-6989586621679775885"><span class="hs-identifier hs-type">ffnDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-92"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679775884"><span class="annot"><a href="#local-6989586621679775884"><span class="hs-identifier hs-type">posEncDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-93"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679775883"><span class="annot"><a href="#local-6989586621679775883"><span class="hs-identifier hs-type">dropoutP</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span class="hs-special">)</span><span>
</span><span id="line-94"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-95"></span><span>  </span><span id="TransformerDecoder"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TransformerDecoder"><span class="hs-identifier hs-var">TransformerDecoder</span></a></span></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-96"></span><span>    </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679776230"><span class="annot"><a href="#local-6989586621679776230"><span class="hs-identifier hs-type">style</span></a></span></span><span> </span><span id="local-6989586621679776229"><span class="annot"><a href="#local-6989586621679776229"><span class="hs-identifier hs-type">numLayers</span></a></span></span><span> </span><span id="local-6989586621679776228"><span class="annot"><a href="#local-6989586621679776228"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679776227"><span class="annot"><a href="#local-6989586621679776227"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679776226"><span class="annot"><a href="#local-6989586621679776226"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679776225"><span class="annot"><a href="#local-6989586621679776225"><span class="hs-identifier hs-type">headDim</span></a></span></span><span> </span><span id="local-6989586621679776224"><span class="annot"><a href="#local-6989586621679776224"><span class="hs-identifier hs-type">headEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679776223"><span class="annot"><a href="#local-6989586621679776223"><span class="hs-identifier hs-type">embedDim</span></a></span></span><span> </span><span id="local-6989586621679776222"><span class="annot"><a href="#local-6989586621679776222"><span class="hs-identifier hs-type">decoderInputEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679776221"><span class="annot"><a href="#local-6989586621679776221"><span class="hs-identifier hs-type">encoderOutputEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679776220"><span class="annot"><a href="#local-6989586621679776220"><span class="hs-identifier hs-type">ffnDim</span></a></span></span><span> </span><span id="local-6989586621679776218"><span class="annot"><a href="#local-6989586621679776218"><span class="hs-identifier hs-type">posEncDim</span></a></span></span><span> </span><span id="local-6989586621679776219"><span class="annot"><a href="#local-6989586621679776219"><span class="hs-identifier hs-type">dropoutP</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-97"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#GTransformerDecoder"><span class="hs-identifier hs-type">GTransformerDecoder</span></a></span><span>
</span><span id="line-98"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TDStackF"><span class="hs-identifier hs-type">TDStackF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679776230"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679776229"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679776228"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679776227"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679776226"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679776225"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679776224"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679776223"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679776222"><span class="hs-identifier hs-type">decoderInputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679776221"><span class="hs-identifier hs-type">encoderOutputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679776220"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679776219"><span class="hs-identifier hs-type">dropoutP</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-99"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TDEmbedLayerNormF"><span class="hs-identifier hs-type">TDEmbedLayerNormF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679776230"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679776228"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679776227"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679776226"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679776222"><span class="hs-identifier hs-type">decoderInputEmbedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-100"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TDLayerNormF"><span class="hs-identifier hs-type">TDLayerNormF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679776230"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679776228"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679776227"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679776226"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679776222"><span class="hs-identifier hs-type">decoderInputEmbedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-101"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TDDropoutF"><span class="hs-identifier hs-type">TDDropoutF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679776230"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679776219"><span class="hs-identifier hs-type">dropoutP</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-102"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TDPosEncF"><span class="hs-identifier hs-type">TDPosEncF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679776230"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679776228"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679776227"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679776226"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679776225"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679776222"><span class="hs-identifier hs-type">decoderInputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679776218"><span class="hs-identifier hs-type">posEncDim</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-103"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TransformerDecoder"><span class="hs-identifier hs-type">TransformerDecoder</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679776230"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679776229"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679776228"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679776227"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679776226"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679776225"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679776224"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679776223"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679776222"><span class="hs-identifier hs-type">decoderInputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679776221"><span class="hs-identifier hs-type">encoderOutputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679776220"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679776218"><span class="hs-identifier hs-type">posEncDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679776219"><span class="hs-identifier hs-type">dropoutP</span></a></span><span>
</span><span id="line-104"></span><span>
</span><span id="line-105"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span>
</span><span id="line-106"></span><span>  </span><span id="TDStackF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TDStackF"><span class="hs-identifier hs-var">TDStackF</span></a></span></span><span>
</span><span id="line-107"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679775881"><span class="annot"><a href="#local-6989586621679775881"><span class="hs-identifier hs-type">style</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerStyle"><span class="hs-identifier hs-type">TransformerStyle</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-108"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679775880"><span class="annot"><a href="#local-6989586621679775880"><span class="hs-identifier hs-type">numLayers</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span>
</span><span id="line-109"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679775879"><span class="annot"><a href="#local-6989586621679775879"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#RequiresGradient"><span class="hs-identifier hs-type">RequiresGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-110"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679775878"><span class="annot"><a href="#local-6989586621679775878"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier hs-type">Device</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#DeviceType"><span class="hs-identifier hs-type">DeviceType</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-111"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679775877"><span class="annot"><a href="#local-6989586621679775877"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier hs-type">DType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-112"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679775876"><span class="annot"><a href="#local-6989586621679775876"><span class="hs-identifier hs-type">headDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-113"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679775875"><span class="annot"><a href="#local-6989586621679775875"><span class="hs-identifier hs-type">headEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-114"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679775874"><span class="annot"><a href="#local-6989586621679775874"><span class="hs-identifier hs-type">embedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-115"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679775873"><span class="annot"><a href="#local-6989586621679775873"><span class="hs-identifier hs-type">decoderInputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-116"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679775872"><span class="annot"><a href="#local-6989586621679775872"><span class="hs-identifier hs-type">encoderOutputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-117"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679775871"><span class="annot"><a href="#local-6989586621679775871"><span class="hs-identifier hs-type">ffnDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-118"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679775870"><span class="annot"><a href="#local-6989586621679775870"><span class="hs-identifier hs-type">dropoutP</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-119"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span>
</span><span id="line-120"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-121"></span><span>  </span><span id="TDStackF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TDStackF"><span class="hs-identifier hs-var">TDStackF</span></a></span></span><span> </span><span id="local-6989586621679775869"><span class="annot"><a href="#local-6989586621679775869"><span class="hs-identifier hs-type hs-type">style</span></a></span></span><span> </span><span id="local-6989586621679775868"><span class="annot"><a href="#local-6989586621679775868"><span class="hs-identifier hs-type hs-type">numLayers</span></a></span></span><span> </span><span id="local-6989586621679775867"><span class="annot"><a href="#local-6989586621679775867"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679775866"><span class="annot"><a href="#local-6989586621679775866"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679775865"><span class="annot"><a href="#local-6989586621679775865"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679775864"><span class="annot"><a href="#local-6989586621679775864"><span class="hs-identifier hs-type hs-type">headDim</span></a></span></span><span> </span><span id="local-6989586621679775863"><span class="annot"><a href="#local-6989586621679775863"><span class="hs-identifier hs-type hs-type">headEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679775862"><span class="annot"><a href="#local-6989586621679775862"><span class="hs-identifier hs-type hs-type">embedDim</span></a></span></span><span> </span><span id="local-6989586621679775861"><span class="annot"><a href="#local-6989586621679775861"><span class="hs-identifier hs-type hs-type">decoderInputEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679775860"><span class="annot"><a href="#local-6989586621679775860"><span class="hs-identifier hs-type hs-type">encoderOutputEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679775859"><span class="annot"><a href="#local-6989586621679775859"><span class="hs-identifier hs-type hs-type">ffnDim</span></a></span></span><span> </span><span id="local-6989586621679775858"><span class="annot"><a href="#local-6989586621679775858"><span class="hs-identifier hs-type hs-type">dropoutP</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-122"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.DecoderStack.html#TransformerDecoderStack"><span class="hs-identifier hs-type">TransformerDecoderStack</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775869"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775868"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775867"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775866"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775865"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775864"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775863"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775862"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775861"><span class="hs-identifier hs-type">decoderInputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775860"><span class="hs-identifier hs-type">encoderOutputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775859"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775858"><span class="hs-identifier hs-type">dropoutP</span></a></span><span>
</span><span id="line-123"></span><span>
</span><span id="line-124"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span>
</span><span id="line-125"></span><span>  </span><span id="TDEmbedLayerNormF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TDEmbedLayerNormF"><span class="hs-identifier hs-var">TDEmbedLayerNormF</span></a></span></span><span>
</span><span id="line-126"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679775857"><span class="annot"><a href="#local-6989586621679775857"><span class="hs-identifier hs-type">style</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerStyle"><span class="hs-identifier hs-type">TransformerStyle</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-127"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679775856"><span class="annot"><a href="#local-6989586621679775856"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#RequiresGradient"><span class="hs-identifier hs-type">RequiresGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-128"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679775855"><span class="annot"><a href="#local-6989586621679775855"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier hs-type">Device</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#DeviceType"><span class="hs-identifier hs-type">DeviceType</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-129"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679775854"><span class="annot"><a href="#local-6989586621679775854"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier hs-type">DType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-130"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679775853"><span class="annot"><a href="#local-6989586621679775853"><span class="hs-identifier hs-type">decoderInputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-131"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span>
</span><span id="line-132"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-133"></span><span>  </span><span id="TDEmbedLayerNormF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TDEmbedLayerNormF"><span class="hs-identifier hs-var">TDEmbedLayerNormF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#T5"><span class="hs-identifier hs-type">T5</span></a></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-134"></span><span>  </span><span id="TDEmbedLayerNormF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TDEmbedLayerNormF"><span class="hs-identifier hs-var">TDEmbedLayerNormF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ByT5"><span class="hs-identifier hs-type">ByT5</span></a></span><span> </span><span id="local-6989586621679775852"><span class="annot"><a href="#local-6989586621679775852"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679775851"><span class="annot"><a href="#local-6989586621679775851"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679775850"><span class="annot"><a href="#local-6989586621679775850"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679775849"><span class="annot"><a href="#local-6989586621679775849"><span class="hs-identifier hs-type hs-type">decoderInputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TDEmbedLayerNormF"><span class="hs-identifier hs-type">TDEmbedLayerNormF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#T5"><span class="hs-identifier hs-type">T5</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775852"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775851"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775850"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775849"><span class="hs-identifier hs-type">decoderInputEmbedDim</span></a></span><span>
</span><span id="line-135"></span><span>  </span><span id="TDEmbedLayerNormF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TDEmbedLayerNormF"><span class="hs-identifier hs-var">TDEmbedLayerNormF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span> </span><span id="local-6989586621679775848"><span class="annot"><a href="#local-6989586621679775848"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679775847"><span class="annot"><a href="#local-6989586621679775847"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679775846"><span class="annot"><a href="#local-6989586621679775846"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679775845"><span class="annot"><a href="#local-6989586621679775845"><span class="hs-identifier hs-type hs-type">decoderInputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Normalization.html#LayerNorm"><span class="hs-identifier hs-type">LayerNorm</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Type.html#WithBias"><span class="hs-identifier hs-type">WithBias</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775848"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775847"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775846"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679775845"><span class="hs-identifier hs-type">decoderInputEmbedDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-136"></span><span>  </span><span id="TDEmbedLayerNormF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TDEmbedLayerNormF"><span class="hs-identifier hs-var">TDEmbedLayerNormF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MBART"><span class="hs-identifier hs-type">MBART</span></a></span><span> </span><span id="local-6989586621679775844"><span class="annot"><a href="#local-6989586621679775844"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679775843"><span class="annot"><a href="#local-6989586621679775843"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679775842"><span class="annot"><a href="#local-6989586621679775842"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679775841"><span class="annot"><a href="#local-6989586621679775841"><span class="hs-identifier hs-type hs-type">decoderInputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TDEmbedLayerNormF"><span class="hs-identifier hs-type">TDEmbedLayerNormF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775844"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775843"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775842"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775841"><span class="hs-identifier hs-type">decoderInputEmbedDim</span></a></span><span>
</span><span id="line-137"></span><span>  </span><span id="TDEmbedLayerNormF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TDEmbedLayerNormF"><span class="hs-identifier hs-var">TDEmbedLayerNormF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#Pegasus"><span class="hs-identifier hs-type">Pegasus</span></a></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-138"></span><span>
</span><span id="line-139"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span>
</span><span id="line-140"></span><span>  </span><span id="TDLayerNormF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TDLayerNormF"><span class="hs-identifier hs-var">TDLayerNormF</span></a></span></span><span>
</span><span id="line-141"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679775840"><span class="annot"><a href="#local-6989586621679775840"><span class="hs-identifier hs-type">style</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerStyle"><span class="hs-identifier hs-type">TransformerStyle</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-142"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679775839"><span class="annot"><a href="#local-6989586621679775839"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#RequiresGradient"><span class="hs-identifier hs-type">RequiresGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-143"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679775838"><span class="annot"><a href="#local-6989586621679775838"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier hs-type">Device</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#DeviceType"><span class="hs-identifier hs-type">DeviceType</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-144"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679775837"><span class="annot"><a href="#local-6989586621679775837"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier hs-type">DType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-145"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679775836"><span class="annot"><a href="#local-6989586621679775836"><span class="hs-identifier hs-type">decoderInputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-146"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span>
</span><span id="line-147"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-148"></span><span>  </span><span id="TDLayerNormF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TDLayerNormF"><span class="hs-identifier hs-var">TDLayerNormF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#T5"><span class="hs-identifier hs-type">T5</span></a></span><span> </span><span id="local-6989586621679775835"><span class="annot"><a href="#local-6989586621679775835"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679775834"><span class="annot"><a href="#local-6989586621679775834"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679775833"><span class="annot"><a href="#local-6989586621679775833"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679775832"><span class="annot"><a href="#local-6989586621679775832"><span class="hs-identifier hs-type hs-type">decoderInputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Normalization.html#LayerNorm"><span class="hs-identifier hs-type">LayerNorm</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Type.html#WithoutBias"><span class="hs-identifier hs-type">WithoutBias</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775835"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775834"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775833"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679775832"><span class="hs-identifier hs-type">decoderInputEmbedDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-149"></span><span>  </span><span id="TDLayerNormF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TDLayerNormF"><span class="hs-identifier hs-var">TDLayerNormF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ByT5"><span class="hs-identifier hs-type">ByT5</span></a></span><span> </span><span id="local-6989586621679775831"><span class="annot"><a href="#local-6989586621679775831"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679775830"><span class="annot"><a href="#local-6989586621679775830"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679775829"><span class="annot"><a href="#local-6989586621679775829"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679775828"><span class="annot"><a href="#local-6989586621679775828"><span class="hs-identifier hs-type hs-type">decoderInputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TDLayerNormF"><span class="hs-identifier hs-type">TDLayerNormF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#T5"><span class="hs-identifier hs-type">T5</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775831"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775830"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775829"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775828"><span class="hs-identifier hs-type">decoderInputEmbedDim</span></a></span><span>
</span><span id="line-150"></span><span>  </span><span id="TDLayerNormF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TDLayerNormF"><span class="hs-identifier hs-var">TDLayerNormF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-151"></span><span>  </span><span id="TDLayerNormF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TDLayerNormF"><span class="hs-identifier hs-var">TDLayerNormF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MBART"><span class="hs-identifier hs-type">MBART</span></a></span><span> </span><span id="local-6989586621679775827"><span class="annot"><a href="#local-6989586621679775827"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679775826"><span class="annot"><a href="#local-6989586621679775826"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679775825"><span class="annot"><a href="#local-6989586621679775825"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679775824"><span class="annot"><a href="#local-6989586621679775824"><span class="hs-identifier hs-type hs-type">decoderInputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TDLayerNormF"><span class="hs-identifier hs-type">TDLayerNormF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775827"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775826"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775825"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775824"><span class="hs-identifier hs-type">decoderInputEmbedDim</span></a></span><span>
</span><span id="line-152"></span><span>  </span><span id="TDLayerNormF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TDLayerNormF"><span class="hs-identifier hs-var">TDLayerNormF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#Pegasus"><span class="hs-identifier hs-type">Pegasus</span></a></span><span> </span><span id="local-6989586621679775823"><span class="annot"><a href="#local-6989586621679775823"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679775822"><span class="annot"><a href="#local-6989586621679775822"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679775821"><span class="annot"><a href="#local-6989586621679775821"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679775820"><span class="annot"><a href="#local-6989586621679775820"><span class="hs-identifier hs-type hs-type">decoderInputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Normalization.html#LayerNorm"><span class="hs-identifier hs-type">LayerNorm</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Type.html#WithBias"><span class="hs-identifier hs-type">WithBias</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775823"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775822"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775821"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679775820"><span class="hs-identifier hs-type">decoderInputEmbedDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-153"></span><span>
</span><span id="line-154"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span>
</span><span id="line-155"></span><span>  </span><span id="TDDropoutF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TDDropoutF"><span class="hs-identifier hs-var">TDDropoutF</span></a></span></span><span>
</span><span id="line-156"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679775819"><span class="annot"><a href="#local-6989586621679775819"><span class="hs-identifier hs-type">style</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerStyle"><span class="hs-identifier hs-type">TransformerStyle</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-157"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679775818"><span class="annot"><a href="#local-6989586621679775818"><span class="hs-identifier hs-type">dropoutP</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-158"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span>
</span><span id="line-159"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-160"></span><span>  </span><span id="TDDropoutF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TDDropoutF"><span class="hs-identifier hs-var">TDDropoutF</span></a></span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span id="local-6989586621679775817"><span class="annot"><a href="#local-6989586621679775817"><span class="hs-identifier hs-type hs-type">dropoutP</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Dropout.html#Dropout"><span class="hs-identifier hs-type">Dropout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775817"><span class="hs-identifier hs-type">dropoutP</span></a></span><span>
</span><span id="line-161"></span><span>
</span><span id="line-162"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span>
</span><span id="line-163"></span><span>  </span><span id="TDPosEncF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TDPosEncF"><span class="hs-identifier hs-var">TDPosEncF</span></a></span></span><span>
</span><span id="line-164"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679775816"><span class="annot"><a href="#local-6989586621679775816"><span class="hs-identifier hs-type">style</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerStyle"><span class="hs-identifier hs-type">TransformerStyle</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-165"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679775815"><span class="annot"><a href="#local-6989586621679775815"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#RequiresGradient"><span class="hs-identifier hs-type">RequiresGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-166"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679775814"><span class="annot"><a href="#local-6989586621679775814"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier hs-type">Device</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#DeviceType"><span class="hs-identifier hs-type">DeviceType</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-167"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679775813"><span class="annot"><a href="#local-6989586621679775813"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier hs-type">DType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-168"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679775812"><span class="annot"><a href="#local-6989586621679775812"><span class="hs-identifier hs-type">headDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-169"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679775811"><span class="annot"><a href="#local-6989586621679775811"><span class="hs-identifier hs-type">decoderInputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-170"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679775810"><span class="annot"><a href="#local-6989586621679775810"><span class="hs-identifier hs-type">posEncDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-171"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span>
</span><span id="line-172"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-173"></span><span>  </span><span id="TDPosEncF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TDPosEncF"><span class="hs-identifier hs-var">TDPosEncF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#T5"><span class="hs-identifier hs-type">T5</span></a></span><span> </span><span id="local-6989586621679775809"><span class="annot"><a href="#local-6989586621679775809"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679775808"><span class="annot"><a href="#local-6989586621679775808"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679775807"><span class="annot"><a href="#local-6989586621679775807"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679775806"><span class="annot"><a href="#local-6989586621679775806"><span class="hs-identifier hs-type hs-type">headDim</span></a></span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span id="local-6989586621679775805"><span class="annot"><a href="#local-6989586621679775805"><span class="hs-identifier hs-type hs-type">posEncDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Sparse.html#Embedding"><span class="hs-identifier hs-type">Embedding</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775809"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Dense"><span class="hs-identifier hs-type">Dense</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679775808"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775807"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775805"><span class="hs-identifier hs-type">posEncDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775806"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><span class="hs-identifier hs-type">Nothing</span></span><span>
</span><span id="line-174"></span><span>  </span><span id="TDPosEncF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TDPosEncF"><span class="hs-identifier hs-var">TDPosEncF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ByT5"><span class="hs-identifier hs-type">ByT5</span></a></span><span> </span><span id="local-6989586621679775804"><span class="annot"><a href="#local-6989586621679775804"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679775803"><span class="annot"><a href="#local-6989586621679775803"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679775802"><span class="annot"><a href="#local-6989586621679775802"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679775801"><span class="annot"><a href="#local-6989586621679775801"><span class="hs-identifier hs-type hs-type">headDim</span></a></span></span><span> </span><span id="local-6989586621679775800"><span class="annot"><a href="#local-6989586621679775800"><span class="hs-identifier hs-type hs-type">decoderInputEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679775799"><span class="annot"><a href="#local-6989586621679775799"><span class="hs-identifier hs-type hs-type">posEncDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TDPosEncF"><span class="hs-identifier hs-type">TDPosEncF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#T5"><span class="hs-identifier hs-type">T5</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775804"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775803"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775802"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775801"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775800"><span class="hs-identifier hs-type">decoderInputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775799"><span class="hs-identifier hs-type">posEncDim</span></a></span><span>
</span><span id="line-175"></span><span>  </span><span id="TDPosEncF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TDPosEncF"><span class="hs-identifier hs-var">TDPosEncF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span> </span><span id="local-6989586621679775798"><span class="annot"><a href="#local-6989586621679775798"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679775797"><span class="annot"><a href="#local-6989586621679775797"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679775796"><span class="annot"><a href="#local-6989586621679775796"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span id="local-6989586621679775795"><span class="annot"><a href="#local-6989586621679775795"><span class="hs-identifier hs-type hs-type">decoderInputEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679775794"><span class="annot"><a href="#local-6989586621679775794"><span class="hs-identifier hs-type hs-type">posEncDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Sparse.html#Embedding"><span class="hs-identifier hs-type">Embedding</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775798"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Dense"><span class="hs-identifier hs-type">Dense</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679775797"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775796"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775794"><span class="hs-identifier hs-type">posEncDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775795"><span class="hs-identifier hs-type">decoderInputEmbedDim</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><span class="hs-identifier hs-type">Nothing</span></span><span>
</span><span id="line-176"></span><span>  </span><span id="TDPosEncF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TDPosEncF"><span class="hs-identifier hs-var">TDPosEncF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MBART"><span class="hs-identifier hs-type">MBART</span></a></span><span> </span><span id="local-6989586621679775793"><span class="annot"><a href="#local-6989586621679775793"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679775792"><span class="annot"><a href="#local-6989586621679775792"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679775791"><span class="annot"><a href="#local-6989586621679775791"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679775790"><span class="annot"><a href="#local-6989586621679775790"><span class="hs-identifier hs-type hs-type">headDim</span></a></span></span><span> </span><span id="local-6989586621679775789"><span class="annot"><a href="#local-6989586621679775789"><span class="hs-identifier hs-type hs-type">decoderInputEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679775788"><span class="annot"><a href="#local-6989586621679775788"><span class="hs-identifier hs-type hs-type">posEncDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TDPosEncF"><span class="hs-identifier hs-type">TDPosEncF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775793"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775792"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775791"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775790"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775789"><span class="hs-identifier hs-type">decoderInputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775788"><span class="hs-identifier hs-type">posEncDim</span></a></span><span>
</span><span id="line-177"></span><span>  </span><span id="TDPosEncF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TDPosEncF"><span class="hs-identifier hs-var">TDPosEncF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#Pegasus"><span class="hs-identifier hs-type">Pegasus</span></a></span><span> </span><span id="local-6989586621679775787"><span class="annot"><a href="#local-6989586621679775787"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679775786"><span class="annot"><a href="#local-6989586621679775786"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679775785"><span class="annot"><a href="#local-6989586621679775785"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679775784"><span class="annot"><a href="#local-6989586621679775784"><span class="hs-identifier hs-type hs-type">headDim</span></a></span></span><span> </span><span id="local-6989586621679775783"><span class="annot"><a href="#local-6989586621679775783"><span class="hs-identifier hs-type hs-type">decoderInputEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679775782"><span class="annot"><a href="#local-6989586621679775782"><span class="hs-identifier hs-type hs-type">posEncDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TDPosEncF"><span class="hs-identifier hs-type">TDPosEncF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775787"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775786"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775785"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775784"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775783"><span class="hs-identifier hs-type">decoderInputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775782"><span class="hs-identifier hs-type">posEncDim</span></a></span><span>
</span><span id="line-178"></span><span>
</span><span id="line-179"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span>
</span><span id="line-180"></span><span>  </span><span id="HasInitializeTDEmbedLayerNormInputF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#HasInitializeTDEmbedLayerNormInputF"><span class="hs-identifier hs-var">HasInitializeTDEmbedLayerNormInputF</span></a></span></span><span>
</span><span id="line-181"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679775781"><span class="annot"><a href="#local-6989586621679775781"><span class="hs-identifier hs-type">style</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerStyle"><span class="hs-identifier hs-type">TransformerStyle</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-182"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679775780"><span class="annot"><a href="#local-6989586621679775780"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#RequiresGradient"><span class="hs-identifier hs-type">RequiresGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-183"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679775779"><span class="annot"><a href="#local-6989586621679775779"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier hs-type">Device</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#DeviceType"><span class="hs-identifier hs-type">DeviceType</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-184"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679775778"><span class="annot"><a href="#local-6989586621679775778"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier hs-type">DType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-185"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679775777"><span class="annot"><a href="#local-6989586621679775777"><span class="hs-identifier hs-type">decoderInputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-186"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span>
</span><span id="line-187"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-188"></span><span>  </span><span id="HasInitializeTDEmbedLayerNormInputF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#HasInitializeTDEmbedLayerNormInputF"><span class="hs-identifier hs-var">HasInitializeTDEmbedLayerNormInputF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#T5"><span class="hs-identifier hs-type">T5</span></a></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-189"></span><span>  </span><span id="HasInitializeTDEmbedLayerNormInputF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#HasInitializeTDEmbedLayerNormInputF"><span class="hs-identifier hs-var">HasInitializeTDEmbedLayerNormInputF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ByT5"><span class="hs-identifier hs-type">ByT5</span></a></span><span> </span><span id="local-6989586621679775776"><span class="annot"><a href="#local-6989586621679775776"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679775775"><span class="annot"><a href="#local-6989586621679775775"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679775774"><span class="annot"><a href="#local-6989586621679775774"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679775773"><span class="annot"><a href="#local-6989586621679775773"><span class="hs-identifier hs-type hs-type">decoderInputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#HasInitializeTDEmbedLayerNormInputF"><span class="hs-identifier hs-type">HasInitializeTDEmbedLayerNormInputF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#T5"><span class="hs-identifier hs-type">T5</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775776"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775775"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775774"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775773"><span class="hs-identifier hs-type">decoderInputEmbedDim</span></a></span><span>
</span><span id="line-190"></span><span>  </span><span id="HasInitializeTDEmbedLayerNormInputF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#HasInitializeTDEmbedLayerNormInputF"><span class="hs-identifier hs-var">HasInitializeTDEmbedLayerNormInputF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span> </span><span id="local-6989586621679775772"><span class="annot"><a href="#local-6989586621679775772"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679775771"><span class="annot"><a href="#local-6989586621679775771"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679775770"><span class="annot"><a href="#local-6989586621679775770"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679775769"><span class="annot"><a href="#local-6989586621679775769"><span class="hs-identifier hs-type hs-type">decoderInputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier hs-type">SGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775772"><span class="hs-identifier hs-type">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#SDevice"><span class="hs-identifier hs-type">SDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775771"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier hs-type">SDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775770"><span class="hs-identifier hs-type">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-type">SShape</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679775769"><span class="hs-identifier hs-type">decoderInputEmbedDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span class="hs-special">)</span><span>
</span><span id="line-191"></span><span>  </span><span id="HasInitializeTDEmbedLayerNormInputF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#HasInitializeTDEmbedLayerNormInputF"><span class="hs-identifier hs-var">HasInitializeTDEmbedLayerNormInputF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MBART"><span class="hs-identifier hs-type">MBART</span></a></span><span> </span><span id="local-6989586621679775768"><span class="annot"><a href="#local-6989586621679775768"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679775767"><span class="annot"><a href="#local-6989586621679775767"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679775766"><span class="annot"><a href="#local-6989586621679775766"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679775765"><span class="annot"><a href="#local-6989586621679775765"><span class="hs-identifier hs-type hs-type">decoderInputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#HasInitializeTDEmbedLayerNormInputF"><span class="hs-identifier hs-type">HasInitializeTDEmbedLayerNormInputF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775768"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775767"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775766"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775765"><span class="hs-identifier hs-type">decoderInputEmbedDim</span></a></span><span>
</span><span id="line-192"></span><span>  </span><span id="HasInitializeTDEmbedLayerNormInputF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#HasInitializeTDEmbedLayerNormInputF"><span class="hs-identifier hs-var">HasInitializeTDEmbedLayerNormInputF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#Pegasus"><span class="hs-identifier hs-type">Pegasus</span></a></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-193"></span><span>
</span><span id="line-194"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span>
</span><span id="line-195"></span><span>  </span><span id="HasInitializeTDLayerNormInputF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#HasInitializeTDLayerNormInputF"><span class="hs-identifier hs-var">HasInitializeTDLayerNormInputF</span></a></span></span><span>
</span><span id="line-196"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679775764"><span class="annot"><a href="#local-6989586621679775764"><span class="hs-identifier hs-type">style</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerStyle"><span class="hs-identifier hs-type">TransformerStyle</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-197"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679775763"><span class="annot"><a href="#local-6989586621679775763"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#RequiresGradient"><span class="hs-identifier hs-type">RequiresGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-198"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679775762"><span class="annot"><a href="#local-6989586621679775762"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier hs-type">Device</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#DeviceType"><span class="hs-identifier hs-type">DeviceType</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-199"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679775761"><span class="annot"><a href="#local-6989586621679775761"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier hs-type">DType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-200"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679775760"><span class="annot"><a href="#local-6989586621679775760"><span class="hs-identifier hs-type">decoderInputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-201"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span>
</span><span id="line-202"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-203"></span><span>  </span><span id="HasInitializeTDLayerNormInputF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#HasInitializeTDLayerNormInputF"><span class="hs-identifier hs-var">HasInitializeTDLayerNormInputF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#T5"><span class="hs-identifier hs-type">T5</span></a></span><span> </span><span id="local-6989586621679775759"><span class="annot"><a href="#local-6989586621679775759"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679775758"><span class="annot"><a href="#local-6989586621679775758"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679775757"><span class="annot"><a href="#local-6989586621679775757"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679775756"><span class="annot"><a href="#local-6989586621679775756"><span class="hs-identifier hs-type hs-type">decoderInputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier hs-type">SGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775759"><span class="hs-identifier hs-type">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#SDevice"><span class="hs-identifier hs-type">SDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775758"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier hs-type">SDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775757"><span class="hs-identifier hs-type">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-type">SShape</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679775756"><span class="hs-identifier hs-type">decoderInputEmbedDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span class="hs-special">)</span><span>
</span><span id="line-204"></span><span>  </span><span id="HasInitializeTDLayerNormInputF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#HasInitializeTDLayerNormInputF"><span class="hs-identifier hs-var">HasInitializeTDLayerNormInputF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ByT5"><span class="hs-identifier hs-type">ByT5</span></a></span><span> </span><span id="local-6989586621679775755"><span class="annot"><a href="#local-6989586621679775755"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679775754"><span class="annot"><a href="#local-6989586621679775754"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679775753"><span class="annot"><a href="#local-6989586621679775753"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679775752"><span class="annot"><a href="#local-6989586621679775752"><span class="hs-identifier hs-type hs-type">decoderInputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#HasInitializeTDLayerNormInputF"><span class="hs-identifier hs-type">HasInitializeTDLayerNormInputF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#T5"><span class="hs-identifier hs-type">T5</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775755"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775754"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775753"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775752"><span class="hs-identifier hs-type">decoderInputEmbedDim</span></a></span><span>
</span><span id="line-205"></span><span>  </span><span id="HasInitializeTDLayerNormInputF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#HasInitializeTDLayerNormInputF"><span class="hs-identifier hs-var">HasInitializeTDLayerNormInputF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-206"></span><span>  </span><span id="HasInitializeTDLayerNormInputF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#HasInitializeTDLayerNormInputF"><span class="hs-identifier hs-var">HasInitializeTDLayerNormInputF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MBART"><span class="hs-identifier hs-type">MBART</span></a></span><span> </span><span id="local-6989586621679775751"><span class="annot"><a href="#local-6989586621679775751"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679775750"><span class="annot"><a href="#local-6989586621679775750"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679775749"><span class="annot"><a href="#local-6989586621679775749"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679775748"><span class="annot"><a href="#local-6989586621679775748"><span class="hs-identifier hs-type hs-type">decoderInputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#HasInitializeTDLayerNormInputF"><span class="hs-identifier hs-type">HasInitializeTDLayerNormInputF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775751"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775750"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775749"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775748"><span class="hs-identifier hs-type">decoderInputEmbedDim</span></a></span><span>
</span><span id="line-207"></span><span>  </span><span id="HasInitializeTDLayerNormInputF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#HasInitializeTDLayerNormInputF"><span class="hs-identifier hs-var">HasInitializeTDLayerNormInputF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#Pegasus"><span class="hs-identifier hs-type">Pegasus</span></a></span><span> </span><span id="local-6989586621679775747"><span class="annot"><a href="#local-6989586621679775747"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679775746"><span class="annot"><a href="#local-6989586621679775746"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679775745"><span class="annot"><a href="#local-6989586621679775745"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679775744"><span class="annot"><a href="#local-6989586621679775744"><span class="hs-identifier hs-type hs-type">decoderInputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier hs-type">SGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775747"><span class="hs-identifier hs-type">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#SDevice"><span class="hs-identifier hs-type">SDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775746"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier hs-type">SDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775745"><span class="hs-identifier hs-type">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-type">SShape</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679775744"><span class="hs-identifier hs-type">decoderInputEmbedDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span class="hs-special">)</span><span>
</span><span id="line-208"></span><span>
</span><span id="line-209"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span>
</span><span id="line-210"></span><span>  </span><span id="HasInitializeTDPosEncInputF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#HasInitializeTDPosEncInputF"><span class="hs-identifier hs-var">HasInitializeTDPosEncInputF</span></a></span></span><span>
</span><span id="line-211"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679775743"><span class="annot"><a href="#local-6989586621679775743"><span class="hs-identifier hs-type">style</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerStyle"><span class="hs-identifier hs-type">TransformerStyle</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-212"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679775742"><span class="annot"><a href="#local-6989586621679775742"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#RequiresGradient"><span class="hs-identifier hs-type">RequiresGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-213"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679775741"><span class="annot"><a href="#local-6989586621679775741"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier hs-type">Device</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#DeviceType"><span class="hs-identifier hs-type">DeviceType</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-214"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679775740"><span class="annot"><a href="#local-6989586621679775740"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier hs-type">DType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-215"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679775739"><span class="annot"><a href="#local-6989586621679775739"><span class="hs-identifier hs-type">headDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-216"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679775738"><span class="annot"><a href="#local-6989586621679775738"><span class="hs-identifier hs-type">decoderInputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-217"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679775737"><span class="annot"><a href="#local-6989586621679775737"><span class="hs-identifier hs-type">posEncDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-218"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span>
</span><span id="line-219"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-220"></span><span>  </span><span id="HasInitializeTDPosEncInputF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#HasInitializeTDPosEncInputF"><span class="hs-identifier hs-var">HasInitializeTDPosEncInputF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#T5"><span class="hs-identifier hs-type">T5</span></a></span><span> </span><span id="local-6989586621679775736"><span class="annot"><a href="#local-6989586621679775736"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679775735"><span class="annot"><a href="#local-6989586621679775735"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679775734"><span class="annot"><a href="#local-6989586621679775734"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679775733"><span class="annot"><a href="#local-6989586621679775733"><span class="hs-identifier hs-type hs-type">headDim</span></a></span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span id="local-6989586621679775732"><span class="annot"><a href="#local-6989586621679775732"><span class="hs-identifier hs-type hs-type">posEncDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier hs-type">SGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775736"><span class="hs-identifier hs-type">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#SLayout"><span class="hs-identifier hs-type">SLayout</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Dense"><span class="hs-identifier hs-type">Dense</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#SDevice"><span class="hs-identifier hs-type">SDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775735"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier hs-type">SDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775734"><span class="hs-identifier hs-type">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775732"><span class="hs-identifier hs-type">posEncDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775733"><span class="hs-identifier hs-type">headDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-221"></span><span>  </span><span id="HasInitializeTDPosEncInputF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#HasInitializeTDPosEncInputF"><span class="hs-identifier hs-var">HasInitializeTDPosEncInputF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ByT5"><span class="hs-identifier hs-type">ByT5</span></a></span><span> </span><span id="local-6989586621679775731"><span class="annot"><a href="#local-6989586621679775731"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679775730"><span class="annot"><a href="#local-6989586621679775730"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679775729"><span class="annot"><a href="#local-6989586621679775729"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679775728"><span class="annot"><a href="#local-6989586621679775728"><span class="hs-identifier hs-type hs-type">headDim</span></a></span></span><span> </span><span id="local-6989586621679775727"><span class="annot"><a href="#local-6989586621679775727"><span class="hs-identifier hs-type hs-type">decoderInputEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679775726"><span class="annot"><a href="#local-6989586621679775726"><span class="hs-identifier hs-type hs-type">posEncDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#HasInitializeTDPosEncInputF"><span class="hs-identifier hs-type">HasInitializeTDPosEncInputF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#T5"><span class="hs-identifier hs-type">T5</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775731"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775730"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775729"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775728"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775727"><span class="hs-identifier hs-type">decoderInputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775726"><span class="hs-identifier hs-type">posEncDim</span></a></span><span>
</span><span id="line-222"></span><span>  </span><span id="HasInitializeTDPosEncInputF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#HasInitializeTDPosEncInputF"><span class="hs-identifier hs-var">HasInitializeTDPosEncInputF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span> </span><span id="local-6989586621679775725"><span class="annot"><a href="#local-6989586621679775725"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679775724"><span class="annot"><a href="#local-6989586621679775724"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679775723"><span class="annot"><a href="#local-6989586621679775723"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span id="local-6989586621679775722"><span class="annot"><a href="#local-6989586621679775722"><span class="hs-identifier hs-type hs-type">decoderInputEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679775721"><span class="annot"><a href="#local-6989586621679775721"><span class="hs-identifier hs-type hs-type">posEncDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier hs-type">SGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775725"><span class="hs-identifier hs-type">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#SLayout"><span class="hs-identifier hs-type">SLayout</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Dense"><span class="hs-identifier hs-type">Dense</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#SDevice"><span class="hs-identifier hs-type">SDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775724"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier hs-type">SDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775723"><span class="hs-identifier hs-type">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775721"><span class="hs-identifier hs-type">posEncDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775722"><span class="hs-identifier hs-type">decoderInputEmbedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-223"></span><span>  </span><span id="HasInitializeTDPosEncInputF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#HasInitializeTDPosEncInputF"><span class="hs-identifier hs-var">HasInitializeTDPosEncInputF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MBART"><span class="hs-identifier hs-type">MBART</span></a></span><span> </span><span id="local-6989586621679775720"><span class="annot"><a href="#local-6989586621679775720"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679775719"><span class="annot"><a href="#local-6989586621679775719"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679775718"><span class="annot"><a href="#local-6989586621679775718"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679775717"><span class="annot"><a href="#local-6989586621679775717"><span class="hs-identifier hs-type hs-type">headDim</span></a></span></span><span> </span><span id="local-6989586621679775716"><span class="annot"><a href="#local-6989586621679775716"><span class="hs-identifier hs-type hs-type">decoderInputEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679775715"><span class="annot"><a href="#local-6989586621679775715"><span class="hs-identifier hs-type hs-type">posEncDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#HasInitializeTDPosEncInputF"><span class="hs-identifier hs-type">HasInitializeTDPosEncInputF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775720"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775719"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775718"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775717"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775716"><span class="hs-identifier hs-type">decoderInputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775715"><span class="hs-identifier hs-type">posEncDim</span></a></span><span>
</span><span id="line-224"></span><span>  </span><span id="HasInitializeTDPosEncInputF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#HasInitializeTDPosEncInputF"><span class="hs-identifier hs-var">HasInitializeTDPosEncInputF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#Pegasus"><span class="hs-identifier hs-type">Pegasus</span></a></span><span> </span><span id="local-6989586621679775714"><span class="annot"><a href="#local-6989586621679775714"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679775713"><span class="annot"><a href="#local-6989586621679775713"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679775712"><span class="annot"><a href="#local-6989586621679775712"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679775711"><span class="annot"><a href="#local-6989586621679775711"><span class="hs-identifier hs-type hs-type">headDim</span></a></span></span><span> </span><span id="local-6989586621679775710"><span class="annot"><a href="#local-6989586621679775710"><span class="hs-identifier hs-type hs-type">decoderInputEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679775709"><span class="annot"><a href="#local-6989586621679775709"><span class="hs-identifier hs-type hs-type">posEncDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#HasInitializeTDPosEncInputF"><span class="hs-identifier hs-type">HasInitializeTDPosEncInputF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775714"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775713"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775712"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775711"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775710"><span class="hs-identifier hs-type">decoderInputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775709"><span class="hs-identifier hs-type">posEncDim</span></a></span><span>
</span><span id="line-225"></span><span>
</span><span id="line-226"></span><span id="local-6989586621679775686"><span id="local-6989586621679775687"><span id="local-6989586621679775688"><span id="local-6989586621679775689"><span id="local-6989586621679775690"><span id="local-6989586621679775691"><span id="local-6989586621679775692"><span id="local-6989586621679775693"><span id="local-6989586621679775694"><span id="local-6989586621679775695"><span id="local-6989586621679775696"><span id="local-6989586621679775697"><span id="local-6989586621679775698"><span id="local-6989586621679775699"><span id="local-6989586621679775700"><span id="local-6989586621679775701"><span id="local-6989586621679775702"><span id="local-6989586621679775703"><span id="local-6989586621679775704"><span id="local-6989586621679775705"><span id="local-6989586621679775706"><span id="local-6989586621679775707"><span id="local-6989586621679775708"><span class="hs-keyword">instance</span><span>
</span><span id="line-227"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-type">SingI</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775708"><span class="hs-identifier hs-type">style</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-228"></span><span>    </span><span class="annot"><a href="#local-6989586621679775707"><span class="hs-identifier hs-type">stack</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TDStackF"><span class="hs-identifier hs-type">TDStackF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775708"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775706"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775705"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775704"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775703"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775702"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775701"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775700"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775699"><span class="hs-identifier hs-type">decoderInputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775698"><span class="hs-identifier hs-type">encoderOutputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775697"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775696"><span class="hs-identifier hs-type">dropoutP</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-229"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775707"><span class="hs-identifier hs-type">stack</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier hs-type">SGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775705"><span class="hs-identifier hs-type">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#SDevice"><span class="hs-identifier hs-type">SDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775704"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier hs-type">SDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775703"><span class="hs-identifier hs-type">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775702"><span class="hs-identifier hs-type">headDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775701"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775700"><span class="hs-identifier hs-type">embedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775699"><span class="hs-identifier hs-type">decoderInputEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775698"><span class="hs-identifier hs-type">encoderOutputEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775697"><span class="hs-identifier hs-type">ffnDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679775696"><span class="hs-identifier hs-type">dropoutP</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679775695"><span class="hs-identifier hs-type">generator</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775694"><span class="hs-identifier hs-type">generator'</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-230"></span><span>    </span><span class="annot"><a href="#local-6989586621679775693"><span class="hs-identifier hs-type">embedLayerNorm</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TDEmbedLayerNormF"><span class="hs-identifier hs-type">TDEmbedLayerNormF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775708"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775705"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775704"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775703"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775699"><span class="hs-identifier hs-type">decoderInputEmbedDim</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-231"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775693"><span class="hs-identifier hs-type">embedLayerNorm</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#HasInitializeTDEmbedLayerNormInputF"><span class="hs-identifier hs-type">HasInitializeTDEmbedLayerNormInputF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775708"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775705"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775704"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775703"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775699"><span class="hs-identifier hs-type">decoderInputEmbedDim</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679775694"><span class="hs-identifier hs-type">generator'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775692"><span class="hs-identifier hs-type">generator''</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-232"></span><span>    </span><span class="annot"><a href="#local-6989586621679775691"><span class="hs-identifier hs-type">layerNorm</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TDLayerNormF"><span class="hs-identifier hs-type">TDLayerNormF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775708"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775705"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775704"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775703"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775699"><span class="hs-identifier hs-type">decoderInputEmbedDim</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-233"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775691"><span class="hs-identifier hs-type">layerNorm</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#HasInitializeTDLayerNormInputF"><span class="hs-identifier hs-type">HasInitializeTDLayerNormInputF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775708"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775705"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775704"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775703"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775699"><span class="hs-identifier hs-type">decoderInputEmbedDim</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679775692"><span class="hs-identifier hs-type">generator''</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775690"><span class="hs-identifier hs-type">generator'''</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-234"></span><span>    </span><span class="annot"><a href="#local-6989586621679775689"><span class="hs-identifier hs-type">dropout</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TDDropoutF"><span class="hs-identifier hs-type">TDDropoutF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775708"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775696"><span class="hs-identifier hs-type">dropoutP</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-235"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775689"><span class="hs-identifier hs-type">dropout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775696"><span class="hs-identifier hs-type">dropoutP</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775690"><span class="hs-identifier hs-type">generator'''</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775690"><span class="hs-identifier hs-type">generator'''</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-236"></span><span>    </span><span class="annot"><a href="#local-6989586621679775688"><span class="hs-identifier hs-type">posEnc</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TDPosEncF"><span class="hs-identifier hs-type">TDPosEncF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775708"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775705"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775704"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775703"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775702"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775699"><span class="hs-identifier hs-type">decoderInputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775687"><span class="hs-identifier hs-type">posEncDim</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-237"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775688"><span class="hs-identifier hs-type">posEnc</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#HasInitializeTDPosEncInputF"><span class="hs-identifier hs-type">HasInitializeTDPosEncInputF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775708"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775705"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775704"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775703"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775702"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775699"><span class="hs-identifier hs-type">decoderInputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775687"><span class="hs-identifier hs-type">posEncDim</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679775690"><span class="hs-identifier hs-type">generator'''</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775686"><span class="hs-identifier hs-type">generator''''</span></a></span><span>
</span><span id="line-238"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-239"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span>
</span><span id="line-240"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TransformerDecoder"><span class="hs-identifier hs-type">TransformerDecoder</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775708"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775706"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775705"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775704"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775703"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775702"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775701"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775700"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775699"><span class="hs-identifier hs-type">decoderInputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775698"><span class="hs-identifier hs-type">encoderOutputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775697"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775687"><span class="hs-identifier hs-type">posEncDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775696"><span class="hs-identifier hs-type">dropoutP</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-241"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier hs-type">SGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775705"><span class="hs-identifier hs-type">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#SDevice"><span class="hs-identifier hs-type">SDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775704"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier hs-type">SDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775703"><span class="hs-identifier hs-type">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775702"><span class="hs-identifier hs-type">headDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775701"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775700"><span class="hs-identifier hs-type">embedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775699"><span class="hs-identifier hs-type">decoderInputEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775698"><span class="hs-identifier hs-type">encoderOutputEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775697"><span class="hs-identifier hs-type">ffnDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775687"><span class="hs-identifier hs-type">posEncDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679775696"><span class="hs-identifier hs-type">dropoutP</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span class="hs-special">)</span><span>
</span><span id="line-242"></span><span>    </span><span class="annot"><a href="#local-6989586621679775695"><span class="hs-identifier hs-type">generator</span></a></span><span>
</span><span id="line-243"></span><span>    </span><span class="annot"><a href="#local-6989586621679775686"><span class="hs-identifier hs-type">generator''''</span></a></span><span>
</span><span id="line-244"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-245"></span><span>  </span><span id="local-6989586621679775683"><span class="annot"><span class="annottext">initialize :: (SGradient gradient, SDevice device, SDataType dataType,
 SDim headDim, SDim headEmbedDim, SDim embedDim,
 SDim decoderInputEmbedDim, SDim encoderOutputEmbedDim, SDim ffnDim,
 SDim posEncDim, dropoutP, Double)
-&gt; generator
-&gt; (TransformerDecoder
      style
      numLayers
      gradient
      device
      dataType
      headDim
      headEmbedDim
      embedDim
      decoderInputEmbedDim
      encoderOutputEmbedDim
      ffnDim
      posEncDim
      dropoutP,
    generator'''')
</span><a href="Torch.GraduallyTyped.NN.Class.html#initialize"><span class="hs-identifier hs-var hs-var hs-var hs-var">initialize</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679775681"><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679775681"><span class="hs-identifier hs-var">gradient</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679775680"><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679775680"><span class="hs-identifier hs-var">device</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679775679"><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679775679"><span class="hs-identifier hs-var">dataType</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679775678"><span class="annot"><span class="annottext">SDim headDim
</span><a href="#local-6989586621679775678"><span class="hs-identifier hs-var">headDim</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679775677"><span class="annot"><span class="annottext">SDim headEmbedDim
</span><a href="#local-6989586621679775677"><span class="hs-identifier hs-var">headEmbedDim</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679775676"><span class="annot"><span class="annottext">SDim embedDim
</span><a href="#local-6989586621679775676"><span class="hs-identifier hs-var">embedDim</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679775675"><span class="annot"><span class="annottext">SDim decoderInputEmbedDim
</span><a href="#local-6989586621679775675"><span class="hs-identifier hs-var">decoderInputEmbedDim</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679775674"><span class="annot"><span class="annottext">SDim encoderOutputEmbedDim
</span><a href="#local-6989586621679775674"><span class="hs-identifier hs-var">encoderOutputEmbedDim</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679775673"><span class="annot"><span class="annottext">SDim ffnDim
</span><a href="#local-6989586621679775673"><span class="hs-identifier hs-var">ffnDim</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679775672"><span class="annot"><span class="annottext">SDim posEncDim
</span><a href="#local-6989586621679775672"><span class="hs-identifier hs-var">posEncDim</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679775671"><span class="annot"><span class="annottext">dropoutP
</span><a href="#local-6989586621679775671"><span class="hs-identifier hs-var">dropoutP</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679775670"><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679775670"><span class="hs-identifier hs-var">eps</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-246"></span><span>    </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679775669"><span class="annot"><span class="annottext">decoderStack :: IxState
  generator
  generator'
  (TransformerDecoderStack
     style
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     decoderInputEmbedDim
     encoderOutputEmbedDim
     ffnDim
     dropoutP)
</span><a href="#local-6989586621679775669"><span class="hs-identifier hs-var hs-var">decoderStack</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(generator
 -&gt; (TransformerDecoderStack
       style
       numLayers
       gradient
       device
       dataType
       headDim
       headEmbedDim
       embedDim
       decoderInputEmbedDim
       encoderOutputEmbedDim
       ffnDim
       dropoutP,
     generator'))
-&gt; IxState
     generator
     generator'
     (TransformerDecoderStack
        style
        numLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        decoderInputEmbedDim
        encoderOutputEmbedDim
        ffnDim
        dropoutP)
forall i j a. (i -&gt; (a, j)) -&gt; IxState i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxState</span></a></span><span> </span><span class="annot"><span class="annottext">((generator
  -&gt; (TransformerDecoderStack
        style
        numLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        decoderInputEmbedDim
        encoderOutputEmbedDim
        ffnDim
        dropoutP,
      generator'))
 -&gt; IxState
      generator
      generator'
      (TransformerDecoderStack
         style
         numLayers
         gradient
         device
         dataType
         headDim
         headEmbedDim
         embedDim
         decoderInputEmbedDim
         encoderOutputEmbedDim
         ffnDim
         dropoutP))
-&gt; ((SGradient gradient, SDevice device, SDataType dataType,
     SDim headDim, SDim headEmbedDim, SDim embedDim,
     SDim decoderInputEmbedDim, SDim encoderOutputEmbedDim, SDim ffnDim,
     dropoutP, Double)
    -&gt; generator
    -&gt; (TransformerDecoderStack
          style
          numLayers
          gradient
          device
          dataType
          headDim
          headEmbedDim
          embedDim
          decoderInputEmbedDim
          encoderOutputEmbedDim
          ffnDim
          dropoutP,
        generator'))
-&gt; (SGradient gradient, SDevice device, SDataType dataType,
    SDim headDim, SDim headEmbedDim, SDim embedDim,
    SDim decoderInputEmbedDim, SDim encoderOutputEmbedDim, SDim ffnDim,
    dropoutP, Double)
-&gt; IxState
     generator
     generator'
     (TransformerDecoderStack
        style
        numLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        decoderInputEmbedDim
        encoderOutputEmbedDim
        ffnDim
        dropoutP)
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">(SGradient gradient, SDevice device, SDataType dataType,
 SDim headDim, SDim headEmbedDim, SDim embedDim,
 SDim decoderInputEmbedDim, SDim encoderOutputEmbedDim, SDim ffnDim,
 dropoutP, Double)
-&gt; generator
-&gt; (TransformerDecoderStack
      style
      numLayers
      gradient
      device
      dataType
      headDim
      headEmbedDim
      embedDim
      decoderInputEmbedDim
      encoderOutputEmbedDim
      ffnDim
      dropoutP,
    generator')
forall model input generator generatorOutput.
HasInitialize model input generator generatorOutput =&gt;
input -&gt; generator -&gt; (model, generatorOutput)
</span><a href="Torch.GraduallyTyped.NN.Class.html#initialize"><span class="hs-identifier hs-var">initialize</span></a></span><span> </span><span class="annot"><span class="annottext">((SGradient gradient, SDevice device, SDataType dataType,
  SDim headDim, SDim headEmbedDim, SDim embedDim,
  SDim decoderInputEmbedDim, SDim encoderOutputEmbedDim, SDim ffnDim,
  dropoutP, Double)
 -&gt; IxState
      generator
      generator'
      (TransformerDecoderStack
         style
         numLayers
         gradient
         device
         dataType
         headDim
         headEmbedDim
         embedDim
         decoderInputEmbedDim
         encoderOutputEmbedDim
         ffnDim
         dropoutP))
-&gt; (SGradient gradient, SDevice device, SDataType dataType,
    SDim headDim, SDim headEmbedDim, SDim embedDim,
    SDim decoderInputEmbedDim, SDim encoderOutputEmbedDim, SDim ffnDim,
    dropoutP, Double)
-&gt; IxState
     generator
     generator'
     (TransformerDecoderStack
        style
        numLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        decoderInputEmbedDim
        encoderOutputEmbedDim
        ffnDim
        dropoutP)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679775681"><span class="hs-identifier hs-var">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679775680"><span class="hs-identifier hs-var">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679775679"><span class="hs-identifier hs-var">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim headDim
</span><a href="#local-6989586621679775678"><span class="hs-identifier hs-var">headDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim headEmbedDim
</span><a href="#local-6989586621679775677"><span class="hs-identifier hs-var">headEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim embedDim
</span><a href="#local-6989586621679775676"><span class="hs-identifier hs-var">embedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim decoderInputEmbedDim
</span><a href="#local-6989586621679775675"><span class="hs-identifier hs-var">decoderInputEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim encoderOutputEmbedDim
</span><a href="#local-6989586621679775674"><span class="hs-identifier hs-var">encoderOutputEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim ffnDim
</span><a href="#local-6989586621679775673"><span class="hs-identifier hs-var">ffnDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">dropoutP
</span><a href="#local-6989586621679775671"><span class="hs-identifier hs-var">dropoutP</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679775670"><span class="hs-identifier hs-var">eps</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-247"></span><span>        </span><span id="local-6989586621679775666"><span class="annot"><span class="annottext">embedLayerNorm :: IxState generator' generator'' embedLayerNorm
</span><a href="#local-6989586621679775666"><span class="hs-identifier hs-var hs-var">embedLayerNorm</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(generator' -&gt; (embedLayerNorm, generator''))
-&gt; IxState generator' generator'' embedLayerNorm
forall i j a. (i -&gt; (a, j)) -&gt; IxState i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxState</span></a></span><span> </span><span class="annot"><span class="annottext">((generator' -&gt; (embedLayerNorm, generator''))
 -&gt; IxState generator' generator'' embedLayerNorm)
-&gt; (HasInitializeTDEmbedLayerNormInputF
      style gradient device dataType decoderInputEmbedDim
    -&gt; generator' -&gt; (embedLayerNorm, generator''))
-&gt; HasInitializeTDEmbedLayerNormInputF
     style gradient device dataType decoderInputEmbedDim
-&gt; IxState generator' generator'' embedLayerNorm
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">HasInitializeTDEmbedLayerNormInputF
  style gradient device dataType decoderInputEmbedDim
-&gt; generator' -&gt; (embedLayerNorm, generator'')
forall model input generator generatorOutput.
HasInitialize model input generator generatorOutput =&gt;
input -&gt; generator -&gt; (model, generatorOutput)
</span><a href="Torch.GraduallyTyped.NN.Class.html#initialize"><span class="hs-identifier hs-var">initialize</span></a></span><span> </span><span class="annot"><span class="annottext">(HasInitializeTDEmbedLayerNormInputF
   style gradient device dataType decoderInputEmbedDim
 -&gt; IxState generator' generator'' embedLayerNorm)
-&gt; HasInitializeTDEmbedLayerNormInputF
     style gradient device dataType decoderInputEmbedDim
-&gt; IxState generator' generator'' embedLayerNorm
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-keyword">case</span><span> </span><span class="annot"><span class="annottext">SingI style =&gt; Sing style
forall k (a :: k). SingI a =&gt; Sing a
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">sing</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679775708"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="hs-keyword">of</span><span>
</span><span id="line-248"></span><span>          </span><span class="annot"><span class="annottext">Sing style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-249"></span><span>          </span><span class="annot"><span class="annottext">Sing style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-250"></span><span>          </span><span class="annot"><span class="annottext">Sing style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679775681"><span class="hs-identifier hs-var">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679775680"><span class="hs-identifier hs-var">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679775679"><span class="hs-identifier hs-var">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SList '[decoderInputEmbedDim]
-&gt; SShape ('Shape '[decoderInputEmbedDim])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList '[decoderInputEmbedDim]
 -&gt; SShape ('Shape '[decoderInputEmbedDim]))
-&gt; SList '[decoderInputEmbedDim]
-&gt; SShape ('Shape '[decoderInputEmbedDim])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SDim decoderInputEmbedDim
</span><a href="#local-6989586621679775675"><span class="hs-identifier hs-var">decoderInputEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim decoderInputEmbedDim
-&gt; SList '[] -&gt; SList '[decoderInputEmbedDim]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679775670"><span class="hs-identifier hs-var">eps</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-251"></span><span>          </span><span class="annot"><span class="annottext">Sing style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679775681"><span class="hs-identifier hs-var">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679775680"><span class="hs-identifier hs-var">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679775679"><span class="hs-identifier hs-var">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SList '[decoderInputEmbedDim]
-&gt; SShape ('Shape '[decoderInputEmbedDim])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList '[decoderInputEmbedDim]
 -&gt; SShape ('Shape '[decoderInputEmbedDim]))
-&gt; SList '[decoderInputEmbedDim]
-&gt; SShape ('Shape '[decoderInputEmbedDim])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SDim decoderInputEmbedDim
</span><a href="#local-6989586621679775675"><span class="hs-identifier hs-var">decoderInputEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim decoderInputEmbedDim
-&gt; SList '[] -&gt; SList '[decoderInputEmbedDim]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679775670"><span class="hs-identifier hs-var">eps</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-252"></span><span>          </span><span class="annot"><span class="annottext">Sing style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-253"></span><span>          </span><span class="annot"><span class="annottext">Sing style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">HasInitializeTDEmbedLayerNormInputF
  style gradient device dataType decoderInputEmbedDim
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-254"></span><span>          </span><span class="annot"><span class="annottext">Sing style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">HasInitializeTDEmbedLayerNormInputF
  style gradient device dataType decoderInputEmbedDim
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-255"></span><span>          </span><span class="annot"><span class="annottext">Sing style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SGPT2"><span class="hs-identifier hs-var">SGPT2</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">HasInitializeTDEmbedLayerNormInputF
  style gradient device dataType decoderInputEmbedDim
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-256"></span><span>        </span><span id="local-6989586621679775655"><span class="annot"><span class="annottext">layerNorm :: IxState generator'' generator''' layerNorm
</span><a href="#local-6989586621679775655"><span class="hs-identifier hs-var hs-var">layerNorm</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(generator'' -&gt; (layerNorm, generator'''))
-&gt; IxState generator'' generator''' layerNorm
forall i j a. (i -&gt; (a, j)) -&gt; IxState i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxState</span></a></span><span> </span><span class="annot"><span class="annottext">((generator'' -&gt; (layerNorm, generator'''))
 -&gt; IxState generator'' generator''' layerNorm)
-&gt; (HasInitializeTDLayerNormInputF
      style gradient device dataType decoderInputEmbedDim
    -&gt; generator'' -&gt; (layerNorm, generator'''))
-&gt; HasInitializeTDLayerNormInputF
     style gradient device dataType decoderInputEmbedDim
-&gt; IxState generator'' generator''' layerNorm
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">HasInitializeTDLayerNormInputF
  style gradient device dataType decoderInputEmbedDim
-&gt; generator'' -&gt; (layerNorm, generator''')
forall model input generator generatorOutput.
HasInitialize model input generator generatorOutput =&gt;
input -&gt; generator -&gt; (model, generatorOutput)
</span><a href="Torch.GraduallyTyped.NN.Class.html#initialize"><span class="hs-identifier hs-var">initialize</span></a></span><span> </span><span class="annot"><span class="annottext">(HasInitializeTDLayerNormInputF
   style gradient device dataType decoderInputEmbedDim
 -&gt; IxState generator'' generator''' layerNorm)
-&gt; HasInitializeTDLayerNormInputF
     style gradient device dataType decoderInputEmbedDim
-&gt; IxState generator'' generator''' layerNorm
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-keyword">case</span><span> </span><span class="annot"><span class="annottext">SingI style =&gt; Sing style
forall k (a :: k). SingI a =&gt; Sing a
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">sing</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679775708"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="hs-keyword">of</span><span>
</span><span id="line-257"></span><span>          </span><span class="annot"><span class="annottext">Sing style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679775681"><span class="hs-identifier hs-var">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679775680"><span class="hs-identifier hs-var">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679775679"><span class="hs-identifier hs-var">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SList '[decoderInputEmbedDim]
-&gt; SShape ('Shape '[decoderInputEmbedDim])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList '[decoderInputEmbedDim]
 -&gt; SShape ('Shape '[decoderInputEmbedDim]))
-&gt; SList '[decoderInputEmbedDim]
-&gt; SShape ('Shape '[decoderInputEmbedDim])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SDim decoderInputEmbedDim
</span><a href="#local-6989586621679775675"><span class="hs-identifier hs-var">decoderInputEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim decoderInputEmbedDim
-&gt; SList '[] -&gt; SList '[decoderInputEmbedDim]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679775670"><span class="hs-identifier hs-var">eps</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-258"></span><span>          </span><span class="annot"><span class="annottext">Sing style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679775681"><span class="hs-identifier hs-var">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679775680"><span class="hs-identifier hs-var">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679775679"><span class="hs-identifier hs-var">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SList '[decoderInputEmbedDim]
-&gt; SShape ('Shape '[decoderInputEmbedDim])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList '[decoderInputEmbedDim]
 -&gt; SShape ('Shape '[decoderInputEmbedDim]))
-&gt; SList '[decoderInputEmbedDim]
-&gt; SShape ('Shape '[decoderInputEmbedDim])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SDim decoderInputEmbedDim
</span><a href="#local-6989586621679775675"><span class="hs-identifier hs-var">decoderInputEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim decoderInputEmbedDim
-&gt; SList '[] -&gt; SList '[decoderInputEmbedDim]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679775670"><span class="hs-identifier hs-var">eps</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-259"></span><span>          </span><span class="annot"><span class="annottext">Sing style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-260"></span><span>          </span><span class="annot"><span class="annottext">Sing style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-261"></span><span>          </span><span class="annot"><span class="annottext">Sing style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679775681"><span class="hs-identifier hs-var">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679775680"><span class="hs-identifier hs-var">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679775679"><span class="hs-identifier hs-var">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SList '[decoderInputEmbedDim]
-&gt; SShape ('Shape '[decoderInputEmbedDim])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList '[decoderInputEmbedDim]
 -&gt; SShape ('Shape '[decoderInputEmbedDim]))
-&gt; SList '[decoderInputEmbedDim]
-&gt; SShape ('Shape '[decoderInputEmbedDim])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SDim decoderInputEmbedDim
</span><a href="#local-6989586621679775675"><span class="hs-identifier hs-var">decoderInputEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim decoderInputEmbedDim
-&gt; SList '[] -&gt; SList '[decoderInputEmbedDim]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679775670"><span class="hs-identifier hs-var">eps</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-262"></span><span>          </span><span class="annot"><span class="annottext">Sing style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">HasInitializeTDLayerNormInputF
  style gradient device dataType decoderInputEmbedDim
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-263"></span><span>          </span><span class="annot"><span class="annottext">Sing style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">HasInitializeTDLayerNormInputF
  style gradient device dataType decoderInputEmbedDim
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-264"></span><span>          </span><span class="annot"><span class="annottext">Sing style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SGPT2"><span class="hs-identifier hs-var">SGPT2</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">HasInitializeTDLayerNormInputF
  style gradient device dataType decoderInputEmbedDim
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-265"></span><span>        </span><span id="local-6989586621679775654"><span class="annot"><span class="annottext">dropout :: IxState generator''' generator''' (Dropout dropoutP)
</span><a href="#local-6989586621679775654"><span class="hs-identifier hs-var hs-var">dropout</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(generator''' -&gt; (Dropout dropoutP, generator'''))
-&gt; IxState generator''' generator''' (Dropout dropoutP)
forall i j a. (i -&gt; (a, j)) -&gt; IxState i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxState</span></a></span><span> </span><span class="annot"><span class="annottext">((generator''' -&gt; (Dropout dropoutP, generator'''))
 -&gt; IxState generator''' generator''' (Dropout dropoutP))
-&gt; (dropoutP -&gt; generator''' -&gt; (Dropout dropoutP, generator'''))
-&gt; dropoutP
-&gt; IxState generator''' generator''' (Dropout dropoutP)
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">dropoutP -&gt; generator''' -&gt; (Dropout dropoutP, generator''')
forall model input generator generatorOutput.
HasInitialize model input generator generatorOutput =&gt;
input -&gt; generator -&gt; (model, generatorOutput)
</span><a href="Torch.GraduallyTyped.NN.Class.html#initialize"><span class="hs-identifier hs-var">initialize</span></a></span><span> </span><span class="annot"><span class="annottext">(dropoutP -&gt; IxState generator''' generator''' (Dropout dropoutP))
-&gt; dropoutP -&gt; IxState generator''' generator''' (Dropout dropoutP)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">dropoutP
</span><a href="#local-6989586621679775671"><span class="hs-identifier hs-var">dropoutP</span></a></span><span>
</span><span id="line-266"></span><span>        </span><span id="local-6989586621679775653"><span class="annot"><span class="annottext">posEnc :: IxState generator''' generator'''' posEnc
</span><a href="#local-6989586621679775653"><span class="hs-identifier hs-var hs-var">posEnc</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(generator''' -&gt; (posEnc, generator''''))
-&gt; IxState generator''' generator'''' posEnc
forall i j a. (i -&gt; (a, j)) -&gt; IxState i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxState</span></a></span><span> </span><span class="annot"><span class="annottext">((generator''' -&gt; (posEnc, generator''''))
 -&gt; IxState generator''' generator'''' posEnc)
-&gt; (HasInitializeTDPosEncInputF
      style
      gradient
      device
      dataType
      headDim
      decoderInputEmbedDim
      posEncDim
    -&gt; generator''' -&gt; (posEnc, generator''''))
-&gt; HasInitializeTDPosEncInputF
     style
     gradient
     device
     dataType
     headDim
     decoderInputEmbedDim
     posEncDim
-&gt; IxState generator''' generator'''' posEnc
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">HasInitializeTDPosEncInputF
  style
  gradient
  device
  dataType
  headDim
  decoderInputEmbedDim
  posEncDim
-&gt; generator''' -&gt; (posEnc, generator'''')
forall model input generator generatorOutput.
HasInitialize model input generator generatorOutput =&gt;
input -&gt; generator -&gt; (model, generatorOutput)
</span><a href="Torch.GraduallyTyped.NN.Class.html#initialize"><span class="hs-identifier hs-var">initialize</span></a></span><span> </span><span class="annot"><span class="annottext">(HasInitializeTDPosEncInputF
   style
   gradient
   device
   dataType
   headDim
   decoderInputEmbedDim
   posEncDim
 -&gt; IxState generator''' generator'''' posEnc)
-&gt; HasInitializeTDPosEncInputF
     style
     gradient
     device
     dataType
     headDim
     decoderInputEmbedDim
     posEncDim
-&gt; IxState generator''' generator'''' posEnc
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-keyword">case</span><span> </span><span class="annot"><span class="annottext">SingI style =&gt; Sing style
forall k (a :: k). SingI a =&gt; Sing a
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">sing</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679775708"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="hs-keyword">of</span><span>
</span><span id="line-267"></span><span>          </span><span class="annot"><span class="annottext">Sing style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679775681"><span class="hs-identifier hs-var">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SLayoutType 'Dense -&gt; SLayout ('Layout 'Dense)
forall (layoutType :: LayoutType).
SLayoutType layoutType -&gt; SLayout ('Layout layoutType)
</span><a href="Torch.GraduallyTyped.Layout.html#SLayout"><span class="hs-identifier hs-var">SLayout</span></a></span><span> </span><span class="annot"><span class="annottext">SLayoutType 'Dense
</span><a href="Torch.GraduallyTyped.Layout.html#SDense"><span class="hs-identifier hs-var">SDense</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679775680"><span class="hs-identifier hs-var">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679775679"><span class="hs-identifier hs-var">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim posEncDim
</span><a href="#local-6989586621679775672"><span class="hs-identifier hs-var">posEncDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim headDim
</span><a href="#local-6989586621679775678"><span class="hs-identifier hs-var">headDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-268"></span><span>          </span><span class="annot"><span class="annottext">Sing style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679775681"><span class="hs-identifier hs-var">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SLayoutType 'Dense -&gt; SLayout ('Layout 'Dense)
forall (layoutType :: LayoutType).
SLayoutType layoutType -&gt; SLayout ('Layout layoutType)
</span><a href="Torch.GraduallyTyped.Layout.html#SLayout"><span class="hs-identifier hs-var">SLayout</span></a></span><span> </span><span class="annot"><span class="annottext">SLayoutType 'Dense
</span><a href="Torch.GraduallyTyped.Layout.html#SDense"><span class="hs-identifier hs-var">SDense</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679775680"><span class="hs-identifier hs-var">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679775679"><span class="hs-identifier hs-var">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim posEncDim
</span><a href="#local-6989586621679775672"><span class="hs-identifier hs-var">posEncDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim headDim
</span><a href="#local-6989586621679775678"><span class="hs-identifier hs-var">headDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-269"></span><span>          </span><span class="annot"><span class="annottext">Sing style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679775681"><span class="hs-identifier hs-var">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SLayoutType 'Dense -&gt; SLayout ('Layout 'Dense)
forall (layoutType :: LayoutType).
SLayoutType layoutType -&gt; SLayout ('Layout layoutType)
</span><a href="Torch.GraduallyTyped.Layout.html#SLayout"><span class="hs-identifier hs-var">SLayout</span></a></span><span> </span><span class="annot"><span class="annottext">SLayoutType 'Dense
</span><a href="Torch.GraduallyTyped.Layout.html#SDense"><span class="hs-identifier hs-var">SDense</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679775680"><span class="hs-identifier hs-var">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679775679"><span class="hs-identifier hs-var">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim posEncDim
</span><a href="#local-6989586621679775672"><span class="hs-identifier hs-var">posEncDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim decoderInputEmbedDim
</span><a href="#local-6989586621679775675"><span class="hs-identifier hs-var">decoderInputEmbedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-270"></span><span>          </span><span class="annot"><span class="annottext">Sing style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679775681"><span class="hs-identifier hs-var">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SLayoutType 'Dense -&gt; SLayout ('Layout 'Dense)
forall (layoutType :: LayoutType).
SLayoutType layoutType -&gt; SLayout ('Layout layoutType)
</span><a href="Torch.GraduallyTyped.Layout.html#SLayout"><span class="hs-identifier hs-var">SLayout</span></a></span><span> </span><span class="annot"><span class="annottext">SLayoutType 'Dense
</span><a href="Torch.GraduallyTyped.Layout.html#SDense"><span class="hs-identifier hs-var">SDense</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679775680"><span class="hs-identifier hs-var">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679775679"><span class="hs-identifier hs-var">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim posEncDim
</span><a href="#local-6989586621679775672"><span class="hs-identifier hs-var">posEncDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim decoderInputEmbedDim
</span><a href="#local-6989586621679775675"><span class="hs-identifier hs-var">decoderInputEmbedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-271"></span><span>          </span><span class="annot"><span class="annottext">Sing style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679775681"><span class="hs-identifier hs-var">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SLayoutType 'Dense -&gt; SLayout ('Layout 'Dense)
forall (layoutType :: LayoutType).
SLayoutType layoutType -&gt; SLayout ('Layout layoutType)
</span><a href="Torch.GraduallyTyped.Layout.html#SLayout"><span class="hs-identifier hs-var">SLayout</span></a></span><span> </span><span class="annot"><span class="annottext">SLayoutType 'Dense
</span><a href="Torch.GraduallyTyped.Layout.html#SDense"><span class="hs-identifier hs-var">SDense</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679775680"><span class="hs-identifier hs-var">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679775679"><span class="hs-identifier hs-var">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim posEncDim
</span><a href="#local-6989586621679775672"><span class="hs-identifier hs-var">posEncDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim decoderInputEmbedDim
</span><a href="#local-6989586621679775675"><span class="hs-identifier hs-var">decoderInputEmbedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-272"></span><span>          </span><span class="annot"><span class="annottext">Sing style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">HasInitializeTDPosEncInputF
  style
  gradient
  device
  dataType
  headDim
  decoderInputEmbedDim
  posEncDim
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-273"></span><span>          </span><span class="annot"><span class="annottext">Sing style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">HasInitializeTDPosEncInputF
  style
  gradient
  device
  dataType
  headDim
  decoderInputEmbedDim
  posEncDim
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-274"></span><span>          </span><span class="annot"><span class="annottext">Sing style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SGPT2"><span class="hs-identifier hs-var">SGPT2</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">HasInitializeTDPosEncInputF
  style
  gradient
  device
  dataType
  headDim
  decoderInputEmbedDim
  posEncDim
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-275"></span><span>     </span><span class="hs-keyword">in</span><span> </span><span class="annot"><span class="annottext">IxState
  generator
  generator''''
  (TransformerDecoder
     style
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     decoderInputEmbedDim
     encoderOutputEmbedDim
     ffnDim
     posEncDim
     dropoutP)
-&gt; generator
-&gt; (TransformerDecoder
      style
      numLayers
      gradient
      device
      dataType
      headDim
      headEmbedDim
      embedDim
      decoderInputEmbedDim
      encoderOutputEmbedDim
      ffnDim
      posEncDim
      dropoutP,
    generator'''')
forall i j a. IxState i j a -&gt; i -&gt; (a, j)
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var hs-var">runIxState</span></a></span><span> </span><span class="annot"><span class="annottext">(IxState
   generator
   generator''''
   (TransformerDecoder
      style
      numLayers
      gradient
      device
      dataType
      headDim
      headEmbedDim
      embedDim
      decoderInputEmbedDim
      encoderOutputEmbedDim
      ffnDim
      posEncDim
      dropoutP)
 -&gt; generator
 -&gt; (TransformerDecoder
       style
       numLayers
       gradient
       device
       dataType
       headDim
       headEmbedDim
       embedDim
       decoderInputEmbedDim
       encoderOutputEmbedDim
       ffnDim
       posEncDim
       dropoutP,
     generator''''))
-&gt; IxState
     generator
     generator''''
     (TransformerDecoder
        style
        numLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        decoderInputEmbedDim
        encoderOutputEmbedDim
        ffnDim
        posEncDim
        dropoutP)
-&gt; generator
-&gt; (TransformerDecoder
      style
      numLayers
      gradient
      device
      dataType
      headDim
      headEmbedDim
      embedDim
      decoderInputEmbedDim
      encoderOutputEmbedDim
      ffnDim
      posEncDim
      dropoutP,
    generator'''')
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-276"></span><span>          </span><span class="hs-special">(</span><span class="annot"><span class="annottext">TransformerDecoderStack
  style
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  decoderInputEmbedDim
  encoderOutputEmbedDim
  ffnDim
  dropoutP
-&gt; embedLayerNorm
-&gt; layerNorm
-&gt; Dropout dropoutP
-&gt; posEnc
-&gt; GTransformerDecoder
     (TransformerDecoderStack
        style
        numLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        decoderInputEmbedDim
        encoderOutputEmbedDim
        ffnDim
        dropoutP)
     embedLayerNorm
     layerNorm
     (Dropout dropoutP)
     posEnc
forall stack embedLayerNorm layerNorm dropout posEnc.
stack
-&gt; embedLayerNorm
-&gt; layerNorm
-&gt; dropout
-&gt; posEnc
-&gt; GTransformerDecoder
     stack embedLayerNorm layerNorm dropout posEnc
</span><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#GTransformerDecoder"><span class="hs-identifier hs-var">GTransformerDecoder</span></a></span><span> </span><span class="annot"><span class="annottext">(TransformerDecoderStack
   style
   numLayers
   gradient
   device
   dataType
   headDim
   headEmbedDim
   embedDim
   decoderInputEmbedDim
   encoderOutputEmbedDim
   ffnDim
   dropoutP
 -&gt; embedLayerNorm
 -&gt; layerNorm
 -&gt; Dropout dropoutP
 -&gt; posEnc
 -&gt; GTransformerDecoder
      (TransformerDecoderStack
         style
         numLayers
         gradient
         device
         dataType
         headDim
         headEmbedDim
         embedDim
         decoderInputEmbedDim
         encoderOutputEmbedDim
         ffnDim
         dropoutP)
      embedLayerNorm
      layerNorm
      (Dropout dropoutP)
      posEnc)
-&gt; IxState
     generator
     generator'
     (TransformerDecoderStack
        style
        numLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        decoderInputEmbedDim
        encoderOutputEmbedDim
        ffnDim
        dropoutP)
-&gt; IxState
     generator
     generator'
     (embedLayerNorm
      -&gt; layerNorm
      -&gt; Dropout dropoutP
      -&gt; posEnc
      -&gt; GTransformerDecoder
           (TransformerDecoderStack
              style
              numLayers
              gradient
              device
              dataType
              headDim
              headEmbedDim
              embedDim
              decoderInputEmbedDim
              encoderOutputEmbedDim
              ffnDim
              dropoutP)
           embedLayerNorm
           layerNorm
           (Dropout dropoutP)
           posEnc)
forall k1 k2 (f :: k1 -&gt; k2 -&gt; * -&gt; *) a b (j :: k1) (k3 :: k2).
IxFunctor f =&gt;
(a -&gt; b) -&gt; f j k3 a -&gt; f j k3 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&lt;&lt;$&gt;&gt;</span></a></span><span> </span><span class="annot"><span class="annottext">IxState
  generator
  generator'
  (TransformerDecoderStack
     style
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     decoderInputEmbedDim
     encoderOutputEmbedDim
     ffnDim
     dropoutP)
</span><a href="#local-6989586621679775669"><span class="hs-identifier hs-var">decoderStack</span></a></span><span> </span><span class="annot"><span class="annottext">IxState
  generator
  generator'
  (embedLayerNorm
   -&gt; layerNorm
   -&gt; Dropout dropoutP
   -&gt; posEnc
   -&gt; GTransformerDecoder
        (TransformerDecoderStack
           style
           numLayers
           gradient
           device
           dataType
           headDim
           headEmbedDim
           embedDim
           decoderInputEmbedDim
           encoderOutputEmbedDim
           ffnDim
           dropoutP)
        embedLayerNorm
        layerNorm
        (Dropout dropoutP)
        posEnc)
-&gt; IxState generator' generator'' embedLayerNorm
-&gt; IxState
     generator
     generator''
     (layerNorm
      -&gt; Dropout dropoutP
      -&gt; posEnc
      -&gt; GTransformerDecoder
           (TransformerDecoderStack
              style
              numLayers
              gradient
              device
              dataType
              headDim
              headEmbedDim
              embedDim
              decoderInputEmbedDim
              encoderOutputEmbedDim
              ffnDim
              dropoutP)
           embedLayerNorm
           layerNorm
           (Dropout dropoutP)
           posEnc)
forall k1 (f :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a b
       (k2 :: k1).
IxApplicative f =&gt;
f i j (a -&gt; b) -&gt; f j k2 a -&gt; f i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&lt;&lt;*&gt;&gt;</span></a></span><span> </span><span class="annot"><span class="annottext">IxState generator' generator'' embedLayerNorm
</span><a href="#local-6989586621679775666"><span class="hs-identifier hs-var">embedLayerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">IxState
  generator
  generator''
  (layerNorm
   -&gt; Dropout dropoutP
   -&gt; posEnc
   -&gt; GTransformerDecoder
        (TransformerDecoderStack
           style
           numLayers
           gradient
           device
           dataType
           headDim
           headEmbedDim
           embedDim
           decoderInputEmbedDim
           encoderOutputEmbedDim
           ffnDim
           dropoutP)
        embedLayerNorm
        layerNorm
        (Dropout dropoutP)
        posEnc)
-&gt; IxState generator'' generator''' layerNorm
-&gt; IxState
     generator
     generator'''
     (Dropout dropoutP
      -&gt; posEnc
      -&gt; GTransformerDecoder
           (TransformerDecoderStack
              style
              numLayers
              gradient
              device
              dataType
              headDim
              headEmbedDim
              embedDim
              decoderInputEmbedDim
              encoderOutputEmbedDim
              ffnDim
              dropoutP)
           embedLayerNorm
           layerNorm
           (Dropout dropoutP)
           posEnc)
forall k1 (f :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a b
       (k2 :: k1).
IxApplicative f =&gt;
f i j (a -&gt; b) -&gt; f j k2 a -&gt; f i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&lt;&lt;*&gt;&gt;</span></a></span><span> </span><span class="annot"><span class="annottext">IxState generator'' generator''' layerNorm
</span><a href="#local-6989586621679775655"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">IxState
  generator
  generator'''
  (Dropout dropoutP
   -&gt; posEnc
   -&gt; GTransformerDecoder
        (TransformerDecoderStack
           style
           numLayers
           gradient
           device
           dataType
           headDim
           headEmbedDim
           embedDim
           decoderInputEmbedDim
           encoderOutputEmbedDim
           ffnDim
           dropoutP)
        embedLayerNorm
        layerNorm
        (Dropout dropoutP)
        posEnc)
-&gt; IxState generator''' generator''' (Dropout dropoutP)
-&gt; IxState
     generator
     generator'''
     (posEnc
      -&gt; GTransformerDecoder
           (TransformerDecoderStack
              style
              numLayers
              gradient
              device
              dataType
              headDim
              headEmbedDim
              embedDim
              decoderInputEmbedDim
              encoderOutputEmbedDim
              ffnDim
              dropoutP)
           embedLayerNorm
           layerNorm
           (Dropout dropoutP)
           posEnc)
forall k1 (f :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a b
       (k2 :: k1).
IxApplicative f =&gt;
f i j (a -&gt; b) -&gt; f j k2 a -&gt; f i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&lt;&lt;*&gt;&gt;</span></a></span><span> </span><span class="annot"><span class="annottext">IxState generator''' generator''' (Dropout dropoutP)
</span><a href="#local-6989586621679775654"><span class="hs-identifier hs-var">dropout</span></a></span><span> </span><span class="annot"><span class="annottext">IxState
  generator
  generator'''
  (posEnc
   -&gt; GTransformerDecoder
        (TransformerDecoderStack
           style
           numLayers
           gradient
           device
           dataType
           headDim
           headEmbedDim
           embedDim
           decoderInputEmbedDim
           encoderOutputEmbedDim
           ffnDim
           dropoutP)
        embedLayerNorm
        layerNorm
        (Dropout dropoutP)
        posEnc)
-&gt; IxState generator''' generator'''' posEnc
-&gt; IxState
     generator
     generator''''
     (GTransformerDecoder
        (TransformerDecoderStack
           style
           numLayers
           gradient
           device
           dataType
           headDim
           headEmbedDim
           embedDim
           decoderInputEmbedDim
           encoderOutputEmbedDim
           ffnDim
           dropoutP)
        embedLayerNorm
        layerNorm
        (Dropout dropoutP)
        posEnc)
forall k1 (f :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a b
       (k2 :: k1).
IxApplicative f =&gt;
f i j (a -&gt; b) -&gt; f j k2 a -&gt; f i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&lt;&lt;*&gt;&gt;</span></a></span><span> </span><span class="annot"><span class="annottext">IxState generator''' generator'''' posEnc
</span><a href="#local-6989586621679775653"><span class="hs-identifier hs-var">posEnc</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">IxState
  generator
  generator''''
  (GTransformerDecoder
     (TransformerDecoderStack
        style
        numLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        decoderInputEmbedDim
        encoderOutputEmbedDim
        ffnDim
        dropoutP)
     embedLayerNorm
     layerNorm
     (Dropout dropoutP)
     posEnc)
-&gt; (GTransformerDecoder
      (TransformerDecoderStack
         style
         numLayers
         gradient
         device
         dataType
         headDim
         headEmbedDim
         embedDim
         decoderInputEmbedDim
         encoderOutputEmbedDim
         ffnDim
         dropoutP)
      embedLayerNorm
      layerNorm
      (Dropout dropoutP)
      posEnc
    -&gt; IxState
         generator''''
         generator''''
         (TransformerDecoder
            style
            numLayers
            gradient
            device
            dataType
            headDim
            headEmbedDim
            embedDim
            decoderInputEmbedDim
            encoderOutputEmbedDim
            ffnDim
            posEncDim
            dropoutP))
-&gt; IxState
     generator
     generator''''
     (TransformerDecoder
        style
        numLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        decoderInputEmbedDim
        encoderOutputEmbedDim
        ffnDim
        posEncDim
        dropoutP)
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">TransformerDecoder
  style
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  decoderInputEmbedDim
  encoderOutputEmbedDim
  ffnDim
  posEncDim
  dropoutP
-&gt; IxState
     generator''''
     generator''''
     (TransformerDecoder
        style
        numLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        decoderInputEmbedDim
        encoderOutputEmbedDim
        ffnDim
        posEncDim
        dropoutP)
forall k (m :: k -&gt; k -&gt; * -&gt; *) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">(TransformerDecoder
   style
   numLayers
   gradient
   device
   dataType
   headDim
   headEmbedDim
   embedDim
   decoderInputEmbedDim
   encoderOutputEmbedDim
   ffnDim
   posEncDim
   dropoutP
 -&gt; IxState
      generator''''
      generator''''
      (TransformerDecoder
         style
         numLayers
         gradient
         device
         dataType
         headDim
         headEmbedDim
         embedDim
         decoderInputEmbedDim
         encoderOutputEmbedDim
         ffnDim
         posEncDim
         dropoutP))
-&gt; (GTransformerDecoder
      (TransformerDecoderStack
         style
         numLayers
         gradient
         device
         dataType
         headDim
         headEmbedDim
         embedDim
         decoderInputEmbedDim
         encoderOutputEmbedDim
         ffnDim
         dropoutP)
      embedLayerNorm
      layerNorm
      (Dropout dropoutP)
      posEnc
    -&gt; TransformerDecoder
         style
         numLayers
         gradient
         device
         dataType
         headDim
         headEmbedDim
         embedDim
         decoderInputEmbedDim
         encoderOutputEmbedDim
         ffnDim
         posEncDim
         dropoutP)
-&gt; GTransformerDecoder
     (TransformerDecoderStack
        style
        numLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        decoderInputEmbedDim
        encoderOutputEmbedDim
        ffnDim
        dropoutP)
     embedLayerNorm
     layerNorm
     (Dropout dropoutP)
     posEnc
-&gt; IxState
     generator''''
     generator''''
     (TransformerDecoder
        style
        numLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        decoderInputEmbedDim
        encoderOutputEmbedDim
        ffnDim
        posEncDim
        dropoutP)
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">GTransformerDecoder
  (TransformerDecoderStack
     style
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     decoderInputEmbedDim
     encoderOutputEmbedDim
     ffnDim
     dropoutP)
  embedLayerNorm
  layerNorm
  (Dropout dropoutP)
  posEnc
-&gt; TransformerDecoder
     style
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     decoderInputEmbedDim
     encoderOutputEmbedDim
     ffnDim
     posEncDim
     dropoutP
forall (style :: TransformerStyle) (numLayers :: Nat)
       (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (headDim :: Dim (Name Symbol) (Size Nat))
       (headEmbedDim :: Dim (Name Symbol) (Size Nat))
       (embedDim :: Dim (Name Symbol) (Size Nat))
       (decoderInputEmbedDim :: Dim (Name Symbol) (Size Nat))
       (encoderOutputEmbedDim :: Dim (Name Symbol) (Size Nat))
       (ffnDim :: Dim (Name Symbol) (Size Nat))
       (posEncDim :: Dim (Name Symbol) (Size Nat)) dropoutP.
GTransformerDecoder
  (TDStackF
     style
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     decoderInputEmbedDim
     encoderOutputEmbedDim
     ffnDim
     dropoutP)
  (TDEmbedLayerNormF
     style gradient device dataType decoderInputEmbedDim)
  (TDLayerNormF style gradient device dataType decoderInputEmbedDim)
  (TDDropoutF style dropoutP)
  (TDPosEncF
     style
     gradient
     device
     dataType
     headDim
     decoderInputEmbedDim
     posEncDim)
-&gt; TransformerDecoder
     style
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     decoderInputEmbedDim
     encoderOutputEmbedDim
     ffnDim
     posEncDim
     dropoutP
</span><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TransformerDecoder"><span class="hs-identifier hs-var">TransformerDecoder</span></a></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span>
</span><span id="line-277"></span><span>
</span><span id="line-278"></span><span id="local-6989586621679775637"><span id="local-6989586621679775638"><span id="local-6989586621679775639"><span id="local-6989586621679775640"><span id="local-6989586621679775641"><span id="local-6989586621679775642"><span id="local-6989586621679775643"><span id="local-6989586621679775644"><span id="local-6989586621679775645"><span id="local-6989586621679775646"><span id="local-6989586621679775647"><span id="local-6989586621679775648"><span id="local-6989586621679775649"><span class="hs-keyword">instance</span><span>
</span><span id="line-279"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-type">SingI</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775649"><span class="hs-identifier hs-type">style</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">KnownNat</span></span><span> </span><span class="annot"><a href="#local-6989586621679775648"><span class="hs-identifier hs-type">numLayers</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-280"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasStateDict"><span class="hs-identifier hs-type">HasStateDict</span></a></span><span>
</span><span id="line-281"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TransformerDecoder"><span class="hs-identifier hs-type">TransformerDecoder</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775649"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775648"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775647"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775646"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775645"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775644"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775643"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775642"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775641"><span class="hs-identifier hs-type">decoderInputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775640"><span class="hs-identifier hs-type">encoderOutputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775639"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775638"><span class="hs-identifier hs-type">posEncDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775637"><span class="hs-identifier hs-type">dropoutP</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-282"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier hs-type">SGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775647"><span class="hs-identifier hs-type">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#SDevice"><span class="hs-identifier hs-type">SDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775646"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier hs-type">SDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775645"><span class="hs-identifier hs-type">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775644"><span class="hs-identifier hs-type">headDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775643"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775642"><span class="hs-identifier hs-type">embedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775641"><span class="hs-identifier hs-type">decoderInputEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775640"><span class="hs-identifier hs-type">encoderOutputEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775639"><span class="hs-identifier hs-type">ffnDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775638"><span class="hs-identifier hs-type">posEncDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679775637"><span class="hs-identifier hs-type">dropoutP</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span class="hs-special">)</span><span>
</span><span id="line-283"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-284"></span><span>  </span><span id="local-6989586621679775633"><span class="annot"><span class="annottext">fromStateDict :: (SGradient gradient, SDevice device, SDataType dataType,
 SDim headDim, SDim headEmbedDim, SDim embedDim,
 SDim decoderInputEmbedDim, SDim encoderOutputEmbedDim, SDim ffnDim,
 SDim posEncDim, dropoutP, Double)
-&gt; StateDictKey
-&gt; m (TransformerDecoder
        style
        numLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        decoderInputEmbedDim
        encoderOutputEmbedDim
        ffnDim
        posEncDim
        dropoutP)
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var hs-var hs-var hs-var">fromStateDict</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679775631"><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679775631"><span class="hs-identifier hs-var">gradient</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679775630"><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679775630"><span class="hs-identifier hs-var">device</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679775629"><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679775629"><span class="hs-identifier hs-var">dataType</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679775628"><span class="annot"><span class="annottext">SDim headDim
</span><a href="#local-6989586621679775628"><span class="hs-identifier hs-var">headDim</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679775627"><span class="annot"><span class="annottext">SDim headEmbedDim
</span><a href="#local-6989586621679775627"><span class="hs-identifier hs-var">headEmbedDim</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679775626"><span class="annot"><span class="annottext">SDim embedDim
</span><a href="#local-6989586621679775626"><span class="hs-identifier hs-var">embedDim</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679775625"><span class="annot"><span class="annottext">SDim decoderInputEmbedDim
</span><a href="#local-6989586621679775625"><span class="hs-identifier hs-var">decoderInputEmbedDim</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679775624"><span class="annot"><span class="annottext">SDim encoderOutputEmbedDim
</span><a href="#local-6989586621679775624"><span class="hs-identifier hs-var">encoderOutputEmbedDim</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679775623"><span class="annot"><span class="annottext">SDim ffnDim
</span><a href="#local-6989586621679775623"><span class="hs-identifier hs-var">ffnDim</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679775622"><span class="annot"><span class="annottext">SDim posEncDim
</span><a href="#local-6989586621679775622"><span class="hs-identifier hs-var">posEncDim</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679775621"><span class="annot"><span class="annottext">dropoutP
</span><a href="#local-6989586621679775621"><span class="hs-identifier hs-var">dropoutP</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679775620"><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679775620"><span class="hs-identifier hs-var">eps</span></a></span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679775619"><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679775619"><span class="hs-identifier hs-var">k</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-285"></span><span>    </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679775618"><span class="annot"><span class="annottext">stack :: STransformerStyle style
-&gt; m (TransformerDecoderStack
        style
        numLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        decoderInputEmbedDim
        encoderOutputEmbedDim
        ffnDim
        dropoutP)
</span><a href="#local-6989586621679775618"><span class="hs-identifier hs-var hs-var">stack</span></a></span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(SGradient gradient, SDevice device, SDataType dataType,
 SDim headDim, SDim headEmbedDim, SDim embedDim,
 SDim decoderInputEmbedDim, SDim encoderOutputEmbedDim, SDim ffnDim,
 dropoutP, Double)
-&gt; StateDictKey
-&gt; m (TransformerDecoderStack
        'T5
        numLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        decoderInputEmbedDim
        encoderOutputEmbedDim
        ffnDim
        dropoutP)
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
input -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679775631"><span class="hs-identifier hs-var">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679775630"><span class="hs-identifier hs-var">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679775629"><span class="hs-identifier hs-var">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim headDim
</span><a href="#local-6989586621679775628"><span class="hs-identifier hs-var">headDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim headEmbedDim
</span><a href="#local-6989586621679775627"><span class="hs-identifier hs-var">headEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim embedDim
</span><a href="#local-6989586621679775626"><span class="hs-identifier hs-var">embedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim decoderInputEmbedDim
</span><a href="#local-6989586621679775625"><span class="hs-identifier hs-var">decoderInputEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim encoderOutputEmbedDim
</span><a href="#local-6989586621679775624"><span class="hs-identifier hs-var">encoderOutputEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim ffnDim
</span><a href="#local-6989586621679775623"><span class="hs-identifier hs-var">ffnDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">dropoutP
</span><a href="#local-6989586621679775621"><span class="hs-identifier hs-var">dropoutP</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679775620"><span class="hs-identifier hs-var">eps</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679775619"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;block.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-286"></span><span>        </span><span class="annot"><a href="#local-6989586621679775618"><span class="hs-identifier hs-var">stack</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(SGradient gradient, SDevice device, SDataType dataType,
 SDim headDim, SDim headEmbedDim, SDim embedDim,
 SDim decoderInputEmbedDim, SDim encoderOutputEmbedDim, SDim ffnDim,
 dropoutP, Double)
-&gt; StateDictKey
-&gt; m (TransformerDecoderStack
        'ByT5
        numLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        decoderInputEmbedDim
        encoderOutputEmbedDim
        ffnDim
        dropoutP)
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
input -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679775631"><span class="hs-identifier hs-var">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679775630"><span class="hs-identifier hs-var">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679775629"><span class="hs-identifier hs-var">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim headDim
</span><a href="#local-6989586621679775628"><span class="hs-identifier hs-var">headDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim headEmbedDim
</span><a href="#local-6989586621679775627"><span class="hs-identifier hs-var">headEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim embedDim
</span><a href="#local-6989586621679775626"><span class="hs-identifier hs-var">embedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim decoderInputEmbedDim
</span><a href="#local-6989586621679775625"><span class="hs-identifier hs-var">decoderInputEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim encoderOutputEmbedDim
</span><a href="#local-6989586621679775624"><span class="hs-identifier hs-var">encoderOutputEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim ffnDim
</span><a href="#local-6989586621679775623"><span class="hs-identifier hs-var">ffnDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">dropoutP
</span><a href="#local-6989586621679775621"><span class="hs-identifier hs-var">dropoutP</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679775620"><span class="hs-identifier hs-var">eps</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679775619"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;block.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-287"></span><span>        </span><span class="annot"><a href="#local-6989586621679775618"><span class="hs-identifier hs-var">stack</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(SGradient gradient, SDevice device, SDataType dataType,
 SDim headDim, SDim headEmbedDim, SDim embedDim,
 SDim decoderInputEmbedDim, SDim encoderOutputEmbedDim, SDim ffnDim,
 dropoutP, Double)
-&gt; StateDictKey
-&gt; m (TransformerDecoderStack
        'BART
        numLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        decoderInputEmbedDim
        encoderOutputEmbedDim
        ffnDim
        dropoutP)
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
input -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679775631"><span class="hs-identifier hs-var">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679775630"><span class="hs-identifier hs-var">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679775629"><span class="hs-identifier hs-var">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim headDim
</span><a href="#local-6989586621679775628"><span class="hs-identifier hs-var">headDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim headEmbedDim
</span><a href="#local-6989586621679775627"><span class="hs-identifier hs-var">headEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim embedDim
</span><a href="#local-6989586621679775626"><span class="hs-identifier hs-var">embedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim decoderInputEmbedDim
</span><a href="#local-6989586621679775625"><span class="hs-identifier hs-var">decoderInputEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim encoderOutputEmbedDim
</span><a href="#local-6989586621679775624"><span class="hs-identifier hs-var">encoderOutputEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim ffnDim
</span><a href="#local-6989586621679775623"><span class="hs-identifier hs-var">ffnDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">dropoutP
</span><a href="#local-6989586621679775621"><span class="hs-identifier hs-var">dropoutP</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679775620"><span class="hs-identifier hs-var">eps</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679775619"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;layers.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-288"></span><span>        </span><span class="annot"><a href="#local-6989586621679775618"><span class="hs-identifier hs-var">stack</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(SGradient gradient, SDevice device, SDataType dataType,
 SDim headDim, SDim headEmbedDim, SDim embedDim,
 SDim decoderInputEmbedDim, SDim encoderOutputEmbedDim, SDim ffnDim,
 dropoutP, Double)
-&gt; StateDictKey
-&gt; m (TransformerDecoderStack
        'MBART
        numLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        decoderInputEmbedDim
        encoderOutputEmbedDim
        ffnDim
        dropoutP)
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
input -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679775631"><span class="hs-identifier hs-var">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679775630"><span class="hs-identifier hs-var">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679775629"><span class="hs-identifier hs-var">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim headDim
</span><a href="#local-6989586621679775628"><span class="hs-identifier hs-var">headDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim headEmbedDim
</span><a href="#local-6989586621679775627"><span class="hs-identifier hs-var">headEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim embedDim
</span><a href="#local-6989586621679775626"><span class="hs-identifier hs-var">embedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim decoderInputEmbedDim
</span><a href="#local-6989586621679775625"><span class="hs-identifier hs-var">decoderInputEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim encoderOutputEmbedDim
</span><a href="#local-6989586621679775624"><span class="hs-identifier hs-var">encoderOutputEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim ffnDim
</span><a href="#local-6989586621679775623"><span class="hs-identifier hs-var">ffnDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">dropoutP
</span><a href="#local-6989586621679775621"><span class="hs-identifier hs-var">dropoutP</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679775620"><span class="hs-identifier hs-var">eps</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679775619"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;layers.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-289"></span><span>        </span><span class="annot"><a href="#local-6989586621679775618"><span class="hs-identifier hs-var">stack</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(SGradient gradient, SDevice device, SDataType dataType,
 SDim headDim, SDim headEmbedDim, SDim embedDim,
 SDim decoderInputEmbedDim, SDim encoderOutputEmbedDim, SDim ffnDim,
 dropoutP, Double)
-&gt; StateDictKey
-&gt; m (TransformerDecoderStack
        'Pegasus
        numLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        decoderInputEmbedDim
        encoderOutputEmbedDim
        ffnDim
        dropoutP)
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
input -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679775631"><span class="hs-identifier hs-var">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679775630"><span class="hs-identifier hs-var">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679775629"><span class="hs-identifier hs-var">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim headDim
</span><a href="#local-6989586621679775628"><span class="hs-identifier hs-var">headDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim headEmbedDim
</span><a href="#local-6989586621679775627"><span class="hs-identifier hs-var">headEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim embedDim
</span><a href="#local-6989586621679775626"><span class="hs-identifier hs-var">embedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim decoderInputEmbedDim
</span><a href="#local-6989586621679775625"><span class="hs-identifier hs-var">decoderInputEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim encoderOutputEmbedDim
</span><a href="#local-6989586621679775624"><span class="hs-identifier hs-var">encoderOutputEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim ffnDim
</span><a href="#local-6989586621679775623"><span class="hs-identifier hs-var">ffnDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">dropoutP
</span><a href="#local-6989586621679775621"><span class="hs-identifier hs-var">dropoutP</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679775620"><span class="hs-identifier hs-var">eps</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679775619"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;layers.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-290"></span><span>        </span><span class="annot"><a href="#local-6989586621679775618"><span class="hs-identifier hs-var">stack</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">m (TransformerDecoderStack
     style
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     decoderInputEmbedDim
     encoderOutputEmbedDim
     ffnDim
     dropoutP)
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-291"></span><span>        </span><span class="annot"><a href="#local-6989586621679775618"><span class="hs-identifier hs-var">stack</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">m (TransformerDecoderStack
     style
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     decoderInputEmbedDim
     encoderOutputEmbedDim
     ffnDim
     dropoutP)
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-292"></span><span>        </span><span class="annot"><a href="#local-6989586621679775618"><span class="hs-identifier hs-var">stack</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SGPT2"><span class="hs-identifier hs-var">SGPT2</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">m (TransformerDecoderStack
     style
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     decoderInputEmbedDim
     encoderOutputEmbedDim
     ffnDim
     dropoutP)
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-293"></span><span>        </span><span id="local-6989586621679775617"><span class="annot"><span class="annottext">embedLayerNorm :: STransformerStyle style
-&gt; m (TDEmbedLayerNormF
        style gradient device dataType decoderInputEmbedDim)
</span><a href="#local-6989586621679775617"><span class="hs-identifier hs-var hs-var">embedLayerNorm</span></a></span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">() -&gt; StateDictKey -&gt; m ()
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
input -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679775619"><span class="hs-identifier hs-var">k</span></a></span><span>
</span><span id="line-294"></span><span>        </span><span class="annot"><a href="#local-6989586621679775617"><span class="hs-identifier hs-var">embedLayerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">() -&gt; StateDictKey -&gt; m ()
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
input -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679775619"><span class="hs-identifier hs-var">k</span></a></span><span>
</span><span id="line-295"></span><span>        </span><span class="annot"><a href="#local-6989586621679775617"><span class="hs-identifier hs-var">embedLayerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(SGradient gradient, SDevice device, SDataType dataType,
 SShape ('Shape '[decoderInputEmbedDim]), Double)
-&gt; StateDictKey
-&gt; m (LayerNorm
        'WithBias
        gradient
        device
        dataType
        ('Shape '[decoderInputEmbedDim]))
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
input -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679775631"><span class="hs-identifier hs-var">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679775630"><span class="hs-identifier hs-var">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679775629"><span class="hs-identifier hs-var">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SList '[decoderInputEmbedDim]
-&gt; SShape ('Shape '[decoderInputEmbedDim])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList '[decoderInputEmbedDim]
 -&gt; SShape ('Shape '[decoderInputEmbedDim]))
-&gt; SList '[decoderInputEmbedDim]
-&gt; SShape ('Shape '[decoderInputEmbedDim])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SDim decoderInputEmbedDim
</span><a href="#local-6989586621679775625"><span class="hs-identifier hs-var">decoderInputEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim decoderInputEmbedDim
-&gt; SList '[] -&gt; SList '[decoderInputEmbedDim]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679775620"><span class="hs-identifier hs-var">eps</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679775619"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;layernorm_embedding.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-296"></span><span>        </span><span class="annot"><a href="#local-6989586621679775617"><span class="hs-identifier hs-var">embedLayerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(SGradient gradient, SDevice device, SDataType dataType,
 SShape ('Shape '[decoderInputEmbedDim]), Double)
-&gt; StateDictKey
-&gt; m (LayerNorm
        'WithBias
        gradient
        device
        dataType
        ('Shape '[decoderInputEmbedDim]))
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
input -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679775631"><span class="hs-identifier hs-var">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679775630"><span class="hs-identifier hs-var">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679775629"><span class="hs-identifier hs-var">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SList '[decoderInputEmbedDim]
-&gt; SShape ('Shape '[decoderInputEmbedDim])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList '[decoderInputEmbedDim]
 -&gt; SShape ('Shape '[decoderInputEmbedDim]))
-&gt; SList '[decoderInputEmbedDim]
-&gt; SShape ('Shape '[decoderInputEmbedDim])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SDim decoderInputEmbedDim
</span><a href="#local-6989586621679775625"><span class="hs-identifier hs-var">decoderInputEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim decoderInputEmbedDim
-&gt; SList '[] -&gt; SList '[decoderInputEmbedDim]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679775620"><span class="hs-identifier hs-var">eps</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679775619"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;layernorm_embedding.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-297"></span><span>        </span><span class="annot"><a href="#local-6989586621679775617"><span class="hs-identifier hs-var">embedLayerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">() -&gt; StateDictKey -&gt; m ()
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
input -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679775619"><span class="hs-identifier hs-var">k</span></a></span><span>
</span><span id="line-298"></span><span>        </span><span class="annot"><a href="#local-6989586621679775617"><span class="hs-identifier hs-var">embedLayerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">m (TDEmbedLayerNormF
     style gradient device dataType decoderInputEmbedDim)
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-299"></span><span>        </span><span class="annot"><a href="#local-6989586621679775617"><span class="hs-identifier hs-var">embedLayerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">m (TDEmbedLayerNormF
     style gradient device dataType decoderInputEmbedDim)
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-300"></span><span>        </span><span class="annot"><a href="#local-6989586621679775617"><span class="hs-identifier hs-var">embedLayerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SGPT2"><span class="hs-identifier hs-var">SGPT2</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">m (TDEmbedLayerNormF
     style gradient device dataType decoderInputEmbedDim)
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-301"></span><span>        </span><span id="local-6989586621679775616"><span class="annot"><span class="annottext">layerNorm :: STransformerStyle style
-&gt; m (TDLayerNormF
        style gradient device dataType decoderInputEmbedDim)
</span><a href="#local-6989586621679775616"><span class="hs-identifier hs-var hs-var">layerNorm</span></a></span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(SGradient gradient, SDevice device, SDataType dataType,
 SShape ('Shape '[decoderInputEmbedDim]), Double)
-&gt; StateDictKey
-&gt; m (LayerNorm
        'WithoutBias
        gradient
        device
        dataType
        ('Shape '[decoderInputEmbedDim]))
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
input -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679775631"><span class="hs-identifier hs-var">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679775630"><span class="hs-identifier hs-var">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679775629"><span class="hs-identifier hs-var">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SList '[decoderInputEmbedDim]
-&gt; SShape ('Shape '[decoderInputEmbedDim])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList '[decoderInputEmbedDim]
 -&gt; SShape ('Shape '[decoderInputEmbedDim]))
-&gt; SList '[decoderInputEmbedDim]
-&gt; SShape ('Shape '[decoderInputEmbedDim])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SDim decoderInputEmbedDim
</span><a href="#local-6989586621679775625"><span class="hs-identifier hs-var">decoderInputEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim decoderInputEmbedDim
-&gt; SList '[] -&gt; SList '[decoderInputEmbedDim]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679775620"><span class="hs-identifier hs-var">eps</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679775619"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;final_layer_norm.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-302"></span><span>        </span><span class="annot"><a href="#local-6989586621679775616"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(SGradient gradient, SDevice device, SDataType dataType,
 SShape ('Shape '[decoderInputEmbedDim]), Double)
-&gt; StateDictKey
-&gt; m (LayerNorm
        'WithoutBias
        gradient
        device
        dataType
        ('Shape '[decoderInputEmbedDim]))
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
input -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679775631"><span class="hs-identifier hs-var">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679775630"><span class="hs-identifier hs-var">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679775629"><span class="hs-identifier hs-var">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SList '[decoderInputEmbedDim]
-&gt; SShape ('Shape '[decoderInputEmbedDim])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList '[decoderInputEmbedDim]
 -&gt; SShape ('Shape '[decoderInputEmbedDim]))
-&gt; SList '[decoderInputEmbedDim]
-&gt; SShape ('Shape '[decoderInputEmbedDim])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SDim decoderInputEmbedDim
</span><a href="#local-6989586621679775625"><span class="hs-identifier hs-var">decoderInputEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim decoderInputEmbedDim
-&gt; SList '[] -&gt; SList '[decoderInputEmbedDim]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679775620"><span class="hs-identifier hs-var">eps</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679775619"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;final_layer_norm.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-303"></span><span>        </span><span class="annot"><a href="#local-6989586621679775616"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">() -&gt; StateDictKey -&gt; m ()
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
input -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679775619"><span class="hs-identifier hs-var">k</span></a></span><span>
</span><span id="line-304"></span><span>        </span><span class="annot"><a href="#local-6989586621679775616"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">() -&gt; StateDictKey -&gt; m ()
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
input -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679775619"><span class="hs-identifier hs-var">k</span></a></span><span>
</span><span id="line-305"></span><span>        </span><span class="annot"><a href="#local-6989586621679775616"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(SGradient gradient, SDevice device, SDataType dataType,
 SShape ('Shape '[decoderInputEmbedDim]), Double)
-&gt; StateDictKey
-&gt; m (LayerNorm
        'WithBias
        gradient
        device
        dataType
        ('Shape '[decoderInputEmbedDim]))
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
input -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679775631"><span class="hs-identifier hs-var">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679775630"><span class="hs-identifier hs-var">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679775629"><span class="hs-identifier hs-var">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SList '[decoderInputEmbedDim]
-&gt; SShape ('Shape '[decoderInputEmbedDim])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList '[decoderInputEmbedDim]
 -&gt; SShape ('Shape '[decoderInputEmbedDim]))
-&gt; SList '[decoderInputEmbedDim]
-&gt; SShape ('Shape '[decoderInputEmbedDim])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SDim decoderInputEmbedDim
</span><a href="#local-6989586621679775625"><span class="hs-identifier hs-var">decoderInputEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim decoderInputEmbedDim
-&gt; SList '[] -&gt; SList '[decoderInputEmbedDim]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679775620"><span class="hs-identifier hs-var">eps</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679775619"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;layer_norm.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-306"></span><span>        </span><span class="annot"><a href="#local-6989586621679775616"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">m (TDLayerNormF
     style gradient device dataType decoderInputEmbedDim)
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-307"></span><span>        </span><span class="annot"><a href="#local-6989586621679775616"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">m (TDLayerNormF
     style gradient device dataType decoderInputEmbedDim)
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-308"></span><span>        </span><span class="annot"><a href="#local-6989586621679775616"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SGPT2"><span class="hs-identifier hs-var">SGPT2</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">m (TDLayerNormF
     style gradient device dataType decoderInputEmbedDim)
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-309"></span><span>        </span><span id="local-6989586621679775615"><span class="annot"><span class="annottext">dropout :: STransformerStyle style -&gt; m (Dropout dropoutP)
</span><a href="#local-6989586621679775615"><span class="hs-identifier hs-var hs-var">dropout</span></a></span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">dropoutP -&gt; StateDictKey -&gt; m (Dropout dropoutP)
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
input -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">dropoutP
</span><a href="#local-6989586621679775621"><span class="hs-identifier hs-var">dropoutP</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679775619"><span class="hs-identifier hs-var">k</span></a></span><span>
</span><span id="line-310"></span><span>        </span><span id="local-6989586621679775614"><span class="annot"><span class="annottext">posEnc :: STransformerStyle style
-&gt; m (TDPosEncF
        style
        gradient
        device
        dataType
        headDim
        decoderInputEmbedDim
        posEncDim)
</span><a href="#local-6989586621679775614"><span class="hs-identifier hs-var hs-var">posEnc</span></a></span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(SGradient gradient, SLayout ('Layout 'Dense), SDevice device,
 SDataType dataType, SDim posEncDim, SDim headDim)
-&gt; StateDictKey
-&gt; m (Embedding
        gradient
        ('Layout 'Dense)
        device
        dataType
        posEncDim
        headDim
        'Nothing)
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
input -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679775631"><span class="hs-identifier hs-var">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SLayoutType 'Dense -&gt; SLayout ('Layout 'Dense)
forall (layoutType :: LayoutType).
SLayoutType layoutType -&gt; SLayout ('Layout layoutType)
</span><a href="Torch.GraduallyTyped.Layout.html#SLayout"><span class="hs-identifier hs-var">SLayout</span></a></span><span> </span><span class="annot"><span class="annottext">SLayoutType 'Dense
</span><a href="Torch.GraduallyTyped.Layout.html#SDense"><span class="hs-identifier hs-var">SDense</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679775630"><span class="hs-identifier hs-var">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679775629"><span class="hs-identifier hs-var">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim posEncDim
</span><a href="#local-6989586621679775622"><span class="hs-identifier hs-var">posEncDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim headDim
</span><a href="#local-6989586621679775628"><span class="hs-identifier hs-var">headDim</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679775619"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;block.0.layer.0.SelfAttention.relative_attention_bias.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-311"></span><span>        </span><span class="annot"><a href="#local-6989586621679775614"><span class="hs-identifier hs-var">posEnc</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(SGradient gradient, SLayout ('Layout 'Dense), SDevice device,
 SDataType dataType, SDim posEncDim, SDim headDim)
-&gt; StateDictKey
-&gt; m (Embedding
        gradient
        ('Layout 'Dense)
        device
        dataType
        posEncDim
        headDim
        'Nothing)
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
input -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679775631"><span class="hs-identifier hs-var">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SLayoutType 'Dense -&gt; SLayout ('Layout 'Dense)
forall (layoutType :: LayoutType).
SLayoutType layoutType -&gt; SLayout ('Layout layoutType)
</span><a href="Torch.GraduallyTyped.Layout.html#SLayout"><span class="hs-identifier hs-var">SLayout</span></a></span><span> </span><span class="annot"><span class="annottext">SLayoutType 'Dense
</span><a href="Torch.GraduallyTyped.Layout.html#SDense"><span class="hs-identifier hs-var">SDense</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679775630"><span class="hs-identifier hs-var">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679775629"><span class="hs-identifier hs-var">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim posEncDim
</span><a href="#local-6989586621679775622"><span class="hs-identifier hs-var">posEncDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim headDim
</span><a href="#local-6989586621679775628"><span class="hs-identifier hs-var">headDim</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679775619"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;block.0.layer.0.SelfAttention.relative_attention_bias.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-312"></span><span>        </span><span class="annot"><a href="#local-6989586621679775614"><span class="hs-identifier hs-var">posEnc</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(SGradient gradient, SLayout ('Layout 'Dense), SDevice device,
 SDataType dataType, SDim posEncDim, SDim decoderInputEmbedDim)
-&gt; StateDictKey
-&gt; m (Embedding
        gradient
        ('Layout 'Dense)
        device
        dataType
        posEncDim
        decoderInputEmbedDim
        'Nothing)
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
input -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679775631"><span class="hs-identifier hs-var">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SLayoutType 'Dense -&gt; SLayout ('Layout 'Dense)
forall (layoutType :: LayoutType).
SLayoutType layoutType -&gt; SLayout ('Layout layoutType)
</span><a href="Torch.GraduallyTyped.Layout.html#SLayout"><span class="hs-identifier hs-var">SLayout</span></a></span><span> </span><span class="annot"><span class="annottext">SLayoutType 'Dense
</span><a href="Torch.GraduallyTyped.Layout.html#SDense"><span class="hs-identifier hs-var">SDense</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679775630"><span class="hs-identifier hs-var">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679775629"><span class="hs-identifier hs-var">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim posEncDim
</span><a href="#local-6989586621679775622"><span class="hs-identifier hs-var">posEncDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim decoderInputEmbedDim
</span><a href="#local-6989586621679775625"><span class="hs-identifier hs-var">decoderInputEmbedDim</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679775619"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;embed_positions.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-313"></span><span>        </span><span class="annot"><a href="#local-6989586621679775614"><span class="hs-identifier hs-var">posEnc</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(SGradient gradient, SLayout ('Layout 'Dense), SDevice device,
 SDataType dataType, SDim posEncDim, SDim decoderInputEmbedDim)
-&gt; StateDictKey
-&gt; m (Embedding
        gradient
        ('Layout 'Dense)
        device
        dataType
        posEncDim
        decoderInputEmbedDim
        'Nothing)
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
input -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679775631"><span class="hs-identifier hs-var">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SLayoutType 'Dense -&gt; SLayout ('Layout 'Dense)
forall (layoutType :: LayoutType).
SLayoutType layoutType -&gt; SLayout ('Layout layoutType)
</span><a href="Torch.GraduallyTyped.Layout.html#SLayout"><span class="hs-identifier hs-var">SLayout</span></a></span><span> </span><span class="annot"><span class="annottext">SLayoutType 'Dense
</span><a href="Torch.GraduallyTyped.Layout.html#SDense"><span class="hs-identifier hs-var">SDense</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679775630"><span class="hs-identifier hs-var">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679775629"><span class="hs-identifier hs-var">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim posEncDim
</span><a href="#local-6989586621679775622"><span class="hs-identifier hs-var">posEncDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim decoderInputEmbedDim
</span><a href="#local-6989586621679775625"><span class="hs-identifier hs-var">decoderInputEmbedDim</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679775619"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;embed_positions.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-314"></span><span>        </span><span class="annot"><a href="#local-6989586621679775614"><span class="hs-identifier hs-var">posEnc</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(SGradient gradient, SLayout ('Layout 'Dense), SDevice device,
 SDataType dataType, SDim posEncDim, SDim decoderInputEmbedDim)
-&gt; StateDictKey
-&gt; m (Embedding
        gradient
        ('Layout 'Dense)
        device
        dataType
        posEncDim
        decoderInputEmbedDim
        'Nothing)
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
input -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679775631"><span class="hs-identifier hs-var">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SLayoutType 'Dense -&gt; SLayout ('Layout 'Dense)
forall (layoutType :: LayoutType).
SLayoutType layoutType -&gt; SLayout ('Layout layoutType)
</span><a href="Torch.GraduallyTyped.Layout.html#SLayout"><span class="hs-identifier hs-var">SLayout</span></a></span><span> </span><span class="annot"><span class="annottext">SLayoutType 'Dense
</span><a href="Torch.GraduallyTyped.Layout.html#SDense"><span class="hs-identifier hs-var">SDense</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679775630"><span class="hs-identifier hs-var">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679775629"><span class="hs-identifier hs-var">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim posEncDim
</span><a href="#local-6989586621679775622"><span class="hs-identifier hs-var">posEncDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim decoderInputEmbedDim
</span><a href="#local-6989586621679775625"><span class="hs-identifier hs-var">decoderInputEmbedDim</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679775619"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;embed_positions.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-315"></span><span>        </span><span class="annot"><a href="#local-6989586621679775614"><span class="hs-identifier hs-var">posEnc</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">m (TDPosEncF
     style
     gradient
     device
     dataType
     headDim
     decoderInputEmbedDim
     posEncDim)
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-316"></span><span>        </span><span class="annot"><a href="#local-6989586621679775614"><span class="hs-identifier hs-var">posEnc</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">m (TDPosEncF
     style
     gradient
     device
     dataType
     headDim
     decoderInputEmbedDim
     posEncDim)
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-317"></span><span>        </span><span class="annot"><a href="#local-6989586621679775614"><span class="hs-identifier hs-var">posEnc</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SGPT2"><span class="hs-identifier hs-var">SGPT2</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">m (TDPosEncF
     style
     gradient
     device
     dataType
     headDim
     decoderInputEmbedDim
     posEncDim)
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-318"></span><span>     </span><span class="hs-keyword">in</span><span> </span><span class="annot"><span class="annottext">GTransformerDecoder
  (TransformerDecoderStack
     style
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     decoderInputEmbedDim
     encoderOutputEmbedDim
     ffnDim
     dropoutP)
  (TDEmbedLayerNormF
     style gradient device dataType decoderInputEmbedDim)
  (TDLayerNormF style gradient device dataType decoderInputEmbedDim)
  (Dropout dropoutP)
  (TDPosEncF
     style
     gradient
     device
     dataType
     headDim
     decoderInputEmbedDim
     posEncDim)
-&gt; TransformerDecoder
     style
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     decoderInputEmbedDim
     encoderOutputEmbedDim
     ffnDim
     posEncDim
     dropoutP
forall (style :: TransformerStyle) (numLayers :: Nat)
       (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (headDim :: Dim (Name Symbol) (Size Nat))
       (headEmbedDim :: Dim (Name Symbol) (Size Nat))
       (embedDim :: Dim (Name Symbol) (Size Nat))
       (decoderInputEmbedDim :: Dim (Name Symbol) (Size Nat))
       (encoderOutputEmbedDim :: Dim (Name Symbol) (Size Nat))
       (ffnDim :: Dim (Name Symbol) (Size Nat))
       (posEncDim :: Dim (Name Symbol) (Size Nat)) dropoutP.
GTransformerDecoder
  (TDStackF
     style
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     decoderInputEmbedDim
     encoderOutputEmbedDim
     ffnDim
     dropoutP)
  (TDEmbedLayerNormF
     style gradient device dataType decoderInputEmbedDim)
  (TDLayerNormF style gradient device dataType decoderInputEmbedDim)
  (TDDropoutF style dropoutP)
  (TDPosEncF
     style
     gradient
     device
     dataType
     headDim
     decoderInputEmbedDim
     posEncDim)
-&gt; TransformerDecoder
     style
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     decoderInputEmbedDim
     encoderOutputEmbedDim
     ffnDim
     posEncDim
     dropoutP
</span><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TransformerDecoder"><span class="hs-identifier hs-var">TransformerDecoder</span></a></span><span>
</span><span id="line-319"></span><span>          </span><span class="annot"><span class="annottext">(GTransformerDecoder
   (TransformerDecoderStack
      style
      numLayers
      gradient
      device
      dataType
      headDim
      headEmbedDim
      embedDim
      decoderInputEmbedDim
      encoderOutputEmbedDim
      ffnDim
      dropoutP)
   (TDEmbedLayerNormF
      style gradient device dataType decoderInputEmbedDim)
   (TDLayerNormF style gradient device dataType decoderInputEmbedDim)
   (Dropout dropoutP)
   (TDPosEncF
      style
      gradient
      device
      dataType
      headDim
      decoderInputEmbedDim
      posEncDim)
 -&gt; TransformerDecoder
      style
      numLayers
      gradient
      device
      dataType
      headDim
      headEmbedDim
      embedDim
      decoderInputEmbedDim
      encoderOutputEmbedDim
      ffnDim
      posEncDim
      dropoutP)
-&gt; m (GTransformerDecoder
        (TransformerDecoderStack
           style
           numLayers
           gradient
           device
           dataType
           headDim
           headEmbedDim
           embedDim
           decoderInputEmbedDim
           encoderOutputEmbedDim
           ffnDim
           dropoutP)
        (TDEmbedLayerNormF
           style gradient device dataType decoderInputEmbedDim)
        (TDLayerNormF style gradient device dataType decoderInputEmbedDim)
        (Dropout dropoutP)
        (TDPosEncF
           style
           gradient
           device
           dataType
           headDim
           decoderInputEmbedDim
           posEncDim))
-&gt; m (TransformerDecoder
        style
        numLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        decoderInputEmbedDim
        encoderOutputEmbedDim
        ffnDim
        posEncDim
        dropoutP)
forall (f :: * -&gt; *) a b. Functor f =&gt; (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;$&gt;</span></span><span> </span><span class="hs-special">(</span><span> </span><span class="annot"><span class="annottext">TransformerDecoderStack
  style
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  decoderInputEmbedDim
  encoderOutputEmbedDim
  ffnDim
  dropoutP
-&gt; TDEmbedLayerNormF
     style gradient device dataType decoderInputEmbedDim
-&gt; TDLayerNormF style gradient device dataType decoderInputEmbedDim
-&gt; Dropout dropoutP
-&gt; TDPosEncF
     style
     gradient
     device
     dataType
     headDim
     decoderInputEmbedDim
     posEncDim
-&gt; GTransformerDecoder
     (TransformerDecoderStack
        style
        numLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        decoderInputEmbedDim
        encoderOutputEmbedDim
        ffnDim
        dropoutP)
     (TDEmbedLayerNormF
        style gradient device dataType decoderInputEmbedDim)
     (TDLayerNormF style gradient device dataType decoderInputEmbedDim)
     (Dropout dropoutP)
     (TDPosEncF
        style
        gradient
        device
        dataType
        headDim
        decoderInputEmbedDim
        posEncDim)
forall stack embedLayerNorm layerNorm dropout posEnc.
stack
-&gt; embedLayerNorm
-&gt; layerNorm
-&gt; dropout
-&gt; posEnc
-&gt; GTransformerDecoder
     stack embedLayerNorm layerNorm dropout posEnc
</span><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#GTransformerDecoder"><span class="hs-identifier hs-var">GTransformerDecoder</span></a></span><span>
</span><span id="line-320"></span><span>                  </span><span class="annot"><span class="annottext">(TransformerDecoderStack
   style
   numLayers
   gradient
   device
   dataType
   headDim
   headEmbedDim
   embedDim
   decoderInputEmbedDim
   encoderOutputEmbedDim
   ffnDim
   dropoutP
 -&gt; TDEmbedLayerNormF
      style gradient device dataType decoderInputEmbedDim
 -&gt; TDLayerNormF style gradient device dataType decoderInputEmbedDim
 -&gt; Dropout dropoutP
 -&gt; TDPosEncF
      style
      gradient
      device
      dataType
      headDim
      decoderInputEmbedDim
      posEncDim
 -&gt; GTransformerDecoder
      (TransformerDecoderStack
         style
         numLayers
         gradient
         device
         dataType
         headDim
         headEmbedDim
         embedDim
         decoderInputEmbedDim
         encoderOutputEmbedDim
         ffnDim
         dropoutP)
      (TDEmbedLayerNormF
         style gradient device dataType decoderInputEmbedDim)
      (TDLayerNormF style gradient device dataType decoderInputEmbedDim)
      (Dropout dropoutP)
      (TDPosEncF
         style
         gradient
         device
         dataType
         headDim
         decoderInputEmbedDim
         posEncDim))
-&gt; m (TransformerDecoderStack
        style
        numLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        decoderInputEmbedDim
        encoderOutputEmbedDim
        ffnDim
        dropoutP)
-&gt; m (TDEmbedLayerNormF
        style gradient device dataType decoderInputEmbedDim
      -&gt; TDLayerNormF style gradient device dataType decoderInputEmbedDim
      -&gt; Dropout dropoutP
      -&gt; TDPosEncF
           style
           gradient
           device
           dataType
           headDim
           decoderInputEmbedDim
           posEncDim
      -&gt; GTransformerDecoder
           (TransformerDecoderStack
              style
              numLayers
              gradient
              device
              dataType
              headDim
              headEmbedDim
              embedDim
              decoderInputEmbedDim
              encoderOutputEmbedDim
              ffnDim
              dropoutP)
           (TDEmbedLayerNormF
              style gradient device dataType decoderInputEmbedDim)
           (TDLayerNormF style gradient device dataType decoderInputEmbedDim)
           (Dropout dropoutP)
           (TDPosEncF
              style
              gradient
              device
              dataType
              headDim
              decoderInputEmbedDim
              posEncDim))
forall (f :: * -&gt; *) a b. Functor f =&gt; (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;$&gt;</span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; m (TransformerDecoderStack
        style
        numLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        decoderInputEmbedDim
        encoderOutputEmbedDim
        ffnDim
        dropoutP)
</span><a href="#local-6989586621679775618"><span class="hs-identifier hs-var">stack</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SingI style =&gt; Sing style
forall k (a :: k). SingI a =&gt; Sing a
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">sing</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679775649"><span class="hs-identifier hs-type">style</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-321"></span><span>                  </span><span class="annot"><span class="annottext">m (TDEmbedLayerNormF
     style gradient device dataType decoderInputEmbedDim
   -&gt; TDLayerNormF style gradient device dataType decoderInputEmbedDim
   -&gt; Dropout dropoutP
   -&gt; TDPosEncF
        style
        gradient
        device
        dataType
        headDim
        decoderInputEmbedDim
        posEncDim
   -&gt; GTransformerDecoder
        (TransformerDecoderStack
           style
           numLayers
           gradient
           device
           dataType
           headDim
           headEmbedDim
           embedDim
           decoderInputEmbedDim
           encoderOutputEmbedDim
           ffnDim
           dropoutP)
        (TDEmbedLayerNormF
           style gradient device dataType decoderInputEmbedDim)
        (TDLayerNormF style gradient device dataType decoderInputEmbedDim)
        (Dropout dropoutP)
        (TDPosEncF
           style
           gradient
           device
           dataType
           headDim
           decoderInputEmbedDim
           posEncDim))
-&gt; m (TDEmbedLayerNormF
        style gradient device dataType decoderInputEmbedDim)
-&gt; m (TDLayerNormF
        style gradient device dataType decoderInputEmbedDim
      -&gt; Dropout dropoutP
      -&gt; TDPosEncF
           style
           gradient
           device
           dataType
           headDim
           decoderInputEmbedDim
           posEncDim
      -&gt; GTransformerDecoder
           (TransformerDecoderStack
              style
              numLayers
              gradient
              device
              dataType
              headDim
              headEmbedDim
              embedDim
              decoderInputEmbedDim
              encoderOutputEmbedDim
              ffnDim
              dropoutP)
           (TDEmbedLayerNormF
              style gradient device dataType decoderInputEmbedDim)
           (TDLayerNormF style gradient device dataType decoderInputEmbedDim)
           (Dropout dropoutP)
           (TDPosEncF
              style
              gradient
              device
              dataType
              headDim
              decoderInputEmbedDim
              posEncDim))
forall (f :: * -&gt; *) a b. Applicative f =&gt; f (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;*&gt;</span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; m (TDEmbedLayerNormF
        style gradient device dataType decoderInputEmbedDim)
</span><a href="#local-6989586621679775617"><span class="hs-identifier hs-var">embedLayerNorm</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SingI style =&gt; Sing style
forall k (a :: k). SingI a =&gt; Sing a
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">sing</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679775649"><span class="hs-identifier hs-type">style</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-322"></span><span>                  </span><span class="annot"><span class="annottext">m (TDLayerNormF style gradient device dataType decoderInputEmbedDim
   -&gt; Dropout dropoutP
   -&gt; TDPosEncF
        style
        gradient
        device
        dataType
        headDim
        decoderInputEmbedDim
        posEncDim
   -&gt; GTransformerDecoder
        (TransformerDecoderStack
           style
           numLayers
           gradient
           device
           dataType
           headDim
           headEmbedDim
           embedDim
           decoderInputEmbedDim
           encoderOutputEmbedDim
           ffnDim
           dropoutP)
        (TDEmbedLayerNormF
           style gradient device dataType decoderInputEmbedDim)
        (TDLayerNormF style gradient device dataType decoderInputEmbedDim)
        (Dropout dropoutP)
        (TDPosEncF
           style
           gradient
           device
           dataType
           headDim
           decoderInputEmbedDim
           posEncDim))
-&gt; m (TDLayerNormF
        style gradient device dataType decoderInputEmbedDim)
-&gt; m (Dropout dropoutP
      -&gt; TDPosEncF
           style
           gradient
           device
           dataType
           headDim
           decoderInputEmbedDim
           posEncDim
      -&gt; GTransformerDecoder
           (TransformerDecoderStack
              style
              numLayers
              gradient
              device
              dataType
              headDim
              headEmbedDim
              embedDim
              decoderInputEmbedDim
              encoderOutputEmbedDim
              ffnDim
              dropoutP)
           (TDEmbedLayerNormF
              style gradient device dataType decoderInputEmbedDim)
           (TDLayerNormF style gradient device dataType decoderInputEmbedDim)
           (Dropout dropoutP)
           (TDPosEncF
              style
              gradient
              device
              dataType
              headDim
              decoderInputEmbedDim
              posEncDim))
forall (f :: * -&gt; *) a b. Applicative f =&gt; f (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;*&gt;</span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; m (TDLayerNormF
        style gradient device dataType decoderInputEmbedDim)
</span><a href="#local-6989586621679775616"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SingI style =&gt; Sing style
forall k (a :: k). SingI a =&gt; Sing a
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">sing</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679775649"><span class="hs-identifier hs-type">style</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-323"></span><span>                  </span><span class="annot"><span class="annottext">m (Dropout dropoutP
   -&gt; TDPosEncF
        style
        gradient
        device
        dataType
        headDim
        decoderInputEmbedDim
        posEncDim
   -&gt; GTransformerDecoder
        (TransformerDecoderStack
           style
           numLayers
           gradient
           device
           dataType
           headDim
           headEmbedDim
           embedDim
           decoderInputEmbedDim
           encoderOutputEmbedDim
           ffnDim
           dropoutP)
        (TDEmbedLayerNormF
           style gradient device dataType decoderInputEmbedDim)
        (TDLayerNormF style gradient device dataType decoderInputEmbedDim)
        (Dropout dropoutP)
        (TDPosEncF
           style
           gradient
           device
           dataType
           headDim
           decoderInputEmbedDim
           posEncDim))
-&gt; m (Dropout dropoutP)
-&gt; m (TDPosEncF
        style
        gradient
        device
        dataType
        headDim
        decoderInputEmbedDim
        posEncDim
      -&gt; GTransformerDecoder
           (TransformerDecoderStack
              style
              numLayers
              gradient
              device
              dataType
              headDim
              headEmbedDim
              embedDim
              decoderInputEmbedDim
              encoderOutputEmbedDim
              ffnDim
              dropoutP)
           (TDEmbedLayerNormF
              style gradient device dataType decoderInputEmbedDim)
           (TDLayerNormF style gradient device dataType decoderInputEmbedDim)
           (Dropout dropoutP)
           (TDPosEncF
              style
              gradient
              device
              dataType
              headDim
              decoderInputEmbedDim
              posEncDim))
forall (f :: * -&gt; *) a b. Applicative f =&gt; f (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;*&gt;</span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style -&gt; m (Dropout dropoutP)
</span><a href="#local-6989586621679775615"><span class="hs-identifier hs-var">dropout</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SingI style =&gt; Sing style
forall k (a :: k). SingI a =&gt; Sing a
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">sing</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679775649"><span class="hs-identifier hs-type">style</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-324"></span><span>                  </span><span class="annot"><span class="annottext">m (TDPosEncF
     style
     gradient
     device
     dataType
     headDim
     decoderInputEmbedDim
     posEncDim
   -&gt; GTransformerDecoder
        (TransformerDecoderStack
           style
           numLayers
           gradient
           device
           dataType
           headDim
           headEmbedDim
           embedDim
           decoderInputEmbedDim
           encoderOutputEmbedDim
           ffnDim
           dropoutP)
        (TDEmbedLayerNormF
           style gradient device dataType decoderInputEmbedDim)
        (TDLayerNormF style gradient device dataType decoderInputEmbedDim)
        (Dropout dropoutP)
        (TDPosEncF
           style
           gradient
           device
           dataType
           headDim
           decoderInputEmbedDim
           posEncDim))
-&gt; m (TDPosEncF
        style
        gradient
        device
        dataType
        headDim
        decoderInputEmbedDim
        posEncDim)
-&gt; m (GTransformerDecoder
        (TransformerDecoderStack
           style
           numLayers
           gradient
           device
           dataType
           headDim
           headEmbedDim
           embedDim
           decoderInputEmbedDim
           encoderOutputEmbedDim
           ffnDim
           dropoutP)
        (TDEmbedLayerNormF
           style gradient device dataType decoderInputEmbedDim)
        (TDLayerNormF style gradient device dataType decoderInputEmbedDim)
        (Dropout dropoutP)
        (TDPosEncF
           style
           gradient
           device
           dataType
           headDim
           decoderInputEmbedDim
           posEncDim))
forall (f :: * -&gt; *) a b. Applicative f =&gt; f (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;*&gt;</span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; m (TDPosEncF
        style
        gradient
        device
        dataType
        headDim
        decoderInputEmbedDim
        posEncDim)
</span><a href="#local-6989586621679775614"><span class="hs-identifier hs-var">posEnc</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SingI style =&gt; Sing style
forall k (a :: k). SingI a =&gt; Sing a
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">sing</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679775649"><span class="hs-identifier hs-type">style</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-325"></span><span>              </span><span class="hs-special">)</span><span>
</span><span id="line-326"></span><span>  </span><span id="local-6989586621679775612"><span class="annot"><span class="annottext">toStateDict :: StateDictKey
-&gt; TransformerDecoder
     style
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     decoderInputEmbedDim
     encoderOutputEmbedDim
     ffnDim
     posEncDim
     dropoutP
-&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var hs-var hs-var hs-var">toStateDict</span></a></span></span><span> </span><span id="local-6989586621679775610"><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679775610"><span class="hs-identifier hs-var">k</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TransformerDecoder"><span class="hs-identifier hs-type">TransformerDecoder</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#GTransformerDecoder"><span class="hs-identifier hs-type">GTransformerDecoder</span></a></span><span> </span><span class="hs-special">{</span><span id="local-6989586621679775605"><span id="local-6989586621679775606"><span id="local-6989586621679775607"><span id="local-6989586621679775608"><span id="local-6989586621679775609"><span class="annot"><span class="annottext">TDPosEncF
  style
  gradient
  device
  dataType
  headDim
  decoderInputEmbedDim
  posEncDim
TDDropoutF style dropoutP
TDLayerNormF style gradient device dataType decoderInputEmbedDim
TDEmbedLayerNormF
  style gradient device dataType decoderInputEmbedDim
TDStackF
  style
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  decoderInputEmbedDim
  encoderOutputEmbedDim
  ffnDim
  dropoutP
tdPosEnc :: TDPosEncF
  style
  gradient
  device
  dataType
  headDim
  decoderInputEmbedDim
  posEncDim
tdDropout :: TDDropoutF style dropoutP
tdLayerNorm :: TDLayerNormF style gradient device dataType decoderInputEmbedDim
tdEmbedLayerNorm :: TDEmbedLayerNormF
  style gradient device dataType decoderInputEmbedDim
tdStack :: TDStackF
  style
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  decoderInputEmbedDim
  encoderOutputEmbedDim
  ffnDim
  dropoutP
tdPosEnc :: forall stack embedLayerNorm layerNorm dropout posEnc.
GTransformerDecoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; posEnc
tdDropout :: forall stack embedLayerNorm layerNorm dropout posEnc.
GTransformerDecoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; dropout
tdLayerNorm :: forall stack embedLayerNorm layerNorm dropout posEnc.
GTransformerDecoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; layerNorm
tdEmbedLayerNorm :: forall stack embedLayerNorm layerNorm dropout posEnc.
GTransformerDecoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; embedLayerNorm
tdStack :: forall stack embedLayerNorm layerNorm dropout posEnc.
GTransformerDecoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; stack
</span><a href="#local-6989586621679775605"><span class="hs-glyph hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">..</span></a></span></span></span></span></span></span><span class="hs-special">}</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-327"></span><span>    </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679775604"><span class="annot"><span class="annottext">stack :: STransformerStyle style
-&gt; TransformerDecoderStack
     style
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     decoderInputEmbedDim
     encoderOutputEmbedDim
     ffnDim
     dropoutP
-&gt; m ()
</span><a href="#local-6989586621679775604"><span class="hs-identifier hs-var hs-var">stack</span></a></span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; TransformerDecoderStack
     'T5
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     decoderInputEmbedDim
     encoderOutputEmbedDim
     ffnDim
     dropoutP
-&gt; m ()
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679775610"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;block.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-328"></span><span>        </span><span class="annot"><a href="#local-6989586621679775604"><span class="hs-identifier hs-var">stack</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; TransformerDecoderStack
     'ByT5
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     decoderInputEmbedDim
     encoderOutputEmbedDim
     ffnDim
     dropoutP
-&gt; m ()
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679775610"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;block.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-329"></span><span>        </span><span class="annot"><a href="#local-6989586621679775604"><span class="hs-identifier hs-var">stack</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; TransformerDecoderStack
     'BART
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     decoderInputEmbedDim
     encoderOutputEmbedDim
     ffnDim
     dropoutP
-&gt; m ()
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679775610"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;layers.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-330"></span><span>        </span><span class="annot"><a href="#local-6989586621679775604"><span class="hs-identifier hs-var">stack</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; TransformerDecoderStack
     'MBART
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     decoderInputEmbedDim
     encoderOutputEmbedDim
     ffnDim
     dropoutP
-&gt; m ()
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679775610"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;layers.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-331"></span><span>        </span><span class="annot"><a href="#local-6989586621679775604"><span class="hs-identifier hs-var">stack</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; TransformerDecoderStack
     'Pegasus
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     decoderInputEmbedDim
     encoderOutputEmbedDim
     ffnDim
     dropoutP
-&gt; m ()
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679775610"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;layers.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-332"></span><span>        </span><span class="annot"><a href="#local-6989586621679775604"><span class="hs-identifier hs-var">stack</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">TransformerDecoderStack
  style
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  decoderInputEmbedDim
  encoderOutputEmbedDim
  ffnDim
  dropoutP
-&gt; m ()
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-333"></span><span>        </span><span class="annot"><a href="#local-6989586621679775604"><span class="hs-identifier hs-var">stack</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">TransformerDecoderStack
  style
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  decoderInputEmbedDim
  encoderOutputEmbedDim
  ffnDim
  dropoutP
-&gt; m ()
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-334"></span><span>        </span><span class="annot"><a href="#local-6989586621679775604"><span class="hs-identifier hs-var">stack</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SGPT2"><span class="hs-identifier hs-var">SGPT2</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">TransformerDecoderStack
  style
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  decoderInputEmbedDim
  encoderOutputEmbedDim
  ffnDim
  dropoutP
-&gt; m ()
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-335"></span><span>        </span><span id="local-6989586621679775603"><span class="annot"><span class="annottext">embedLayerNorm :: STransformerStyle style
-&gt; TDEmbedLayerNormF
     style gradient device dataType decoderInputEmbedDim
-&gt; m ()
</span><a href="#local-6989586621679775603"><span class="hs-identifier hs-var hs-var">embedLayerNorm</span></a></span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; () -&gt; m ()
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679775610"><span class="hs-identifier hs-var">k</span></a></span><span>
</span><span id="line-336"></span><span>        </span><span class="annot"><a href="#local-6989586621679775603"><span class="hs-identifier hs-var">embedLayerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; () -&gt; m ()
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679775610"><span class="hs-identifier hs-var">k</span></a></span><span>
</span><span id="line-337"></span><span>        </span><span class="annot"><a href="#local-6989586621679775603"><span class="hs-identifier hs-var">embedLayerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; LayerNorm
     'WithBias gradient device dataType ('Shape '[decoderInputEmbedDim])
-&gt; m ()
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679775610"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;layernorm_embedding.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-338"></span><span>        </span><span class="annot"><a href="#local-6989586621679775603"><span class="hs-identifier hs-var">embedLayerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; LayerNorm
     'WithBias gradient device dataType ('Shape '[decoderInputEmbedDim])
-&gt; m ()
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679775610"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;layernorm_embedding.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-339"></span><span>        </span><span class="annot"><a href="#local-6989586621679775603"><span class="hs-identifier hs-var">embedLayerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; () -&gt; m ()
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679775610"><span class="hs-identifier hs-var">k</span></a></span><span>
</span><span id="line-340"></span><span>        </span><span class="annot"><a href="#local-6989586621679775603"><span class="hs-identifier hs-var">embedLayerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">TDEmbedLayerNormF
  style gradient device dataType decoderInputEmbedDim
-&gt; m ()
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-341"></span><span>        </span><span class="annot"><a href="#local-6989586621679775603"><span class="hs-identifier hs-var">embedLayerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">TDEmbedLayerNormF
  style gradient device dataType decoderInputEmbedDim
-&gt; m ()
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-342"></span><span>        </span><span class="annot"><a href="#local-6989586621679775603"><span class="hs-identifier hs-var">embedLayerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SGPT2"><span class="hs-identifier hs-var">SGPT2</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">TDEmbedLayerNormF
  style gradient device dataType decoderInputEmbedDim
-&gt; m ()
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-343"></span><span>        </span><span id="local-6989586621679775602"><span class="annot"><span class="annottext">layerNorm :: STransformerStyle style
-&gt; TDLayerNormF style gradient device dataType decoderInputEmbedDim
-&gt; m ()
</span><a href="#local-6989586621679775602"><span class="hs-identifier hs-var hs-var">layerNorm</span></a></span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; LayerNorm
     'WithoutBias
     gradient
     device
     dataType
     ('Shape '[decoderInputEmbedDim])
-&gt; m ()
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679775610"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;final_layer_norm.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-344"></span><span>        </span><span class="annot"><a href="#local-6989586621679775602"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; LayerNorm
     'WithoutBias
     gradient
     device
     dataType
     ('Shape '[decoderInputEmbedDim])
-&gt; m ()
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679775610"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;final_layer_norm.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-345"></span><span>        </span><span class="annot"><a href="#local-6989586621679775602"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; () -&gt; m ()
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679775610"><span class="hs-identifier hs-var">k</span></a></span><span>
</span><span id="line-346"></span><span>        </span><span class="annot"><a href="#local-6989586621679775602"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; () -&gt; m ()
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679775610"><span class="hs-identifier hs-var">k</span></a></span><span>
</span><span id="line-347"></span><span>        </span><span class="annot"><a href="#local-6989586621679775602"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; LayerNorm
     'WithBias gradient device dataType ('Shape '[decoderInputEmbedDim])
-&gt; m ()
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679775610"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;layer_norm.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-348"></span><span>        </span><span class="annot"><a href="#local-6989586621679775602"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">TDLayerNormF style gradient device dataType decoderInputEmbedDim
-&gt; m ()
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-349"></span><span>        </span><span class="annot"><a href="#local-6989586621679775602"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">TDLayerNormF style gradient device dataType decoderInputEmbedDim
-&gt; m ()
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-350"></span><span>        </span><span class="annot"><a href="#local-6989586621679775602"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SGPT2"><span class="hs-identifier hs-var">SGPT2</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">TDLayerNormF style gradient device dataType decoderInputEmbedDim
-&gt; m ()
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-351"></span><span>        </span><span id="local-6989586621679775601"><span class="annot"><span class="annottext">dropout :: STransformerStyle style -&gt; Dropout dropoutP -&gt; m ()
</span><a href="#local-6989586621679775601"><span class="hs-identifier hs-var hs-var">dropout</span></a></span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; Dropout dropoutP -&gt; m ()
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679775610"><span class="hs-identifier hs-var">k</span></a></span><span>
</span><span id="line-352"></span><span>        </span><span id="local-6989586621679775600"><span class="annot"><span class="annottext">posEnc :: STransformerStyle style
-&gt; TDPosEncF
     style
     gradient
     device
     dataType
     headDim
     decoderInputEmbedDim
     posEncDim
-&gt; m ()
</span><a href="#local-6989586621679775600"><span class="hs-identifier hs-var hs-var">posEnc</span></a></span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; Embedding
     gradient
     ('Layout 'Dense)
     device
     dataType
     posEncDim
     headDim
     'Nothing
-&gt; m ()
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679775610"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;block.0.layer.0.SelfAttention.relative_attention_bias.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-353"></span><span>        </span><span class="annot"><a href="#local-6989586621679775600"><span class="hs-identifier hs-var">posEnc</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; Embedding
     gradient
     ('Layout 'Dense)
     device
     dataType
     posEncDim
     headDim
     'Nothing
-&gt; m ()
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679775610"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;block.0.layer.0.SelfAttention.relative_attention_bias.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-354"></span><span>        </span><span class="annot"><a href="#local-6989586621679775600"><span class="hs-identifier hs-var">posEnc</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; Embedding
     gradient
     ('Layout 'Dense)
     device
     dataType
     posEncDim
     decoderInputEmbedDim
     'Nothing
-&gt; m ()
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679775610"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;embed_positions.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-355"></span><span>        </span><span class="annot"><a href="#local-6989586621679775600"><span class="hs-identifier hs-var">posEnc</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; Embedding
     gradient
     ('Layout 'Dense)
     device
     dataType
     posEncDim
     decoderInputEmbedDim
     'Nothing
-&gt; m ()
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679775610"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;embed_positions.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-356"></span><span>        </span><span class="annot"><a href="#local-6989586621679775600"><span class="hs-identifier hs-var">posEnc</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; Embedding
     gradient
     ('Layout 'Dense)
     device
     dataType
     posEncDim
     decoderInputEmbedDim
     'Nothing
-&gt; m ()
forall model input (m :: * -&gt; *).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679775610"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;embed_positions.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-357"></span><span>        </span><span class="annot"><a href="#local-6989586621679775600"><span class="hs-identifier hs-var">posEnc</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">TDPosEncF
  style
  gradient
  device
  dataType
  headDim
  decoderInputEmbedDim
  posEncDim
-&gt; m ()
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-358"></span><span>        </span><span class="annot"><a href="#local-6989586621679775600"><span class="hs-identifier hs-var">posEnc</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">TDPosEncF
  style
  gradient
  device
  dataType
  headDim
  decoderInputEmbedDim
  posEncDim
-&gt; m ()
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-359"></span><span>        </span><span class="annot"><a href="#local-6989586621679775600"><span class="hs-identifier hs-var">posEnc</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SGPT2"><span class="hs-identifier hs-var">SGPT2</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">TDPosEncF
  style
  gradient
  device
  dataType
  headDim
  decoderInputEmbedDim
  posEncDim
-&gt; m ()
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-360"></span><span>     </span><span class="hs-keyword">in</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-361"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; TransformerDecoderStack
     style
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     decoderInputEmbedDim
     encoderOutputEmbedDim
     ffnDim
     dropoutP
-&gt; m ()
</span><a href="#local-6989586621679775604"><span class="hs-identifier hs-var">stack</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SingI style =&gt; Sing style
forall k (a :: k). SingI a =&gt; Sing a
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">sing</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679775649"><span class="hs-identifier hs-type">style</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">TransformerDecoderStack
  style
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  decoderInputEmbedDim
  encoderOutputEmbedDim
  ffnDim
  dropoutP
TDStackF
  style
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  decoderInputEmbedDim
  encoderOutputEmbedDim
  ffnDim
  dropoutP
</span><a href="#local-6989586621679775609"><span class="hs-identifier hs-var">tdStack</span></a></span><span>
</span><span id="line-362"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; TDEmbedLayerNormF
     style gradient device dataType decoderInputEmbedDim
-&gt; m ()
</span><a href="#local-6989586621679775603"><span class="hs-identifier hs-var">embedLayerNorm</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SingI style =&gt; Sing style
forall k (a :: k). SingI a =&gt; Sing a
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">sing</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679775649"><span class="hs-identifier hs-type">style</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">TDEmbedLayerNormF
  style gradient device dataType decoderInputEmbedDim
</span><a href="#local-6989586621679775608"><span class="hs-identifier hs-var">tdEmbedLayerNorm</span></a></span><span>
</span><span id="line-363"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; TDLayerNormF style gradient device dataType decoderInputEmbedDim
-&gt; m ()
</span><a href="#local-6989586621679775602"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SingI style =&gt; Sing style
forall k (a :: k). SingI a =&gt; Sing a
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">sing</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679775649"><span class="hs-identifier hs-type">style</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">TDLayerNormF style gradient device dataType decoderInputEmbedDim
</span><a href="#local-6989586621679775607"><span class="hs-identifier hs-var">tdLayerNorm</span></a></span><span>
</span><span id="line-364"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">STransformerStyle style -&gt; Dropout dropoutP -&gt; m ()
</span><a href="#local-6989586621679775601"><span class="hs-identifier hs-var">dropout</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SingI style =&gt; Sing style
forall k (a :: k). SingI a =&gt; Sing a
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">sing</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679775649"><span class="hs-identifier hs-type">style</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Dropout dropoutP
TDDropoutF style dropoutP
</span><a href="#local-6989586621679775606"><span class="hs-identifier hs-var">tdDropout</span></a></span><span>
</span><span id="line-365"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; TDPosEncF
     style
     gradient
     device
     dataType
     headDim
     decoderInputEmbedDim
     posEncDim
-&gt; m ()
</span><a href="#local-6989586621679775600"><span class="hs-identifier hs-var">posEnc</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SingI style =&gt; Sing style
forall k (a :: k). SingI a =&gt; Sing a
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">sing</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679775649"><span class="hs-identifier hs-type">style</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">TDPosEncF
  style
  gradient
  device
  dataType
  headDim
  decoderInputEmbedDim
  posEncDim
</span><a href="#local-6989586621679775605"><span class="hs-identifier hs-var">tdPosEnc</span></a></span><span>
</span><span id="line-366"></span><span>          </span><span class="annot"><span class="annottext">() -&gt; m ()
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span></span></span></span></span></span></span></span></span></span></span></span></span></span><span>
</span><span id="line-367"></span><span>
</span><span id="line-368"></span><span class="hs-comment">-- | 'HasForward' instance for @TransformerDecoder numLayers 'T5@.</span><span>
</span><span id="line-369"></span><span class="hs-comment">--</span><span>
</span><span id="line-370"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-371"></span><span class="hs-comment">-- &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;  &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;  &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;  &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;  &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;</span><span>
</span><span id="line-372"></span><span class="hs-comment">-- &#9474; decoderInput &#9474;  &#9474; encoderOutput &#9474;  &#9474; decoderRelPos &#9474;  &#9474; decoderAttentionMask &#9474;  &#9474; crossAttentionMask &#9474;</span><span>
</span><span id="line-373"></span><span class="hs-comment">-- &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;  &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;  &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;  &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;  &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-374"></span><span class="hs-comment">--        &#9474;                  &#9474;                  &#9474;                     &#9474;                        &#9474;</span><span>
</span><span id="line-375"></span><span class="hs-comment">--        &#9474;                  &#9474;                  &#9660;                     &#9474;                        &#9474;</span><span>
</span><span id="line-376"></span><span class="hs-comment">--        &#9474;                  &#9474;              tdPosEnc                  &#9474;                        &#9474;</span><span>
</span><span id="line-377"></span><span class="hs-comment">--        &#9474;                  &#9474;                  &#9660;                     &#9474;                        &#9474;</span><span>
</span><span id="line-378"></span><span class="hs-comment">--        &#9474;                  &#9474;              transpose                 &#9474;                        &#9474;</span><span>
</span><span id="line-379"></span><span class="hs-comment">--        &#9474;                  &#9474;                  &#9660;                     &#9660;                        &#9660;</span><span>
</span><span id="line-380"></span><span class="hs-comment">--        &#9474;                  &#9474;              transpose             unsqueeze                unsqueeze</span><span>
</span><span id="line-381"></span><span class="hs-comment">--        &#9660;                  &#9474;                  &#9474;                     &#9474;                        &#9474;</span><span>
</span><span id="line-382"></span><span class="hs-comment">--    tdDropout              &#9474;                  &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9658;add&#9668;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;                        &#9474;</span><span>
</span><span id="line-383"></span><span class="hs-comment">--        &#9660;                  &#9474;                             &#9474;                                   &#9474;</span><span>
</span><span id="line-384"></span><span class="hs-comment">--     tdStack&#9668;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;&#9668;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;&#9668;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-385"></span><span class="hs-comment">--        &#9660;</span><span>
</span><span id="line-386"></span><span class="hs-comment">--   tdLayerNorm</span><span>
</span><span id="line-387"></span><span class="hs-comment">--        &#9660;</span><span>
</span><span id="line-388"></span><span class="hs-comment">--    tdDropout</span><span>
</span><span id="line-389"></span><span class="hs-comment">--        &#9474;</span><span>
</span><span id="line-390"></span><span class="hs-comment">--        &#9660;</span><span>
</span><span id="line-391"></span><span class="hs-comment">--    &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;</span><span>
</span><span id="line-392"></span><span class="hs-comment">--    &#9474; output &#9474;</span><span>
</span><span id="line-393"></span><span class="hs-comment">--    &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-394"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-395"></span><span id="local-6989586621679775562"><span id="local-6989586621679775563"><span id="local-6989586621679775564"><span id="local-6989586621679775565"><span id="local-6989586621679775566"><span id="local-6989586621679775567"><span id="local-6989586621679775568"><span id="local-6989586621679775569"><span id="local-6989586621679775570"><span id="local-6989586621679775571"><span id="local-6989586621679775572"><span id="local-6989586621679775573"><span id="local-6989586621679775574"><span id="local-6989586621679775575"><span id="local-6989586621679775576"><span id="local-6989586621679775577"><span id="local-6989586621679775578"><span id="local-6989586621679775579"><span id="local-6989586621679775580"><span id="local-6989586621679775581"><span id="local-6989586621679775582"><span id="local-6989586621679775583"><span id="local-6989586621679775584"><span id="local-6989586621679775585"><span id="local-6989586621679775586"><span id="local-6989586621679775587"><span id="local-6989586621679775588"><span id="local-6989586621679775589"><span id="local-6989586621679775590"><span id="local-6989586621679775591"><span id="local-6989586621679775592"><span id="local-6989586621679775593"><span id="local-6989586621679775594"><span id="local-6989586621679775595"><span id="local-6989586621679775596"><span id="local-6989586621679775597"><span id="local-6989586621679775598"><span id="local-6989586621679775599"><span class="hs-keyword">instance</span><span>
</span><span id="line-396"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-397"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Dropout.html#Dropout"><span class="hs-identifier hs-type">Dropout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775599"><span class="hs-identifier hs-type">dropoutP</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-398"></span><span>      </span><span class="annot"><a href="#local-6989586621679775598"><span class="hs-identifier hs-type">decoderInput</span></a></span><span>
</span><span id="line-399"></span><span>      </span><span class="annot"><a href="#local-6989586621679775597"><span class="hs-identifier hs-type">generator</span></a></span><span>
</span><span id="line-400"></span><span>      </span><span class="annot"><a href="#local-6989586621679775596"><span class="hs-identifier hs-type">dropoutOutput</span></a></span><span>
</span><span id="line-401"></span><span>      </span><span class="annot"><a href="#local-6989586621679775595"><span class="hs-identifier hs-type">dropoutGeneratorOutput</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-402"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-403"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.DecoderStack.html#TransformerDecoderStack"><span class="hs-identifier hs-type">TransformerDecoderStack</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#T5"><span class="hs-identifier hs-type">T5</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775594"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775593"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775592"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775591"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775590"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775589"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775588"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775587"><span class="hs-identifier hs-type">decoderInputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775586"><span class="hs-identifier hs-type">encoderOutputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775585"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775599"><span class="hs-identifier hs-type">dropoutP</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-404"></span><span>      </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="#local-6989586621679775596"><span class="hs-identifier hs-type">dropoutOutput</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-405"></span><span>        </span><span class="annot"><a href="#local-6989586621679775584"><span class="hs-identifier hs-type">encoderOutput</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-406"></span><span>        </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-407"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679775593"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775583"><span class="hs-identifier hs-type">decoderRelPosGradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775582"><span class="hs-identifier hs-type">decoderAttentionMaskGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-408"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Dense"><span class="hs-identifier hs-type">Dense</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775581"><span class="hs-identifier hs-type">decoderRelPosLayout</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775580"><span class="hs-identifier hs-type">decoderAttentionMaskLayout</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-409"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679775592"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775579"><span class="hs-identifier hs-type">decoderRelPosDevice</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775578"><span class="hs-identifier hs-type">decoderAttentionMaskDevice</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-410"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Seq"><span class="hs-identifier hs-type">Seq</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679775577"><span class="hs-identifier hs-type">decoderRelPosDataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#Int64"><span class="hs-identifier hs-type">Int64</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679775591"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775576"><span class="hs-identifier hs-type">decoderAttentionMaskDataType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-411"></span><span>          </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#BroadcastShapesF"><span class="hs-identifier hs-type">BroadcastShapesF</span></a></span><span>
</span><span id="line-412"></span><span>              </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#TransposeF"><span class="hs-identifier hs-type">TransposeF</span></a></span><span>
</span><span id="line-413"></span><span>                  </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-414"></span><span>                  </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">2</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-415"></span><span>                  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#TransposeF"><span class="hs-identifier hs-type">TransposeF</span></a></span><span>
</span><span id="line-416"></span><span>                      </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">2</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-417"></span><span>                      </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">3</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-418"></span><span>                      </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Functional.Sparse.html#EmbeddingF"><span class="hs-identifier hs-type">EmbeddingF</span></a></span><span>
</span><span id="line-419"></span><span>                          </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679775575"><span class="hs-identifier hs-type">posEncDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679775590"><span class="hs-identifier hs-type">headDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-420"></span><span>                          </span><span class="annot"><a href="#local-6989586621679775574"><span class="hs-identifier hs-type">decoderRelPosShape</span></a></span><span>
</span><span id="line-421"></span><span>                      </span><span class="hs-special">)</span><span>
</span><span id="line-422"></span><span>                  </span><span class="hs-special">)</span><span>
</span><span id="line-423"></span><span>              </span><span class="hs-special">)</span><span>
</span><span id="line-424"></span><span>              </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#UnsqueezeF"><span class="hs-identifier hs-type">UnsqueezeF</span></a></span><span>
</span><span id="line-425"></span><span>                  </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-426"></span><span>                  </span><span class="annot"><a href="#local-6989586621679775573"><span class="hs-identifier hs-type">decoderAttentionMaskShape</span></a></span><span>
</span><span id="line-427"></span><span>              </span><span class="hs-special">)</span><span>
</span><span id="line-428"></span><span>          </span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-429"></span><span>        </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-430"></span><span>          </span><span class="annot"><a href="#local-6989586621679775572"><span class="hs-identifier hs-type">crossAttentionMaskGradient</span></a></span><span>
</span><span id="line-431"></span><span>          </span><span class="annot"><a href="#local-6989586621679775571"><span class="hs-identifier hs-type">crossAttentionMaskLayout</span></a></span><span>
</span><span id="line-432"></span><span>          </span><span class="annot"><a href="#local-6989586621679775570"><span class="hs-identifier hs-type">crossAttentionMaskDevice</span></a></span><span>
</span><span id="line-433"></span><span>          </span><span class="annot"><a href="#local-6989586621679775569"><span class="hs-identifier hs-type">crossAttentionMaskDataType</span></a></span><span>
</span><span id="line-434"></span><span>          </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#UnsqueezeF"><span class="hs-identifier hs-type">UnsqueezeF</span></a></span><span>
</span><span id="line-435"></span><span>              </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-436"></span><span>              </span><span class="annot"><a href="#local-6989586621679775568"><span class="hs-identifier hs-type">crossAttentionMaskShape</span></a></span><span>
</span><span id="line-437"></span><span>          </span><span class="hs-special">)</span><span>
</span><span id="line-438"></span><span>      </span><span class="hs-special">)</span><span>
</span><span id="line-439"></span><span>      </span><span class="annot"><a href="#local-6989586621679775595"><span class="hs-identifier hs-type">dropoutGeneratorOutput</span></a></span><span>
</span><span id="line-440"></span><span>      </span><span class="annot"><a href="#local-6989586621679775567"><span class="hs-identifier hs-type">stackOutput</span></a></span><span>
</span><span id="line-441"></span><span>      </span><span class="annot"><a href="#local-6989586621679775566"><span class="hs-identifier hs-type">stackGeneratorOutput</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-442"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-443"></span><span>      </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Normalization.html#LayerNorm"><span class="hs-identifier hs-type">LayerNorm</span></a></span><span>
</span><span id="line-444"></span><span>          </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Type.html#WithoutBias"><span class="hs-identifier hs-type">WithoutBias</span></a></span><span>
</span><span id="line-445"></span><span>          </span><span class="annot"><a href="#local-6989586621679775593"><span class="hs-identifier hs-type">gradient</span></a></span><span>
</span><span id="line-446"></span><span>          </span><span class="annot"><a href="#local-6989586621679775592"><span class="hs-identifier hs-type">device</span></a></span><span>
</span><span id="line-447"></span><span>          </span><span class="annot"><a href="#local-6989586621679775591"><span class="hs-identifier hs-type">dataType</span></a></span><span>
</span><span id="line-448"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679775587"><span class="hs-identifier hs-type">decoderInputEmbedDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-449"></span><span>      </span><span class="hs-special">)</span><span>
</span><span id="line-450"></span><span>      </span><span class="annot"><a href="#local-6989586621679775567"><span class="hs-identifier hs-type">stackOutput</span></a></span><span>
</span><span id="line-451"></span><span>      </span><span class="annot"><a href="#local-6989586621679775566"><span class="hs-identifier hs-type">stackGeneratorOutput</span></a></span><span>
</span><span id="line-452"></span><span>      </span><span class="annot"><a href="#local-6989586621679775565"><span class="hs-identifier hs-type">layerNormOutput</span></a></span><span>
</span><span id="line-453"></span><span>      </span><span class="annot"><a href="#local-6989586621679775564"><span class="hs-identifier hs-type">layerNormGeneratorOutput</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-454"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-455"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Dropout.html#Dropout"><span class="hs-identifier hs-type">Dropout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775599"><span class="hs-identifier hs-type">dropoutP</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-456"></span><span>      </span><span class="annot"><a href="#local-6989586621679775565"><span class="hs-identifier hs-type">layerNormOutput</span></a></span><span>
</span><span id="line-457"></span><span>      </span><span class="annot"><a href="#local-6989586621679775564"><span class="hs-identifier hs-type">layerNormGeneratorOutput</span></a></span><span>
</span><span id="line-458"></span><span>      </span><span class="annot"><a href="#local-6989586621679775563"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-459"></span><span>      </span><span class="annot"><a href="#local-6989586621679775562"><span class="hs-identifier hs-type">generatorOutput</span></a></span><span>
</span><span id="line-460"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-461"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-462"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TransformerDecoder"><span class="hs-identifier hs-type">TransformerDecoder</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#T5"><span class="hs-identifier hs-type">T5</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775594"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775593"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775592"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775591"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775590"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775589"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775588"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775587"><span class="hs-identifier hs-type">decoderInputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775586"><span class="hs-identifier hs-type">encoderOutputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775585"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775575"><span class="hs-identifier hs-type">posEncDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775599"><span class="hs-identifier hs-type">dropoutP</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-463"></span><span>    </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="#local-6989586621679775598"><span class="hs-identifier hs-type">decoderInput</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-464"></span><span>      </span><span class="annot"><a href="#local-6989586621679775584"><span class="hs-identifier hs-type">encoderOutput</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-465"></span><span>      </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775583"><span class="hs-identifier hs-type">decoderRelPosGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775581"><span class="hs-identifier hs-type">decoderRelPosLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775579"><span class="hs-identifier hs-type">decoderRelPosDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775577"><span class="hs-identifier hs-type">decoderRelPosDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775574"><span class="hs-identifier hs-type">decoderRelPosShape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-466"></span><span>      </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775582"><span class="hs-identifier hs-type">decoderAttentionMaskGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775580"><span class="hs-identifier hs-type">decoderAttentionMaskLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775578"><span class="hs-identifier hs-type">decoderAttentionMaskDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775576"><span class="hs-identifier hs-type">decoderAttentionMaskDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775573"><span class="hs-identifier hs-type">decoderAttentionMaskShape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-467"></span><span>      </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775572"><span class="hs-identifier hs-type">crossAttentionMaskGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775571"><span class="hs-identifier hs-type">crossAttentionMaskLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775570"><span class="hs-identifier hs-type">crossAttentionMaskDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775569"><span class="hs-identifier hs-type">crossAttentionMaskDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775568"><span class="hs-identifier hs-type">crossAttentionMaskShape</span></a></span><span>
</span><span id="line-468"></span><span>    </span><span class="hs-special">)</span><span>
</span><span id="line-469"></span><span>    </span><span class="annot"><a href="#local-6989586621679775597"><span class="hs-identifier hs-type">generator</span></a></span><span>
</span><span id="line-470"></span><span>    </span><span class="annot"><a href="#local-6989586621679775563"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-471"></span><span>    </span><span class="annot"><a href="#local-6989586621679775562"><span class="hs-identifier hs-type">generatorOutput</span></a></span><span>
</span><span id="line-472"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-473"></span><span>  </span><span id="local-6989586621679775559"><span class="annot"><span class="annottext">forward :: TransformerDecoder
  'T5
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  decoderInputEmbedDim
  encoderOutputEmbedDim
  ffnDim
  posEncDim
  dropoutP
-&gt; (decoderInput, encoderOutput,
    Tensor
      decoderRelPosGradient
      decoderRelPosLayout
      decoderRelPosDevice
      decoderRelPosDataType
      decoderRelPosShape,
    Tensor
      decoderAttentionMaskGradient
      decoderAttentionMaskLayout
      decoderAttentionMaskDevice
      decoderAttentionMaskDataType
      decoderAttentionMaskShape,
    Tensor
      crossAttentionMaskGradient
      crossAttentionMaskLayout
      crossAttentionMaskDevice
      crossAttentionMaskDataType
      crossAttentionMaskShape)
-&gt; generator
-&gt; m (output, generatorOutput)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var hs-var hs-var hs-var">forward</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TransformerDecoder"><span class="hs-identifier hs-type">TransformerDecoder</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#GTransformerDecoder"><span class="hs-identifier hs-type">GTransformerDecoder</span></a></span><span> </span><span class="hs-special">{</span><span id="local-6989586621679775553"><span id="local-6989586621679775554"><span id="local-6989586621679775555"><span id="local-6989586621679775556"><span id="local-6989586621679775557"><span class="annot"><span class="annottext">TDPosEncF
  'T5 gradient device dataType headDim decoderInputEmbedDim posEncDim
TDDropoutF 'T5 dropoutP
TDLayerNormF 'T5 gradient device dataType decoderInputEmbedDim
TDEmbedLayerNormF 'T5 gradient device dataType decoderInputEmbedDim
TDStackF
  'T5
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  decoderInputEmbedDim
  encoderOutputEmbedDim
  ffnDim
  dropoutP
tdPosEnc :: TDPosEncF
  'T5 gradient device dataType headDim decoderInputEmbedDim posEncDim
tdDropout :: TDDropoutF 'T5 dropoutP
tdLayerNorm :: TDLayerNormF 'T5 gradient device dataType decoderInputEmbedDim
tdEmbedLayerNorm :: TDEmbedLayerNormF 'T5 gradient device dataType decoderInputEmbedDim
tdStack :: TDStackF
  'T5
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  decoderInputEmbedDim
  encoderOutputEmbedDim
  ffnDim
  dropoutP
tdPosEnc :: forall stack embedLayerNorm layerNorm dropout posEnc.
GTransformerDecoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; posEnc
tdDropout :: forall stack embedLayerNorm layerNorm dropout posEnc.
GTransformerDecoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; dropout
tdLayerNorm :: forall stack embedLayerNorm layerNorm dropout posEnc.
GTransformerDecoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; layerNorm
tdEmbedLayerNorm :: forall stack embedLayerNorm layerNorm dropout posEnc.
GTransformerDecoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; embedLayerNorm
tdStack :: forall stack embedLayerNorm layerNorm dropout posEnc.
GTransformerDecoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; stack
</span><a href="#local-6989586621679775553"><span class="hs-glyph hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">..</span></a></span></span></span></span></span></span><span class="hs-special">}</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679775552"><span class="annot"><span class="annottext">decoderInput
</span><a href="#local-6989586621679775552"><span class="hs-identifier hs-var">decoderInput</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679775551"><span class="annot"><span class="annottext">encoderOutput
</span><a href="#local-6989586621679775551"><span class="hs-identifier hs-var">encoderOutput</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679775550"><span class="annot"><span class="annottext">Tensor
  decoderRelPosGradient
  decoderRelPosLayout
  decoderRelPosDevice
  decoderRelPosDataType
  decoderRelPosShape
</span><a href="#local-6989586621679775550"><span class="hs-identifier hs-var">decoderRelPos</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679775549"><span class="annot"><span class="annottext">Tensor
  decoderAttentionMaskGradient
  decoderAttentionMaskLayout
  decoderAttentionMaskDevice
  decoderAttentionMaskDataType
  decoderAttentionMaskShape
</span><a href="#local-6989586621679775549"><span class="hs-identifier hs-var">decoderAttentionMask</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679775548"><span class="annot"><span class="annottext">Tensor
  crossAttentionMaskGradient
  crossAttentionMaskLayout
  crossAttentionMaskDevice
  crossAttentionMaskDataType
  crossAttentionMaskShape
</span><a href="#local-6989586621679775548"><span class="hs-identifier hs-var">crossAttentionMask</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-474"></span><span>    </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679775547"><span class="annot"><span class="annottext">decoderRelPosBias :: IxStateT
  m
  dropoutGeneratorOutput
  dropoutGeneratorOutput
  (Tensor
     (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
     (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
     (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
     (Seq
        (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
        dataType)
     (TransposeF
        ('SelectDim ('ByIndex 1))
        ('SelectDim ('ByIndex 2))
        (TransposeF
           ('SelectDim ('ByIndex 2))
           ('SelectDim ('ByIndex 3))
           (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape))))
</span><a href="#local-6989586621679775547"><span class="hs-identifier hs-var hs-var">decoderRelPosBias</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-475"></span><span>          </span><span class="annot"><span class="annottext">Tensor
  decoderRelPosGradient
  decoderRelPosLayout
  decoderRelPosDevice
  decoderRelPosDataType
  decoderRelPosShape
-&gt; IxStateT
     m
     dropoutGeneratorOutput
     dropoutGeneratorOutput
     (Tensor
        decoderRelPosGradient
        decoderRelPosLayout
        decoderRelPosDevice
        decoderRelPosDataType
        decoderRelPosShape)
forall k (m :: k -&gt; k -&gt; * -&gt; *) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  decoderRelPosGradient
  decoderRelPosLayout
  decoderRelPosDevice
  decoderRelPosDataType
  decoderRelPosShape
</span><a href="#local-6989586621679775550"><span class="hs-identifier hs-var">decoderRelPos</span></a></span><span>
</span><span id="line-476"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  dropoutGeneratorOutput
  dropoutGeneratorOutput
  (Tensor
     decoderRelPosGradient
     decoderRelPosLayout
     decoderRelPosDevice
     decoderRelPosDataType
     decoderRelPosShape)
-&gt; (Tensor
      decoderRelPosGradient
      decoderRelPosLayout
      decoderRelPosDevice
      decoderRelPosDataType
      decoderRelPosShape
    -&gt; IxStateT
         m
         dropoutGeneratorOutput
         dropoutGeneratorOutput
         (Tensor
            (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
            (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
            (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
            (Seq
               (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
               dataType)
            (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)))
-&gt; IxStateT
     m
     dropoutGeneratorOutput
     dropoutGeneratorOutput
     (Tensor
        (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
        (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
        (Seq
           (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
           dataType)
        (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape))
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(dropoutGeneratorOutput
 -&gt; m (Tensor
         (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
         (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
         (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
         (Seq
            (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
            dataType)
         (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape),
       dropoutGeneratorOutput))
-&gt; IxStateT
     m
     dropoutGeneratorOutput
     dropoutGeneratorOutput
     (Tensor
        (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
        (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
        (Seq
           (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
           dataType)
        (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape))
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((dropoutGeneratorOutput
  -&gt; m (Tensor
          (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
          (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
          (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
          (Seq
             (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
             dataType)
          (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape),
        dropoutGeneratorOutput))
 -&gt; IxStateT
      m
      dropoutGeneratorOutput
      dropoutGeneratorOutput
      (Tensor
         (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
         (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
         (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
         (Seq
            (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
            dataType)
         (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)))
-&gt; (Tensor
      decoderRelPosGradient
      decoderRelPosLayout
      decoderRelPosDevice
      decoderRelPosDataType
      decoderRelPosShape
    -&gt; dropoutGeneratorOutput
    -&gt; m (Tensor
            (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
            (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
            (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
            (Seq
               (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
               dataType)
            (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape),
          dropoutGeneratorOutput))
-&gt; Tensor
     decoderRelPosGradient
     decoderRelPosLayout
     decoderRelPosDevice
     decoderRelPosDataType
     decoderRelPosShape
-&gt; IxStateT
     m
     dropoutGeneratorOutput
     dropoutGeneratorOutput
     (Tensor
        (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
        (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
        (Seq
           (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
           dataType)
        (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape))
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Embedding
  gradient
  ('Layout 'Dense)
  device
  dataType
  posEncDim
  headDim
  'Nothing
-&gt; Tensor
     decoderRelPosGradient
     decoderRelPosLayout
     decoderRelPosDevice
     decoderRelPosDataType
     decoderRelPosShape
-&gt; dropoutGeneratorOutput
-&gt; m (Tensor
        (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
        (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
        (Seq
           (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
           dataType)
        (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape),
      dropoutGeneratorOutput)
forall model input generator output generatorOutput (m :: * -&gt; *).
(HasForward model input generator output generatorOutput,
 MonadThrow m) =&gt;
model -&gt; input -&gt; generator -&gt; m (output, generatorOutput)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">Embedding
  gradient
  ('Layout 'Dense)
  device
  dataType
  posEncDim
  headDim
  'Nothing
TDPosEncF
  'T5 gradient device dataType headDim decoderInputEmbedDim posEncDim
</span><a href="#local-6989586621679775553"><span class="hs-identifier hs-var">tdPosEnc</span></a></span><span>
</span><span id="line-477"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  dropoutGeneratorOutput
  dropoutGeneratorOutput
  (Tensor
     (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
     (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
     (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
     (Seq
        (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
        dataType)
     (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape))
-&gt; (Tensor
      (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
      (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
      (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
      (Seq
         (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
         dataType)
      (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)
    -&gt; IxStateT
         m
         dropoutGeneratorOutput
         dropoutGeneratorOutput
         (Tensor
            (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
            (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
            (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
            (Seq
               (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
               dataType)
            (TransposeF
               ('SelectDim ('ByIndex 2))
               ('SelectDim ('ByIndex 3))
               (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape))))
-&gt; IxStateT
     m
     dropoutGeneratorOutput
     dropoutGeneratorOutput
     (Tensor
        (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
        (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
        (Seq
           (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
           dataType)
        (TransposeF
           ('SelectDim ('ByIndex 2))
           ('SelectDim ('ByIndex 3))
           (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)))
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">m (Tensor
     (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
     (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
     (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
     (Seq
        (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
        dataType)
     (TransposeF
        ('SelectDim ('ByIndex 2))
        ('SelectDim ('ByIndex 3))
        (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)))
-&gt; IxStateT
     m
     dropoutGeneratorOutput
     dropoutGeneratorOutput
     (Tensor
        (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
        (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
        (Seq
           (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
           dataType)
        (TransposeF
           ('SelectDim ('ByIndex 2))
           ('SelectDim ('ByIndex 3))
           (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)))
forall k (t :: (* -&gt; *) -&gt; k -&gt; k -&gt; * -&gt; *) (m :: * -&gt; *) a
       (i :: k).
(IxMonadTrans t, Monad m) =&gt;
m a -&gt; t m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ilift</span></a></span><span> </span><span class="annot"><span class="annottext">(m (Tensor
      (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
      (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
      (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
      (Seq
         (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
         dataType)
      (TransposeF
         ('SelectDim ('ByIndex 2))
         ('SelectDim ('ByIndex 3))
         (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)))
 -&gt; IxStateT
      m
      dropoutGeneratorOutput
      dropoutGeneratorOutput
      (Tensor
         (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
         (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
         (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
         (Seq
            (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
            dataType)
         (TransposeF
            ('SelectDim ('ByIndex 2))
            ('SelectDim ('ByIndex 3))
            (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape))))
-&gt; (Tensor
      (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
      (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
      (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
      (Seq
         (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
         dataType)
      (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)
    -&gt; m (Tensor
            (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
            (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
            (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
            (Seq
               (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
               dataType)
            (TransposeF
               ('SelectDim ('ByIndex 2))
               ('SelectDim ('ByIndex 3))
               (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape))))
-&gt; Tensor
     (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
     (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
     (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
     (Seq
        (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
        dataType)
     (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)
-&gt; IxStateT
     m
     dropoutGeneratorOutput
     dropoutGeneratorOutput
     (Tensor
        (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
        (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
        (Seq
           (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
           dataType)
        (TransposeF
           ('SelectDim ('ByIndex 2))
           ('SelectDim ('ByIndex 3))
           (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)))
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]) (m :: * -&gt; *).
(shape'
 ~ TransposeF
     ('SelectDim ('ByIndex 2)) ('SelectDim ('ByIndex 3)) shape,
 SingI ('SelectDim ('ByIndex 2)), SingI ('SelectDim ('ByIndex 3)),
 MonadThrow m) =&gt;
Tensor gradient layout device dataType shape
-&gt; m (Tensor gradient layout device dataType shape')
forall (selectDim0 :: SelectDim (By Symbol Nat))
       (selectDim1 :: SelectDim (By Symbol Nat))
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]) (m :: * -&gt; *).
(shape' ~ TransposeF selectDim0 selectDim1 shape, SingI selectDim0,
 SingI selectDim1, MonadThrow m) =&gt;
Tensor gradient layout device dataType shape
-&gt; m (Tensor gradient layout device dataType shape')
</span><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#transpose"><span class="hs-identifier hs-var">transpose</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">2</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">3</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-478"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  dropoutGeneratorOutput
  dropoutGeneratorOutput
  (Tensor
     (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
     (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
     (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
     (Seq
        (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
        dataType)
     (TransposeF
        ('SelectDim ('ByIndex 2))
        ('SelectDim ('ByIndex 3))
        (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)))
-&gt; (Tensor
      (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
      (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
      (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
      (Seq
         (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
         dataType)
      (TransposeF
         ('SelectDim ('ByIndex 2))
         ('SelectDim ('ByIndex 3))
         (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape))
    -&gt; IxStateT
         m
         dropoutGeneratorOutput
         dropoutGeneratorOutput
         (Tensor
            (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
            (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
            (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
            (Seq
               (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
               dataType)
            (TransposeF
               ('SelectDim ('ByIndex 1))
               ('SelectDim ('ByIndex 2))
               (TransposeF
                  ('SelectDim ('ByIndex 2))
                  ('SelectDim ('ByIndex 3))
                  (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)))))
-&gt; IxStateT
     m
     dropoutGeneratorOutput
     dropoutGeneratorOutput
     (Tensor
        (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
        (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
        (Seq
           (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
           dataType)
        (TransposeF
           ('SelectDim ('ByIndex 1))
           ('SelectDim ('ByIndex 2))
           (TransposeF
              ('SelectDim ('ByIndex 2))
              ('SelectDim ('ByIndex 3))
              (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape))))
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">m (Tensor
     (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
     (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
     (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
     (Seq
        (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
        dataType)
     (TransposeF
        ('SelectDim ('ByIndex 1))
        ('SelectDim ('ByIndex 2))
        (TransposeF
           ('SelectDim ('ByIndex 2))
           ('SelectDim ('ByIndex 3))
           (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape))))
-&gt; IxStateT
     m
     dropoutGeneratorOutput
     dropoutGeneratorOutput
     (Tensor
        (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
        (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
        (Seq
           (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
           dataType)
        (TransposeF
           ('SelectDim ('ByIndex 1))
           ('SelectDim ('ByIndex 2))
           (TransposeF
              ('SelectDim ('ByIndex 2))
              ('SelectDim ('ByIndex 3))
              (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape))))
forall k (t :: (* -&gt; *) -&gt; k -&gt; k -&gt; * -&gt; *) (m :: * -&gt; *) a
       (i :: k).
(IxMonadTrans t, Monad m) =&gt;
m a -&gt; t m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ilift</span></a></span><span> </span><span class="annot"><span class="annottext">(m (Tensor
      (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
      (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
      (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
      (Seq
         (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
         dataType)
      (TransposeF
         ('SelectDim ('ByIndex 1))
         ('SelectDim ('ByIndex 2))
         (TransposeF
            ('SelectDim ('ByIndex 2))
            ('SelectDim ('ByIndex 3))
            (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape))))
 -&gt; IxStateT
      m
      dropoutGeneratorOutput
      dropoutGeneratorOutput
      (Tensor
         (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
         (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
         (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
         (Seq
            (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
            dataType)
         (TransposeF
            ('SelectDim ('ByIndex 1))
            ('SelectDim ('ByIndex 2))
            (TransposeF
               ('SelectDim ('ByIndex 2))
               ('SelectDim ('ByIndex 3))
               (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)))))
-&gt; (Tensor
      (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
      (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
      (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
      (Seq
         (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
         dataType)
      (TransposeF
         ('SelectDim ('ByIndex 2))
         ('SelectDim ('ByIndex 3))
         (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape))
    -&gt; m (Tensor
            (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
            (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
            (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
            (Seq
               (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
               dataType)
            (TransposeF
               ('SelectDim ('ByIndex 1))
               ('SelectDim ('ByIndex 2))
               (TransposeF
                  ('SelectDim ('ByIndex 2))
                  ('SelectDim ('ByIndex 3))
                  (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)))))
-&gt; Tensor
     (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
     (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
     (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
     (Seq
        (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
        dataType)
     (TransposeF
        ('SelectDim ('ByIndex 2))
        ('SelectDim ('ByIndex 3))
        (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape))
-&gt; IxStateT
     m
     dropoutGeneratorOutput
     dropoutGeneratorOutput
     (Tensor
        (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
        (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
        (Seq
           (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
           dataType)
        (TransposeF
           ('SelectDim ('ByIndex 1))
           ('SelectDim ('ByIndex 2))
           (TransposeF
              ('SelectDim ('ByIndex 2))
              ('SelectDim ('ByIndex 3))
              (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape))))
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]) (m :: * -&gt; *).
(shape'
 ~ TransposeF
     ('SelectDim ('ByIndex 1)) ('SelectDim ('ByIndex 2)) shape,
 SingI ('SelectDim ('ByIndex 1)), SingI ('SelectDim ('ByIndex 2)),
 MonadThrow m) =&gt;
Tensor gradient layout device dataType shape
-&gt; m (Tensor gradient layout device dataType shape')
forall (selectDim0 :: SelectDim (By Symbol Nat))
       (selectDim1 :: SelectDim (By Symbol Nat))
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]) (m :: * -&gt; *).
(shape' ~ TransposeF selectDim0 selectDim1 shape, SingI selectDim0,
 SingI selectDim1, MonadThrow m) =&gt;
Tensor gradient layout device dataType shape
-&gt; m (Tensor gradient layout device dataType shape')
</span><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#transpose"><span class="hs-identifier hs-var">transpose</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">2</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-479"></span><span>        </span><span id="local-6989586621679775545"><span class="annot"><span class="annottext">decoderAttentionBias :: IxStateT
  m
  dropoutGeneratorOutput
  dropoutGeneratorOutput
  (Tensor
     (Or
        (Gradient RequiresGradient)
        (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
        decoderAttentionMaskGradient)
     (Unify
        (Layout LayoutType)
        (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
        decoderAttentionMaskLayout)
     (Unify
        (Device (DeviceType Nat))
        (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
        decoderAttentionMaskDevice)
     (Unify
        (DataType DType)
        (Seq
           (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
           dataType)
        decoderAttentionMaskDataType)
     (BroadcastShapesF
        (TransposeF
           ('SelectDim ('ByIndex 1))
           ('SelectDim ('ByIndex 2))
           (TransposeF
              ('SelectDim ('ByIndex 2))
              ('SelectDim ('ByIndex 3))
              (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)))
        (UnsqueezeF ('SelectDim ('ByIndex 1)) decoderAttentionMaskShape)))
</span><a href="#local-6989586621679775545"><span class="hs-identifier hs-var hs-var">decoderAttentionBias</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-480"></span><span>          </span><span class="annot"><span class="annottext">IxStateT
  m
  dropoutGeneratorOutput
  dropoutGeneratorOutput
  (Tensor
     (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
     (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
     (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
     (Seq
        (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
        dataType)
     (TransposeF
        ('SelectDim ('ByIndex 1))
        ('SelectDim ('ByIndex 2))
        (TransposeF
           ('SelectDim ('ByIndex 2))
           ('SelectDim ('ByIndex 3))
           (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape))))
</span><a href="#local-6989586621679775547"><span class="hs-identifier hs-var">decoderRelPosBias</span></a></span><span>
</span><span id="line-481"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  dropoutGeneratorOutput
  dropoutGeneratorOutput
  (Tensor
     (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
     (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
     (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
     (Seq
        (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
        dataType)
     (TransposeF
        ('SelectDim ('ByIndex 1))
        ('SelectDim ('ByIndex 2))
        (TransposeF
           ('SelectDim ('ByIndex 2))
           ('SelectDim ('ByIndex 3))
           (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape))))
-&gt; (Tensor
      (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
      (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
      (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
      (Seq
         (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
         dataType)
      (TransposeF
         ('SelectDim ('ByIndex 1))
         ('SelectDim ('ByIndex 2))
         (TransposeF
            ('SelectDim ('ByIndex 2))
            ('SelectDim ('ByIndex 3))
            (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)))
    -&gt; IxStateT
         m
         dropoutGeneratorOutput
         dropoutGeneratorOutput
         (Tensor
            (Or
               (Gradient RequiresGradient)
               (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
               decoderAttentionMaskGradient)
            (Unify
               (Layout LayoutType)
               (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
               decoderAttentionMaskLayout)
            (Unify
               (Device (DeviceType Nat))
               (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
               decoderAttentionMaskDevice)
            (Unify
               (DataType DType)
               (Seq
                  (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
                  dataType)
               decoderAttentionMaskDataType)
            (BroadcastShapesF
               (TransposeF
                  ('SelectDim ('ByIndex 1))
                  ('SelectDim ('ByIndex 2))
                  (TransposeF
                     ('SelectDim ('ByIndex 2))
                     ('SelectDim ('ByIndex 3))
                     (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)))
               (UnsqueezeF ('SelectDim ('ByIndex 1)) decoderAttentionMaskShape))))
-&gt; IxStateT
     m
     dropoutGeneratorOutput
     dropoutGeneratorOutput
     (Tensor
        (Or
           (Gradient RequiresGradient)
           (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
           decoderAttentionMaskGradient)
        (Unify
           (Layout LayoutType)
           (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
           decoderAttentionMaskLayout)
        (Unify
           (Device (DeviceType Nat))
           (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
           decoderAttentionMaskDevice)
        (Unify
           (DataType DType)
           (Seq
              (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
              dataType)
           decoderAttentionMaskDataType)
        (BroadcastShapesF
           (TransposeF
              ('SelectDim ('ByIndex 1))
              ('SelectDim ('ByIndex 2))
              (TransposeF
                 ('SelectDim ('ByIndex 2))
                 ('SelectDim ('ByIndex 3))
                 (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)))
           (UnsqueezeF ('SelectDim ('ByIndex 1)) decoderAttentionMaskShape)))
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  (Or
     (Gradient RequiresGradient)
     (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
     decoderAttentionMaskGradient)
  (Unify
     (Layout LayoutType)
     (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
     decoderAttentionMaskLayout)
  (Unify
     (Device (DeviceType Nat))
     (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
     decoderAttentionMaskDevice)
  (Unify
     (DataType DType)
     (Seq
        (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
        dataType)
     decoderAttentionMaskDataType)
  (BroadcastShapesF
     (TransposeF
        ('SelectDim ('ByIndex 1))
        ('SelectDim ('ByIndex 2))
        (TransposeF
           ('SelectDim ('ByIndex 2))
           ('SelectDim ('ByIndex 3))
           (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)))
     (UnsqueezeF ('SelectDim ('ByIndex 1)) decoderAttentionMaskShape))
-&gt; IxStateT
     m
     dropoutGeneratorOutput
     dropoutGeneratorOutput
     (Tensor
        (Or
           (Gradient RequiresGradient)
           (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
           decoderAttentionMaskGradient)
        (Unify
           (Layout LayoutType)
           (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
           decoderAttentionMaskLayout)
        (Unify
           (Device (DeviceType Nat))
           (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
           decoderAttentionMaskDevice)
        (Unify
           (DataType DType)
           (Seq
              (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
              dataType)
           decoderAttentionMaskDataType)
        (BroadcastShapesF
           (TransposeF
              ('SelectDim ('ByIndex 1))
              ('SelectDim ('ByIndex 2))
              (TransposeF
                 ('SelectDim ('ByIndex 2))
                 ('SelectDim ('ByIndex 3))
                 (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)))
           (UnsqueezeF ('SelectDim ('ByIndex 1)) decoderAttentionMaskShape)))
forall k (m :: k -&gt; k -&gt; * -&gt; *) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">(Tensor
   (Or
      (Gradient RequiresGradient)
      (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
      decoderAttentionMaskGradient)
   (Unify
      (Layout LayoutType)
      (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
      decoderAttentionMaskLayout)
   (Unify
      (Device (DeviceType Nat))
      (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
      decoderAttentionMaskDevice)
   (Unify
      (DataType DType)
      (Seq
         (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
         dataType)
      decoderAttentionMaskDataType)
   (BroadcastShapesF
      (TransposeF
         ('SelectDim ('ByIndex 1))
         ('SelectDim ('ByIndex 2))
         (TransposeF
            ('SelectDim ('ByIndex 2))
            ('SelectDim ('ByIndex 3))
            (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)))
      (UnsqueezeF ('SelectDim ('ByIndex 1)) decoderAttentionMaskShape))
 -&gt; IxStateT
      m
      dropoutGeneratorOutput
      dropoutGeneratorOutput
      (Tensor
         (Or
            (Gradient RequiresGradient)
            (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
            decoderAttentionMaskGradient)
         (Unify
            (Layout LayoutType)
            (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
            decoderAttentionMaskLayout)
         (Unify
            (Device (DeviceType Nat))
            (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
            decoderAttentionMaskDevice)
         (Unify
            (DataType DType)
            (Seq
               (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
               dataType)
            decoderAttentionMaskDataType)
         (BroadcastShapesF
            (TransposeF
               ('SelectDim ('ByIndex 1))
               ('SelectDim ('ByIndex 2))
               (TransposeF
                  ('SelectDim ('ByIndex 2))
                  ('SelectDim ('ByIndex 3))
                  (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)))
            (UnsqueezeF ('SelectDim ('ByIndex 1)) decoderAttentionMaskShape))))
-&gt; (Tensor
      (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
      (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
      (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
      (Seq
         (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
         dataType)
      (TransposeF
         ('SelectDim ('ByIndex 1))
         ('SelectDim ('ByIndex 2))
         (TransposeF
            ('SelectDim ('ByIndex 2))
            ('SelectDim ('ByIndex 3))
            (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)))
    -&gt; Tensor
         (Or
            (Gradient RequiresGradient)
            (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
            decoderAttentionMaskGradient)
         (Unify
            (Layout LayoutType)
            (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
            decoderAttentionMaskLayout)
         (Unify
            (Device (DeviceType Nat))
            (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
            decoderAttentionMaskDevice)
         (Unify
            (DataType DType)
            (Seq
               (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
               dataType)
            decoderAttentionMaskDataType)
         (BroadcastShapesF
            (TransposeF
               ('SelectDim ('ByIndex 1))
               ('SelectDim ('ByIndex 2))
               (TransposeF
                  ('SelectDim ('ByIndex 2))
                  ('SelectDim ('ByIndex 3))
                  (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)))
            (UnsqueezeF ('SelectDim ('ByIndex 1)) decoderAttentionMaskShape)))
-&gt; Tensor
     (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
     (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
     (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
     (Seq
        (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
        dataType)
     (TransposeF
        ('SelectDim ('ByIndex 1))
        ('SelectDim ('ByIndex 2))
        (TransposeF
           ('SelectDim ('ByIndex 2))
           ('SelectDim ('ByIndex 3))
           (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)))
-&gt; IxStateT
     m
     dropoutGeneratorOutput
     dropoutGeneratorOutput
     (Tensor
        (Or
           (Gradient RequiresGradient)
           (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
           decoderAttentionMaskGradient)
        (Unify
           (Layout LayoutType)
           (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
           decoderAttentionMaskLayout)
        (Unify
           (Device (DeviceType Nat))
           (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
           decoderAttentionMaskDevice)
        (Unify
           (DataType DType)
           (Seq
              (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
              dataType)
           decoderAttentionMaskDataType)
        (BroadcastShapesF
           (TransposeF
              ('SelectDim ('ByIndex 1))
              ('SelectDim ('ByIndex 2))
              (TransposeF
                 ('SelectDim ('ByIndex 2))
                 ('SelectDim ('ByIndex 3))
                 (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)))
           (UnsqueezeF ('SelectDim ('ByIndex 1)) decoderAttentionMaskShape)))
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Tensor
  (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
  (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
  (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
  (Seq
     (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
     dataType)
  (TransposeF
     ('SelectDim ('ByIndex 1))
     ('SelectDim ('ByIndex 2))
     (TransposeF
        ('SelectDim ('ByIndex 2))
        ('SelectDim ('ByIndex 3))
        (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)))
-&gt; Tensor
     decoderAttentionMaskGradient
     decoderAttentionMaskLayout
     decoderAttentionMaskDevice
     decoderAttentionMaskDataType
     (UnsqueezeF ('SelectDim ('ByIndex 1)) decoderAttentionMaskShape)
-&gt; Tensor
     (Or (Gradient RequiresGradient) gradient decoderRelPosGradient
      &lt;|&gt; decoderAttentionMaskGradient)
     (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout
      &lt;+&gt; decoderAttentionMaskLayout)
     (Unify (Device (DeviceType Nat)) device decoderRelPosDevice
      &lt;+&gt; decoderAttentionMaskDevice)
     (Seq
        (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
        dataType
      &lt;+&gt; decoderAttentionMaskDataType)
     (BroadcastShapesF
        (TransposeF
           ('SelectDim ('ByIndex 1))
           ('SelectDim ('ByIndex 2))
           (TransposeF
              ('SelectDim ('ByIndex 2))
              ('SelectDim ('ByIndex 3))
              (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)))
        (UnsqueezeF ('SelectDim ('ByIndex 1)) decoderAttentionMaskShape))
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (gradient' :: Gradient RequiresGradient)
       (layout' :: Layout LayoutType) (device' :: Device (DeviceType Nat))
       (dataType' :: DataType DType)
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]).
Tensor gradient layout device dataType shape
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; Tensor
     (gradient &lt;|&gt; gradient')
     (layout &lt;+&gt; layout')
     (device &lt;+&gt; device')
     (dataType &lt;+&gt; dataType')
     (BroadcastShapesF shape shape')
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#add"><span class="hs-operator hs-var">`add`</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  decoderAttentionMaskGradient
  decoderAttentionMaskLayout
  decoderAttentionMaskDevice
  decoderAttentionMaskDataType
  decoderAttentionMaskShape
-&gt; Tensor
     decoderAttentionMaskGradient
     decoderAttentionMaskLayout
     decoderAttentionMaskDevice
     decoderAttentionMaskDataType
     (UnsqueezeF ('SelectDim ('ByIndex 1)) decoderAttentionMaskShape)
forall (selectDim :: SelectDim (By Symbol Nat))
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]).
(shape' ~ UnsqueezeF selectDim shape, SingI selectDim) =&gt;
Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape'
</span><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#unsqueeze"><span class="hs-identifier hs-var">unsqueeze</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
  decoderAttentionMaskGradient
  decoderAttentionMaskLayout
  decoderAttentionMaskDevice
  decoderAttentionMaskDataType
  decoderAttentionMaskShape
</span><a href="#local-6989586621679775549"><span class="hs-identifier hs-var">decoderAttentionMask</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-482"></span><span>        </span><span id="local-6989586621679775544"><span class="annot"><span class="annottext">crossAttentionBias :: Tensor
  crossAttentionMaskGradient
  crossAttentionMaskLayout
  crossAttentionMaskDevice
  crossAttentionMaskDataType
  (UnsqueezeF ('SelectDim ('ByIndex 1)) crossAttentionMaskShape)
</span><a href="#local-6989586621679775544"><span class="hs-identifier hs-var hs-var">crossAttentionBias</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor
  crossAttentionMaskGradient
  crossAttentionMaskLayout
  crossAttentionMaskDevice
  crossAttentionMaskDataType
  crossAttentionMaskShape
-&gt; Tensor
     crossAttentionMaskGradient
     crossAttentionMaskLayout
     crossAttentionMaskDevice
     crossAttentionMaskDataType
     (UnsqueezeF ('SelectDim ('ByIndex 1)) crossAttentionMaskShape)
forall (selectDim :: SelectDim (By Symbol Nat))
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]).
(shape' ~ UnsqueezeF selectDim shape, SingI selectDim) =&gt;
Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape'
</span><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#unsqueeze"><span class="hs-identifier hs-var">unsqueeze</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
  crossAttentionMaskGradient
  crossAttentionMaskLayout
  crossAttentionMaskDevice
  crossAttentionMaskDataType
  crossAttentionMaskShape
</span><a href="#local-6989586621679775548"><span class="hs-identifier hs-var">crossAttentionMask</span></a></span><span>
</span><span id="line-483"></span><span>     </span><span class="hs-keyword">in</span><span> </span><span class="annot"><span class="annottext">IxStateT m generator generatorOutput output
-&gt; generator -&gt; m (output, generatorOutput)
forall (m :: * -&gt; *) i j a. IxStateT m i j a -&gt; i -&gt; m (a, j)
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var hs-var">runIxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">(IxStateT m generator generatorOutput output
 -&gt; generator -&gt; m (output, generatorOutput))
-&gt; IxStateT m generator generatorOutput output
-&gt; generator
-&gt; m (output, generatorOutput)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-484"></span><span>          </span><span class="annot"><span class="annottext">decoderInput -&gt; IxStateT m generator generator decoderInput
forall k (m :: k -&gt; k -&gt; * -&gt; *) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">decoderInput
</span><a href="#local-6989586621679775552"><span class="hs-identifier hs-var">decoderInput</span></a></span><span>
</span><span id="line-485"></span><span>            </span><span class="annot"><span class="annottext">IxStateT m generator generator decoderInput
-&gt; (decoderInput
    -&gt; IxStateT m generator dropoutGeneratorOutput dropoutOutput)
-&gt; IxStateT m generator dropoutGeneratorOutput dropoutOutput
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(generator -&gt; m (dropoutOutput, dropoutGeneratorOutput))
-&gt; IxStateT m generator dropoutGeneratorOutput dropoutOutput
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((generator -&gt; m (dropoutOutput, dropoutGeneratorOutput))
 -&gt; IxStateT m generator dropoutGeneratorOutput dropoutOutput)
-&gt; (decoderInput
    -&gt; generator -&gt; m (dropoutOutput, dropoutGeneratorOutput))
-&gt; decoderInput
-&gt; IxStateT m generator dropoutGeneratorOutput dropoutOutput
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Dropout dropoutP
-&gt; decoderInput
-&gt; generator
-&gt; m (dropoutOutput, dropoutGeneratorOutput)
forall model input generator output generatorOutput (m :: * -&gt; *).
(HasForward model input generator output generatorOutput,
 MonadThrow m) =&gt;
model -&gt; input -&gt; generator -&gt; m (output, generatorOutput)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">Dropout dropoutP
TDDropoutF 'T5 dropoutP
</span><a href="#local-6989586621679775554"><span class="hs-identifier hs-var">tdDropout</span></a></span><span>
</span><span id="line-486"></span><span>            </span><span class="annot"><span class="annottext">IxStateT m generator dropoutGeneratorOutput dropoutOutput
-&gt; (dropoutOutput
    -&gt; IxStateT
         m dropoutGeneratorOutput stackGeneratorOutput stackOutput)
-&gt; IxStateT m generator stackGeneratorOutput stackOutput
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="hs-special">(</span><span> </span><span class="hs-glyph">\</span><span id="local-6989586621679775542"><span class="annot"><span class="annottext">dropoutOutput
</span><a href="#local-6989586621679775542"><span class="hs-identifier hs-var">decoderInput'</span></a></span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-487"></span><span>                     </span><span class="annot"><span class="annottext">IxStateT
  m
  dropoutGeneratorOutput
  dropoutGeneratorOutput
  (Tensor
     (Or
        (Gradient RequiresGradient)
        (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
        decoderAttentionMaskGradient)
     (Unify
        (Layout LayoutType)
        (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
        decoderAttentionMaskLayout)
     (Unify
        (Device (DeviceType Nat))
        (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
        decoderAttentionMaskDevice)
     (Unify
        (DataType DType)
        (Seq
           (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
           dataType)
        decoderAttentionMaskDataType)
     (BroadcastShapesF
        (TransposeF
           ('SelectDim ('ByIndex 1))
           ('SelectDim ('ByIndex 2))
           (TransposeF
              ('SelectDim ('ByIndex 2))
              ('SelectDim ('ByIndex 3))
              (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)))
        (UnsqueezeF ('SelectDim ('ByIndex 1)) decoderAttentionMaskShape)))
</span><a href="#local-6989586621679775545"><span class="hs-identifier hs-var">decoderAttentionBias</span></a></span><span>
</span><span id="line-488"></span><span>                       </span><span class="annot"><span class="annottext">IxStateT
  m
  dropoutGeneratorOutput
  dropoutGeneratorOutput
  (Tensor
     (Or
        (Gradient RequiresGradient)
        (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
        decoderAttentionMaskGradient)
     (Unify
        (Layout LayoutType)
        (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
        decoderAttentionMaskLayout)
     (Unify
        (Device (DeviceType Nat))
        (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
        decoderAttentionMaskDevice)
     (Unify
        (DataType DType)
        (Seq
           (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
           dataType)
        decoderAttentionMaskDataType)
     (BroadcastShapesF
        (TransposeF
           ('SelectDim ('ByIndex 1))
           ('SelectDim ('ByIndex 2))
           (TransposeF
              ('SelectDim ('ByIndex 2))
              ('SelectDim ('ByIndex 3))
              (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)))
        (UnsqueezeF ('SelectDim ('ByIndex 1)) decoderAttentionMaskShape)))
-&gt; (Tensor
      (Or
         (Gradient RequiresGradient)
         (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
         decoderAttentionMaskGradient)
      (Unify
         (Layout LayoutType)
         (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
         decoderAttentionMaskLayout)
      (Unify
         (Device (DeviceType Nat))
         (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
         decoderAttentionMaskDevice)
      (Unify
         (DataType DType)
         (Seq
            (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
            dataType)
         decoderAttentionMaskDataType)
      (BroadcastShapesF
         (TransposeF
            ('SelectDim ('ByIndex 1))
            ('SelectDim ('ByIndex 2))
            (TransposeF
               ('SelectDim ('ByIndex 2))
               ('SelectDim ('ByIndex 3))
               (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)))
         (UnsqueezeF ('SelectDim ('ByIndex 1)) decoderAttentionMaskShape))
    -&gt; IxStateT
         m dropoutGeneratorOutput stackGeneratorOutput stackOutput)
-&gt; IxStateT
     m dropoutGeneratorOutput stackGeneratorOutput stackOutput
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="hs-special">(</span><span> </span><span class="hs-glyph">\</span><span id="local-6989586621679775541"><span class="annot"><span class="annottext">Tensor
  (Or
     (Gradient RequiresGradient)
     (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
     decoderAttentionMaskGradient)
  (Unify
     (Layout LayoutType)
     (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
     decoderAttentionMaskLayout)
  (Unify
     (Device (DeviceType Nat))
     (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
     decoderAttentionMaskDevice)
  (Unify
     (DataType DType)
     (Seq
        (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
        dataType)
     decoderAttentionMaskDataType)
  (BroadcastShapesF
     (TransposeF
        ('SelectDim ('ByIndex 1))
        ('SelectDim ('ByIndex 2))
        (TransposeF
           ('SelectDim ('ByIndex 2))
           ('SelectDim ('ByIndex 3))
           (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)))
     (UnsqueezeF ('SelectDim ('ByIndex 1)) decoderAttentionMaskShape))
</span><a href="#local-6989586621679775541"><span class="hs-identifier hs-var">decoderAttentionBias'</span></a></span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-489"></span><span>                                </span><span class="annot"><span class="annottext">(dropoutGeneratorOutput -&gt; m (stackOutput, stackGeneratorOutput))
-&gt; IxStateT
     m dropoutGeneratorOutput stackGeneratorOutput stackOutput
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((dropoutGeneratorOutput -&gt; m (stackOutput, stackGeneratorOutput))
 -&gt; IxStateT
      m dropoutGeneratorOutput stackGeneratorOutput stackOutput)
-&gt; (dropoutGeneratorOutput
    -&gt; m (stackOutput, stackGeneratorOutput))
-&gt; IxStateT
     m dropoutGeneratorOutput stackGeneratorOutput stackOutput
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-490"></span><span>                                  </span><span class="annot"><span class="annottext">TransformerDecoderStack
  'T5
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  decoderInputEmbedDim
  encoderOutputEmbedDim
  ffnDim
  dropoutP
-&gt; (dropoutOutput, encoderOutput,
    Tensor
      (Or
         (Gradient RequiresGradient)
         (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
         decoderAttentionMaskGradient)
      (Unify
         (Layout LayoutType)
         (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
         decoderAttentionMaskLayout)
      (Unify
         (Device (DeviceType Nat))
         (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
         decoderAttentionMaskDevice)
      (Unify
         (DataType DType)
         (Seq
            (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
            dataType)
         decoderAttentionMaskDataType)
      (BroadcastShapesF
         (TransposeF
            ('SelectDim ('ByIndex 1))
            ('SelectDim ('ByIndex 2))
            (TransposeF
               ('SelectDim ('ByIndex 2))
               ('SelectDim ('ByIndex 3))
               (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)))
         (UnsqueezeF ('SelectDim ('ByIndex 1)) decoderAttentionMaskShape)),
    Tensor
      crossAttentionMaskGradient
      crossAttentionMaskLayout
      crossAttentionMaskDevice
      crossAttentionMaskDataType
      (UnsqueezeF ('SelectDim ('ByIndex 1)) crossAttentionMaskShape))
-&gt; dropoutGeneratorOutput
-&gt; m (stackOutput, stackGeneratorOutput)
forall model input generator output generatorOutput (m :: * -&gt; *).
(HasForward model input generator output generatorOutput,
 MonadThrow m) =&gt;
model -&gt; input -&gt; generator -&gt; m (output, generatorOutput)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span>
</span><span id="line-491"></span><span>                                    </span><span class="annot"><span class="annottext">TransformerDecoderStack
  'T5
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  decoderInputEmbedDim
  encoderOutputEmbedDim
  ffnDim
  dropoutP
TDStackF
  'T5
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  decoderInputEmbedDim
  encoderOutputEmbedDim
  ffnDim
  dropoutP
</span><a href="#local-6989586621679775557"><span class="hs-identifier hs-var">tdStack</span></a></span><span>
</span><span id="line-492"></span><span>                                    </span><span class="hs-special">(</span><span> </span><span class="annot"><span class="annottext">dropoutOutput
</span><a href="#local-6989586621679775542"><span class="hs-identifier hs-var">decoderInput'</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-493"></span><span>                                      </span><span class="annot"><span class="annottext">encoderOutput
</span><a href="#local-6989586621679775551"><span class="hs-identifier hs-var">encoderOutput</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-494"></span><span>                                      </span><span class="annot"><span class="annottext">Tensor
  (Or
     (Gradient RequiresGradient)
     (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
     decoderAttentionMaskGradient)
  (Unify
     (Layout LayoutType)
     (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
     decoderAttentionMaskLayout)
  (Unify
     (Device (DeviceType Nat))
     (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
     decoderAttentionMaskDevice)
  (Unify
     (DataType DType)
     (Seq
        (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
        dataType)
     decoderAttentionMaskDataType)
  (BroadcastShapesF
     (TransposeF
        ('SelectDim ('ByIndex 1))
        ('SelectDim ('ByIndex 2))
        (TransposeF
           ('SelectDim ('ByIndex 2))
           ('SelectDim ('ByIndex 3))
           (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)))
     (UnsqueezeF ('SelectDim ('ByIndex 1)) decoderAttentionMaskShape))
</span><a href="#local-6989586621679775541"><span class="hs-identifier hs-var">decoderAttentionBias'</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-495"></span><span>                                      </span><span class="annot"><span class="annottext">Tensor
  crossAttentionMaskGradient
  crossAttentionMaskLayout
  crossAttentionMaskDevice
  crossAttentionMaskDataType
  (UnsqueezeF ('SelectDim ('ByIndex 1)) crossAttentionMaskShape)
</span><a href="#local-6989586621679775544"><span class="hs-identifier hs-var">crossAttentionBias</span></a></span><span>
</span><span id="line-496"></span><span>                                    </span><span class="hs-special">)</span><span>
</span><span id="line-497"></span><span>                            </span><span class="hs-special">)</span><span>
</span><span id="line-498"></span><span>                 </span><span class="hs-special">)</span><span>
</span><span id="line-499"></span><span>            </span><span class="annot"><span class="annottext">IxStateT m generator stackGeneratorOutput stackOutput
-&gt; (stackOutput
    -&gt; IxStateT
         m stackGeneratorOutput layerNormGeneratorOutput layerNormOutput)
-&gt; IxStateT m generator layerNormGeneratorOutput layerNormOutput
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(stackGeneratorOutput
 -&gt; m (layerNormOutput, layerNormGeneratorOutput))
-&gt; IxStateT
     m stackGeneratorOutput layerNormGeneratorOutput layerNormOutput
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((stackGeneratorOutput
  -&gt; m (layerNormOutput, layerNormGeneratorOutput))
 -&gt; IxStateT
      m stackGeneratorOutput layerNormGeneratorOutput layerNormOutput)
-&gt; (stackOutput
    -&gt; stackGeneratorOutput
    -&gt; m (layerNormOutput, layerNormGeneratorOutput))
-&gt; stackOutput
-&gt; IxStateT
     m stackGeneratorOutput layerNormGeneratorOutput layerNormOutput
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">LayerNorm
  'WithoutBias
  gradient
  device
  dataType
  ('Shape '[decoderInputEmbedDim])
-&gt; stackOutput
-&gt; stackGeneratorOutput
-&gt; m (layerNormOutput, layerNormGeneratorOutput)
forall model input generator output generatorOutput (m :: * -&gt; *).
(HasForward model input generator output generatorOutput,
 MonadThrow m) =&gt;
model -&gt; input -&gt; generator -&gt; m (output, generatorOutput)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">LayerNorm
  'WithoutBias
  gradient
  device
  dataType
  ('Shape '[decoderInputEmbedDim])
TDLayerNormF 'T5 gradient device dataType decoderInputEmbedDim
</span><a href="#local-6989586621679775555"><span class="hs-identifier hs-var">tdLayerNorm</span></a></span><span>
</span><span id="line-500"></span><span>            </span><span class="annot"><span class="annottext">IxStateT m generator layerNormGeneratorOutput layerNormOutput
-&gt; (layerNormOutput
    -&gt; IxStateT m layerNormGeneratorOutput generatorOutput output)
-&gt; IxStateT m generator generatorOutput output
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(layerNormGeneratorOutput -&gt; m (output, generatorOutput))
-&gt; IxStateT m layerNormGeneratorOutput generatorOutput output
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((layerNormGeneratorOutput -&gt; m (output, generatorOutput))
 -&gt; IxStateT m layerNormGeneratorOutput generatorOutput output)
-&gt; (layerNormOutput
    -&gt; layerNormGeneratorOutput -&gt; m (output, generatorOutput))
-&gt; layerNormOutput
-&gt; IxStateT m layerNormGeneratorOutput generatorOutput output
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Dropout dropoutP
-&gt; layerNormOutput
-&gt; layerNormGeneratorOutput
-&gt; m (output, generatorOutput)
forall model input generator output generatorOutput (m :: * -&gt; *).
(HasForward model input generator output generatorOutput,
 MonadThrow m) =&gt;
model -&gt; input -&gt; generator -&gt; m (output, generatorOutput)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">Dropout dropoutP
TDDropoutF 'T5 dropoutP
</span><a href="#local-6989586621679775554"><span class="hs-identifier hs-var">tdDropout</span></a></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span>
</span><span id="line-501"></span><span>
</span><span id="line-502"></span><span id="testDecoder"><span class="annot"><span class="annottext">testDecoder :: IO
  (Tensor
     ('Gradient 'WithGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     ('DataType 'Float)
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7),
           'Dim ('Name &quot;*&quot;) ('Size 512)]))
</span><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#testDecoder"><span class="hs-identifier hs-var hs-var">testDecoder</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-503"></span><span>  </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679775539"><span class="annot"><span class="annottext">gradient :: SGradient ('Gradient 'WithGradient)
</span><a href="#local-6989586621679775539"><span class="hs-identifier hs-var hs-var">gradient</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SRequiresGradient 'WithGradient
-&gt; SGradient ('Gradient 'WithGradient)
forall (requiresGradient :: RequiresGradient).
SRequiresGradient requiresGradient
-&gt; SGradient ('Gradient requiresGradient)
</span><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier hs-var">SGradient</span></a></span><span> </span><span class="annot"><span class="annottext">SRequiresGradient 'WithGradient
</span><a href="Torch.GraduallyTyped.RequiresGradient.html#SWithGradient"><span class="hs-identifier hs-var">SWithGradient</span></a></span><span>
</span><span id="line-504"></span><span>      </span><span id="local-6989586621679775536"><span class="annot"><span class="annottext">device :: SDevice ('Device 'CPU)
</span><a href="#local-6989586621679775536"><span class="hs-identifier hs-var hs-var">device</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SDeviceType 'CPU -&gt; SDevice ('Device 'CPU)
forall (deviceType :: DeviceType Nat).
SDeviceType deviceType -&gt; SDevice ('Device deviceType)
</span><a href="Torch.GraduallyTyped.Device.html#SDevice"><span class="hs-identifier hs-var">SDevice</span></a></span><span> </span><span class="annot"><span class="annottext">SDeviceType 'CPU
</span><a href="Torch.GraduallyTyped.Device.html#SCPU"><span class="hs-identifier hs-var">SCPU</span></a></span><span>
</span><span id="line-505"></span><span>      </span><span id="local-6989586621679775533"><span class="annot"><span class="annottext">dataType :: SDataType ('DataType 'Float)
</span><a href="#local-6989586621679775533"><span class="hs-identifier hs-var hs-var">dataType</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SDType 'Float -&gt; SDataType ('DataType 'Float)
forall (dType :: DType).
SDType dType -&gt; SDataType ('DataType dType)
</span><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier hs-var">SDataType</span></a></span><span> </span><span class="annot"><span class="annottext">SDType 'Float
</span><a href="Torch.GraduallyTyped.DType.html#SFloat"><span class="hs-identifier hs-var">SFloat</span></a></span><span>
</span><span id="line-506"></span><span>      </span><span id="local-6989586621679775530"><span class="annot"><span class="annottext">headDim :: SDim ('Dim ('Name &quot;*&quot;) ('Size 8))
</span><a href="#local-6989586621679775530"><span class="hs-identifier hs-var hs-var">headDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize ('Size 8) -&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 8))
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownNat 8 =&gt; SSize ('Size 8)
forall (size :: Nat). KnownNat size =&gt; SSize ('Size size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier hs-var">SSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">8</span></span><span>
</span><span id="line-507"></span><span>      </span><span id="local-6989586621679775527"><span class="annot"><span class="annottext">headEmbedDim :: SDim ('Dim ('Name &quot;*&quot;) ('Size 64))
</span><a href="#local-6989586621679775527"><span class="hs-identifier hs-var hs-var">headEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize ('Size 64) -&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 64))
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownNat 64 =&gt; SSize ('Size 64)
forall (size :: Nat). KnownNat size =&gt; SSize ('Size size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier hs-var">SSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">64</span></span><span>
</span><span id="line-508"></span><span>      </span><span id="local-6989586621679775526"><span class="annot"><span class="annottext">embedDim :: SDim ('Dim ('Name &quot;*&quot;) ('Size 512))
</span><a href="#local-6989586621679775526"><span class="hs-identifier hs-var hs-var">embedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize ('Size 512) -&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 512))
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownNat 512 =&gt; SSize ('Size 512)
forall (size :: Nat). KnownNat size =&gt; SSize ('Size size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier hs-var">SSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">512</span></span><span>
</span><span id="line-509"></span><span>      </span><span id="local-6989586621679775525"><span class="annot"><span class="annottext">decoderInputEmbedDim :: SDim ('Dim ('Name &quot;*&quot;) ('Size 512))
</span><a href="#local-6989586621679775525"><span class="hs-identifier hs-var hs-var">decoderInputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize ('Size 512) -&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 512))
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownNat 512 =&gt; SSize ('Size 512)
forall (size :: Nat). KnownNat size =&gt; SSize ('Size size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier hs-var">SSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">512</span></span><span>
</span><span id="line-510"></span><span>      </span><span id="local-6989586621679775524"><span class="annot"><span class="annottext">encoderOutputEmbedDim :: SDim ('Dim ('Name &quot;*&quot;) ('Size 512))
</span><a href="#local-6989586621679775524"><span class="hs-identifier hs-var hs-var">encoderOutputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 512))
</span><a href="#local-6989586621679775525"><span class="hs-identifier hs-var">decoderInputEmbedDim</span></a></span><span>
</span><span id="line-511"></span><span>      </span><span id="local-6989586621679775523"><span class="annot"><span class="annottext">ffnDim :: SDim ('Dim ('Name &quot;*&quot;) ('Size 2048))
</span><a href="#local-6989586621679775523"><span class="hs-identifier hs-var hs-var">ffnDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize ('Size 2048) -&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 2048))
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownNat 2048 =&gt; SSize ('Size 2048)
forall (size :: Nat). KnownNat size =&gt; SSize ('Size size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier hs-var">SSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">2048</span></span><span>
</span><span id="line-512"></span><span>      </span><span id="local-6989586621679775522"><span class="annot"><span class="annottext">posEncDim :: SDim ('Dim ('Name &quot;*&quot;) ('Size 32))
</span><a href="#local-6989586621679775522"><span class="hs-identifier hs-var hs-var">posEncDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize ('Size 32) -&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 32))
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownNat 32 =&gt; SSize ('Size 32)
forall (size :: Nat). KnownNat size =&gt; SSize ('Size size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier hs-var">SSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">32</span></span><span>
</span><span id="line-513"></span><span>      </span><span id="local-6989586621679775521"><span class="annot"><span class="annottext">Float
</span><a href="#local-6989586621679775521"><span class="hs-identifier hs-var">dropoutP</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Float</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Float
</span><span class="hs-number">0.0</span></span><span>
</span><span id="line-514"></span><span>      </span><span id="local-6989586621679775520"><span class="annot"><span class="annottext">eps :: Double
</span><a href="#local-6989586621679775520"><span class="hs-identifier hs-var hs-var">eps</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Double
</span><span class="hs-number">1e-6</span></span><span>
</span><span id="line-515"></span><span>  </span><span id="local-6989586621679775519"><span class="annot"><span class="annottext">Generator ('Device 'CPU)
</span><a href="#local-6989586621679775519"><span class="hs-identifier hs-var">g</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">SDevice ('Device 'CPU) -&gt; Word64 -&gt; IO (Generator ('Device 'CPU))
forall (device :: Device (DeviceType Nat)).
SDevice device -&gt; Word64 -&gt; IO (Generator device)
</span><a href="Torch.GraduallyTyped.Random.html#sMkGenerator"><span class="hs-identifier hs-var">sMkGenerator</span></a></span><span> </span><span class="annot"><span class="annottext">SDevice ('Device 'CPU)
</span><a href="#local-6989586621679775536"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">Word64
</span><span class="hs-number">0</span></span><span>
</span><span id="line-516"></span><span>  </span><span class="hs-keyword">let</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679775518"><span class="annot"><span class="annottext">TransformerDecoder
  'T5
  1
  ('Gradient 'WithGradient)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Dim ('Name &quot;*&quot;) ('Size 8))
  ('Dim ('Name &quot;*&quot;) ('Size 64))
  ('Dim ('Name &quot;*&quot;) ('Size 512))
  ('Dim ('Name &quot;*&quot;) ('Size 512))
  ('Dim ('Name &quot;*&quot;) ('Size 512))
  ('Dim ('Name &quot;*&quot;) ('Size 2048))
  ('Dim ('Name &quot;*&quot;) ('Size 32))
  Float
</span><a href="#local-6989586621679775518"><span class="hs-identifier hs-var">encoder</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679775517"><span class="annot"><span class="annottext">Generator ('Device 'CPU)
</span><a href="#local-6989586621679775517"><span class="hs-identifier hs-var">g'</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(SGradient ('Gradient 'WithGradient), SDevice ('Device 'CPU),
 SDataType ('DataType 'Float), SDim ('Dim ('Name &quot;*&quot;) ('Size 8)),
 SDim ('Dim ('Name &quot;*&quot;) ('Size 64)),
 SDim ('Dim ('Name &quot;*&quot;) ('Size 512)),
 SDim ('Dim ('Name &quot;*&quot;) ('Size 512)),
 SDim ('Dim ('Name &quot;*&quot;) ('Size 512)),
 SDim ('Dim ('Name &quot;*&quot;) ('Size 2048)),
 SDim ('Dim ('Name &quot;*&quot;) ('Size 32)), Float, Double)
-&gt; Generator ('Device 'CPU)
-&gt; (TransformerDecoder
      'T5
      1
      ('Gradient 'WithGradient)
      ('Device 'CPU)
      ('DataType 'Float)
      ('Dim ('Name &quot;*&quot;) ('Size 8))
      ('Dim ('Name &quot;*&quot;) ('Size 64))
      ('Dim ('Name &quot;*&quot;) ('Size 512))
      ('Dim ('Name &quot;*&quot;) ('Size 512))
      ('Dim ('Name &quot;*&quot;) ('Size 512))
      ('Dim ('Name &quot;*&quot;) ('Size 2048))
      ('Dim ('Name &quot;*&quot;) ('Size 32))
      Float,
    Generator ('Device 'CPU))
forall model input generator generatorOutput.
HasInitialize model input generator generatorOutput =&gt;
input -&gt; generator -&gt; (model, generatorOutput)
</span><a href="Torch.GraduallyTyped.NN.Class.html#initialize"><span class="hs-identifier hs-var">initialize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TransformerDecoder"><span class="hs-identifier hs-type">TransformerDecoder</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#T5"><span class="hs-identifier hs-type">T5</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SGradient ('Gradient 'WithGradient)
</span><a href="#local-6989586621679775539"><span class="hs-identifier hs-var">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDevice ('Device 'CPU)
</span><a href="#local-6989586621679775536"><span class="hs-identifier hs-var">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDataType ('DataType 'Float)
</span><a href="#local-6989586621679775533"><span class="hs-identifier hs-var">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 8))
</span><a href="#local-6989586621679775530"><span class="hs-identifier hs-var">headDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 64))
</span><a href="#local-6989586621679775527"><span class="hs-identifier hs-var">headEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 512))
</span><a href="#local-6989586621679775526"><span class="hs-identifier hs-var">embedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 512))
</span><a href="#local-6989586621679775525"><span class="hs-identifier hs-var">decoderInputEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 512))
</span><a href="#local-6989586621679775524"><span class="hs-identifier hs-var">encoderOutputEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 2048))
</span><a href="#local-6989586621679775523"><span class="hs-identifier hs-var">ffnDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 32))
</span><a href="#local-6989586621679775522"><span class="hs-identifier hs-var">posEncDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Float
</span><a href="#local-6989586621679775521"><span class="hs-identifier hs-var">dropoutP</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679775520"><span class="hs-identifier hs-var">eps</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Generator ('Device 'CPU)
</span><a href="#local-6989586621679775519"><span class="hs-identifier hs-var">g</span></a></span><span>
</span><span id="line-517"></span><span>      </span><span id="local-6989586621679775516"><span class="annot"><span class="annottext">batchDim :: SDim ('Dim ('Name &quot;*&quot;) ('Size 3))
</span><a href="#local-6989586621679775516"><span class="hs-identifier hs-var hs-var">batchDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize ('Size 3) -&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 3))
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownNat 3 =&gt; SSize ('Size 3)
forall (size :: Nat). KnownNat size =&gt; SSize ('Size size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier hs-var">SSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">3</span></span><span>
</span><span id="line-518"></span><span>      </span><span id="local-6989586621679775515"><span class="annot"><span class="annottext">seqDim :: SDim ('Dim ('Name &quot;*&quot;) ('Size 13))
</span><a href="#local-6989586621679775515"><span class="hs-identifier hs-var hs-var">seqDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize ('Size 13) -&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 13))
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownNat 13 =&gt; SSize ('Size 13)
forall (size :: Nat). KnownNat size =&gt; SSize ('Size size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier hs-var">SSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">13</span></span><span>
</span><span id="line-519"></span><span>      </span><span id="local-6989586621679775514"><span class="annot"><span class="annottext">decoderSeqDim :: SDim ('Dim ('Name &quot;*&quot;) ('Size 7))
</span><a href="#local-6989586621679775514"><span class="hs-identifier hs-var hs-var">decoderSeqDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize ('Size 7) -&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 7))
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownNat 7 =&gt; SSize ('Size 7)
forall (size :: Nat). KnownNat size =&gt; SSize ('Size size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier hs-var">SSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">7</span></span><span>
</span><span id="line-520"></span><span>      </span><span id="local-6989586621679775513"><span class="annot"><span class="annottext">sOnes' :: SDataType dataType
-&gt; SShape shape
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     dataType
     shape
</span><a href="#local-6989586621679775513"><span class="hs-identifier hs-var hs-var">sOnes'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SGradient ('Gradient 'WithoutGradient)
-&gt; SLayout ('Layout 'Dense)
-&gt; SDevice ('Device 'CPU)
-&gt; SDataType dataType
-&gt; SShape shape
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     dataType
     shape
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SShape shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.Creation.html#sOnes"><span class="hs-identifier hs-var">sOnes</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SRequiresGradient 'WithoutGradient
-&gt; SGradient ('Gradient 'WithoutGradient)
forall (requiresGradient :: RequiresGradient).
SRequiresGradient requiresGradient
-&gt; SGradient ('Gradient requiresGradient)
</span><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier hs-var">SGradient</span></a></span><span> </span><span class="annot"><span class="annottext">SRequiresGradient 'WithoutGradient
</span><a href="Torch.GraduallyTyped.RequiresGradient.html#SWithoutGradient"><span class="hs-identifier hs-var">SWithoutGradient</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SLayoutType 'Dense -&gt; SLayout ('Layout 'Dense)
forall (layoutType :: LayoutType).
SLayoutType layoutType -&gt; SLayout ('Layout layoutType)
</span><a href="Torch.GraduallyTyped.Layout.html#SLayout"><span class="hs-identifier hs-var">SLayout</span></a></span><span> </span><span class="annot"><span class="annottext">SLayoutType 'Dense
</span><a href="Torch.GraduallyTyped.Layout.html#SDense"><span class="hs-identifier hs-var">SDense</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">SDevice ('Device 'CPU)
</span><a href="#local-6989586621679775536"><span class="hs-identifier hs-var">device</span></a></span><span>
</span><span id="line-521"></span><span>      </span><span id="local-6989586621679775511"><span class="annot"><span class="annottext">decoderInput :: Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7),
        'Dim ('Name &quot;*&quot;) ('Size 512)])
</span><a href="#local-6989586621679775511"><span class="hs-identifier hs-var hs-var">decoderInput</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SDataType ('DataType 'Float)
-&gt; SShape
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7),
           'Dim ('Name &quot;*&quot;) ('Size 512)])
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     ('DataType 'Float)
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7),
           'Dim ('Name &quot;*&quot;) ('Size 512)])
forall (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SDataType dataType
-&gt; SShape shape
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     dataType
     shape
</span><a href="#local-6989586621679775513"><span class="hs-identifier hs-var">sOnes'</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType ('DataType 'Float)
</span><a href="#local-6989586621679775533"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SList
  '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7),
     'Dim ('Name &quot;*&quot;) ('Size 512)]
-&gt; SShape
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7),
           'Dim ('Name &quot;*&quot;) ('Size 512)])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList
   '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7),
      'Dim ('Name &quot;*&quot;) ('Size 512)]
 -&gt; SShape
      ('Shape
         '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7),
            'Dim ('Name &quot;*&quot;) ('Size 512)]))
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7),
        'Dim ('Name &quot;*&quot;) ('Size 512)]
-&gt; SShape
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7),
           'Dim ('Name &quot;*&quot;) ('Size 512)])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 3))
</span><a href="#local-6989586621679775516"><span class="hs-identifier hs-var">batchDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 3))
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 7), 'Dim ('Name &quot;*&quot;) ('Size 512)]
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7),
        'Dim ('Name &quot;*&quot;) ('Size 512)]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 7))
</span><a href="#local-6989586621679775514"><span class="hs-identifier hs-var">decoderSeqDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 7))
-&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 512)]
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 7), 'Dim ('Name &quot;*&quot;) ('Size 512)]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 512))
</span><a href="#local-6989586621679775525"><span class="hs-identifier hs-var">decoderInputEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 512))
-&gt; SList '[] -&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 512)]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-522"></span><span>      </span><span id="local-6989586621679775510"><span class="annot"><span class="annottext">encoderOutput :: Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 13),
        'Dim ('Name &quot;*&quot;) ('Size 512)])
</span><a href="#local-6989586621679775510"><span class="hs-identifier hs-var hs-var">encoderOutput</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SDataType ('DataType 'Float)
-&gt; SShape
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 13),
           'Dim ('Name &quot;*&quot;) ('Size 512)])
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     ('DataType 'Float)
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 13),
           'Dim ('Name &quot;*&quot;) ('Size 512)])
forall (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SDataType dataType
-&gt; SShape shape
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     dataType
     shape
</span><a href="#local-6989586621679775513"><span class="hs-identifier hs-var">sOnes'</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType ('DataType 'Float)
</span><a href="#local-6989586621679775533"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SList
  '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 13),
     'Dim ('Name &quot;*&quot;) ('Size 512)]
-&gt; SShape
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 13),
           'Dim ('Name &quot;*&quot;) ('Size 512)])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList
   '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 13),
      'Dim ('Name &quot;*&quot;) ('Size 512)]
 -&gt; SShape
      ('Shape
         '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 13),
            'Dim ('Name &quot;*&quot;) ('Size 512)]))
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 13),
        'Dim ('Name &quot;*&quot;) ('Size 512)]
-&gt; SShape
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 13),
           'Dim ('Name &quot;*&quot;) ('Size 512)])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 3))
</span><a href="#local-6989586621679775516"><span class="hs-identifier hs-var">batchDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 3))
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 13), 'Dim ('Name &quot;*&quot;) ('Size 512)]
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 13),
        'Dim ('Name &quot;*&quot;) ('Size 512)]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 13))
</span><a href="#local-6989586621679775515"><span class="hs-identifier hs-var">seqDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 13))
-&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 512)]
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 13), 'Dim ('Name &quot;*&quot;) ('Size 512)]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 512))
</span><a href="#local-6989586621679775524"><span class="hs-identifier hs-var">encoderOutputEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 512))
-&gt; SList '[] -&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 512)]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-523"></span><span>      </span><span id="local-6989586621679775509"><span class="annot"><span class="annottext">decoderRelPos :: Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Int64)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 7),
        'Dim ('Name &quot;*&quot;) ('Size 7)])
</span><a href="#local-6989586621679775509"><span class="hs-identifier hs-var hs-var">decoderRelPos</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SDataType ('DataType 'Int64)
-&gt; SShape
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 7),
           'Dim ('Name &quot;*&quot;) ('Size 7)])
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     ('DataType 'Int64)
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 7),
           'Dim ('Name &quot;*&quot;) ('Size 7)])
forall (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SDataType dataType
-&gt; SShape shape
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     dataType
     shape
</span><a href="#local-6989586621679775513"><span class="hs-identifier hs-var">sOnes'</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SDType 'Int64 -&gt; SDataType ('DataType 'Int64)
forall (dType :: DType).
SDType dType -&gt; SDataType ('DataType dType)
</span><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier hs-var">SDataType</span></a></span><span> </span><span class="annot"><span class="annottext">SDType 'Int64
</span><a href="Torch.GraduallyTyped.DType.html#SInt64"><span class="hs-identifier hs-var">SInt64</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SList
  '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 7),
     'Dim ('Name &quot;*&quot;) ('Size 7)]
-&gt; SShape
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 7),
           'Dim ('Name &quot;*&quot;) ('Size 7)])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList
   '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 7),
      'Dim ('Name &quot;*&quot;) ('Size 7)]
 -&gt; SShape
      ('Shape
         '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 7),
            'Dim ('Name &quot;*&quot;) ('Size 7)]))
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 7),
        'Dim ('Name &quot;*&quot;) ('Size 7)]
-&gt; SShape
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 7),
           'Dim ('Name &quot;*&quot;) ('Size 7)])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize ('Size 1) -&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 1))
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownNat 1 =&gt; SSize ('Size 1)
forall (size :: Nat). KnownNat size =&gt; SSize ('Size size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier hs-var">SSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">1</span></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 1))
-&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 7), 'Dim ('Name &quot;*&quot;) ('Size 7)]
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 7),
        'Dim ('Name &quot;*&quot;) ('Size 7)]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 7))
</span><a href="#local-6989586621679775514"><span class="hs-identifier hs-var">decoderSeqDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 7))
-&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 7)]
-&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 7), 'Dim ('Name &quot;*&quot;) ('Size 7)]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 7))
</span><a href="#local-6989586621679775514"><span class="hs-identifier hs-var">decoderSeqDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 7))
-&gt; SList '[] -&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 7)]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-524"></span><span>      </span><span id="local-6989586621679775507"><span class="annot"><span class="annottext">decoderAttentionMask :: Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7),
        'Dim ('Name &quot;*&quot;) ('Size 7)])
</span><a href="#local-6989586621679775507"><span class="hs-identifier hs-var hs-var">decoderAttentionMask</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SDataType ('DataType 'Float)
-&gt; SShape
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7),
           'Dim ('Name &quot;*&quot;) ('Size 7)])
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     ('DataType 'Float)
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7),
           'Dim ('Name &quot;*&quot;) ('Size 7)])
forall (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SDataType dataType
-&gt; SShape shape
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     dataType
     shape
</span><a href="#local-6989586621679775513"><span class="hs-identifier hs-var">sOnes'</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType ('DataType 'Float)
</span><a href="#local-6989586621679775533"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SList
  '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7),
     'Dim ('Name &quot;*&quot;) ('Size 7)]
-&gt; SShape
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7),
           'Dim ('Name &quot;*&quot;) ('Size 7)])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList
   '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7),
      'Dim ('Name &quot;*&quot;) ('Size 7)]
 -&gt; SShape
      ('Shape
         '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7),
            'Dim ('Name &quot;*&quot;) ('Size 7)]))
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7),
        'Dim ('Name &quot;*&quot;) ('Size 7)]
-&gt; SShape
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7),
           'Dim ('Name &quot;*&quot;) ('Size 7)])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 3))
</span><a href="#local-6989586621679775516"><span class="hs-identifier hs-var">batchDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 3))
-&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 7), 'Dim ('Name &quot;*&quot;) ('Size 7)]
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7),
        'Dim ('Name &quot;*&quot;) ('Size 7)]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 7))
</span><a href="#local-6989586621679775514"><span class="hs-identifier hs-var">decoderSeqDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 7))
-&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 7)]
-&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 7), 'Dim ('Name &quot;*&quot;) ('Size 7)]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 7))
</span><a href="#local-6989586621679775514"><span class="hs-identifier hs-var">decoderSeqDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 7))
-&gt; SList '[] -&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 7)]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-525"></span><span>      </span><span id="local-6989586621679775506"><span class="annot"><span class="annottext">crossAttentionMask :: Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7),
        'Dim ('Name &quot;*&quot;) ('Size 13)])
</span><a href="#local-6989586621679775506"><span class="hs-identifier hs-var hs-var">crossAttentionMask</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SDataType ('DataType 'Float)
-&gt; SShape
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7),
           'Dim ('Name &quot;*&quot;) ('Size 13)])
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     ('DataType 'Float)
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7),
           'Dim ('Name &quot;*&quot;) ('Size 13)])
forall (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SDataType dataType
-&gt; SShape shape
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     dataType
     shape
</span><a href="#local-6989586621679775513"><span class="hs-identifier hs-var">sOnes'</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType ('DataType 'Float)
</span><a href="#local-6989586621679775533"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SList
  '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7),
     'Dim ('Name &quot;*&quot;) ('Size 13)]
-&gt; SShape
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7),
           'Dim ('Name &quot;*&quot;) ('Size 13)])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList
   '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7),
      'Dim ('Name &quot;*&quot;) ('Size 13)]
 -&gt; SShape
      ('Shape
         '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7),
            'Dim ('Name &quot;*&quot;) ('Size 13)]))
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7),
        'Dim ('Name &quot;*&quot;) ('Size 13)]
-&gt; SShape
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7),
           'Dim ('Name &quot;*&quot;) ('Size 13)])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 3))
</span><a href="#local-6989586621679775516"><span class="hs-identifier hs-var">batchDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 3))
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 7), 'Dim ('Name &quot;*&quot;) ('Size 13)]
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7),
        'Dim ('Name &quot;*&quot;) ('Size 13)]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 7))
</span><a href="#local-6989586621679775514"><span class="hs-identifier hs-var">decoderSeqDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 7))
-&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 13)]
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 7), 'Dim ('Name &quot;*&quot;) ('Size 13)]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 13))
</span><a href="#local-6989586621679775515"><span class="hs-identifier hs-var">seqDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 13))
-&gt; SList '[] -&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 13)]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-526"></span><span>  </span><span class="hs-special">(</span><span id="local-6989586621679775505"><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7),
        'Dim ('Name &quot;*&quot;) ('Size 512)])
</span><a href="#local-6989586621679775505"><span class="hs-identifier hs-var">output</span></a></span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Generator ('Device 'CPU)
</span><span class="hs-identifier">_</span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">TransformerDecoder
  'T5
  1
  ('Gradient 'WithGradient)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Dim ('Name &quot;*&quot;) ('Size 8))
  ('Dim ('Name &quot;*&quot;) ('Size 64))
  ('Dim ('Name &quot;*&quot;) ('Size 512))
  ('Dim ('Name &quot;*&quot;) ('Size 512))
  ('Dim ('Name &quot;*&quot;) ('Size 512))
  ('Dim ('Name &quot;*&quot;) ('Size 2048))
  ('Dim ('Name &quot;*&quot;) ('Size 32))
  Float
-&gt; (Tensor
      ('Gradient 'WithoutGradient)
      ('Layout 'Dense)
      ('Device 'CPU)
      ('DataType 'Float)
      ('Shape
         '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7),
            'Dim ('Name &quot;*&quot;) ('Size 512)]),
    Tensor
      ('Gradient 'WithoutGradient)
      ('Layout 'Dense)
      ('Device 'CPU)
      ('DataType 'Float)
      ('Shape
         '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 13),
            'Dim ('Name &quot;*&quot;) ('Size 512)]),
    Tensor
      ('Gradient 'WithoutGradient)
      ('Layout 'Dense)
      ('Device 'CPU)
      ('DataType 'Int64)
      ('Shape
         '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 7),
            'Dim ('Name &quot;*&quot;) ('Size 7)]),
    Tensor
      ('Gradient 'WithoutGradient)
      ('Layout 'Dense)
      ('Device 'CPU)
      ('DataType 'Float)
      ('Shape
         '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7),
            'Dim ('Name &quot;*&quot;) ('Size 7)]),
    Tensor
      ('Gradient 'WithoutGradient)
      ('Layout 'Dense)
      ('Device 'CPU)
      ('DataType 'Float)
      ('Shape
         '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7),
            'Dim ('Name &quot;*&quot;) ('Size 13)]))
-&gt; Generator ('Device 'CPU)
-&gt; IO
     (Tensor
        ('Gradient 'WithGradient)
        ('Layout 'Dense)
        ('Device 'CPU)
        ('DataType 'Float)
        ('Shape
           '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7),
              'Dim ('Name &quot;*&quot;) ('Size 512)]),
      Generator ('Device 'CPU))
forall model input generator output generatorOutput (m :: * -&gt; *).
(HasForward model input generator output generatorOutput,
 MonadThrow m) =&gt;
model -&gt; input -&gt; generator -&gt; m (output, generatorOutput)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">TransformerDecoder
  'T5
  1
  ('Gradient 'WithGradient)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Dim ('Name &quot;*&quot;) ('Size 8))
  ('Dim ('Name &quot;*&quot;) ('Size 64))
  ('Dim ('Name &quot;*&quot;) ('Size 512))
  ('Dim ('Name &quot;*&quot;) ('Size 512))
  ('Dim ('Name &quot;*&quot;) ('Size 512))
  ('Dim ('Name &quot;*&quot;) ('Size 2048))
  ('Dim ('Name &quot;*&quot;) ('Size 32))
  Float
</span><a href="#local-6989586621679775518"><span class="hs-identifier hs-var">encoder</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7),
        'Dim ('Name &quot;*&quot;) ('Size 512)])
</span><a href="#local-6989586621679775511"><span class="hs-identifier hs-var">decoderInput</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 13),
        'Dim ('Name &quot;*&quot;) ('Size 512)])
</span><a href="#local-6989586621679775510"><span class="hs-identifier hs-var">encoderOutput</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Int64)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 7),
        'Dim ('Name &quot;*&quot;) ('Size 7)])
</span><a href="#local-6989586621679775509"><span class="hs-identifier hs-var">decoderRelPos</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7),
        'Dim ('Name &quot;*&quot;) ('Size 7)])
</span><a href="#local-6989586621679775507"><span class="hs-identifier hs-var">decoderAttentionMask</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7),
        'Dim ('Name &quot;*&quot;) ('Size 13)])
</span><a href="#local-6989586621679775506"><span class="hs-identifier hs-var">crossAttentionMask</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Generator ('Device 'CPU)
</span><a href="#local-6989586621679775517"><span class="hs-identifier hs-var">g'</span></a></span><span>
</span><span id="line-527"></span><span>  </span><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7),
        'Dim ('Name &quot;*&quot;) ('Size 512)])
-&gt; IO
     (Tensor
        ('Gradient 'WithGradient)
        ('Layout 'Dense)
        ('Device 'CPU)
        ('DataType 'Float)
        ('Shape
           '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7),
              'Dim ('Name &quot;*&quot;) ('Size 512)]))
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7),
        'Dim ('Name &quot;*&quot;) ('Size 512)])
</span><a href="#local-6989586621679775505"><span class="hs-identifier hs-var">output</span></a></span><span>
</span><span id="line-528"></span><span>
</span><span id="line-529"></span><span class="hs-comment">-- | 'HasForward' instance for @TransformerDecoder numLayers 'ByT5@.</span><span>
</span><span id="line-530"></span><span class="hs-comment">--</span><span>
</span><span id="line-531"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-532"></span><span class="hs-comment">-- &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;  &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;  &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;  &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;  &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;</span><span>
</span><span id="line-533"></span><span class="hs-comment">-- &#9474; decoderInput &#9474;  &#9474; encoderOutput &#9474;  &#9474; decoderRelPos &#9474;  &#9474; decoderAttentionMask &#9474;  &#9474; crossAttentionMask &#9474;</span><span>
</span><span id="line-534"></span><span class="hs-comment">-- &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;  &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;  &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;  &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;  &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-535"></span><span class="hs-comment">--        &#9474;                  &#9474;                  &#9474;                     &#9474;                        &#9474;</span><span>
</span><span id="line-536"></span><span class="hs-comment">--        &#9474;                  &#9474;                  &#9660;                     &#9474;                        &#9474;</span><span>
</span><span id="line-537"></span><span class="hs-comment">--        &#9474;                  &#9474;              tdPosEnc                  &#9474;                        &#9474;</span><span>
</span><span id="line-538"></span><span class="hs-comment">--        &#9474;                  &#9474;                  &#9660;                     &#9474;                        &#9474;</span><span>
</span><span id="line-539"></span><span class="hs-comment">--        &#9474;                  &#9474;              transpose                 &#9474;                        &#9474;</span><span>
</span><span id="line-540"></span><span class="hs-comment">--        &#9474;                  &#9474;                  &#9660;                     &#9660;                        &#9660;</span><span>
</span><span id="line-541"></span><span class="hs-comment">--        &#9474;                  &#9474;              transpose             unsqueeze                unsqueeze</span><span>
</span><span id="line-542"></span><span class="hs-comment">--        &#9660;                  &#9474;                  &#9474;                     &#9474;                        &#9474;</span><span>
</span><span id="line-543"></span><span class="hs-comment">--    tdDropout              &#9474;                  &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9658;add&#9668;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;                        &#9474;</span><span>
</span><span id="line-544"></span><span class="hs-comment">--        &#9660;                  &#9474;                             &#9474;                                   &#9474;</span><span>
</span><span id="line-545"></span><span class="hs-comment">--     tdStack&#9668;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;&#9668;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;&#9668;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-546"></span><span class="hs-comment">--        &#9660;</span><span>
</span><span id="line-547"></span><span class="hs-comment">--   tdLayerNorm</span><span>
</span><span id="line-548"></span><span class="hs-comment">--        &#9660;</span><span>
</span><span id="line-549"></span><span class="hs-comment">--    tdDropout</span><span>
</span><span id="line-550"></span><span class="hs-comment">--        &#9474;</span><span>
</span><span id="line-551"></span><span class="hs-comment">--        &#9660;</span><span>
</span><span id="line-552"></span><span class="hs-comment">--    &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;</span><span>
</span><span id="line-553"></span><span class="hs-comment">--    &#9474; output &#9474;</span><span>
</span><span id="line-554"></span><span class="hs-comment">--    &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-555"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-556"></span><span id="local-6989586621679775467"><span id="local-6989586621679775468"><span id="local-6989586621679775469"><span id="local-6989586621679775470"><span id="local-6989586621679775471"><span id="local-6989586621679775472"><span id="local-6989586621679775473"><span id="local-6989586621679775474"><span id="local-6989586621679775475"><span id="local-6989586621679775476"><span id="local-6989586621679775477"><span id="local-6989586621679775478"><span id="local-6989586621679775479"><span id="local-6989586621679775480"><span id="local-6989586621679775481"><span id="local-6989586621679775482"><span id="local-6989586621679775483"><span id="local-6989586621679775484"><span id="local-6989586621679775485"><span id="local-6989586621679775486"><span id="local-6989586621679775487"><span id="local-6989586621679775488"><span id="local-6989586621679775489"><span id="local-6989586621679775490"><span id="local-6989586621679775491"><span id="local-6989586621679775492"><span id="local-6989586621679775493"><span id="local-6989586621679775494"><span id="local-6989586621679775495"><span id="local-6989586621679775496"><span id="local-6989586621679775497"><span id="local-6989586621679775498"><span id="local-6989586621679775499"><span id="local-6989586621679775500"><span id="local-6989586621679775501"><span id="local-6989586621679775502"><span id="local-6989586621679775503"><span id="local-6989586621679775504"><span class="hs-keyword">instance</span><span>
</span><span id="line-557"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-558"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Dropout.html#Dropout"><span class="hs-identifier hs-type">Dropout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775504"><span class="hs-identifier hs-type">dropoutP</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-559"></span><span>      </span><span class="annot"><a href="#local-6989586621679775503"><span class="hs-identifier hs-type">decoderInput</span></a></span><span>
</span><span id="line-560"></span><span>      </span><span class="annot"><a href="#local-6989586621679775502"><span class="hs-identifier hs-type">generator</span></a></span><span>
</span><span id="line-561"></span><span>      </span><span class="annot"><a href="#local-6989586621679775501"><span class="hs-identifier hs-type">dropoutOutput</span></a></span><span>
</span><span id="line-562"></span><span>      </span><span class="annot"><a href="#local-6989586621679775500"><span class="hs-identifier hs-type">dropoutGeneratorOutput</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-563"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-564"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.DecoderStack.html#TransformerDecoderStack"><span class="hs-identifier hs-type">TransformerDecoderStack</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ByT5"><span class="hs-identifier hs-type">ByT5</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775499"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775498"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775497"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775496"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775495"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775494"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775493"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775492"><span class="hs-identifier hs-type">decoderInputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775491"><span class="hs-identifier hs-type">encoderOutputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775490"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775504"><span class="hs-identifier hs-type">dropoutP</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-565"></span><span>      </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="#local-6989586621679775501"><span class="hs-identifier hs-type">dropoutOutput</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-566"></span><span>        </span><span class="annot"><a href="#local-6989586621679775489"><span class="hs-identifier hs-type">encoderOutput</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-567"></span><span>        </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-568"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679775498"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775488"><span class="hs-identifier hs-type">decoderRelPosGradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775487"><span class="hs-identifier hs-type">decoderAttentionMaskGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-569"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Dense"><span class="hs-identifier hs-type">Dense</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775486"><span class="hs-identifier hs-type">decoderRelPosLayout</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775485"><span class="hs-identifier hs-type">decoderAttentionMaskLayout</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-570"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679775497"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775484"><span class="hs-identifier hs-type">decoderRelPosDevice</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775483"><span class="hs-identifier hs-type">decoderAttentionMaskDevice</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-571"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Seq"><span class="hs-identifier hs-type">Seq</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679775482"><span class="hs-identifier hs-type">decoderRelPosDataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#Int64"><span class="hs-identifier hs-type">Int64</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679775496"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775481"><span class="hs-identifier hs-type">decoderAttentionMaskDataType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-572"></span><span>          </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#BroadcastShapesF"><span class="hs-identifier hs-type">BroadcastShapesF</span></a></span><span>
</span><span id="line-573"></span><span>              </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#TransposeF"><span class="hs-identifier hs-type">TransposeF</span></a></span><span>
</span><span id="line-574"></span><span>                  </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-575"></span><span>                  </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">2</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-576"></span><span>                  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#TransposeF"><span class="hs-identifier hs-type">TransposeF</span></a></span><span>
</span><span id="line-577"></span><span>                      </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">2</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-578"></span><span>                      </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">3</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-579"></span><span>                      </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Functional.Sparse.html#EmbeddingF"><span class="hs-identifier hs-type">EmbeddingF</span></a></span><span>
</span><span id="line-580"></span><span>                          </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679775480"><span class="hs-identifier hs-type">posEncDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679775495"><span class="hs-identifier hs-type">headDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-581"></span><span>                          </span><span class="annot"><a href="#local-6989586621679775479"><span class="hs-identifier hs-type">decoderRelPosShape</span></a></span><span>
</span><span id="line-582"></span><span>                      </span><span class="hs-special">)</span><span>
</span><span id="line-583"></span><span>                  </span><span class="hs-special">)</span><span>
</span><span id="line-584"></span><span>              </span><span class="hs-special">)</span><span>
</span><span id="line-585"></span><span>              </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#UnsqueezeF"><span class="hs-identifier hs-type">UnsqueezeF</span></a></span><span>
</span><span id="line-586"></span><span>                  </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-587"></span><span>                  </span><span class="annot"><a href="#local-6989586621679775478"><span class="hs-identifier hs-type">decoderAttentionMaskShape</span></a></span><span>
</span><span id="line-588"></span><span>              </span><span class="hs-special">)</span><span>
</span><span id="line-589"></span><span>          </span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-590"></span><span>        </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-591"></span><span>          </span><span class="annot"><a href="#local-6989586621679775477"><span class="hs-identifier hs-type">crossAttentionMaskGradient</span></a></span><span>
</span><span id="line-592"></span><span>          </span><span class="annot"><a href="#local-6989586621679775476"><span class="hs-identifier hs-type">crossAttentionMaskLayout</span></a></span><span>
</span><span id="line-593"></span><span>          </span><span class="annot"><a href="#local-6989586621679775475"><span class="hs-identifier hs-type">crossAttentionMaskDevice</span></a></span><span>
</span><span id="line-594"></span><span>          </span><span class="annot"><a href="#local-6989586621679775474"><span class="hs-identifier hs-type">crossAttentionMaskDataType</span></a></span><span>
</span><span id="line-595"></span><span>          </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#UnsqueezeF"><span class="hs-identifier hs-type">UnsqueezeF</span></a></span><span>
</span><span id="line-596"></span><span>              </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-597"></span><span>              </span><span class="annot"><a href="#local-6989586621679775473"><span class="hs-identifier hs-type">crossAttentionMaskShape</span></a></span><span>
</span><span id="line-598"></span><span>          </span><span class="hs-special">)</span><span>
</span><span id="line-599"></span><span>      </span><span class="hs-special">)</span><span>
</span><span id="line-600"></span><span>      </span><span class="annot"><a href="#local-6989586621679775500"><span class="hs-identifier hs-type">dropoutGeneratorOutput</span></a></span><span>
</span><span id="line-601"></span><span>      </span><span class="annot"><a href="#local-6989586621679775472"><span class="hs-identifier hs-type">stackOutput</span></a></span><span>
</span><span id="line-602"></span><span>      </span><span class="annot"><a href="#local-6989586621679775471"><span class="hs-identifier hs-type">stackGeneratorOutput</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-603"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-604"></span><span>      </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Normalization.html#LayerNorm"><span class="hs-identifier hs-type">LayerNorm</span></a></span><span>
</span><span id="line-605"></span><span>          </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Type.html#WithoutBias"><span class="hs-identifier hs-type">WithoutBias</span></a></span><span>
</span><span id="line-606"></span><span>          </span><span class="annot"><a href="#local-6989586621679775498"><span class="hs-identifier hs-type">gradient</span></a></span><span>
</span><span id="line-607"></span><span>          </span><span class="annot"><a href="#local-6989586621679775497"><span class="hs-identifier hs-type">device</span></a></span><span>
</span><span id="line-608"></span><span>          </span><span class="annot"><a href="#local-6989586621679775496"><span class="hs-identifier hs-type">dataType</span></a></span><span>
</span><span id="line-609"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679775492"><span class="hs-identifier hs-type">decoderInputEmbedDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-610"></span><span>      </span><span class="hs-special">)</span><span>
</span><span id="line-611"></span><span>      </span><span class="annot"><a href="#local-6989586621679775472"><span class="hs-identifier hs-type">stackOutput</span></a></span><span>
</span><span id="line-612"></span><span>      </span><span class="annot"><a href="#local-6989586621679775471"><span class="hs-identifier hs-type">stackGeneratorOutput</span></a></span><span>
</span><span id="line-613"></span><span>      </span><span class="annot"><a href="#local-6989586621679775470"><span class="hs-identifier hs-type">layerNormOutput</span></a></span><span>
</span><span id="line-614"></span><span>      </span><span class="annot"><a href="#local-6989586621679775469"><span class="hs-identifier hs-type">layerNormGeneratorOutput</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-615"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-616"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Dropout.html#Dropout"><span class="hs-identifier hs-type">Dropout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775504"><span class="hs-identifier hs-type">dropoutP</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-617"></span><span>      </span><span class="annot"><a href="#local-6989586621679775470"><span class="hs-identifier hs-type">layerNormOutput</span></a></span><span>
</span><span id="line-618"></span><span>      </span><span class="annot"><a href="#local-6989586621679775469"><span class="hs-identifier hs-type">layerNormGeneratorOutput</span></a></span><span>
</span><span id="line-619"></span><span>      </span><span class="annot"><a href="#local-6989586621679775468"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-620"></span><span>      </span><span class="annot"><a href="#local-6989586621679775467"><span class="hs-identifier hs-type">generatorOutput</span></a></span><span>
</span><span id="line-621"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-622"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-623"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TransformerDecoder"><span class="hs-identifier hs-type">TransformerDecoder</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ByT5"><span class="hs-identifier hs-type">ByT5</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775499"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775498"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775497"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775496"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775495"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775494"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775493"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775492"><span class="hs-identifier hs-type">decoderInputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775491"><span class="hs-identifier hs-type">encoderOutputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775490"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775480"><span class="hs-identifier hs-type">posEncDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775504"><span class="hs-identifier hs-type">dropoutP</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-624"></span><span>    </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="#local-6989586621679775503"><span class="hs-identifier hs-type">decoderInput</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-625"></span><span>      </span><span class="annot"><a href="#local-6989586621679775489"><span class="hs-identifier hs-type">encoderOutput</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-626"></span><span>      </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775488"><span class="hs-identifier hs-type">decoderRelPosGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775486"><span class="hs-identifier hs-type">decoderRelPosLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775484"><span class="hs-identifier hs-type">decoderRelPosDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775482"><span class="hs-identifier hs-type">decoderRelPosDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775479"><span class="hs-identifier hs-type">decoderRelPosShape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-627"></span><span>      </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775487"><span class="hs-identifier hs-type">decoderAttentionMaskGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775485"><span class="hs-identifier hs-type">decoderAttentionMaskLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775483"><span class="hs-identifier hs-type">decoderAttentionMaskDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775481"><span class="hs-identifier hs-type">decoderAttentionMaskDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775478"><span class="hs-identifier hs-type">decoderAttentionMaskShape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-628"></span><span>      </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775477"><span class="hs-identifier hs-type">crossAttentionMaskGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775476"><span class="hs-identifier hs-type">crossAttentionMaskLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775475"><span class="hs-identifier hs-type">crossAttentionMaskDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775474"><span class="hs-identifier hs-type">crossAttentionMaskDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775473"><span class="hs-identifier hs-type">crossAttentionMaskShape</span></a></span><span>
</span><span id="line-629"></span><span>    </span><span class="hs-special">)</span><span>
</span><span id="line-630"></span><span>    </span><span class="annot"><a href="#local-6989586621679775502"><span class="hs-identifier hs-type">generator</span></a></span><span>
</span><span id="line-631"></span><span>    </span><span class="annot"><a href="#local-6989586621679775468"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-632"></span><span>    </span><span class="annot"><a href="#local-6989586621679775467"><span class="hs-identifier hs-type">generatorOutput</span></a></span><span>
</span><span id="line-633"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-634"></span><span>  </span><span id="local-6989586621679775465"><span class="annot"><span class="annottext">forward :: TransformerDecoder
  'ByT5
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  decoderInputEmbedDim
  encoderOutputEmbedDim
  ffnDim
  posEncDim
  dropoutP
-&gt; (decoderInput, encoderOutput,
    Tensor
      decoderRelPosGradient
      decoderRelPosLayout
      decoderRelPosDevice
      decoderRelPosDataType
      decoderRelPosShape,
    Tensor
      decoderAttentionMaskGradient
      decoderAttentionMaskLayout
      decoderAttentionMaskDevice
      decoderAttentionMaskDataType
      decoderAttentionMaskShape,
    Tensor
      crossAttentionMaskGradient
      crossAttentionMaskLayout
      crossAttentionMaskDevice
      crossAttentionMaskDataType
      crossAttentionMaskShape)
-&gt; generator
-&gt; m (output, generatorOutput)
</span><a href="#local-6989586621679775465"><span class="hs-identifier hs-var hs-var hs-var hs-var">forward</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TransformerDecoder"><span class="hs-identifier hs-type">TransformerDecoder</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#GTransformerDecoder"><span class="hs-identifier hs-type">GTransformerDecoder</span></a></span><span> </span><span class="hs-special">{</span><span id="local-6989586621679775460"><span id="local-6989586621679775461"><span id="local-6989586621679775462"><span id="local-6989586621679775463"><span id="local-6989586621679775464"><span class="annot"><span class="annottext">TDPosEncF
  'ByT5
  gradient
  device
  dataType
  headDim
  decoderInputEmbedDim
  posEncDim
TDDropoutF 'ByT5 dropoutP
TDLayerNormF 'ByT5 gradient device dataType decoderInputEmbedDim
TDEmbedLayerNormF
  'ByT5 gradient device dataType decoderInputEmbedDim
TDStackF
  'ByT5
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  decoderInputEmbedDim
  encoderOutputEmbedDim
  ffnDim
  dropoutP
tdPosEnc :: TDPosEncF
  'ByT5
  gradient
  device
  dataType
  headDim
  decoderInputEmbedDim
  posEncDim
tdDropout :: TDDropoutF 'ByT5 dropoutP
tdLayerNorm :: TDLayerNormF 'ByT5 gradient device dataType decoderInputEmbedDim
tdEmbedLayerNorm :: TDEmbedLayerNormF
  'ByT5 gradient device dataType decoderInputEmbedDim
tdStack :: TDStackF
  'ByT5
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  decoderInputEmbedDim
  encoderOutputEmbedDim
  ffnDim
  dropoutP
tdPosEnc :: forall stack embedLayerNorm layerNorm dropout posEnc.
GTransformerDecoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; posEnc
tdDropout :: forall stack embedLayerNorm layerNorm dropout posEnc.
GTransformerDecoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; dropout
tdLayerNorm :: forall stack embedLayerNorm layerNorm dropout posEnc.
GTransformerDecoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; layerNorm
tdEmbedLayerNorm :: forall stack embedLayerNorm layerNorm dropout posEnc.
GTransformerDecoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; embedLayerNorm
tdStack :: forall stack embedLayerNorm layerNorm dropout posEnc.
GTransformerDecoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; stack
</span><a href="#local-6989586621679775460"><span class="hs-glyph hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">..</span></a></span></span></span></span></span></span><span class="hs-special">}</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679775459"><span class="annot"><span class="annottext">decoderInput
</span><a href="#local-6989586621679775459"><span class="hs-identifier hs-var">decoderInput</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679775458"><span class="annot"><span class="annottext">encoderOutput
</span><a href="#local-6989586621679775458"><span class="hs-identifier hs-var">encoderOutput</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679775457"><span class="annot"><span class="annottext">Tensor
  decoderRelPosGradient
  decoderRelPosLayout
  decoderRelPosDevice
  decoderRelPosDataType
  decoderRelPosShape
</span><a href="#local-6989586621679775457"><span class="hs-identifier hs-var">decoderRelPos</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679775456"><span class="annot"><span class="annottext">Tensor
  decoderAttentionMaskGradient
  decoderAttentionMaskLayout
  decoderAttentionMaskDevice
  decoderAttentionMaskDataType
  decoderAttentionMaskShape
</span><a href="#local-6989586621679775456"><span class="hs-identifier hs-var">decoderAttentionMask</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679775455"><span class="annot"><span class="annottext">Tensor
  crossAttentionMaskGradient
  crossAttentionMaskLayout
  crossAttentionMaskDevice
  crossAttentionMaskDataType
  crossAttentionMaskShape
</span><a href="#local-6989586621679775455"><span class="hs-identifier hs-var">crossAttentionMask</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-635"></span><span>    </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679775454"><span class="annot"><span class="annottext">decoderRelPosBias :: IxStateT
  m
  dropoutGeneratorOutput
  dropoutGeneratorOutput
  (Tensor
     (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
     (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
     (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
     (Seq
        (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
        dataType)
     (TransposeF
        ('SelectDim ('ByIndex 1))
        ('SelectDim ('ByIndex 2))
        (TransposeF
           ('SelectDim ('ByIndex 2))
           ('SelectDim ('ByIndex 3))
           (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape))))
</span><a href="#local-6989586621679775454"><span class="hs-identifier hs-var hs-var">decoderRelPosBias</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-636"></span><span>          </span><span class="annot"><span class="annottext">Tensor
  decoderRelPosGradient
  decoderRelPosLayout
  decoderRelPosDevice
  decoderRelPosDataType
  decoderRelPosShape
-&gt; IxStateT
     m
     dropoutGeneratorOutput
     dropoutGeneratorOutput
     (Tensor
        decoderRelPosGradient
        decoderRelPosLayout
        decoderRelPosDevice
        decoderRelPosDataType
        decoderRelPosShape)
forall k (m :: k -&gt; k -&gt; * -&gt; *) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  decoderRelPosGradient
  decoderRelPosLayout
  decoderRelPosDevice
  decoderRelPosDataType
  decoderRelPosShape
</span><a href="#local-6989586621679775457"><span class="hs-identifier hs-var">decoderRelPos</span></a></span><span>
</span><span id="line-637"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  dropoutGeneratorOutput
  dropoutGeneratorOutput
  (Tensor
     decoderRelPosGradient
     decoderRelPosLayout
     decoderRelPosDevice
     decoderRelPosDataType
     decoderRelPosShape)
-&gt; (Tensor
      decoderRelPosGradient
      decoderRelPosLayout
      decoderRelPosDevice
      decoderRelPosDataType
      decoderRelPosShape
    -&gt; IxStateT
         m
         dropoutGeneratorOutput
         dropoutGeneratorOutput
         (Tensor
            (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
            (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
            (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
            (Seq
               (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
               dataType)
            (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)))
-&gt; IxStateT
     m
     dropoutGeneratorOutput
     dropoutGeneratorOutput
     (Tensor
        (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
        (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
        (Seq
           (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
           dataType)
        (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape))
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(dropoutGeneratorOutput
 -&gt; m (Tensor
         (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
         (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
         (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
         (Seq
            (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
            dataType)
         (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape),
       dropoutGeneratorOutput))
-&gt; IxStateT
     m
     dropoutGeneratorOutput
     dropoutGeneratorOutput
     (Tensor
        (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
        (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
        (Seq
           (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
           dataType)
        (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape))
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((dropoutGeneratorOutput
  -&gt; m (Tensor
          (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
          (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
          (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
          (Seq
             (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
             dataType)
          (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape),
        dropoutGeneratorOutput))
 -&gt; IxStateT
      m
      dropoutGeneratorOutput
      dropoutGeneratorOutput
      (Tensor
         (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
         (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
         (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
         (Seq
            (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
            dataType)
         (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)))
-&gt; (Tensor
      decoderRelPosGradient
      decoderRelPosLayout
      decoderRelPosDevice
      decoderRelPosDataType
      decoderRelPosShape
    -&gt; dropoutGeneratorOutput
    -&gt; m (Tensor
            (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
            (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
            (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
            (Seq
               (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
               dataType)
            (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape),
          dropoutGeneratorOutput))
-&gt; Tensor
     decoderRelPosGradient
     decoderRelPosLayout
     decoderRelPosDevice
     decoderRelPosDataType
     decoderRelPosShape
-&gt; IxStateT
     m
     dropoutGeneratorOutput
     dropoutGeneratorOutput
     (Tensor
        (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
        (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
        (Seq
           (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
           dataType)
        (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape))
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Embedding
  gradient
  ('Layout 'Dense)
  device
  dataType
  posEncDim
  headDim
  'Nothing
-&gt; Tensor
     decoderRelPosGradient
     decoderRelPosLayout
     decoderRelPosDevice
     decoderRelPosDataType
     decoderRelPosShape
-&gt; dropoutGeneratorOutput
-&gt; m (Tensor
        (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
        (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
        (Seq
           (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
           dataType)
        (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape),
      dropoutGeneratorOutput)
forall model input generator output generatorOutput (m :: * -&gt; *).
(HasForward model input generator output generatorOutput,
 MonadThrow m) =&gt;
model -&gt; input -&gt; generator -&gt; m (output, generatorOutput)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">Embedding
  gradient
  ('Layout 'Dense)
  device
  dataType
  posEncDim
  headDim
  'Nothing
TDPosEncF
  'ByT5
  gradient
  device
  dataType
  headDim
  decoderInputEmbedDim
  posEncDim
</span><a href="#local-6989586621679775460"><span class="hs-identifier hs-var">tdPosEnc</span></a></span><span>
</span><span id="line-638"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  dropoutGeneratorOutput
  dropoutGeneratorOutput
  (Tensor
     (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
     (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
     (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
     (Seq
        (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
        dataType)
     (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape))
-&gt; (Tensor
      (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
      (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
      (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
      (Seq
         (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
         dataType)
      (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)
    -&gt; IxStateT
         m
         dropoutGeneratorOutput
         dropoutGeneratorOutput
         (Tensor
            (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
            (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
            (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
            (Seq
               (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
               dataType)
            (TransposeF
               ('SelectDim ('ByIndex 2))
               ('SelectDim ('ByIndex 3))
               (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape))))
-&gt; IxStateT
     m
     dropoutGeneratorOutput
     dropoutGeneratorOutput
     (Tensor
        (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
        (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
        (Seq
           (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
           dataType)
        (TransposeF
           ('SelectDim ('ByIndex 2))
           ('SelectDim ('ByIndex 3))
           (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)))
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">m (Tensor
     (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
     (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
     (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
     (Seq
        (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
        dataType)
     (TransposeF
        ('SelectDim ('ByIndex 2))
        ('SelectDim ('ByIndex 3))
        (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)))
-&gt; IxStateT
     m
     dropoutGeneratorOutput
     dropoutGeneratorOutput
     (Tensor
        (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
        (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
        (Seq
           (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
           dataType)
        (TransposeF
           ('SelectDim ('ByIndex 2))
           ('SelectDim ('ByIndex 3))
           (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)))
forall k (t :: (* -&gt; *) -&gt; k -&gt; k -&gt; * -&gt; *) (m :: * -&gt; *) a
       (i :: k).
(IxMonadTrans t, Monad m) =&gt;
m a -&gt; t m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ilift</span></a></span><span> </span><span class="annot"><span class="annottext">(m (Tensor
      (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
      (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
      (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
      (Seq
         (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
         dataType)
      (TransposeF
         ('SelectDim ('ByIndex 2))
         ('SelectDim ('ByIndex 3))
         (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)))
 -&gt; IxStateT
      m
      dropoutGeneratorOutput
      dropoutGeneratorOutput
      (Tensor
         (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
         (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
         (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
         (Seq
            (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
            dataType)
         (TransposeF
            ('SelectDim ('ByIndex 2))
            ('SelectDim ('ByIndex 3))
            (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape))))
-&gt; (Tensor
      (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
      (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
      (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
      (Seq
         (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
         dataType)
      (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)
    -&gt; m (Tensor
            (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
            (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
            (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
            (Seq
               (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
               dataType)
            (TransposeF
               ('SelectDim ('ByIndex 2))
               ('SelectDim ('ByIndex 3))
               (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape))))
-&gt; Tensor
     (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
     (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
     (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
     (Seq
        (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
        dataType)
     (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)
-&gt; IxStateT
     m
     dropoutGeneratorOutput
     dropoutGeneratorOutput
     (Tensor
        (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
        (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
        (Seq
           (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
           dataType)
        (TransposeF
           ('SelectDim ('ByIndex 2))
           ('SelectDim ('ByIndex 3))
           (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)))
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]) (m :: * -&gt; *).
(shape'
 ~ TransposeF
     ('SelectDim ('ByIndex 2)) ('SelectDim ('ByIndex 3)) shape,
 SingI ('SelectDim ('ByIndex 2)), SingI ('SelectDim ('ByIndex 3)),
 MonadThrow m) =&gt;
Tensor gradient layout device dataType shape
-&gt; m (Tensor gradient layout device dataType shape')
forall (selectDim0 :: SelectDim (By Symbol Nat))
       (selectDim1 :: SelectDim (By Symbol Nat))
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]) (m :: * -&gt; *).
(shape' ~ TransposeF selectDim0 selectDim1 shape, SingI selectDim0,
 SingI selectDim1, MonadThrow m) =&gt;
Tensor gradient layout device dataType shape
-&gt; m (Tensor gradient layout device dataType shape')
</span><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#transpose"><span class="hs-identifier hs-var">transpose</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">2</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">3</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-639"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  dropoutGeneratorOutput
  dropoutGeneratorOutput
  (Tensor
     (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
     (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
     (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
     (Seq
        (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
        dataType)
     (TransposeF
        ('SelectDim ('ByIndex 2))
        ('SelectDim ('ByIndex 3))
        (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)))
-&gt; (Tensor
      (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
      (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
      (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
      (Seq
         (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
         dataType)
      (TransposeF
         ('SelectDim ('ByIndex 2))
         ('SelectDim ('ByIndex 3))
         (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape))
    -&gt; IxStateT
         m
         dropoutGeneratorOutput
         dropoutGeneratorOutput
         (Tensor
            (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
            (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
            (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
            (Seq
               (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
               dataType)
            (TransposeF
               ('SelectDim ('ByIndex 1))
               ('SelectDim ('ByIndex 2))
               (TransposeF
                  ('SelectDim ('ByIndex 2))
                  ('SelectDim ('ByIndex 3))
                  (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)))))
-&gt; IxStateT
     m
     dropoutGeneratorOutput
     dropoutGeneratorOutput
     (Tensor
        (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
        (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
        (Seq
           (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
           dataType)
        (TransposeF
           ('SelectDim ('ByIndex 1))
           ('SelectDim ('ByIndex 2))
           (TransposeF
              ('SelectDim ('ByIndex 2))
              ('SelectDim ('ByIndex 3))
              (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape))))
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">m (Tensor
     (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
     (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
     (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
     (Seq
        (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
        dataType)
     (TransposeF
        ('SelectDim ('ByIndex 1))
        ('SelectDim ('ByIndex 2))
        (TransposeF
           ('SelectDim ('ByIndex 2))
           ('SelectDim ('ByIndex 3))
           (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape))))
-&gt; IxStateT
     m
     dropoutGeneratorOutput
     dropoutGeneratorOutput
     (Tensor
        (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
        (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
        (Seq
           (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
           dataType)
        (TransposeF
           ('SelectDim ('ByIndex 1))
           ('SelectDim ('ByIndex 2))
           (TransposeF
              ('SelectDim ('ByIndex 2))
              ('SelectDim ('ByIndex 3))
              (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape))))
forall k (t :: (* -&gt; *) -&gt; k -&gt; k -&gt; * -&gt; *) (m :: * -&gt; *) a
       (i :: k).
(IxMonadTrans t, Monad m) =&gt;
m a -&gt; t m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ilift</span></a></span><span> </span><span class="annot"><span class="annottext">(m (Tensor
      (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
      (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
      (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
      (Seq
         (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
         dataType)
      (TransposeF
         ('SelectDim ('ByIndex 1))
         ('SelectDim ('ByIndex 2))
         (TransposeF
            ('SelectDim ('ByIndex 2))
            ('SelectDim ('ByIndex 3))
            (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape))))
 -&gt; IxStateT
      m
      dropoutGeneratorOutput
      dropoutGeneratorOutput
      (Tensor
         (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
         (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
         (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
         (Seq
            (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
            dataType)
         (TransposeF
            ('SelectDim ('ByIndex 1))
            ('SelectDim ('ByIndex 2))
            (TransposeF
               ('SelectDim ('ByIndex 2))
               ('SelectDim ('ByIndex 3))
               (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)))))
-&gt; (Tensor
      (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
      (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
      (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
      (Seq
         (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
         dataType)
      (TransposeF
         ('SelectDim ('ByIndex 2))
         ('SelectDim ('ByIndex 3))
         (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape))
    -&gt; m (Tensor
            (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
            (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
            (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
            (Seq
               (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
               dataType)
            (TransposeF
               ('SelectDim ('ByIndex 1))
               ('SelectDim ('ByIndex 2))
               (TransposeF
                  ('SelectDim ('ByIndex 2))
                  ('SelectDim ('ByIndex 3))
                  (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)))))
-&gt; Tensor
     (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
     (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
     (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
     (Seq
        (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
        dataType)
     (TransposeF
        ('SelectDim ('ByIndex 2))
        ('SelectDim ('ByIndex 3))
        (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape))
-&gt; IxStateT
     m
     dropoutGeneratorOutput
     dropoutGeneratorOutput
     (Tensor
        (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
        (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
        (Seq
           (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
           dataType)
        (TransposeF
           ('SelectDim ('ByIndex 1))
           ('SelectDim ('ByIndex 2))
           (TransposeF
              ('SelectDim ('ByIndex 2))
              ('SelectDim ('ByIndex 3))
              (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape))))
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]) (m :: * -&gt; *).
(shape'
 ~ TransposeF
     ('SelectDim ('ByIndex 1)) ('SelectDim ('ByIndex 2)) shape,
 SingI ('SelectDim ('ByIndex 1)), SingI ('SelectDim ('ByIndex 2)),
 MonadThrow m) =&gt;
Tensor gradient layout device dataType shape
-&gt; m (Tensor gradient layout device dataType shape')
forall (selectDim0 :: SelectDim (By Symbol Nat))
       (selectDim1 :: SelectDim (By Symbol Nat))
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]) (m :: * -&gt; *).
(shape' ~ TransposeF selectDim0 selectDim1 shape, SingI selectDim0,
 SingI selectDim1, MonadThrow m) =&gt;
Tensor gradient layout device dataType shape
-&gt; m (Tensor gradient layout device dataType shape')
</span><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#transpose"><span class="hs-identifier hs-var">transpose</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">2</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-640"></span><span>        </span><span id="local-6989586621679775453"><span class="annot"><span class="annottext">decoderAttentionBias :: IxStateT
  m
  dropoutGeneratorOutput
  dropoutGeneratorOutput
  (Tensor
     (Or
        (Gradient RequiresGradient)
        (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
        decoderAttentionMaskGradient)
     (Unify
        (Layout LayoutType)
        (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
        decoderAttentionMaskLayout)
     (Unify
        (Device (DeviceType Nat))
        (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
        decoderAttentionMaskDevice)
     (Unify
        (DataType DType)
        (Seq
           (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
           dataType)
        decoderAttentionMaskDataType)
     (BroadcastShapesF
        (TransposeF
           ('SelectDim ('ByIndex 1))
           ('SelectDim ('ByIndex 2))
           (TransposeF
              ('SelectDim ('ByIndex 2))
              ('SelectDim ('ByIndex 3))
              (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)))
        (UnsqueezeF ('SelectDim ('ByIndex 1)) decoderAttentionMaskShape)))
</span><a href="#local-6989586621679775453"><span class="hs-identifier hs-var hs-var">decoderAttentionBias</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-641"></span><span>          </span><span class="annot"><span class="annottext">IxStateT
  m
  dropoutGeneratorOutput
  dropoutGeneratorOutput
  (Tensor
     (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
     (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
     (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
     (Seq
        (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
        dataType)
     (TransposeF
        ('SelectDim ('ByIndex 1))
        ('SelectDim ('ByIndex 2))
        (TransposeF
           ('SelectDim ('ByIndex 2))
           ('SelectDim ('ByIndex 3))
           (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape))))
</span><a href="#local-6989586621679775454"><span class="hs-identifier hs-var">decoderRelPosBias</span></a></span><span>
</span><span id="line-642"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  dropoutGeneratorOutput
  dropoutGeneratorOutput
  (Tensor
     (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
     (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
     (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
     (Seq
        (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
        dataType)
     (TransposeF
        ('SelectDim ('ByIndex 1))
        ('SelectDim ('ByIndex 2))
        (TransposeF
           ('SelectDim ('ByIndex 2))
           ('SelectDim ('ByIndex 3))
           (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape))))
-&gt; (Tensor
      (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
      (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
      (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
      (Seq
         (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
         dataType)
      (TransposeF
         ('SelectDim ('ByIndex 1))
         ('SelectDim ('ByIndex 2))
         (TransposeF
            ('SelectDim ('ByIndex 2))
            ('SelectDim ('ByIndex 3))
            (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)))
    -&gt; IxStateT
         m
         dropoutGeneratorOutput
         dropoutGeneratorOutput
         (Tensor
            (Or
               (Gradient RequiresGradient)
               (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
               decoderAttentionMaskGradient)
            (Unify
               (Layout LayoutType)
               (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
               decoderAttentionMaskLayout)
            (Unify
               (Device (DeviceType Nat))
               (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
               decoderAttentionMaskDevice)
            (Unify
               (DataType DType)
               (Seq
                  (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
                  dataType)
               decoderAttentionMaskDataType)
            (BroadcastShapesF
               (TransposeF
                  ('SelectDim ('ByIndex 1))
                  ('SelectDim ('ByIndex 2))
                  (TransposeF
                     ('SelectDim ('ByIndex 2))
                     ('SelectDim ('ByIndex 3))
                     (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)))
               (UnsqueezeF ('SelectDim ('ByIndex 1)) decoderAttentionMaskShape))))
-&gt; IxStateT
     m
     dropoutGeneratorOutput
     dropoutGeneratorOutput
     (Tensor
        (Or
           (Gradient RequiresGradient)
           (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
           decoderAttentionMaskGradient)
        (Unify
           (Layout LayoutType)
           (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
           decoderAttentionMaskLayout)
        (Unify
           (Device (DeviceType Nat))
           (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
           decoderAttentionMaskDevice)
        (Unify
           (DataType DType)
           (Seq
              (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
              dataType)
           decoderAttentionMaskDataType)
        (BroadcastShapesF
           (TransposeF
              ('SelectDim ('ByIndex 1))
              ('SelectDim ('ByIndex 2))
              (TransposeF
                 ('SelectDim ('ByIndex 2))
                 ('SelectDim ('ByIndex 3))
                 (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)))
           (UnsqueezeF ('SelectDim ('ByIndex 1)) decoderAttentionMaskShape)))
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  (Or
     (Gradient RequiresGradient)
     (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
     decoderAttentionMaskGradient)
  (Unify
     (Layout LayoutType)
     (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
     decoderAttentionMaskLayout)
  (Unify
     (Device (DeviceType Nat))
     (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
     decoderAttentionMaskDevice)
  (Unify
     (DataType DType)
     (Seq
        (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
        dataType)
     decoderAttentionMaskDataType)
  (BroadcastShapesF
     (TransposeF
        ('SelectDim ('ByIndex 1))
        ('SelectDim ('ByIndex 2))
        (TransposeF
           ('SelectDim ('ByIndex 2))
           ('SelectDim ('ByIndex 3))
           (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)))
     (UnsqueezeF ('SelectDim ('ByIndex 1)) decoderAttentionMaskShape))
-&gt; IxStateT
     m
     dropoutGeneratorOutput
     dropoutGeneratorOutput
     (Tensor
        (Or
           (Gradient RequiresGradient)
           (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
           decoderAttentionMaskGradient)
        (Unify
           (Layout LayoutType)
           (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
           decoderAttentionMaskLayout)
        (Unify
           (Device (DeviceType Nat))
           (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
           decoderAttentionMaskDevice)
        (Unify
           (DataType DType)
           (Seq
              (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
              dataType)
           decoderAttentionMaskDataType)
        (BroadcastShapesF
           (TransposeF
              ('SelectDim ('ByIndex 1))
              ('SelectDim ('ByIndex 2))
              (TransposeF
                 ('SelectDim ('ByIndex 2))
                 ('SelectDim ('ByIndex 3))
                 (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)))
           (UnsqueezeF ('SelectDim ('ByIndex 1)) decoderAttentionMaskShape)))
forall k (m :: k -&gt; k -&gt; * -&gt; *) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">(Tensor
   (Or
      (Gradient RequiresGradient)
      (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
      decoderAttentionMaskGradient)
   (Unify
      (Layout LayoutType)
      (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
      decoderAttentionMaskLayout)
   (Unify
      (Device (DeviceType Nat))
      (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
      decoderAttentionMaskDevice)
   (Unify
      (DataType DType)
      (Seq
         (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
         dataType)
      decoderAttentionMaskDataType)
   (BroadcastShapesF
      (TransposeF
         ('SelectDim ('ByIndex 1))
         ('SelectDim ('ByIndex 2))
         (TransposeF
            ('SelectDim ('ByIndex 2))
            ('SelectDim ('ByIndex 3))
            (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)))
      (UnsqueezeF ('SelectDim ('ByIndex 1)) decoderAttentionMaskShape))
 -&gt; IxStateT
      m
      dropoutGeneratorOutput
      dropoutGeneratorOutput
      (Tensor
         (Or
            (Gradient RequiresGradient)
            (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
            decoderAttentionMaskGradient)
         (Unify
            (Layout LayoutType)
            (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
            decoderAttentionMaskLayout)
         (Unify
            (Device (DeviceType Nat))
            (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
            decoderAttentionMaskDevice)
         (Unify
            (DataType DType)
            (Seq
               (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
               dataType)
            decoderAttentionMaskDataType)
         (BroadcastShapesF
            (TransposeF
               ('SelectDim ('ByIndex 1))
               ('SelectDim ('ByIndex 2))
               (TransposeF
                  ('SelectDim ('ByIndex 2))
                  ('SelectDim ('ByIndex 3))
                  (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)))
            (UnsqueezeF ('SelectDim ('ByIndex 1)) decoderAttentionMaskShape))))
-&gt; (Tensor
      (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
      (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
      (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
      (Seq
         (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
         dataType)
      (TransposeF
         ('SelectDim ('ByIndex 1))
         ('SelectDim ('ByIndex 2))
         (TransposeF
            ('SelectDim ('ByIndex 2))
            ('SelectDim ('ByIndex 3))
            (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)))
    -&gt; Tensor
         (Or
            (Gradient RequiresGradient)
            (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
            decoderAttentionMaskGradient)
         (Unify
            (Layout LayoutType)
            (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
            decoderAttentionMaskLayout)
         (Unify
            (Device (DeviceType Nat))
            (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
            decoderAttentionMaskDevice)
         (Unify
            (DataType DType)
            (Seq
               (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
               dataType)
            decoderAttentionMaskDataType)
         (BroadcastShapesF
            (TransposeF
               ('SelectDim ('ByIndex 1))
               ('SelectDim ('ByIndex 2))
               (TransposeF
                  ('SelectDim ('ByIndex 2))
                  ('SelectDim ('ByIndex 3))
                  (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)))
            (UnsqueezeF ('SelectDim ('ByIndex 1)) decoderAttentionMaskShape)))
-&gt; Tensor
     (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
     (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
     (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
     (Seq
        (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
        dataType)
     (TransposeF
        ('SelectDim ('ByIndex 1))
        ('SelectDim ('ByIndex 2))
        (TransposeF
           ('SelectDim ('ByIndex 2))
           ('SelectDim ('ByIndex 3))
           (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)))
-&gt; IxStateT
     m
     dropoutGeneratorOutput
     dropoutGeneratorOutput
     (Tensor
        (Or
           (Gradient RequiresGradient)
           (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
           decoderAttentionMaskGradient)
        (Unify
           (Layout LayoutType)
           (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
           decoderAttentionMaskLayout)
        (Unify
           (Device (DeviceType Nat))
           (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
           decoderAttentionMaskDevice)
        (Unify
           (DataType DType)
           (Seq
              (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
              dataType)
           decoderAttentionMaskDataType)
        (BroadcastShapesF
           (TransposeF
              ('SelectDim ('ByIndex 1))
              ('SelectDim ('ByIndex 2))
              (TransposeF
                 ('SelectDim ('ByIndex 2))
                 ('SelectDim ('ByIndex 3))
                 (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)))
           (UnsqueezeF ('SelectDim ('ByIndex 1)) decoderAttentionMaskShape)))
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Tensor
  (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
  (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
  (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
  (Seq
     (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
     dataType)
  (TransposeF
     ('SelectDim ('ByIndex 1))
     ('SelectDim ('ByIndex 2))
     (TransposeF
        ('SelectDim ('ByIndex 2))
        ('SelectDim ('ByIndex 3))
        (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)))
-&gt; Tensor
     decoderAttentionMaskGradient
     decoderAttentionMaskLayout
     decoderAttentionMaskDevice
     decoderAttentionMaskDataType
     (UnsqueezeF ('SelectDim ('ByIndex 1)) decoderAttentionMaskShape)
-&gt; Tensor
     (Or (Gradient RequiresGradient) gradient decoderRelPosGradient
      &lt;|&gt; decoderAttentionMaskGradient)
     (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout
      &lt;+&gt; decoderAttentionMaskLayout)
     (Unify (Device (DeviceType Nat)) device decoderRelPosDevice
      &lt;+&gt; decoderAttentionMaskDevice)
     (Seq
        (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
        dataType
      &lt;+&gt; decoderAttentionMaskDataType)
     (BroadcastShapesF
        (TransposeF
           ('SelectDim ('ByIndex 1))
           ('SelectDim ('ByIndex 2))
           (TransposeF
              ('SelectDim ('ByIndex 2))
              ('SelectDim ('ByIndex 3))
              (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)))
        (UnsqueezeF ('SelectDim ('ByIndex 1)) decoderAttentionMaskShape))
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (gradient' :: Gradient RequiresGradient)
       (layout' :: Layout LayoutType) (device' :: Device (DeviceType Nat))
       (dataType' :: DataType DType)
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]).
Tensor gradient layout device dataType shape
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; Tensor
     (gradient &lt;|&gt; gradient')
     (layout &lt;+&gt; layout')
     (device &lt;+&gt; device')
     (dataType &lt;+&gt; dataType')
     (BroadcastShapesF shape shape')
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#add"><span class="hs-operator hs-var">`add`</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  decoderAttentionMaskGradient
  decoderAttentionMaskLayout
  decoderAttentionMaskDevice
  decoderAttentionMaskDataType
  decoderAttentionMaskShape
-&gt; Tensor
     decoderAttentionMaskGradient
     decoderAttentionMaskLayout
     decoderAttentionMaskDevice
     decoderAttentionMaskDataType
     (UnsqueezeF ('SelectDim ('ByIndex 1)) decoderAttentionMaskShape)
forall (selectDim :: SelectDim (By Symbol Nat))
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]).
(shape' ~ UnsqueezeF selectDim shape, SingI selectDim) =&gt;
Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape'
</span><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#unsqueeze"><span class="hs-identifier hs-var">unsqueeze</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
  decoderAttentionMaskGradient
  decoderAttentionMaskLayout
  decoderAttentionMaskDevice
  decoderAttentionMaskDataType
  decoderAttentionMaskShape
</span><a href="#local-6989586621679775456"><span class="hs-identifier hs-var">decoderAttentionMask</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-643"></span><span>        </span><span id="local-6989586621679775452"><span class="annot"><span class="annottext">crossAttentionBias :: Tensor
  crossAttentionMaskGradient
  crossAttentionMaskLayout
  crossAttentionMaskDevice
  crossAttentionMaskDataType
  (UnsqueezeF ('SelectDim ('ByIndex 1)) crossAttentionMaskShape)
</span><a href="#local-6989586621679775452"><span class="hs-identifier hs-var hs-var">crossAttentionBias</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor
  crossAttentionMaskGradient
  crossAttentionMaskLayout
  crossAttentionMaskDevice
  crossAttentionMaskDataType
  crossAttentionMaskShape
-&gt; Tensor
     crossAttentionMaskGradient
     crossAttentionMaskLayout
     crossAttentionMaskDevice
     crossAttentionMaskDataType
     (UnsqueezeF ('SelectDim ('ByIndex 1)) crossAttentionMaskShape)
forall (selectDim :: SelectDim (By Symbol Nat))
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]).
(shape' ~ UnsqueezeF selectDim shape, SingI selectDim) =&gt;
Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape'
</span><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#unsqueeze"><span class="hs-identifier hs-var">unsqueeze</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
  crossAttentionMaskGradient
  crossAttentionMaskLayout
  crossAttentionMaskDevice
  crossAttentionMaskDataType
  crossAttentionMaskShape
</span><a href="#local-6989586621679775455"><span class="hs-identifier hs-var">crossAttentionMask</span></a></span><span>
</span><span id="line-644"></span><span>     </span><span class="hs-keyword">in</span><span> </span><span class="annot"><span class="annottext">IxStateT m generator generatorOutput output
-&gt; generator -&gt; m (output, generatorOutput)
forall (m :: * -&gt; *) i j a. IxStateT m i j a -&gt; i -&gt; m (a, j)
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var hs-var">runIxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">(IxStateT m generator generatorOutput output
 -&gt; generator -&gt; m (output, generatorOutput))
-&gt; IxStateT m generator generatorOutput output
-&gt; generator
-&gt; m (output, generatorOutput)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-645"></span><span>          </span><span class="annot"><span class="annottext">decoderInput -&gt; IxStateT m generator generator decoderInput
forall k (m :: k -&gt; k -&gt; * -&gt; *) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">decoderInput
</span><a href="#local-6989586621679775459"><span class="hs-identifier hs-var">decoderInput</span></a></span><span>
</span><span id="line-646"></span><span>            </span><span class="annot"><span class="annottext">IxStateT m generator generator decoderInput
-&gt; (decoderInput
    -&gt; IxStateT m generator dropoutGeneratorOutput dropoutOutput)
-&gt; IxStateT m generator dropoutGeneratorOutput dropoutOutput
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(generator -&gt; m (dropoutOutput, dropoutGeneratorOutput))
-&gt; IxStateT m generator dropoutGeneratorOutput dropoutOutput
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((generator -&gt; m (dropoutOutput, dropoutGeneratorOutput))
 -&gt; IxStateT m generator dropoutGeneratorOutput dropoutOutput)
-&gt; (decoderInput
    -&gt; generator -&gt; m (dropoutOutput, dropoutGeneratorOutput))
-&gt; decoderInput
-&gt; IxStateT m generator dropoutGeneratorOutput dropoutOutput
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Dropout dropoutP
-&gt; decoderInput
-&gt; generator
-&gt; m (dropoutOutput, dropoutGeneratorOutput)
forall model input generator output generatorOutput (m :: * -&gt; *).
(HasForward model input generator output generatorOutput,
 MonadThrow m) =&gt;
model -&gt; input -&gt; generator -&gt; m (output, generatorOutput)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">Dropout dropoutP
TDDropoutF 'ByT5 dropoutP
</span><a href="#local-6989586621679775461"><span class="hs-identifier hs-var">tdDropout</span></a></span><span>
</span><span id="line-647"></span><span>            </span><span class="annot"><span class="annottext">IxStateT m generator dropoutGeneratorOutput dropoutOutput
-&gt; (dropoutOutput
    -&gt; IxStateT
         m dropoutGeneratorOutput stackGeneratorOutput stackOutput)
-&gt; IxStateT m generator stackGeneratorOutput stackOutput
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="hs-special">(</span><span> </span><span class="hs-glyph">\</span><span id="local-6989586621679775451"><span class="annot"><span class="annottext">dropoutOutput
</span><a href="#local-6989586621679775451"><span class="hs-identifier hs-var">decoderInput'</span></a></span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-648"></span><span>                     </span><span class="annot"><span class="annottext">IxStateT
  m
  dropoutGeneratorOutput
  dropoutGeneratorOutput
  (Tensor
     (Or
        (Gradient RequiresGradient)
        (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
        decoderAttentionMaskGradient)
     (Unify
        (Layout LayoutType)
        (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
        decoderAttentionMaskLayout)
     (Unify
        (Device (DeviceType Nat))
        (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
        decoderAttentionMaskDevice)
     (Unify
        (DataType DType)
        (Seq
           (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
           dataType)
        decoderAttentionMaskDataType)
     (BroadcastShapesF
        (TransposeF
           ('SelectDim ('ByIndex 1))
           ('SelectDim ('ByIndex 2))
           (TransposeF
              ('SelectDim ('ByIndex 2))
              ('SelectDim ('ByIndex 3))
              (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)))
        (UnsqueezeF ('SelectDim ('ByIndex 1)) decoderAttentionMaskShape)))
</span><a href="#local-6989586621679775453"><span class="hs-identifier hs-var">decoderAttentionBias</span></a></span><span>
</span><span id="line-649"></span><span>                       </span><span class="annot"><span class="annottext">IxStateT
  m
  dropoutGeneratorOutput
  dropoutGeneratorOutput
  (Tensor
     (Or
        (Gradient RequiresGradient)
        (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
        decoderAttentionMaskGradient)
     (Unify
        (Layout LayoutType)
        (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
        decoderAttentionMaskLayout)
     (Unify
        (Device (DeviceType Nat))
        (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
        decoderAttentionMaskDevice)
     (Unify
        (DataType DType)
        (Seq
           (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
           dataType)
        decoderAttentionMaskDataType)
     (BroadcastShapesF
        (TransposeF
           ('SelectDim ('ByIndex 1))
           ('SelectDim ('ByIndex 2))
           (TransposeF
              ('SelectDim ('ByIndex 2))
              ('SelectDim ('ByIndex 3))
              (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)))
        (UnsqueezeF ('SelectDim ('ByIndex 1)) decoderAttentionMaskShape)))
-&gt; (Tensor
      (Or
         (Gradient RequiresGradient)
         (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
         decoderAttentionMaskGradient)
      (Unify
         (Layout LayoutType)
         (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
         decoderAttentionMaskLayout)
      (Unify
         (Device (DeviceType Nat))
         (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
         decoderAttentionMaskDevice)
      (Unify
         (DataType DType)
         (Seq
            (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
            dataType)
         decoderAttentionMaskDataType)
      (BroadcastShapesF
         (TransposeF
            ('SelectDim ('ByIndex 1))
            ('SelectDim ('ByIndex 2))
            (TransposeF
               ('SelectDim ('ByIndex 2))
               ('SelectDim ('ByIndex 3))
               (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)))
         (UnsqueezeF ('SelectDim ('ByIndex 1)) decoderAttentionMaskShape))
    -&gt; IxStateT
         m dropoutGeneratorOutput stackGeneratorOutput stackOutput)
-&gt; IxStateT
     m dropoutGeneratorOutput stackGeneratorOutput stackOutput
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="hs-special">(</span><span> </span><span class="hs-glyph">\</span><span id="local-6989586621679775450"><span class="annot"><span class="annottext">Tensor
  (Or
     (Gradient RequiresGradient)
     (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
     decoderAttentionMaskGradient)
  (Unify
     (Layout LayoutType)
     (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
     decoderAttentionMaskLayout)
  (Unify
     (Device (DeviceType Nat))
     (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
     decoderAttentionMaskDevice)
  (Unify
     (DataType DType)
     (Seq
        (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
        dataType)
     decoderAttentionMaskDataType)
  (BroadcastShapesF
     (TransposeF
        ('SelectDim ('ByIndex 1))
        ('SelectDim ('ByIndex 2))
        (TransposeF
           ('SelectDim ('ByIndex 2))
           ('SelectDim ('ByIndex 3))
           (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)))
     (UnsqueezeF ('SelectDim ('ByIndex 1)) decoderAttentionMaskShape))
</span><a href="#local-6989586621679775450"><span class="hs-identifier hs-var">decoderAttentionBias'</span></a></span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-650"></span><span>                                </span><span class="annot"><span class="annottext">(dropoutGeneratorOutput -&gt; m (stackOutput, stackGeneratorOutput))
-&gt; IxStateT
     m dropoutGeneratorOutput stackGeneratorOutput stackOutput
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((dropoutGeneratorOutput -&gt; m (stackOutput, stackGeneratorOutput))
 -&gt; IxStateT
      m dropoutGeneratorOutput stackGeneratorOutput stackOutput)
-&gt; (dropoutGeneratorOutput
    -&gt; m (stackOutput, stackGeneratorOutput))
-&gt; IxStateT
     m dropoutGeneratorOutput stackGeneratorOutput stackOutput
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-651"></span><span>                                  </span><span class="annot"><span class="annottext">TransformerDecoderStack
  'ByT5
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  decoderInputEmbedDim
  encoderOutputEmbedDim
  ffnDim
  dropoutP
-&gt; (dropoutOutput, encoderOutput,
    Tensor
      (Or
         (Gradient RequiresGradient)
         (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
         decoderAttentionMaskGradient)
      (Unify
         (Layout LayoutType)
         (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
         decoderAttentionMaskLayout)
      (Unify
         (Device (DeviceType Nat))
         (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
         decoderAttentionMaskDevice)
      (Unify
         (DataType DType)
         (Seq
            (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
            dataType)
         decoderAttentionMaskDataType)
      (BroadcastShapesF
         (TransposeF
            ('SelectDim ('ByIndex 1))
            ('SelectDim ('ByIndex 2))
            (TransposeF
               ('SelectDim ('ByIndex 2))
               ('SelectDim ('ByIndex 3))
               (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)))
         (UnsqueezeF ('SelectDim ('ByIndex 1)) decoderAttentionMaskShape)),
    Tensor
      crossAttentionMaskGradient
      crossAttentionMaskLayout
      crossAttentionMaskDevice
      crossAttentionMaskDataType
      (UnsqueezeF ('SelectDim ('ByIndex 1)) crossAttentionMaskShape))
-&gt; dropoutGeneratorOutput
-&gt; m (stackOutput, stackGeneratorOutput)
forall model input generator output generatorOutput (m :: * -&gt; *).
(HasForward model input generator output generatorOutput,
 MonadThrow m) =&gt;
model -&gt; input -&gt; generator -&gt; m (output, generatorOutput)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span>
</span><span id="line-652"></span><span>                                    </span><span class="annot"><span class="annottext">TransformerDecoderStack
  'ByT5
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  decoderInputEmbedDim
  encoderOutputEmbedDim
  ffnDim
  dropoutP
TDStackF
  'ByT5
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  decoderInputEmbedDim
  encoderOutputEmbedDim
  ffnDim
  dropoutP
</span><a href="#local-6989586621679775464"><span class="hs-identifier hs-var">tdStack</span></a></span><span>
</span><span id="line-653"></span><span>                                    </span><span class="hs-special">(</span><span> </span><span class="annot"><span class="annottext">dropoutOutput
</span><a href="#local-6989586621679775451"><span class="hs-identifier hs-var">decoderInput'</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-654"></span><span>                                      </span><span class="annot"><span class="annottext">encoderOutput
</span><a href="#local-6989586621679775458"><span class="hs-identifier hs-var">encoderOutput</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-655"></span><span>                                      </span><span class="annot"><span class="annottext">Tensor
  (Or
     (Gradient RequiresGradient)
     (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
     decoderAttentionMaskGradient)
  (Unify
     (Layout LayoutType)
     (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
     decoderAttentionMaskLayout)
  (Unify
     (Device (DeviceType Nat))
     (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
     decoderAttentionMaskDevice)
  (Unify
     (DataType DType)
     (Seq
        (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
        dataType)
     decoderAttentionMaskDataType)
  (BroadcastShapesF
     (TransposeF
        ('SelectDim ('ByIndex 1))
        ('SelectDim ('ByIndex 2))
        (TransposeF
           ('SelectDim ('ByIndex 2))
           ('SelectDim ('ByIndex 3))
           (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)))
     (UnsqueezeF ('SelectDim ('ByIndex 1)) decoderAttentionMaskShape))
</span><a href="#local-6989586621679775450"><span class="hs-identifier hs-var">decoderAttentionBias'</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-656"></span><span>                                      </span><span class="annot"><span class="annottext">Tensor
  crossAttentionMaskGradient
  crossAttentionMaskLayout
  crossAttentionMaskDevice
  crossAttentionMaskDataType
  (UnsqueezeF ('SelectDim ('ByIndex 1)) crossAttentionMaskShape)
</span><a href="#local-6989586621679775452"><span class="hs-identifier hs-var">crossAttentionBias</span></a></span><span>
</span><span id="line-657"></span><span>                                    </span><span class="hs-special">)</span><span>
</span><span id="line-658"></span><span>                            </span><span class="hs-special">)</span><span>
</span><span id="line-659"></span><span>                 </span><span class="hs-special">)</span><span>
</span><span id="line-660"></span><span>            </span><span class="annot"><span class="annottext">IxStateT m generator stackGeneratorOutput stackOutput
-&gt; (stackOutput
    -&gt; IxStateT
         m stackGeneratorOutput layerNormGeneratorOutput layerNormOutput)
-&gt; IxStateT m generator layerNormGeneratorOutput layerNormOutput
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(stackGeneratorOutput
 -&gt; m (layerNormOutput, layerNormGeneratorOutput))
-&gt; IxStateT
     m stackGeneratorOutput layerNormGeneratorOutput layerNormOutput
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((stackGeneratorOutput
  -&gt; m (layerNormOutput, layerNormGeneratorOutput))
 -&gt; IxStateT
      m stackGeneratorOutput layerNormGeneratorOutput layerNormOutput)
-&gt; (stackOutput
    -&gt; stackGeneratorOutput
    -&gt; m (layerNormOutput, layerNormGeneratorOutput))
-&gt; stackOutput
-&gt; IxStateT
     m stackGeneratorOutput layerNormGeneratorOutput layerNormOutput
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">LayerNorm
  'WithoutBias
  gradient
  device
  dataType
  ('Shape '[decoderInputEmbedDim])
-&gt; stackOutput
-&gt; stackGeneratorOutput
-&gt; m (layerNormOutput, layerNormGeneratorOutput)
forall model input generator output generatorOutput (m :: * -&gt; *).
(HasForward model input generator output generatorOutput,
 MonadThrow m) =&gt;
model -&gt; input -&gt; generator -&gt; m (output, generatorOutput)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">LayerNorm
  'WithoutBias
  gradient
  device
  dataType
  ('Shape '[decoderInputEmbedDim])
TDLayerNormF 'ByT5 gradient device dataType decoderInputEmbedDim
</span><a href="#local-6989586621679775462"><span class="hs-identifier hs-var">tdLayerNorm</span></a></span><span>
</span><span id="line-661"></span><span>            </span><span class="annot"><span class="annottext">IxStateT m generator layerNormGeneratorOutput layerNormOutput
-&gt; (layerNormOutput
    -&gt; IxStateT m layerNormGeneratorOutput generatorOutput output)
-&gt; IxStateT m generator generatorOutput output
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(layerNormGeneratorOutput -&gt; m (output, generatorOutput))
-&gt; IxStateT m layerNormGeneratorOutput generatorOutput output
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((layerNormGeneratorOutput -&gt; m (output, generatorOutput))
 -&gt; IxStateT m layerNormGeneratorOutput generatorOutput output)
-&gt; (layerNormOutput
    -&gt; layerNormGeneratorOutput -&gt; m (output, generatorOutput))
-&gt; layerNormOutput
-&gt; IxStateT m layerNormGeneratorOutput generatorOutput output
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Dropout dropoutP
-&gt; layerNormOutput
-&gt; layerNormGeneratorOutput
-&gt; m (output, generatorOutput)
forall model input generator output generatorOutput (m :: * -&gt; *).
(HasForward model input generator output generatorOutput,
 MonadThrow m) =&gt;
model -&gt; input -&gt; generator -&gt; m (output, generatorOutput)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">Dropout dropoutP
TDDropoutF 'ByT5 dropoutP
</span><a href="#local-6989586621679775461"><span class="hs-identifier hs-var">tdDropout</span></a></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span>
</span><span id="line-662"></span><span>
</span><span id="line-663"></span><span class="hs-comment">-- | 'HasForward' instance for @TransformerDecoder numLayers 'BART@.</span><span>
</span><span id="line-664"></span><span class="hs-comment">--</span><span>
</span><span id="line-665"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-666"></span><span class="hs-comment">-- &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;  &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;  &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;  &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;  &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;</span><span>
</span><span id="line-667"></span><span class="hs-comment">-- &#9474; decoderInput &#9474;  &#9474; decoderPos &#9474;  &#9474; encoderOutput &#9474;  &#9474; decoderAttentionMask &#9474;  &#9474; crossAttentionMask &#9474;</span><span>
</span><span id="line-668"></span><span class="hs-comment">-- &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;  &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;  &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;  &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;  &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-669"></span><span class="hs-comment">--        &#9474;                 &#9474;                &#9474;                     &#9474;                         &#9474;</span><span>
</span><span id="line-670"></span><span class="hs-comment">--        &#9474;                 &#9660;                &#9474;                     &#9474;                         &#9474;</span><span>
</span><span id="line-671"></span><span class="hs-comment">--        &#9474;             tdPosEnc             &#9474;                     &#9474;                         &#9474;</span><span>
</span><span id="line-672"></span><span class="hs-comment">--        &#9474;                 &#9474;                &#9474;                     &#9474;                         &#9474;</span><span>
</span><span id="line-673"></span><span class="hs-comment">--        &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9658;add&#9668;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;                &#9474;                     &#9474;                         &#9474;</span><span>
</span><span id="line-674"></span><span class="hs-comment">--                 &#9474;                         &#9474;                     &#9474;                         &#9474;</span><span>
</span><span id="line-675"></span><span class="hs-comment">--                 &#9660;                         &#9474;                     &#9474;                         &#9474;</span><span>
</span><span id="line-676"></span><span class="hs-comment">--          tdEmbedLayerNorm                 &#9474;                     &#9474;                         &#9474;</span><span>
</span><span id="line-677"></span><span class="hs-comment">--                 &#9660;                         &#9474;                     &#9660;                         &#9660;</span><span>
</span><span id="line-678"></span><span class="hs-comment">--             tdDropout                     &#9474;                 unsqueeze                 unsqueeze</span><span>
</span><span id="line-679"></span><span class="hs-comment">--                 &#9660;                         &#9474;                     &#9474;                         &#9474;</span><span>
</span><span id="line-680"></span><span class="hs-comment">--              tdStack&#9668;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;&#9668;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;&#9668;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-681"></span><span class="hs-comment">--                 &#9474;</span><span>
</span><span id="line-682"></span><span class="hs-comment">--                 &#9660;</span><span>
</span><span id="line-683"></span><span class="hs-comment">--            &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;</span><span>
</span><span id="line-684"></span><span class="hs-comment">--            &#9474; output &#9474;</span><span>
</span><span id="line-685"></span><span class="hs-comment">--            &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-686"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-687"></span><span id="local-6989586621679775411"><span id="local-6989586621679775412"><span id="local-6989586621679775413"><span id="local-6989586621679775414"><span id="local-6989586621679775415"><span id="local-6989586621679775416"><span id="local-6989586621679775417"><span id="local-6989586621679775418"><span id="local-6989586621679775419"><span id="local-6989586621679775420"><span id="local-6989586621679775421"><span id="local-6989586621679775422"><span id="local-6989586621679775423"><span id="local-6989586621679775424"><span id="local-6989586621679775425"><span id="local-6989586621679775426"><span id="local-6989586621679775427"><span id="local-6989586621679775428"><span id="local-6989586621679775429"><span id="local-6989586621679775430"><span id="local-6989586621679775431"><span id="local-6989586621679775432"><span id="local-6989586621679775433"><span id="local-6989586621679775434"><span id="local-6989586621679775435"><span id="local-6989586621679775436"><span id="local-6989586621679775437"><span id="local-6989586621679775438"><span id="local-6989586621679775439"><span id="local-6989586621679775440"><span id="local-6989586621679775441"><span id="local-6989586621679775442"><span id="local-6989586621679775443"><span id="local-6989586621679775444"><span id="local-6989586621679775445"><span id="local-6989586621679775446"><span id="local-6989586621679775447"><span id="local-6989586621679775448"><span id="local-6989586621679775449"><span class="hs-keyword">instance</span><span>
</span><span id="line-688"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-689"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TDEmbedLayerNormF"><span class="hs-identifier hs-type">TDEmbedLayerNormF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775449"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775448"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775447"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775446"><span class="hs-identifier hs-type">decoderInputEmbedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-690"></span><span>      </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-691"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679775445"><span class="hs-identifier hs-type">decoderInputGradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775449"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775444"><span class="hs-identifier hs-type">decoderPosGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-692"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679775443"><span class="hs-identifier hs-type">decoderInputLayout</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Dense"><span class="hs-identifier hs-type">Dense</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775442"><span class="hs-identifier hs-type">decoderPosLayout</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-693"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679775441"><span class="hs-identifier hs-type">decoderInputDevice</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775448"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775440"><span class="hs-identifier hs-type">decoderPosDevice</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-694"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679775439"><span class="hs-identifier hs-type">decoderInputDataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Seq"><span class="hs-identifier hs-type">Seq</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679775438"><span class="hs-identifier hs-type">decoderPosDataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#Int64"><span class="hs-identifier hs-type">Int64</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679775447"><span class="hs-identifier hs-type">dataType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-695"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#BroadcastShapesF"><span class="hs-identifier hs-type">BroadcastShapesF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775437"><span class="hs-identifier hs-type">decoderInputShape</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Functional.Sparse.html#EmbeddingF"><span class="hs-identifier hs-type">EmbeddingF</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679775436"><span class="hs-identifier hs-type">posEncDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679775446"><span class="hs-identifier hs-type">decoderInputEmbedDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679775435"><span class="hs-identifier hs-type">decoderPosShape</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-696"></span><span>      </span><span class="hs-special">)</span><span>
</span><span id="line-697"></span><span>      </span><span class="annot"><a href="#local-6989586621679775434"><span class="hs-identifier hs-type">generator</span></a></span><span>
</span><span id="line-698"></span><span>      </span><span class="annot"><a href="#local-6989586621679775433"><span class="hs-identifier hs-type">layerNormOutput</span></a></span><span>
</span><span id="line-699"></span><span>      </span><span class="annot"><a href="#local-6989586621679775434"><span class="hs-identifier hs-type">generator</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-700"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-701"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TDDropoutF"><span class="hs-identifier hs-type">TDDropoutF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775432"><span class="hs-identifier hs-type">dropoutP</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-702"></span><span>      </span><span class="annot"><a href="#local-6989586621679775433"><span class="hs-identifier hs-type">layerNormOutput</span></a></span><span>
</span><span id="line-703"></span><span>      </span><span class="annot"><a href="#local-6989586621679775434"><span class="hs-identifier hs-type">generator</span></a></span><span>
</span><span id="line-704"></span><span>      </span><span class="annot"><a href="#local-6989586621679775431"><span class="hs-identifier hs-type">dropoutOutput</span></a></span><span>
</span><span id="line-705"></span><span>      </span><span class="annot"><a href="#local-6989586621679775430"><span class="hs-identifier hs-type">dropoutGeneratorOutput</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-706"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-707"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TDStackF"><span class="hs-identifier hs-type">TDStackF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775429"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775449"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775448"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775447"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775428"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775427"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775426"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775446"><span class="hs-identifier hs-type">decoderInputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775425"><span class="hs-identifier hs-type">encoderOutputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775424"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775432"><span class="hs-identifier hs-type">dropoutP</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-708"></span><span>      </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="#local-6989586621679775431"><span class="hs-identifier hs-type">dropoutOutput</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-709"></span><span>        </span><span class="annot"><a href="#local-6989586621679775423"><span class="hs-identifier hs-type">encoderOutput</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-710"></span><span>        </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-711"></span><span>          </span><span class="annot"><a href="#local-6989586621679775422"><span class="hs-identifier hs-type">decoderAttentionMaskGradient</span></a></span><span>
</span><span id="line-712"></span><span>          </span><span class="annot"><a href="#local-6989586621679775421"><span class="hs-identifier hs-type">decoderAttentionMaskLayout</span></a></span><span>
</span><span id="line-713"></span><span>          </span><span class="annot"><a href="#local-6989586621679775420"><span class="hs-identifier hs-type">decoderAttentionMaskDevice</span></a></span><span>
</span><span id="line-714"></span><span>          </span><span class="annot"><a href="#local-6989586621679775419"><span class="hs-identifier hs-type">decoderAttentionMaskDataType</span></a></span><span>
</span><span id="line-715"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#UnsqueezeF"><span class="hs-identifier hs-type">UnsqueezeF</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679775418"><span class="hs-identifier hs-type">decoderAttentionMaskShape</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-716"></span><span>        </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-717"></span><span>          </span><span class="annot"><a href="#local-6989586621679775417"><span class="hs-identifier hs-type">crossAttentionMaskGradient</span></a></span><span>
</span><span id="line-718"></span><span>          </span><span class="annot"><a href="#local-6989586621679775416"><span class="hs-identifier hs-type">crossAttentionMaskLayout</span></a></span><span>
</span><span id="line-719"></span><span>          </span><span class="annot"><a href="#local-6989586621679775415"><span class="hs-identifier hs-type">crossAttentionMaskDevice</span></a></span><span>
</span><span id="line-720"></span><span>          </span><span class="annot"><a href="#local-6989586621679775414"><span class="hs-identifier hs-type">crossAttentionMaskDataType</span></a></span><span>
</span><span id="line-721"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#UnsqueezeF"><span class="hs-identifier hs-type">UnsqueezeF</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679775413"><span class="hs-identifier hs-type">crossAttentionMaskShape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-722"></span><span>      </span><span class="hs-special">)</span><span>
</span><span id="line-723"></span><span>      </span><span class="annot"><a href="#local-6989586621679775430"><span class="hs-identifier hs-type">dropoutGeneratorOutput</span></a></span><span>
</span><span id="line-724"></span><span>      </span><span class="annot"><a href="#local-6989586621679775412"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-725"></span><span>      </span><span class="annot"><a href="#local-6989586621679775411"><span class="hs-identifier hs-type">generatorOutput</span></a></span><span>
</span><span id="line-726"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-727"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-728"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TransformerDecoder"><span class="hs-identifier hs-type">TransformerDecoder</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775429"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775449"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775448"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775447"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775428"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775427"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775426"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775446"><span class="hs-identifier hs-type">decoderInputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775425"><span class="hs-identifier hs-type">encoderOutputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775424"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775436"><span class="hs-identifier hs-type">posEncDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775432"><span class="hs-identifier hs-type">dropoutP</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-729"></span><span>    </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775445"><span class="hs-identifier hs-type">decoderInputGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775443"><span class="hs-identifier hs-type">decoderInputLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775441"><span class="hs-identifier hs-type">decoderInputDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775439"><span class="hs-identifier hs-type">decoderInputDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775437"><span class="hs-identifier hs-type">decoderInputShape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-730"></span><span>      </span><span class="annot"><a href="#local-6989586621679775423"><span class="hs-identifier hs-type">encoderOutput</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-731"></span><span>      </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775444"><span class="hs-identifier hs-type">decoderPosGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775442"><span class="hs-identifier hs-type">decoderPosLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775440"><span class="hs-identifier hs-type">decoderPosDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775438"><span class="hs-identifier hs-type">decoderPosDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775435"><span class="hs-identifier hs-type">decoderPosShape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-732"></span><span>      </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775422"><span class="hs-identifier hs-type">decoderAttentionMaskGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775421"><span class="hs-identifier hs-type">decoderAttentionMaskLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775420"><span class="hs-identifier hs-type">decoderAttentionMaskDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775419"><span class="hs-identifier hs-type">decoderAttentionMaskDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775418"><span class="hs-identifier hs-type">decoderAttentionMaskShape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-733"></span><span>      </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775417"><span class="hs-identifier hs-type">crossAttentionMaskGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775416"><span class="hs-identifier hs-type">crossAttentionMaskLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775415"><span class="hs-identifier hs-type">crossAttentionMaskDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775414"><span class="hs-identifier hs-type">crossAttentionMaskDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775413"><span class="hs-identifier hs-type">crossAttentionMaskShape</span></a></span><span>
</span><span id="line-734"></span><span>    </span><span class="hs-special">)</span><span>
</span><span id="line-735"></span><span>    </span><span class="annot"><a href="#local-6989586621679775434"><span class="hs-identifier hs-type">generator</span></a></span><span>
</span><span id="line-736"></span><span>    </span><span class="annot"><a href="#local-6989586621679775412"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-737"></span><span>    </span><span class="annot"><a href="#local-6989586621679775411"><span class="hs-identifier hs-type">generatorOutput</span></a></span><span>
</span><span id="line-738"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-739"></span><span>  </span><span id="local-6989586621679775409"><span class="annot"><span class="annottext">forward :: TransformerDecoder
  'BART
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  decoderInputEmbedDim
  encoderOutputEmbedDim
  ffnDim
  posEncDim
  dropoutP
-&gt; (Tensor
      decoderInputGradient
      decoderInputLayout
      decoderInputDevice
      decoderInputDataType
      decoderInputShape,
    encoderOutput,
    Tensor
      decoderPosGradient
      decoderPosLayout
      decoderPosDevice
      decoderPosDataType
      decoderPosShape,
    Tensor
      decoderAttentionMaskGradient
      decoderAttentionMaskLayout
      decoderAttentionMaskDevice
      decoderAttentionMaskDataType
      decoderAttentionMaskShape,
    Tensor
      crossAttentionMaskGradient
      crossAttentionMaskLayout
      crossAttentionMaskDevice
      crossAttentionMaskDataType
      crossAttentionMaskShape)
-&gt; generator
-&gt; m (output, generatorOutput)
</span><a href="#local-6989586621679775409"><span class="hs-identifier hs-var hs-var hs-var hs-var">forward</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TransformerDecoder"><span class="hs-identifier hs-type">TransformerDecoder</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#GTransformerDecoder"><span class="hs-identifier hs-type">GTransformerDecoder</span></a></span><span> </span><span class="hs-special">{</span><span id="local-6989586621679775404"><span id="local-6989586621679775405"><span id="local-6989586621679775406"><span id="local-6989586621679775407"><span id="local-6989586621679775408"><span class="annot"><span class="annottext">TDPosEncF
  'BART
  gradient
  device
  dataType
  headDim
  decoderInputEmbedDim
  posEncDim
TDDropoutF 'BART dropoutP
TDLayerNormF 'BART gradient device dataType decoderInputEmbedDim
TDEmbedLayerNormF
  'BART gradient device dataType decoderInputEmbedDim
TDStackF
  'BART
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  decoderInputEmbedDim
  encoderOutputEmbedDim
  ffnDim
  dropoutP
tdPosEnc :: TDPosEncF
  'BART
  gradient
  device
  dataType
  headDim
  decoderInputEmbedDim
  posEncDim
tdDropout :: TDDropoutF 'BART dropoutP
tdLayerNorm :: TDLayerNormF 'BART gradient device dataType decoderInputEmbedDim
tdEmbedLayerNorm :: TDEmbedLayerNormF
  'BART gradient device dataType decoderInputEmbedDim
tdStack :: TDStackF
  'BART
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  decoderInputEmbedDim
  encoderOutputEmbedDim
  ffnDim
  dropoutP
tdPosEnc :: forall stack embedLayerNorm layerNorm dropout posEnc.
GTransformerDecoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; posEnc
tdDropout :: forall stack embedLayerNorm layerNorm dropout posEnc.
GTransformerDecoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; dropout
tdLayerNorm :: forall stack embedLayerNorm layerNorm dropout posEnc.
GTransformerDecoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; layerNorm
tdEmbedLayerNorm :: forall stack embedLayerNorm layerNorm dropout posEnc.
GTransformerDecoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; embedLayerNorm
tdStack :: forall stack embedLayerNorm layerNorm dropout posEnc.
GTransformerDecoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; stack
</span><a href="#local-6989586621679775404"><span class="hs-glyph hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">..</span></a></span></span></span></span></span></span><span class="hs-special">}</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679775403"><span class="annot"><span class="annottext">Tensor
  decoderInputGradient
  decoderInputLayout
  decoderInputDevice
  decoderInputDataType
  decoderInputShape
</span><a href="#local-6989586621679775403"><span class="hs-identifier hs-var">decoderInput</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679775402"><span class="annot"><span class="annottext">encoderOutput
</span><a href="#local-6989586621679775402"><span class="hs-identifier hs-var">encoderOutput</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679775401"><span class="annot"><span class="annottext">Tensor
  decoderPosGradient
  decoderPosLayout
  decoderPosDevice
  decoderPosDataType
  decoderPosShape
</span><a href="#local-6989586621679775401"><span class="hs-identifier hs-var">decoderPos</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679775400"><span class="annot"><span class="annottext">Tensor
  decoderAttentionMaskGradient
  decoderAttentionMaskLayout
  decoderAttentionMaskDevice
  decoderAttentionMaskDataType
  decoderAttentionMaskShape
</span><a href="#local-6989586621679775400"><span class="hs-identifier hs-var">decoderAttentionMask</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679775399"><span class="annot"><span class="annottext">Tensor
  crossAttentionMaskGradient
  crossAttentionMaskLayout
  crossAttentionMaskDevice
  crossAttentionMaskDataType
  crossAttentionMaskShape
</span><a href="#local-6989586621679775399"><span class="hs-identifier hs-var">crossAttentionMask</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-740"></span><span>    </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679775398"><span class="annot"><span class="annottext">decoderAttentionBias :: Tensor
  decoderAttentionMaskGradient
  decoderAttentionMaskLayout
  decoderAttentionMaskDevice
  decoderAttentionMaskDataType
  (UnsqueezeF ('SelectDim ('ByIndex 1)) decoderAttentionMaskShape)
</span><a href="#local-6989586621679775398"><span class="hs-identifier hs-var hs-var">decoderAttentionBias</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor
  decoderAttentionMaskGradient
  decoderAttentionMaskLayout
  decoderAttentionMaskDevice
  decoderAttentionMaskDataType
  decoderAttentionMaskShape
-&gt; Tensor
     decoderAttentionMaskGradient
     decoderAttentionMaskLayout
     decoderAttentionMaskDevice
     decoderAttentionMaskDataType
     (UnsqueezeF ('SelectDim ('ByIndex 1)) decoderAttentionMaskShape)
forall (selectDim :: SelectDim (By Symbol Nat))
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]).
(shape' ~ UnsqueezeF selectDim shape, SingI selectDim) =&gt;
Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape'
</span><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#unsqueeze"><span class="hs-identifier hs-var">unsqueeze</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
  decoderAttentionMaskGradient
  decoderAttentionMaskLayout
  decoderAttentionMaskDevice
  decoderAttentionMaskDataType
  decoderAttentionMaskShape
</span><a href="#local-6989586621679775400"><span class="hs-identifier hs-var">decoderAttentionMask</span></a></span><span>
</span><span id="line-741"></span><span>        </span><span id="local-6989586621679775397"><span class="annot"><span class="annottext">crossAttentionBias :: Tensor
  crossAttentionMaskGradient
  crossAttentionMaskLayout
  crossAttentionMaskDevice
  crossAttentionMaskDataType
  (UnsqueezeF ('SelectDim ('ByIndex 1)) crossAttentionMaskShape)
</span><a href="#local-6989586621679775397"><span class="hs-identifier hs-var hs-var">crossAttentionBias</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor
  crossAttentionMaskGradient
  crossAttentionMaskLayout
  crossAttentionMaskDevice
  crossAttentionMaskDataType
  crossAttentionMaskShape
-&gt; Tensor
     crossAttentionMaskGradient
     crossAttentionMaskLayout
     crossAttentionMaskDevice
     crossAttentionMaskDataType
     (UnsqueezeF ('SelectDim ('ByIndex 1)) crossAttentionMaskShape)
forall (selectDim :: SelectDim (By Symbol Nat))
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]).
(shape' ~ UnsqueezeF selectDim shape, SingI selectDim) =&gt;
Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape'
</span><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#unsqueeze"><span class="hs-identifier hs-var">unsqueeze</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
  crossAttentionMaskGradient
  crossAttentionMaskLayout
  crossAttentionMaskDevice
  crossAttentionMaskDataType
  crossAttentionMaskShape
</span><a href="#local-6989586621679775399"><span class="hs-identifier hs-var">crossAttentionMask</span></a></span><span>
</span><span id="line-742"></span><span>     </span><span class="hs-keyword">in</span><span> </span><span class="annot"><span class="annottext">IxStateT m generator generatorOutput output
-&gt; generator -&gt; m (output, generatorOutput)
forall (m :: * -&gt; *) i j a. IxStateT m i j a -&gt; i -&gt; m (a, j)
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var hs-var">runIxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">(IxStateT m generator generatorOutput output
 -&gt; generator -&gt; m (output, generatorOutput))
-&gt; IxStateT m generator generatorOutput output
-&gt; generator
-&gt; m (output, generatorOutput)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-743"></span><span>          </span><span class="annot"><span class="annottext">Tensor
  decoderPosGradient
  decoderPosLayout
  decoderPosDevice
  decoderPosDataType
  decoderPosShape
-&gt; IxStateT
     m
     generator
     generator
     (Tensor
        decoderPosGradient
        decoderPosLayout
        decoderPosDevice
        decoderPosDataType
        decoderPosShape)
forall k (m :: k -&gt; k -&gt; * -&gt; *) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  decoderPosGradient
  decoderPosLayout
  decoderPosDevice
  decoderPosDataType
  decoderPosShape
</span><a href="#local-6989586621679775401"><span class="hs-identifier hs-var">decoderPos</span></a></span><span>
</span><span id="line-744"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  generator
  generator
  (Tensor
     decoderPosGradient
     decoderPosLayout
     decoderPosDevice
     decoderPosDataType
     decoderPosShape)
-&gt; (Tensor
      decoderPosGradient
      decoderPosLayout
      decoderPosDevice
      decoderPosDataType
      decoderPosShape
    -&gt; IxStateT
         m
         generator
         generator
         (Tensor
            (Or (Gradient RequiresGradient) gradient decoderPosGradient)
            (Unify (Layout LayoutType) ('Layout 'Dense) decoderPosLayout)
            (Unify (Device (DeviceType Nat)) device decoderPosDevice)
            (Seq
               (Unify (DataType DType) decoderPosDataType ('DataType 'Int64))
               dataType)
            (EmbeddingF
               ('Shape '[posEncDim, decoderInputEmbedDim]) decoderPosShape)))
-&gt; IxStateT
     m
     generator
     generator
     (Tensor
        (Or (Gradient RequiresGradient) gradient decoderPosGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) decoderPosLayout)
        (Unify (Device (DeviceType Nat)) device decoderPosDevice)
        (Seq
           (Unify (DataType DType) decoderPosDataType ('DataType 'Int64))
           dataType)
        (EmbeddingF
           ('Shape '[posEncDim, decoderInputEmbedDim]) decoderPosShape))
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(generator
 -&gt; m (Tensor
         (Or (Gradient RequiresGradient) gradient decoderPosGradient)
         (Unify (Layout LayoutType) ('Layout 'Dense) decoderPosLayout)
         (Unify (Device (DeviceType Nat)) device decoderPosDevice)
         (Seq
            (Unify (DataType DType) decoderPosDataType ('DataType 'Int64))
            dataType)
         (EmbeddingF
            ('Shape '[posEncDim, decoderInputEmbedDim]) decoderPosShape),
       generator))
-&gt; IxStateT
     m
     generator
     generator
     (Tensor
        (Or (Gradient RequiresGradient) gradient decoderPosGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) decoderPosLayout)
        (Unify (Device (DeviceType Nat)) device decoderPosDevice)
        (Seq
           (Unify (DataType DType) decoderPosDataType ('DataType 'Int64))
           dataType)
        (EmbeddingF
           ('Shape '[posEncDim, decoderInputEmbedDim]) decoderPosShape))
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((generator
  -&gt; m (Tensor
          (Or (Gradient RequiresGradient) gradient decoderPosGradient)
          (Unify (Layout LayoutType) ('Layout 'Dense) decoderPosLayout)
          (Unify (Device (DeviceType Nat)) device decoderPosDevice)
          (Seq
             (Unify (DataType DType) decoderPosDataType ('DataType 'Int64))
             dataType)
          (EmbeddingF
             ('Shape '[posEncDim, decoderInputEmbedDim]) decoderPosShape),
        generator))
 -&gt; IxStateT
      m
      generator
      generator
      (Tensor
         (Or (Gradient RequiresGradient) gradient decoderPosGradient)
         (Unify (Layout LayoutType) ('Layout 'Dense) decoderPosLayout)
         (Unify (Device (DeviceType Nat)) device decoderPosDevice)
         (Seq
            (Unify (DataType DType) decoderPosDataType ('DataType 'Int64))
            dataType)
         (EmbeddingF
            ('Shape '[posEncDim, decoderInputEmbedDim]) decoderPosShape)))
-&gt; (Tensor
      decoderPosGradient
      decoderPosLayout
      decoderPosDevice
      decoderPosDataType
      decoderPosShape
    -&gt; generator
    -&gt; m (Tensor
            (Or (Gradient RequiresGradient) gradient decoderPosGradient)
            (Unify (Layout LayoutType) ('Layout 'Dense) decoderPosLayout)
            (Unify (Device (DeviceType Nat)) device decoderPosDevice)
            (Seq
               (Unify (DataType DType) decoderPosDataType ('DataType 'Int64))
               dataType)
            (EmbeddingF
               ('Shape '[posEncDim, decoderInputEmbedDim]) decoderPosShape),
          generator))
-&gt; Tensor
     decoderPosGradient
     decoderPosLayout
     decoderPosDevice
     decoderPosDataType
     decoderPosShape
-&gt; IxStateT
     m
     generator
     generator
     (Tensor
        (Or (Gradient RequiresGradient) gradient decoderPosGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) decoderPosLayout)
        (Unify (Device (DeviceType Nat)) device decoderPosDevice)
        (Seq
           (Unify (DataType DType) decoderPosDataType ('DataType 'Int64))
           dataType)
        (EmbeddingF
           ('Shape '[posEncDim, decoderInputEmbedDim]) decoderPosShape))
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Embedding
  gradient
  ('Layout 'Dense)
  device
  dataType
  posEncDim
  decoderInputEmbedDim
  'Nothing
-&gt; Tensor
     decoderPosGradient
     decoderPosLayout
     decoderPosDevice
     decoderPosDataType
     decoderPosShape
-&gt; generator
-&gt; m (Tensor
        (Or (Gradient RequiresGradient) gradient decoderPosGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) decoderPosLayout)
        (Unify (Device (DeviceType Nat)) device decoderPosDevice)
        (Seq
           (Unify (DataType DType) decoderPosDataType ('DataType 'Int64))
           dataType)
        (EmbeddingF
           ('Shape '[posEncDim, decoderInputEmbedDim]) decoderPosShape),
      generator)
forall model input generator output generatorOutput (m :: * -&gt; *).
(HasForward model input generator output generatorOutput,
 MonadThrow m) =&gt;
model -&gt; input -&gt; generator -&gt; m (output, generatorOutput)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">Embedding
  gradient
  ('Layout 'Dense)
  device
  dataType
  posEncDim
  decoderInputEmbedDim
  'Nothing
TDPosEncF
  'BART
  gradient
  device
  dataType
  headDim
  decoderInputEmbedDim
  posEncDim
</span><a href="#local-6989586621679775404"><span class="hs-identifier hs-var">tdPosEnc</span></a></span><span>
</span><span id="line-745"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  generator
  generator
  (Tensor
     (Or (Gradient RequiresGradient) gradient decoderPosGradient)
     (Unify (Layout LayoutType) ('Layout 'Dense) decoderPosLayout)
     (Unify (Device (DeviceType Nat)) device decoderPosDevice)
     (Seq
        (Unify (DataType DType) decoderPosDataType ('DataType 'Int64))
        dataType)
     (EmbeddingF
        ('Shape '[posEncDim, decoderInputEmbedDim]) decoderPosShape))
-&gt; (Tensor
      (Or (Gradient RequiresGradient) gradient decoderPosGradient)
      (Unify (Layout LayoutType) ('Layout 'Dense) decoderPosLayout)
      (Unify (Device (DeviceType Nat)) device decoderPosDevice)
      (Seq
         (Unify (DataType DType) decoderPosDataType ('DataType 'Int64))
         dataType)
      (EmbeddingF
         ('Shape '[posEncDim, decoderInputEmbedDim]) decoderPosShape)
    -&gt; IxStateT
         m
         generator
         generator
         (Tensor
            (Or
               (Gradient RequiresGradient)
               decoderInputGradient
               (Or (Gradient RequiresGradient) gradient decoderPosGradient))
            (Unify
               (Layout LayoutType)
               decoderInputLayout
               (Unify (Layout LayoutType) ('Layout 'Dense) decoderPosLayout))
            (Unify
               (Device (DeviceType Nat))
               decoderInputDevice
               (Unify (Device (DeviceType Nat)) device decoderPosDevice))
            (Unify
               (DataType DType)
               decoderInputDataType
               (Seq
                  (Unify (DataType DType) decoderPosDataType ('DataType 'Int64))
                  dataType))
            (BroadcastShapesF
               decoderInputShape
               (EmbeddingF
                  ('Shape '[posEncDim, decoderInputEmbedDim]) decoderPosShape))))
-&gt; IxStateT
     m
     generator
     generator
     (Tensor
        (Or
           (Gradient RequiresGradient)
           decoderInputGradient
           (Or (Gradient RequiresGradient) gradient decoderPosGradient))
        (Unify
           (Layout LayoutType)
           decoderInputLayout
           (Unify (Layout LayoutType) ('Layout 'Dense) decoderPosLayout))
        (Unify
           (Device (DeviceType Nat))
           decoderInputDevice
           (Unify (Device (DeviceType Nat)) device decoderPosDevice))
        (Unify
           (DataType DType)
           decoderInputDataType
           (Seq
              (Unify (DataType DType) decoderPosDataType ('DataType 'Int64))
              dataType))
        (BroadcastShapesF
           decoderInputShape
           (EmbeddingF
              ('Shape '[posEncDim, decoderInputEmbedDim]) decoderPosShape)))
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  (Or
     (Gradient RequiresGradient)
     decoderInputGradient
     (Or (Gradient RequiresGradient) gradient decoderPosGradient))
  (Unify
     (Layout LayoutType)
     decoderInputLayout
     (Unify (Layout LayoutType) ('Layout 'Dense) decoderPosLayout))
  (Unify
     (Device (DeviceType Nat))
     decoderInputDevice
     (Unify (Device (DeviceType Nat)) device decoderPosDevice))
  (Unify
     (DataType DType)
     decoderInputDataType
     (Seq
        (Unify (DataType DType) decoderPosDataType ('DataType 'Int64))
        dataType))
  (BroadcastShapesF
     decoderInputShape
     (EmbeddingF
        ('Shape '[posEncDim, decoderInputEmbedDim]) decoderPosShape))
-&gt; IxStateT
     m
     generator
     generator
     (Tensor
        (Or
           (Gradient RequiresGradient)
           decoderInputGradient
           (Or (Gradient RequiresGradient) gradient decoderPosGradient))
        (Unify
           (Layout LayoutType)
           decoderInputLayout
           (Unify (Layout LayoutType) ('Layout 'Dense) decoderPosLayout))
        (Unify
           (Device (DeviceType Nat))
           decoderInputDevice
           (Unify (Device (DeviceType Nat)) device decoderPosDevice))
        (Unify
           (DataType DType)
           decoderInputDataType
           (Seq
              (Unify (DataType DType) decoderPosDataType ('DataType 'Int64))
              dataType))
        (BroadcastShapesF
           decoderInputShape
           (EmbeddingF
              ('Shape '[posEncDim, decoderInputEmbedDim]) decoderPosShape)))
forall k (m :: k -&gt; k -&gt; * -&gt; *) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">(Tensor
   (Or
      (Gradient RequiresGradient)
      decoderInputGradient
      (Or (Gradient RequiresGradient) gradient decoderPosGradient))
   (Unify
      (Layout LayoutType)
      decoderInputLayout
      (Unify (Layout LayoutType) ('Layout 'Dense) decoderPosLayout))
   (Unify
      (Device (DeviceType Nat))
      decoderInputDevice
      (Unify (Device (DeviceType Nat)) device decoderPosDevice))
   (Unify
      (DataType DType)
      decoderInputDataType
      (Seq
         (Unify (DataType DType) decoderPosDataType ('DataType 'Int64))
         dataType))
   (BroadcastShapesF
      decoderInputShape
      (EmbeddingF
         ('Shape '[posEncDim, decoderInputEmbedDim]) decoderPosShape))
 -&gt; IxStateT
      m
      generator
      generator
      (Tensor
         (Or
            (Gradient RequiresGradient)
            decoderInputGradient
            (Or (Gradient RequiresGradient) gradient decoderPosGradient))
         (Unify
            (Layout LayoutType)
            decoderInputLayout
            (Unify (Layout LayoutType) ('Layout 'Dense) decoderPosLayout))
         (Unify
            (Device (DeviceType Nat))
            decoderInputDevice
            (Unify (Device (DeviceType Nat)) device decoderPosDevice))
         (Unify
            (DataType DType)
            decoderInputDataType
            (Seq
               (Unify (DataType DType) decoderPosDataType ('DataType 'Int64))
               dataType))
         (BroadcastShapesF
            decoderInputShape
            (EmbeddingF
               ('Shape '[posEncDim, decoderInputEmbedDim]) decoderPosShape))))
-&gt; (Tensor
      (Or (Gradient RequiresGradient) gradient decoderPosGradient)
      (Unify (Layout LayoutType) ('Layout 'Dense) decoderPosLayout)
      (Unify (Device (DeviceType Nat)) device decoderPosDevice)
      (Seq
         (Unify (DataType DType) decoderPosDataType ('DataType 'Int64))
         dataType)
      (EmbeddingF
         ('Shape '[posEncDim, decoderInputEmbedDim]) decoderPosShape)
    -&gt; Tensor
         (Or
            (Gradient RequiresGradient)
            decoderInputGradient
            (Or (Gradient RequiresGradient) gradient decoderPosGradient))
         (Unify
            (Layout LayoutType)
            decoderInputLayout
            (Unify (Layout LayoutType) ('Layout 'Dense) decoderPosLayout))
         (Unify
            (Device (DeviceType Nat))
            decoderInputDevice
            (Unify (Device (DeviceType Nat)) device decoderPosDevice))
         (Unify
            (DataType DType)
            decoderInputDataType
            (Seq
               (Unify (DataType DType) decoderPosDataType ('DataType 'Int64))
               dataType))
         (BroadcastShapesF
            decoderInputShape
            (EmbeddingF
               ('Shape '[posEncDim, decoderInputEmbedDim]) decoderPosShape)))
-&gt; Tensor
     (Or (Gradient RequiresGradient) gradient decoderPosGradient)
     (Unify (Layout LayoutType) ('Layout 'Dense) decoderPosLayout)
     (Unify (Device (DeviceType Nat)) device decoderPosDevice)
     (Seq
        (Unify (DataType DType) decoderPosDataType ('DataType 'Int64))
        dataType)
     (EmbeddingF
        ('Shape '[posEncDim, decoderInputEmbedDim]) decoderPosShape)
-&gt; IxStateT
     m
     generator
     generator
     (Tensor
        (Or
           (Gradient RequiresGradient)
           decoderInputGradient
           (Or (Gradient RequiresGradient) gradient decoderPosGradient))
        (Unify
           (Layout LayoutType)
           decoderInputLayout
           (Unify (Layout LayoutType) ('Layout 'Dense) decoderPosLayout))
        (Unify
           (Device (DeviceType Nat))
           decoderInputDevice
           (Unify (Device (DeviceType Nat)) device decoderPosDevice))
        (Unify
           (DataType DType)
           decoderInputDataType
           (Seq
              (Unify (DataType DType) decoderPosDataType ('DataType 'Int64))
              dataType))
        (BroadcastShapesF
           decoderInputShape
           (EmbeddingF
              ('Shape '[posEncDim, decoderInputEmbedDim]) decoderPosShape)))
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Tensor
  decoderInputGradient
  decoderInputLayout
  decoderInputDevice
  decoderInputDataType
  decoderInputShape
</span><a href="#local-6989586621679775403"><span class="hs-identifier hs-var">decoderInput</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  decoderInputGradient
  decoderInputLayout
  decoderInputDevice
  decoderInputDataType
  decoderInputShape
-&gt; Tensor
     (Or (Gradient RequiresGradient) gradient decoderPosGradient)
     (Unify (Layout LayoutType) ('Layout 'Dense) decoderPosLayout)
     (Unify (Device (DeviceType Nat)) device decoderPosDevice)
     (Seq
        (Unify (DataType DType) decoderPosDataType ('DataType 'Int64))
        dataType)
     (EmbeddingF
        ('Shape '[posEncDim, decoderInputEmbedDim]) decoderPosShape)
-&gt; Tensor
     (decoderInputGradient
      &lt;|&gt; Or (Gradient RequiresGradient) gradient decoderPosGradient)
     (decoderInputLayout
      &lt;+&gt; Unify (Layout LayoutType) ('Layout 'Dense) decoderPosLayout)
     (decoderInputDevice
      &lt;+&gt; Unify (Device (DeviceType Nat)) device decoderPosDevice)
     (decoderInputDataType
      &lt;+&gt; Seq
            (Unify (DataType DType) decoderPosDataType ('DataType 'Int64))
            dataType)
     (BroadcastShapesF
        decoderInputShape
        (EmbeddingF
           ('Shape '[posEncDim, decoderInputEmbedDim]) decoderPosShape))
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (gradient' :: Gradient RequiresGradient)
       (layout' :: Layout LayoutType) (device' :: Device (DeviceType Nat))
       (dataType' :: DataType DType)
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]).
Tensor gradient layout device dataType shape
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; Tensor
     (gradient &lt;|&gt; gradient')
     (layout &lt;+&gt; layout')
     (device &lt;+&gt; device')
     (dataType &lt;+&gt; dataType')
     (BroadcastShapesF shape shape')
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#add"><span class="hs-operator hs-var">`add`</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-746"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  generator
  generator
  (Tensor
     (Or
        (Gradient RequiresGradient)
        decoderInputGradient
        (Or (Gradient RequiresGradient) gradient decoderPosGradient))
     (Unify
        (Layout LayoutType)
        decoderInputLayout
        (Unify (Layout LayoutType) ('Layout 'Dense) decoderPosLayout))
     (Unify
        (Device (DeviceType Nat))
        decoderInputDevice
        (Unify (Device (DeviceType Nat)) device decoderPosDevice))
     (Unify
        (DataType DType)
        decoderInputDataType
        (Seq
           (Unify (DataType DType) decoderPosDataType ('DataType 'Int64))
           dataType))
     (BroadcastShapesF
        decoderInputShape
        (EmbeddingF
           ('Shape '[posEncDim, decoderInputEmbedDim]) decoderPosShape)))
-&gt; (Tensor
      (Or
         (Gradient RequiresGradient)
         decoderInputGradient
         (Or (Gradient RequiresGradient) gradient decoderPosGradient))
      (Unify
         (Layout LayoutType)
         decoderInputLayout
         (Unify (Layout LayoutType) ('Layout 'Dense) decoderPosLayout))
      (Unify
         (Device (DeviceType Nat))
         decoderInputDevice
         (Unify (Device (DeviceType Nat)) device decoderPosDevice))
      (Unify
         (DataType DType)
         decoderInputDataType
         (Seq
            (Unify (DataType DType) decoderPosDataType ('DataType 'Int64))
            dataType))
      (BroadcastShapesF
         decoderInputShape
         (EmbeddingF
            ('Shape '[posEncDim, decoderInputEmbedDim]) decoderPosShape))
    -&gt; IxStateT m generator generator layerNormOutput)
-&gt; IxStateT m generator generator layerNormOutput
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(generator -&gt; m (layerNormOutput, generator))
-&gt; IxStateT m generator generator layerNormOutput
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((generator -&gt; m (layerNormOutput, generator))
 -&gt; IxStateT m generator generator layerNormOutput)
-&gt; (Tensor
      (Or
         (Gradient RequiresGradient)
         decoderInputGradient
         (Or (Gradient RequiresGradient) gradient decoderPosGradient))
      (Unify
         (Layout LayoutType)
         decoderInputLayout
         (Unify (Layout LayoutType) ('Layout 'Dense) decoderPosLayout))
      (Unify
         (Device (DeviceType Nat))
         decoderInputDevice
         (Unify (Device (DeviceType Nat)) device decoderPosDevice))
      (Unify
         (DataType DType)
         decoderInputDataType
         (Seq
            (Unify (DataType DType) decoderPosDataType ('DataType 'Int64))
            dataType))
      (BroadcastShapesF
         decoderInputShape
         (EmbeddingF
            ('Shape '[posEncDim, decoderInputEmbedDim]) decoderPosShape))
    -&gt; generator -&gt; m (layerNormOutput, generator))
-&gt; Tensor
     (Or
        (Gradient RequiresGradient)
        decoderInputGradient
        (Or (Gradient RequiresGradient) gradient decoderPosGradient))
     (Unify
        (Layout LayoutType)
        decoderInputLayout
        (Unify (Layout LayoutType) ('Layout 'Dense) decoderPosLayout))
     (Unify
        (Device (DeviceType Nat))
        decoderInputDevice
        (Unify (Device (DeviceType Nat)) device decoderPosDevice))
     (Unify
        (DataType DType)
        decoderInputDataType
        (Seq
           (Unify (DataType DType) decoderPosDataType ('DataType 'Int64))
           dataType))
     (BroadcastShapesF
        decoderInputShape
        (EmbeddingF
           ('Shape '[posEncDim, decoderInputEmbedDim]) decoderPosShape))
-&gt; IxStateT m generator generator layerNormOutput
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">LayerNorm
  'WithBias gradient device dataType ('Shape '[decoderInputEmbedDim])
-&gt; Tensor
     (Or
        (Gradient RequiresGradient)
        decoderInputGradient
        (Or (Gradient RequiresGradient) gradient decoderPosGradient))
     (Unify
        (Layout LayoutType)
        decoderInputLayout
        (Unify (Layout LayoutType) ('Layout 'Dense) decoderPosLayout))
     (Unify
        (Device (DeviceType Nat))
        decoderInputDevice
        (Unify (Device (DeviceType Nat)) device decoderPosDevice))
     (Unify
        (DataType DType)
        decoderInputDataType
        (Seq
           (Unify (DataType DType) decoderPosDataType ('DataType 'Int64))
           dataType))
     (BroadcastShapesF
        decoderInputShape
        (EmbeddingF
           ('Shape '[posEncDim, decoderInputEmbedDim]) decoderPosShape))
-&gt; generator
-&gt; m (layerNormOutput, generator)
forall model input generator output generatorOutput (m :: * -&gt; *).
(HasForward model input generator output generatorOutput,
 MonadThrow m) =&gt;
model -&gt; input -&gt; generator -&gt; m (output, generatorOutput)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">LayerNorm
  'WithBias gradient device dataType ('Shape '[decoderInputEmbedDim])
TDEmbedLayerNormF
  'BART gradient device dataType decoderInputEmbedDim
</span><a href="#local-6989586621679775407"><span class="hs-identifier hs-var">tdEmbedLayerNorm</span></a></span><span>
</span><span id="line-747"></span><span>            </span><span class="annot"><span class="annottext">IxStateT m generator generator layerNormOutput
-&gt; (layerNormOutput
    -&gt; IxStateT m generator dropoutGeneratorOutput dropoutOutput)
-&gt; IxStateT m generator dropoutGeneratorOutput dropoutOutput
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(generator -&gt; m (dropoutOutput, dropoutGeneratorOutput))
-&gt; IxStateT m generator dropoutGeneratorOutput dropoutOutput
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((generator -&gt; m (dropoutOutput, dropoutGeneratorOutput))
 -&gt; IxStateT m generator dropoutGeneratorOutput dropoutOutput)
-&gt; (layerNormOutput
    -&gt; generator -&gt; m (dropoutOutput, dropoutGeneratorOutput))
-&gt; layerNormOutput
-&gt; IxStateT m generator dropoutGeneratorOutput dropoutOutput
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Dropout dropoutP
-&gt; layerNormOutput
-&gt; generator
-&gt; m (dropoutOutput, dropoutGeneratorOutput)
forall model input generator output generatorOutput (m :: * -&gt; *).
(HasForward model input generator output generatorOutput,
 MonadThrow m) =&gt;
model -&gt; input -&gt; generator -&gt; m (output, generatorOutput)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">Dropout dropoutP
TDDropoutF 'BART dropoutP
</span><a href="#local-6989586621679775405"><span class="hs-identifier hs-var">tdDropout</span></a></span><span>
</span><span id="line-748"></span><span>            </span><span class="annot"><span class="annottext">IxStateT m generator dropoutGeneratorOutput dropoutOutput
-&gt; (dropoutOutput
    -&gt; IxStateT m dropoutGeneratorOutput generatorOutput output)
-&gt; IxStateT m generator generatorOutput output
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="hs-special">(</span><span> </span><span class="hs-glyph">\</span><span id="local-6989586621679775396"><span class="annot"><span class="annottext">dropoutOutput
</span><a href="#local-6989586621679775396"><span class="hs-identifier hs-var">decoderInput'</span></a></span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-749"></span><span>                     </span><span class="annot"><span class="annottext">(dropoutGeneratorOutput -&gt; m (output, generatorOutput))
-&gt; IxStateT m dropoutGeneratorOutput generatorOutput output
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((dropoutGeneratorOutput -&gt; m (output, generatorOutput))
 -&gt; IxStateT m dropoutGeneratorOutput generatorOutput output)
-&gt; (dropoutGeneratorOutput -&gt; m (output, generatorOutput))
-&gt; IxStateT m dropoutGeneratorOutput generatorOutput output
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-750"></span><span>                       </span><span class="annot"><span class="annottext">TransformerDecoderStack
  'BART
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  decoderInputEmbedDim
  encoderOutputEmbedDim
  ffnDim
  dropoutP
-&gt; (dropoutOutput, encoderOutput,
    Tensor
      decoderAttentionMaskGradient
      decoderAttentionMaskLayout
      decoderAttentionMaskDevice
      decoderAttentionMaskDataType
      (UnsqueezeF ('SelectDim ('ByIndex 1)) decoderAttentionMaskShape),
    Tensor
      crossAttentionMaskGradient
      crossAttentionMaskLayout
      crossAttentionMaskDevice
      crossAttentionMaskDataType
      (UnsqueezeF ('SelectDim ('ByIndex 1)) crossAttentionMaskShape))
-&gt; dropoutGeneratorOutput
-&gt; m (output, generatorOutput)
forall model input generator output generatorOutput (m :: * -&gt; *).
(HasForward model input generator output generatorOutput,
 MonadThrow m) =&gt;
model -&gt; input -&gt; generator -&gt; m (output, generatorOutput)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span>
</span><span id="line-751"></span><span>                         </span><span class="annot"><span class="annottext">TransformerDecoderStack
  'BART
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  decoderInputEmbedDim
  encoderOutputEmbedDim
  ffnDim
  dropoutP
TDStackF
  'BART
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  decoderInputEmbedDim
  encoderOutputEmbedDim
  ffnDim
  dropoutP
</span><a href="#local-6989586621679775408"><span class="hs-identifier hs-var">tdStack</span></a></span><span>
</span><span id="line-752"></span><span>                         </span><span class="hs-special">(</span><span> </span><span class="annot"><span class="annottext">dropoutOutput
</span><a href="#local-6989586621679775396"><span class="hs-identifier hs-var">decoderInput'</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-753"></span><span>                           </span><span class="annot"><span class="annottext">encoderOutput
</span><a href="#local-6989586621679775402"><span class="hs-identifier hs-var">encoderOutput</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-754"></span><span>                           </span><span class="annot"><span class="annottext">Tensor
  decoderAttentionMaskGradient
  decoderAttentionMaskLayout
  decoderAttentionMaskDevice
  decoderAttentionMaskDataType
  (UnsqueezeF ('SelectDim ('ByIndex 1)) decoderAttentionMaskShape)
</span><a href="#local-6989586621679775398"><span class="hs-identifier hs-var">decoderAttentionBias</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-755"></span><span>                           </span><span class="annot"><span class="annottext">Tensor
  crossAttentionMaskGradient
  crossAttentionMaskLayout
  crossAttentionMaskDevice
  crossAttentionMaskDataType
  (UnsqueezeF ('SelectDim ('ByIndex 1)) crossAttentionMaskShape)
</span><a href="#local-6989586621679775397"><span class="hs-identifier hs-var">crossAttentionBias</span></a></span><span>
</span><span id="line-756"></span><span>                         </span><span class="hs-special">)</span><span>
</span><span id="line-757"></span><span>                 </span><span class="hs-special">)</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span>
</span><span id="line-758"></span><span>
</span><span id="line-759"></span><span class="hs-comment">-- | 'HasForward' instance for @TransformerDecoder numLayers 'MBART@.</span><span>
</span><span id="line-760"></span><span class="hs-comment">--</span><span>
</span><span id="line-761"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-762"></span><span class="hs-comment">-- &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;  &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;  &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;  &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;  &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;</span><span>
</span><span id="line-763"></span><span class="hs-comment">-- &#9474; decoderInput &#9474;  &#9474; decoderPos &#9474;  &#9474; encoderOutput &#9474;  &#9474; decoderAttentionMask &#9474;  &#9474; crossAttentionMask &#9474;</span><span>
</span><span id="line-764"></span><span class="hs-comment">-- &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;  &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;  &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;  &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;  &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-765"></span><span class="hs-comment">--        &#9474;                 &#9474;                &#9474;                     &#9474;                         &#9474;</span><span>
</span><span id="line-766"></span><span class="hs-comment">--        &#9474;                 &#9660;                &#9474;                     &#9474;                         &#9474;</span><span>
</span><span id="line-767"></span><span class="hs-comment">--        &#9474;             tdPosEnc             &#9474;                     &#9474;                         &#9474;</span><span>
</span><span id="line-768"></span><span class="hs-comment">--        &#9474;                 &#9474;                &#9474;                     &#9474;                         &#9474;</span><span>
</span><span id="line-769"></span><span class="hs-comment">--        &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9658;add&#9668;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;                &#9474;                     &#9474;                         &#9474;</span><span>
</span><span id="line-770"></span><span class="hs-comment">--                 &#9474;                         &#9474;                     &#9474;                         &#9474;</span><span>
</span><span id="line-771"></span><span class="hs-comment">--                 &#9660;                         &#9474;                     &#9474;                         &#9474;</span><span>
</span><span id="line-772"></span><span class="hs-comment">--          tdEmbedLayerNorm                 &#9474;                     &#9474;                         &#9474;</span><span>
</span><span id="line-773"></span><span class="hs-comment">--                 &#9660;                         &#9474;                     &#9660;                         &#9660;</span><span>
</span><span id="line-774"></span><span class="hs-comment">--             tdDropout                     &#9474;                 unsqueeze                 unsqueeze</span><span>
</span><span id="line-775"></span><span class="hs-comment">--                 &#9660;                         &#9474;                     &#9474;                         &#9474;</span><span>
</span><span id="line-776"></span><span class="hs-comment">--              tdStack&#9668;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;&#9668;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;&#9668;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-777"></span><span class="hs-comment">--                 &#9660;</span><span>
</span><span id="line-778"></span><span class="hs-comment">--            tdLayerNorm</span><span>
</span><span id="line-779"></span><span class="hs-comment">--                 &#9474;</span><span>
</span><span id="line-780"></span><span class="hs-comment">--                 &#9660;</span><span>
</span><span id="line-781"></span><span class="hs-comment">--            &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;</span><span>
</span><span id="line-782"></span><span class="hs-comment">--            &#9474; output &#9474;</span><span>
</span><span id="line-783"></span><span class="hs-comment">--            &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-784"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-785"></span><span>
</span><span id="line-786"></span><span class="hs-comment">-- | 'HasForward' instance for @TransformerDecoder numLayers 'Pegasus@.</span><span>
</span><span id="line-787"></span><span class="hs-comment">--</span><span>
</span><span id="line-788"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-789"></span><span class="hs-comment">-- &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;  &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;  &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;  &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;  &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;</span><span>
</span><span id="line-790"></span><span class="hs-comment">-- &#9474; decoderInput &#9474;  &#9474; decoderPos &#9474;  &#9474; encoderOutput &#9474;  &#9474; decoderAttentionMask &#9474;  &#9474; crossAttentionMask &#9474;</span><span>
</span><span id="line-791"></span><span class="hs-comment">-- &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;  &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;  &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;  &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;  &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-792"></span><span class="hs-comment">--        &#9474;                 &#9474;                &#9474;                     &#9474;                         &#9474;</span><span>
</span><span id="line-793"></span><span class="hs-comment">--        &#9474;                 &#9660;                &#9474;                     &#9474;                         &#9474;</span><span>
</span><span id="line-794"></span><span class="hs-comment">--        &#9474;             tdPosEnc             &#9474;                     &#9474;                         &#9474;</span><span>
</span><span id="line-795"></span><span class="hs-comment">--        &#9474;                 &#9474;                &#9474;                     &#9474;                         &#9474;</span><span>
</span><span id="line-796"></span><span class="hs-comment">--        &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9658;add&#9668;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;                &#9474;                     &#9474;                         &#9474;</span><span>
</span><span id="line-797"></span><span class="hs-comment">--                 &#9474;                         &#9474;                     &#9474;                         &#9474;</span><span>
</span><span id="line-798"></span><span class="hs-comment">--                 &#9660;                         &#9474;                     &#9660;                         &#9660;</span><span>
</span><span id="line-799"></span><span class="hs-comment">--             tdDropout                     &#9474;                 unsqueeze                 unsqueeze</span><span>
</span><span id="line-800"></span><span class="hs-comment">--                 &#9660;                         &#9474;                     &#9474;                         &#9474;</span><span>
</span><span id="line-801"></span><span class="hs-comment">--              tdStack&#9668;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;&#9668;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;&#9668;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-802"></span><span class="hs-comment">--                 &#9660;</span><span>
</span><span id="line-803"></span><span class="hs-comment">--            tdLayerNorm</span><span>
</span><span id="line-804"></span><span class="hs-comment">--                 &#9474;</span><span>
</span><span id="line-805"></span><span class="hs-comment">--                 &#9660;</span><span>
</span><span id="line-806"></span><span class="hs-comment">--            &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;</span><span>
</span><span id="line-807"></span><span class="hs-comment">--            &#9474; output &#9474;</span><span>
</span><span id="line-808"></span><span class="hs-comment">--            &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-809"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-810"></span><span id="local-6989586621679775357"><span id="local-6989586621679775358"><span id="local-6989586621679775359"><span id="local-6989586621679775360"><span id="local-6989586621679775361"><span id="local-6989586621679775362"><span id="local-6989586621679775363"><span id="local-6989586621679775364"><span id="local-6989586621679775365"><span id="local-6989586621679775366"><span id="local-6989586621679775367"><span id="local-6989586621679775368"><span id="local-6989586621679775369"><span id="local-6989586621679775370"><span id="local-6989586621679775371"><span id="local-6989586621679775372"><span id="local-6989586621679775373"><span id="local-6989586621679775374"><span id="local-6989586621679775375"><span id="local-6989586621679775376"><span id="local-6989586621679775377"><span id="local-6989586621679775378"><span id="local-6989586621679775379"><span id="local-6989586621679775380"><span id="local-6989586621679775381"><span id="local-6989586621679775382"><span id="local-6989586621679775383"><span id="local-6989586621679775384"><span id="local-6989586621679775385"><span id="local-6989586621679775386"><span id="local-6989586621679775387"><span id="local-6989586621679775388"><span id="local-6989586621679775389"><span id="local-6989586621679775390"><span id="local-6989586621679775391"><span id="local-6989586621679775392"><span id="local-6989586621679775393"><span id="local-6989586621679775394"><span id="local-6989586621679775395"><span class="hs-keyword">instance</span><span>
</span><span id="line-811"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-812"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TDDropoutF"><span class="hs-identifier hs-type">TDDropoutF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#Pegasus"><span class="hs-identifier hs-type">Pegasus</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775395"><span class="hs-identifier hs-type">dropoutP</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-813"></span><span>      </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-814"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679775394"><span class="hs-identifier hs-type">decoderInputGradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775393"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775392"><span class="hs-identifier hs-type">decoderPosGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-815"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679775391"><span class="hs-identifier hs-type">decoderInputLayout</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Dense"><span class="hs-identifier hs-type">Dense</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775390"><span class="hs-identifier hs-type">decoderPosLayout</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-816"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679775389"><span class="hs-identifier hs-type">decoderInputDevice</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775388"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775387"><span class="hs-identifier hs-type">decoderPosDevice</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-817"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679775386"><span class="hs-identifier hs-type">decoderInputDataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Seq"><span class="hs-identifier hs-type">Seq</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679775385"><span class="hs-identifier hs-type">decoderPosDataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#Int64"><span class="hs-identifier hs-type">Int64</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679775384"><span class="hs-identifier hs-type">dataType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-818"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#BroadcastShapesF"><span class="hs-identifier hs-type">BroadcastShapesF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775383"><span class="hs-identifier hs-type">decoderInputShape</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Functional.Sparse.html#EmbeddingF"><span class="hs-identifier hs-type">EmbeddingF</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679775382"><span class="hs-identifier hs-type">posEncDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679775381"><span class="hs-identifier hs-type">decoderInputEmbedDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679775380"><span class="hs-identifier hs-type">decoderPosShape</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-819"></span><span>      </span><span class="hs-special">)</span><span>
</span><span id="line-820"></span><span>      </span><span class="annot"><a href="#local-6989586621679775379"><span class="hs-identifier hs-type">generator</span></a></span><span>
</span><span id="line-821"></span><span>      </span><span class="annot"><a href="#local-6989586621679775378"><span class="hs-identifier hs-type">dropoutOutput</span></a></span><span>
</span><span id="line-822"></span><span>      </span><span class="annot"><a href="#local-6989586621679775377"><span class="hs-identifier hs-type">dropoutGeneratorOutput</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-823"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-824"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TDStackF"><span class="hs-identifier hs-type">TDStackF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#Pegasus"><span class="hs-identifier hs-type">Pegasus</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775376"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775393"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775388"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775384"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775375"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775374"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775373"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775381"><span class="hs-identifier hs-type">decoderInputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775372"><span class="hs-identifier hs-type">encoderOutputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775371"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775395"><span class="hs-identifier hs-type">dropoutP</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-825"></span><span>      </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="#local-6989586621679775378"><span class="hs-identifier hs-type">dropoutOutput</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-826"></span><span>        </span><span class="annot"><a href="#local-6989586621679775370"><span class="hs-identifier hs-type">encoderOutput</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-827"></span><span>        </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-828"></span><span>          </span><span class="annot"><a href="#local-6989586621679775369"><span class="hs-identifier hs-type">decoderAttentionMaskGradient</span></a></span><span>
</span><span id="line-829"></span><span>          </span><span class="annot"><a href="#local-6989586621679775368"><span class="hs-identifier hs-type">decoderAttentionMaskLayout</span></a></span><span>
</span><span id="line-830"></span><span>          </span><span class="annot"><a href="#local-6989586621679775367"><span class="hs-identifier hs-type">decoderAttentionMaskDevice</span></a></span><span>
</span><span id="line-831"></span><span>          </span><span class="annot"><a href="#local-6989586621679775366"><span class="hs-identifier hs-type">decoderAttentionMaskDataType</span></a></span><span>
</span><span id="line-832"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#UnsqueezeF"><span class="hs-identifier hs-type">UnsqueezeF</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679775365"><span class="hs-identifier hs-type">decoderAttentionMaskShape</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-833"></span><span>        </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-834"></span><span>          </span><span class="annot"><a href="#local-6989586621679775364"><span class="hs-identifier hs-type">crossAttentionMaskGradient</span></a></span><span>
</span><span id="line-835"></span><span>          </span><span class="annot"><a href="#local-6989586621679775363"><span class="hs-identifier hs-type">crossAttentionMaskLayout</span></a></span><span>
</span><span id="line-836"></span><span>          </span><span class="annot"><a href="#local-6989586621679775362"><span class="hs-identifier hs-type">crossAttentionMaskDevice</span></a></span><span>
</span><span id="line-837"></span><span>          </span><span class="annot"><a href="#local-6989586621679775361"><span class="hs-identifier hs-type">crossAttentionMaskDataType</span></a></span><span>
</span><span id="line-838"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#UnsqueezeF"><span class="hs-identifier hs-type">UnsqueezeF</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679775360"><span class="hs-identifier hs-type">crossAttentionMaskShape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-839"></span><span>      </span><span class="hs-special">)</span><span>
</span><span id="line-840"></span><span>      </span><span class="annot"><a href="#local-6989586621679775377"><span class="hs-identifier hs-type">dropoutGeneratorOutput</span></a></span><span>
</span><span id="line-841"></span><span>      </span><span class="annot"><a href="#local-6989586621679775359"><span class="hs-identifier hs-type">stackOutput</span></a></span><span>
</span><span id="line-842"></span><span>      </span><span class="annot"><a href="#local-6989586621679775358"><span class="hs-identifier hs-type">generatorOutput</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-843"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-844"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TDLayerNormF"><span class="hs-identifier hs-type">TDLayerNormF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#Pegasus"><span class="hs-identifier hs-type">Pegasus</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775393"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775388"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775384"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775381"><span class="hs-identifier hs-type">decoderInputEmbedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-845"></span><span>      </span><span class="annot"><a href="#local-6989586621679775359"><span class="hs-identifier hs-type">stackOutput</span></a></span><span>
</span><span id="line-846"></span><span>      </span><span class="annot"><a href="#local-6989586621679775358"><span class="hs-identifier hs-type">generatorOutput</span></a></span><span>
</span><span id="line-847"></span><span>      </span><span class="annot"><a href="#local-6989586621679775357"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-848"></span><span>      </span><span class="annot"><a href="#local-6989586621679775358"><span class="hs-identifier hs-type">generatorOutput</span></a></span><span>
</span><span id="line-849"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-850"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-851"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TransformerDecoder"><span class="hs-identifier hs-type">TransformerDecoder</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#Pegasus"><span class="hs-identifier hs-type">Pegasus</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775376"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775393"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775388"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775384"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775375"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775374"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775373"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775381"><span class="hs-identifier hs-type">decoderInputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775372"><span class="hs-identifier hs-type">encoderOutputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775371"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775382"><span class="hs-identifier hs-type">posEncDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775395"><span class="hs-identifier hs-type">dropoutP</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-852"></span><span>    </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775394"><span class="hs-identifier hs-type">decoderInputGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775391"><span class="hs-identifier hs-type">decoderInputLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775389"><span class="hs-identifier hs-type">decoderInputDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775386"><span class="hs-identifier hs-type">decoderInputDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775383"><span class="hs-identifier hs-type">decoderInputShape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-853"></span><span>      </span><span class="annot"><a href="#local-6989586621679775370"><span class="hs-identifier hs-type">encoderOutput</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-854"></span><span>      </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775392"><span class="hs-identifier hs-type">decoderPosGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775390"><span class="hs-identifier hs-type">decoderPosLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775387"><span class="hs-identifier hs-type">decoderPosDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775385"><span class="hs-identifier hs-type">decoderPosDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775380"><span class="hs-identifier hs-type">decoderPosShape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-855"></span><span>      </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775369"><span class="hs-identifier hs-type">decoderAttentionMaskGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775368"><span class="hs-identifier hs-type">decoderAttentionMaskLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775367"><span class="hs-identifier hs-type">decoderAttentionMaskDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775366"><span class="hs-identifier hs-type">decoderAttentionMaskDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775365"><span class="hs-identifier hs-type">decoderAttentionMaskShape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-856"></span><span>      </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775364"><span class="hs-identifier hs-type">crossAttentionMaskGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775363"><span class="hs-identifier hs-type">crossAttentionMaskLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775362"><span class="hs-identifier hs-type">crossAttentionMaskDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775361"><span class="hs-identifier hs-type">crossAttentionMaskDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679775360"><span class="hs-identifier hs-type">crossAttentionMaskShape</span></a></span><span>
</span><span id="line-857"></span><span>    </span><span class="hs-special">)</span><span>
</span><span id="line-858"></span><span>    </span><span class="annot"><a href="#local-6989586621679775379"><span class="hs-identifier hs-type">generator</span></a></span><span>
</span><span id="line-859"></span><span>    </span><span class="annot"><a href="#local-6989586621679775357"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-860"></span><span>    </span><span class="annot"><a href="#local-6989586621679775358"><span class="hs-identifier hs-type">generatorOutput</span></a></span><span>
</span><span id="line-861"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-862"></span><span>  </span><span id="local-6989586621679775355"><span class="annot"><span class="annottext">forward :: TransformerDecoder
  'Pegasus
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  decoderInputEmbedDim
  encoderOutputEmbedDim
  ffnDim
  posEncDim
  dropoutP
-&gt; (Tensor
      decoderInputGradient
      decoderInputLayout
      decoderInputDevice
      decoderInputDataType
      decoderInputShape,
    encoderOutput,
    Tensor
      decoderPosGradient
      decoderPosLayout
      decoderPosDevice
      decoderPosDataType
      decoderPosShape,
    Tensor
      decoderAttentionMaskGradient
      decoderAttentionMaskLayout
      decoderAttentionMaskDevice
      decoderAttentionMaskDataType
      decoderAttentionMaskShape,
    Tensor
      crossAttentionMaskGradient
      crossAttentionMaskLayout
      crossAttentionMaskDevice
      crossAttentionMaskDataType
      crossAttentionMaskShape)
-&gt; generator
-&gt; m (output, generatorOutput)
</span><a href="#local-6989586621679775355"><span class="hs-identifier hs-var hs-var hs-var hs-var">forward</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TransformerDecoder"><span class="hs-identifier hs-type">TransformerDecoder</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#GTransformerDecoder"><span class="hs-identifier hs-type">GTransformerDecoder</span></a></span><span> </span><span class="hs-special">{</span><span id="local-6989586621679775350"><span id="local-6989586621679775351"><span id="local-6989586621679775352"><span id="local-6989586621679775353"><span id="local-6989586621679775354"><span class="annot"><span class="annottext">TDPosEncF
  'Pegasus
  gradient
  device
  dataType
  headDim
  decoderInputEmbedDim
  posEncDim
TDDropoutF 'Pegasus dropoutP
TDLayerNormF 'Pegasus gradient device dataType decoderInputEmbedDim
TDEmbedLayerNormF
  'Pegasus gradient device dataType decoderInputEmbedDim
TDStackF
  'Pegasus
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  decoderInputEmbedDim
  encoderOutputEmbedDim
  ffnDim
  dropoutP
tdPosEnc :: TDPosEncF
  'Pegasus
  gradient
  device
  dataType
  headDim
  decoderInputEmbedDim
  posEncDim
tdDropout :: TDDropoutF 'Pegasus dropoutP
tdLayerNorm :: TDLayerNormF 'Pegasus gradient device dataType decoderInputEmbedDim
tdEmbedLayerNorm :: TDEmbedLayerNormF
  'Pegasus gradient device dataType decoderInputEmbedDim
tdStack :: TDStackF
  'Pegasus
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  decoderInputEmbedDim
  encoderOutputEmbedDim
  ffnDim
  dropoutP
tdPosEnc :: forall stack embedLayerNorm layerNorm dropout posEnc.
GTransformerDecoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; posEnc
tdDropout :: forall stack embedLayerNorm layerNorm dropout posEnc.
GTransformerDecoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; dropout
tdLayerNorm :: forall stack embedLayerNorm layerNorm dropout posEnc.
GTransformerDecoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; layerNorm
tdEmbedLayerNorm :: forall stack embedLayerNorm layerNorm dropout posEnc.
GTransformerDecoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; embedLayerNorm
tdStack :: forall stack embedLayerNorm layerNorm dropout posEnc.
GTransformerDecoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; stack
</span><a href="#local-6989586621679775350"><span class="hs-glyph hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">..</span></a></span></span></span></span></span></span><span class="hs-special">}</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679775349"><span class="annot"><span class="annottext">Tensor
  decoderInputGradient
  decoderInputLayout
  decoderInputDevice
  decoderInputDataType
  decoderInputShape
</span><a href="#local-6989586621679775349"><span class="hs-identifier hs-var">decoderInput</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679775348"><span class="annot"><span class="annottext">encoderOutput
</span><a href="#local-6989586621679775348"><span class="hs-identifier hs-var">encoderOutput</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679775347"><span class="annot"><span class="annottext">Tensor
  decoderPosGradient
  decoderPosLayout
  decoderPosDevice
  decoderPosDataType
  decoderPosShape
</span><a href="#local-6989586621679775347"><span class="hs-identifier hs-var">decoderPos</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679775346"><span class="annot"><span class="annottext">Tensor
  decoderAttentionMaskGradient
  decoderAttentionMaskLayout
  decoderAttentionMaskDevice
  decoderAttentionMaskDataType
  decoderAttentionMaskShape
</span><a href="#local-6989586621679775346"><span class="hs-identifier hs-var">decoderAttentionMask</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679775345"><span class="annot"><span class="annottext">Tensor
  crossAttentionMaskGradient
  crossAttentionMaskLayout
  crossAttentionMaskDevice
  crossAttentionMaskDataType
  crossAttentionMaskShape
</span><a href="#local-6989586621679775345"><span class="hs-identifier hs-var">crossAttentionMask</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-863"></span><span>    </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679775344"><span class="annot"><span class="annottext">decoderAttentionBias :: Tensor
  decoderAttentionMaskGradient
  decoderAttentionMaskLayout
  decoderAttentionMaskDevice
  decoderAttentionMaskDataType
  (UnsqueezeF ('SelectDim ('ByIndex 1)) decoderAttentionMaskShape)
</span><a href="#local-6989586621679775344"><span class="hs-identifier hs-var hs-var">decoderAttentionBias</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor
  decoderAttentionMaskGradient
  decoderAttentionMaskLayout
  decoderAttentionMaskDevice
  decoderAttentionMaskDataType
  decoderAttentionMaskShape
-&gt; Tensor
     decoderAttentionMaskGradient
     decoderAttentionMaskLayout
     decoderAttentionMaskDevice
     decoderAttentionMaskDataType
     (UnsqueezeF ('SelectDim ('ByIndex 1)) decoderAttentionMaskShape)
forall (selectDim :: SelectDim (By Symbol Nat))
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]).
(shape' ~ UnsqueezeF selectDim shape, SingI selectDim) =&gt;
Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape'
</span><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#unsqueeze"><span class="hs-identifier hs-var">unsqueeze</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
  decoderAttentionMaskGradient
  decoderAttentionMaskLayout
  decoderAttentionMaskDevice
  decoderAttentionMaskDataType
  decoderAttentionMaskShape
</span><a href="#local-6989586621679775346"><span class="hs-identifier hs-var">decoderAttentionMask</span></a></span><span>
</span><span id="line-864"></span><span>        </span><span id="local-6989586621679775343"><span class="annot"><span class="annottext">crossAttentionBias :: Tensor
  crossAttentionMaskGradient
  crossAttentionMaskLayout
  crossAttentionMaskDevice
  crossAttentionMaskDataType
  (UnsqueezeF ('SelectDim ('ByIndex 1)) crossAttentionMaskShape)
</span><a href="#local-6989586621679775343"><span class="hs-identifier hs-var hs-var">crossAttentionBias</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor
  crossAttentionMaskGradient
  crossAttentionMaskLayout
  crossAttentionMaskDevice
  crossAttentionMaskDataType
  crossAttentionMaskShape
-&gt; Tensor
     crossAttentionMaskGradient
     crossAttentionMaskLayout
     crossAttentionMaskDevice
     crossAttentionMaskDataType
     (UnsqueezeF ('SelectDim ('ByIndex 1)) crossAttentionMaskShape)
forall (selectDim :: SelectDim (By Symbol Nat))
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]).
(shape' ~ UnsqueezeF selectDim shape, SingI selectDim) =&gt;
Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape'
</span><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#unsqueeze"><span class="hs-identifier hs-var">unsqueeze</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
  crossAttentionMaskGradient
  crossAttentionMaskLayout
  crossAttentionMaskDevice
  crossAttentionMaskDataType
  crossAttentionMaskShape
</span><a href="#local-6989586621679775345"><span class="hs-identifier hs-var">crossAttentionMask</span></a></span><span>
</span><span id="line-865"></span><span>     </span><span class="hs-keyword">in</span><span> </span><span class="annot"><span class="annottext">IxStateT m generator generatorOutput output
-&gt; generator -&gt; m (output, generatorOutput)
forall (m :: * -&gt; *) i j a. IxStateT m i j a -&gt; i -&gt; m (a, j)
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var hs-var">runIxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">(IxStateT m generator generatorOutput output
 -&gt; generator -&gt; m (output, generatorOutput))
-&gt; IxStateT m generator generatorOutput output
-&gt; generator
-&gt; m (output, generatorOutput)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-866"></span><span>          </span><span class="annot"><span class="annottext">Tensor
  decoderPosGradient
  decoderPosLayout
  decoderPosDevice
  decoderPosDataType
  decoderPosShape
-&gt; IxStateT
     m
     generator
     generator
     (Tensor
        decoderPosGradient
        decoderPosLayout
        decoderPosDevice
        decoderPosDataType
        decoderPosShape)
forall k (m :: k -&gt; k -&gt; * -&gt; *) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  decoderPosGradient
  decoderPosLayout
  decoderPosDevice
  decoderPosDataType
  decoderPosShape
</span><a href="#local-6989586621679775347"><span class="hs-identifier hs-var">decoderPos</span></a></span><span>
</span><span id="line-867"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  generator
  generator
  (Tensor
     decoderPosGradient
     decoderPosLayout
     decoderPosDevice
     decoderPosDataType
     decoderPosShape)
-&gt; (Tensor
      decoderPosGradient
      decoderPosLayout
      decoderPosDevice
      decoderPosDataType
      decoderPosShape
    -&gt; IxStateT
         m
         generator
         generator
         (Tensor
            (Or (Gradient RequiresGradient) gradient decoderPosGradient)
            (Unify (Layout LayoutType) ('Layout 'Dense) decoderPosLayout)
            (Unify (Device (DeviceType Nat)) device decoderPosDevice)
            (Seq
               (Unify (DataType DType) decoderPosDataType ('DataType 'Int64))
               dataType)
            (EmbeddingF
               ('Shape '[posEncDim, decoderInputEmbedDim]) decoderPosShape)))
-&gt; IxStateT
     m
     generator
     generator
     (Tensor
        (Or (Gradient RequiresGradient) gradient decoderPosGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) decoderPosLayout)
        (Unify (Device (DeviceType Nat)) device decoderPosDevice)
        (Seq
           (Unify (DataType DType) decoderPosDataType ('DataType 'Int64))
           dataType)
        (EmbeddingF
           ('Shape '[posEncDim, decoderInputEmbedDim]) decoderPosShape))
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(generator
 -&gt; m (Tensor
         (Or (Gradient RequiresGradient) gradient decoderPosGradient)
         (Unify (Layout LayoutType) ('Layout 'Dense) decoderPosLayout)
         (Unify (Device (DeviceType Nat)) device decoderPosDevice)
         (Seq
            (Unify (DataType DType) decoderPosDataType ('DataType 'Int64))
            dataType)
         (EmbeddingF
            ('Shape '[posEncDim, decoderInputEmbedDim]) decoderPosShape),
       generator))
-&gt; IxStateT
     m
     generator
     generator
     (Tensor
        (Or (Gradient RequiresGradient) gradient decoderPosGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) decoderPosLayout)
        (Unify (Device (DeviceType Nat)) device decoderPosDevice)
        (Seq
           (Unify (DataType DType) decoderPosDataType ('DataType 'Int64))
           dataType)
        (EmbeddingF
           ('Shape '[posEncDim, decoderInputEmbedDim]) decoderPosShape))
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((generator
  -&gt; m (Tensor
          (Or (Gradient RequiresGradient) gradient decoderPosGradient)
          (Unify (Layout LayoutType) ('Layout 'Dense) decoderPosLayout)
          (Unify (Device (DeviceType Nat)) device decoderPosDevice)
          (Seq
             (Unify (DataType DType) decoderPosDataType ('DataType 'Int64))
             dataType)
          (EmbeddingF
             ('Shape '[posEncDim, decoderInputEmbedDim]) decoderPosShape),
        generator))
 -&gt; IxStateT
      m
      generator
      generator
      (Tensor
         (Or (Gradient RequiresGradient) gradient decoderPosGradient)
         (Unify (Layout LayoutType) ('Layout 'Dense) decoderPosLayout)
         (Unify (Device (DeviceType Nat)) device decoderPosDevice)
         (Seq
            (Unify (DataType DType) decoderPosDataType ('DataType 'Int64))
            dataType)
         (EmbeddingF
            ('Shape '[posEncDim, decoderInputEmbedDim]) decoderPosShape)))
-&gt; (Tensor
      decoderPosGradient
      decoderPosLayout
      decoderPosDevice
      decoderPosDataType
      decoderPosShape
    -&gt; generator
    -&gt; m (Tensor
            (Or (Gradient RequiresGradient) gradient decoderPosGradient)
            (Unify (Layout LayoutType) ('Layout 'Dense) decoderPosLayout)
            (Unify (Device (DeviceType Nat)) device decoderPosDevice)
            (Seq
               (Unify (DataType DType) decoderPosDataType ('DataType 'Int64))
               dataType)
            (EmbeddingF
               ('Shape '[posEncDim, decoderInputEmbedDim]) decoderPosShape),
          generator))
-&gt; Tensor
     decoderPosGradient
     decoderPosLayout
     decoderPosDevice
     decoderPosDataType
     decoderPosShape
-&gt; IxStateT
     m
     generator
     generator
     (Tensor
        (Or (Gradient RequiresGradient) gradient decoderPosGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) decoderPosLayout)
        (Unify (Device (DeviceType Nat)) device decoderPosDevice)
        (Seq
           (Unify (DataType DType) decoderPosDataType ('DataType 'Int64))
           dataType)
        (EmbeddingF
           ('Shape '[posEncDim, decoderInputEmbedDim]) decoderPosShape))
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Embedding
  gradient
  ('Layout 'Dense)
  device
  dataType
  posEncDim
  decoderInputEmbedDim
  'Nothing
-&gt; Tensor
     decoderPosGradient
     decoderPosLayout
     decoderPosDevice
     decoderPosDataType
     decoderPosShape
-&gt; generator
-&gt; m (Tensor
        (Or (Gradient RequiresGradient) gradient decoderPosGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) decoderPosLayout)
        (Unify (Device (DeviceType Nat)) device decoderPosDevice)
        (Seq
           (Unify (DataType DType) decoderPosDataType ('DataType 'Int64))
           dataType)
        (EmbeddingF
           ('Shape '[posEncDim, decoderInputEmbedDim]) decoderPosShape),
      generator)
forall model input generator output generatorOutput (m :: * -&gt; *).
(HasForward model input generator output generatorOutput,
 MonadThrow m) =&gt;
model -&gt; input -&gt; generator -&gt; m (output, generatorOutput)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">Embedding
  gradient
  ('Layout 'Dense)
  device
  dataType
  posEncDim
  decoderInputEmbedDim
  'Nothing
TDPosEncF
  'Pegasus
  gradient
  device
  dataType
  headDim
  decoderInputEmbedDim
  posEncDim
</span><a href="#local-6989586621679775350"><span class="hs-identifier hs-var">tdPosEnc</span></a></span><span>
</span><span id="line-868"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  generator
  generator
  (Tensor
     (Or (Gradient RequiresGradient) gradient decoderPosGradient)
     (Unify (Layout LayoutType) ('Layout 'Dense) decoderPosLayout)
     (Unify (Device (DeviceType Nat)) device decoderPosDevice)
     (Seq
        (Unify (DataType DType) decoderPosDataType ('DataType 'Int64))
        dataType)
     (EmbeddingF
        ('Shape '[posEncDim, decoderInputEmbedDim]) decoderPosShape))
-&gt; (Tensor
      (Or (Gradient RequiresGradient) gradient decoderPosGradient)
      (Unify (Layout LayoutType) ('Layout 'Dense) decoderPosLayout)
      (Unify (Device (DeviceType Nat)) device decoderPosDevice)
      (Seq
         (Unify (DataType DType) decoderPosDataType ('DataType 'Int64))
         dataType)
      (EmbeddingF
         ('Shape '[posEncDim, decoderInputEmbedDim]) decoderPosShape)
    -&gt; IxStateT
         m
         generator
         generator
         (Tensor
            (Or
               (Gradient RequiresGradient)
               decoderInputGradient
               (Or (Gradient RequiresGradient) gradient decoderPosGradient))
            (Unify
               (Layout LayoutType)
               decoderInputLayout
               (Unify (Layout LayoutType) ('Layout 'Dense) decoderPosLayout))
            (Unify
               (Device (DeviceType Nat))
               decoderInputDevice
               (Unify (Device (DeviceType Nat)) device decoderPosDevice))
            (Unify
               (DataType DType)
               decoderInputDataType
               (Seq
                  (Unify (DataType DType) decoderPosDataType ('DataType 'Int64))
                  dataType))
            (BroadcastShapesF
               decoderInputShape
               (EmbeddingF
                  ('Shape '[posEncDim, decoderInputEmbedDim]) decoderPosShape))))
-&gt; IxStateT
     m
     generator
     generator
     (Tensor
        (Or
           (Gradient RequiresGradient)
           decoderInputGradient
           (Or (Gradient RequiresGradient) gradient decoderPosGradient))
        (Unify
           (Layout LayoutType)
           decoderInputLayout
           (Unify (Layout LayoutType) ('Layout 'Dense) decoderPosLayout))
        (Unify
           (Device (DeviceType Nat))
           decoderInputDevice
           (Unify (Device (DeviceType Nat)) device decoderPosDevice))
        (Unify
           (DataType DType)
           decoderInputDataType
           (Seq
              (Unify (DataType DType) decoderPosDataType ('DataType 'Int64))
              dataType))
        (BroadcastShapesF
           decoderInputShape
           (EmbeddingF
              ('Shape '[posEncDim, decoderInputEmbedDim]) decoderPosShape)))
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  (Or
     (Gradient RequiresGradient)
     decoderInputGradient
     (Or (Gradient RequiresGradient) gradient decoderPosGradient))
  (Unify
     (Layout LayoutType)
     decoderInputLayout
     (Unify (Layout LayoutType) ('Layout 'Dense) decoderPosLayout))
  (Unify
     (Device (DeviceType Nat))
     decoderInputDevice
     (Unify (Device (DeviceType Nat)) device decoderPosDevice))
  (Unify
     (DataType DType)
     decoderInputDataType
     (Seq
        (Unify (DataType DType) decoderPosDataType ('DataType 'Int64))
        dataType))
  (BroadcastShapesF
     decoderInputShape
     (EmbeddingF
        ('Shape '[posEncDim, decoderInputEmbedDim]) decoderPosShape))
-&gt; IxStateT
     m
     generator
     generator
     (Tensor
        (Or
           (Gradient RequiresGradient)
           decoderInputGradient
           (Or (Gradient RequiresGradient) gradient decoderPosGradient))
        (Unify
           (Layout LayoutType)
           decoderInputLayout
           (Unify (Layout LayoutType) ('Layout 'Dense) decoderPosLayout))
        (Unify
           (Device (DeviceType Nat))
           decoderInputDevice
           (Unify (Device (DeviceType Nat)) device decoderPosDevice))
        (Unify
           (DataType DType)
           decoderInputDataType
           (Seq
              (Unify (DataType DType) decoderPosDataType ('DataType 'Int64))
              dataType))
        (BroadcastShapesF
           decoderInputShape
           (EmbeddingF
              ('Shape '[posEncDim, decoderInputEmbedDim]) decoderPosShape)))
forall k (m :: k -&gt; k -&gt; * -&gt; *) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">(Tensor
   (Or
      (Gradient RequiresGradient)
      decoderInputGradient
      (Or (Gradient RequiresGradient) gradient decoderPosGradient))
   (Unify
      (Layout LayoutType)
      decoderInputLayout
      (Unify (Layout LayoutType) ('Layout 'Dense) decoderPosLayout))
   (Unify
      (Device (DeviceType Nat))
      decoderInputDevice
      (Unify (Device (DeviceType Nat)) device decoderPosDevice))
   (Unify
      (DataType DType)
      decoderInputDataType
      (Seq
         (Unify (DataType DType) decoderPosDataType ('DataType 'Int64))
         dataType))
   (BroadcastShapesF
      decoderInputShape
      (EmbeddingF
         ('Shape '[posEncDim, decoderInputEmbedDim]) decoderPosShape))
 -&gt; IxStateT
      m
      generator
      generator
      (Tensor
         (Or
            (Gradient RequiresGradient)
            decoderInputGradient
            (Or (Gradient RequiresGradient) gradient decoderPosGradient))
         (Unify
            (Layout LayoutType)
            decoderInputLayout
            (Unify (Layout LayoutType) ('Layout 'Dense) decoderPosLayout))
         (Unify
            (Device (DeviceType Nat))
            decoderInputDevice
            (Unify (Device (DeviceType Nat)) device decoderPosDevice))
         (Unify
            (DataType DType)
            decoderInputDataType
            (Seq
               (Unify (DataType DType) decoderPosDataType ('DataType 'Int64))
               dataType))
         (BroadcastShapesF
            decoderInputShape
            (EmbeddingF
               ('Shape '[posEncDim, decoderInputEmbedDim]) decoderPosShape))))
-&gt; (Tensor
      (Or (Gradient RequiresGradient) gradient decoderPosGradient)
      (Unify (Layout LayoutType) ('Layout 'Dense) decoderPosLayout)
      (Unify (Device (DeviceType Nat)) device decoderPosDevice)
      (Seq
         (Unify (DataType DType) decoderPosDataType ('DataType 'Int64))
         dataType)
      (EmbeddingF
         ('Shape '[posEncDim, decoderInputEmbedDim]) decoderPosShape)
    -&gt; Tensor
         (Or
            (Gradient RequiresGradient)
            decoderInputGradient
            (Or (Gradient RequiresGradient) gradient decoderPosGradient))
         (Unify
            (Layout LayoutType)
            decoderInputLayout
            (Unify (Layout LayoutType) ('Layout 'Dense) decoderPosLayout))
         (Unify
            (Device (DeviceType Nat))
            decoderInputDevice
            (Unify (Device (DeviceType Nat)) device decoderPosDevice))
         (Unify
            (DataType DType)
            decoderInputDataType
            (Seq
               (Unify (DataType DType) decoderPosDataType ('DataType 'Int64))
               dataType))
         (BroadcastShapesF
            decoderInputShape
            (EmbeddingF
               ('Shape '[posEncDim, decoderInputEmbedDim]) decoderPosShape)))
-&gt; Tensor
     (Or (Gradient RequiresGradient) gradient decoderPosGradient)
     (Unify (Layout LayoutType) ('Layout 'Dense) decoderPosLayout)
     (Unify (Device (DeviceType Nat)) device decoderPosDevice)
     (Seq
        (Unify (DataType DType) decoderPosDataType ('DataType 'Int64))
        dataType)
     (EmbeddingF
        ('Shape '[posEncDim, decoderInputEmbedDim]) decoderPosShape)
-&gt; IxStateT
     m
     generator
     generator
     (Tensor
        (Or
           (Gradient RequiresGradient)
           decoderInputGradient
           (Or (Gradient RequiresGradient) gradient decoderPosGradient))
        (Unify
           (Layout LayoutType)
           decoderInputLayout
           (Unify (Layout LayoutType) ('Layout 'Dense) decoderPosLayout))
        (Unify
           (Device (DeviceType Nat))
           decoderInputDevice
           (Unify (Device (DeviceType Nat)) device decoderPosDevice))
        (Unify
           (DataType DType)
           decoderInputDataType
           (Seq
              (Unify (DataType DType) decoderPosDataType ('DataType 'Int64))
              dataType))
        (BroadcastShapesF
           decoderInputShape
           (EmbeddingF
              ('Shape '[posEncDim, decoderInputEmbedDim]) decoderPosShape)))
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Tensor
  decoderInputGradient
  decoderInputLayout
  decoderInputDevice
  decoderInputDataType
  decoderInputShape
</span><a href="#local-6989586621679775349"><span class="hs-identifier hs-var">decoderInput</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  decoderInputGradient
  decoderInputLayout
  decoderInputDevice
  decoderInputDataType
  decoderInputShape
-&gt; Tensor
     (Or (Gradient RequiresGradient) gradient decoderPosGradient)
     (Unify (Layout LayoutType) ('Layout 'Dense) decoderPosLayout)
     (Unify (Device (DeviceType Nat)) device decoderPosDevice)
     (Seq
        (Unify (DataType DType) decoderPosDataType ('DataType 'Int64))
        dataType)
     (EmbeddingF
        ('Shape '[posEncDim, decoderInputEmbedDim]) decoderPosShape)
-&gt; Tensor
     (decoderInputGradient
      &lt;|&gt; Or (Gradient RequiresGradient) gradient decoderPosGradient)
     (decoderInputLayout
      &lt;+&gt; Unify (Layout LayoutType) ('Layout 'Dense) decoderPosLayout)
     (decoderInputDevice
      &lt;+&gt; Unify (Device (DeviceType Nat)) device decoderPosDevice)
     (decoderInputDataType
      &lt;+&gt; Seq
            (Unify (DataType DType) decoderPosDataType ('DataType 'Int64))
            dataType)
     (BroadcastShapesF
        decoderInputShape
        (EmbeddingF
           ('Shape '[posEncDim, decoderInputEmbedDim]) decoderPosShape))
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (gradient' :: Gradient RequiresGradient)
       (layout' :: Layout LayoutType) (device' :: Device (DeviceType Nat))
       (dataType' :: DataType DType)
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]).
Tensor gradient layout device dataType shape
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; Tensor
     (gradient &lt;|&gt; gradient')
     (layout &lt;+&gt; layout')
     (device &lt;+&gt; device')
     (dataType &lt;+&gt; dataType')
     (BroadcastShapesF shape shape')
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#add"><span class="hs-operator hs-var">`add`</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-869"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  generator
  generator
  (Tensor
     (Or
        (Gradient RequiresGradient)
        decoderInputGradient
        (Or (Gradient RequiresGradient) gradient decoderPosGradient))
     (Unify
        (Layout LayoutType)
        decoderInputLayout
        (Unify (Layout LayoutType) ('Layout 'Dense) decoderPosLayout))
     (Unify
        (Device (DeviceType Nat))
        decoderInputDevice
        (Unify (Device (DeviceType Nat)) device decoderPosDevice))
     (Unify
        (DataType DType)
        decoderInputDataType
        (Seq
           (Unify (DataType DType) decoderPosDataType ('DataType 'Int64))
           dataType))
     (BroadcastShapesF
        decoderInputShape
        (EmbeddingF
           ('Shape '[posEncDim, decoderInputEmbedDim]) decoderPosShape)))
-&gt; (Tensor
      (Or
         (Gradient RequiresGradient)
         decoderInputGradient
         (Or (Gradient RequiresGradient) gradient decoderPosGradient))
      (Unify
         (Layout LayoutType)
         decoderInputLayout
         (Unify (Layout LayoutType) ('Layout 'Dense) decoderPosLayout))
      (Unify
         (Device (DeviceType Nat))
         decoderInputDevice
         (Unify (Device (DeviceType Nat)) device decoderPosDevice))
      (Unify
         (DataType DType)
         decoderInputDataType
         (Seq
            (Unify (DataType DType) decoderPosDataType ('DataType 'Int64))
            dataType))
      (BroadcastShapesF
         decoderInputShape
         (EmbeddingF
            ('Shape '[posEncDim, decoderInputEmbedDim]) decoderPosShape))
    -&gt; IxStateT m generator dropoutGeneratorOutput dropoutOutput)
-&gt; IxStateT m generator dropoutGeneratorOutput dropoutOutput
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(generator -&gt; m (dropoutOutput, dropoutGeneratorOutput))
-&gt; IxStateT m generator dropoutGeneratorOutput dropoutOutput
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((generator -&gt; m (dropoutOutput, dropoutGeneratorOutput))
 -&gt; IxStateT m generator dropoutGeneratorOutput dropoutOutput)
-&gt; (Tensor
      (Or
         (Gradient RequiresGradient)
         decoderInputGradient
         (Or (Gradient RequiresGradient) gradient decoderPosGradient))
      (Unify
         (Layout LayoutType)
         decoderInputLayout
         (Unify (Layout LayoutType) ('Layout 'Dense) decoderPosLayout))
      (Unify
         (Device (DeviceType Nat))
         decoderInputDevice
         (Unify (Device (DeviceType Nat)) device decoderPosDevice))
      (Unify
         (DataType DType)
         decoderInputDataType
         (Seq
            (Unify (DataType DType) decoderPosDataType ('DataType 'Int64))
            dataType))
      (BroadcastShapesF
         decoderInputShape
         (EmbeddingF
            ('Shape '[posEncDim, decoderInputEmbedDim]) decoderPosShape))
    -&gt; generator -&gt; m (dropoutOutput, dropoutGeneratorOutput))
-&gt; Tensor
     (Or
        (Gradient RequiresGradient)
        decoderInputGradient
        (Or (Gradient RequiresGradient) gradient decoderPosGradient))
     (Unify
        (Layout LayoutType)
        decoderInputLayout
        (Unify (Layout LayoutType) ('Layout 'Dense) decoderPosLayout))
     (Unify
        (Device (DeviceType Nat))
        decoderInputDevice
        (Unify (Device (DeviceType Nat)) device decoderPosDevice))
     (Unify
        (DataType DType)
        decoderInputDataType
        (Seq
           (Unify (DataType DType) decoderPosDataType ('DataType 'Int64))
           dataType))
     (BroadcastShapesF
        decoderInputShape
        (EmbeddingF
           ('Shape '[posEncDim, decoderInputEmbedDim]) decoderPosShape))
-&gt; IxStateT m generator dropoutGeneratorOutput dropoutOutput
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Dropout dropoutP
-&gt; Tensor
     (Or
        (Gradient RequiresGradient)
        decoderInputGradient
        (Or (Gradient RequiresGradient) gradient decoderPosGradient))
     (Unify
        (Layout LayoutType)
        decoderInputLayout
        (Unify (Layout LayoutType) ('Layout 'Dense) decoderPosLayout))
     (Unify
        (Device (DeviceType Nat))
        decoderInputDevice
        (Unify (Device (DeviceType Nat)) device decoderPosDevice))
     (Unify
        (DataType DType)
        decoderInputDataType
        (Seq
           (Unify (DataType DType) decoderPosDataType ('DataType 'Int64))
           dataType))
     (BroadcastShapesF
        decoderInputShape
        (EmbeddingF
           ('Shape '[posEncDim, decoderInputEmbedDim]) decoderPosShape))
-&gt; generator
-&gt; m (dropoutOutput, dropoutGeneratorOutput)
forall model input generator output generatorOutput (m :: * -&gt; *).
(HasForward model input generator output generatorOutput,
 MonadThrow m) =&gt;
model -&gt; input -&gt; generator -&gt; m (output, generatorOutput)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">Dropout dropoutP
TDDropoutF 'Pegasus dropoutP
</span><a href="#local-6989586621679775351"><span class="hs-identifier hs-var">tdDropout</span></a></span><span>
</span><span id="line-870"></span><span>            </span><span class="annot"><span class="annottext">IxStateT m generator dropoutGeneratorOutput dropoutOutput
-&gt; (dropoutOutput
    -&gt; IxStateT m dropoutGeneratorOutput generatorOutput stackOutput)
-&gt; IxStateT m generator generatorOutput stackOutput
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="hs-special">(</span><span> </span><span class="hs-glyph">\</span><span id="local-6989586621679775342"><span class="annot"><span class="annottext">dropoutOutput
</span><a href="#local-6989586621679775342"><span class="hs-identifier hs-var">decoderInput'</span></a></span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-871"></span><span>                     </span><span class="annot"><span class="annottext">(dropoutGeneratorOutput -&gt; m (stackOutput, generatorOutput))
-&gt; IxStateT m dropoutGeneratorOutput generatorOutput stackOutput
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((dropoutGeneratorOutput -&gt; m (stackOutput, generatorOutput))
 -&gt; IxStateT m dropoutGeneratorOutput generatorOutput stackOutput)
-&gt; (dropoutGeneratorOutput -&gt; m (stackOutput, generatorOutput))
-&gt; IxStateT m dropoutGeneratorOutput generatorOutput stackOutput
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-872"></span><span>                       </span><span class="annot"><span class="annottext">TransformerDecoderStack
  'Pegasus
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  decoderInputEmbedDim
  encoderOutputEmbedDim
  ffnDim
  dropoutP
-&gt; (dropoutOutput, encoderOutput,
    Tensor
      decoderAttentionMaskGradient
      decoderAttentionMaskLayout
      decoderAttentionMaskDevice
      decoderAttentionMaskDataType
      (UnsqueezeF ('SelectDim ('ByIndex 1)) decoderAttentionMaskShape),
    Tensor
      crossAttentionMaskGradient
      crossAttentionMaskLayout
      crossAttentionMaskDevice
      crossAttentionMaskDataType
      (UnsqueezeF ('SelectDim ('ByIndex 1)) crossAttentionMaskShape))
-&gt; dropoutGeneratorOutput
-&gt; m (stackOutput, generatorOutput)
forall model input generator output generatorOutput (m :: * -&gt; *).
(HasForward model input generator output generatorOutput,
 MonadThrow m) =&gt;
model -&gt; input -&gt; generator -&gt; m (output, generatorOutput)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span>
</span><span id="line-873"></span><span>                         </span><span class="annot"><span class="annottext">TransformerDecoderStack
  'Pegasus
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  decoderInputEmbedDim
  encoderOutputEmbedDim
  ffnDim
  dropoutP
TDStackF
  'Pegasus
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  decoderInputEmbedDim
  encoderOutputEmbedDim
  ffnDim
  dropoutP
</span><a href="#local-6989586621679775354"><span class="hs-identifier hs-var">tdStack</span></a></span><span>
</span><span id="line-874"></span><span>                         </span><span class="hs-special">(</span><span> </span><span class="annot"><span class="annottext">dropoutOutput
</span><a href="#local-6989586621679775342"><span class="hs-identifier hs-var">decoderInput'</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-875"></span><span>                           </span><span class="annot"><span class="annottext">encoderOutput
</span><a href="#local-6989586621679775348"><span class="hs-identifier hs-var">encoderOutput</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-876"></span><span>                           </span><span class="annot"><span class="annottext">Tensor
  decoderAttentionMaskGradient
  decoderAttentionMaskLayout
  decoderAttentionMaskDevice
  decoderAttentionMaskDataType
  (UnsqueezeF ('SelectDim ('ByIndex 1)) decoderAttentionMaskShape)
</span><a href="#local-6989586621679775344"><span class="hs-identifier hs-var">decoderAttentionBias</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-877"></span><span>                           </span><span class="annot"><span class="annottext">Tensor
  crossAttentionMaskGradient
  crossAttentionMaskLayout
  crossAttentionMaskDevice
  crossAttentionMaskDataType
  (UnsqueezeF ('SelectDim ('ByIndex 1)) crossAttentionMaskShape)
</span><a href="#local-6989586621679775343"><span class="hs-identifier hs-var">crossAttentionBias</span></a></span><span>
</span><span id="line-878"></span><span>                         </span><span class="hs-special">)</span><span>
</span><span id="line-879"></span><span>                 </span><span class="hs-special">)</span><span>
</span><span id="line-880"></span><span>            </span><span class="annot"><span class="annottext">IxStateT m generator generatorOutput stackOutput
-&gt; (stackOutput
    -&gt; IxStateT m generatorOutput generatorOutput output)
-&gt; IxStateT m generator generatorOutput output
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(generatorOutput -&gt; m (output, generatorOutput))
-&gt; IxStateT m generatorOutput generatorOutput output
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((generatorOutput -&gt; m (output, generatorOutput))
 -&gt; IxStateT m generatorOutput generatorOutput output)
-&gt; (stackOutput -&gt; generatorOutput -&gt; m (output, generatorOutput))
-&gt; stackOutput
-&gt; IxStateT m generatorOutput generatorOutput output
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">LayerNorm
  'WithBias gradient device dataType ('Shape '[decoderInputEmbedDim])
-&gt; stackOutput -&gt; generatorOutput -&gt; m (output, generatorOutput)
forall model input generator output generatorOutput (m :: * -&gt; *).
(HasForward model input generator output generatorOutput,
 MonadThrow m) =&gt;
model -&gt; input -&gt; generator -&gt; m (output, generatorOutput)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">LayerNorm
  'WithBias gradient device dataType ('Shape '[decoderInputEmbedDim])
TDLayerNormF 'Pegasus gradient device dataType decoderInputEmbedDim
</span><a href="#local-6989586621679775352"><span class="hs-identifier hs-var">tdLayerNorm</span></a></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></pre></body></html>