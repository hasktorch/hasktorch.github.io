<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><link rel="stylesheet" type="text/css" href="style.css" /><script type="text/javascript" src="highlight.js"></script></head><body><pre><span class="hs-pragma">{-# LANGUAGE ConstraintKinds #-}</span><span>
</span><span id="line-2"></span><span class="hs-pragma">{-# LANGUAGE DataKinds #-}</span><span>
</span><span id="line-3"></span><span class="hs-pragma">{-# LANGUAGE FlexibleContexts #-}</span><span>
</span><span id="line-4"></span><span class="hs-pragma">{-# LANGUAGE FlexibleInstances #-}</span><span>
</span><span id="line-5"></span><span class="hs-pragma">{-# LANGUAGE GADTs #-}</span><span>
</span><span id="line-6"></span><span class="hs-pragma">{-# LANGUAGE MultiParamTypeClasses #-}</span><span>
</span><span id="line-7"></span><span class="hs-pragma">{-# LANGUAGE PartialTypeSignatures #-}</span><span>
</span><span id="line-8"></span><span class="hs-pragma">{-# LANGUAGE PatternSynonyms #-}</span><span>
</span><span id="line-9"></span><span class="hs-pragma">{-# LANGUAGE RecordWildCards #-}</span><span>
</span><span id="line-10"></span><span class="hs-pragma">{-# LANGUAGE ScopedTypeVariables #-}</span><span>
</span><span id="line-11"></span><span class="hs-pragma">{-# LANGUAGE TypeApplications #-}</span><span>
</span><span id="line-12"></span><span class="hs-pragma">{-# LANGUAGE TypeFamilies #-}</span><span>
</span><span id="line-13"></span><span class="hs-pragma">{-# LANGUAGE TypeOperators #-}</span><span>
</span><span id="line-14"></span><span class="hs-pragma">{-# LANGUAGE UndecidableInstances #-}</span><span>
</span><span id="line-15"></span><span class="hs-pragma">{-# OPTIONS_GHC -fplugin TypeLevel.Rewrite
                -fplugin-opt=TypeLevel.Rewrite:Torch.GraduallyTyped.Unify.UnifyRightAssociativeL
                -fplugin-opt=TypeLevel.Rewrite:Torch.GraduallyTyped.Unify.OrRightAssociativeL #-}</span><span>
</span><span id="line-18"></span><span class="hs-pragma">{-# OPTIONS_GHC -v2 -Wall #-}</span><span>
</span><span id="line-19"></span><span>
</span><span id="line-20"></span><span class="hs-keyword">module</span><span> </span><span class="hs-identifier">Torch.GraduallyTyped.NN.Transformer.Decoder</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-21"></span><span>
</span><span id="line-22"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier">Control.Monad.Indexed</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier">IxPointed</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier">ireturn</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator">(&gt;&gt;&gt;=)</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-23"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier">Control.Monad.Indexed.State</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier">IxState</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier">IxStateT</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-24"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier">Control.Monad.Indexed.Trans</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier">IxMonadTrans</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier">ilift</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-25"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier">Data.Functor.Indexed</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator">(&lt;&lt;$&gt;&gt;)</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator">(&lt;&lt;*&gt;&gt;)</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-26"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">Data.Kind</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier">Type</span></span><span class="hs-special">)</span><span>
</span><span id="line-27"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">Data.Singletons</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">SingI</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">sing</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-28"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">Data.Singletons.Prelude.List</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">SList</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">SNil</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-29"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">Data.Singletons.Prelude.Maybe</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">SMaybe</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">SNothing</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-30"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">Data.Singletons.TypeLits</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">SNat</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">SNat</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-31"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">GHC.TypeLits</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier">KnownNat</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier">Nat</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier">Symbol</span></span><span class="hs-special">)</span><span>
</span><span id="line-32"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html"><span class="hs-identifier">Torch.GraduallyTyped.DType</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier">DType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier">DataType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#SDType"><span class="hs-identifier">SDType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier">SDataType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-33"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html"><span class="hs-identifier">Torch.GraduallyTyped.Device</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier">Device</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#DeviceType"><span class="hs-identifier">DeviceType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#SDevice"><span class="hs-identifier">SDevice</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#SDeviceType"><span class="hs-identifier">SDeviceType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-34"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html"><span class="hs-identifier">Torch.GraduallyTyped.Layout</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier">Layout</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#LayoutType"><span class="hs-identifier">LayoutType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#SLayout"><span class="hs-identifier">SLayout</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#SLayoutType"><span class="hs-identifier">SLayoutType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-35"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html"><span class="hs-identifier">Torch.GraduallyTyped.NN.Class</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier">HasForward</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier">HasInitialize</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasStateDict"><span class="hs-identifier">HasStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier">ModelSpec</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-36"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Dropout.html"><span class="hs-identifier">Torch.GraduallyTyped.NN.Dropout</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Dropout.html#Dropout"><span class="hs-identifier">Dropout</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-37"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Functional.Sparse.html"><span class="hs-identifier">Torch.GraduallyTyped.NN.Functional.Sparse</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Functional.Sparse.html#EmbeddingF"><span class="hs-identifier">EmbeddingF</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-38"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Normalization.html"><span class="hs-identifier">Torch.GraduallyTyped.NN.Normalization</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Normalization.html#LayerNorm"><span class="hs-identifier">LayerNorm</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Normalization.html#LayerNormSpec"><span class="hs-identifier">LayerNormSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-39"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Sparse.html"><span class="hs-identifier">Torch.GraduallyTyped.NN.Sparse</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Sparse.html#Embedding"><span class="hs-identifier">Embedding</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Sparse.html#EmbeddingSpec"><span class="hs-identifier">EmbeddingSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-40"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.DecoderStack.html"><span class="hs-identifier">Torch.GraduallyTyped.NN.Transformer.DecoderStack</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.DecoderStack.html#TransformerDecoderStack"><span class="hs-identifier">TransformerDecoderStack</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.DecoderStack.html#TransformerDecoderStackSpec"><span class="hs-identifier">TransformerDecoderStackSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-41"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html"><span class="hs-identifier">Torch.GraduallyTyped.NN.Transformer.Type</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#STransformerStyle"><span class="hs-identifier">STransformerStyle</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerStyle"><span class="hs-identifier">TransformerStyle</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-42"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Type.html"><span class="hs-identifier">Torch.GraduallyTyped.NN.Type</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Type.html#HasBias"><span class="hs-identifier">HasBias</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Type.html#SHasBias"><span class="hs-identifier">SHasBias</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Type.html#SWithBias"><span class="hs-identifier">SWithBias</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Type.html#SWithoutBias"><span class="hs-identifier">SWithoutBias</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-43"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html"><span class="hs-identifier">Torch.GraduallyTyped.Prelude</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Seq"><span class="hs-identifier">Seq</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-44"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Random.html"><span class="hs-identifier">Torch.GraduallyTyped.Random</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Random.html#sGeneratorToDevice"><span class="hs-identifier">sGeneratorToDevice</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Random.html#sMkGenerator"><span class="hs-identifier">sMkGenerator</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-45"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html"><span class="hs-identifier">Torch.GraduallyTyped.RequiresGradient</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier">Gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#RequiresGradient"><span class="hs-identifier">RequiresGradient</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier">SGradient</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#SRequiresGradient"><span class="hs-identifier">SRequiresGradient</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-46"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.html"><span class="hs-identifier">Torch.GraduallyTyped.Shape</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier">Name</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier">SDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier">SName</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier">SShape</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier">SSize</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier">Shape</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier">Size</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-47"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html"><span class="hs-identifier">Torch.GraduallyTyped.Shape.Class</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#BroadcastShapesF"><span class="hs-identifier">BroadcastShapesF</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-48"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html"><span class="hs-identifier">Torch.GraduallyTyped.Shape.Type</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#By"><span class="hs-identifier">By</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="hs-keyword">pattern</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator">(:&amp;:)</span></a></span><span class="hs-special">,</span><span> </span><span class="hs-keyword">pattern</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator">(:|:)</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-49"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Creation.html"><span class="hs-identifier">Torch.GraduallyTyped.Tensor.Creation</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Creation.html#sOnes"><span class="hs-identifier">sOnes</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-50"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html"><span class="hs-identifier">Torch.GraduallyTyped.Tensor.IndexingSlicingJoining</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#TransposeF"><span class="hs-identifier">TransposeF</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#UnsqueezeF"><span class="hs-identifier">UnsqueezeF</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#transpose"><span class="hs-identifier">transpose</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#unsqueeze"><span class="hs-identifier">unsqueeze</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-51"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html"><span class="hs-identifier">Torch.GraduallyTyped.Tensor.MathOperations.Pointwise</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#add"><span class="hs-identifier">add</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-52"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html"><span class="hs-identifier">Torch.GraduallyTyped.Tensor.Type</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier">Tensor</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorSpec"><span class="hs-identifier">TensorSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-53"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html"><span class="hs-identifier">Torch.GraduallyTyped.Unify</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-keyword">type</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator">(&lt;+&gt;)</span></a></span><span class="hs-special">,</span><span> </span><span class="hs-keyword">type</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator">(&lt;|&gt;)</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-54"></span><span>
</span><span id="line-55"></span><span class="hs-comment">-- | Generic transformer decoder.</span><span>
</span><span id="line-56"></span><span class="hs-comment">-- Needs to be specialized to a given transformer type, e.g. 'T5'.</span><span>
</span><span id="line-57"></span><span class="hs-comment">-- See 'TransformerDecoder'.</span><span>
</span><span id="line-58"></span><span class="hs-keyword">data</span><span>
</span><span id="line-59"></span><span>  </span><span id="GTransformerDecoder"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#GTransformerDecoder"><span class="hs-identifier hs-var">GTransformerDecoder</span></a></span></span><span>
</span><span id="line-60"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679808831"><span class="annot"><a href="#local-6989586621679808831"><span class="hs-identifier hs-type">stack</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span class="hs-special">)</span><span>
</span><span id="line-61"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679808830"><span class="annot"><a href="#local-6989586621679808830"><span class="hs-identifier hs-type">embedLayerNorm</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span class="hs-special">)</span><span>
</span><span id="line-62"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679808829"><span class="annot"><a href="#local-6989586621679808829"><span class="hs-identifier hs-type">layerNorm</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span class="hs-special">)</span><span>
</span><span id="line-63"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679808828"><span class="annot"><a href="#local-6989586621679808828"><span class="hs-identifier hs-type">dropout</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span class="hs-special">)</span><span>
</span><span id="line-64"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679808827"><span class="annot"><a href="#local-6989586621679808827"><span class="hs-identifier hs-type">posEnc</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span class="hs-special">)</span><span>
</span><span id="line-65"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-66"></span><span>  </span><span id="GTransformerDecoder"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#GTransformerDecoder"><span class="hs-identifier hs-var">GTransformerDecoder</span></a></span></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-67"></span><span>    </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679809195"><span class="annot"><a href="#local-6989586621679809195"><span class="hs-identifier hs-type">stack</span></a></span></span><span> </span><span id="local-6989586621679809194"><span class="annot"><a href="#local-6989586621679809194"><span class="hs-identifier hs-type">embedLayerNorm</span></a></span></span><span> </span><span id="local-6989586621679809193"><span class="annot"><a href="#local-6989586621679809193"><span class="hs-identifier hs-type">layerNorm</span></a></span></span><span> </span><span id="local-6989586621679809192"><span class="annot"><a href="#local-6989586621679809192"><span class="hs-identifier hs-type">dropout</span></a></span></span><span> </span><span id="local-6989586621679809191"><span class="annot"><a href="#local-6989586621679809191"><span class="hs-identifier hs-type">posEnc</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-68"></span><span>    </span><span class="hs-special">{</span><span> </span><span class="hs-comment">-- | decoder layer stack</span><span>
</span><span id="line-69"></span><span>      </span><span id="tdStack"><span class="annot"><span class="annottext">GTransformerDecoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; stack
</span><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#tdStack"><span class="hs-identifier hs-var hs-var">tdStack</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679809195"><span class="hs-identifier hs-type">stack</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-70"></span><span>      </span><span class="hs-comment">-- | decoder embedding layer norm</span><span>
</span><span id="line-71"></span><span>      </span><span id="tdEmbedLayerNorm"><span class="annot"><span class="annottext">GTransformerDecoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; embedLayerNorm
</span><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#tdEmbedLayerNorm"><span class="hs-identifier hs-var hs-var">tdEmbedLayerNorm</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679809194"><span class="hs-identifier hs-type">embedLayerNorm</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-72"></span><span>      </span><span class="hs-comment">-- | decoder layer norm</span><span>
</span><span id="line-73"></span><span>      </span><span id="tdLayerNorm"><span class="annot"><span class="annottext">GTransformerDecoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; layerNorm
</span><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#tdLayerNorm"><span class="hs-identifier hs-var hs-var">tdLayerNorm</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679809193"><span class="hs-identifier hs-type">layerNorm</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-74"></span><span>      </span><span class="hs-comment">-- | decoder dropout</span><span>
</span><span id="line-75"></span><span>      </span><span id="tdDropout"><span class="annot"><span class="annottext">GTransformerDecoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; dropout
</span><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#tdDropout"><span class="hs-identifier hs-var hs-var">tdDropout</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679809192"><span class="hs-identifier hs-type">dropout</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-76"></span><span>      </span><span class="hs-comment">-- | positional encoding</span><span>
</span><span id="line-77"></span><span>      </span><span id="tdPosEnc"><span class="annot"><span class="annottext">GTransformerDecoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; posEnc
</span><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#tdPosEnc"><span class="hs-identifier hs-var hs-var">tdPosEnc</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679809191"><span class="hs-identifier hs-type">posEnc</span></a></span><span>
</span><span id="line-78"></span><span>    </span><span class="hs-special">}</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-79"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#GTransformerDecoder"><span class="hs-identifier hs-type">GTransformerDecoder</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679809195"><span class="hs-identifier hs-type">stack</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679809194"><span class="hs-identifier hs-type">embedLayerNorm</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679809193"><span class="hs-identifier hs-type">layerNorm</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679809192"><span class="hs-identifier hs-type">dropout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679809191"><span class="hs-identifier hs-type">posEnc</span></a></span><span>
</span><span id="line-80"></span><span>
</span><span id="line-81"></span><span class="hs-comment">-- | Transformer decoder.</span><span>
</span><span id="line-82"></span><span class="hs-keyword">newtype</span><span>
</span><span id="line-83"></span><span>  </span><span id="TransformerDecoder"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TransformerDecoder"><span class="hs-identifier hs-var">TransformerDecoder</span></a></span></span><span>
</span><span id="line-84"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679808820"><span class="annot"><a href="#local-6989586621679808820"><span class="hs-identifier hs-type">style</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerStyle"><span class="hs-identifier hs-type">TransformerStyle</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-85"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679808819"><span class="annot"><a href="#local-6989586621679808819"><span class="hs-identifier hs-type">numLayers</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span>
</span><span id="line-86"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679808818"><span class="annot"><a href="#local-6989586621679808818"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#RequiresGradient"><span class="hs-identifier hs-type">RequiresGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-87"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679808817"><span class="annot"><a href="#local-6989586621679808817"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier hs-type">Device</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#DeviceType"><span class="hs-identifier hs-type">DeviceType</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-88"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679808816"><span class="annot"><a href="#local-6989586621679808816"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier hs-type">DType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-89"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679808815"><span class="annot"><a href="#local-6989586621679808815"><span class="hs-identifier hs-type">headDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-90"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679808814"><span class="annot"><a href="#local-6989586621679808814"><span class="hs-identifier hs-type">headEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-91"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679808813"><span class="annot"><a href="#local-6989586621679808813"><span class="hs-identifier hs-type">embedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-92"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679808812"><span class="annot"><a href="#local-6989586621679808812"><span class="hs-identifier hs-type">decoderInputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-93"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679808811"><span class="annot"><a href="#local-6989586621679808811"><span class="hs-identifier hs-type">encoderOutputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-94"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679808810"><span class="annot"><a href="#local-6989586621679808810"><span class="hs-identifier hs-type">ffnDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-95"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679808809"><span class="annot"><a href="#local-6989586621679808809"><span class="hs-identifier hs-type">posEncDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-96"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-97"></span><span>  </span><span id="TransformerDecoder"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TransformerDecoder"><span class="hs-identifier hs-var">TransformerDecoder</span></a></span></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-98"></span><span>    </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679809157"><span class="annot"><a href="#local-6989586621679809157"><span class="hs-identifier hs-type">style</span></a></span></span><span> </span><span id="local-6989586621679809156"><span class="annot"><a href="#local-6989586621679809156"><span class="hs-identifier hs-type">numLayers</span></a></span></span><span> </span><span id="local-6989586621679809155"><span class="annot"><a href="#local-6989586621679809155"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679809154"><span class="annot"><a href="#local-6989586621679809154"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679809153"><span class="annot"><a href="#local-6989586621679809153"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679809152"><span class="annot"><a href="#local-6989586621679809152"><span class="hs-identifier hs-type">headDim</span></a></span></span><span> </span><span id="local-6989586621679809151"><span class="annot"><a href="#local-6989586621679809151"><span class="hs-identifier hs-type">headEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679809150"><span class="annot"><a href="#local-6989586621679809150"><span class="hs-identifier hs-type">embedDim</span></a></span></span><span> </span><span id="local-6989586621679809149"><span class="annot"><a href="#local-6989586621679809149"><span class="hs-identifier hs-type">decoderInputEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679809148"><span class="annot"><a href="#local-6989586621679809148"><span class="hs-identifier hs-type">encoderOutputEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679809147"><span class="annot"><a href="#local-6989586621679809147"><span class="hs-identifier hs-type">ffnDim</span></a></span></span><span> </span><span id="local-6989586621679809146"><span class="annot"><a href="#local-6989586621679809146"><span class="hs-identifier hs-type">posEncDim</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-99"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#GTransformerDecoder"><span class="hs-identifier hs-type">GTransformerDecoder</span></a></span><span>
</span><span id="line-100"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TDStackF"><span class="hs-identifier hs-type">TDStackF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679809157"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679809156"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679809155"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679809154"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679809153"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679809152"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679809151"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679809150"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679809149"><span class="hs-identifier hs-type">decoderInputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679809148"><span class="hs-identifier hs-type">encoderOutputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679809147"><span class="hs-identifier hs-type">ffnDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-101"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TDEmbedLayerNormF"><span class="hs-identifier hs-type">TDEmbedLayerNormF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679809157"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679809155"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679809154"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679809153"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679809149"><span class="hs-identifier hs-type">decoderInputEmbedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-102"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TDLayerNormF"><span class="hs-identifier hs-type">TDLayerNormF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679809157"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679809155"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679809154"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679809153"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679809149"><span class="hs-identifier hs-type">decoderInputEmbedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-103"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TDDropoutF"><span class="hs-identifier hs-type">TDDropoutF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679809157"><span class="hs-identifier hs-type">style</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-104"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TDPosEncF"><span class="hs-identifier hs-type">TDPosEncF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679809157"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679809155"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679809154"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679809153"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679809152"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679809149"><span class="hs-identifier hs-type">decoderInputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679809146"><span class="hs-identifier hs-type">posEncDim</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-105"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TransformerDecoder"><span class="hs-identifier hs-type">TransformerDecoder</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679809157"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679809156"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679809155"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679809154"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679809153"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679809152"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679809151"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679809150"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679809149"><span class="hs-identifier hs-type">decoderInputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679809148"><span class="hs-identifier hs-type">encoderOutputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679809147"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679809146"><span class="hs-identifier hs-type">posEncDim</span></a></span><span>
</span><span id="line-106"></span><span>
</span><span id="line-107"></span><span class="hs-keyword">data</span><span>
</span><span id="line-108"></span><span>  </span><span id="TransformerDecoderSpec"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TransformerDecoderSpec"><span class="hs-identifier hs-var">TransformerDecoderSpec</span></a></span></span><span>
</span><span id="line-109"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679808807"><span class="annot"><a href="#local-6989586621679808807"><span class="hs-identifier hs-type">style</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerStyle"><span class="hs-identifier hs-type">TransformerStyle</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-110"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679808806"><span class="annot"><a href="#local-6989586621679808806"><span class="hs-identifier hs-type">numLayers</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span>
</span><span id="line-111"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679808805"><span class="annot"><a href="#local-6989586621679808805"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#RequiresGradient"><span class="hs-identifier hs-type">RequiresGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-112"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679808804"><span class="annot"><a href="#local-6989586621679808804"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier hs-type">Device</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#DeviceType"><span class="hs-identifier hs-type">DeviceType</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-113"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679808803"><span class="annot"><a href="#local-6989586621679808803"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier hs-type">DType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-114"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679808802"><span class="annot"><a href="#local-6989586621679808802"><span class="hs-identifier hs-type">headDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-115"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679808801"><span class="annot"><a href="#local-6989586621679808801"><span class="hs-identifier hs-type">headEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-116"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679808800"><span class="annot"><a href="#local-6989586621679808800"><span class="hs-identifier hs-type">embedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-117"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679808799"><span class="annot"><a href="#local-6989586621679808799"><span class="hs-identifier hs-type">decoderInputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-118"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679808798"><span class="annot"><a href="#local-6989586621679808798"><span class="hs-identifier hs-type">encoderOutputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-119"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679808797"><span class="annot"><a href="#local-6989586621679808797"><span class="hs-identifier hs-type">ffnDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-120"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679808796"><span class="annot"><a href="#local-6989586621679808796"><span class="hs-identifier hs-type">posEncDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-121"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-122"></span><span>  </span><span id="TransformerDecoderSpec"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TransformerDecoderSpec"><span class="hs-identifier hs-var">TransformerDecoderSpec</span></a></span></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-123"></span><span>    </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679808994"><span class="annot"><a href="#local-6989586621679808994"><span class="hs-identifier hs-type">style</span></a></span></span><span> </span><span id="local-6989586621679808993"><span class="annot"><a href="#local-6989586621679808993"><span class="hs-identifier hs-type">numLayers</span></a></span></span><span> </span><span id="local-6989586621679808992"><span class="annot"><a href="#local-6989586621679808992"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679808991"><span class="annot"><a href="#local-6989586621679808991"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679808990"><span class="annot"><a href="#local-6989586621679808990"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679808989"><span class="annot"><a href="#local-6989586621679808989"><span class="hs-identifier hs-type">headDim</span></a></span></span><span> </span><span id="local-6989586621679808988"><span class="annot"><a href="#local-6989586621679808988"><span class="hs-identifier hs-type">headEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679808987"><span class="annot"><a href="#local-6989586621679808987"><span class="hs-identifier hs-type">embedDim</span></a></span></span><span> </span><span id="local-6989586621679808986"><span class="annot"><a href="#local-6989586621679808986"><span class="hs-identifier hs-type">decoderInputEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679808985"><span class="annot"><a href="#local-6989586621679808985"><span class="hs-identifier hs-type">encoderOutputEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679808984"><span class="annot"><a href="#local-6989586621679808984"><span class="hs-identifier hs-type">ffnDim</span></a></span></span><span> </span><span id="local-6989586621679808983"><span class="annot"><a href="#local-6989586621679808983"><span class="hs-identifier hs-type">posEncDim</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-124"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#STransformerStyle"><span class="hs-identifier hs-type">STransformerStyle</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808994"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-125"></span><span>    </span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-type">SNat</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808993"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-126"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier hs-type">SGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808992"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-127"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#SDevice"><span class="hs-identifier hs-type">SDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808991"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-128"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier hs-type">SDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808990"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-129"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808989"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-130"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808988"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-131"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808987"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-132"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808986"><span class="hs-identifier hs-type">decoderInputEmbedDim</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-133"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808985"><span class="hs-identifier hs-type">encoderOutputEmbedDim</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-134"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808984"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-135"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808983"><span class="hs-identifier hs-type">posEncDim</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-136"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-137"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-138"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TransformerDecoderSpec"><span class="hs-identifier hs-type">TransformerDecoderSpec</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808994"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808993"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808992"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808991"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808990"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808989"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808988"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808987"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808986"><span class="hs-identifier hs-type">decoderInputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808985"><span class="hs-identifier hs-type">encoderOutputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808984"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808983"><span class="hs-identifier hs-type">posEncDim</span></a></span><span>
</span><span id="line-139"></span><span>
</span><span id="line-140"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">instance</span><span> </span><span id="ModelSpec"><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier hs-var">ModelSpec</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TransformerDecoder"><span class="hs-identifier hs-type">TransformerDecoder</span></a></span><span> </span><span id="local-6989586621679808794"><span class="annot"><a href="#local-6989586621679808794"><span class="hs-identifier hs-type hs-type">style</span></a></span></span><span> </span><span id="local-6989586621679808793"><span class="annot"><a href="#local-6989586621679808793"><span class="hs-identifier hs-type hs-type">numLayers</span></a></span></span><span> </span><span id="local-6989586621679808792"><span class="annot"><a href="#local-6989586621679808792"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679808791"><span class="annot"><a href="#local-6989586621679808791"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679808790"><span class="annot"><a href="#local-6989586621679808790"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679808789"><span class="annot"><a href="#local-6989586621679808789"><span class="hs-identifier hs-type hs-type">headDim</span></a></span></span><span> </span><span id="local-6989586621679808788"><span class="annot"><a href="#local-6989586621679808788"><span class="hs-identifier hs-type hs-type">headEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679808787"><span class="annot"><a href="#local-6989586621679808787"><span class="hs-identifier hs-type hs-type">embedDim</span></a></span></span><span> </span><span id="local-6989586621679808786"><span class="annot"><a href="#local-6989586621679808786"><span class="hs-identifier hs-type hs-type">decoderInputEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679808785"><span class="annot"><a href="#local-6989586621679808785"><span class="hs-identifier hs-type hs-type">encoderOutputEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679808784"><span class="annot"><a href="#local-6989586621679808784"><span class="hs-identifier hs-type hs-type">ffnDim</span></a></span></span><span> </span><span id="local-6989586621679808783"><span class="annot"><a href="#local-6989586621679808783"><span class="hs-identifier hs-type hs-type">posEncDim</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TransformerDecoderSpec"><span class="hs-identifier hs-type">TransformerDecoderSpec</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808794"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808793"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808792"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808791"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808790"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808789"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808788"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808787"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808786"><span class="hs-identifier hs-type">decoderInputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808785"><span class="hs-identifier hs-type">encoderOutputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808784"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808783"><span class="hs-identifier hs-type">posEncDim</span></a></span><span>
</span><span id="line-141"></span><span>
</span><span id="line-142"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span>
</span><span id="line-143"></span><span>  </span><span id="TDStackF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TDStackF"><span class="hs-identifier hs-var">TDStackF</span></a></span></span><span>
</span><span id="line-144"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679808782"><span class="annot"><a href="#local-6989586621679808782"><span class="hs-identifier hs-type">style</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerStyle"><span class="hs-identifier hs-type">TransformerStyle</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-145"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679808781"><span class="annot"><a href="#local-6989586621679808781"><span class="hs-identifier hs-type">numLayers</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span>
</span><span id="line-146"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679808780"><span class="annot"><a href="#local-6989586621679808780"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#RequiresGradient"><span class="hs-identifier hs-type">RequiresGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-147"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679808779"><span class="annot"><a href="#local-6989586621679808779"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier hs-type">Device</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#DeviceType"><span class="hs-identifier hs-type">DeviceType</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-148"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679808778"><span class="annot"><a href="#local-6989586621679808778"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier hs-type">DType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-149"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679808777"><span class="annot"><a href="#local-6989586621679808777"><span class="hs-identifier hs-type">headDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-150"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679808776"><span class="annot"><a href="#local-6989586621679808776"><span class="hs-identifier hs-type">headEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-151"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679808775"><span class="annot"><a href="#local-6989586621679808775"><span class="hs-identifier hs-type">embedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-152"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679808774"><span class="annot"><a href="#local-6989586621679808774"><span class="hs-identifier hs-type">decoderInputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-153"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679808773"><span class="annot"><a href="#local-6989586621679808773"><span class="hs-identifier hs-type">encoderOutputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-154"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679808772"><span class="annot"><a href="#local-6989586621679808772"><span class="hs-identifier hs-type">ffnDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-155"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span>
</span><span id="line-156"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-157"></span><span>  </span><span id="TDStackF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TDStackF"><span class="hs-identifier hs-var">TDStackF</span></a></span></span><span> </span><span id="local-6989586621679808771"><span class="annot"><a href="#local-6989586621679808771"><span class="hs-identifier hs-type hs-type">style</span></a></span></span><span> </span><span id="local-6989586621679808770"><span class="annot"><a href="#local-6989586621679808770"><span class="hs-identifier hs-type hs-type">numLayers</span></a></span></span><span> </span><span id="local-6989586621679808769"><span class="annot"><a href="#local-6989586621679808769"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679808768"><span class="annot"><a href="#local-6989586621679808768"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679808767"><span class="annot"><a href="#local-6989586621679808767"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679808766"><span class="annot"><a href="#local-6989586621679808766"><span class="hs-identifier hs-type hs-type">headDim</span></a></span></span><span> </span><span id="local-6989586621679808765"><span class="annot"><a href="#local-6989586621679808765"><span class="hs-identifier hs-type hs-type">headEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679808764"><span class="annot"><a href="#local-6989586621679808764"><span class="hs-identifier hs-type hs-type">embedDim</span></a></span></span><span> </span><span id="local-6989586621679808763"><span class="annot"><a href="#local-6989586621679808763"><span class="hs-identifier hs-type hs-type">decoderInputEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679808762"><span class="annot"><a href="#local-6989586621679808762"><span class="hs-identifier hs-type hs-type">encoderOutputEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679808761"><span class="annot"><a href="#local-6989586621679808761"><span class="hs-identifier hs-type hs-type">ffnDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-158"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.DecoderStack.html#TransformerDecoderStack"><span class="hs-identifier hs-type">TransformerDecoderStack</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808771"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808770"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808769"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808768"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808767"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808766"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808765"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808764"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808763"><span class="hs-identifier hs-type">decoderInputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808762"><span class="hs-identifier hs-type">encoderOutputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808761"><span class="hs-identifier hs-type">ffnDim</span></a></span><span>
</span><span id="line-159"></span><span>
</span><span id="line-160"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span>
</span><span id="line-161"></span><span>  </span><span id="TDEmbedLayerNormF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TDEmbedLayerNormF"><span class="hs-identifier hs-var">TDEmbedLayerNormF</span></a></span></span><span>
</span><span id="line-162"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679808760"><span class="annot"><a href="#local-6989586621679808760"><span class="hs-identifier hs-type">style</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerStyle"><span class="hs-identifier hs-type">TransformerStyle</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-163"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679808759"><span class="annot"><a href="#local-6989586621679808759"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#RequiresGradient"><span class="hs-identifier hs-type">RequiresGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-164"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679808758"><span class="annot"><a href="#local-6989586621679808758"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier hs-type">Device</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#DeviceType"><span class="hs-identifier hs-type">DeviceType</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-165"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679808757"><span class="annot"><a href="#local-6989586621679808757"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier hs-type">DType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-166"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679808756"><span class="annot"><a href="#local-6989586621679808756"><span class="hs-identifier hs-type">decoderInputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-167"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span>
</span><span id="line-168"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-169"></span><span>  </span><span id="TDEmbedLayerNormF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TDEmbedLayerNormF"><span class="hs-identifier hs-var">TDEmbedLayerNormF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#T5"><span class="hs-identifier hs-type">T5</span></a></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-170"></span><span>  </span><span id="TDEmbedLayerNormF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TDEmbedLayerNormF"><span class="hs-identifier hs-var">TDEmbedLayerNormF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ByT5"><span class="hs-identifier hs-type">ByT5</span></a></span><span> </span><span id="local-6989586621679808755"><span class="annot"><a href="#local-6989586621679808755"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679808754"><span class="annot"><a href="#local-6989586621679808754"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679808753"><span class="annot"><a href="#local-6989586621679808753"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679808752"><span class="annot"><a href="#local-6989586621679808752"><span class="hs-identifier hs-type hs-type">decoderInputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TDEmbedLayerNormF"><span class="hs-identifier hs-type">TDEmbedLayerNormF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#T5"><span class="hs-identifier hs-type">T5</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808755"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808754"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808753"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808752"><span class="hs-identifier hs-type">decoderInputEmbedDim</span></a></span><span>
</span><span id="line-171"></span><span>  </span><span id="TDEmbedLayerNormF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TDEmbedLayerNormF"><span class="hs-identifier hs-var">TDEmbedLayerNormF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span> </span><span id="local-6989586621679808751"><span class="annot"><a href="#local-6989586621679808751"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679808750"><span class="annot"><a href="#local-6989586621679808750"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679808749"><span class="annot"><a href="#local-6989586621679808749"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679808748"><span class="annot"><a href="#local-6989586621679808748"><span class="hs-identifier hs-type hs-type">decoderInputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Normalization.html#LayerNorm"><span class="hs-identifier hs-type">LayerNorm</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Type.html#WithBias"><span class="hs-identifier hs-type">WithBias</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808751"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808750"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808749"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679808748"><span class="hs-identifier hs-type">decoderInputEmbedDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-172"></span><span>  </span><span id="TDEmbedLayerNormF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TDEmbedLayerNormF"><span class="hs-identifier hs-var">TDEmbedLayerNormF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MBART"><span class="hs-identifier hs-type">MBART</span></a></span><span> </span><span id="local-6989586621679808747"><span class="annot"><a href="#local-6989586621679808747"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679808746"><span class="annot"><a href="#local-6989586621679808746"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679808745"><span class="annot"><a href="#local-6989586621679808745"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679808744"><span class="annot"><a href="#local-6989586621679808744"><span class="hs-identifier hs-type hs-type">decoderInputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TDEmbedLayerNormF"><span class="hs-identifier hs-type">TDEmbedLayerNormF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808747"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808746"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808745"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808744"><span class="hs-identifier hs-type">decoderInputEmbedDim</span></a></span><span>
</span><span id="line-173"></span><span>  </span><span id="TDEmbedLayerNormF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TDEmbedLayerNormF"><span class="hs-identifier hs-var">TDEmbedLayerNormF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#Pegasus"><span class="hs-identifier hs-type">Pegasus</span></a></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-174"></span><span>
</span><span id="line-175"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span>
</span><span id="line-176"></span><span>  </span><span id="TDLayerNormF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TDLayerNormF"><span class="hs-identifier hs-var">TDLayerNormF</span></a></span></span><span>
</span><span id="line-177"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679808743"><span class="annot"><a href="#local-6989586621679808743"><span class="hs-identifier hs-type">style</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerStyle"><span class="hs-identifier hs-type">TransformerStyle</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-178"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679808742"><span class="annot"><a href="#local-6989586621679808742"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#RequiresGradient"><span class="hs-identifier hs-type">RequiresGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-179"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679808741"><span class="annot"><a href="#local-6989586621679808741"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier hs-type">Device</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#DeviceType"><span class="hs-identifier hs-type">DeviceType</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-180"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679808740"><span class="annot"><a href="#local-6989586621679808740"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier hs-type">DType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-181"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679808739"><span class="annot"><a href="#local-6989586621679808739"><span class="hs-identifier hs-type">decoderInputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-182"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span>
</span><span id="line-183"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-184"></span><span>  </span><span id="TDLayerNormF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TDLayerNormF"><span class="hs-identifier hs-var">TDLayerNormF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#T5"><span class="hs-identifier hs-type">T5</span></a></span><span> </span><span id="local-6989586621679808738"><span class="annot"><a href="#local-6989586621679808738"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679808737"><span class="annot"><a href="#local-6989586621679808737"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679808736"><span class="annot"><a href="#local-6989586621679808736"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679808735"><span class="annot"><a href="#local-6989586621679808735"><span class="hs-identifier hs-type hs-type">decoderInputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Normalization.html#LayerNorm"><span class="hs-identifier hs-type">LayerNorm</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Type.html#WithoutBias"><span class="hs-identifier hs-type">WithoutBias</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808738"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808737"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808736"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679808735"><span class="hs-identifier hs-type">decoderInputEmbedDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-185"></span><span>  </span><span id="TDLayerNormF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TDLayerNormF"><span class="hs-identifier hs-var">TDLayerNormF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ByT5"><span class="hs-identifier hs-type">ByT5</span></a></span><span> </span><span id="local-6989586621679808734"><span class="annot"><a href="#local-6989586621679808734"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679808733"><span class="annot"><a href="#local-6989586621679808733"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679808732"><span class="annot"><a href="#local-6989586621679808732"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679808731"><span class="annot"><a href="#local-6989586621679808731"><span class="hs-identifier hs-type hs-type">decoderInputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TDLayerNormF"><span class="hs-identifier hs-type">TDLayerNormF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#T5"><span class="hs-identifier hs-type">T5</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808734"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808733"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808732"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808731"><span class="hs-identifier hs-type">decoderInputEmbedDim</span></a></span><span>
</span><span id="line-186"></span><span>  </span><span id="TDLayerNormF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TDLayerNormF"><span class="hs-identifier hs-var">TDLayerNormF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-187"></span><span>  </span><span id="TDLayerNormF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TDLayerNormF"><span class="hs-identifier hs-var">TDLayerNormF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MBART"><span class="hs-identifier hs-type">MBART</span></a></span><span> </span><span id="local-6989586621679808730"><span class="annot"><a href="#local-6989586621679808730"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679808729"><span class="annot"><a href="#local-6989586621679808729"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679808728"><span class="annot"><a href="#local-6989586621679808728"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679808727"><span class="annot"><a href="#local-6989586621679808727"><span class="hs-identifier hs-type hs-type">decoderInputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TDLayerNormF"><span class="hs-identifier hs-type">TDLayerNormF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808730"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808729"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808728"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808727"><span class="hs-identifier hs-type">decoderInputEmbedDim</span></a></span><span>
</span><span id="line-188"></span><span>  </span><span id="TDLayerNormF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TDLayerNormF"><span class="hs-identifier hs-var">TDLayerNormF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#Pegasus"><span class="hs-identifier hs-type">Pegasus</span></a></span><span> </span><span id="local-6989586621679808726"><span class="annot"><a href="#local-6989586621679808726"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679808725"><span class="annot"><a href="#local-6989586621679808725"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679808724"><span class="annot"><a href="#local-6989586621679808724"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679808723"><span class="annot"><a href="#local-6989586621679808723"><span class="hs-identifier hs-type hs-type">decoderInputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Normalization.html#LayerNorm"><span class="hs-identifier hs-type">LayerNorm</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Type.html#WithBias"><span class="hs-identifier hs-type">WithBias</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808726"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808725"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808724"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679808723"><span class="hs-identifier hs-type">decoderInputEmbedDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-189"></span><span>
</span><span id="line-190"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span>
</span><span id="line-191"></span><span>  </span><span id="TDDropoutF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TDDropoutF"><span class="hs-identifier hs-var">TDDropoutF</span></a></span></span><span>
</span><span id="line-192"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679808722"><span class="annot"><a href="#local-6989586621679808722"><span class="hs-identifier hs-type">style</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerStyle"><span class="hs-identifier hs-type">TransformerStyle</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-193"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span>
</span><span id="line-194"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-195"></span><span>  </span><span id="TDDropoutF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TDDropoutF"><span class="hs-identifier hs-var">TDDropoutF</span></a></span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Dropout.html#Dropout"><span class="hs-identifier hs-type">Dropout</span></a></span><span>
</span><span id="line-196"></span><span>
</span><span id="line-197"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span>
</span><span id="line-198"></span><span>  </span><span id="TDPosEncF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TDPosEncF"><span class="hs-identifier hs-var">TDPosEncF</span></a></span></span><span>
</span><span id="line-199"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679808721"><span class="annot"><a href="#local-6989586621679808721"><span class="hs-identifier hs-type">style</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerStyle"><span class="hs-identifier hs-type">TransformerStyle</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-200"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679808720"><span class="annot"><a href="#local-6989586621679808720"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#RequiresGradient"><span class="hs-identifier hs-type">RequiresGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-201"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679808719"><span class="annot"><a href="#local-6989586621679808719"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier hs-type">Device</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#DeviceType"><span class="hs-identifier hs-type">DeviceType</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-202"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679808718"><span class="annot"><a href="#local-6989586621679808718"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier hs-type">DType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-203"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679808717"><span class="annot"><a href="#local-6989586621679808717"><span class="hs-identifier hs-type">headDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-204"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679808716"><span class="annot"><a href="#local-6989586621679808716"><span class="hs-identifier hs-type">decoderInputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-205"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679808715"><span class="annot"><a href="#local-6989586621679808715"><span class="hs-identifier hs-type">posEncDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-206"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span>
</span><span id="line-207"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-208"></span><span>  </span><span id="TDPosEncF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TDPosEncF"><span class="hs-identifier hs-var">TDPosEncF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#T5"><span class="hs-identifier hs-type">T5</span></a></span><span> </span><span id="local-6989586621679808714"><span class="annot"><a href="#local-6989586621679808714"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679808713"><span class="annot"><a href="#local-6989586621679808713"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679808712"><span class="annot"><a href="#local-6989586621679808712"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679808711"><span class="annot"><a href="#local-6989586621679808711"><span class="hs-identifier hs-type hs-type">headDim</span></a></span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span id="local-6989586621679808710"><span class="annot"><a href="#local-6989586621679808710"><span class="hs-identifier hs-type hs-type">posEncDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Sparse.html#Embedding"><span class="hs-identifier hs-type">Embedding</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808714"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Dense"><span class="hs-identifier hs-type">Dense</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679808713"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808712"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808710"><span class="hs-identifier hs-type">posEncDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808711"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><span class="hs-identifier hs-type">Nothing</span></span><span>
</span><span id="line-209"></span><span>  </span><span id="TDPosEncF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TDPosEncF"><span class="hs-identifier hs-var">TDPosEncF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ByT5"><span class="hs-identifier hs-type">ByT5</span></a></span><span> </span><span id="local-6989586621679808709"><span class="annot"><a href="#local-6989586621679808709"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679808708"><span class="annot"><a href="#local-6989586621679808708"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679808707"><span class="annot"><a href="#local-6989586621679808707"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679808706"><span class="annot"><a href="#local-6989586621679808706"><span class="hs-identifier hs-type hs-type">headDim</span></a></span></span><span> </span><span id="local-6989586621679808705"><span class="annot"><a href="#local-6989586621679808705"><span class="hs-identifier hs-type hs-type">decoderInputEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679808704"><span class="annot"><a href="#local-6989586621679808704"><span class="hs-identifier hs-type hs-type">posEncDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TDPosEncF"><span class="hs-identifier hs-type">TDPosEncF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#T5"><span class="hs-identifier hs-type">T5</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808709"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808708"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808707"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808706"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808705"><span class="hs-identifier hs-type">decoderInputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808704"><span class="hs-identifier hs-type">posEncDim</span></a></span><span>
</span><span id="line-210"></span><span>  </span><span id="TDPosEncF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TDPosEncF"><span class="hs-identifier hs-var">TDPosEncF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span> </span><span id="local-6989586621679808703"><span class="annot"><a href="#local-6989586621679808703"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679808702"><span class="annot"><a href="#local-6989586621679808702"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679808701"><span class="annot"><a href="#local-6989586621679808701"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span id="local-6989586621679808700"><span class="annot"><a href="#local-6989586621679808700"><span class="hs-identifier hs-type hs-type">decoderInputEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679808699"><span class="annot"><a href="#local-6989586621679808699"><span class="hs-identifier hs-type hs-type">posEncDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Sparse.html#Embedding"><span class="hs-identifier hs-type">Embedding</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808703"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Dense"><span class="hs-identifier hs-type">Dense</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679808702"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808701"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808699"><span class="hs-identifier hs-type">posEncDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808700"><span class="hs-identifier hs-type">decoderInputEmbedDim</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><span class="hs-identifier hs-type">Nothing</span></span><span>
</span><span id="line-211"></span><span>  </span><span id="TDPosEncF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TDPosEncF"><span class="hs-identifier hs-var">TDPosEncF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MBART"><span class="hs-identifier hs-type">MBART</span></a></span><span> </span><span id="local-6989586621679808698"><span class="annot"><a href="#local-6989586621679808698"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679808697"><span class="annot"><a href="#local-6989586621679808697"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679808696"><span class="annot"><a href="#local-6989586621679808696"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679808695"><span class="annot"><a href="#local-6989586621679808695"><span class="hs-identifier hs-type hs-type">headDim</span></a></span></span><span> </span><span id="local-6989586621679808694"><span class="annot"><a href="#local-6989586621679808694"><span class="hs-identifier hs-type hs-type">decoderInputEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679808693"><span class="annot"><a href="#local-6989586621679808693"><span class="hs-identifier hs-type hs-type">posEncDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TDPosEncF"><span class="hs-identifier hs-type">TDPosEncF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808698"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808697"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808696"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808695"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808694"><span class="hs-identifier hs-type">decoderInputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808693"><span class="hs-identifier hs-type">posEncDim</span></a></span><span>
</span><span id="line-212"></span><span>  </span><span id="TDPosEncF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TDPosEncF"><span class="hs-identifier hs-var">TDPosEncF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#Pegasus"><span class="hs-identifier hs-type">Pegasus</span></a></span><span> </span><span id="local-6989586621679808692"><span class="annot"><a href="#local-6989586621679808692"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679808691"><span class="annot"><a href="#local-6989586621679808691"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679808690"><span class="annot"><a href="#local-6989586621679808690"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679808689"><span class="annot"><a href="#local-6989586621679808689"><span class="hs-identifier hs-type hs-type">headDim</span></a></span></span><span> </span><span id="local-6989586621679808688"><span class="annot"><a href="#local-6989586621679808688"><span class="hs-identifier hs-type hs-type">decoderInputEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679808687"><span class="annot"><a href="#local-6989586621679808687"><span class="hs-identifier hs-type hs-type">posEncDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TDPosEncF"><span class="hs-identifier hs-type">TDPosEncF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808692"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808691"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808690"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808689"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808688"><span class="hs-identifier hs-type">decoderInputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808687"><span class="hs-identifier hs-type">posEncDim</span></a></span><span>
</span><span id="line-213"></span><span>
</span><span id="line-214"></span><span id="local-6989586621679808669"><span id="local-6989586621679808670"><span id="local-6989586621679808671"><span id="local-6989586621679808672"><span id="local-6989586621679808673"><span id="local-6989586621679808674"><span id="local-6989586621679808675"><span id="local-6989586621679808676"><span id="local-6989586621679808677"><span id="local-6989586621679808678"><span id="local-6989586621679808679"><span id="local-6989586621679808680"><span id="local-6989586621679808681"><span id="local-6989586621679808682"><span id="local-6989586621679808683"><span id="local-6989586621679808684"><span id="local-6989586621679808685"><span id="local-6989586621679808686"><span class="hs-keyword">instance</span><span>
</span><span id="line-215"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-type">SingI</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808686"><span class="hs-identifier hs-type">style</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-216"></span><span>    </span><span class="annot"><a href="#local-6989586621679808685"><span class="hs-identifier hs-type">decoderStack</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TDStackF"><span class="hs-identifier hs-type">TDStackF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808686"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808684"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808683"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808682"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808681"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808680"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808679"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808678"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808677"><span class="hs-identifier hs-type">decoderInputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808676"><span class="hs-identifier hs-type">encoderOutputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808675"><span class="hs-identifier hs-type">ffnDim</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-217"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808685"><span class="hs-identifier hs-type">decoderStack</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808682"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808685"><span class="hs-identifier hs-type">decoderStack</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808682"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-218"></span><span>    </span><span class="annot"><a href="#local-6989586621679808674"><span class="hs-identifier hs-type">embedLayerNorm</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TDEmbedLayerNormF"><span class="hs-identifier hs-type">TDEmbedLayerNormF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808686"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808683"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808682"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808681"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808677"><span class="hs-identifier hs-type">decoderInputEmbedDim</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-219"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808674"><span class="hs-identifier hs-type">embedLayerNorm</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808682"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808674"><span class="hs-identifier hs-type">embedLayerNorm</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808682"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-220"></span><span>    </span><span class="annot"><a href="#local-6989586621679808673"><span class="hs-identifier hs-type">layerNorm</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TDLayerNormF"><span class="hs-identifier hs-type">TDLayerNormF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808686"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808683"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808682"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808681"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808677"><span class="hs-identifier hs-type">decoderInputEmbedDim</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-221"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808673"><span class="hs-identifier hs-type">layerNorm</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808682"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808673"><span class="hs-identifier hs-type">layerNorm</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808682"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-222"></span><span>    </span><span class="annot"><a href="#local-6989586621679808672"><span class="hs-identifier hs-type">dropout</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TDDropoutF"><span class="hs-identifier hs-type">TDDropoutF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808686"><span class="hs-identifier hs-type">style</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-223"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808672"><span class="hs-identifier hs-type">dropout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808682"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808672"><span class="hs-identifier hs-type">dropout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808682"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-224"></span><span>    </span><span class="annot"><a href="#local-6989586621679808671"><span class="hs-identifier hs-type">posEnc</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TDPosEncF"><span class="hs-identifier hs-type">TDPosEncF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808686"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808683"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808682"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808681"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808680"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808677"><span class="hs-identifier hs-type">decoderInputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808670"><span class="hs-identifier hs-type">posEncDim</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-225"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808671"><span class="hs-identifier hs-type">posEnc</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808682"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808671"><span class="hs-identifier hs-type">posEnc</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808682"><span class="hs-identifier hs-type">device</span></a></span><span>
</span><span id="line-226"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-227"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span>
</span><span id="line-228"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TransformerDecoder"><span class="hs-identifier hs-type">TransformerDecoder</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808686"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808684"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808683"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808682"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808681"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808680"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808679"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808678"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808677"><span class="hs-identifier hs-type">decoderInputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808676"><span class="hs-identifier hs-type">encoderOutputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808675"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808670"><span class="hs-identifier hs-type">posEncDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-229"></span><span>    </span><span class="annot"><a href="#local-6989586621679808669"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-230"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TransformerDecoder"><span class="hs-identifier hs-type">TransformerDecoder</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808686"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808684"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808683"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808682"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808681"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808680"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808679"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808678"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808677"><span class="hs-identifier hs-type">decoderInputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808676"><span class="hs-identifier hs-type">encoderOutputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808675"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808670"><span class="hs-identifier hs-type">posEncDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-231"></span><span>    </span><span class="annot"><a href="#local-6989586621679808682"><span class="hs-identifier hs-type">device</span></a></span><span>
</span><span id="line-232"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-233"></span><span>  </span><span id="local-6989586621679808666"><span class="annot"><span class="annottext">initialize :: ModelSpec
  (TransformerDecoder
     style
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     decoderInputEmbedDim
     encoderOutputEmbedDim
     ffnDim
     posEncDim)
-&gt; Generator generatorDevice
-&gt; m (TransformerDecoder
        style
        numLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        decoderInputEmbedDim
        encoderOutputEmbedDim
        ffnDim
        posEncDim,
      Generator device)
</span><a href="Torch.GraduallyTyped.NN.Class.html#initialize"><span class="hs-identifier hs-var hs-var hs-var hs-var">initialize</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TransformerDecoderSpec"><span class="hs-identifier hs-type">TransformerDecoderSpec</span></a></span><span> </span><span id="local-6989586621679808664"><span class="annot"><a href="#local-6989586621679808664"><span class="hs-identifier hs-var">style</span></a></span></span><span> </span><span id="local-6989586621679808663"><span class="annot"><a href="#local-6989586621679808663"><span class="hs-identifier hs-var">numLayers</span></a></span></span><span> </span><span id="local-6989586621679808662"><span class="annot"><a href="#local-6989586621679808662"><span class="hs-identifier hs-var">gradient</span></a></span></span><span> </span><span id="local-6989586621679808661"><span class="annot"><a href="#local-6989586621679808661"><span class="hs-identifier hs-var">device</span></a></span></span><span> </span><span id="local-6989586621679808660"><span class="annot"><a href="#local-6989586621679808660"><span class="hs-identifier hs-var">dataType</span></a></span></span><span> </span><span id="local-6989586621679808659"><span class="annot"><a href="#local-6989586621679808659"><span class="hs-identifier hs-var">headDim</span></a></span></span><span> </span><span id="local-6989586621679808658"><span class="annot"><a href="#local-6989586621679808658"><span class="hs-identifier hs-var">headEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679808657"><span class="annot"><a href="#local-6989586621679808657"><span class="hs-identifier hs-var">embedDim</span></a></span></span><span> </span><span id="local-6989586621679808656"><span class="annot"><a href="#local-6989586621679808656"><span class="hs-identifier hs-var">decoderInputEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679808655"><span class="annot"><a href="#local-6989586621679808655"><span class="hs-identifier hs-var">encoderOutputEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679808654"><span class="annot"><a href="#local-6989586621679808654"><span class="hs-identifier hs-var">ffnDim</span></a></span></span><span> </span><span id="local-6989586621679808653"><span class="annot"><a href="#local-6989586621679808653"><span class="hs-identifier hs-var">posEncDim</span></a></span></span><span> </span><span id="local-6989586621679808652"><span class="annot"><a href="#local-6989586621679808652"><span class="hs-identifier hs-var">dropoutP</span></a></span></span><span> </span><span id="local-6989586621679808651"><span class="annot"><a href="#local-6989586621679808651"><span class="hs-identifier hs-var">eps</span></a></span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679808650"><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679808650"><span class="hs-identifier hs-var">generator</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-234"></span><span>    </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679808649"><span class="annot"><span class="annottext">generator' :: Generator device
</span><a href="#local-6989586621679808649"><span class="hs-identifier hs-var hs-var">generator'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SDevice device -&gt; Generator generatorDevice -&gt; Generator device
forall (generatorDevice' :: Device (DeviceType Nat))
       (generatorDevice :: Device (DeviceType Nat)).
SDevice generatorDevice'
-&gt; Generator generatorDevice -&gt; Generator generatorDevice'
</span><a href="Torch.GraduallyTyped.Random.html#sGeneratorToDevice"><span class="hs-identifier hs-var">sGeneratorToDevice</span></a></span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679808661"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679808650"><span class="hs-identifier hs-var">generator</span></a></span><span>
</span><span id="line-235"></span><span>        </span><span id="local-6989586621679808648"><span class="annot"><span class="annottext">decoderStack :: IxStateT
  m
  (Generator device)
  (Generator device)
  (TransformerDecoderStack
     style
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     decoderInputEmbedDim
     encoderOutputEmbedDim
     ffnDim)
</span><a href="#local-6989586621679808648"><span class="hs-identifier hs-var hs-var">decoderStack</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(Generator device
 -&gt; m (TransformerDecoderStack
         style
         numLayers
         gradient
         device
         dataType
         headDim
         headEmbedDim
         embedDim
         decoderInputEmbedDim
         encoderOutputEmbedDim
         ffnDim,
       Generator device))
-&gt; IxStateT
     m
     (Generator device)
     (Generator device)
     (TransformerDecoderStack
        style
        numLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        decoderInputEmbedDim
        encoderOutputEmbedDim
        ffnDim)
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator device
  -&gt; m (TransformerDecoderStack
          style
          numLayers
          gradient
          device
          dataType
          headDim
          headEmbedDim
          embedDim
          decoderInputEmbedDim
          encoderOutputEmbedDim
          ffnDim,
        Generator device))
 -&gt; IxStateT
      m
      (Generator device)
      (Generator device)
      (TransformerDecoderStack
         style
         numLayers
         gradient
         device
         dataType
         headDim
         headEmbedDim
         embedDim
         decoderInputEmbedDim
         encoderOutputEmbedDim
         ffnDim))
-&gt; (TransformerDecoderStackSpec
      style
      numLayers
      gradient
      device
      dataType
      headDim
      headEmbedDim
      embedDim
      decoderInputEmbedDim
      encoderOutputEmbedDim
      ffnDim
    -&gt; Generator device
    -&gt; m (TransformerDecoderStack
            style
            numLayers
            gradient
            device
            dataType
            headDim
            headEmbedDim
            embedDim
            decoderInputEmbedDim
            encoderOutputEmbedDim
            ffnDim,
          Generator device))
-&gt; TransformerDecoderStackSpec
     style
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     decoderInputEmbedDim
     encoderOutputEmbedDim
     ffnDim
-&gt; IxStateT
     m
     (Generator device)
     (Generator device)
     (TransformerDecoderStack
        style
        numLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        decoderInputEmbedDim
        encoderOutputEmbedDim
        ffnDim)
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">forall model (generatorDevice :: Device (DeviceType Nat)) output
       (generatorOutputDevice :: Device (DeviceType Nat)) (m :: * -&gt; *).
(HasInitialize model generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
ModelSpec model
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
forall (generatorDevice :: Device (DeviceType Nat)) output
       (generatorOutputDevice :: Device (DeviceType Nat)) (m :: * -&gt; *).
(HasInitialize
   decoderStack generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
ModelSpec decoderStack
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#initialize"><span class="hs-identifier hs-var">initialize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679808685"><span class="hs-identifier hs-type">decoderStack</span></a></span><span> </span><span class="annot"><span class="annottext">(TransformerDecoderStackSpec
   style
   numLayers
   gradient
   device
   dataType
   headDim
   headEmbedDim
   embedDim
   decoderInputEmbedDim
   encoderOutputEmbedDim
   ffnDim
 -&gt; IxStateT
      m
      (Generator device)
      (Generator device)
      (TransformerDecoderStack
         style
         numLayers
         gradient
         device
         dataType
         headDim
         headEmbedDim
         embedDim
         decoderInputEmbedDim
         encoderOutputEmbedDim
         ffnDim))
-&gt; TransformerDecoderStackSpec
     style
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     decoderInputEmbedDim
     encoderOutputEmbedDim
     ffnDim
-&gt; IxStateT
     m
     (Generator device)
     (Generator device)
     (TransformerDecoderStack
        style
        numLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        decoderInputEmbedDim
        encoderOutputEmbedDim
        ffnDim)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; SNat numLayers
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim headDim
-&gt; SDim headEmbedDim
-&gt; SDim embedDim
-&gt; SDim decoderInputEmbedDim
-&gt; SDim encoderOutputEmbedDim
-&gt; SDim ffnDim
-&gt; Double
-&gt; Double
-&gt; TransformerDecoderStackSpec
     style
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     decoderInputEmbedDim
     encoderOutputEmbedDim
     ffnDim
forall (style :: TransformerStyle) (numLayers :: Nat)
       (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (headDim :: Dim (Name Symbol) (Size Nat))
       (headEmbedDim :: Dim (Name Symbol) (Size Nat))
       (embedDim :: Dim (Name Symbol) (Size Nat))
       (queryEmbedDim :: Dim (Name Symbol) (Size Nat))
       (keyEmbedDim :: Dim (Name Symbol) (Size Nat))
       (ffnDim :: Dim (Name Symbol) (Size Nat)).
STransformerStyle style
-&gt; SNat numLayers
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim headDim
-&gt; SDim headEmbedDim
-&gt; SDim embedDim
-&gt; SDim queryEmbedDim
-&gt; SDim keyEmbedDim
-&gt; SDim ffnDim
-&gt; Double
-&gt; Double
-&gt; TransformerDecoderStackSpec
     style
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     keyEmbedDim
     ffnDim
</span><a href="Torch.GraduallyTyped.NN.Transformer.DecoderStack.html#TransformerDecoderStackSpec"><span class="hs-identifier hs-var">TransformerDecoderStackSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="#local-6989586621679808664"><span class="hs-identifier hs-var">style</span></a></span><span> </span><span class="annot"><span class="annottext">SNat numLayers
</span><a href="#local-6989586621679808663"><span class="hs-identifier hs-var">numLayers</span></a></span><span> </span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679808662"><span class="hs-identifier hs-var">gradient</span></a></span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679808661"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679808660"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="annot"><span class="annottext">SDim headDim
</span><a href="#local-6989586621679808659"><span class="hs-identifier hs-var">headDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim headEmbedDim
</span><a href="#local-6989586621679808658"><span class="hs-identifier hs-var">headEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim embedDim
</span><a href="#local-6989586621679808657"><span class="hs-identifier hs-var">embedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim decoderInputEmbedDim
</span><a href="#local-6989586621679808656"><span class="hs-identifier hs-var">decoderInputEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim encoderOutputEmbedDim
</span><a href="#local-6989586621679808655"><span class="hs-identifier hs-var">encoderOutputEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ffnDim
</span><a href="#local-6989586621679808654"><span class="hs-identifier hs-var">ffnDim</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679808652"><span class="hs-identifier hs-var">dropoutP</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679808651"><span class="hs-identifier hs-var">eps</span></a></span><span>
</span><span id="line-236"></span><span>        </span><span id="local-6989586621679808644"><span class="annot"><span class="annottext">embedLayerNormSpec :: LayerNormSpec
  'WithBias gradient device dataType ('Shape '[decoderInputEmbedDim])
</span><a href="#local-6989586621679808644"><span class="hs-identifier hs-var hs-var">embedLayerNormSpec</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SHasBias 'WithBias
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SShape ('Shape '[decoderInputEmbedDim])
-&gt; Double
-&gt; LayerNormSpec
     'WithBias gradient device dataType ('Shape '[decoderInputEmbedDim])
forall (hasBias :: HasBias) (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (normalizedShape :: Shape [Dim (Name Symbol) (Size Nat)]).
SHasBias hasBias
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SShape normalizedShape
-&gt; Double
-&gt; LayerNormSpec hasBias gradient device dataType normalizedShape
</span><a href="Torch.GraduallyTyped.NN.Normalization.html#LayerNormSpec"><span class="hs-identifier hs-var">LayerNormSpec</span></a></span><span> </span><span class="annot"><span class="annottext">SHasBias 'WithBias
</span><a href="Torch.GraduallyTyped.NN.Type.html#SWithBias"><span class="hs-identifier hs-var">SWithBias</span></a></span><span> </span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679808662"><span class="hs-identifier hs-var">gradient</span></a></span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679808661"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679808660"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SList '[decoderInputEmbedDim]
-&gt; SShape ('Shape '[decoderInputEmbedDim])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList '[decoderInputEmbedDim]
 -&gt; SShape ('Shape '[decoderInputEmbedDim]))
-&gt; SList '[decoderInputEmbedDim]
-&gt; SShape ('Shape '[decoderInputEmbedDim])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SDim decoderInputEmbedDim
</span><a href="#local-6989586621679808656"><span class="hs-identifier hs-var">decoderInputEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim decoderInputEmbedDim
-&gt; SList '[] -&gt; SList '[decoderInputEmbedDim]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679808651"><span class="hs-identifier hs-var">eps</span></a></span><span>
</span><span id="line-237"></span><span>        </span><span id="local-6989586621679808641"><span class="annot"><span class="annottext">embedLayerNorm :: IxStateT m (Generator device) (Generator device) embedLayerNorm
</span><a href="#local-6989586621679808641"><span class="hs-identifier hs-var hs-var">embedLayerNorm</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(Generator device -&gt; m (embedLayerNorm, Generator device))
-&gt; IxStateT m (Generator device) (Generator device) embedLayerNorm
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator device -&gt; m (embedLayerNorm, Generator device))
 -&gt; IxStateT m (Generator device) (Generator device) embedLayerNorm)
-&gt; (ModelSpec embedLayerNorm
    -&gt; Generator device -&gt; m (embedLayerNorm, Generator device))
-&gt; ModelSpec embedLayerNorm
-&gt; IxStateT m (Generator device) (Generator device) embedLayerNorm
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">forall model (generatorDevice :: Device (DeviceType Nat)) output
       (generatorOutputDevice :: Device (DeviceType Nat)) (m :: * -&gt; *).
(HasInitialize model generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
ModelSpec model
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
forall (generatorDevice :: Device (DeviceType Nat)) output
       (generatorOutputDevice :: Device (DeviceType Nat)) (m :: * -&gt; *).
(HasInitialize
   embedLayerNorm generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
ModelSpec embedLayerNorm
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#initialize"><span class="hs-identifier hs-var">initialize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679808674"><span class="hs-identifier hs-type">embedLayerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">(ModelSpec embedLayerNorm
 -&gt; IxStateT m (Generator device) (Generator device) embedLayerNorm)
-&gt; ModelSpec embedLayerNorm
-&gt; IxStateT m (Generator device) (Generator device) embedLayerNorm
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-keyword">case</span><span> </span><span class="annot"><span class="annottext">SingI style =&gt; Sing style
forall k (a :: k). SingI a =&gt; Sing a
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">sing</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679808686"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="hs-keyword">of</span><span>
</span><span id="line-238"></span><span>          </span><span class="annot"><span class="annottext">Sing style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-239"></span><span>          </span><span class="annot"><span class="annottext">Sing style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-240"></span><span>          </span><span class="annot"><span class="annottext">Sing style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">ModelSpec embedLayerNorm
LayerNormSpec
  'WithBias gradient device dataType ('Shape '[decoderInputEmbedDim])
</span><a href="#local-6989586621679808644"><span class="hs-identifier hs-var">embedLayerNormSpec</span></a></span><span>
</span><span id="line-241"></span><span>          </span><span class="annot"><span class="annottext">Sing style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">ModelSpec embedLayerNorm
LayerNormSpec
  'WithBias gradient device dataType ('Shape '[decoderInputEmbedDim])
</span><a href="#local-6989586621679808644"><span class="hs-identifier hs-var">embedLayerNormSpec</span></a></span><span>
</span><span id="line-242"></span><span>          </span><span class="annot"><span class="annottext">Sing style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-243"></span><span>          </span><span class="annot"><span class="annottext">Sing style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">ModelSpec embedLayerNorm
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-244"></span><span>          </span><span class="annot"><span class="annottext">Sing style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">ModelSpec embedLayerNorm
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-245"></span><span>          </span><span class="annot"><span class="annottext">Sing style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SGPT2"><span class="hs-identifier hs-var">SGPT2</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">ModelSpec embedLayerNorm
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-246"></span><span>        </span><span id="local-6989586621679808631"><span class="annot"><span class="annottext">layerNormWithoutBiasSpec :: LayerNormSpec
  'WithoutBias
  gradient
  device
  dataType
  ('Shape '[decoderInputEmbedDim])
</span><a href="#local-6989586621679808631"><span class="hs-identifier hs-var hs-var">layerNormWithoutBiasSpec</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SHasBias 'WithoutBias
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SShape ('Shape '[decoderInputEmbedDim])
-&gt; Double
-&gt; LayerNormSpec
     'WithoutBias
     gradient
     device
     dataType
     ('Shape '[decoderInputEmbedDim])
forall (hasBias :: HasBias) (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (normalizedShape :: Shape [Dim (Name Symbol) (Size Nat)]).
SHasBias hasBias
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SShape normalizedShape
-&gt; Double
-&gt; LayerNormSpec hasBias gradient device dataType normalizedShape
</span><a href="Torch.GraduallyTyped.NN.Normalization.html#LayerNormSpec"><span class="hs-identifier hs-var">LayerNormSpec</span></a></span><span> </span><span class="annot"><span class="annottext">SHasBias 'WithoutBias
</span><a href="Torch.GraduallyTyped.NN.Type.html#SWithoutBias"><span class="hs-identifier hs-var">SWithoutBias</span></a></span><span> </span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679808662"><span class="hs-identifier hs-var">gradient</span></a></span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679808661"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679808660"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SList '[decoderInputEmbedDim]
-&gt; SShape ('Shape '[decoderInputEmbedDim])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList '[decoderInputEmbedDim]
 -&gt; SShape ('Shape '[decoderInputEmbedDim]))
-&gt; SList '[decoderInputEmbedDim]
-&gt; SShape ('Shape '[decoderInputEmbedDim])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SDim decoderInputEmbedDim
</span><a href="#local-6989586621679808656"><span class="hs-identifier hs-var">decoderInputEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim decoderInputEmbedDim
-&gt; SList '[] -&gt; SList '[decoderInputEmbedDim]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679808651"><span class="hs-identifier hs-var">eps</span></a></span><span>
</span><span id="line-247"></span><span>        </span><span id="local-6989586621679808630"><span class="annot"><span class="annottext">layerNormWithBiasSpec :: LayerNormSpec
  'WithBias gradient device dataType ('Shape '[decoderInputEmbedDim])
</span><a href="#local-6989586621679808630"><span class="hs-identifier hs-var hs-var">layerNormWithBiasSpec</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SHasBias 'WithBias
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SShape ('Shape '[decoderInputEmbedDim])
-&gt; Double
-&gt; LayerNormSpec
     'WithBias gradient device dataType ('Shape '[decoderInputEmbedDim])
forall (hasBias :: HasBias) (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (normalizedShape :: Shape [Dim (Name Symbol) (Size Nat)]).
SHasBias hasBias
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SShape normalizedShape
-&gt; Double
-&gt; LayerNormSpec hasBias gradient device dataType normalizedShape
</span><a href="Torch.GraduallyTyped.NN.Normalization.html#LayerNormSpec"><span class="hs-identifier hs-var">LayerNormSpec</span></a></span><span> </span><span class="annot"><span class="annottext">SHasBias 'WithBias
</span><a href="Torch.GraduallyTyped.NN.Type.html#SWithBias"><span class="hs-identifier hs-var">SWithBias</span></a></span><span> </span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679808662"><span class="hs-identifier hs-var">gradient</span></a></span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679808661"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679808660"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SList '[decoderInputEmbedDim]
-&gt; SShape ('Shape '[decoderInputEmbedDim])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList '[decoderInputEmbedDim]
 -&gt; SShape ('Shape '[decoderInputEmbedDim]))
-&gt; SList '[decoderInputEmbedDim]
-&gt; SShape ('Shape '[decoderInputEmbedDim])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SDim decoderInputEmbedDim
</span><a href="#local-6989586621679808656"><span class="hs-identifier hs-var">decoderInputEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim decoderInputEmbedDim
-&gt; SList '[] -&gt; SList '[decoderInputEmbedDim]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679808651"><span class="hs-identifier hs-var">eps</span></a></span><span>
</span><span id="line-248"></span><span>        </span><span id="local-6989586621679808629"><span class="annot"><span class="annottext">layerNorm :: IxStateT m (Generator device) (Generator device) layerNorm
</span><a href="#local-6989586621679808629"><span class="hs-identifier hs-var hs-var">layerNorm</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(Generator device -&gt; m (layerNorm, Generator device))
-&gt; IxStateT m (Generator device) (Generator device) layerNorm
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator device -&gt; m (layerNorm, Generator device))
 -&gt; IxStateT m (Generator device) (Generator device) layerNorm)
-&gt; (ModelSpec layerNorm
    -&gt; Generator device -&gt; m (layerNorm, Generator device))
-&gt; ModelSpec layerNorm
-&gt; IxStateT m (Generator device) (Generator device) layerNorm
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">forall model (generatorDevice :: Device (DeviceType Nat)) output
       (generatorOutputDevice :: Device (DeviceType Nat)) (m :: * -&gt; *).
(HasInitialize model generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
ModelSpec model
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
forall (generatorDevice :: Device (DeviceType Nat)) output
       (generatorOutputDevice :: Device (DeviceType Nat)) (m :: * -&gt; *).
(HasInitialize
   layerNorm generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
ModelSpec layerNorm
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#initialize"><span class="hs-identifier hs-var">initialize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679808673"><span class="hs-identifier hs-type">layerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">(ModelSpec layerNorm
 -&gt; IxStateT m (Generator device) (Generator device) layerNorm)
-&gt; ModelSpec layerNorm
-&gt; IxStateT m (Generator device) (Generator device) layerNorm
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-keyword">case</span><span> </span><span class="annot"><span class="annottext">SingI style =&gt; Sing style
forall k (a :: k). SingI a =&gt; Sing a
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">sing</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679808686"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="hs-keyword">of</span><span>
</span><span id="line-249"></span><span>          </span><span class="annot"><span class="annottext">Sing style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">ModelSpec layerNorm
LayerNormSpec
  'WithoutBias
  gradient
  device
  dataType
  ('Shape '[decoderInputEmbedDim])
</span><a href="#local-6989586621679808631"><span class="hs-identifier hs-var">layerNormWithoutBiasSpec</span></a></span><span>
</span><span id="line-250"></span><span>          </span><span class="annot"><span class="annottext">Sing style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">ModelSpec layerNorm
LayerNormSpec
  'WithoutBias
  gradient
  device
  dataType
  ('Shape '[decoderInputEmbedDim])
</span><a href="#local-6989586621679808631"><span class="hs-identifier hs-var">layerNormWithoutBiasSpec</span></a></span><span>
</span><span id="line-251"></span><span>          </span><span class="annot"><span class="annottext">Sing style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-252"></span><span>          </span><span class="annot"><span class="annottext">Sing style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-253"></span><span>          </span><span class="annot"><span class="annottext">Sing style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">ModelSpec layerNorm
LayerNormSpec
  'WithBias gradient device dataType ('Shape '[decoderInputEmbedDim])
</span><a href="#local-6989586621679808630"><span class="hs-identifier hs-var">layerNormWithBiasSpec</span></a></span><span>
</span><span id="line-254"></span><span>          </span><span class="annot"><span class="annottext">Sing style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">ModelSpec layerNorm
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-255"></span><span>          </span><span class="annot"><span class="annottext">Sing style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">ModelSpec layerNorm
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-256"></span><span>          </span><span class="annot"><span class="annottext">Sing style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SGPT2"><span class="hs-identifier hs-var">SGPT2</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">ModelSpec layerNorm
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-257"></span><span>        </span><span id="local-6989586621679808628"><span class="annot"><span class="annottext">dropout :: IxStateT m (Generator device) (Generator device) Dropout
</span><a href="#local-6989586621679808628"><span class="hs-identifier hs-var hs-var">dropout</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(Generator device -&gt; m (Dropout, Generator device))
-&gt; IxStateT m (Generator device) (Generator device) Dropout
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator device -&gt; m (Dropout, Generator device))
 -&gt; IxStateT m (Generator device) (Generator device) Dropout)
-&gt; (Dropout -&gt; Generator device -&gt; m (Dropout, Generator device))
-&gt; Dropout
-&gt; IxStateT m (Generator device) (Generator device) Dropout
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">forall model (generatorDevice :: Device (DeviceType Nat)) output
       (generatorOutputDevice :: Device (DeviceType Nat)) (m :: * -&gt; *).
(HasInitialize model generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
ModelSpec model
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
forall (generatorDevice :: Device (DeviceType Nat)) output
       (generatorOutputDevice :: Device (DeviceType Nat)) (m :: * -&gt; *).
(HasInitialize
   dropout generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
ModelSpec dropout
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#initialize"><span class="hs-identifier hs-var">initialize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679808672"><span class="hs-identifier hs-type">dropout</span></a></span><span> </span><span class="annot"><span class="annottext">(Dropout
 -&gt; IxStateT m (Generator device) (Generator device) Dropout)
-&gt; Dropout
-&gt; IxStateT m (Generator device) (Generator device) Dropout
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">Double -&gt; Dropout
</span><a href="Torch.GraduallyTyped.NN.Dropout.html#Dropout"><span class="hs-identifier hs-var">Dropout</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679808652"><span class="hs-identifier hs-var">dropoutP</span></a></span><span>
</span><span id="line-258"></span><span>        </span><span id="local-6989586621679808626"><span class="annot"><span class="annottext">relPosEncSpec :: EmbeddingSpec
  gradient
  ('Layout 'Dense)
  device
  dataType
  posEncDim
  headDim
  'Nothing
</span><a href="#local-6989586621679808626"><span class="hs-identifier hs-var hs-var">relPosEncSpec</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SGradient gradient
-&gt; SLayout ('Layout 'Dense)
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim posEncDim
-&gt; SDim headDim
-&gt; SMaybe 'Nothing
-&gt; EmbeddingSpec
     gradient
     ('Layout 'Dense)
     device
     dataType
     posEncDim
     headDim
     'Nothing
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (embedNumDim :: Dim (Name Symbol) (Size Nat))
       (embedDim :: Dim (Name Symbol) (Size Nat))
       (paddingIdx :: Maybe Nat).
SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim embedNumDim
-&gt; SDim embedDim
-&gt; SMaybe paddingIdx
-&gt; EmbeddingSpec
     gradient layout device dataType embedNumDim embedDim paddingIdx
</span><a href="Torch.GraduallyTyped.NN.Sparse.html#EmbeddingSpec"><span class="hs-identifier hs-var">EmbeddingSpec</span></a></span><span> </span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679808662"><span class="hs-identifier hs-var">gradient</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SLayoutType 'Dense -&gt; SLayout ('Layout 'Dense)
forall (layoutType :: LayoutType).
SLayoutType layoutType -&gt; SLayout ('Layout layoutType)
</span><a href="Torch.GraduallyTyped.Layout.html#SLayout"><span class="hs-identifier hs-var">SLayout</span></a></span><span> </span><span class="annot"><span class="annottext">SLayoutType 'Dense
</span><a href="Torch.GraduallyTyped.Layout.html#SDense"><span class="hs-identifier hs-var">SDense</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679808661"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679808660"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="annot"><span class="annottext">SDim posEncDim
</span><a href="#local-6989586621679808653"><span class="hs-identifier hs-var">posEncDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim headDim
</span><a href="#local-6989586621679808659"><span class="hs-identifier hs-var">headDim</span></a></span><span> </span><span class="annot"><span class="annottext">SMaybe 'Nothing
forall a. SMaybe 'Nothing
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNothing</span></a></span><span>
</span><span id="line-259"></span><span>        </span><span id="local-6989586621679808622"><span class="annot"><span class="annottext">posEncSpec :: EmbeddingSpec
  gradient
  ('Layout 'Dense)
  device
  dataType
  posEncDim
  decoderInputEmbedDim
  'Nothing
</span><a href="#local-6989586621679808622"><span class="hs-identifier hs-var hs-var">posEncSpec</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SGradient gradient
-&gt; SLayout ('Layout 'Dense)
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim posEncDim
-&gt; SDim decoderInputEmbedDim
-&gt; SMaybe 'Nothing
-&gt; EmbeddingSpec
     gradient
     ('Layout 'Dense)
     device
     dataType
     posEncDim
     decoderInputEmbedDim
     'Nothing
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (embedNumDim :: Dim (Name Symbol) (Size Nat))
       (embedDim :: Dim (Name Symbol) (Size Nat))
       (paddingIdx :: Maybe Nat).
SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim embedNumDim
-&gt; SDim embedDim
-&gt; SMaybe paddingIdx
-&gt; EmbeddingSpec
     gradient layout device dataType embedNumDim embedDim paddingIdx
</span><a href="Torch.GraduallyTyped.NN.Sparse.html#EmbeddingSpec"><span class="hs-identifier hs-var">EmbeddingSpec</span></a></span><span> </span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679808662"><span class="hs-identifier hs-var">gradient</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SLayoutType 'Dense -&gt; SLayout ('Layout 'Dense)
forall (layoutType :: LayoutType).
SLayoutType layoutType -&gt; SLayout ('Layout layoutType)
</span><a href="Torch.GraduallyTyped.Layout.html#SLayout"><span class="hs-identifier hs-var">SLayout</span></a></span><span> </span><span class="annot"><span class="annottext">SLayoutType 'Dense
</span><a href="Torch.GraduallyTyped.Layout.html#SDense"><span class="hs-identifier hs-var">SDense</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679808661"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679808660"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="annot"><span class="annottext">SDim posEncDim
</span><a href="#local-6989586621679808653"><span class="hs-identifier hs-var">posEncDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim decoderInputEmbedDim
</span><a href="#local-6989586621679808656"><span class="hs-identifier hs-var">decoderInputEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SMaybe 'Nothing
forall a. SMaybe 'Nothing
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNothing</span></a></span><span>
</span><span id="line-260"></span><span>        </span><span id="local-6989586621679808621"><span class="annot"><span class="annottext">posEnc :: IxStateT m (Generator device) (Generator device) posEnc
</span><a href="#local-6989586621679808621"><span class="hs-identifier hs-var hs-var">posEnc</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(Generator device -&gt; m (posEnc, Generator device))
-&gt; IxStateT m (Generator device) (Generator device) posEnc
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator device -&gt; m (posEnc, Generator device))
 -&gt; IxStateT m (Generator device) (Generator device) posEnc)
-&gt; (ModelSpec posEnc
    -&gt; Generator device -&gt; m (posEnc, Generator device))
-&gt; ModelSpec posEnc
-&gt; IxStateT m (Generator device) (Generator device) posEnc
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">forall model (generatorDevice :: Device (DeviceType Nat)) output
       (generatorOutputDevice :: Device (DeviceType Nat)) (m :: * -&gt; *).
(HasInitialize model generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
ModelSpec model
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
forall (generatorDevice :: Device (DeviceType Nat)) output
       (generatorOutputDevice :: Device (DeviceType Nat)) (m :: * -&gt; *).
(HasInitialize posEnc generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
ModelSpec posEnc
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#initialize"><span class="hs-identifier hs-var">initialize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679808671"><span class="hs-identifier hs-type">posEnc</span></a></span><span> </span><span class="annot"><span class="annottext">(ModelSpec posEnc
 -&gt; IxStateT m (Generator device) (Generator device) posEnc)
-&gt; ModelSpec posEnc
-&gt; IxStateT m (Generator device) (Generator device) posEnc
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-keyword">case</span><span> </span><span class="annot"><span class="annottext">SingI style =&gt; Sing style
forall k (a :: k). SingI a =&gt; Sing a
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">sing</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679808686"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="hs-keyword">of</span><span>
</span><span id="line-261"></span><span>          </span><span class="annot"><span class="annottext">Sing style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">ModelSpec posEnc
EmbeddingSpec
  gradient
  ('Layout 'Dense)
  device
  dataType
  posEncDim
  headDim
  'Nothing
</span><a href="#local-6989586621679808626"><span class="hs-identifier hs-var">relPosEncSpec</span></a></span><span>
</span><span id="line-262"></span><span>          </span><span class="annot"><span class="annottext">Sing style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">ModelSpec posEnc
EmbeddingSpec
  gradient
  ('Layout 'Dense)
  device
  dataType
  posEncDim
  headDim
  'Nothing
</span><a href="#local-6989586621679808626"><span class="hs-identifier hs-var">relPosEncSpec</span></a></span><span>
</span><span id="line-263"></span><span>          </span><span class="annot"><span class="annottext">Sing style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">ModelSpec posEnc
EmbeddingSpec
  gradient
  ('Layout 'Dense)
  device
  dataType
  posEncDim
  decoderInputEmbedDim
  'Nothing
</span><a href="#local-6989586621679808622"><span class="hs-identifier hs-var">posEncSpec</span></a></span><span>
</span><span id="line-264"></span><span>          </span><span class="annot"><span class="annottext">Sing style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">ModelSpec posEnc
EmbeddingSpec
  gradient
  ('Layout 'Dense)
  device
  dataType
  posEncDim
  decoderInputEmbedDim
  'Nothing
</span><a href="#local-6989586621679808622"><span class="hs-identifier hs-var">posEncSpec</span></a></span><span>
</span><span id="line-265"></span><span>          </span><span class="annot"><span class="annottext">Sing style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">ModelSpec posEnc
EmbeddingSpec
  gradient
  ('Layout 'Dense)
  device
  dataType
  posEncDim
  decoderInputEmbedDim
  'Nothing
</span><a href="#local-6989586621679808622"><span class="hs-identifier hs-var">posEncSpec</span></a></span><span>
</span><span id="line-266"></span><span>          </span><span class="annot"><span class="annottext">Sing style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">ModelSpec posEnc
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-267"></span><span>          </span><span class="annot"><span class="annottext">Sing style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">ModelSpec posEnc
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-268"></span><span>          </span><span class="annot"><span class="annottext">Sing style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SGPT2"><span class="hs-identifier hs-var">SGPT2</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">ModelSpec posEnc
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-269"></span><span>        </span><span id="local-6989586621679808620"><span class="annot"><span class="annottext">gtd :: IxStateT
  m
  (Generator device)
  (Generator device)
  (GTransformerDecoder
     (TransformerDecoderStack
        style
        numLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        decoderInputEmbedDim
        encoderOutputEmbedDim
        ffnDim)
     embedLayerNorm
     layerNorm
     Dropout
     posEnc)
</span><a href="#local-6989586621679808620"><span class="hs-identifier hs-var hs-var">gtd</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-270"></span><span>          </span><span class="annot"><span class="annottext">TransformerDecoderStack
  style
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  decoderInputEmbedDim
  encoderOutputEmbedDim
  ffnDim
-&gt; embedLayerNorm
-&gt; layerNorm
-&gt; Dropout
-&gt; posEnc
-&gt; GTransformerDecoder
     (TransformerDecoderStack
        style
        numLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        decoderInputEmbedDim
        encoderOutputEmbedDim
        ffnDim)
     embedLayerNorm
     layerNorm
     Dropout
     posEnc
forall stack embedLayerNorm layerNorm dropout posEnc.
stack
-&gt; embedLayerNorm
-&gt; layerNorm
-&gt; dropout
-&gt; posEnc
-&gt; GTransformerDecoder
     stack embedLayerNorm layerNorm dropout posEnc
</span><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#GTransformerDecoder"><span class="hs-identifier hs-var">GTransformerDecoder</span></a></span><span>
</span><span id="line-271"></span><span>            </span><span class="annot"><span class="annottext">(TransformerDecoderStack
   style
   numLayers
   gradient
   device
   dataType
   headDim
   headEmbedDim
   embedDim
   decoderInputEmbedDim
   encoderOutputEmbedDim
   ffnDim
 -&gt; embedLayerNorm
 -&gt; layerNorm
 -&gt; Dropout
 -&gt; posEnc
 -&gt; GTransformerDecoder
      (TransformerDecoderStack
         style
         numLayers
         gradient
         device
         dataType
         headDim
         headEmbedDim
         embedDim
         decoderInputEmbedDim
         encoderOutputEmbedDim
         ffnDim)
      embedLayerNorm
      layerNorm
      Dropout
      posEnc)
-&gt; IxStateT
     m
     (Generator device)
     (Generator device)
     (TransformerDecoderStack
        style
        numLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        decoderInputEmbedDim
        encoderOutputEmbedDim
        ffnDim)
-&gt; IxStateT
     m
     (Generator device)
     (Generator device)
     (embedLayerNorm
      -&gt; layerNorm
      -&gt; Dropout
      -&gt; posEnc
      -&gt; GTransformerDecoder
           (TransformerDecoderStack
              style
              numLayers
              gradient
              device
              dataType
              headDim
              headEmbedDim
              embedDim
              decoderInputEmbedDim
              encoderOutputEmbedDim
              ffnDim)
           embedLayerNorm
           layerNorm
           Dropout
           posEnc)
forall k1 k2 (f :: k1 -&gt; k2 -&gt; * -&gt; *) a b (j :: k1) (k3 :: k2).
IxFunctor f =&gt;
(a -&gt; b) -&gt; f j k3 a -&gt; f j k3 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&lt;&lt;$&gt;&gt;</span></a></span><span> </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator device)
  (Generator device)
  (TransformerDecoderStack
     style
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     decoderInputEmbedDim
     encoderOutputEmbedDim
     ffnDim)
</span><a href="#local-6989586621679808648"><span class="hs-identifier hs-var">decoderStack</span></a></span><span>
</span><span id="line-272"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator device)
  (Generator device)
  (embedLayerNorm
   -&gt; layerNorm
   -&gt; Dropout
   -&gt; posEnc
   -&gt; GTransformerDecoder
        (TransformerDecoderStack
           style
           numLayers
           gradient
           device
           dataType
           headDim
           headEmbedDim
           embedDim
           decoderInputEmbedDim
           encoderOutputEmbedDim
           ffnDim)
        embedLayerNorm
        layerNorm
        Dropout
        posEnc)
-&gt; IxStateT m (Generator device) (Generator device) embedLayerNorm
-&gt; IxStateT
     m
     (Generator device)
     (Generator device)
     (layerNorm
      -&gt; Dropout
      -&gt; posEnc
      -&gt; GTransformerDecoder
           (TransformerDecoderStack
              style
              numLayers
              gradient
              device
              dataType
              headDim
              headEmbedDim
              embedDim
              decoderInputEmbedDim
              encoderOutputEmbedDim
              ffnDim)
           embedLayerNorm
           layerNorm
           Dropout
           posEnc)
forall k1 (f :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a b
       (k2 :: k1).
IxApplicative f =&gt;
f i j (a -&gt; b) -&gt; f j k2 a -&gt; f i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&lt;&lt;*&gt;&gt;</span></a></span><span> </span><span class="annot"><span class="annottext">IxStateT m (Generator device) (Generator device) embedLayerNorm
</span><a href="#local-6989586621679808641"><span class="hs-identifier hs-var">embedLayerNorm</span></a></span><span>
</span><span id="line-273"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator device)
  (Generator device)
  (layerNorm
   -&gt; Dropout
   -&gt; posEnc
   -&gt; GTransformerDecoder
        (TransformerDecoderStack
           style
           numLayers
           gradient
           device
           dataType
           headDim
           headEmbedDim
           embedDim
           decoderInputEmbedDim
           encoderOutputEmbedDim
           ffnDim)
        embedLayerNorm
        layerNorm
        Dropout
        posEnc)
-&gt; IxStateT m (Generator device) (Generator device) layerNorm
-&gt; IxStateT
     m
     (Generator device)
     (Generator device)
     (Dropout
      -&gt; posEnc
      -&gt; GTransformerDecoder
           (TransformerDecoderStack
              style
              numLayers
              gradient
              device
              dataType
              headDim
              headEmbedDim
              embedDim
              decoderInputEmbedDim
              encoderOutputEmbedDim
              ffnDim)
           embedLayerNorm
           layerNorm
           Dropout
           posEnc)
forall k1 (f :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a b
       (k2 :: k1).
IxApplicative f =&gt;
f i j (a -&gt; b) -&gt; f j k2 a -&gt; f i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&lt;&lt;*&gt;&gt;</span></a></span><span> </span><span class="annot"><span class="annottext">IxStateT m (Generator device) (Generator device) layerNorm
</span><a href="#local-6989586621679808629"><span class="hs-identifier hs-var">layerNorm</span></a></span><span>
</span><span id="line-274"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator device)
  (Generator device)
  (Dropout
   -&gt; posEnc
   -&gt; GTransformerDecoder
        (TransformerDecoderStack
           style
           numLayers
           gradient
           device
           dataType
           headDim
           headEmbedDim
           embedDim
           decoderInputEmbedDim
           encoderOutputEmbedDim
           ffnDim)
        embedLayerNorm
        layerNorm
        Dropout
        posEnc)
-&gt; IxStateT m (Generator device) (Generator device) Dropout
-&gt; IxStateT
     m
     (Generator device)
     (Generator device)
     (posEnc
      -&gt; GTransformerDecoder
           (TransformerDecoderStack
              style
              numLayers
              gradient
              device
              dataType
              headDim
              headEmbedDim
              embedDim
              decoderInputEmbedDim
              encoderOutputEmbedDim
              ffnDim)
           embedLayerNorm
           layerNorm
           Dropout
           posEnc)
forall k1 (f :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a b
       (k2 :: k1).
IxApplicative f =&gt;
f i j (a -&gt; b) -&gt; f j k2 a -&gt; f i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&lt;&lt;*&gt;&gt;</span></a></span><span> </span><span class="annot"><span class="annottext">IxStateT m (Generator device) (Generator device) Dropout
</span><a href="#local-6989586621679808628"><span class="hs-identifier hs-var">dropout</span></a></span><span>
</span><span id="line-275"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator device)
  (Generator device)
  (posEnc
   -&gt; GTransformerDecoder
        (TransformerDecoderStack
           style
           numLayers
           gradient
           device
           dataType
           headDim
           headEmbedDim
           embedDim
           decoderInputEmbedDim
           encoderOutputEmbedDim
           ffnDim)
        embedLayerNorm
        layerNorm
        Dropout
        posEnc)
-&gt; IxStateT m (Generator device) (Generator device) posEnc
-&gt; IxStateT
     m
     (Generator device)
     (Generator device)
     (GTransformerDecoder
        (TransformerDecoderStack
           style
           numLayers
           gradient
           device
           dataType
           headDim
           headEmbedDim
           embedDim
           decoderInputEmbedDim
           encoderOutputEmbedDim
           ffnDim)
        embedLayerNorm
        layerNorm
        Dropout
        posEnc)
forall k1 (f :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a b
       (k2 :: k1).
IxApplicative f =&gt;
f i j (a -&gt; b) -&gt; f j k2 a -&gt; f i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&lt;&lt;*&gt;&gt;</span></a></span><span> </span><span class="annot"><span class="annottext">IxStateT m (Generator device) (Generator device) posEnc
</span><a href="#local-6989586621679808621"><span class="hs-identifier hs-var">posEnc</span></a></span><span>
</span><span id="line-276"></span><span>     </span><span class="hs-keyword">in</span><span> </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator device)
  (Generator device)
  (TransformerDecoder
     style
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     decoderInputEmbedDim
     encoderOutputEmbedDim
     ffnDim
     posEncDim)
-&gt; Generator device
-&gt; m (TransformerDecoder
        style
        numLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        decoderInputEmbedDim
        encoderOutputEmbedDim
        ffnDim
        posEncDim,
      Generator device)
forall (m :: * -&gt; *) i j a. IxStateT m i j a -&gt; i -&gt; m (a, j)
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var hs-var">runIxStateT</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator device)
  (Generator device)
  (GTransformerDecoder
     (TransformerDecoderStack
        style
        numLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        decoderInputEmbedDim
        encoderOutputEmbedDim
        ffnDim)
     embedLayerNorm
     layerNorm
     Dropout
     posEnc)
</span><a href="#local-6989586621679808620"><span class="hs-identifier hs-var">gtd</span></a></span><span> </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator device)
  (Generator device)
  (GTransformerDecoder
     (TransformerDecoderStack
        style
        numLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        decoderInputEmbedDim
        encoderOutputEmbedDim
        ffnDim)
     embedLayerNorm
     layerNorm
     Dropout
     posEnc)
-&gt; (GTransformerDecoder
      (TransformerDecoderStack
         style
         numLayers
         gradient
         device
         dataType
         headDim
         headEmbedDim
         embedDim
         decoderInputEmbedDim
         encoderOutputEmbedDim
         ffnDim)
      embedLayerNorm
      layerNorm
      Dropout
      posEnc
    -&gt; IxStateT
         m
         (Generator device)
         (Generator device)
         (TransformerDecoder
            style
            numLayers
            gradient
            device
            dataType
            headDim
            headEmbedDim
            embedDim
            decoderInputEmbedDim
            encoderOutputEmbedDim
            ffnDim
            posEncDim))
-&gt; IxStateT
     m
     (Generator device)
     (Generator device)
     (TransformerDecoder
        style
        numLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        decoderInputEmbedDim
        encoderOutputEmbedDim
        ffnDim
        posEncDim)
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">TransformerDecoder
  style
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  decoderInputEmbedDim
  encoderOutputEmbedDim
  ffnDim
  posEncDim
-&gt; IxStateT
     m
     (Generator device)
     (Generator device)
     (TransformerDecoder
        style
        numLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        decoderInputEmbedDim
        encoderOutputEmbedDim
        ffnDim
        posEncDim)
forall k (m :: k -&gt; k -&gt; * -&gt; *) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">(TransformerDecoder
   style
   numLayers
   gradient
   device
   dataType
   headDim
   headEmbedDim
   embedDim
   decoderInputEmbedDim
   encoderOutputEmbedDim
   ffnDim
   posEncDim
 -&gt; IxStateT
      m
      (Generator device)
      (Generator device)
      (TransformerDecoder
         style
         numLayers
         gradient
         device
         dataType
         headDim
         headEmbedDim
         embedDim
         decoderInputEmbedDim
         encoderOutputEmbedDim
         ffnDim
         posEncDim))
-&gt; (GTransformerDecoder
      (TransformerDecoderStack
         style
         numLayers
         gradient
         device
         dataType
         headDim
         headEmbedDim
         embedDim
         decoderInputEmbedDim
         encoderOutputEmbedDim
         ffnDim)
      embedLayerNorm
      layerNorm
      Dropout
      posEnc
    -&gt; TransformerDecoder
         style
         numLayers
         gradient
         device
         dataType
         headDim
         headEmbedDim
         embedDim
         decoderInputEmbedDim
         encoderOutputEmbedDim
         ffnDim
         posEncDim)
-&gt; GTransformerDecoder
     (TransformerDecoderStack
        style
        numLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        decoderInputEmbedDim
        encoderOutputEmbedDim
        ffnDim)
     embedLayerNorm
     layerNorm
     Dropout
     posEnc
-&gt; IxStateT
     m
     (Generator device)
     (Generator device)
     (TransformerDecoder
        style
        numLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        decoderInputEmbedDim
        encoderOutputEmbedDim
        ffnDim
        posEncDim)
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">GTransformerDecoder
  (TransformerDecoderStack
     style
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     decoderInputEmbedDim
     encoderOutputEmbedDim
     ffnDim)
  embedLayerNorm
  layerNorm
  Dropout
  posEnc
-&gt; TransformerDecoder
     style
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     decoderInputEmbedDim
     encoderOutputEmbedDim
     ffnDim
     posEncDim
forall (style :: TransformerStyle) (numLayers :: Nat)
       (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (headDim :: Dim (Name Symbol) (Size Nat))
       (headEmbedDim :: Dim (Name Symbol) (Size Nat))
       (embedDim :: Dim (Name Symbol) (Size Nat))
       (decoderInputEmbedDim :: Dim (Name Symbol) (Size Nat))
       (encoderOutputEmbedDim :: Dim (Name Symbol) (Size Nat))
       (ffnDim :: Dim (Name Symbol) (Size Nat))
       (posEncDim :: Dim (Name Symbol) (Size Nat)).
GTransformerDecoder
  (TDStackF
     style
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     decoderInputEmbedDim
     encoderOutputEmbedDim
     ffnDim)
  (TDEmbedLayerNormF
     style gradient device dataType decoderInputEmbedDim)
  (TDLayerNormF style gradient device dataType decoderInputEmbedDim)
  (TDDropoutF style)
  (TDPosEncF
     style
     gradient
     device
     dataType
     headDim
     decoderInputEmbedDim
     posEncDim)
-&gt; TransformerDecoder
     style
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     decoderInputEmbedDim
     encoderOutputEmbedDim
     ffnDim
     posEncDim
</span><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TransformerDecoder"><span class="hs-identifier hs-var">TransformerDecoder</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Generator device
</span><a href="#local-6989586621679808649"><span class="hs-identifier hs-var">generator'</span></a></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span>
</span><span id="line-277"></span><span>
</span><span id="line-278"></span><span id="local-6989586621679808607"><span id="local-6989586621679808608"><span id="local-6989586621679808609"><span id="local-6989586621679808610"><span id="local-6989586621679808611"><span id="local-6989586621679808612"><span id="local-6989586621679808613"><span id="local-6989586621679808614"><span id="local-6989586621679808615"><span id="local-6989586621679808616"><span id="local-6989586621679808617"><span id="local-6989586621679808618"><span class="hs-keyword">instance</span><span>
</span><span id="line-279"></span><span>  </span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-type">SingI</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808618"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-280"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasStateDict"><span class="hs-identifier hs-type">HasStateDict</span></a></span><span>
</span><span id="line-281"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TransformerDecoder"><span class="hs-identifier hs-type">TransformerDecoder</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808618"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808617"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808616"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808615"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808614"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808613"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808612"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808611"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808610"><span class="hs-identifier hs-type">decoderInputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808609"><span class="hs-identifier hs-type">encoderOutputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808608"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808607"><span class="hs-identifier hs-type">posEncDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-282"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-283"></span><span>  </span><span id="local-6989586621679808603"><span class="annot"><span class="annottext">fromStateDict :: ModelSpec
  (TransformerDecoder
     style
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     decoderInputEmbedDim
     encoderOutputEmbedDim
     ffnDim
     posEncDim)
-&gt; StateDictKey
-&gt; m (TransformerDecoder
        style
        numLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        decoderInputEmbedDim
        encoderOutputEmbedDim
        ffnDim
        posEncDim)
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var hs-var hs-var hs-var">fromStateDict</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TransformerDecoderSpec"><span class="hs-identifier hs-type">TransformerDecoderSpec</span></a></span><span> </span><span id="local-6989586621679808601"><span class="annot"><a href="#local-6989586621679808601"><span class="hs-identifier hs-var">style</span></a></span></span><span> </span><span id="local-6989586621679808600"><span class="annot"><a href="#local-6989586621679808600"><span class="hs-identifier hs-var">numLayers</span></a></span></span><span> </span><span id="local-6989586621679808599"><span class="annot"><a href="#local-6989586621679808599"><span class="hs-identifier hs-var">gradient</span></a></span></span><span> </span><span id="local-6989586621679808598"><span class="annot"><a href="#local-6989586621679808598"><span class="hs-identifier hs-var">device</span></a></span></span><span> </span><span id="local-6989586621679808597"><span class="annot"><a href="#local-6989586621679808597"><span class="hs-identifier hs-var">dataType</span></a></span></span><span> </span><span id="local-6989586621679808596"><span class="annot"><a href="#local-6989586621679808596"><span class="hs-identifier hs-var">headDim</span></a></span></span><span> </span><span id="local-6989586621679808595"><span class="annot"><a href="#local-6989586621679808595"><span class="hs-identifier hs-var">headEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679808594"><span class="annot"><a href="#local-6989586621679808594"><span class="hs-identifier hs-var">embedDim</span></a></span></span><span> </span><span id="local-6989586621679808593"><span class="annot"><a href="#local-6989586621679808593"><span class="hs-identifier hs-var">decoderInputEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679808592"><span class="annot"><a href="#local-6989586621679808592"><span class="hs-identifier hs-var">encoderOutputEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679808591"><span class="annot"><a href="#local-6989586621679808591"><span class="hs-identifier hs-var">ffnDim</span></a></span></span><span> </span><span id="local-6989586621679808590"><span class="annot"><a href="#local-6989586621679808590"><span class="hs-identifier hs-var">posEncDim</span></a></span></span><span> </span><span id="local-6989586621679808589"><span class="annot"><a href="#local-6989586621679808589"><span class="hs-identifier hs-var">dropoutP</span></a></span></span><span> </span><span id="local-6989586621679808588"><span class="annot"><a href="#local-6989586621679808588"><span class="hs-identifier hs-var">eps</span></a></span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679808587"><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679808587"><span class="hs-identifier hs-var">k</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-284"></span><span>    </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679808586"><span class="annot"><span class="annottext">decoderStackSpec :: TransformerDecoderStackSpec
  style
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  decoderInputEmbedDim
  encoderOutputEmbedDim
  ffnDim
</span><a href="#local-6989586621679808586"><span class="hs-identifier hs-var hs-var">decoderStackSpec</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; SNat numLayers
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim headDim
-&gt; SDim headEmbedDim
-&gt; SDim embedDim
-&gt; SDim decoderInputEmbedDim
-&gt; SDim encoderOutputEmbedDim
-&gt; SDim ffnDim
-&gt; Double
-&gt; Double
-&gt; TransformerDecoderStackSpec
     style
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     decoderInputEmbedDim
     encoderOutputEmbedDim
     ffnDim
forall (style :: TransformerStyle) (numLayers :: Nat)
       (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (headDim :: Dim (Name Symbol) (Size Nat))
       (headEmbedDim :: Dim (Name Symbol) (Size Nat))
       (embedDim :: Dim (Name Symbol) (Size Nat))
       (queryEmbedDim :: Dim (Name Symbol) (Size Nat))
       (keyEmbedDim :: Dim (Name Symbol) (Size Nat))
       (ffnDim :: Dim (Name Symbol) (Size Nat)).
STransformerStyle style
-&gt; SNat numLayers
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim headDim
-&gt; SDim headEmbedDim
-&gt; SDim embedDim
-&gt; SDim queryEmbedDim
-&gt; SDim keyEmbedDim
-&gt; SDim ffnDim
-&gt; Double
-&gt; Double
-&gt; TransformerDecoderStackSpec
     style
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     keyEmbedDim
     ffnDim
</span><a href="Torch.GraduallyTyped.NN.Transformer.DecoderStack.html#TransformerDecoderStackSpec"><span class="hs-identifier hs-var">TransformerDecoderStackSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="#local-6989586621679808601"><span class="hs-identifier hs-var">style</span></a></span><span> </span><span class="annot"><span class="annottext">SNat numLayers
</span><a href="#local-6989586621679808600"><span class="hs-identifier hs-var">numLayers</span></a></span><span> </span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679808599"><span class="hs-identifier hs-var">gradient</span></a></span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679808598"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679808597"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="annot"><span class="annottext">SDim headDim
</span><a href="#local-6989586621679808596"><span class="hs-identifier hs-var">headDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim headEmbedDim
</span><a href="#local-6989586621679808595"><span class="hs-identifier hs-var">headEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim embedDim
</span><a href="#local-6989586621679808594"><span class="hs-identifier hs-var">embedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim decoderInputEmbedDim
</span><a href="#local-6989586621679808593"><span class="hs-identifier hs-var">decoderInputEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim encoderOutputEmbedDim
</span><a href="#local-6989586621679808592"><span class="hs-identifier hs-var">encoderOutputEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ffnDim
</span><a href="#local-6989586621679808591"><span class="hs-identifier hs-var">ffnDim</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679808589"><span class="hs-identifier hs-var">dropoutP</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679808588"><span class="hs-identifier hs-var">eps</span></a></span><span>
</span><span id="line-285"></span><span>        </span><span id="local-6989586621679808585"><span class="annot"><span class="annottext">decoderStack :: STransformerStyle style
-&gt; m (TransformerDecoderStack
        style
        numLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        decoderInputEmbedDim
        encoderOutputEmbedDim
        ffnDim)
</span><a href="#local-6989586621679808585"><span class="hs-identifier hs-var hs-var">decoderStack</span></a></span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (TransformerDecoderStack
     'T5
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     decoderInputEmbedDim
     encoderOutputEmbedDim
     ffnDim)
-&gt; StateDictKey
-&gt; m (TransformerDecoderStack
        'T5
        numLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        decoderInputEmbedDim
        encoderOutputEmbedDim
        ffnDim)
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
ModelSpec model -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (TransformerDecoderStack
     'T5
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     decoderInputEmbedDim
     encoderOutputEmbedDim
     ffnDim)
TransformerDecoderStackSpec
  style
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  decoderInputEmbedDim
  encoderOutputEmbedDim
  ffnDim
</span><a href="#local-6989586621679808586"><span class="hs-identifier hs-var">decoderStackSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679808587"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;block.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-286"></span><span>        </span><span class="annot"><a href="#local-6989586621679808585"><span class="hs-identifier hs-var">decoderStack</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (TransformerDecoderStack
     'ByT5
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     decoderInputEmbedDim
     encoderOutputEmbedDim
     ffnDim)
-&gt; StateDictKey
-&gt; m (TransformerDecoderStack
        'ByT5
        numLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        decoderInputEmbedDim
        encoderOutputEmbedDim
        ffnDim)
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
ModelSpec model -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (TransformerDecoderStack
     'ByT5
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     decoderInputEmbedDim
     encoderOutputEmbedDim
     ffnDim)
TransformerDecoderStackSpec
  style
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  decoderInputEmbedDim
  encoderOutputEmbedDim
  ffnDim
</span><a href="#local-6989586621679808586"><span class="hs-identifier hs-var">decoderStackSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679808587"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;block.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-287"></span><span>        </span><span class="annot"><a href="#local-6989586621679808585"><span class="hs-identifier hs-var">decoderStack</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (TransformerDecoderStack
     'BART
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     decoderInputEmbedDim
     encoderOutputEmbedDim
     ffnDim)
-&gt; StateDictKey
-&gt; m (TransformerDecoderStack
        'BART
        numLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        decoderInputEmbedDim
        encoderOutputEmbedDim
        ffnDim)
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
ModelSpec model -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (TransformerDecoderStack
     'BART
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     decoderInputEmbedDim
     encoderOutputEmbedDim
     ffnDim)
TransformerDecoderStackSpec
  style
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  decoderInputEmbedDim
  encoderOutputEmbedDim
  ffnDim
</span><a href="#local-6989586621679808586"><span class="hs-identifier hs-var">decoderStackSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679808587"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;layers.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-288"></span><span>        </span><span class="annot"><a href="#local-6989586621679808585"><span class="hs-identifier hs-var">decoderStack</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (TransformerDecoderStack
     'MBART
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     decoderInputEmbedDim
     encoderOutputEmbedDim
     ffnDim)
-&gt; StateDictKey
-&gt; m (TransformerDecoderStack
        'MBART
        numLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        decoderInputEmbedDim
        encoderOutputEmbedDim
        ffnDim)
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
ModelSpec model -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (TransformerDecoderStack
     'MBART
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     decoderInputEmbedDim
     encoderOutputEmbedDim
     ffnDim)
TransformerDecoderStackSpec
  style
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  decoderInputEmbedDim
  encoderOutputEmbedDim
  ffnDim
</span><a href="#local-6989586621679808586"><span class="hs-identifier hs-var">decoderStackSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679808587"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;layers.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-289"></span><span>        </span><span class="annot"><a href="#local-6989586621679808585"><span class="hs-identifier hs-var">decoderStack</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (TransformerDecoderStack
     'Pegasus
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     decoderInputEmbedDim
     encoderOutputEmbedDim
     ffnDim)
-&gt; StateDictKey
-&gt; m (TransformerDecoderStack
        'Pegasus
        numLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        decoderInputEmbedDim
        encoderOutputEmbedDim
        ffnDim)
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
ModelSpec model -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (TransformerDecoderStack
     'Pegasus
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     decoderInputEmbedDim
     encoderOutputEmbedDim
     ffnDim)
TransformerDecoderStackSpec
  style
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  decoderInputEmbedDim
  encoderOutputEmbedDim
  ffnDim
</span><a href="#local-6989586621679808586"><span class="hs-identifier hs-var">decoderStackSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679808587"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;layers.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-290"></span><span>        </span><span class="annot"><a href="#local-6989586621679808585"><span class="hs-identifier hs-var">decoderStack</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">m (TransformerDecoderStack
     style
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     decoderInputEmbedDim
     encoderOutputEmbedDim
     ffnDim)
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-291"></span><span>        </span><span class="annot"><a href="#local-6989586621679808585"><span class="hs-identifier hs-var">decoderStack</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">m (TransformerDecoderStack
     style
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     decoderInputEmbedDim
     encoderOutputEmbedDim
     ffnDim)
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-292"></span><span>        </span><span class="annot"><a href="#local-6989586621679808585"><span class="hs-identifier hs-var">decoderStack</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SGPT2"><span class="hs-identifier hs-var">SGPT2</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">m (TransformerDecoderStack
     style
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     decoderInputEmbedDim
     encoderOutputEmbedDim
     ffnDim)
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-293"></span><span>        </span><span id="local-6989586621679808584"><span class="annot"><span class="annottext">embedLayerNormSpec :: LayerNormSpec
  'WithBias gradient device dataType ('Shape '[decoderInputEmbedDim])
</span><a href="#local-6989586621679808584"><span class="hs-identifier hs-var hs-var">embedLayerNormSpec</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SHasBias 'WithBias
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SShape ('Shape '[decoderInputEmbedDim])
-&gt; Double
-&gt; LayerNormSpec
     'WithBias gradient device dataType ('Shape '[decoderInputEmbedDim])
forall (hasBias :: HasBias) (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (normalizedShape :: Shape [Dim (Name Symbol) (Size Nat)]).
SHasBias hasBias
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SShape normalizedShape
-&gt; Double
-&gt; LayerNormSpec hasBias gradient device dataType normalizedShape
</span><a href="Torch.GraduallyTyped.NN.Normalization.html#LayerNormSpec"><span class="hs-identifier hs-var">LayerNormSpec</span></a></span><span> </span><span class="annot"><span class="annottext">SHasBias 'WithBias
</span><a href="Torch.GraduallyTyped.NN.Type.html#SWithBias"><span class="hs-identifier hs-var">SWithBias</span></a></span><span> </span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679808599"><span class="hs-identifier hs-var">gradient</span></a></span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679808598"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679808597"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SList '[decoderInputEmbedDim]
-&gt; SShape ('Shape '[decoderInputEmbedDim])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList '[decoderInputEmbedDim]
 -&gt; SShape ('Shape '[decoderInputEmbedDim]))
-&gt; SList '[decoderInputEmbedDim]
-&gt; SShape ('Shape '[decoderInputEmbedDim])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SDim decoderInputEmbedDim
</span><a href="#local-6989586621679808593"><span class="hs-identifier hs-var">decoderInputEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim decoderInputEmbedDim
-&gt; SList '[] -&gt; SList '[decoderInputEmbedDim]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679808588"><span class="hs-identifier hs-var">eps</span></a></span><span>
</span><span id="line-294"></span><span>        </span><span id="local-6989586621679808583"><span class="annot"><span class="annottext">embedLayerNorm :: STransformerStyle style
-&gt; m (TDEmbedLayerNormF
        style gradient device dataType decoderInputEmbedDim)
</span><a href="#local-6989586621679808583"><span class="hs-identifier hs-var hs-var">embedLayerNorm</span></a></span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec () -&gt; StateDictKey -&gt; m ()
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
ModelSpec model -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679808587"><span class="hs-identifier hs-var">k</span></a></span><span>
</span><span id="line-295"></span><span>        </span><span class="annot"><a href="#local-6989586621679808583"><span class="hs-identifier hs-var">embedLayerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec () -&gt; StateDictKey -&gt; m ()
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
ModelSpec model -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679808587"><span class="hs-identifier hs-var">k</span></a></span><span>
</span><span id="line-296"></span><span>        </span><span class="annot"><a href="#local-6989586621679808583"><span class="hs-identifier hs-var">embedLayerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (LayerNorm
     'WithBias
     gradient
     device
     dataType
     ('Shape '[decoderInputEmbedDim]))
-&gt; StateDictKey
-&gt; m (LayerNorm
        'WithBias
        gradient
        device
        dataType
        ('Shape '[decoderInputEmbedDim]))
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
ModelSpec model -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (LayerNorm
     'WithBias
     gradient
     device
     dataType
     ('Shape '[decoderInputEmbedDim]))
LayerNormSpec
  'WithBias gradient device dataType ('Shape '[decoderInputEmbedDim])
</span><a href="#local-6989586621679808584"><span class="hs-identifier hs-var">embedLayerNormSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679808587"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;layernorm_embedding.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-297"></span><span>        </span><span class="annot"><a href="#local-6989586621679808583"><span class="hs-identifier hs-var">embedLayerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (LayerNorm
     'WithBias
     gradient
     device
     dataType
     ('Shape '[decoderInputEmbedDim]))
-&gt; StateDictKey
-&gt; m (LayerNorm
        'WithBias
        gradient
        device
        dataType
        ('Shape '[decoderInputEmbedDim]))
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
ModelSpec model -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (LayerNorm
     'WithBias
     gradient
     device
     dataType
     ('Shape '[decoderInputEmbedDim]))
LayerNormSpec
  'WithBias gradient device dataType ('Shape '[decoderInputEmbedDim])
</span><a href="#local-6989586621679808584"><span class="hs-identifier hs-var">embedLayerNormSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679808587"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;layernorm_embedding.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-298"></span><span>        </span><span class="annot"><a href="#local-6989586621679808583"><span class="hs-identifier hs-var">embedLayerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec () -&gt; StateDictKey -&gt; m ()
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
ModelSpec model -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679808587"><span class="hs-identifier hs-var">k</span></a></span><span>
</span><span id="line-299"></span><span>        </span><span class="annot"><a href="#local-6989586621679808583"><span class="hs-identifier hs-var">embedLayerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">m (TDEmbedLayerNormF
     style gradient device dataType decoderInputEmbedDim)
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-300"></span><span>        </span><span class="annot"><a href="#local-6989586621679808583"><span class="hs-identifier hs-var">embedLayerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">m (TDEmbedLayerNormF
     style gradient device dataType decoderInputEmbedDim)
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-301"></span><span>        </span><span class="annot"><a href="#local-6989586621679808583"><span class="hs-identifier hs-var">embedLayerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SGPT2"><span class="hs-identifier hs-var">SGPT2</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">m (TDEmbedLayerNormF
     style gradient device dataType decoderInputEmbedDim)
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-302"></span><span>        </span><span id="local-6989586621679808582"><span class="annot"><span class="annottext">layerNormWithoutBiasSpec :: LayerNormSpec
  'WithoutBias
  gradient
  device
  dataType
  ('Shape '[decoderInputEmbedDim])
</span><a href="#local-6989586621679808582"><span class="hs-identifier hs-var hs-var">layerNormWithoutBiasSpec</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SHasBias 'WithoutBias
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SShape ('Shape '[decoderInputEmbedDim])
-&gt; Double
-&gt; LayerNormSpec
     'WithoutBias
     gradient
     device
     dataType
     ('Shape '[decoderInputEmbedDim])
forall (hasBias :: HasBias) (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (normalizedShape :: Shape [Dim (Name Symbol) (Size Nat)]).
SHasBias hasBias
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SShape normalizedShape
-&gt; Double
-&gt; LayerNormSpec hasBias gradient device dataType normalizedShape
</span><a href="Torch.GraduallyTyped.NN.Normalization.html#LayerNormSpec"><span class="hs-identifier hs-var">LayerNormSpec</span></a></span><span> </span><span class="annot"><span class="annottext">SHasBias 'WithoutBias
</span><a href="Torch.GraduallyTyped.NN.Type.html#SWithoutBias"><span class="hs-identifier hs-var">SWithoutBias</span></a></span><span> </span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679808599"><span class="hs-identifier hs-var">gradient</span></a></span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679808598"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679808597"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SList '[decoderInputEmbedDim]
-&gt; SShape ('Shape '[decoderInputEmbedDim])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList '[decoderInputEmbedDim]
 -&gt; SShape ('Shape '[decoderInputEmbedDim]))
-&gt; SList '[decoderInputEmbedDim]
-&gt; SShape ('Shape '[decoderInputEmbedDim])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SDim decoderInputEmbedDim
</span><a href="#local-6989586621679808593"><span class="hs-identifier hs-var">decoderInputEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim decoderInputEmbedDim
-&gt; SList '[] -&gt; SList '[decoderInputEmbedDim]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679808588"><span class="hs-identifier hs-var">eps</span></a></span><span>
</span><span id="line-303"></span><span>        </span><span id="local-6989586621679808581"><span class="annot"><span class="annottext">layerNormWithBiasSpec :: LayerNormSpec
  'WithBias gradient device dataType ('Shape '[decoderInputEmbedDim])
</span><a href="#local-6989586621679808581"><span class="hs-identifier hs-var hs-var">layerNormWithBiasSpec</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SHasBias 'WithBias
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SShape ('Shape '[decoderInputEmbedDim])
-&gt; Double
-&gt; LayerNormSpec
     'WithBias gradient device dataType ('Shape '[decoderInputEmbedDim])
forall (hasBias :: HasBias) (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (normalizedShape :: Shape [Dim (Name Symbol) (Size Nat)]).
SHasBias hasBias
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SShape normalizedShape
-&gt; Double
-&gt; LayerNormSpec hasBias gradient device dataType normalizedShape
</span><a href="Torch.GraduallyTyped.NN.Normalization.html#LayerNormSpec"><span class="hs-identifier hs-var">LayerNormSpec</span></a></span><span> </span><span class="annot"><span class="annottext">SHasBias 'WithBias
</span><a href="Torch.GraduallyTyped.NN.Type.html#SWithBias"><span class="hs-identifier hs-var">SWithBias</span></a></span><span> </span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679808599"><span class="hs-identifier hs-var">gradient</span></a></span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679808598"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679808597"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SList '[decoderInputEmbedDim]
-&gt; SShape ('Shape '[decoderInputEmbedDim])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList '[decoderInputEmbedDim]
 -&gt; SShape ('Shape '[decoderInputEmbedDim]))
-&gt; SList '[decoderInputEmbedDim]
-&gt; SShape ('Shape '[decoderInputEmbedDim])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SDim decoderInputEmbedDim
</span><a href="#local-6989586621679808593"><span class="hs-identifier hs-var">decoderInputEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim decoderInputEmbedDim
-&gt; SList '[] -&gt; SList '[decoderInputEmbedDim]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679808588"><span class="hs-identifier hs-var">eps</span></a></span><span>
</span><span id="line-304"></span><span>        </span><span id="local-6989586621679808580"><span class="annot"><span class="annottext">layerNorm :: STransformerStyle style
-&gt; m (TDLayerNormF
        style gradient device dataType decoderInputEmbedDim)
</span><a href="#local-6989586621679808580"><span class="hs-identifier hs-var hs-var">layerNorm</span></a></span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (LayerNorm
     'WithoutBias
     gradient
     device
     dataType
     ('Shape '[decoderInputEmbedDim]))
-&gt; StateDictKey
-&gt; m (LayerNorm
        'WithoutBias
        gradient
        device
        dataType
        ('Shape '[decoderInputEmbedDim]))
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
ModelSpec model -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (LayerNorm
     'WithoutBias
     gradient
     device
     dataType
     ('Shape '[decoderInputEmbedDim]))
LayerNormSpec
  'WithoutBias
  gradient
  device
  dataType
  ('Shape '[decoderInputEmbedDim])
</span><a href="#local-6989586621679808582"><span class="hs-identifier hs-var">layerNormWithoutBiasSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679808587"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;final_layer_norm.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-305"></span><span>        </span><span class="annot"><a href="#local-6989586621679808580"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (LayerNorm
     'WithoutBias
     gradient
     device
     dataType
     ('Shape '[decoderInputEmbedDim]))
-&gt; StateDictKey
-&gt; m (LayerNorm
        'WithoutBias
        gradient
        device
        dataType
        ('Shape '[decoderInputEmbedDim]))
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
ModelSpec model -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (LayerNorm
     'WithoutBias
     gradient
     device
     dataType
     ('Shape '[decoderInputEmbedDim]))
LayerNormSpec
  'WithoutBias
  gradient
  device
  dataType
  ('Shape '[decoderInputEmbedDim])
</span><a href="#local-6989586621679808582"><span class="hs-identifier hs-var">layerNormWithoutBiasSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679808587"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;final_layer_norm.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-306"></span><span>        </span><span class="annot"><a href="#local-6989586621679808580"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec () -&gt; StateDictKey -&gt; m ()
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
ModelSpec model -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679808587"><span class="hs-identifier hs-var">k</span></a></span><span>
</span><span id="line-307"></span><span>        </span><span class="annot"><a href="#local-6989586621679808580"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec () -&gt; StateDictKey -&gt; m ()
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
ModelSpec model -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679808587"><span class="hs-identifier hs-var">k</span></a></span><span>
</span><span id="line-308"></span><span>        </span><span class="annot"><a href="#local-6989586621679808580"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (LayerNorm
     'WithBias
     gradient
     device
     dataType
     ('Shape '[decoderInputEmbedDim]))
-&gt; StateDictKey
-&gt; m (LayerNorm
        'WithBias
        gradient
        device
        dataType
        ('Shape '[decoderInputEmbedDim]))
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
ModelSpec model -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (LayerNorm
     'WithBias
     gradient
     device
     dataType
     ('Shape '[decoderInputEmbedDim]))
LayerNormSpec
  'WithBias gradient device dataType ('Shape '[decoderInputEmbedDim])
</span><a href="#local-6989586621679808581"><span class="hs-identifier hs-var">layerNormWithBiasSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679808587"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;layer_norm.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-309"></span><span>        </span><span class="annot"><a href="#local-6989586621679808580"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">m (TDLayerNormF
     style gradient device dataType decoderInputEmbedDim)
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-310"></span><span>        </span><span class="annot"><a href="#local-6989586621679808580"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">m (TDLayerNormF
     style gradient device dataType decoderInputEmbedDim)
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-311"></span><span>        </span><span class="annot"><a href="#local-6989586621679808580"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SGPT2"><span class="hs-identifier hs-var">SGPT2</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">m (TDLayerNormF
     style gradient device dataType decoderInputEmbedDim)
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-312"></span><span>        </span><span id="local-6989586621679808579"><span class="annot"><span class="annottext">dropout :: STransformerStyle style -&gt; m Dropout
</span><a href="#local-6989586621679808579"><span class="hs-identifier hs-var hs-var">dropout</span></a></span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec Dropout -&gt; StateDictKey -&gt; m Dropout
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
ModelSpec model -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Double -&gt; Dropout
</span><a href="Torch.GraduallyTyped.NN.Dropout.html#Dropout"><span class="hs-identifier hs-var">Dropout</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679808589"><span class="hs-identifier hs-var">dropoutP</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679808587"><span class="hs-identifier hs-var">k</span></a></span><span>
</span><span id="line-313"></span><span>        </span><span id="local-6989586621679808578"><span class="annot"><span class="annottext">relPosEncSpec :: EmbeddingSpec
  gradient
  ('Layout 'Dense)
  device
  dataType
  posEncDim
  headDim
  'Nothing
</span><a href="#local-6989586621679808578"><span class="hs-identifier hs-var hs-var">relPosEncSpec</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SGradient gradient
-&gt; SLayout ('Layout 'Dense)
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim posEncDim
-&gt; SDim headDim
-&gt; SMaybe 'Nothing
-&gt; EmbeddingSpec
     gradient
     ('Layout 'Dense)
     device
     dataType
     posEncDim
     headDim
     'Nothing
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (embedNumDim :: Dim (Name Symbol) (Size Nat))
       (embedDim :: Dim (Name Symbol) (Size Nat))
       (paddingIdx :: Maybe Nat).
SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim embedNumDim
-&gt; SDim embedDim
-&gt; SMaybe paddingIdx
-&gt; EmbeddingSpec
     gradient layout device dataType embedNumDim embedDim paddingIdx
</span><a href="Torch.GraduallyTyped.NN.Sparse.html#EmbeddingSpec"><span class="hs-identifier hs-var">EmbeddingSpec</span></a></span><span> </span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679808599"><span class="hs-identifier hs-var">gradient</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SLayoutType 'Dense -&gt; SLayout ('Layout 'Dense)
forall (layoutType :: LayoutType).
SLayoutType layoutType -&gt; SLayout ('Layout layoutType)
</span><a href="Torch.GraduallyTyped.Layout.html#SLayout"><span class="hs-identifier hs-var">SLayout</span></a></span><span> </span><span class="annot"><span class="annottext">SLayoutType 'Dense
</span><a href="Torch.GraduallyTyped.Layout.html#SDense"><span class="hs-identifier hs-var">SDense</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679808598"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679808597"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="annot"><span class="annottext">SDim posEncDim
</span><a href="#local-6989586621679808590"><span class="hs-identifier hs-var">posEncDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim headDim
</span><a href="#local-6989586621679808596"><span class="hs-identifier hs-var">headDim</span></a></span><span> </span><span class="annot"><span class="annottext">SMaybe 'Nothing
forall a. SMaybe 'Nothing
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNothing</span></a></span><span>
</span><span id="line-314"></span><span>        </span><span id="local-6989586621679808577"><span class="annot"><span class="annottext">posEncSpec :: EmbeddingSpec
  gradient
  ('Layout 'Dense)
  device
  dataType
  posEncDim
  decoderInputEmbedDim
  'Nothing
</span><a href="#local-6989586621679808577"><span class="hs-identifier hs-var hs-var">posEncSpec</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SGradient gradient
-&gt; SLayout ('Layout 'Dense)
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim posEncDim
-&gt; SDim decoderInputEmbedDim
-&gt; SMaybe 'Nothing
-&gt; EmbeddingSpec
     gradient
     ('Layout 'Dense)
     device
     dataType
     posEncDim
     decoderInputEmbedDim
     'Nothing
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (embedNumDim :: Dim (Name Symbol) (Size Nat))
       (embedDim :: Dim (Name Symbol) (Size Nat))
       (paddingIdx :: Maybe Nat).
SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim embedNumDim
-&gt; SDim embedDim
-&gt; SMaybe paddingIdx
-&gt; EmbeddingSpec
     gradient layout device dataType embedNumDim embedDim paddingIdx
</span><a href="Torch.GraduallyTyped.NN.Sparse.html#EmbeddingSpec"><span class="hs-identifier hs-var">EmbeddingSpec</span></a></span><span> </span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679808599"><span class="hs-identifier hs-var">gradient</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SLayoutType 'Dense -&gt; SLayout ('Layout 'Dense)
forall (layoutType :: LayoutType).
SLayoutType layoutType -&gt; SLayout ('Layout layoutType)
</span><a href="Torch.GraduallyTyped.Layout.html#SLayout"><span class="hs-identifier hs-var">SLayout</span></a></span><span> </span><span class="annot"><span class="annottext">SLayoutType 'Dense
</span><a href="Torch.GraduallyTyped.Layout.html#SDense"><span class="hs-identifier hs-var">SDense</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679808598"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679808597"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="annot"><span class="annottext">SDim posEncDim
</span><a href="#local-6989586621679808590"><span class="hs-identifier hs-var">posEncDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim decoderInputEmbedDim
</span><a href="#local-6989586621679808593"><span class="hs-identifier hs-var">decoderInputEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SMaybe 'Nothing
forall a. SMaybe 'Nothing
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNothing</span></a></span><span>
</span><span id="line-315"></span><span>        </span><span id="local-6989586621679808576"><span class="annot"><span class="annottext">posEnc :: STransformerStyle style
-&gt; m (TDPosEncF
        style
        gradient
        device
        dataType
        headDim
        decoderInputEmbedDim
        posEncDim)
</span><a href="#local-6989586621679808576"><span class="hs-identifier hs-var hs-var">posEnc</span></a></span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (Embedding
     gradient
     ('Layout 'Dense)
     device
     dataType
     posEncDim
     headDim
     'Nothing)
-&gt; StateDictKey
-&gt; m (Embedding
        gradient
        ('Layout 'Dense)
        device
        dataType
        posEncDim
        headDim
        'Nothing)
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
ModelSpec model -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (Embedding
     gradient
     ('Layout 'Dense)
     device
     dataType
     posEncDim
     headDim
     'Nothing)
EmbeddingSpec
  gradient
  ('Layout 'Dense)
  device
  dataType
  posEncDim
  headDim
  'Nothing
</span><a href="#local-6989586621679808578"><span class="hs-identifier hs-var">relPosEncSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679808587"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;block.0.layer.0.SelfAttention.relative_attention_bias.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-316"></span><span>        </span><span class="annot"><a href="#local-6989586621679808576"><span class="hs-identifier hs-var">posEnc</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (Embedding
     gradient
     ('Layout 'Dense)
     device
     dataType
     posEncDim
     headDim
     'Nothing)
-&gt; StateDictKey
-&gt; m (Embedding
        gradient
        ('Layout 'Dense)
        device
        dataType
        posEncDim
        headDim
        'Nothing)
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
ModelSpec model -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (Embedding
     gradient
     ('Layout 'Dense)
     device
     dataType
     posEncDim
     headDim
     'Nothing)
EmbeddingSpec
  gradient
  ('Layout 'Dense)
  device
  dataType
  posEncDim
  headDim
  'Nothing
</span><a href="#local-6989586621679808578"><span class="hs-identifier hs-var">relPosEncSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679808587"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;block.0.layer.0.SelfAttention.relative_attention_bias.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-317"></span><span>        </span><span class="annot"><a href="#local-6989586621679808576"><span class="hs-identifier hs-var">posEnc</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (Embedding
     gradient
     ('Layout 'Dense)
     device
     dataType
     posEncDim
     decoderInputEmbedDim
     'Nothing)
-&gt; StateDictKey
-&gt; m (Embedding
        gradient
        ('Layout 'Dense)
        device
        dataType
        posEncDim
        decoderInputEmbedDim
        'Nothing)
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
ModelSpec model -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (Embedding
     gradient
     ('Layout 'Dense)
     device
     dataType
     posEncDim
     decoderInputEmbedDim
     'Nothing)
EmbeddingSpec
  gradient
  ('Layout 'Dense)
  device
  dataType
  posEncDim
  decoderInputEmbedDim
  'Nothing
</span><a href="#local-6989586621679808577"><span class="hs-identifier hs-var">posEncSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679808587"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;embed_positions.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-318"></span><span>        </span><span class="annot"><a href="#local-6989586621679808576"><span class="hs-identifier hs-var">posEnc</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (Embedding
     gradient
     ('Layout 'Dense)
     device
     dataType
     posEncDim
     decoderInputEmbedDim
     'Nothing)
-&gt; StateDictKey
-&gt; m (Embedding
        gradient
        ('Layout 'Dense)
        device
        dataType
        posEncDim
        decoderInputEmbedDim
        'Nothing)
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
ModelSpec model -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (Embedding
     gradient
     ('Layout 'Dense)
     device
     dataType
     posEncDim
     decoderInputEmbedDim
     'Nothing)
EmbeddingSpec
  gradient
  ('Layout 'Dense)
  device
  dataType
  posEncDim
  decoderInputEmbedDim
  'Nothing
</span><a href="#local-6989586621679808577"><span class="hs-identifier hs-var">posEncSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679808587"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;embed_positions.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-319"></span><span>        </span><span class="annot"><a href="#local-6989586621679808576"><span class="hs-identifier hs-var">posEnc</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (Embedding
     gradient
     ('Layout 'Dense)
     device
     dataType
     posEncDim
     decoderInputEmbedDim
     'Nothing)
-&gt; StateDictKey
-&gt; m (Embedding
        gradient
        ('Layout 'Dense)
        device
        dataType
        posEncDim
        decoderInputEmbedDim
        'Nothing)
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
ModelSpec model -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (Embedding
     gradient
     ('Layout 'Dense)
     device
     dataType
     posEncDim
     decoderInputEmbedDim
     'Nothing)
EmbeddingSpec
  gradient
  ('Layout 'Dense)
  device
  dataType
  posEncDim
  decoderInputEmbedDim
  'Nothing
</span><a href="#local-6989586621679808577"><span class="hs-identifier hs-var">posEncSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679808587"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;embed_positions.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-320"></span><span>        </span><span class="annot"><a href="#local-6989586621679808576"><span class="hs-identifier hs-var">posEnc</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">m (TDPosEncF
     style
     gradient
     device
     dataType
     headDim
     decoderInputEmbedDim
     posEncDim)
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-321"></span><span>        </span><span class="annot"><a href="#local-6989586621679808576"><span class="hs-identifier hs-var">posEnc</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">m (TDPosEncF
     style
     gradient
     device
     dataType
     headDim
     decoderInputEmbedDim
     posEncDim)
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-322"></span><span>        </span><span class="annot"><a href="#local-6989586621679808576"><span class="hs-identifier hs-var">posEnc</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SGPT2"><span class="hs-identifier hs-var">SGPT2</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">m (TDPosEncF
     style
     gradient
     device
     dataType
     headDim
     decoderInputEmbedDim
     posEncDim)
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-323"></span><span>     </span><span class="hs-keyword">in</span><span> </span><span class="annot"><span class="annottext">GTransformerDecoder
  (TransformerDecoderStack
     style
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     decoderInputEmbedDim
     encoderOutputEmbedDim
     ffnDim)
  (TDEmbedLayerNormF
     style gradient device dataType decoderInputEmbedDim)
  (TDLayerNormF style gradient device dataType decoderInputEmbedDim)
  Dropout
  (TDPosEncF
     style
     gradient
     device
     dataType
     headDim
     decoderInputEmbedDim
     posEncDim)
-&gt; TransformerDecoder
     style
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     decoderInputEmbedDim
     encoderOutputEmbedDim
     ffnDim
     posEncDim
forall (style :: TransformerStyle) (numLayers :: Nat)
       (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (headDim :: Dim (Name Symbol) (Size Nat))
       (headEmbedDim :: Dim (Name Symbol) (Size Nat))
       (embedDim :: Dim (Name Symbol) (Size Nat))
       (decoderInputEmbedDim :: Dim (Name Symbol) (Size Nat))
       (encoderOutputEmbedDim :: Dim (Name Symbol) (Size Nat))
       (ffnDim :: Dim (Name Symbol) (Size Nat))
       (posEncDim :: Dim (Name Symbol) (Size Nat)).
GTransformerDecoder
  (TDStackF
     style
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     decoderInputEmbedDim
     encoderOutputEmbedDim
     ffnDim)
  (TDEmbedLayerNormF
     style gradient device dataType decoderInputEmbedDim)
  (TDLayerNormF style gradient device dataType decoderInputEmbedDim)
  (TDDropoutF style)
  (TDPosEncF
     style
     gradient
     device
     dataType
     headDim
     decoderInputEmbedDim
     posEncDim)
-&gt; TransformerDecoder
     style
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     decoderInputEmbedDim
     encoderOutputEmbedDim
     ffnDim
     posEncDim
</span><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TransformerDecoder"><span class="hs-identifier hs-var">TransformerDecoder</span></a></span><span>
</span><span id="line-324"></span><span>          </span><span class="annot"><span class="annottext">(GTransformerDecoder
   (TransformerDecoderStack
      style
      numLayers
      gradient
      device
      dataType
      headDim
      headEmbedDim
      embedDim
      decoderInputEmbedDim
      encoderOutputEmbedDim
      ffnDim)
   (TDEmbedLayerNormF
      style gradient device dataType decoderInputEmbedDim)
   (TDLayerNormF style gradient device dataType decoderInputEmbedDim)
   Dropout
   (TDPosEncF
      style
      gradient
      device
      dataType
      headDim
      decoderInputEmbedDim
      posEncDim)
 -&gt; TransformerDecoder
      style
      numLayers
      gradient
      device
      dataType
      headDim
      headEmbedDim
      embedDim
      decoderInputEmbedDim
      encoderOutputEmbedDim
      ffnDim
      posEncDim)
-&gt; m (GTransformerDecoder
        (TransformerDecoderStack
           style
           numLayers
           gradient
           device
           dataType
           headDim
           headEmbedDim
           embedDim
           decoderInputEmbedDim
           encoderOutputEmbedDim
           ffnDim)
        (TDEmbedLayerNormF
           style gradient device dataType decoderInputEmbedDim)
        (TDLayerNormF style gradient device dataType decoderInputEmbedDim)
        Dropout
        (TDPosEncF
           style
           gradient
           device
           dataType
           headDim
           decoderInputEmbedDim
           posEncDim))
-&gt; m (TransformerDecoder
        style
        numLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        decoderInputEmbedDim
        encoderOutputEmbedDim
        ffnDim
        posEncDim)
forall (f :: * -&gt; *) a b. Functor f =&gt; (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;$&gt;</span></span><span> </span><span class="hs-special">(</span><span> </span><span class="annot"><span class="annottext">TransformerDecoderStack
  style
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  decoderInputEmbedDim
  encoderOutputEmbedDim
  ffnDim
-&gt; TDEmbedLayerNormF
     style gradient device dataType decoderInputEmbedDim
-&gt; TDLayerNormF style gradient device dataType decoderInputEmbedDim
-&gt; Dropout
-&gt; TDPosEncF
     style
     gradient
     device
     dataType
     headDim
     decoderInputEmbedDim
     posEncDim
-&gt; GTransformerDecoder
     (TransformerDecoderStack
        style
        numLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        decoderInputEmbedDim
        encoderOutputEmbedDim
        ffnDim)
     (TDEmbedLayerNormF
        style gradient device dataType decoderInputEmbedDim)
     (TDLayerNormF style gradient device dataType decoderInputEmbedDim)
     Dropout
     (TDPosEncF
        style
        gradient
        device
        dataType
        headDim
        decoderInputEmbedDim
        posEncDim)
forall stack embedLayerNorm layerNorm dropout posEnc.
stack
-&gt; embedLayerNorm
-&gt; layerNorm
-&gt; dropout
-&gt; posEnc
-&gt; GTransformerDecoder
     stack embedLayerNorm layerNorm dropout posEnc
</span><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#GTransformerDecoder"><span class="hs-identifier hs-var">GTransformerDecoder</span></a></span><span>
</span><span id="line-325"></span><span>                  </span><span class="annot"><span class="annottext">(TransformerDecoderStack
   style
   numLayers
   gradient
   device
   dataType
   headDim
   headEmbedDim
   embedDim
   decoderInputEmbedDim
   encoderOutputEmbedDim
   ffnDim
 -&gt; TDEmbedLayerNormF
      style gradient device dataType decoderInputEmbedDim
 -&gt; TDLayerNormF style gradient device dataType decoderInputEmbedDim
 -&gt; Dropout
 -&gt; TDPosEncF
      style
      gradient
      device
      dataType
      headDim
      decoderInputEmbedDim
      posEncDim
 -&gt; GTransformerDecoder
      (TransformerDecoderStack
         style
         numLayers
         gradient
         device
         dataType
         headDim
         headEmbedDim
         embedDim
         decoderInputEmbedDim
         encoderOutputEmbedDim
         ffnDim)
      (TDEmbedLayerNormF
         style gradient device dataType decoderInputEmbedDim)
      (TDLayerNormF style gradient device dataType decoderInputEmbedDim)
      Dropout
      (TDPosEncF
         style
         gradient
         device
         dataType
         headDim
         decoderInputEmbedDim
         posEncDim))
-&gt; m (TransformerDecoderStack
        style
        numLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        decoderInputEmbedDim
        encoderOutputEmbedDim
        ffnDim)
-&gt; m (TDEmbedLayerNormF
        style gradient device dataType decoderInputEmbedDim
      -&gt; TDLayerNormF style gradient device dataType decoderInputEmbedDim
      -&gt; Dropout
      -&gt; TDPosEncF
           style
           gradient
           device
           dataType
           headDim
           decoderInputEmbedDim
           posEncDim
      -&gt; GTransformerDecoder
           (TransformerDecoderStack
              style
              numLayers
              gradient
              device
              dataType
              headDim
              headEmbedDim
              embedDim
              decoderInputEmbedDim
              encoderOutputEmbedDim
              ffnDim)
           (TDEmbedLayerNormF
              style gradient device dataType decoderInputEmbedDim)
           (TDLayerNormF style gradient device dataType decoderInputEmbedDim)
           Dropout
           (TDPosEncF
              style
              gradient
              device
              dataType
              headDim
              decoderInputEmbedDim
              posEncDim))
forall (f :: * -&gt; *) a b. Functor f =&gt; (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;$&gt;</span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; m (TransformerDecoderStack
        style
        numLayers
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        decoderInputEmbedDim
        encoderOutputEmbedDim
        ffnDim)
</span><a href="#local-6989586621679808585"><span class="hs-identifier hs-var">decoderStack</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="#local-6989586621679808601"><span class="hs-identifier hs-var">style</span></a></span><span>
</span><span id="line-326"></span><span>                  </span><span class="annot"><span class="annottext">m (TDEmbedLayerNormF
     style gradient device dataType decoderInputEmbedDim
   -&gt; TDLayerNormF style gradient device dataType decoderInputEmbedDim
   -&gt; Dropout
   -&gt; TDPosEncF
        style
        gradient
        device
        dataType
        headDim
        decoderInputEmbedDim
        posEncDim
   -&gt; GTransformerDecoder
        (TransformerDecoderStack
           style
           numLayers
           gradient
           device
           dataType
           headDim
           headEmbedDim
           embedDim
           decoderInputEmbedDim
           encoderOutputEmbedDim
           ffnDim)
        (TDEmbedLayerNormF
           style gradient device dataType decoderInputEmbedDim)
        (TDLayerNormF style gradient device dataType decoderInputEmbedDim)
        Dropout
        (TDPosEncF
           style
           gradient
           device
           dataType
           headDim
           decoderInputEmbedDim
           posEncDim))
-&gt; m (TDEmbedLayerNormF
        style gradient device dataType decoderInputEmbedDim)
-&gt; m (TDLayerNormF
        style gradient device dataType decoderInputEmbedDim
      -&gt; Dropout
      -&gt; TDPosEncF
           style
           gradient
           device
           dataType
           headDim
           decoderInputEmbedDim
           posEncDim
      -&gt; GTransformerDecoder
           (TransformerDecoderStack
              style
              numLayers
              gradient
              device
              dataType
              headDim
              headEmbedDim
              embedDim
              decoderInputEmbedDim
              encoderOutputEmbedDim
              ffnDim)
           (TDEmbedLayerNormF
              style gradient device dataType decoderInputEmbedDim)
           (TDLayerNormF style gradient device dataType decoderInputEmbedDim)
           Dropout
           (TDPosEncF
              style
              gradient
              device
              dataType
              headDim
              decoderInputEmbedDim
              posEncDim))
forall (f :: * -&gt; *) a b. Applicative f =&gt; f (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;*&gt;</span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; m (TDEmbedLayerNormF
        style gradient device dataType decoderInputEmbedDim)
</span><a href="#local-6989586621679808583"><span class="hs-identifier hs-var">embedLayerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="#local-6989586621679808601"><span class="hs-identifier hs-var">style</span></a></span><span>
</span><span id="line-327"></span><span>                  </span><span class="annot"><span class="annottext">m (TDLayerNormF style gradient device dataType decoderInputEmbedDim
   -&gt; Dropout
   -&gt; TDPosEncF
        style
        gradient
        device
        dataType
        headDim
        decoderInputEmbedDim
        posEncDim
   -&gt; GTransformerDecoder
        (TransformerDecoderStack
           style
           numLayers
           gradient
           device
           dataType
           headDim
           headEmbedDim
           embedDim
           decoderInputEmbedDim
           encoderOutputEmbedDim
           ffnDim)
        (TDEmbedLayerNormF
           style gradient device dataType decoderInputEmbedDim)
        (TDLayerNormF style gradient device dataType decoderInputEmbedDim)
        Dropout
        (TDPosEncF
           style
           gradient
           device
           dataType
           headDim
           decoderInputEmbedDim
           posEncDim))
-&gt; m (TDLayerNormF
        style gradient device dataType decoderInputEmbedDim)
-&gt; m (Dropout
      -&gt; TDPosEncF
           style
           gradient
           device
           dataType
           headDim
           decoderInputEmbedDim
           posEncDim
      -&gt; GTransformerDecoder
           (TransformerDecoderStack
              style
              numLayers
              gradient
              device
              dataType
              headDim
              headEmbedDim
              embedDim
              decoderInputEmbedDim
              encoderOutputEmbedDim
              ffnDim)
           (TDEmbedLayerNormF
              style gradient device dataType decoderInputEmbedDim)
           (TDLayerNormF style gradient device dataType decoderInputEmbedDim)
           Dropout
           (TDPosEncF
              style
              gradient
              device
              dataType
              headDim
              decoderInputEmbedDim
              posEncDim))
forall (f :: * -&gt; *) a b. Applicative f =&gt; f (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;*&gt;</span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; m (TDLayerNormF
        style gradient device dataType decoderInputEmbedDim)
</span><a href="#local-6989586621679808580"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="#local-6989586621679808601"><span class="hs-identifier hs-var">style</span></a></span><span>
</span><span id="line-328"></span><span>                  </span><span class="annot"><span class="annottext">m (Dropout
   -&gt; TDPosEncF
        style
        gradient
        device
        dataType
        headDim
        decoderInputEmbedDim
        posEncDim
   -&gt; GTransformerDecoder
        (TransformerDecoderStack
           style
           numLayers
           gradient
           device
           dataType
           headDim
           headEmbedDim
           embedDim
           decoderInputEmbedDim
           encoderOutputEmbedDim
           ffnDim)
        (TDEmbedLayerNormF
           style gradient device dataType decoderInputEmbedDim)
        (TDLayerNormF style gradient device dataType decoderInputEmbedDim)
        Dropout
        (TDPosEncF
           style
           gradient
           device
           dataType
           headDim
           decoderInputEmbedDim
           posEncDim))
-&gt; m Dropout
-&gt; m (TDPosEncF
        style
        gradient
        device
        dataType
        headDim
        decoderInputEmbedDim
        posEncDim
      -&gt; GTransformerDecoder
           (TransformerDecoderStack
              style
              numLayers
              gradient
              device
              dataType
              headDim
              headEmbedDim
              embedDim
              decoderInputEmbedDim
              encoderOutputEmbedDim
              ffnDim)
           (TDEmbedLayerNormF
              style gradient device dataType decoderInputEmbedDim)
           (TDLayerNormF style gradient device dataType decoderInputEmbedDim)
           Dropout
           (TDPosEncF
              style
              gradient
              device
              dataType
              headDim
              decoderInputEmbedDim
              posEncDim))
forall (f :: * -&gt; *) a b. Applicative f =&gt; f (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;*&gt;</span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style -&gt; m Dropout
</span><a href="#local-6989586621679808579"><span class="hs-identifier hs-var">dropout</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="#local-6989586621679808601"><span class="hs-identifier hs-var">style</span></a></span><span>
</span><span id="line-329"></span><span>                  </span><span class="annot"><span class="annottext">m (TDPosEncF
     style
     gradient
     device
     dataType
     headDim
     decoderInputEmbedDim
     posEncDim
   -&gt; GTransformerDecoder
        (TransformerDecoderStack
           style
           numLayers
           gradient
           device
           dataType
           headDim
           headEmbedDim
           embedDim
           decoderInputEmbedDim
           encoderOutputEmbedDim
           ffnDim)
        (TDEmbedLayerNormF
           style gradient device dataType decoderInputEmbedDim)
        (TDLayerNormF style gradient device dataType decoderInputEmbedDim)
        Dropout
        (TDPosEncF
           style
           gradient
           device
           dataType
           headDim
           decoderInputEmbedDim
           posEncDim))
-&gt; m (TDPosEncF
        style
        gradient
        device
        dataType
        headDim
        decoderInputEmbedDim
        posEncDim)
-&gt; m (GTransformerDecoder
        (TransformerDecoderStack
           style
           numLayers
           gradient
           device
           dataType
           headDim
           headEmbedDim
           embedDim
           decoderInputEmbedDim
           encoderOutputEmbedDim
           ffnDim)
        (TDEmbedLayerNormF
           style gradient device dataType decoderInputEmbedDim)
        (TDLayerNormF style gradient device dataType decoderInputEmbedDim)
        Dropout
        (TDPosEncF
           style
           gradient
           device
           dataType
           headDim
           decoderInputEmbedDim
           posEncDim))
forall (f :: * -&gt; *) a b. Applicative f =&gt; f (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;*&gt;</span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; m (TDPosEncF
        style
        gradient
        device
        dataType
        headDim
        decoderInputEmbedDim
        posEncDim)
</span><a href="#local-6989586621679808576"><span class="hs-identifier hs-var">posEnc</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="#local-6989586621679808601"><span class="hs-identifier hs-var">style</span></a></span><span>
</span><span id="line-330"></span><span>              </span><span class="hs-special">)</span><span>
</span><span id="line-331"></span><span>  </span><span id="local-6989586621679808574"><span class="annot"><span class="annottext">toStateDict :: StateDictKey
-&gt; TransformerDecoder
     style
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     decoderInputEmbedDim
     encoderOutputEmbedDim
     ffnDim
     posEncDim
-&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var hs-var hs-var hs-var">toStateDict</span></a></span></span><span> </span><span id="local-6989586621679808572"><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679808572"><span class="hs-identifier hs-var">k</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TransformerDecoder"><span class="hs-identifier hs-type">TransformerDecoder</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#GTransformerDecoder"><span class="hs-identifier hs-type">GTransformerDecoder</span></a></span><span> </span><span class="hs-special">{</span><span id="local-6989586621679808567"><span id="local-6989586621679808568"><span id="local-6989586621679808569"><span id="local-6989586621679808570"><span id="local-6989586621679808571"><span class="annot"><span class="annottext">TDPosEncF
  style
  gradient
  device
  dataType
  headDim
  decoderInputEmbedDim
  posEncDim
TDDropoutF style
TDLayerNormF style gradient device dataType decoderInputEmbedDim
TDEmbedLayerNormF
  style gradient device dataType decoderInputEmbedDim
TDStackF
  style
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  decoderInputEmbedDim
  encoderOutputEmbedDim
  ffnDim
tdPosEnc :: TDPosEncF
  style
  gradient
  device
  dataType
  headDim
  decoderInputEmbedDim
  posEncDim
tdDropout :: TDDropoutF style
tdLayerNorm :: TDLayerNormF style gradient device dataType decoderInputEmbedDim
tdEmbedLayerNorm :: TDEmbedLayerNormF
  style gradient device dataType decoderInputEmbedDim
tdStack :: TDStackF
  style
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  decoderInputEmbedDim
  encoderOutputEmbedDim
  ffnDim
tdPosEnc :: forall stack embedLayerNorm layerNorm dropout posEnc.
GTransformerDecoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; posEnc
tdDropout :: forall stack embedLayerNorm layerNorm dropout posEnc.
GTransformerDecoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; dropout
tdLayerNorm :: forall stack embedLayerNorm layerNorm dropout posEnc.
GTransformerDecoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; layerNorm
tdEmbedLayerNorm :: forall stack embedLayerNorm layerNorm dropout posEnc.
GTransformerDecoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; embedLayerNorm
tdStack :: forall stack embedLayerNorm layerNorm dropout posEnc.
GTransformerDecoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; stack
</span><a href="#local-6989586621679808567"><span class="hs-glyph hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">..</span></a></span></span></span></span></span></span><span class="hs-special">}</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-332"></span><span>    </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679808566"><span class="annot"><span class="annottext">stack :: STransformerStyle style
-&gt; TransformerDecoderStack
     style
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     decoderInputEmbedDim
     encoderOutputEmbedDim
     ffnDim
-&gt; m ()
</span><a href="#local-6989586621679808566"><span class="hs-identifier hs-var hs-var">stack</span></a></span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; TransformerDecoderStack
     'T5
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     decoderInputEmbedDim
     encoderOutputEmbedDim
     ffnDim
-&gt; m ()
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679808572"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;block.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-333"></span><span>        </span><span class="annot"><a href="#local-6989586621679808566"><span class="hs-identifier hs-var">stack</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; TransformerDecoderStack
     'ByT5
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     decoderInputEmbedDim
     encoderOutputEmbedDim
     ffnDim
-&gt; m ()
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679808572"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;block.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-334"></span><span>        </span><span class="annot"><a href="#local-6989586621679808566"><span class="hs-identifier hs-var">stack</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; TransformerDecoderStack
     'BART
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     decoderInputEmbedDim
     encoderOutputEmbedDim
     ffnDim
-&gt; m ()
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679808572"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;layers.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-335"></span><span>        </span><span class="annot"><a href="#local-6989586621679808566"><span class="hs-identifier hs-var">stack</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; TransformerDecoderStack
     'MBART
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     decoderInputEmbedDim
     encoderOutputEmbedDim
     ffnDim
-&gt; m ()
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679808572"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;layers.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-336"></span><span>        </span><span class="annot"><a href="#local-6989586621679808566"><span class="hs-identifier hs-var">stack</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; TransformerDecoderStack
     'Pegasus
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     decoderInputEmbedDim
     encoderOutputEmbedDim
     ffnDim
-&gt; m ()
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679808572"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;layers.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-337"></span><span>        </span><span class="annot"><a href="#local-6989586621679808566"><span class="hs-identifier hs-var">stack</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">TransformerDecoderStack
  style
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  decoderInputEmbedDim
  encoderOutputEmbedDim
  ffnDim
-&gt; m ()
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-338"></span><span>        </span><span class="annot"><a href="#local-6989586621679808566"><span class="hs-identifier hs-var">stack</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">TransformerDecoderStack
  style
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  decoderInputEmbedDim
  encoderOutputEmbedDim
  ffnDim
-&gt; m ()
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-339"></span><span>        </span><span class="annot"><a href="#local-6989586621679808566"><span class="hs-identifier hs-var">stack</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SGPT2"><span class="hs-identifier hs-var">SGPT2</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">TransformerDecoderStack
  style
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  decoderInputEmbedDim
  encoderOutputEmbedDim
  ffnDim
-&gt; m ()
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-340"></span><span>        </span><span id="local-6989586621679808565"><span class="annot"><span class="annottext">embedLayerNorm :: STransformerStyle style
-&gt; TDEmbedLayerNormF
     style gradient device dataType decoderInputEmbedDim
-&gt; m ()
</span><a href="#local-6989586621679808565"><span class="hs-identifier hs-var hs-var">embedLayerNorm</span></a></span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; () -&gt; m ()
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679808572"><span class="hs-identifier hs-var">k</span></a></span><span>
</span><span id="line-341"></span><span>        </span><span class="annot"><a href="#local-6989586621679808565"><span class="hs-identifier hs-var">embedLayerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; () -&gt; m ()
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679808572"><span class="hs-identifier hs-var">k</span></a></span><span>
</span><span id="line-342"></span><span>        </span><span class="annot"><a href="#local-6989586621679808565"><span class="hs-identifier hs-var">embedLayerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; LayerNorm
     'WithBias gradient device dataType ('Shape '[decoderInputEmbedDim])
-&gt; m ()
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679808572"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;layernorm_embedding.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-343"></span><span>        </span><span class="annot"><a href="#local-6989586621679808565"><span class="hs-identifier hs-var">embedLayerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; LayerNorm
     'WithBias gradient device dataType ('Shape '[decoderInputEmbedDim])
-&gt; m ()
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679808572"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;layernorm_embedding.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-344"></span><span>        </span><span class="annot"><a href="#local-6989586621679808565"><span class="hs-identifier hs-var">embedLayerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; () -&gt; m ()
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679808572"><span class="hs-identifier hs-var">k</span></a></span><span>
</span><span id="line-345"></span><span>        </span><span class="annot"><a href="#local-6989586621679808565"><span class="hs-identifier hs-var">embedLayerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">TDEmbedLayerNormF
  style gradient device dataType decoderInputEmbedDim
-&gt; m ()
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-346"></span><span>        </span><span class="annot"><a href="#local-6989586621679808565"><span class="hs-identifier hs-var">embedLayerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">TDEmbedLayerNormF
  style gradient device dataType decoderInputEmbedDim
-&gt; m ()
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-347"></span><span>        </span><span class="annot"><a href="#local-6989586621679808565"><span class="hs-identifier hs-var">embedLayerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SGPT2"><span class="hs-identifier hs-var">SGPT2</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">TDEmbedLayerNormF
  style gradient device dataType decoderInputEmbedDim
-&gt; m ()
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-348"></span><span>        </span><span id="local-6989586621679808564"><span class="annot"><span class="annottext">layerNorm :: STransformerStyle style
-&gt; TDLayerNormF style gradient device dataType decoderInputEmbedDim
-&gt; m ()
</span><a href="#local-6989586621679808564"><span class="hs-identifier hs-var hs-var">layerNorm</span></a></span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; LayerNorm
     'WithoutBias
     gradient
     device
     dataType
     ('Shape '[decoderInputEmbedDim])
-&gt; m ()
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679808572"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;final_layer_norm.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-349"></span><span>        </span><span class="annot"><a href="#local-6989586621679808564"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; LayerNorm
     'WithoutBias
     gradient
     device
     dataType
     ('Shape '[decoderInputEmbedDim])
-&gt; m ()
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679808572"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;final_layer_norm.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-350"></span><span>        </span><span class="annot"><a href="#local-6989586621679808564"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; () -&gt; m ()
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679808572"><span class="hs-identifier hs-var">k</span></a></span><span>
</span><span id="line-351"></span><span>        </span><span class="annot"><a href="#local-6989586621679808564"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; () -&gt; m ()
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679808572"><span class="hs-identifier hs-var">k</span></a></span><span>
</span><span id="line-352"></span><span>        </span><span class="annot"><a href="#local-6989586621679808564"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; LayerNorm
     'WithBias gradient device dataType ('Shape '[decoderInputEmbedDim])
-&gt; m ()
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679808572"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;layer_norm.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-353"></span><span>        </span><span class="annot"><a href="#local-6989586621679808564"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">TDLayerNormF style gradient device dataType decoderInputEmbedDim
-&gt; m ()
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-354"></span><span>        </span><span class="annot"><a href="#local-6989586621679808564"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">TDLayerNormF style gradient device dataType decoderInputEmbedDim
-&gt; m ()
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-355"></span><span>        </span><span class="annot"><a href="#local-6989586621679808564"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SGPT2"><span class="hs-identifier hs-var">SGPT2</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">TDLayerNormF style gradient device dataType decoderInputEmbedDim
-&gt; m ()
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-356"></span><span>        </span><span id="local-6989586621679808563"><span class="annot"><span class="annottext">dropout :: STransformerStyle style -&gt; Dropout -&gt; m ()
</span><a href="#local-6989586621679808563"><span class="hs-identifier hs-var hs-var">dropout</span></a></span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; Dropout -&gt; m ()
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679808572"><span class="hs-identifier hs-var">k</span></a></span><span>
</span><span id="line-357"></span><span>        </span><span id="local-6989586621679808562"><span class="annot"><span class="annottext">posEnc :: STransformerStyle style
-&gt; TDPosEncF
     style
     gradient
     device
     dataType
     headDim
     decoderInputEmbedDim
     posEncDim
-&gt; m ()
</span><a href="#local-6989586621679808562"><span class="hs-identifier hs-var hs-var">posEnc</span></a></span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; Embedding
     gradient
     ('Layout 'Dense)
     device
     dataType
     posEncDim
     headDim
     'Nothing
-&gt; m ()
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679808572"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;block.0.layer.0.SelfAttention.relative_attention_bias.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-358"></span><span>        </span><span class="annot"><a href="#local-6989586621679808562"><span class="hs-identifier hs-var">posEnc</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; Embedding
     gradient
     ('Layout 'Dense)
     device
     dataType
     posEncDim
     headDim
     'Nothing
-&gt; m ()
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679808572"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;block.0.layer.0.SelfAttention.relative_attention_bias.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-359"></span><span>        </span><span class="annot"><a href="#local-6989586621679808562"><span class="hs-identifier hs-var">posEnc</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; Embedding
     gradient
     ('Layout 'Dense)
     device
     dataType
     posEncDim
     decoderInputEmbedDim
     'Nothing
-&gt; m ()
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679808572"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;embed_positions.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-360"></span><span>        </span><span class="annot"><a href="#local-6989586621679808562"><span class="hs-identifier hs-var">posEnc</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; Embedding
     gradient
     ('Layout 'Dense)
     device
     dataType
     posEncDim
     decoderInputEmbedDim
     'Nothing
-&gt; m ()
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679808572"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;embed_positions.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-361"></span><span>        </span><span class="annot"><a href="#local-6989586621679808562"><span class="hs-identifier hs-var">posEnc</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; Embedding
     gradient
     ('Layout 'Dense)
     device
     dataType
     posEncDim
     decoderInputEmbedDim
     'Nothing
-&gt; m ()
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679808572"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;embed_positions.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-362"></span><span>        </span><span class="annot"><a href="#local-6989586621679808562"><span class="hs-identifier hs-var">posEnc</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">TDPosEncF
  style
  gradient
  device
  dataType
  headDim
  decoderInputEmbedDim
  posEncDim
-&gt; m ()
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-363"></span><span>        </span><span class="annot"><a href="#local-6989586621679808562"><span class="hs-identifier hs-var">posEnc</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">TDPosEncF
  style
  gradient
  device
  dataType
  headDim
  decoderInputEmbedDim
  posEncDim
-&gt; m ()
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-364"></span><span>        </span><span class="annot"><a href="#local-6989586621679808562"><span class="hs-identifier hs-var">posEnc</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SGPT2"><span class="hs-identifier hs-var">SGPT2</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">TDPosEncF
  style
  gradient
  device
  dataType
  headDim
  decoderInputEmbedDim
  posEncDim
-&gt; m ()
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-365"></span><span>     </span><span class="hs-keyword">in</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-366"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; TransformerDecoderStack
     style
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     decoderInputEmbedDim
     encoderOutputEmbedDim
     ffnDim
-&gt; m ()
</span><a href="#local-6989586621679808566"><span class="hs-identifier hs-var">stack</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SingI style =&gt; Sing style
forall k (a :: k). SingI a =&gt; Sing a
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">sing</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679808618"><span class="hs-identifier hs-type">style</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">TransformerDecoderStack
  style
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  decoderInputEmbedDim
  encoderOutputEmbedDim
  ffnDim
TDStackF
  style
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  decoderInputEmbedDim
  encoderOutputEmbedDim
  ffnDim
</span><a href="#local-6989586621679808571"><span class="hs-identifier hs-var">tdStack</span></a></span><span>
</span><span id="line-367"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; TDEmbedLayerNormF
     style gradient device dataType decoderInputEmbedDim
-&gt; m ()
</span><a href="#local-6989586621679808565"><span class="hs-identifier hs-var">embedLayerNorm</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SingI style =&gt; Sing style
forall k (a :: k). SingI a =&gt; Sing a
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">sing</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679808618"><span class="hs-identifier hs-type">style</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">TDEmbedLayerNormF
  style gradient device dataType decoderInputEmbedDim
</span><a href="#local-6989586621679808570"><span class="hs-identifier hs-var">tdEmbedLayerNorm</span></a></span><span>
</span><span id="line-368"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; TDLayerNormF style gradient device dataType decoderInputEmbedDim
-&gt; m ()
</span><a href="#local-6989586621679808564"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SingI style =&gt; Sing style
forall k (a :: k). SingI a =&gt; Sing a
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">sing</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679808618"><span class="hs-identifier hs-type">style</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">TDLayerNormF style gradient device dataType decoderInputEmbedDim
</span><a href="#local-6989586621679808569"><span class="hs-identifier hs-var">tdLayerNorm</span></a></span><span>
</span><span id="line-369"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">STransformerStyle style -&gt; Dropout -&gt; m ()
</span><a href="#local-6989586621679808563"><span class="hs-identifier hs-var">dropout</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SingI style =&gt; Sing style
forall k (a :: k). SingI a =&gt; Sing a
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">sing</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679808618"><span class="hs-identifier hs-type">style</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Dropout
TDDropoutF style
</span><a href="#local-6989586621679808568"><span class="hs-identifier hs-var">tdDropout</span></a></span><span>
</span><span id="line-370"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; TDPosEncF
     style
     gradient
     device
     dataType
     headDim
     decoderInputEmbedDim
     posEncDim
-&gt; m ()
</span><a href="#local-6989586621679808562"><span class="hs-identifier hs-var">posEnc</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SingI style =&gt; Sing style
forall k (a :: k). SingI a =&gt; Sing a
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">sing</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679808618"><span class="hs-identifier hs-type">style</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">TDPosEncF
  style
  gradient
  device
  dataType
  headDim
  decoderInputEmbedDim
  posEncDim
</span><a href="#local-6989586621679808567"><span class="hs-identifier hs-var">tdPosEnc</span></a></span><span>
</span><span id="line-371"></span><span>          </span><span class="annot"><span class="annottext">() -&gt; m ()
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span></span></span></span></span></span></span></span></span></span></span></span></span><span>
</span><span id="line-372"></span><span>
</span><span id="line-373"></span><span class="hs-comment">-- | 'HasForward' instance for @TransformerDecoder numLayers 'T5@.</span><span>
</span><span id="line-374"></span><span class="hs-comment">--</span><span>
</span><span id="line-375"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-376"></span><span class="hs-comment">-- &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;  &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;  &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;  &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;  &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;</span><span>
</span><span id="line-377"></span><span class="hs-comment">-- &#9474; decoderInput &#9474;  &#9474; encoderOutput &#9474;  &#9474; decoderRelPos &#9474;  &#9474; decoderAttentionMask &#9474;  &#9474; crossAttentionMask &#9474;</span><span>
</span><span id="line-378"></span><span class="hs-comment">-- &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;  &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;  &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;  &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;  &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-379"></span><span class="hs-comment">--        &#9474;                  &#9474;                  &#9474;                     &#9474;                        &#9474;</span><span>
</span><span id="line-380"></span><span class="hs-comment">--        &#9474;                  &#9474;                  &#9660;                     &#9474;                        &#9474;</span><span>
</span><span id="line-381"></span><span class="hs-comment">--        &#9474;                  &#9474;              tdPosEnc                  &#9474;                        &#9474;</span><span>
</span><span id="line-382"></span><span class="hs-comment">--        &#9474;                  &#9474;                  &#9660;                     &#9474;                        &#9474;</span><span>
</span><span id="line-383"></span><span class="hs-comment">--        &#9474;                  &#9474;              transpose                 &#9474;                        &#9474;</span><span>
</span><span id="line-384"></span><span class="hs-comment">--        &#9474;                  &#9474;                  &#9660;                     &#9660;                        &#9660;</span><span>
</span><span id="line-385"></span><span class="hs-comment">--        &#9474;                  &#9474;              transpose             unsqueeze                unsqueeze</span><span>
</span><span id="line-386"></span><span class="hs-comment">--        &#9660;                  &#9474;                  &#9474;                     &#9474;                        &#9474;</span><span>
</span><span id="line-387"></span><span class="hs-comment">--    tdDropout              &#9474;                  &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9658;add&#9668;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;                        &#9474;</span><span>
</span><span id="line-388"></span><span class="hs-comment">--        &#9660;                  &#9474;                             &#9474;                                   &#9474;</span><span>
</span><span id="line-389"></span><span class="hs-comment">--     tdStack&#9668;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;&#9668;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;&#9668;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-390"></span><span class="hs-comment">--        &#9660;</span><span>
</span><span id="line-391"></span><span class="hs-comment">--   tdLayerNorm</span><span>
</span><span id="line-392"></span><span class="hs-comment">--        &#9660;</span><span>
</span><span id="line-393"></span><span class="hs-comment">--    tdDropout</span><span>
</span><span id="line-394"></span><span class="hs-comment">--        &#9474;</span><span>
</span><span id="line-395"></span><span class="hs-comment">--        &#9660;</span><span>
</span><span id="line-396"></span><span class="hs-comment">--    &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;</span><span>
</span><span id="line-397"></span><span class="hs-comment">--    &#9474; output &#9474;</span><span>
</span><span id="line-398"></span><span class="hs-comment">--    &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-399"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-400"></span><span id="local-6989586621679808525"><span id="local-6989586621679808526"><span id="local-6989586621679808527"><span id="local-6989586621679808528"><span id="local-6989586621679808529"><span id="local-6989586621679808530"><span id="local-6989586621679808531"><span id="local-6989586621679808532"><span id="local-6989586621679808533"><span id="local-6989586621679808534"><span id="local-6989586621679808535"><span id="local-6989586621679808536"><span id="local-6989586621679808537"><span id="local-6989586621679808538"><span id="local-6989586621679808539"><span id="local-6989586621679808540"><span id="local-6989586621679808541"><span id="local-6989586621679808542"><span id="local-6989586621679808543"><span id="local-6989586621679808544"><span id="local-6989586621679808545"><span id="local-6989586621679808546"><span id="local-6989586621679808547"><span id="local-6989586621679808548"><span id="local-6989586621679808549"><span id="local-6989586621679808550"><span id="local-6989586621679808551"><span id="local-6989586621679808552"><span id="local-6989586621679808553"><span id="local-6989586621679808554"><span id="local-6989586621679808555"><span id="local-6989586621679808556"><span id="local-6989586621679808557"><span id="local-6989586621679808558"><span id="local-6989586621679808559"><span id="local-6989586621679808560"><span id="local-6989586621679808561"><span class="hs-keyword">instance</span><span>
</span><span id="line-401"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-402"></span><span>      </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Dropout.html#Dropout"><span class="hs-identifier hs-type">Dropout</span></a></span><span>
</span><span id="line-403"></span><span>      </span><span class="annot"><a href="#local-6989586621679808561"><span class="hs-identifier hs-type">decoderInput</span></a></span><span>
</span><span id="line-404"></span><span>      </span><span class="annot"><a href="#local-6989586621679808560"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-405"></span><span>      </span><span class="annot"><a href="#local-6989586621679808559"><span class="hs-identifier hs-type">dropoutOutput</span></a></span><span>
</span><span id="line-406"></span><span>      </span><span class="annot"><a href="#local-6989586621679808558"><span class="hs-identifier hs-type">dropoutGeneratorOutputDevice</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-407"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-408"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.DecoderStack.html#TransformerDecoderStack"><span class="hs-identifier hs-type">TransformerDecoderStack</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#T5"><span class="hs-identifier hs-type">T5</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808557"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808556"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808555"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808554"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808553"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808552"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808551"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808550"><span class="hs-identifier hs-type">decoderInputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808549"><span class="hs-identifier hs-type">encoderOutputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808548"><span class="hs-identifier hs-type">ffnDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-409"></span><span>      </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="#local-6989586621679808559"><span class="hs-identifier hs-type">dropoutOutput</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-410"></span><span>        </span><span class="annot"><a href="#local-6989586621679808547"><span class="hs-identifier hs-type">encoderOutput</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-411"></span><span>        </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-412"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679808556"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808546"><span class="hs-identifier hs-type">decoderRelPosGradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808545"><span class="hs-identifier hs-type">decoderAttentionMaskGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-413"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Dense"><span class="hs-identifier hs-type">Dense</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808544"><span class="hs-identifier hs-type">decoderRelPosLayout</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808543"><span class="hs-identifier hs-type">decoderAttentionMaskLayout</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-414"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679808555"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808542"><span class="hs-identifier hs-type">decoderRelPosDevice</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808541"><span class="hs-identifier hs-type">decoderAttentionMaskDevice</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-415"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Seq"><span class="hs-identifier hs-type">Seq</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679808540"><span class="hs-identifier hs-type">decoderRelPosDataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#Int64"><span class="hs-identifier hs-type">Int64</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679808554"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808539"><span class="hs-identifier hs-type">decoderAttentionMaskDataType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-416"></span><span>          </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#BroadcastShapesF"><span class="hs-identifier hs-type">BroadcastShapesF</span></a></span><span>
</span><span id="line-417"></span><span>              </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#TransposeF"><span class="hs-identifier hs-type">TransposeF</span></a></span><span>
</span><span id="line-418"></span><span>                  </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-419"></span><span>                  </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">2</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-420"></span><span>                  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#TransposeF"><span class="hs-identifier hs-type">TransposeF</span></a></span><span>
</span><span id="line-421"></span><span>                      </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">2</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-422"></span><span>                      </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">3</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-423"></span><span>                      </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Functional.Sparse.html#EmbeddingF"><span class="hs-identifier hs-type">EmbeddingF</span></a></span><span>
</span><span id="line-424"></span><span>                          </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679808538"><span class="hs-identifier hs-type">posEncDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679808553"><span class="hs-identifier hs-type">headDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-425"></span><span>                          </span><span class="annot"><a href="#local-6989586621679808537"><span class="hs-identifier hs-type">decoderRelPosShape</span></a></span><span>
</span><span id="line-426"></span><span>                      </span><span class="hs-special">)</span><span>
</span><span id="line-427"></span><span>                  </span><span class="hs-special">)</span><span>
</span><span id="line-428"></span><span>              </span><span class="hs-special">)</span><span>
</span><span id="line-429"></span><span>              </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#UnsqueezeF"><span class="hs-identifier hs-type">UnsqueezeF</span></a></span><span>
</span><span id="line-430"></span><span>                  </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-431"></span><span>                  </span><span class="annot"><a href="#local-6989586621679808536"><span class="hs-identifier hs-type">decoderAttentionMaskShape</span></a></span><span>
</span><span id="line-432"></span><span>              </span><span class="hs-special">)</span><span>
</span><span id="line-433"></span><span>          </span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-434"></span><span>        </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-435"></span><span>          </span><span class="annot"><a href="#local-6989586621679808535"><span class="hs-identifier hs-type">crossAttentionMaskGradient</span></a></span><span>
</span><span id="line-436"></span><span>          </span><span class="annot"><a href="#local-6989586621679808534"><span class="hs-identifier hs-type">crossAttentionMaskLayout</span></a></span><span>
</span><span id="line-437"></span><span>          </span><span class="annot"><a href="#local-6989586621679808533"><span class="hs-identifier hs-type">crossAttentionMaskDevice</span></a></span><span>
</span><span id="line-438"></span><span>          </span><span class="annot"><a href="#local-6989586621679808532"><span class="hs-identifier hs-type">crossAttentionMaskDataType</span></a></span><span>
</span><span id="line-439"></span><span>          </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#UnsqueezeF"><span class="hs-identifier hs-type">UnsqueezeF</span></a></span><span>
</span><span id="line-440"></span><span>              </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-441"></span><span>              </span><span class="annot"><a href="#local-6989586621679808531"><span class="hs-identifier hs-type">crossAttentionMaskShape</span></a></span><span>
</span><span id="line-442"></span><span>          </span><span class="hs-special">)</span><span>
</span><span id="line-443"></span><span>      </span><span class="hs-special">)</span><span>
</span><span id="line-444"></span><span>      </span><span class="annot"><a href="#local-6989586621679808558"><span class="hs-identifier hs-type">dropoutGeneratorOutputDevice</span></a></span><span>
</span><span id="line-445"></span><span>      </span><span class="annot"><a href="#local-6989586621679808530"><span class="hs-identifier hs-type">stackOutput</span></a></span><span>
</span><span id="line-446"></span><span>      </span><span class="annot"><a href="#local-6989586621679808529"><span class="hs-identifier hs-type">stackGeneratorOutputDevice</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-447"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-448"></span><span>      </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Normalization.html#LayerNorm"><span class="hs-identifier hs-type">LayerNorm</span></a></span><span>
</span><span id="line-449"></span><span>          </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Type.html#WithoutBias"><span class="hs-identifier hs-type">WithoutBias</span></a></span><span>
</span><span id="line-450"></span><span>          </span><span class="annot"><a href="#local-6989586621679808556"><span class="hs-identifier hs-type">gradient</span></a></span><span>
</span><span id="line-451"></span><span>          </span><span class="annot"><a href="#local-6989586621679808555"><span class="hs-identifier hs-type">device</span></a></span><span>
</span><span id="line-452"></span><span>          </span><span class="annot"><a href="#local-6989586621679808554"><span class="hs-identifier hs-type">dataType</span></a></span><span>
</span><span id="line-453"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679808550"><span class="hs-identifier hs-type">decoderInputEmbedDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-454"></span><span>      </span><span class="hs-special">)</span><span>
</span><span id="line-455"></span><span>      </span><span class="annot"><a href="#local-6989586621679808530"><span class="hs-identifier hs-type">stackOutput</span></a></span><span>
</span><span id="line-456"></span><span>      </span><span class="annot"><a href="#local-6989586621679808529"><span class="hs-identifier hs-type">stackGeneratorOutputDevice</span></a></span><span>
</span><span id="line-457"></span><span>      </span><span class="annot"><a href="#local-6989586621679808528"><span class="hs-identifier hs-type">layerNormOutput</span></a></span><span>
</span><span id="line-458"></span><span>      </span><span class="annot"><a href="#local-6989586621679808527"><span class="hs-identifier hs-type">layerNormGeneratorOutputDevice</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-459"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-460"></span><span>      </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Dropout.html#Dropout"><span class="hs-identifier hs-type">Dropout</span></a></span><span>
</span><span id="line-461"></span><span>      </span><span class="annot"><a href="#local-6989586621679808528"><span class="hs-identifier hs-type">layerNormOutput</span></a></span><span>
</span><span id="line-462"></span><span>      </span><span class="annot"><a href="#local-6989586621679808527"><span class="hs-identifier hs-type">layerNormGeneratorOutputDevice</span></a></span><span>
</span><span id="line-463"></span><span>      </span><span class="annot"><a href="#local-6989586621679808526"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-464"></span><span>      </span><span class="annot"><a href="#local-6989586621679808525"><span class="hs-identifier hs-type">generatorOutputDevice</span></a></span><span>
</span><span id="line-465"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-466"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-467"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TransformerDecoder"><span class="hs-identifier hs-type">TransformerDecoder</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#T5"><span class="hs-identifier hs-type">T5</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808557"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808556"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808555"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808554"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808553"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808552"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808551"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808550"><span class="hs-identifier hs-type">decoderInputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808549"><span class="hs-identifier hs-type">encoderOutputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808548"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808538"><span class="hs-identifier hs-type">posEncDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-468"></span><span>    </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="#local-6989586621679808561"><span class="hs-identifier hs-type">decoderInput</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-469"></span><span>      </span><span class="annot"><a href="#local-6989586621679808547"><span class="hs-identifier hs-type">encoderOutput</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-470"></span><span>      </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808546"><span class="hs-identifier hs-type">decoderRelPosGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808544"><span class="hs-identifier hs-type">decoderRelPosLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808542"><span class="hs-identifier hs-type">decoderRelPosDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808540"><span class="hs-identifier hs-type">decoderRelPosDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808537"><span class="hs-identifier hs-type">decoderRelPosShape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-471"></span><span>      </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808545"><span class="hs-identifier hs-type">decoderAttentionMaskGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808543"><span class="hs-identifier hs-type">decoderAttentionMaskLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808541"><span class="hs-identifier hs-type">decoderAttentionMaskDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808539"><span class="hs-identifier hs-type">decoderAttentionMaskDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808536"><span class="hs-identifier hs-type">decoderAttentionMaskShape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-472"></span><span>      </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808535"><span class="hs-identifier hs-type">crossAttentionMaskGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808534"><span class="hs-identifier hs-type">crossAttentionMaskLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808533"><span class="hs-identifier hs-type">crossAttentionMaskDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808532"><span class="hs-identifier hs-type">crossAttentionMaskDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808531"><span class="hs-identifier hs-type">crossAttentionMaskShape</span></a></span><span>
</span><span id="line-473"></span><span>    </span><span class="hs-special">)</span><span>
</span><span id="line-474"></span><span>    </span><span class="annot"><a href="#local-6989586621679808560"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-475"></span><span>    </span><span class="annot"><a href="#local-6989586621679808526"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-476"></span><span>    </span><span class="annot"><a href="#local-6989586621679808525"><span class="hs-identifier hs-type">generatorOutputDevice</span></a></span><span>
</span><span id="line-477"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-478"></span><span>  </span><span id="local-6989586621679808522"><span class="annot"><span class="annottext">forward :: TransformerDecoder
  'T5
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  decoderInputEmbedDim
  encoderOutputEmbedDim
  ffnDim
  posEncDim
-&gt; (decoderInput, encoderOutput,
    Tensor
      decoderRelPosGradient
      decoderRelPosLayout
      decoderRelPosDevice
      decoderRelPosDataType
      decoderRelPosShape,
    Tensor
      decoderAttentionMaskGradient
      decoderAttentionMaskLayout
      decoderAttentionMaskDevice
      decoderAttentionMaskDataType
      decoderAttentionMaskShape,
    Tensor
      crossAttentionMaskGradient
      crossAttentionMaskLayout
      crossAttentionMaskDevice
      crossAttentionMaskDataType
      crossAttentionMaskShape)
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var hs-var hs-var hs-var">forward</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TransformerDecoder"><span class="hs-identifier hs-type">TransformerDecoder</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#GTransformerDecoder"><span class="hs-identifier hs-type">GTransformerDecoder</span></a></span><span> </span><span class="hs-special">{</span><span id="local-6989586621679808516"><span id="local-6989586621679808517"><span id="local-6989586621679808518"><span id="local-6989586621679808519"><span id="local-6989586621679808520"><span class="annot"><span class="annottext">TDPosEncF
  'T5 gradient device dataType headDim decoderInputEmbedDim posEncDim
TDDropoutF 'T5
TDLayerNormF 'T5 gradient device dataType decoderInputEmbedDim
TDEmbedLayerNormF 'T5 gradient device dataType decoderInputEmbedDim
TDStackF
  'T5
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  decoderInputEmbedDim
  encoderOutputEmbedDim
  ffnDim
tdPosEnc :: TDPosEncF
  'T5 gradient device dataType headDim decoderInputEmbedDim posEncDim
tdDropout :: TDDropoutF 'T5
tdLayerNorm :: TDLayerNormF 'T5 gradient device dataType decoderInputEmbedDim
tdEmbedLayerNorm :: TDEmbedLayerNormF 'T5 gradient device dataType decoderInputEmbedDim
tdStack :: TDStackF
  'T5
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  decoderInputEmbedDim
  encoderOutputEmbedDim
  ffnDim
tdPosEnc :: forall stack embedLayerNorm layerNorm dropout posEnc.
GTransformerDecoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; posEnc
tdDropout :: forall stack embedLayerNorm layerNorm dropout posEnc.
GTransformerDecoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; dropout
tdLayerNorm :: forall stack embedLayerNorm layerNorm dropout posEnc.
GTransformerDecoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; layerNorm
tdEmbedLayerNorm :: forall stack embedLayerNorm layerNorm dropout posEnc.
GTransformerDecoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; embedLayerNorm
tdStack :: forall stack embedLayerNorm layerNorm dropout posEnc.
GTransformerDecoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; stack
</span><a href="#local-6989586621679808516"><span class="hs-glyph hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">..</span></a></span></span></span></span></span></span><span class="hs-special">}</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679808515"><span class="annot"><span class="annottext">decoderInput
</span><a href="#local-6989586621679808515"><span class="hs-identifier hs-var">decoderInput</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679808514"><span class="annot"><span class="annottext">encoderOutput
</span><a href="#local-6989586621679808514"><span class="hs-identifier hs-var">encoderOutput</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679808513"><span class="annot"><span class="annottext">Tensor
  decoderRelPosGradient
  decoderRelPosLayout
  decoderRelPosDevice
  decoderRelPosDataType
  decoderRelPosShape
</span><a href="#local-6989586621679808513"><span class="hs-identifier hs-var">decoderRelPos</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679808512"><span class="annot"><span class="annottext">Tensor
  decoderAttentionMaskGradient
  decoderAttentionMaskLayout
  decoderAttentionMaskDevice
  decoderAttentionMaskDataType
  decoderAttentionMaskShape
</span><a href="#local-6989586621679808512"><span class="hs-identifier hs-var">decoderAttentionMask</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679808511"><span class="annot"><span class="annottext">Tensor
  crossAttentionMaskGradient
  crossAttentionMaskLayout
  crossAttentionMaskDevice
  crossAttentionMaskDataType
  crossAttentionMaskShape
</span><a href="#local-6989586621679808511"><span class="hs-identifier hs-var">crossAttentionMask</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-479"></span><span>    </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679808510"><span class="annot"><span class="annottext">decoderRelPosBias :: IxStateT
  m
  (Generator dropoutGeneratorOutputDevice)
  (Generator dropoutGeneratorOutputDevice)
  (Tensor
     (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
     (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
     (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
     (Seq
        (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
        dataType)
     (TransposeF
        ('SelectDim ('ByIndex 1))
        ('SelectDim ('ByIndex 2))
        (TransposeF
           ('SelectDim ('ByIndex 2))
           ('SelectDim ('ByIndex 3))
           (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape))))
</span><a href="#local-6989586621679808510"><span class="hs-identifier hs-var hs-var">decoderRelPosBias</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-480"></span><span>          </span><span class="annot"><span class="annottext">Tensor
  decoderRelPosGradient
  decoderRelPosLayout
  decoderRelPosDevice
  decoderRelPosDataType
  decoderRelPosShape
-&gt; IxStateT
     m
     (Generator dropoutGeneratorOutputDevice)
     (Generator dropoutGeneratorOutputDevice)
     (Tensor
        decoderRelPosGradient
        decoderRelPosLayout
        decoderRelPosDevice
        decoderRelPosDataType
        decoderRelPosShape)
forall k (m :: k -&gt; k -&gt; * -&gt; *) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  decoderRelPosGradient
  decoderRelPosLayout
  decoderRelPosDevice
  decoderRelPosDataType
  decoderRelPosShape
</span><a href="#local-6989586621679808513"><span class="hs-identifier hs-var">decoderRelPos</span></a></span><span>
</span><span id="line-481"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator dropoutGeneratorOutputDevice)
  (Generator dropoutGeneratorOutputDevice)
  (Tensor
     decoderRelPosGradient
     decoderRelPosLayout
     decoderRelPosDevice
     decoderRelPosDataType
     decoderRelPosShape)
-&gt; (Tensor
      decoderRelPosGradient
      decoderRelPosLayout
      decoderRelPosDevice
      decoderRelPosDataType
      decoderRelPosShape
    -&gt; IxStateT
         m
         (Generator dropoutGeneratorOutputDevice)
         (Generator dropoutGeneratorOutputDevice)
         (Tensor
            (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
            (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
            (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
            (Seq
               (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
               dataType)
            (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)))
-&gt; IxStateT
     m
     (Generator dropoutGeneratorOutputDevice)
     (Generator dropoutGeneratorOutputDevice)
     (Tensor
        (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
        (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
        (Seq
           (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
           dataType)
        (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape))
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(Generator dropoutGeneratorOutputDevice
 -&gt; m (Tensor
         (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
         (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
         (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
         (Seq
            (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
            dataType)
         (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape),
       Generator dropoutGeneratorOutputDevice))
-&gt; IxStateT
     m
     (Generator dropoutGeneratorOutputDevice)
     (Generator dropoutGeneratorOutputDevice)
     (Tensor
        (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
        (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
        (Seq
           (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
           dataType)
        (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape))
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator dropoutGeneratorOutputDevice
  -&gt; m (Tensor
          (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
          (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
          (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
          (Seq
             (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
             dataType)
          (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape),
        Generator dropoutGeneratorOutputDevice))
 -&gt; IxStateT
      m
      (Generator dropoutGeneratorOutputDevice)
      (Generator dropoutGeneratorOutputDevice)
      (Tensor
         (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
         (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
         (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
         (Seq
            (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
            dataType)
         (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)))
-&gt; (Tensor
      decoderRelPosGradient
      decoderRelPosLayout
      decoderRelPosDevice
      decoderRelPosDataType
      decoderRelPosShape
    -&gt; Generator dropoutGeneratorOutputDevice
    -&gt; m (Tensor
            (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
            (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
            (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
            (Seq
               (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
               dataType)
            (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape),
          Generator dropoutGeneratorOutputDevice))
-&gt; Tensor
     decoderRelPosGradient
     decoderRelPosLayout
     decoderRelPosDevice
     decoderRelPosDataType
     decoderRelPosShape
-&gt; IxStateT
     m
     (Generator dropoutGeneratorOutputDevice)
     (Generator dropoutGeneratorOutputDevice)
     (Tensor
        (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
        (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
        (Seq
           (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
           dataType)
        (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape))
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Embedding
  gradient
  ('Layout 'Dense)
  device
  dataType
  posEncDim
  headDim
  'Nothing
-&gt; Tensor
     decoderRelPosGradient
     decoderRelPosLayout
     decoderRelPosDevice
     decoderRelPosDataType
     decoderRelPosShape
-&gt; Generator dropoutGeneratorOutputDevice
-&gt; m (Tensor
        (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
        (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
        (Seq
           (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
           dataType)
        (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape),
      Generator dropoutGeneratorOutputDevice)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: * -&gt; *).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">Embedding
  gradient
  ('Layout 'Dense)
  device
  dataType
  posEncDim
  headDim
  'Nothing
TDPosEncF
  'T5 gradient device dataType headDim decoderInputEmbedDim posEncDim
</span><a href="#local-6989586621679808516"><span class="hs-identifier hs-var">tdPosEnc</span></a></span><span>
</span><span id="line-482"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator dropoutGeneratorOutputDevice)
  (Generator dropoutGeneratorOutputDevice)
  (Tensor
     (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
     (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
     (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
     (Seq
        (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
        dataType)
     (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape))
-&gt; (Tensor
      (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
      (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
      (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
      (Seq
         (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
         dataType)
      (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)
    -&gt; IxStateT
         m
         (Generator dropoutGeneratorOutputDevice)
         (Generator dropoutGeneratorOutputDevice)
         (Tensor
            (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
            (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
            (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
            (Seq
               (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
               dataType)
            (TransposeF
               ('SelectDim ('ByIndex 2))
               ('SelectDim ('ByIndex 3))
               (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape))))
-&gt; IxStateT
     m
     (Generator dropoutGeneratorOutputDevice)
     (Generator dropoutGeneratorOutputDevice)
     (Tensor
        (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
        (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
        (Seq
           (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
           dataType)
        (TransposeF
           ('SelectDim ('ByIndex 2))
           ('SelectDim ('ByIndex 3))
           (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)))
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">m (Tensor
     (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
     (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
     (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
     (Seq
        (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
        dataType)
     (TransposeF
        ('SelectDim ('ByIndex 2))
        ('SelectDim ('ByIndex 3))
        (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)))
-&gt; IxStateT
     m
     (Generator dropoutGeneratorOutputDevice)
     (Generator dropoutGeneratorOutputDevice)
     (Tensor
        (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
        (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
        (Seq
           (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
           dataType)
        (TransposeF
           ('SelectDim ('ByIndex 2))
           ('SelectDim ('ByIndex 3))
           (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)))
forall k (t :: (* -&gt; *) -&gt; k -&gt; k -&gt; * -&gt; *) (m :: * -&gt; *) a
       (i :: k).
(IxMonadTrans t, Monad m) =&gt;
m a -&gt; t m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ilift</span></a></span><span> </span><span class="annot"><span class="annottext">(m (Tensor
      (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
      (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
      (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
      (Seq
         (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
         dataType)
      (TransposeF
         ('SelectDim ('ByIndex 2))
         ('SelectDim ('ByIndex 3))
         (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)))
 -&gt; IxStateT
      m
      (Generator dropoutGeneratorOutputDevice)
      (Generator dropoutGeneratorOutputDevice)
      (Tensor
         (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
         (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
         (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
         (Seq
            (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
            dataType)
         (TransposeF
            ('SelectDim ('ByIndex 2))
            ('SelectDim ('ByIndex 3))
            (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape))))
-&gt; (Tensor
      (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
      (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
      (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
      (Seq
         (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
         dataType)
      (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)
    -&gt; m (Tensor
            (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
            (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
            (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
            (Seq
               (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
               dataType)
            (TransposeF
               ('SelectDim ('ByIndex 2))
               ('SelectDim ('ByIndex 3))
               (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape))))
-&gt; Tensor
     (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
     (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
     (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
     (Seq
        (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
        dataType)
     (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)
-&gt; IxStateT
     m
     (Generator dropoutGeneratorOutputDevice)
     (Generator dropoutGeneratorOutputDevice)
     (Tensor
        (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
        (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
        (Seq
           (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
           dataType)
        (TransposeF
           ('SelectDim ('ByIndex 2))
           ('SelectDim ('ByIndex 3))
           (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)))
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]) (m :: * -&gt; *).
(shape'
 ~ TransposeF
     ('SelectDim ('ByIndex 2)) ('SelectDim ('ByIndex 3)) shape,
 SingI ('SelectDim ('ByIndex 2)), SingI ('SelectDim ('ByIndex 3)),
 MonadThrow m) =&gt;
Tensor gradient layout device dataType shape
-&gt; m (Tensor gradient layout device dataType shape')
forall (selectDim0 :: SelectDim (By Symbol Nat))
       (selectDim1 :: SelectDim (By Symbol Nat))
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]) (m :: * -&gt; *).
(shape' ~ TransposeF selectDim0 selectDim1 shape, SingI selectDim0,
 SingI selectDim1, MonadThrow m) =&gt;
Tensor gradient layout device dataType shape
-&gt; m (Tensor gradient layout device dataType shape')
</span><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#transpose"><span class="hs-identifier hs-var">transpose</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">2</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">3</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-483"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator dropoutGeneratorOutputDevice)
  (Generator dropoutGeneratorOutputDevice)
  (Tensor
     (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
     (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
     (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
     (Seq
        (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
        dataType)
     (TransposeF
        ('SelectDim ('ByIndex 2))
        ('SelectDim ('ByIndex 3))
        (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)))
-&gt; (Tensor
      (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
      (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
      (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
      (Seq
         (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
         dataType)
      (TransposeF
         ('SelectDim ('ByIndex 2))
         ('SelectDim ('ByIndex 3))
         (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape))
    -&gt; IxStateT
         m
         (Generator dropoutGeneratorOutputDevice)
         (Generator dropoutGeneratorOutputDevice)
         (Tensor
            (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
            (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
            (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
            (Seq
               (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
               dataType)
            (TransposeF
               ('SelectDim ('ByIndex 1))
               ('SelectDim ('ByIndex 2))
               (TransposeF
                  ('SelectDim ('ByIndex 2))
                  ('SelectDim ('ByIndex 3))
                  (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)))))
-&gt; IxStateT
     m
     (Generator dropoutGeneratorOutputDevice)
     (Generator dropoutGeneratorOutputDevice)
     (Tensor
        (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
        (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
        (Seq
           (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
           dataType)
        (TransposeF
           ('SelectDim ('ByIndex 1))
           ('SelectDim ('ByIndex 2))
           (TransposeF
              ('SelectDim ('ByIndex 2))
              ('SelectDim ('ByIndex 3))
              (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape))))
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">m (Tensor
     (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
     (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
     (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
     (Seq
        (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
        dataType)
     (TransposeF
        ('SelectDim ('ByIndex 1))
        ('SelectDim ('ByIndex 2))
        (TransposeF
           ('SelectDim ('ByIndex 2))
           ('SelectDim ('ByIndex 3))
           (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape))))
-&gt; IxStateT
     m
     (Generator dropoutGeneratorOutputDevice)
     (Generator dropoutGeneratorOutputDevice)
     (Tensor
        (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
        (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
        (Seq
           (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
           dataType)
        (TransposeF
           ('SelectDim ('ByIndex 1))
           ('SelectDim ('ByIndex 2))
           (TransposeF
              ('SelectDim ('ByIndex 2))
              ('SelectDim ('ByIndex 3))
              (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape))))
forall k (t :: (* -&gt; *) -&gt; k -&gt; k -&gt; * -&gt; *) (m :: * -&gt; *) a
       (i :: k).
(IxMonadTrans t, Monad m) =&gt;
m a -&gt; t m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ilift</span></a></span><span> </span><span class="annot"><span class="annottext">(m (Tensor
      (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
      (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
      (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
      (Seq
         (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
         dataType)
      (TransposeF
         ('SelectDim ('ByIndex 1))
         ('SelectDim ('ByIndex 2))
         (TransposeF
            ('SelectDim ('ByIndex 2))
            ('SelectDim ('ByIndex 3))
            (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape))))
 -&gt; IxStateT
      m
      (Generator dropoutGeneratorOutputDevice)
      (Generator dropoutGeneratorOutputDevice)
      (Tensor
         (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
         (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
         (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
         (Seq
            (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
            dataType)
         (TransposeF
            ('SelectDim ('ByIndex 1))
            ('SelectDim ('ByIndex 2))
            (TransposeF
               ('SelectDim ('ByIndex 2))
               ('SelectDim ('ByIndex 3))
               (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)))))
-&gt; (Tensor
      (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
      (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
      (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
      (Seq
         (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
         dataType)
      (TransposeF
         ('SelectDim ('ByIndex 2))
         ('SelectDim ('ByIndex 3))
         (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape))
    -&gt; m (Tensor
            (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
            (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
            (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
            (Seq
               (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
               dataType)
            (TransposeF
               ('SelectDim ('ByIndex 1))
               ('SelectDim ('ByIndex 2))
               (TransposeF
                  ('SelectDim ('ByIndex 2))
                  ('SelectDim ('ByIndex 3))
                  (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)))))
-&gt; Tensor
     (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
     (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
     (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
     (Seq
        (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
        dataType)
     (TransposeF
        ('SelectDim ('ByIndex 2))
        ('SelectDim ('ByIndex 3))
        (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape))
-&gt; IxStateT
     m
     (Generator dropoutGeneratorOutputDevice)
     (Generator dropoutGeneratorOutputDevice)
     (Tensor
        (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
        (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
        (Seq
           (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
           dataType)
        (TransposeF
           ('SelectDim ('ByIndex 1))
           ('SelectDim ('ByIndex 2))
           (TransposeF
              ('SelectDim ('ByIndex 2))
              ('SelectDim ('ByIndex 3))
              (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape))))
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]) (m :: * -&gt; *).
(shape'
 ~ TransposeF
     ('SelectDim ('ByIndex 1)) ('SelectDim ('ByIndex 2)) shape,
 SingI ('SelectDim ('ByIndex 1)), SingI ('SelectDim ('ByIndex 2)),
 MonadThrow m) =&gt;
Tensor gradient layout device dataType shape
-&gt; m (Tensor gradient layout device dataType shape')
forall (selectDim0 :: SelectDim (By Symbol Nat))
       (selectDim1 :: SelectDim (By Symbol Nat))
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]) (m :: * -&gt; *).
(shape' ~ TransposeF selectDim0 selectDim1 shape, SingI selectDim0,
 SingI selectDim1, MonadThrow m) =&gt;
Tensor gradient layout device dataType shape
-&gt; m (Tensor gradient layout device dataType shape')
</span><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#transpose"><span class="hs-identifier hs-var">transpose</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">2</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-484"></span><span>        </span><span id="local-6989586621679808509"><span class="annot"><span class="annottext">decoderAttentionBias :: IxStateT
  m
  (Generator dropoutGeneratorOutputDevice)
  (Generator dropoutGeneratorOutputDevice)
  (Tensor
     (Or
        (Gradient RequiresGradient)
        (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
        decoderAttentionMaskGradient)
     (Unify
        (Layout LayoutType)
        (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
        decoderAttentionMaskLayout)
     (Unify
        (Device (DeviceType Nat))
        (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
        decoderAttentionMaskDevice)
     (Unify
        (DataType DType)
        (Seq
           (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
           dataType)
        decoderAttentionMaskDataType)
     (BroadcastShapesF
        (TransposeF
           ('SelectDim ('ByIndex 1))
           ('SelectDim ('ByIndex 2))
           (TransposeF
              ('SelectDim ('ByIndex 2))
              ('SelectDim ('ByIndex 3))
              (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)))
        (UnsqueezeF ('SelectDim ('ByIndex 1)) decoderAttentionMaskShape)))
</span><a href="#local-6989586621679808509"><span class="hs-identifier hs-var hs-var">decoderAttentionBias</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-485"></span><span>          </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator dropoutGeneratorOutputDevice)
  (Generator dropoutGeneratorOutputDevice)
  (Tensor
     (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
     (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
     (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
     (Seq
        (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
        dataType)
     (TransposeF
        ('SelectDim ('ByIndex 1))
        ('SelectDim ('ByIndex 2))
        (TransposeF
           ('SelectDim ('ByIndex 2))
           ('SelectDim ('ByIndex 3))
           (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape))))
</span><a href="#local-6989586621679808510"><span class="hs-identifier hs-var">decoderRelPosBias</span></a></span><span>
</span><span id="line-486"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator dropoutGeneratorOutputDevice)
  (Generator dropoutGeneratorOutputDevice)
  (Tensor
     (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
     (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
     (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
     (Seq
        (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
        dataType)
     (TransposeF
        ('SelectDim ('ByIndex 1))
        ('SelectDim ('ByIndex 2))
        (TransposeF
           ('SelectDim ('ByIndex 2))
           ('SelectDim ('ByIndex 3))
           (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape))))
-&gt; (Tensor
      (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
      (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
      (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
      (Seq
         (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
         dataType)
      (TransposeF
         ('SelectDim ('ByIndex 1))
         ('SelectDim ('ByIndex 2))
         (TransposeF
            ('SelectDim ('ByIndex 2))
            ('SelectDim ('ByIndex 3))
            (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)))
    -&gt; IxStateT
         m
         (Generator dropoutGeneratorOutputDevice)
         (Generator dropoutGeneratorOutputDevice)
         (Tensor
            (Or
               (Gradient RequiresGradient)
               (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
               decoderAttentionMaskGradient)
            (Unify
               (Layout LayoutType)
               (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
               decoderAttentionMaskLayout)
            (Unify
               (Device (DeviceType Nat))
               (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
               decoderAttentionMaskDevice)
            (Unify
               (DataType DType)
               (Seq
                  (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
                  dataType)
               decoderAttentionMaskDataType)
            (BroadcastShapesF
               (TransposeF
                  ('SelectDim ('ByIndex 1))
                  ('SelectDim ('ByIndex 2))
                  (TransposeF
                     ('SelectDim ('ByIndex 2))
                     ('SelectDim ('ByIndex 3))
                     (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)))
               (UnsqueezeF ('SelectDim ('ByIndex 1)) decoderAttentionMaskShape))))
-&gt; IxStateT
     m
     (Generator dropoutGeneratorOutputDevice)
     (Generator dropoutGeneratorOutputDevice)
     (Tensor
        (Or
           (Gradient RequiresGradient)
           (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
           decoderAttentionMaskGradient)
        (Unify
           (Layout LayoutType)
           (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
           decoderAttentionMaskLayout)
        (Unify
           (Device (DeviceType Nat))
           (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
           decoderAttentionMaskDevice)
        (Unify
           (DataType DType)
           (Seq
              (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
              dataType)
           decoderAttentionMaskDataType)
        (BroadcastShapesF
           (TransposeF
              ('SelectDim ('ByIndex 1))
              ('SelectDim ('ByIndex 2))
              (TransposeF
                 ('SelectDim ('ByIndex 2))
                 ('SelectDim ('ByIndex 3))
                 (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)))
           (UnsqueezeF ('SelectDim ('ByIndex 1)) decoderAttentionMaskShape)))
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  (Or
     (Gradient RequiresGradient)
     (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
     decoderAttentionMaskGradient)
  (Unify
     (Layout LayoutType)
     (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
     decoderAttentionMaskLayout)
  (Unify
     (Device (DeviceType Nat))
     (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
     decoderAttentionMaskDevice)
  (Unify
     (DataType DType)
     (Seq
        (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
        dataType)
     decoderAttentionMaskDataType)
  (BroadcastShapesF
     (TransposeF
        ('SelectDim ('ByIndex 1))
        ('SelectDim ('ByIndex 2))
        (TransposeF
           ('SelectDim ('ByIndex 2))
           ('SelectDim ('ByIndex 3))
           (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)))
     (UnsqueezeF ('SelectDim ('ByIndex 1)) decoderAttentionMaskShape))
-&gt; IxStateT
     m
     (Generator dropoutGeneratorOutputDevice)
     (Generator dropoutGeneratorOutputDevice)
     (Tensor
        (Or
           (Gradient RequiresGradient)
           (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
           decoderAttentionMaskGradient)
        (Unify
           (Layout LayoutType)
           (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
           decoderAttentionMaskLayout)
        (Unify
           (Device (DeviceType Nat))
           (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
           decoderAttentionMaskDevice)
        (Unify
           (DataType DType)
           (Seq
              (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
              dataType)
           decoderAttentionMaskDataType)
        (BroadcastShapesF
           (TransposeF
              ('SelectDim ('ByIndex 1))
              ('SelectDim ('ByIndex 2))
              (TransposeF
                 ('SelectDim ('ByIndex 2))
                 ('SelectDim ('ByIndex 3))
                 (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)))
           (UnsqueezeF ('SelectDim ('ByIndex 1)) decoderAttentionMaskShape)))
forall k (m :: k -&gt; k -&gt; * -&gt; *) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">(Tensor
   (Or
      (Gradient RequiresGradient)
      (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
      decoderAttentionMaskGradient)
   (Unify
      (Layout LayoutType)
      (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
      decoderAttentionMaskLayout)
   (Unify
      (Device (DeviceType Nat))
      (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
      decoderAttentionMaskDevice)
   (Unify
      (DataType DType)
      (Seq
         (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
         dataType)
      decoderAttentionMaskDataType)
   (BroadcastShapesF
      (TransposeF
         ('SelectDim ('ByIndex 1))
         ('SelectDim ('ByIndex 2))
         (TransposeF
            ('SelectDim ('ByIndex 2))
            ('SelectDim ('ByIndex 3))
            (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)))
      (UnsqueezeF ('SelectDim ('ByIndex 1)) decoderAttentionMaskShape))
 -&gt; IxStateT
      m
      (Generator dropoutGeneratorOutputDevice)
      (Generator dropoutGeneratorOutputDevice)
      (Tensor
         (Or
            (Gradient RequiresGradient)
            (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
            decoderAttentionMaskGradient)
         (Unify
            (Layout LayoutType)
            (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
            decoderAttentionMaskLayout)
         (Unify
            (Device (DeviceType Nat))
            (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
            decoderAttentionMaskDevice)
         (Unify
            (DataType DType)
            (Seq
               (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
               dataType)
            decoderAttentionMaskDataType)
         (BroadcastShapesF
            (TransposeF
               ('SelectDim ('ByIndex 1))
               ('SelectDim ('ByIndex 2))
               (TransposeF
                  ('SelectDim ('ByIndex 2))
                  ('SelectDim ('ByIndex 3))
                  (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)))
            (UnsqueezeF ('SelectDim ('ByIndex 1)) decoderAttentionMaskShape))))
-&gt; (Tensor
      (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
      (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
      (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
      (Seq
         (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
         dataType)
      (TransposeF
         ('SelectDim ('ByIndex 1))
         ('SelectDim ('ByIndex 2))
         (TransposeF
            ('SelectDim ('ByIndex 2))
            ('SelectDim ('ByIndex 3))
            (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)))
    -&gt; Tensor
         (Or
            (Gradient RequiresGradient)
            (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
            decoderAttentionMaskGradient)
         (Unify
            (Layout LayoutType)
            (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
            decoderAttentionMaskLayout)
         (Unify
            (Device (DeviceType Nat))
            (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
            decoderAttentionMaskDevice)
         (Unify
            (DataType DType)
            (Seq
               (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
               dataType)
            decoderAttentionMaskDataType)
         (BroadcastShapesF
            (TransposeF
               ('SelectDim ('ByIndex 1))
               ('SelectDim ('ByIndex 2))
               (TransposeF
                  ('SelectDim ('ByIndex 2))
                  ('SelectDim ('ByIndex 3))
                  (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)))
            (UnsqueezeF ('SelectDim ('ByIndex 1)) decoderAttentionMaskShape)))
-&gt; Tensor
     (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
     (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
     (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
     (Seq
        (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
        dataType)
     (TransposeF
        ('SelectDim ('ByIndex 1))
        ('SelectDim ('ByIndex 2))
        (TransposeF
           ('SelectDim ('ByIndex 2))
           ('SelectDim ('ByIndex 3))
           (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)))
-&gt; IxStateT
     m
     (Generator dropoutGeneratorOutputDevice)
     (Generator dropoutGeneratorOutputDevice)
     (Tensor
        (Or
           (Gradient RequiresGradient)
           (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
           decoderAttentionMaskGradient)
        (Unify
           (Layout LayoutType)
           (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
           decoderAttentionMaskLayout)
        (Unify
           (Device (DeviceType Nat))
           (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
           decoderAttentionMaskDevice)
        (Unify
           (DataType DType)
           (Seq
              (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
              dataType)
           decoderAttentionMaskDataType)
        (BroadcastShapesF
           (TransposeF
              ('SelectDim ('ByIndex 1))
              ('SelectDim ('ByIndex 2))
              (TransposeF
                 ('SelectDim ('ByIndex 2))
                 ('SelectDim ('ByIndex 3))
                 (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)))
           (UnsqueezeF ('SelectDim ('ByIndex 1)) decoderAttentionMaskShape)))
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Tensor
  (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
  (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
  (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
  (Seq
     (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
     dataType)
  (TransposeF
     ('SelectDim ('ByIndex 1))
     ('SelectDim ('ByIndex 2))
     (TransposeF
        ('SelectDim ('ByIndex 2))
        ('SelectDim ('ByIndex 3))
        (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)))
-&gt; Tensor
     decoderAttentionMaskGradient
     decoderAttentionMaskLayout
     decoderAttentionMaskDevice
     decoderAttentionMaskDataType
     (UnsqueezeF ('SelectDim ('ByIndex 1)) decoderAttentionMaskShape)
-&gt; Tensor
     (Or (Gradient RequiresGradient) gradient decoderRelPosGradient
      &lt;|&gt; decoderAttentionMaskGradient)
     (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout
      &lt;+&gt; decoderAttentionMaskLayout)
     (Unify (Device (DeviceType Nat)) device decoderRelPosDevice
      &lt;+&gt; decoderAttentionMaskDevice)
     (Seq
        (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
        dataType
      &lt;+&gt; decoderAttentionMaskDataType)
     (BroadcastShapesF
        (TransposeF
           ('SelectDim ('ByIndex 1))
           ('SelectDim ('ByIndex 2))
           (TransposeF
              ('SelectDim ('ByIndex 2))
              ('SelectDim ('ByIndex 3))
              (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)))
        (UnsqueezeF ('SelectDim ('ByIndex 1)) decoderAttentionMaskShape))
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (gradient' :: Gradient RequiresGradient)
       (layout' :: Layout LayoutType) (device' :: Device (DeviceType Nat))
       (dataType' :: DataType DType)
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]).
Tensor gradient layout device dataType shape
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; Tensor
     (gradient &lt;|&gt; gradient')
     (layout &lt;+&gt; layout')
     (device &lt;+&gt; device')
     (dataType &lt;+&gt; dataType')
     (BroadcastShapesF shape shape')
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#add"><span class="hs-operator hs-var">`add`</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  decoderAttentionMaskGradient
  decoderAttentionMaskLayout
  decoderAttentionMaskDevice
  decoderAttentionMaskDataType
  decoderAttentionMaskShape
-&gt; Tensor
     decoderAttentionMaskGradient
     decoderAttentionMaskLayout
     decoderAttentionMaskDevice
     decoderAttentionMaskDataType
     (UnsqueezeF ('SelectDim ('ByIndex 1)) decoderAttentionMaskShape)
forall (selectDim :: SelectDim (By Symbol Nat))
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]).
(shape' ~ UnsqueezeF selectDim shape, SingI selectDim) =&gt;
Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape'
</span><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#unsqueeze"><span class="hs-identifier hs-var">unsqueeze</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
  decoderAttentionMaskGradient
  decoderAttentionMaskLayout
  decoderAttentionMaskDevice
  decoderAttentionMaskDataType
  decoderAttentionMaskShape
</span><a href="#local-6989586621679808512"><span class="hs-identifier hs-var">decoderAttentionMask</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-487"></span><span>        </span><span id="local-6989586621679808508"><span class="annot"><span class="annottext">crossAttentionBias :: Tensor
  crossAttentionMaskGradient
  crossAttentionMaskLayout
  crossAttentionMaskDevice
  crossAttentionMaskDataType
  (UnsqueezeF ('SelectDim ('ByIndex 1)) crossAttentionMaskShape)
</span><a href="#local-6989586621679808508"><span class="hs-identifier hs-var hs-var">crossAttentionBias</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor
  crossAttentionMaskGradient
  crossAttentionMaskLayout
  crossAttentionMaskDevice
  crossAttentionMaskDataType
  crossAttentionMaskShape
-&gt; Tensor
     crossAttentionMaskGradient
     crossAttentionMaskLayout
     crossAttentionMaskDevice
     crossAttentionMaskDataType
     (UnsqueezeF ('SelectDim ('ByIndex 1)) crossAttentionMaskShape)
forall (selectDim :: SelectDim (By Symbol Nat))
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]).
(shape' ~ UnsqueezeF selectDim shape, SingI selectDim) =&gt;
Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape'
</span><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#unsqueeze"><span class="hs-identifier hs-var">unsqueeze</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
  crossAttentionMaskGradient
  crossAttentionMaskLayout
  crossAttentionMaskDevice
  crossAttentionMaskDataType
  crossAttentionMaskShape
</span><a href="#local-6989586621679808511"><span class="hs-identifier hs-var">crossAttentionMask</span></a></span><span>
</span><span id="line-488"></span><span>     </span><span class="hs-keyword">in</span><span> </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorOutputDevice)
  output
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
forall (m :: * -&gt; *) i j a. IxStateT m i j a -&gt; i -&gt; m (a, j)
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var hs-var">runIxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">(IxStateT
   m
   (Generator generatorDevice)
   (Generator generatorOutputDevice)
   output
 -&gt; Generator generatorDevice
 -&gt; m (output, Generator generatorOutputDevice))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorOutputDevice)
     output
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-489"></span><span>          </span><span class="annot"><span class="annottext">decoderInput
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     decoderInput
forall k (m :: k -&gt; k -&gt; * -&gt; *) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">decoderInput
</span><a href="#local-6989586621679808515"><span class="hs-identifier hs-var">decoderInput</span></a></span><span>
</span><span id="line-490"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorDevice)
  decoderInput
-&gt; (decoderInput
    -&gt; IxStateT
         m
         (Generator generatorDevice)
         (Generator dropoutGeneratorOutputDevice)
         dropoutOutput)
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator dropoutGeneratorOutputDevice)
     dropoutOutput
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(Generator generatorDevice
 -&gt; m (dropoutOutput, Generator dropoutGeneratorOutputDevice))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator dropoutGeneratorOutputDevice)
     dropoutOutput
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator generatorDevice
  -&gt; m (dropoutOutput, Generator dropoutGeneratorOutputDevice))
 -&gt; IxStateT
      m
      (Generator generatorDevice)
      (Generator dropoutGeneratorOutputDevice)
      dropoutOutput)
-&gt; (decoderInput
    -&gt; Generator generatorDevice
    -&gt; m (dropoutOutput, Generator dropoutGeneratorOutputDevice))
-&gt; decoderInput
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator dropoutGeneratorOutputDevice)
     dropoutOutput
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Dropout
-&gt; decoderInput
-&gt; Generator generatorDevice
-&gt; m (dropoutOutput, Generator dropoutGeneratorOutputDevice)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: * -&gt; *).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">Dropout
TDDropoutF 'T5
</span><a href="#local-6989586621679808517"><span class="hs-identifier hs-var">tdDropout</span></a></span><span>
</span><span id="line-491"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator dropoutGeneratorOutputDevice)
  dropoutOutput
-&gt; (dropoutOutput
    -&gt; IxStateT
         m
         (Generator dropoutGeneratorOutputDevice)
         (Generator stackGeneratorOutputDevice)
         stackOutput)
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator stackGeneratorOutputDevice)
     stackOutput
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="hs-special">(</span><span> </span><span class="hs-glyph">\</span><span id="local-6989586621679808507"><span class="annot"><span class="annottext">dropoutOutput
</span><a href="#local-6989586621679808507"><span class="hs-identifier hs-var">decoderInput'</span></a></span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-492"></span><span>                     </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator dropoutGeneratorOutputDevice)
  (Generator dropoutGeneratorOutputDevice)
  (Tensor
     (Or
        (Gradient RequiresGradient)
        (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
        decoderAttentionMaskGradient)
     (Unify
        (Layout LayoutType)
        (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
        decoderAttentionMaskLayout)
     (Unify
        (Device (DeviceType Nat))
        (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
        decoderAttentionMaskDevice)
     (Unify
        (DataType DType)
        (Seq
           (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
           dataType)
        decoderAttentionMaskDataType)
     (BroadcastShapesF
        (TransposeF
           ('SelectDim ('ByIndex 1))
           ('SelectDim ('ByIndex 2))
           (TransposeF
              ('SelectDim ('ByIndex 2))
              ('SelectDim ('ByIndex 3))
              (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)))
        (UnsqueezeF ('SelectDim ('ByIndex 1)) decoderAttentionMaskShape)))
</span><a href="#local-6989586621679808509"><span class="hs-identifier hs-var">decoderAttentionBias</span></a></span><span>
</span><span id="line-493"></span><span>                       </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator dropoutGeneratorOutputDevice)
  (Generator dropoutGeneratorOutputDevice)
  (Tensor
     (Or
        (Gradient RequiresGradient)
        (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
        decoderAttentionMaskGradient)
     (Unify
        (Layout LayoutType)
        (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
        decoderAttentionMaskLayout)
     (Unify
        (Device (DeviceType Nat))
        (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
        decoderAttentionMaskDevice)
     (Unify
        (DataType DType)
        (Seq
           (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
           dataType)
        decoderAttentionMaskDataType)
     (BroadcastShapesF
        (TransposeF
           ('SelectDim ('ByIndex 1))
           ('SelectDim ('ByIndex 2))
           (TransposeF
              ('SelectDim ('ByIndex 2))
              ('SelectDim ('ByIndex 3))
              (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)))
        (UnsqueezeF ('SelectDim ('ByIndex 1)) decoderAttentionMaskShape)))
-&gt; (Tensor
      (Or
         (Gradient RequiresGradient)
         (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
         decoderAttentionMaskGradient)
      (Unify
         (Layout LayoutType)
         (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
         decoderAttentionMaskLayout)
      (Unify
         (Device (DeviceType Nat))
         (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
         decoderAttentionMaskDevice)
      (Unify
         (DataType DType)
         (Seq
            (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
            dataType)
         decoderAttentionMaskDataType)
      (BroadcastShapesF
         (TransposeF
            ('SelectDim ('ByIndex 1))
            ('SelectDim ('ByIndex 2))
            (TransposeF
               ('SelectDim ('ByIndex 2))
               ('SelectDim ('ByIndex 3))
               (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)))
         (UnsqueezeF ('SelectDim ('ByIndex 1)) decoderAttentionMaskShape))
    -&gt; IxStateT
         m
         (Generator dropoutGeneratorOutputDevice)
         (Generator stackGeneratorOutputDevice)
         stackOutput)
-&gt; IxStateT
     m
     (Generator dropoutGeneratorOutputDevice)
     (Generator stackGeneratorOutputDevice)
     stackOutput
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="hs-special">(</span><span> </span><span class="hs-glyph">\</span><span id="local-6989586621679808506"><span class="annot"><span class="annottext">Tensor
  (Or
     (Gradient RequiresGradient)
     (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
     decoderAttentionMaskGradient)
  (Unify
     (Layout LayoutType)
     (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
     decoderAttentionMaskLayout)
  (Unify
     (Device (DeviceType Nat))
     (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
     decoderAttentionMaskDevice)
  (Unify
     (DataType DType)
     (Seq
        (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
        dataType)
     decoderAttentionMaskDataType)
  (BroadcastShapesF
     (TransposeF
        ('SelectDim ('ByIndex 1))
        ('SelectDim ('ByIndex 2))
        (TransposeF
           ('SelectDim ('ByIndex 2))
           ('SelectDim ('ByIndex 3))
           (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)))
     (UnsqueezeF ('SelectDim ('ByIndex 1)) decoderAttentionMaskShape))
</span><a href="#local-6989586621679808506"><span class="hs-identifier hs-var">decoderAttentionBias'</span></a></span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-494"></span><span>                                </span><span class="annot"><span class="annottext">(Generator dropoutGeneratorOutputDevice
 -&gt; m (stackOutput, Generator stackGeneratorOutputDevice))
-&gt; IxStateT
     m
     (Generator dropoutGeneratorOutputDevice)
     (Generator stackGeneratorOutputDevice)
     stackOutput
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator dropoutGeneratorOutputDevice
  -&gt; m (stackOutput, Generator stackGeneratorOutputDevice))
 -&gt; IxStateT
      m
      (Generator dropoutGeneratorOutputDevice)
      (Generator stackGeneratorOutputDevice)
      stackOutput)
-&gt; (Generator dropoutGeneratorOutputDevice
    -&gt; m (stackOutput, Generator stackGeneratorOutputDevice))
-&gt; IxStateT
     m
     (Generator dropoutGeneratorOutputDevice)
     (Generator stackGeneratorOutputDevice)
     stackOutput
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-495"></span><span>                                  </span><span class="annot"><span class="annottext">TransformerDecoderStack
  'T5
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  decoderInputEmbedDim
  encoderOutputEmbedDim
  ffnDim
-&gt; (dropoutOutput, encoderOutput,
    Tensor
      (Or
         (Gradient RequiresGradient)
         (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
         decoderAttentionMaskGradient)
      (Unify
         (Layout LayoutType)
         (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
         decoderAttentionMaskLayout)
      (Unify
         (Device (DeviceType Nat))
         (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
         decoderAttentionMaskDevice)
      (Unify
         (DataType DType)
         (Seq
            (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
            dataType)
         decoderAttentionMaskDataType)
      (BroadcastShapesF
         (TransposeF
            ('SelectDim ('ByIndex 1))
            ('SelectDim ('ByIndex 2))
            (TransposeF
               ('SelectDim ('ByIndex 2))
               ('SelectDim ('ByIndex 3))
               (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)))
         (UnsqueezeF ('SelectDim ('ByIndex 1)) decoderAttentionMaskShape)),
    Tensor
      crossAttentionMaskGradient
      crossAttentionMaskLayout
      crossAttentionMaskDevice
      crossAttentionMaskDataType
      (UnsqueezeF ('SelectDim ('ByIndex 1)) crossAttentionMaskShape))
-&gt; Generator dropoutGeneratorOutputDevice
-&gt; m (stackOutput, Generator stackGeneratorOutputDevice)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: * -&gt; *).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span>
</span><span id="line-496"></span><span>                                    </span><span class="annot"><span class="annottext">TransformerDecoderStack
  'T5
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  decoderInputEmbedDim
  encoderOutputEmbedDim
  ffnDim
TDStackF
  'T5
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  decoderInputEmbedDim
  encoderOutputEmbedDim
  ffnDim
</span><a href="#local-6989586621679808520"><span class="hs-identifier hs-var">tdStack</span></a></span><span>
</span><span id="line-497"></span><span>                                    </span><span class="hs-special">(</span><span> </span><span class="annot"><span class="annottext">dropoutOutput
</span><a href="#local-6989586621679808507"><span class="hs-identifier hs-var">decoderInput'</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-498"></span><span>                                      </span><span class="annot"><span class="annottext">encoderOutput
</span><a href="#local-6989586621679808514"><span class="hs-identifier hs-var">encoderOutput</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-499"></span><span>                                      </span><span class="annot"><span class="annottext">Tensor
  (Or
     (Gradient RequiresGradient)
     (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
     decoderAttentionMaskGradient)
  (Unify
     (Layout LayoutType)
     (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
     decoderAttentionMaskLayout)
  (Unify
     (Device (DeviceType Nat))
     (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
     decoderAttentionMaskDevice)
  (Unify
     (DataType DType)
     (Seq
        (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
        dataType)
     decoderAttentionMaskDataType)
  (BroadcastShapesF
     (TransposeF
        ('SelectDim ('ByIndex 1))
        ('SelectDim ('ByIndex 2))
        (TransposeF
           ('SelectDim ('ByIndex 2))
           ('SelectDim ('ByIndex 3))
           (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)))
     (UnsqueezeF ('SelectDim ('ByIndex 1)) decoderAttentionMaskShape))
</span><a href="#local-6989586621679808506"><span class="hs-identifier hs-var">decoderAttentionBias'</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-500"></span><span>                                      </span><span class="annot"><span class="annottext">Tensor
  crossAttentionMaskGradient
  crossAttentionMaskLayout
  crossAttentionMaskDevice
  crossAttentionMaskDataType
  (UnsqueezeF ('SelectDim ('ByIndex 1)) crossAttentionMaskShape)
</span><a href="#local-6989586621679808508"><span class="hs-identifier hs-var">crossAttentionBias</span></a></span><span>
</span><span id="line-501"></span><span>                                    </span><span class="hs-special">)</span><span>
</span><span id="line-502"></span><span>                            </span><span class="hs-special">)</span><span>
</span><span id="line-503"></span><span>                 </span><span class="hs-special">)</span><span>
</span><span id="line-504"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator stackGeneratorOutputDevice)
  stackOutput
-&gt; (stackOutput
    -&gt; IxStateT
         m
         (Generator stackGeneratorOutputDevice)
         (Generator layerNormGeneratorOutputDevice)
         layerNormOutput)
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator layerNormGeneratorOutputDevice)
     layerNormOutput
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(Generator stackGeneratorOutputDevice
 -&gt; m (layerNormOutput, Generator layerNormGeneratorOutputDevice))
-&gt; IxStateT
     m
     (Generator stackGeneratorOutputDevice)
     (Generator layerNormGeneratorOutputDevice)
     layerNormOutput
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator stackGeneratorOutputDevice
  -&gt; m (layerNormOutput, Generator layerNormGeneratorOutputDevice))
 -&gt; IxStateT
      m
      (Generator stackGeneratorOutputDevice)
      (Generator layerNormGeneratorOutputDevice)
      layerNormOutput)
-&gt; (stackOutput
    -&gt; Generator stackGeneratorOutputDevice
    -&gt; m (layerNormOutput, Generator layerNormGeneratorOutputDevice))
-&gt; stackOutput
-&gt; IxStateT
     m
     (Generator stackGeneratorOutputDevice)
     (Generator layerNormGeneratorOutputDevice)
     layerNormOutput
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">LayerNorm
  'WithoutBias
  gradient
  device
  dataType
  ('Shape '[decoderInputEmbedDim])
-&gt; stackOutput
-&gt; Generator stackGeneratorOutputDevice
-&gt; m (layerNormOutput, Generator layerNormGeneratorOutputDevice)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: * -&gt; *).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">LayerNorm
  'WithoutBias
  gradient
  device
  dataType
  ('Shape '[decoderInputEmbedDim])
TDLayerNormF 'T5 gradient device dataType decoderInputEmbedDim
</span><a href="#local-6989586621679808518"><span class="hs-identifier hs-var">tdLayerNorm</span></a></span><span>
</span><span id="line-505"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator layerNormGeneratorOutputDevice)
  layerNormOutput
-&gt; (layerNormOutput
    -&gt; IxStateT
         m
         (Generator layerNormGeneratorOutputDevice)
         (Generator generatorOutputDevice)
         output)
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorOutputDevice)
     output
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(Generator layerNormGeneratorOutputDevice
 -&gt; m (output, Generator generatorOutputDevice))
-&gt; IxStateT
     m
     (Generator layerNormGeneratorOutputDevice)
     (Generator generatorOutputDevice)
     output
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator layerNormGeneratorOutputDevice
  -&gt; m (output, Generator generatorOutputDevice))
 -&gt; IxStateT
      m
      (Generator layerNormGeneratorOutputDevice)
      (Generator generatorOutputDevice)
      output)
-&gt; (layerNormOutput
    -&gt; Generator layerNormGeneratorOutputDevice
    -&gt; m (output, Generator generatorOutputDevice))
-&gt; layerNormOutput
-&gt; IxStateT
     m
     (Generator layerNormGeneratorOutputDevice)
     (Generator generatorOutputDevice)
     output
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Dropout
-&gt; layerNormOutput
-&gt; Generator layerNormGeneratorOutputDevice
-&gt; m (output, Generator generatorOutputDevice)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: * -&gt; *).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">Dropout
TDDropoutF 'T5
</span><a href="#local-6989586621679808517"><span class="hs-identifier hs-var">tdDropout</span></a></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span>
</span><span id="line-506"></span><span>
</span><span id="line-507"></span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#testDecoder"><span class="hs-identifier hs-type">testDecoder</span></a></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">IO</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span>
</span><span id="line-508"></span><span id="testDecoder"><span class="annot"><span class="annottext">testDecoder :: IO
  (Tensor
     ('Gradient 'WithGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     ('DataType 'Float)
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7),
           'Dim ('Name &quot;*&quot;) ('Size 512)]))
</span><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#testDecoder"><span class="hs-identifier hs-var hs-var">testDecoder</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-509"></span><span>  </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679808504"><span class="annot"><span class="annottext">gradient :: SGradient ('Gradient 'WithGradient)
</span><a href="#local-6989586621679808504"><span class="hs-identifier hs-var hs-var">gradient</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SRequiresGradient 'WithGradient
-&gt; SGradient ('Gradient 'WithGradient)
forall (requiresGradient :: RequiresGradient).
SRequiresGradient requiresGradient
-&gt; SGradient ('Gradient requiresGradient)
</span><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier hs-var">SGradient</span></a></span><span> </span><span class="annot"><span class="annottext">SRequiresGradient 'WithGradient
</span><a href="Torch.GraduallyTyped.RequiresGradient.html#SWithGradient"><span class="hs-identifier hs-var">SWithGradient</span></a></span><span>
</span><span id="line-510"></span><span>      </span><span id="local-6989586621679808501"><span class="annot"><span class="annottext">device :: SDevice ('Device 'CPU)
</span><a href="#local-6989586621679808501"><span class="hs-identifier hs-var hs-var">device</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SDeviceType 'CPU -&gt; SDevice ('Device 'CPU)
forall (deviceType :: DeviceType Nat).
SDeviceType deviceType -&gt; SDevice ('Device deviceType)
</span><a href="Torch.GraduallyTyped.Device.html#SDevice"><span class="hs-identifier hs-var">SDevice</span></a></span><span> </span><span class="annot"><span class="annottext">SDeviceType 'CPU
</span><a href="Torch.GraduallyTyped.Device.html#SCPU"><span class="hs-identifier hs-var">SCPU</span></a></span><span>
</span><span id="line-511"></span><span>      </span><span id="local-6989586621679808498"><span class="annot"><span class="annottext">dataType :: SDataType ('DataType 'Float)
</span><a href="#local-6989586621679808498"><span class="hs-identifier hs-var hs-var">dataType</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SDType 'Float -&gt; SDataType ('DataType 'Float)
forall (dType :: DType).
SDType dType -&gt; SDataType ('DataType dType)
</span><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier hs-var">SDataType</span></a></span><span> </span><span class="annot"><span class="annottext">SDType 'Float
</span><a href="Torch.GraduallyTyped.DType.html#SFloat"><span class="hs-identifier hs-var">SFloat</span></a></span><span>
</span><span id="line-512"></span><span>      </span><span id="local-6989586621679808495"><span class="annot"><span class="annottext">headDim :: SDim ('Dim ('Name &quot;*&quot;) ('Size 8))
</span><a href="#local-6989586621679808495"><span class="hs-identifier hs-var hs-var">headDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize ('Size 8) -&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 8))
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownNat 8 =&gt; SSize ('Size 8)
forall (size :: Nat). KnownNat size =&gt; SSize ('Size size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier hs-var">SSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">8</span></span><span>
</span><span id="line-513"></span><span>      </span><span id="local-6989586621679808492"><span class="annot"><span class="annottext">headEmbedDim :: SDim ('Dim ('Name &quot;*&quot;) ('Size 64))
</span><a href="#local-6989586621679808492"><span class="hs-identifier hs-var hs-var">headEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize ('Size 64) -&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 64))
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownNat 64 =&gt; SSize ('Size 64)
forall (size :: Nat). KnownNat size =&gt; SSize ('Size size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier hs-var">SSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">64</span></span><span>
</span><span id="line-514"></span><span>      </span><span id="local-6989586621679808491"><span class="annot"><span class="annottext">embedDim :: SDim ('Dim ('Name &quot;*&quot;) ('Size 512))
</span><a href="#local-6989586621679808491"><span class="hs-identifier hs-var hs-var">embedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize ('Size 512) -&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 512))
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownNat 512 =&gt; SSize ('Size 512)
forall (size :: Nat). KnownNat size =&gt; SSize ('Size size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier hs-var">SSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">512</span></span><span>
</span><span id="line-515"></span><span>      </span><span id="local-6989586621679808490"><span class="annot"><span class="annottext">decoderInputEmbedDim :: SDim ('Dim ('Name &quot;*&quot;) ('Size 512))
</span><a href="#local-6989586621679808490"><span class="hs-identifier hs-var hs-var">decoderInputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize ('Size 512) -&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 512))
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownNat 512 =&gt; SSize ('Size 512)
forall (size :: Nat). KnownNat size =&gt; SSize ('Size size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier hs-var">SSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">512</span></span><span>
</span><span id="line-516"></span><span>      </span><span id="local-6989586621679808489"><span class="annot"><span class="annottext">encoderOutputEmbedDim :: SDim ('Dim ('Name &quot;*&quot;) ('Size 512))
</span><a href="#local-6989586621679808489"><span class="hs-identifier hs-var hs-var">encoderOutputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 512))
</span><a href="#local-6989586621679808490"><span class="hs-identifier hs-var">decoderInputEmbedDim</span></a></span><span>
</span><span id="line-517"></span><span>      </span><span id="local-6989586621679808488"><span class="annot"><span class="annottext">ffnDim :: SDim ('Dim ('Name &quot;*&quot;) ('Size 2048))
</span><a href="#local-6989586621679808488"><span class="hs-identifier hs-var hs-var">ffnDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize ('Size 2048) -&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 2048))
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownNat 2048 =&gt; SSize ('Size 2048)
forall (size :: Nat). KnownNat size =&gt; SSize ('Size size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier hs-var">SSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">2048</span></span><span>
</span><span id="line-518"></span><span>      </span><span id="local-6989586621679808487"><span class="annot"><span class="annottext">posEncDim :: SDim ('Dim ('Name &quot;*&quot;) ('Size 32))
</span><a href="#local-6989586621679808487"><span class="hs-identifier hs-var hs-var">posEncDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize ('Size 32) -&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 32))
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownNat 32 =&gt; SSize ('Size 32)
forall (size :: Nat). KnownNat size =&gt; SSize ('Size size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier hs-var">SSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">32</span></span><span>
</span><span id="line-519"></span><span>      </span><span id="local-6989586621679808486"><span class="annot"><span class="annottext">dropoutP :: Double
</span><a href="#local-6989586621679808486"><span class="hs-identifier hs-var hs-var">dropoutP</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Double
</span><span class="hs-number">0.0</span></span><span>
</span><span id="line-520"></span><span>      </span><span id="local-6989586621679808485"><span class="annot"><span class="annottext">eps :: Double
</span><a href="#local-6989586621679808485"><span class="hs-identifier hs-var hs-var">eps</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Double
</span><span class="hs-number">1e-6</span></span><span>
</span><span id="line-521"></span><span>  </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679808484"><span class="annot"><span class="annottext">g :: Generator ('Device 'CPU)
</span><a href="#local-6989586621679808484"><span class="hs-identifier hs-var hs-var">g</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SDevice ('Device 'CPU) -&gt; Word64 -&gt; Generator ('Device 'CPU)
forall (device :: Device (DeviceType Nat)).
SDevice device -&gt; Word64 -&gt; Generator device
</span><a href="Torch.GraduallyTyped.Random.html#sMkGenerator"><span class="hs-identifier hs-var">sMkGenerator</span></a></span><span> </span><span class="annot"><span class="annottext">SDevice ('Device 'CPU)
</span><a href="#local-6989586621679808501"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">Word64
</span><span class="hs-number">0</span></span><span>
</span><span id="line-522"></span><span>  </span><span class="hs-special">(</span><span id="local-6989586621679808483"><span class="annot"><span class="annottext">TransformerDecoder
  'T5
  1
  ('Gradient 'WithGradient)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Dim ('Name &quot;*&quot;) ('Size 8))
  ('Dim ('Name &quot;*&quot;) ('Size 64))
  ('Dim ('Name &quot;*&quot;) ('Size 512))
  ('Dim ('Name &quot;*&quot;) ('Size 512))
  ('Dim ('Name &quot;*&quot;) ('Size 512))
  ('Dim ('Name &quot;*&quot;) ('Size 2048))
  ('Dim ('Name &quot;*&quot;) ('Size 32))
</span><a href="#local-6989586621679808483"><span class="hs-identifier hs-var">encoder</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679808482"><span class="annot"><span class="annottext">Generator ('Device 'CPU)
</span><a href="#local-6989586621679808482"><span class="hs-identifier hs-var">g'</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (TransformerDecoder
     'T5
     1
     ('Gradient 'WithGradient)
     ('Device 'CPU)
     ('DataType 'Float)
     ('Dim ('Name &quot;*&quot;) ('Size 8))
     ('Dim ('Name &quot;*&quot;) ('Size 64))
     ('Dim ('Name &quot;*&quot;) ('Size 512))
     ('Dim ('Name &quot;*&quot;) ('Size 512))
     ('Dim ('Name &quot;*&quot;) ('Size 512))
     ('Dim ('Name &quot;*&quot;) ('Size 2048))
     ('Dim ('Name &quot;*&quot;) ('Size 32)))
-&gt; Generator ('Device 'CPU)
-&gt; IO
     (TransformerDecoder
        'T5
        1
        ('Gradient 'WithGradient)
        ('Device 'CPU)
        ('DataType 'Float)
        ('Dim ('Name &quot;*&quot;) ('Size 8))
        ('Dim ('Name &quot;*&quot;) ('Size 64))
        ('Dim ('Name &quot;*&quot;) ('Size 512))
        ('Dim ('Name &quot;*&quot;) ('Size 512))
        ('Dim ('Name &quot;*&quot;) ('Size 512))
        ('Dim ('Name &quot;*&quot;) ('Size 2048))
        ('Dim ('Name &quot;*&quot;) ('Size 32)),
      Generator ('Device 'CPU))
forall model (generatorDevice :: Device (DeviceType Nat)) output
       (generatorOutputDevice :: Device (DeviceType Nat)) (m :: * -&gt; *).
(HasInitialize model generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
ModelSpec model
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#initialize"><span class="hs-identifier hs-var">initialize</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">STransformerStyle 'T5
-&gt; SNat 1
-&gt; SGradient ('Gradient 'WithGradient)
-&gt; SDevice ('Device 'CPU)
-&gt; SDataType ('DataType 'Float)
-&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 8))
-&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 64))
-&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 512))
-&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 512))
-&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 512))
-&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 2048))
-&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 32))
-&gt; Double
-&gt; Double
-&gt; TransformerDecoderSpec
     'T5
     1
     ('Gradient 'WithGradient)
     ('Device 'CPU)
     ('DataType 'Float)
     ('Dim ('Name &quot;*&quot;) ('Size 8))
     ('Dim ('Name &quot;*&quot;) ('Size 64))
     ('Dim ('Name &quot;*&quot;) ('Size 512))
     ('Dim ('Name &quot;*&quot;) ('Size 512))
     ('Dim ('Name &quot;*&quot;) ('Size 512))
     ('Dim ('Name &quot;*&quot;) ('Size 2048))
     ('Dim ('Name &quot;*&quot;) ('Size 32))
forall (style :: TransformerStyle) (numLayers :: Nat)
       (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (headDim :: Dim (Name Symbol) (Size Nat))
       (headEmbedDim :: Dim (Name Symbol) (Size Nat))
       (embedDim :: Dim (Name Symbol) (Size Nat))
       (decoderInputEmbedDim :: Dim (Name Symbol) (Size Nat))
       (encoderOutputEmbedDim :: Dim (Name Symbol) (Size Nat))
       (ffnDim :: Dim (Name Symbol) (Size Nat))
       (posEncDim :: Dim (Name Symbol) (Size Nat)).
STransformerStyle style
-&gt; SNat numLayers
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim headDim
-&gt; SDim headEmbedDim
-&gt; SDim embedDim
-&gt; SDim decoderInputEmbedDim
-&gt; SDim encoderOutputEmbedDim
-&gt; SDim ffnDim
-&gt; SDim posEncDim
-&gt; Double
-&gt; Double
-&gt; TransformerDecoderSpec
     style
     numLayers
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     decoderInputEmbedDim
     encoderOutputEmbedDim
     ffnDim
     posEncDim
</span><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TransformerDecoderSpec"><span class="hs-identifier hs-var">TransformerDecoderSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle 'T5
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">KnownNat 1 =&gt; SNat 1
forall (n :: Nat). KnownNat n =&gt; SNat n
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNat</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">SGradient ('Gradient 'WithGradient)
</span><a href="#local-6989586621679808504"><span class="hs-identifier hs-var">gradient</span></a></span><span> </span><span class="annot"><span class="annottext">SDevice ('Device 'CPU)
</span><a href="#local-6989586621679808501"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType ('DataType 'Float)
</span><a href="#local-6989586621679808498"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 8))
</span><a href="#local-6989586621679808495"><span class="hs-identifier hs-var">headDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 64))
</span><a href="#local-6989586621679808492"><span class="hs-identifier hs-var">headEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 512))
</span><a href="#local-6989586621679808491"><span class="hs-identifier hs-var">embedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 512))
</span><a href="#local-6989586621679808490"><span class="hs-identifier hs-var">decoderInputEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 512))
</span><a href="#local-6989586621679808489"><span class="hs-identifier hs-var">encoderOutputEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 2048))
</span><a href="#local-6989586621679808488"><span class="hs-identifier hs-var">ffnDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 32))
</span><a href="#local-6989586621679808487"><span class="hs-identifier hs-var">posEncDim</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679808486"><span class="hs-identifier hs-var">dropoutP</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679808485"><span class="hs-identifier hs-var">eps</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Generator ('Device 'CPU)
</span><a href="#local-6989586621679808484"><span class="hs-identifier hs-var">g</span></a></span><span>
</span><span id="line-523"></span><span>  </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679808481"><span class="annot"><span class="annottext">batchDim :: SDim ('Dim ('Name &quot;*&quot;) ('Size 3))
</span><a href="#local-6989586621679808481"><span class="hs-identifier hs-var hs-var">batchDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize ('Size 3) -&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 3))
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownNat 3 =&gt; SSize ('Size 3)
forall (size :: Nat). KnownNat size =&gt; SSize ('Size size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier hs-var">SSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">3</span></span><span>
</span><span id="line-524"></span><span>      </span><span id="local-6989586621679808480"><span class="annot"><span class="annottext">seqDim :: SDim ('Dim ('Name &quot;*&quot;) ('Size 13))
</span><a href="#local-6989586621679808480"><span class="hs-identifier hs-var hs-var">seqDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize ('Size 13) -&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 13))
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownNat 13 =&gt; SSize ('Size 13)
forall (size :: Nat). KnownNat size =&gt; SSize ('Size size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier hs-var">SSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">13</span></span><span>
</span><span id="line-525"></span><span>      </span><span id="local-6989586621679808479"><span class="annot"><span class="annottext">decoderSeqDim :: SDim ('Dim ('Name &quot;*&quot;) ('Size 7))
</span><a href="#local-6989586621679808479"><span class="hs-identifier hs-var hs-var">decoderSeqDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize ('Size 7) -&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 7))
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownNat 7 =&gt; SSize ('Size 7)
forall (size :: Nat). KnownNat size =&gt; SSize ('Size size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier hs-var">SSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">7</span></span><span>
</span><span id="line-526"></span><span>      </span><span id="local-6989586621679808478"><span class="annot"><span class="annottext">sOnes' :: SDataType dataType
-&gt; SShape shape
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     dataType
     shape
</span><a href="#local-6989586621679808478"><span class="hs-identifier hs-var hs-var">sOnes'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">TensorSpec
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  dataType
  shape
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     dataType
     shape
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
TensorSpec gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.Creation.html#sOnes"><span class="hs-identifier hs-var">sOnes</span></a></span><span> </span><span class="annot"><span class="annottext">(TensorSpec
   ('Gradient 'WithoutGradient)
   ('Layout 'Dense)
   ('Device 'CPU)
   dataType
   shape
 -&gt; Tensor
      ('Gradient 'WithoutGradient)
      ('Layout 'Dense)
      ('Device 'CPU)
      dataType
      shape)
-&gt; (SShape shape
    -&gt; TensorSpec
         ('Gradient 'WithoutGradient)
         ('Layout 'Dense)
         ('Device 'CPU)
         dataType
         shape)
-&gt; SShape shape
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     dataType
     shape
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">((SShape shape
  -&gt; TensorSpec
       ('Gradient 'WithoutGradient)
       ('Layout 'Dense)
       ('Device 'CPU)
       dataType
       shape)
 -&gt; SShape shape
 -&gt; Tensor
      ('Gradient 'WithoutGradient)
      ('Layout 'Dense)
      ('Device 'CPU)
      dataType
      shape)
-&gt; (SDataType dataType
    -&gt; SShape shape
    -&gt; TensorSpec
         ('Gradient 'WithoutGradient)
         ('Layout 'Dense)
         ('Device 'CPU)
         dataType
         shape)
-&gt; SDataType dataType
-&gt; SShape shape
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     dataType
     shape
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">SGradient ('Gradient 'WithoutGradient)
-&gt; SLayout ('Layout 'Dense)
-&gt; SDevice ('Device 'CPU)
-&gt; SDataType dataType
-&gt; SShape shape
-&gt; TensorSpec
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     dataType
     shape
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SShape shape
-&gt; TensorSpec gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorSpec"><span class="hs-identifier hs-var">TensorSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SRequiresGradient 'WithoutGradient
-&gt; SGradient ('Gradient 'WithoutGradient)
forall (requiresGradient :: RequiresGradient).
SRequiresGradient requiresGradient
-&gt; SGradient ('Gradient requiresGradient)
</span><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier hs-var">SGradient</span></a></span><span> </span><span class="annot"><span class="annottext">SRequiresGradient 'WithoutGradient
</span><a href="Torch.GraduallyTyped.RequiresGradient.html#SWithoutGradient"><span class="hs-identifier hs-var">SWithoutGradient</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SLayoutType 'Dense -&gt; SLayout ('Layout 'Dense)
forall (layoutType :: LayoutType).
SLayoutType layoutType -&gt; SLayout ('Layout layoutType)
</span><a href="Torch.GraduallyTyped.Layout.html#SLayout"><span class="hs-identifier hs-var">SLayout</span></a></span><span> </span><span class="annot"><span class="annottext">SLayoutType 'Dense
</span><a href="Torch.GraduallyTyped.Layout.html#SDense"><span class="hs-identifier hs-var">SDense</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">SDevice ('Device 'CPU)
</span><a href="#local-6989586621679808501"><span class="hs-identifier hs-var">device</span></a></span><span>
</span><span id="line-527"></span><span>      </span><span id="local-6989586621679808475"><span class="annot"><span class="annottext">decoderInput :: Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7),
        'Dim ('Name &quot;*&quot;) ('Size 512)])
</span><a href="#local-6989586621679808475"><span class="hs-identifier hs-var hs-var">decoderInput</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SDataType ('DataType 'Float)
-&gt; SShape
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7),
           'Dim ('Name &quot;*&quot;) ('Size 512)])
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     ('DataType 'Float)
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7),
           'Dim ('Name &quot;*&quot;) ('Size 512)])
forall (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SDataType dataType
-&gt; SShape shape
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     dataType
     shape
</span><a href="#local-6989586621679808478"><span class="hs-identifier hs-var">sOnes'</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType ('DataType 'Float)
</span><a href="#local-6989586621679808498"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SList
  '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7),
     'Dim ('Name &quot;*&quot;) ('Size 512)]
-&gt; SShape
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7),
           'Dim ('Name &quot;*&quot;) ('Size 512)])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList
   '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7),
      'Dim ('Name &quot;*&quot;) ('Size 512)]
 -&gt; SShape
      ('Shape
         '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7),
            'Dim ('Name &quot;*&quot;) ('Size 512)]))
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7),
        'Dim ('Name &quot;*&quot;) ('Size 512)]
-&gt; SShape
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7),
           'Dim ('Name &quot;*&quot;) ('Size 512)])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 3))
</span><a href="#local-6989586621679808481"><span class="hs-identifier hs-var">batchDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 3))
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 7), 'Dim ('Name &quot;*&quot;) ('Size 512)]
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7),
        'Dim ('Name &quot;*&quot;) ('Size 512)]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 7))
</span><a href="#local-6989586621679808479"><span class="hs-identifier hs-var">decoderSeqDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 7))
-&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 512)]
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 7), 'Dim ('Name &quot;*&quot;) ('Size 512)]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 512))
</span><a href="#local-6989586621679808490"><span class="hs-identifier hs-var">decoderInputEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 512))
-&gt; SList '[] -&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 512)]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-528"></span><span>      </span><span id="local-6989586621679808474"><span class="annot"><span class="annottext">encoderOutput :: Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 13),
        'Dim ('Name &quot;*&quot;) ('Size 512)])
</span><a href="#local-6989586621679808474"><span class="hs-identifier hs-var hs-var">encoderOutput</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SDataType ('DataType 'Float)
-&gt; SShape
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 13),
           'Dim ('Name &quot;*&quot;) ('Size 512)])
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     ('DataType 'Float)
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 13),
           'Dim ('Name &quot;*&quot;) ('Size 512)])
forall (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SDataType dataType
-&gt; SShape shape
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     dataType
     shape
</span><a href="#local-6989586621679808478"><span class="hs-identifier hs-var">sOnes'</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType ('DataType 'Float)
</span><a href="#local-6989586621679808498"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SList
  '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 13),
     'Dim ('Name &quot;*&quot;) ('Size 512)]
-&gt; SShape
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 13),
           'Dim ('Name &quot;*&quot;) ('Size 512)])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList
   '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 13),
      'Dim ('Name &quot;*&quot;) ('Size 512)]
 -&gt; SShape
      ('Shape
         '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 13),
            'Dim ('Name &quot;*&quot;) ('Size 512)]))
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 13),
        'Dim ('Name &quot;*&quot;) ('Size 512)]
-&gt; SShape
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 13),
           'Dim ('Name &quot;*&quot;) ('Size 512)])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 3))
</span><a href="#local-6989586621679808481"><span class="hs-identifier hs-var">batchDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 3))
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 13), 'Dim ('Name &quot;*&quot;) ('Size 512)]
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 13),
        'Dim ('Name &quot;*&quot;) ('Size 512)]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 13))
</span><a href="#local-6989586621679808480"><span class="hs-identifier hs-var">seqDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 13))
-&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 512)]
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 13), 'Dim ('Name &quot;*&quot;) ('Size 512)]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 512))
</span><a href="#local-6989586621679808489"><span class="hs-identifier hs-var">encoderOutputEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 512))
-&gt; SList '[] -&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 512)]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-529"></span><span>      </span><span id="local-6989586621679808473"><span class="annot"><span class="annottext">decoderRelPos :: Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Int64)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 7),
        'Dim ('Name &quot;*&quot;) ('Size 7)])
</span><a href="#local-6989586621679808473"><span class="hs-identifier hs-var hs-var">decoderRelPos</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SDataType ('DataType 'Int64)
-&gt; SShape
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 7),
           'Dim ('Name &quot;*&quot;) ('Size 7)])
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     ('DataType 'Int64)
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 7),
           'Dim ('Name &quot;*&quot;) ('Size 7)])
forall (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SDataType dataType
-&gt; SShape shape
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     dataType
     shape
</span><a href="#local-6989586621679808478"><span class="hs-identifier hs-var">sOnes'</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SDType 'Int64 -&gt; SDataType ('DataType 'Int64)
forall (dType :: DType).
SDType dType -&gt; SDataType ('DataType dType)
</span><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier hs-var">SDataType</span></a></span><span> </span><span class="annot"><span class="annottext">SDType 'Int64
</span><a href="Torch.GraduallyTyped.DType.html#SInt64"><span class="hs-identifier hs-var">SInt64</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SList
  '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 7),
     'Dim ('Name &quot;*&quot;) ('Size 7)]
-&gt; SShape
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 7),
           'Dim ('Name &quot;*&quot;) ('Size 7)])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList
   '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 7),
      'Dim ('Name &quot;*&quot;) ('Size 7)]
 -&gt; SShape
      ('Shape
         '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 7),
            'Dim ('Name &quot;*&quot;) ('Size 7)]))
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 7),
        'Dim ('Name &quot;*&quot;) ('Size 7)]
-&gt; SShape
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 7),
           'Dim ('Name &quot;*&quot;) ('Size 7)])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize ('Size 1) -&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 1))
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownNat 1 =&gt; SSize ('Size 1)
forall (size :: Nat). KnownNat size =&gt; SSize ('Size size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier hs-var">SSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">1</span></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 1))
-&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 7), 'Dim ('Name &quot;*&quot;) ('Size 7)]
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 7),
        'Dim ('Name &quot;*&quot;) ('Size 7)]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 7))
</span><a href="#local-6989586621679808479"><span class="hs-identifier hs-var">decoderSeqDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 7))
-&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 7)]
-&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 7), 'Dim ('Name &quot;*&quot;) ('Size 7)]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 7))
</span><a href="#local-6989586621679808479"><span class="hs-identifier hs-var">decoderSeqDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 7))
-&gt; SList '[] -&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 7)]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-530"></span><span>      </span><span id="local-6989586621679808471"><span class="annot"><span class="annottext">decoderAttentionMask :: Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7),
        'Dim ('Name &quot;*&quot;) ('Size 7)])
</span><a href="#local-6989586621679808471"><span class="hs-identifier hs-var hs-var">decoderAttentionMask</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SDataType ('DataType 'Float)
-&gt; SShape
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7),
           'Dim ('Name &quot;*&quot;) ('Size 7)])
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     ('DataType 'Float)
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7),
           'Dim ('Name &quot;*&quot;) ('Size 7)])
forall (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SDataType dataType
-&gt; SShape shape
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     dataType
     shape
</span><a href="#local-6989586621679808478"><span class="hs-identifier hs-var">sOnes'</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType ('DataType 'Float)
</span><a href="#local-6989586621679808498"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SList
  '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7),
     'Dim ('Name &quot;*&quot;) ('Size 7)]
-&gt; SShape
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7),
           'Dim ('Name &quot;*&quot;) ('Size 7)])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList
   '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7),
      'Dim ('Name &quot;*&quot;) ('Size 7)]
 -&gt; SShape
      ('Shape
         '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7),
            'Dim ('Name &quot;*&quot;) ('Size 7)]))
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7),
        'Dim ('Name &quot;*&quot;) ('Size 7)]
-&gt; SShape
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7),
           'Dim ('Name &quot;*&quot;) ('Size 7)])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 3))
</span><a href="#local-6989586621679808481"><span class="hs-identifier hs-var">batchDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 3))
-&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 7), 'Dim ('Name &quot;*&quot;) ('Size 7)]
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7),
        'Dim ('Name &quot;*&quot;) ('Size 7)]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 7))
</span><a href="#local-6989586621679808479"><span class="hs-identifier hs-var">decoderSeqDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 7))
-&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 7)]
-&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 7), 'Dim ('Name &quot;*&quot;) ('Size 7)]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 7))
</span><a href="#local-6989586621679808479"><span class="hs-identifier hs-var">decoderSeqDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 7))
-&gt; SList '[] -&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 7)]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-531"></span><span>      </span><span id="local-6989586621679808470"><span class="annot"><span class="annottext">crossAttentionMask :: Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7),
        'Dim ('Name &quot;*&quot;) ('Size 13)])
</span><a href="#local-6989586621679808470"><span class="hs-identifier hs-var hs-var">crossAttentionMask</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SDataType ('DataType 'Float)
-&gt; SShape
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7),
           'Dim ('Name &quot;*&quot;) ('Size 13)])
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     ('DataType 'Float)
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7),
           'Dim ('Name &quot;*&quot;) ('Size 13)])
forall (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SDataType dataType
-&gt; SShape shape
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     dataType
     shape
</span><a href="#local-6989586621679808478"><span class="hs-identifier hs-var">sOnes'</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType ('DataType 'Float)
</span><a href="#local-6989586621679808498"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SList
  '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7),
     'Dim ('Name &quot;*&quot;) ('Size 13)]
-&gt; SShape
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7),
           'Dim ('Name &quot;*&quot;) ('Size 13)])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList
   '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7),
      'Dim ('Name &quot;*&quot;) ('Size 13)]
 -&gt; SShape
      ('Shape
         '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7),
            'Dim ('Name &quot;*&quot;) ('Size 13)]))
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7),
        'Dim ('Name &quot;*&quot;) ('Size 13)]
-&gt; SShape
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7),
           'Dim ('Name &quot;*&quot;) ('Size 13)])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 3))
</span><a href="#local-6989586621679808481"><span class="hs-identifier hs-var">batchDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 3))
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 7), 'Dim ('Name &quot;*&quot;) ('Size 13)]
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7),
        'Dim ('Name &quot;*&quot;) ('Size 13)]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 7))
</span><a href="#local-6989586621679808479"><span class="hs-identifier hs-var">decoderSeqDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 7))
-&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 13)]
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 7), 'Dim ('Name &quot;*&quot;) ('Size 13)]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 13))
</span><a href="#local-6989586621679808480"><span class="hs-identifier hs-var">seqDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 13))
-&gt; SList '[] -&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 13)]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-532"></span><span>  </span><span class="hs-special">(</span><span id="local-6989586621679808469"><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7),
        'Dim ('Name &quot;*&quot;) ('Size 512)])
</span><a href="#local-6989586621679808469"><span class="hs-identifier hs-var">output</span></a></span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Generator ('Device 'CPU)
</span><span class="hs-identifier">_</span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">TransformerDecoder
  'T5
  1
  ('Gradient 'WithGradient)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Dim ('Name &quot;*&quot;) ('Size 8))
  ('Dim ('Name &quot;*&quot;) ('Size 64))
  ('Dim ('Name &quot;*&quot;) ('Size 512))
  ('Dim ('Name &quot;*&quot;) ('Size 512))
  ('Dim ('Name &quot;*&quot;) ('Size 512))
  ('Dim ('Name &quot;*&quot;) ('Size 2048))
  ('Dim ('Name &quot;*&quot;) ('Size 32))
-&gt; (Tensor
      ('Gradient 'WithoutGradient)
      ('Layout 'Dense)
      ('Device 'CPU)
      ('DataType 'Float)
      ('Shape
         '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7),
            'Dim ('Name &quot;*&quot;) ('Size 512)]),
    Tensor
      ('Gradient 'WithoutGradient)
      ('Layout 'Dense)
      ('Device 'CPU)
      ('DataType 'Float)
      ('Shape
         '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 13),
            'Dim ('Name &quot;*&quot;) ('Size 512)]),
    Tensor
      ('Gradient 'WithoutGradient)
      ('Layout 'Dense)
      ('Device 'CPU)
      ('DataType 'Int64)
      ('Shape
         '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 7),
            'Dim ('Name &quot;*&quot;) ('Size 7)]),
    Tensor
      ('Gradient 'WithoutGradient)
      ('Layout 'Dense)
      ('Device 'CPU)
      ('DataType 'Float)
      ('Shape
         '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7),
            'Dim ('Name &quot;*&quot;) ('Size 7)]),
    Tensor
      ('Gradient 'WithoutGradient)
      ('Layout 'Dense)
      ('Device 'CPU)
      ('DataType 'Float)
      ('Shape
         '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7),
            'Dim ('Name &quot;*&quot;) ('Size 13)]))
-&gt; Generator ('Device 'CPU)
-&gt; IO
     (Tensor
        ('Gradient 'WithGradient)
        ('Layout 'Dense)
        ('Device 'CPU)
        ('DataType 'Float)
        ('Shape
           '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7),
              'Dim ('Name &quot;*&quot;) ('Size 512)]),
      Generator ('Device 'CPU))
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: * -&gt; *).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">TransformerDecoder
  'T5
  1
  ('Gradient 'WithGradient)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Dim ('Name &quot;*&quot;) ('Size 8))
  ('Dim ('Name &quot;*&quot;) ('Size 64))
  ('Dim ('Name &quot;*&quot;) ('Size 512))
  ('Dim ('Name &quot;*&quot;) ('Size 512))
  ('Dim ('Name &quot;*&quot;) ('Size 512))
  ('Dim ('Name &quot;*&quot;) ('Size 2048))
  ('Dim ('Name &quot;*&quot;) ('Size 32))
</span><a href="#local-6989586621679808483"><span class="hs-identifier hs-var">encoder</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7),
        'Dim ('Name &quot;*&quot;) ('Size 512)])
</span><a href="#local-6989586621679808475"><span class="hs-identifier hs-var">decoderInput</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 13),
        'Dim ('Name &quot;*&quot;) ('Size 512)])
</span><a href="#local-6989586621679808474"><span class="hs-identifier hs-var">encoderOutput</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Int64)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 7),
        'Dim ('Name &quot;*&quot;) ('Size 7)])
</span><a href="#local-6989586621679808473"><span class="hs-identifier hs-var">decoderRelPos</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7),
        'Dim ('Name &quot;*&quot;) ('Size 7)])
</span><a href="#local-6989586621679808471"><span class="hs-identifier hs-var">decoderAttentionMask</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7),
        'Dim ('Name &quot;*&quot;) ('Size 13)])
</span><a href="#local-6989586621679808470"><span class="hs-identifier hs-var">crossAttentionMask</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Generator ('Device 'CPU)
</span><a href="#local-6989586621679808482"><span class="hs-identifier hs-var">g'</span></a></span><span>
</span><span id="line-533"></span><span>  </span><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7),
        'Dim ('Name &quot;*&quot;) ('Size 512)])
-&gt; IO
     (Tensor
        ('Gradient 'WithGradient)
        ('Layout 'Dense)
        ('Device 'CPU)
        ('DataType 'Float)
        ('Shape
           '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7),
              'Dim ('Name &quot;*&quot;) ('Size 512)]))
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 7),
        'Dim ('Name &quot;*&quot;) ('Size 512)])
</span><a href="#local-6989586621679808469"><span class="hs-identifier hs-var">output</span></a></span><span>
</span><span id="line-534"></span><span>
</span><span id="line-535"></span><span class="hs-comment">-- | 'HasForward' instance for @TransformerDecoder numLayers 'ByT5@.</span><span>
</span><span id="line-536"></span><span class="hs-comment">--</span><span>
</span><span id="line-537"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-538"></span><span class="hs-comment">-- &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;  &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;  &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;  &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;  &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;</span><span>
</span><span id="line-539"></span><span class="hs-comment">-- &#9474; decoderInput &#9474;  &#9474; encoderOutput &#9474;  &#9474; decoderRelPos &#9474;  &#9474; decoderAttentionMask &#9474;  &#9474; crossAttentionMask &#9474;</span><span>
</span><span id="line-540"></span><span class="hs-comment">-- &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;  &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;  &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;  &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;  &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-541"></span><span class="hs-comment">--        &#9474;                  &#9474;                  &#9474;                     &#9474;                        &#9474;</span><span>
</span><span id="line-542"></span><span class="hs-comment">--        &#9474;                  &#9474;                  &#9660;                     &#9474;                        &#9474;</span><span>
</span><span id="line-543"></span><span class="hs-comment">--        &#9474;                  &#9474;              tdPosEnc                  &#9474;                        &#9474;</span><span>
</span><span id="line-544"></span><span class="hs-comment">--        &#9474;                  &#9474;                  &#9660;                     &#9474;                        &#9474;</span><span>
</span><span id="line-545"></span><span class="hs-comment">--        &#9474;                  &#9474;              transpose                 &#9474;                        &#9474;</span><span>
</span><span id="line-546"></span><span class="hs-comment">--        &#9474;                  &#9474;                  &#9660;                     &#9660;                        &#9660;</span><span>
</span><span id="line-547"></span><span class="hs-comment">--        &#9474;                  &#9474;              transpose             unsqueeze                unsqueeze</span><span>
</span><span id="line-548"></span><span class="hs-comment">--        &#9660;                  &#9474;                  &#9474;                     &#9474;                        &#9474;</span><span>
</span><span id="line-549"></span><span class="hs-comment">--    tdDropout              &#9474;                  &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9658;add&#9668;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;                        &#9474;</span><span>
</span><span id="line-550"></span><span class="hs-comment">--        &#9660;                  &#9474;                             &#9474;                                   &#9474;</span><span>
</span><span id="line-551"></span><span class="hs-comment">--     tdStack&#9668;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;&#9668;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;&#9668;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-552"></span><span class="hs-comment">--        &#9660;</span><span>
</span><span id="line-553"></span><span class="hs-comment">--   tdLayerNorm</span><span>
</span><span id="line-554"></span><span class="hs-comment">--        &#9660;</span><span>
</span><span id="line-555"></span><span class="hs-comment">--    tdDropout</span><span>
</span><span id="line-556"></span><span class="hs-comment">--        &#9474;</span><span>
</span><span id="line-557"></span><span class="hs-comment">--        &#9660;</span><span>
</span><span id="line-558"></span><span class="hs-comment">--    &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;</span><span>
</span><span id="line-559"></span><span class="hs-comment">--    &#9474; output &#9474;</span><span>
</span><span id="line-560"></span><span class="hs-comment">--    &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-561"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-562"></span><span id="local-6989586621679808432"><span id="local-6989586621679808433"><span id="local-6989586621679808434"><span id="local-6989586621679808435"><span id="local-6989586621679808436"><span id="local-6989586621679808437"><span id="local-6989586621679808438"><span id="local-6989586621679808439"><span id="local-6989586621679808440"><span id="local-6989586621679808441"><span id="local-6989586621679808442"><span id="local-6989586621679808443"><span id="local-6989586621679808444"><span id="local-6989586621679808445"><span id="local-6989586621679808446"><span id="local-6989586621679808447"><span id="local-6989586621679808448"><span id="local-6989586621679808449"><span id="local-6989586621679808450"><span id="local-6989586621679808451"><span id="local-6989586621679808452"><span id="local-6989586621679808453"><span id="local-6989586621679808454"><span id="local-6989586621679808455"><span id="local-6989586621679808456"><span id="local-6989586621679808457"><span id="local-6989586621679808458"><span id="local-6989586621679808459"><span id="local-6989586621679808460"><span id="local-6989586621679808461"><span id="local-6989586621679808462"><span id="local-6989586621679808463"><span id="local-6989586621679808464"><span id="local-6989586621679808465"><span id="local-6989586621679808466"><span id="local-6989586621679808467"><span id="local-6989586621679808468"><span class="hs-keyword">instance</span><span>
</span><span id="line-563"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-564"></span><span>      </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Dropout.html#Dropout"><span class="hs-identifier hs-type">Dropout</span></a></span><span>
</span><span id="line-565"></span><span>      </span><span class="annot"><a href="#local-6989586621679808468"><span class="hs-identifier hs-type">decoderInput</span></a></span><span>
</span><span id="line-566"></span><span>      </span><span class="annot"><a href="#local-6989586621679808467"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-567"></span><span>      </span><span class="annot"><a href="#local-6989586621679808466"><span class="hs-identifier hs-type">dropoutOutput</span></a></span><span>
</span><span id="line-568"></span><span>      </span><span class="annot"><a href="#local-6989586621679808465"><span class="hs-identifier hs-type">dropoutGeneratorOutputDevice</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-569"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-570"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.DecoderStack.html#TransformerDecoderStack"><span class="hs-identifier hs-type">TransformerDecoderStack</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ByT5"><span class="hs-identifier hs-type">ByT5</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808464"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808463"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808462"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808461"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808460"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808459"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808458"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808457"><span class="hs-identifier hs-type">decoderInputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808456"><span class="hs-identifier hs-type">encoderOutputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808455"><span class="hs-identifier hs-type">ffnDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-571"></span><span>      </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="#local-6989586621679808466"><span class="hs-identifier hs-type">dropoutOutput</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-572"></span><span>        </span><span class="annot"><a href="#local-6989586621679808454"><span class="hs-identifier hs-type">encoderOutput</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-573"></span><span>        </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-574"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679808463"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808453"><span class="hs-identifier hs-type">decoderRelPosGradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808452"><span class="hs-identifier hs-type">decoderAttentionMaskGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-575"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Dense"><span class="hs-identifier hs-type">Dense</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808451"><span class="hs-identifier hs-type">decoderRelPosLayout</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808450"><span class="hs-identifier hs-type">decoderAttentionMaskLayout</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-576"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679808462"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808449"><span class="hs-identifier hs-type">decoderRelPosDevice</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808448"><span class="hs-identifier hs-type">decoderAttentionMaskDevice</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-577"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Seq"><span class="hs-identifier hs-type">Seq</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679808447"><span class="hs-identifier hs-type">decoderRelPosDataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#Int64"><span class="hs-identifier hs-type">Int64</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679808461"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808446"><span class="hs-identifier hs-type">decoderAttentionMaskDataType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-578"></span><span>          </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#BroadcastShapesF"><span class="hs-identifier hs-type">BroadcastShapesF</span></a></span><span>
</span><span id="line-579"></span><span>              </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#TransposeF"><span class="hs-identifier hs-type">TransposeF</span></a></span><span>
</span><span id="line-580"></span><span>                  </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-581"></span><span>                  </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">2</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-582"></span><span>                  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#TransposeF"><span class="hs-identifier hs-type">TransposeF</span></a></span><span>
</span><span id="line-583"></span><span>                      </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">2</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-584"></span><span>                      </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">3</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-585"></span><span>                      </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Functional.Sparse.html#EmbeddingF"><span class="hs-identifier hs-type">EmbeddingF</span></a></span><span>
</span><span id="line-586"></span><span>                          </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679808445"><span class="hs-identifier hs-type">posEncDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679808460"><span class="hs-identifier hs-type">headDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-587"></span><span>                          </span><span class="annot"><a href="#local-6989586621679808444"><span class="hs-identifier hs-type">decoderRelPosShape</span></a></span><span>
</span><span id="line-588"></span><span>                      </span><span class="hs-special">)</span><span>
</span><span id="line-589"></span><span>                  </span><span class="hs-special">)</span><span>
</span><span id="line-590"></span><span>              </span><span class="hs-special">)</span><span>
</span><span id="line-591"></span><span>              </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#UnsqueezeF"><span class="hs-identifier hs-type">UnsqueezeF</span></a></span><span>
</span><span id="line-592"></span><span>                  </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-593"></span><span>                  </span><span class="annot"><a href="#local-6989586621679808443"><span class="hs-identifier hs-type">decoderAttentionMaskShape</span></a></span><span>
</span><span id="line-594"></span><span>              </span><span class="hs-special">)</span><span>
</span><span id="line-595"></span><span>          </span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-596"></span><span>        </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-597"></span><span>          </span><span class="annot"><a href="#local-6989586621679808442"><span class="hs-identifier hs-type">crossAttentionMaskGradient</span></a></span><span>
</span><span id="line-598"></span><span>          </span><span class="annot"><a href="#local-6989586621679808441"><span class="hs-identifier hs-type">crossAttentionMaskLayout</span></a></span><span>
</span><span id="line-599"></span><span>          </span><span class="annot"><a href="#local-6989586621679808440"><span class="hs-identifier hs-type">crossAttentionMaskDevice</span></a></span><span>
</span><span id="line-600"></span><span>          </span><span class="annot"><a href="#local-6989586621679808439"><span class="hs-identifier hs-type">crossAttentionMaskDataType</span></a></span><span>
</span><span id="line-601"></span><span>          </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#UnsqueezeF"><span class="hs-identifier hs-type">UnsqueezeF</span></a></span><span>
</span><span id="line-602"></span><span>              </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-603"></span><span>              </span><span class="annot"><a href="#local-6989586621679808438"><span class="hs-identifier hs-type">crossAttentionMaskShape</span></a></span><span>
</span><span id="line-604"></span><span>          </span><span class="hs-special">)</span><span>
</span><span id="line-605"></span><span>      </span><span class="hs-special">)</span><span>
</span><span id="line-606"></span><span>      </span><span class="annot"><a href="#local-6989586621679808465"><span class="hs-identifier hs-type">dropoutGeneratorOutputDevice</span></a></span><span>
</span><span id="line-607"></span><span>      </span><span class="annot"><a href="#local-6989586621679808437"><span class="hs-identifier hs-type">stackOutput</span></a></span><span>
</span><span id="line-608"></span><span>      </span><span class="annot"><a href="#local-6989586621679808436"><span class="hs-identifier hs-type">stackGeneratorOutputDevice</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-609"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-610"></span><span>      </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Normalization.html#LayerNorm"><span class="hs-identifier hs-type">LayerNorm</span></a></span><span>
</span><span id="line-611"></span><span>          </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Type.html#WithoutBias"><span class="hs-identifier hs-type">WithoutBias</span></a></span><span>
</span><span id="line-612"></span><span>          </span><span class="annot"><a href="#local-6989586621679808463"><span class="hs-identifier hs-type">gradient</span></a></span><span>
</span><span id="line-613"></span><span>          </span><span class="annot"><a href="#local-6989586621679808462"><span class="hs-identifier hs-type">device</span></a></span><span>
</span><span id="line-614"></span><span>          </span><span class="annot"><a href="#local-6989586621679808461"><span class="hs-identifier hs-type">dataType</span></a></span><span>
</span><span id="line-615"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679808457"><span class="hs-identifier hs-type">decoderInputEmbedDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-616"></span><span>      </span><span class="hs-special">)</span><span>
</span><span id="line-617"></span><span>      </span><span class="annot"><a href="#local-6989586621679808437"><span class="hs-identifier hs-type">stackOutput</span></a></span><span>
</span><span id="line-618"></span><span>      </span><span class="annot"><a href="#local-6989586621679808436"><span class="hs-identifier hs-type">stackGeneratorOutputDevice</span></a></span><span>
</span><span id="line-619"></span><span>      </span><span class="annot"><a href="#local-6989586621679808435"><span class="hs-identifier hs-type">layerNormOutput</span></a></span><span>
</span><span id="line-620"></span><span>      </span><span class="annot"><a href="#local-6989586621679808434"><span class="hs-identifier hs-type">layerNormGeneratorOutputDevice</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-621"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-622"></span><span>      </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Dropout.html#Dropout"><span class="hs-identifier hs-type">Dropout</span></a></span><span>
</span><span id="line-623"></span><span>      </span><span class="annot"><a href="#local-6989586621679808435"><span class="hs-identifier hs-type">layerNormOutput</span></a></span><span>
</span><span id="line-624"></span><span>      </span><span class="annot"><a href="#local-6989586621679808434"><span class="hs-identifier hs-type">layerNormGeneratorOutputDevice</span></a></span><span>
</span><span id="line-625"></span><span>      </span><span class="annot"><a href="#local-6989586621679808433"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-626"></span><span>      </span><span class="annot"><a href="#local-6989586621679808432"><span class="hs-identifier hs-type">generatorOutputDevice</span></a></span><span>
</span><span id="line-627"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-628"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-629"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TransformerDecoder"><span class="hs-identifier hs-type">TransformerDecoder</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ByT5"><span class="hs-identifier hs-type">ByT5</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808464"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808463"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808462"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808461"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808460"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808459"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808458"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808457"><span class="hs-identifier hs-type">decoderInputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808456"><span class="hs-identifier hs-type">encoderOutputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808455"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808445"><span class="hs-identifier hs-type">posEncDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-630"></span><span>    </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="#local-6989586621679808468"><span class="hs-identifier hs-type">decoderInput</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-631"></span><span>      </span><span class="annot"><a href="#local-6989586621679808454"><span class="hs-identifier hs-type">encoderOutput</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-632"></span><span>      </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808453"><span class="hs-identifier hs-type">decoderRelPosGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808451"><span class="hs-identifier hs-type">decoderRelPosLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808449"><span class="hs-identifier hs-type">decoderRelPosDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808447"><span class="hs-identifier hs-type">decoderRelPosDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808444"><span class="hs-identifier hs-type">decoderRelPosShape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-633"></span><span>      </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808452"><span class="hs-identifier hs-type">decoderAttentionMaskGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808450"><span class="hs-identifier hs-type">decoderAttentionMaskLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808448"><span class="hs-identifier hs-type">decoderAttentionMaskDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808446"><span class="hs-identifier hs-type">decoderAttentionMaskDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808443"><span class="hs-identifier hs-type">decoderAttentionMaskShape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-634"></span><span>      </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808442"><span class="hs-identifier hs-type">crossAttentionMaskGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808441"><span class="hs-identifier hs-type">crossAttentionMaskLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808440"><span class="hs-identifier hs-type">crossAttentionMaskDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808439"><span class="hs-identifier hs-type">crossAttentionMaskDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808438"><span class="hs-identifier hs-type">crossAttentionMaskShape</span></a></span><span>
</span><span id="line-635"></span><span>    </span><span class="hs-special">)</span><span>
</span><span id="line-636"></span><span>    </span><span class="annot"><a href="#local-6989586621679808467"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-637"></span><span>    </span><span class="annot"><a href="#local-6989586621679808433"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-638"></span><span>    </span><span class="annot"><a href="#local-6989586621679808432"><span class="hs-identifier hs-type">generatorOutputDevice</span></a></span><span>
</span><span id="line-639"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-640"></span><span>  </span><span id="local-6989586621679808430"><span class="annot"><span class="annottext">forward :: TransformerDecoder
  'ByT5
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  decoderInputEmbedDim
  encoderOutputEmbedDim
  ffnDim
  posEncDim
-&gt; (decoderInput, encoderOutput,
    Tensor
      decoderRelPosGradient
      decoderRelPosLayout
      decoderRelPosDevice
      decoderRelPosDataType
      decoderRelPosShape,
    Tensor
      decoderAttentionMaskGradient
      decoderAttentionMaskLayout
      decoderAttentionMaskDevice
      decoderAttentionMaskDataType
      decoderAttentionMaskShape,
    Tensor
      crossAttentionMaskGradient
      crossAttentionMaskLayout
      crossAttentionMaskDevice
      crossAttentionMaskDataType
      crossAttentionMaskShape)
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="#local-6989586621679808430"><span class="hs-identifier hs-var hs-var hs-var hs-var">forward</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TransformerDecoder"><span class="hs-identifier hs-type">TransformerDecoder</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#GTransformerDecoder"><span class="hs-identifier hs-type">GTransformerDecoder</span></a></span><span> </span><span class="hs-special">{</span><span id="local-6989586621679808425"><span id="local-6989586621679808426"><span id="local-6989586621679808427"><span id="local-6989586621679808428"><span id="local-6989586621679808429"><span class="annot"><span class="annottext">TDPosEncF
  'ByT5
  gradient
  device
  dataType
  headDim
  decoderInputEmbedDim
  posEncDim
TDDropoutF 'ByT5
TDLayerNormF 'ByT5 gradient device dataType decoderInputEmbedDim
TDEmbedLayerNormF
  'ByT5 gradient device dataType decoderInputEmbedDim
TDStackF
  'ByT5
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  decoderInputEmbedDim
  encoderOutputEmbedDim
  ffnDim
tdPosEnc :: TDPosEncF
  'ByT5
  gradient
  device
  dataType
  headDim
  decoderInputEmbedDim
  posEncDim
tdDropout :: TDDropoutF 'ByT5
tdLayerNorm :: TDLayerNormF 'ByT5 gradient device dataType decoderInputEmbedDim
tdEmbedLayerNorm :: TDEmbedLayerNormF
  'ByT5 gradient device dataType decoderInputEmbedDim
tdStack :: TDStackF
  'ByT5
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  decoderInputEmbedDim
  encoderOutputEmbedDim
  ffnDim
tdPosEnc :: forall stack embedLayerNorm layerNorm dropout posEnc.
GTransformerDecoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; posEnc
tdDropout :: forall stack embedLayerNorm layerNorm dropout posEnc.
GTransformerDecoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; dropout
tdLayerNorm :: forall stack embedLayerNorm layerNorm dropout posEnc.
GTransformerDecoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; layerNorm
tdEmbedLayerNorm :: forall stack embedLayerNorm layerNorm dropout posEnc.
GTransformerDecoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; embedLayerNorm
tdStack :: forall stack embedLayerNorm layerNorm dropout posEnc.
GTransformerDecoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; stack
</span><a href="#local-6989586621679808425"><span class="hs-glyph hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">..</span></a></span></span></span></span></span></span><span class="hs-special">}</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679808424"><span class="annot"><span class="annottext">decoderInput
</span><a href="#local-6989586621679808424"><span class="hs-identifier hs-var">decoderInput</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679808423"><span class="annot"><span class="annottext">encoderOutput
</span><a href="#local-6989586621679808423"><span class="hs-identifier hs-var">encoderOutput</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679808422"><span class="annot"><span class="annottext">Tensor
  decoderRelPosGradient
  decoderRelPosLayout
  decoderRelPosDevice
  decoderRelPosDataType
  decoderRelPosShape
</span><a href="#local-6989586621679808422"><span class="hs-identifier hs-var">decoderRelPos</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679808421"><span class="annot"><span class="annottext">Tensor
  decoderAttentionMaskGradient
  decoderAttentionMaskLayout
  decoderAttentionMaskDevice
  decoderAttentionMaskDataType
  decoderAttentionMaskShape
</span><a href="#local-6989586621679808421"><span class="hs-identifier hs-var">decoderAttentionMask</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679808420"><span class="annot"><span class="annottext">Tensor
  crossAttentionMaskGradient
  crossAttentionMaskLayout
  crossAttentionMaskDevice
  crossAttentionMaskDataType
  crossAttentionMaskShape
</span><a href="#local-6989586621679808420"><span class="hs-identifier hs-var">crossAttentionMask</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-641"></span><span>    </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679808419"><span class="annot"><span class="annottext">decoderRelPosBias :: IxStateT
  m
  (Generator dropoutGeneratorOutputDevice)
  (Generator dropoutGeneratorOutputDevice)
  (Tensor
     (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
     (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
     (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
     (Seq
        (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
        dataType)
     (TransposeF
        ('SelectDim ('ByIndex 1))
        ('SelectDim ('ByIndex 2))
        (TransposeF
           ('SelectDim ('ByIndex 2))
           ('SelectDim ('ByIndex 3))
           (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape))))
</span><a href="#local-6989586621679808419"><span class="hs-identifier hs-var hs-var">decoderRelPosBias</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-642"></span><span>          </span><span class="annot"><span class="annottext">Tensor
  decoderRelPosGradient
  decoderRelPosLayout
  decoderRelPosDevice
  decoderRelPosDataType
  decoderRelPosShape
-&gt; IxStateT
     m
     (Generator dropoutGeneratorOutputDevice)
     (Generator dropoutGeneratorOutputDevice)
     (Tensor
        decoderRelPosGradient
        decoderRelPosLayout
        decoderRelPosDevice
        decoderRelPosDataType
        decoderRelPosShape)
forall k (m :: k -&gt; k -&gt; * -&gt; *) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  decoderRelPosGradient
  decoderRelPosLayout
  decoderRelPosDevice
  decoderRelPosDataType
  decoderRelPosShape
</span><a href="#local-6989586621679808422"><span class="hs-identifier hs-var">decoderRelPos</span></a></span><span>
</span><span id="line-643"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator dropoutGeneratorOutputDevice)
  (Generator dropoutGeneratorOutputDevice)
  (Tensor
     decoderRelPosGradient
     decoderRelPosLayout
     decoderRelPosDevice
     decoderRelPosDataType
     decoderRelPosShape)
-&gt; (Tensor
      decoderRelPosGradient
      decoderRelPosLayout
      decoderRelPosDevice
      decoderRelPosDataType
      decoderRelPosShape
    -&gt; IxStateT
         m
         (Generator dropoutGeneratorOutputDevice)
         (Generator dropoutGeneratorOutputDevice)
         (Tensor
            (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
            (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
            (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
            (Seq
               (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
               dataType)
            (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)))
-&gt; IxStateT
     m
     (Generator dropoutGeneratorOutputDevice)
     (Generator dropoutGeneratorOutputDevice)
     (Tensor
        (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
        (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
        (Seq
           (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
           dataType)
        (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape))
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(Generator dropoutGeneratorOutputDevice
 -&gt; m (Tensor
         (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
         (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
         (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
         (Seq
            (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
            dataType)
         (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape),
       Generator dropoutGeneratorOutputDevice))
-&gt; IxStateT
     m
     (Generator dropoutGeneratorOutputDevice)
     (Generator dropoutGeneratorOutputDevice)
     (Tensor
        (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
        (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
        (Seq
           (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
           dataType)
        (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape))
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator dropoutGeneratorOutputDevice
  -&gt; m (Tensor
          (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
          (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
          (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
          (Seq
             (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
             dataType)
          (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape),
        Generator dropoutGeneratorOutputDevice))
 -&gt; IxStateT
      m
      (Generator dropoutGeneratorOutputDevice)
      (Generator dropoutGeneratorOutputDevice)
      (Tensor
         (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
         (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
         (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
         (Seq
            (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
            dataType)
         (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)))
-&gt; (Tensor
      decoderRelPosGradient
      decoderRelPosLayout
      decoderRelPosDevice
      decoderRelPosDataType
      decoderRelPosShape
    -&gt; Generator dropoutGeneratorOutputDevice
    -&gt; m (Tensor
            (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
            (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
            (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
            (Seq
               (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
               dataType)
            (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape),
          Generator dropoutGeneratorOutputDevice))
-&gt; Tensor
     decoderRelPosGradient
     decoderRelPosLayout
     decoderRelPosDevice
     decoderRelPosDataType
     decoderRelPosShape
-&gt; IxStateT
     m
     (Generator dropoutGeneratorOutputDevice)
     (Generator dropoutGeneratorOutputDevice)
     (Tensor
        (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
        (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
        (Seq
           (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
           dataType)
        (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape))
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Embedding
  gradient
  ('Layout 'Dense)
  device
  dataType
  posEncDim
  headDim
  'Nothing
-&gt; Tensor
     decoderRelPosGradient
     decoderRelPosLayout
     decoderRelPosDevice
     decoderRelPosDataType
     decoderRelPosShape
-&gt; Generator dropoutGeneratorOutputDevice
-&gt; m (Tensor
        (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
        (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
        (Seq
           (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
           dataType)
        (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape),
      Generator dropoutGeneratorOutputDevice)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: * -&gt; *).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">Embedding
  gradient
  ('Layout 'Dense)
  device
  dataType
  posEncDim
  headDim
  'Nothing
TDPosEncF
  'ByT5
  gradient
  device
  dataType
  headDim
  decoderInputEmbedDim
  posEncDim
</span><a href="#local-6989586621679808425"><span class="hs-identifier hs-var">tdPosEnc</span></a></span><span>
</span><span id="line-644"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator dropoutGeneratorOutputDevice)
  (Generator dropoutGeneratorOutputDevice)
  (Tensor
     (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
     (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
     (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
     (Seq
        (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
        dataType)
     (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape))
-&gt; (Tensor
      (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
      (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
      (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
      (Seq
         (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
         dataType)
      (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)
    -&gt; IxStateT
         m
         (Generator dropoutGeneratorOutputDevice)
         (Generator dropoutGeneratorOutputDevice)
         (Tensor
            (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
            (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
            (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
            (Seq
               (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
               dataType)
            (TransposeF
               ('SelectDim ('ByIndex 2))
               ('SelectDim ('ByIndex 3))
               (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape))))
-&gt; IxStateT
     m
     (Generator dropoutGeneratorOutputDevice)
     (Generator dropoutGeneratorOutputDevice)
     (Tensor
        (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
        (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
        (Seq
           (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
           dataType)
        (TransposeF
           ('SelectDim ('ByIndex 2))
           ('SelectDim ('ByIndex 3))
           (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)))
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">m (Tensor
     (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
     (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
     (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
     (Seq
        (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
        dataType)
     (TransposeF
        ('SelectDim ('ByIndex 2))
        ('SelectDim ('ByIndex 3))
        (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)))
-&gt; IxStateT
     m
     (Generator dropoutGeneratorOutputDevice)
     (Generator dropoutGeneratorOutputDevice)
     (Tensor
        (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
        (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
        (Seq
           (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
           dataType)
        (TransposeF
           ('SelectDim ('ByIndex 2))
           ('SelectDim ('ByIndex 3))
           (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)))
forall k (t :: (* -&gt; *) -&gt; k -&gt; k -&gt; * -&gt; *) (m :: * -&gt; *) a
       (i :: k).
(IxMonadTrans t, Monad m) =&gt;
m a -&gt; t m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ilift</span></a></span><span> </span><span class="annot"><span class="annottext">(m (Tensor
      (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
      (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
      (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
      (Seq
         (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
         dataType)
      (TransposeF
         ('SelectDim ('ByIndex 2))
         ('SelectDim ('ByIndex 3))
         (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)))
 -&gt; IxStateT
      m
      (Generator dropoutGeneratorOutputDevice)
      (Generator dropoutGeneratorOutputDevice)
      (Tensor
         (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
         (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
         (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
         (Seq
            (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
            dataType)
         (TransposeF
            ('SelectDim ('ByIndex 2))
            ('SelectDim ('ByIndex 3))
            (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape))))
-&gt; (Tensor
      (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
      (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
      (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
      (Seq
         (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
         dataType)
      (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)
    -&gt; m (Tensor
            (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
            (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
            (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
            (Seq
               (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
               dataType)
            (TransposeF
               ('SelectDim ('ByIndex 2))
               ('SelectDim ('ByIndex 3))
               (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape))))
-&gt; Tensor
     (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
     (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
     (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
     (Seq
        (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
        dataType)
     (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)
-&gt; IxStateT
     m
     (Generator dropoutGeneratorOutputDevice)
     (Generator dropoutGeneratorOutputDevice)
     (Tensor
        (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
        (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
        (Seq
           (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
           dataType)
        (TransposeF
           ('SelectDim ('ByIndex 2))
           ('SelectDim ('ByIndex 3))
           (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)))
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]) (m :: * -&gt; *).
(shape'
 ~ TransposeF
     ('SelectDim ('ByIndex 2)) ('SelectDim ('ByIndex 3)) shape,
 SingI ('SelectDim ('ByIndex 2)), SingI ('SelectDim ('ByIndex 3)),
 MonadThrow m) =&gt;
Tensor gradient layout device dataType shape
-&gt; m (Tensor gradient layout device dataType shape')
forall (selectDim0 :: SelectDim (By Symbol Nat))
       (selectDim1 :: SelectDim (By Symbol Nat))
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]) (m :: * -&gt; *).
(shape' ~ TransposeF selectDim0 selectDim1 shape, SingI selectDim0,
 SingI selectDim1, MonadThrow m) =&gt;
Tensor gradient layout device dataType shape
-&gt; m (Tensor gradient layout device dataType shape')
</span><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#transpose"><span class="hs-identifier hs-var">transpose</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">2</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">3</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-645"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator dropoutGeneratorOutputDevice)
  (Generator dropoutGeneratorOutputDevice)
  (Tensor
     (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
     (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
     (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
     (Seq
        (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
        dataType)
     (TransposeF
        ('SelectDim ('ByIndex 2))
        ('SelectDim ('ByIndex 3))
        (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)))
-&gt; (Tensor
      (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
      (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
      (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
      (Seq
         (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
         dataType)
      (TransposeF
         ('SelectDim ('ByIndex 2))
         ('SelectDim ('ByIndex 3))
         (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape))
    -&gt; IxStateT
         m
         (Generator dropoutGeneratorOutputDevice)
         (Generator dropoutGeneratorOutputDevice)
         (Tensor
            (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
            (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
            (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
            (Seq
               (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
               dataType)
            (TransposeF
               ('SelectDim ('ByIndex 1))
               ('SelectDim ('ByIndex 2))
               (TransposeF
                  ('SelectDim ('ByIndex 2))
                  ('SelectDim ('ByIndex 3))
                  (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)))))
-&gt; IxStateT
     m
     (Generator dropoutGeneratorOutputDevice)
     (Generator dropoutGeneratorOutputDevice)
     (Tensor
        (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
        (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
        (Seq
           (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
           dataType)
        (TransposeF
           ('SelectDim ('ByIndex 1))
           ('SelectDim ('ByIndex 2))
           (TransposeF
              ('SelectDim ('ByIndex 2))
              ('SelectDim ('ByIndex 3))
              (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape))))
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">m (Tensor
     (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
     (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
     (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
     (Seq
        (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
        dataType)
     (TransposeF
        ('SelectDim ('ByIndex 1))
        ('SelectDim ('ByIndex 2))
        (TransposeF
           ('SelectDim ('ByIndex 2))
           ('SelectDim ('ByIndex 3))
           (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape))))
-&gt; IxStateT
     m
     (Generator dropoutGeneratorOutputDevice)
     (Generator dropoutGeneratorOutputDevice)
     (Tensor
        (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
        (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
        (Seq
           (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
           dataType)
        (TransposeF
           ('SelectDim ('ByIndex 1))
           ('SelectDim ('ByIndex 2))
           (TransposeF
              ('SelectDim ('ByIndex 2))
              ('SelectDim ('ByIndex 3))
              (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape))))
forall k (t :: (* -&gt; *) -&gt; k -&gt; k -&gt; * -&gt; *) (m :: * -&gt; *) a
       (i :: k).
(IxMonadTrans t, Monad m) =&gt;
m a -&gt; t m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ilift</span></a></span><span> </span><span class="annot"><span class="annottext">(m (Tensor
      (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
      (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
      (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
      (Seq
         (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
         dataType)
      (TransposeF
         ('SelectDim ('ByIndex 1))
         ('SelectDim ('ByIndex 2))
         (TransposeF
            ('SelectDim ('ByIndex 2))
            ('SelectDim ('ByIndex 3))
            (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape))))
 -&gt; IxStateT
      m
      (Generator dropoutGeneratorOutputDevice)
      (Generator dropoutGeneratorOutputDevice)
      (Tensor
         (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
         (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
         (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
         (Seq
            (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
            dataType)
         (TransposeF
            ('SelectDim ('ByIndex 1))
            ('SelectDim ('ByIndex 2))
            (TransposeF
               ('SelectDim ('ByIndex 2))
               ('SelectDim ('ByIndex 3))
               (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)))))
-&gt; (Tensor
      (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
      (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
      (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
      (Seq
         (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
         dataType)
      (TransposeF
         ('SelectDim ('ByIndex 2))
         ('SelectDim ('ByIndex 3))
         (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape))
    -&gt; m (Tensor
            (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
            (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
            (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
            (Seq
               (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
               dataType)
            (TransposeF
               ('SelectDim ('ByIndex 1))
               ('SelectDim ('ByIndex 2))
               (TransposeF
                  ('SelectDim ('ByIndex 2))
                  ('SelectDim ('ByIndex 3))
                  (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)))))
-&gt; Tensor
     (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
     (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
     (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
     (Seq
        (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
        dataType)
     (TransposeF
        ('SelectDim ('ByIndex 2))
        ('SelectDim ('ByIndex 3))
        (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape))
-&gt; IxStateT
     m
     (Generator dropoutGeneratorOutputDevice)
     (Generator dropoutGeneratorOutputDevice)
     (Tensor
        (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
        (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
        (Seq
           (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
           dataType)
        (TransposeF
           ('SelectDim ('ByIndex 1))
           ('SelectDim ('ByIndex 2))
           (TransposeF
              ('SelectDim ('ByIndex 2))
              ('SelectDim ('ByIndex 3))
              (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape))))
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]) (m :: * -&gt; *).
(shape'
 ~ TransposeF
     ('SelectDim ('ByIndex 1)) ('SelectDim ('ByIndex 2)) shape,
 SingI ('SelectDim ('ByIndex 1)), SingI ('SelectDim ('ByIndex 2)),
 MonadThrow m) =&gt;
Tensor gradient layout device dataType shape
-&gt; m (Tensor gradient layout device dataType shape')
forall (selectDim0 :: SelectDim (By Symbol Nat))
       (selectDim1 :: SelectDim (By Symbol Nat))
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]) (m :: * -&gt; *).
(shape' ~ TransposeF selectDim0 selectDim1 shape, SingI selectDim0,
 SingI selectDim1, MonadThrow m) =&gt;
Tensor gradient layout device dataType shape
-&gt; m (Tensor gradient layout device dataType shape')
</span><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#transpose"><span class="hs-identifier hs-var">transpose</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">2</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-646"></span><span>        </span><span id="local-6989586621679808418"><span class="annot"><span class="annottext">decoderAttentionBias :: IxStateT
  m
  (Generator dropoutGeneratorOutputDevice)
  (Generator dropoutGeneratorOutputDevice)
  (Tensor
     (Or
        (Gradient RequiresGradient)
        (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
        decoderAttentionMaskGradient)
     (Unify
        (Layout LayoutType)
        (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
        decoderAttentionMaskLayout)
     (Unify
        (Device (DeviceType Nat))
        (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
        decoderAttentionMaskDevice)
     (Unify
        (DataType DType)
        (Seq
           (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
           dataType)
        decoderAttentionMaskDataType)
     (BroadcastShapesF
        (TransposeF
           ('SelectDim ('ByIndex 1))
           ('SelectDim ('ByIndex 2))
           (TransposeF
              ('SelectDim ('ByIndex 2))
              ('SelectDim ('ByIndex 3))
              (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)))
        (UnsqueezeF ('SelectDim ('ByIndex 1)) decoderAttentionMaskShape)))
</span><a href="#local-6989586621679808418"><span class="hs-identifier hs-var hs-var">decoderAttentionBias</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-647"></span><span>          </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator dropoutGeneratorOutputDevice)
  (Generator dropoutGeneratorOutputDevice)
  (Tensor
     (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
     (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
     (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
     (Seq
        (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
        dataType)
     (TransposeF
        ('SelectDim ('ByIndex 1))
        ('SelectDim ('ByIndex 2))
        (TransposeF
           ('SelectDim ('ByIndex 2))
           ('SelectDim ('ByIndex 3))
           (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape))))
</span><a href="#local-6989586621679808419"><span class="hs-identifier hs-var">decoderRelPosBias</span></a></span><span>
</span><span id="line-648"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator dropoutGeneratorOutputDevice)
  (Generator dropoutGeneratorOutputDevice)
  (Tensor
     (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
     (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
     (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
     (Seq
        (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
        dataType)
     (TransposeF
        ('SelectDim ('ByIndex 1))
        ('SelectDim ('ByIndex 2))
        (TransposeF
           ('SelectDim ('ByIndex 2))
           ('SelectDim ('ByIndex 3))
           (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape))))
-&gt; (Tensor
      (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
      (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
      (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
      (Seq
         (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
         dataType)
      (TransposeF
         ('SelectDim ('ByIndex 1))
         ('SelectDim ('ByIndex 2))
         (TransposeF
            ('SelectDim ('ByIndex 2))
            ('SelectDim ('ByIndex 3))
            (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)))
    -&gt; IxStateT
         m
         (Generator dropoutGeneratorOutputDevice)
         (Generator dropoutGeneratorOutputDevice)
         (Tensor
            (Or
               (Gradient RequiresGradient)
               (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
               decoderAttentionMaskGradient)
            (Unify
               (Layout LayoutType)
               (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
               decoderAttentionMaskLayout)
            (Unify
               (Device (DeviceType Nat))
               (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
               decoderAttentionMaskDevice)
            (Unify
               (DataType DType)
               (Seq
                  (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
                  dataType)
               decoderAttentionMaskDataType)
            (BroadcastShapesF
               (TransposeF
                  ('SelectDim ('ByIndex 1))
                  ('SelectDim ('ByIndex 2))
                  (TransposeF
                     ('SelectDim ('ByIndex 2))
                     ('SelectDim ('ByIndex 3))
                     (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)))
               (UnsqueezeF ('SelectDim ('ByIndex 1)) decoderAttentionMaskShape))))
-&gt; IxStateT
     m
     (Generator dropoutGeneratorOutputDevice)
     (Generator dropoutGeneratorOutputDevice)
     (Tensor
        (Or
           (Gradient RequiresGradient)
           (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
           decoderAttentionMaskGradient)
        (Unify
           (Layout LayoutType)
           (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
           decoderAttentionMaskLayout)
        (Unify
           (Device (DeviceType Nat))
           (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
           decoderAttentionMaskDevice)
        (Unify
           (DataType DType)
           (Seq
              (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
              dataType)
           decoderAttentionMaskDataType)
        (BroadcastShapesF
           (TransposeF
              ('SelectDim ('ByIndex 1))
              ('SelectDim ('ByIndex 2))
              (TransposeF
                 ('SelectDim ('ByIndex 2))
                 ('SelectDim ('ByIndex 3))
                 (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)))
           (UnsqueezeF ('SelectDim ('ByIndex 1)) decoderAttentionMaskShape)))
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  (Or
     (Gradient RequiresGradient)
     (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
     decoderAttentionMaskGradient)
  (Unify
     (Layout LayoutType)
     (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
     decoderAttentionMaskLayout)
  (Unify
     (Device (DeviceType Nat))
     (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
     decoderAttentionMaskDevice)
  (Unify
     (DataType DType)
     (Seq
        (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
        dataType)
     decoderAttentionMaskDataType)
  (BroadcastShapesF
     (TransposeF
        ('SelectDim ('ByIndex 1))
        ('SelectDim ('ByIndex 2))
        (TransposeF
           ('SelectDim ('ByIndex 2))
           ('SelectDim ('ByIndex 3))
           (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)))
     (UnsqueezeF ('SelectDim ('ByIndex 1)) decoderAttentionMaskShape))
-&gt; IxStateT
     m
     (Generator dropoutGeneratorOutputDevice)
     (Generator dropoutGeneratorOutputDevice)
     (Tensor
        (Or
           (Gradient RequiresGradient)
           (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
           decoderAttentionMaskGradient)
        (Unify
           (Layout LayoutType)
           (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
           decoderAttentionMaskLayout)
        (Unify
           (Device (DeviceType Nat))
           (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
           decoderAttentionMaskDevice)
        (Unify
           (DataType DType)
           (Seq
              (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
              dataType)
           decoderAttentionMaskDataType)
        (BroadcastShapesF
           (TransposeF
              ('SelectDim ('ByIndex 1))
              ('SelectDim ('ByIndex 2))
              (TransposeF
                 ('SelectDim ('ByIndex 2))
                 ('SelectDim ('ByIndex 3))
                 (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)))
           (UnsqueezeF ('SelectDim ('ByIndex 1)) decoderAttentionMaskShape)))
forall k (m :: k -&gt; k -&gt; * -&gt; *) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">(Tensor
   (Or
      (Gradient RequiresGradient)
      (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
      decoderAttentionMaskGradient)
   (Unify
      (Layout LayoutType)
      (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
      decoderAttentionMaskLayout)
   (Unify
      (Device (DeviceType Nat))
      (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
      decoderAttentionMaskDevice)
   (Unify
      (DataType DType)
      (Seq
         (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
         dataType)
      decoderAttentionMaskDataType)
   (BroadcastShapesF
      (TransposeF
         ('SelectDim ('ByIndex 1))
         ('SelectDim ('ByIndex 2))
         (TransposeF
            ('SelectDim ('ByIndex 2))
            ('SelectDim ('ByIndex 3))
            (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)))
      (UnsqueezeF ('SelectDim ('ByIndex 1)) decoderAttentionMaskShape))
 -&gt; IxStateT
      m
      (Generator dropoutGeneratorOutputDevice)
      (Generator dropoutGeneratorOutputDevice)
      (Tensor
         (Or
            (Gradient RequiresGradient)
            (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
            decoderAttentionMaskGradient)
         (Unify
            (Layout LayoutType)
            (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
            decoderAttentionMaskLayout)
         (Unify
            (Device (DeviceType Nat))
            (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
            decoderAttentionMaskDevice)
         (Unify
            (DataType DType)
            (Seq
               (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
               dataType)
            decoderAttentionMaskDataType)
         (BroadcastShapesF
            (TransposeF
               ('SelectDim ('ByIndex 1))
               ('SelectDim ('ByIndex 2))
               (TransposeF
                  ('SelectDim ('ByIndex 2))
                  ('SelectDim ('ByIndex 3))
                  (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)))
            (UnsqueezeF ('SelectDim ('ByIndex 1)) decoderAttentionMaskShape))))
-&gt; (Tensor
      (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
      (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
      (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
      (Seq
         (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
         dataType)
      (TransposeF
         ('SelectDim ('ByIndex 1))
         ('SelectDim ('ByIndex 2))
         (TransposeF
            ('SelectDim ('ByIndex 2))
            ('SelectDim ('ByIndex 3))
            (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)))
    -&gt; Tensor
         (Or
            (Gradient RequiresGradient)
            (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
            decoderAttentionMaskGradient)
         (Unify
            (Layout LayoutType)
            (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
            decoderAttentionMaskLayout)
         (Unify
            (Device (DeviceType Nat))
            (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
            decoderAttentionMaskDevice)
         (Unify
            (DataType DType)
            (Seq
               (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
               dataType)
            decoderAttentionMaskDataType)
         (BroadcastShapesF
            (TransposeF
               ('SelectDim ('ByIndex 1))
               ('SelectDim ('ByIndex 2))
               (TransposeF
                  ('SelectDim ('ByIndex 2))
                  ('SelectDim ('ByIndex 3))
                  (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)))
            (UnsqueezeF ('SelectDim ('ByIndex 1)) decoderAttentionMaskShape)))
-&gt; Tensor
     (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
     (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
     (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
     (Seq
        (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
        dataType)
     (TransposeF
        ('SelectDim ('ByIndex 1))
        ('SelectDim ('ByIndex 2))
        (TransposeF
           ('SelectDim ('ByIndex 2))
           ('SelectDim ('ByIndex 3))
           (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)))
-&gt; IxStateT
     m
     (Generator dropoutGeneratorOutputDevice)
     (Generator dropoutGeneratorOutputDevice)
     (Tensor
        (Or
           (Gradient RequiresGradient)
           (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
           decoderAttentionMaskGradient)
        (Unify
           (Layout LayoutType)
           (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
           decoderAttentionMaskLayout)
        (Unify
           (Device (DeviceType Nat))
           (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
           decoderAttentionMaskDevice)
        (Unify
           (DataType DType)
           (Seq
              (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
              dataType)
           decoderAttentionMaskDataType)
        (BroadcastShapesF
           (TransposeF
              ('SelectDim ('ByIndex 1))
              ('SelectDim ('ByIndex 2))
              (TransposeF
                 ('SelectDim ('ByIndex 2))
                 ('SelectDim ('ByIndex 3))
                 (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)))
           (UnsqueezeF ('SelectDim ('ByIndex 1)) decoderAttentionMaskShape)))
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Tensor
  (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
  (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
  (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
  (Seq
     (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
     dataType)
  (TransposeF
     ('SelectDim ('ByIndex 1))
     ('SelectDim ('ByIndex 2))
     (TransposeF
        ('SelectDim ('ByIndex 2))
        ('SelectDim ('ByIndex 3))
        (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)))
-&gt; Tensor
     decoderAttentionMaskGradient
     decoderAttentionMaskLayout
     decoderAttentionMaskDevice
     decoderAttentionMaskDataType
     (UnsqueezeF ('SelectDim ('ByIndex 1)) decoderAttentionMaskShape)
-&gt; Tensor
     (Or (Gradient RequiresGradient) gradient decoderRelPosGradient
      &lt;|&gt; decoderAttentionMaskGradient)
     (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout
      &lt;+&gt; decoderAttentionMaskLayout)
     (Unify (Device (DeviceType Nat)) device decoderRelPosDevice
      &lt;+&gt; decoderAttentionMaskDevice)
     (Seq
        (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
        dataType
      &lt;+&gt; decoderAttentionMaskDataType)
     (BroadcastShapesF
        (TransposeF
           ('SelectDim ('ByIndex 1))
           ('SelectDim ('ByIndex 2))
           (TransposeF
              ('SelectDim ('ByIndex 2))
              ('SelectDim ('ByIndex 3))
              (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)))
        (UnsqueezeF ('SelectDim ('ByIndex 1)) decoderAttentionMaskShape))
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (gradient' :: Gradient RequiresGradient)
       (layout' :: Layout LayoutType) (device' :: Device (DeviceType Nat))
       (dataType' :: DataType DType)
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]).
Tensor gradient layout device dataType shape
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; Tensor
     (gradient &lt;|&gt; gradient')
     (layout &lt;+&gt; layout')
     (device &lt;+&gt; device')
     (dataType &lt;+&gt; dataType')
     (BroadcastShapesF shape shape')
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#add"><span class="hs-operator hs-var">`add`</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  decoderAttentionMaskGradient
  decoderAttentionMaskLayout
  decoderAttentionMaskDevice
  decoderAttentionMaskDataType
  decoderAttentionMaskShape
-&gt; Tensor
     decoderAttentionMaskGradient
     decoderAttentionMaskLayout
     decoderAttentionMaskDevice
     decoderAttentionMaskDataType
     (UnsqueezeF ('SelectDim ('ByIndex 1)) decoderAttentionMaskShape)
forall (selectDim :: SelectDim (By Symbol Nat))
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]).
(shape' ~ UnsqueezeF selectDim shape, SingI selectDim) =&gt;
Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape'
</span><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#unsqueeze"><span class="hs-identifier hs-var">unsqueeze</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
  decoderAttentionMaskGradient
  decoderAttentionMaskLayout
  decoderAttentionMaskDevice
  decoderAttentionMaskDataType
  decoderAttentionMaskShape
</span><a href="#local-6989586621679808421"><span class="hs-identifier hs-var">decoderAttentionMask</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-649"></span><span>        </span><span id="local-6989586621679808417"><span class="annot"><span class="annottext">crossAttentionBias :: Tensor
  crossAttentionMaskGradient
  crossAttentionMaskLayout
  crossAttentionMaskDevice
  crossAttentionMaskDataType
  (UnsqueezeF ('SelectDim ('ByIndex 1)) crossAttentionMaskShape)
</span><a href="#local-6989586621679808417"><span class="hs-identifier hs-var hs-var">crossAttentionBias</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor
  crossAttentionMaskGradient
  crossAttentionMaskLayout
  crossAttentionMaskDevice
  crossAttentionMaskDataType
  crossAttentionMaskShape
-&gt; Tensor
     crossAttentionMaskGradient
     crossAttentionMaskLayout
     crossAttentionMaskDevice
     crossAttentionMaskDataType
     (UnsqueezeF ('SelectDim ('ByIndex 1)) crossAttentionMaskShape)
forall (selectDim :: SelectDim (By Symbol Nat))
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]).
(shape' ~ UnsqueezeF selectDim shape, SingI selectDim) =&gt;
Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape'
</span><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#unsqueeze"><span class="hs-identifier hs-var">unsqueeze</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
  crossAttentionMaskGradient
  crossAttentionMaskLayout
  crossAttentionMaskDevice
  crossAttentionMaskDataType
  crossAttentionMaskShape
</span><a href="#local-6989586621679808420"><span class="hs-identifier hs-var">crossAttentionMask</span></a></span><span>
</span><span id="line-650"></span><span>     </span><span class="hs-keyword">in</span><span> </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorOutputDevice)
  output
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
forall (m :: * -&gt; *) i j a. IxStateT m i j a -&gt; i -&gt; m (a, j)
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var hs-var">runIxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">(IxStateT
   m
   (Generator generatorDevice)
   (Generator generatorOutputDevice)
   output
 -&gt; Generator generatorDevice
 -&gt; m (output, Generator generatorOutputDevice))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorOutputDevice)
     output
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-651"></span><span>          </span><span class="annot"><span class="annottext">decoderInput
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     decoderInput
forall k (m :: k -&gt; k -&gt; * -&gt; *) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">decoderInput
</span><a href="#local-6989586621679808424"><span class="hs-identifier hs-var">decoderInput</span></a></span><span>
</span><span id="line-652"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorDevice)
  decoderInput
-&gt; (decoderInput
    -&gt; IxStateT
         m
         (Generator generatorDevice)
         (Generator dropoutGeneratorOutputDevice)
         dropoutOutput)
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator dropoutGeneratorOutputDevice)
     dropoutOutput
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(Generator generatorDevice
 -&gt; m (dropoutOutput, Generator dropoutGeneratorOutputDevice))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator dropoutGeneratorOutputDevice)
     dropoutOutput
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator generatorDevice
  -&gt; m (dropoutOutput, Generator dropoutGeneratorOutputDevice))
 -&gt; IxStateT
      m
      (Generator generatorDevice)
      (Generator dropoutGeneratorOutputDevice)
      dropoutOutput)
-&gt; (decoderInput
    -&gt; Generator generatorDevice
    -&gt; m (dropoutOutput, Generator dropoutGeneratorOutputDevice))
-&gt; decoderInput
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator dropoutGeneratorOutputDevice)
     dropoutOutput
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Dropout
-&gt; decoderInput
-&gt; Generator generatorDevice
-&gt; m (dropoutOutput, Generator dropoutGeneratorOutputDevice)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: * -&gt; *).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">Dropout
TDDropoutF 'ByT5
</span><a href="#local-6989586621679808426"><span class="hs-identifier hs-var">tdDropout</span></a></span><span>
</span><span id="line-653"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator dropoutGeneratorOutputDevice)
  dropoutOutput
-&gt; (dropoutOutput
    -&gt; IxStateT
         m
         (Generator dropoutGeneratorOutputDevice)
         (Generator stackGeneratorOutputDevice)
         stackOutput)
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator stackGeneratorOutputDevice)
     stackOutput
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="hs-special">(</span><span> </span><span class="hs-glyph">\</span><span id="local-6989586621679808416"><span class="annot"><span class="annottext">dropoutOutput
</span><a href="#local-6989586621679808416"><span class="hs-identifier hs-var">decoderInput'</span></a></span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-654"></span><span>                     </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator dropoutGeneratorOutputDevice)
  (Generator dropoutGeneratorOutputDevice)
  (Tensor
     (Or
        (Gradient RequiresGradient)
        (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
        decoderAttentionMaskGradient)
     (Unify
        (Layout LayoutType)
        (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
        decoderAttentionMaskLayout)
     (Unify
        (Device (DeviceType Nat))
        (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
        decoderAttentionMaskDevice)
     (Unify
        (DataType DType)
        (Seq
           (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
           dataType)
        decoderAttentionMaskDataType)
     (BroadcastShapesF
        (TransposeF
           ('SelectDim ('ByIndex 1))
           ('SelectDim ('ByIndex 2))
           (TransposeF
              ('SelectDim ('ByIndex 2))
              ('SelectDim ('ByIndex 3))
              (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)))
        (UnsqueezeF ('SelectDim ('ByIndex 1)) decoderAttentionMaskShape)))
</span><a href="#local-6989586621679808418"><span class="hs-identifier hs-var">decoderAttentionBias</span></a></span><span>
</span><span id="line-655"></span><span>                       </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator dropoutGeneratorOutputDevice)
  (Generator dropoutGeneratorOutputDevice)
  (Tensor
     (Or
        (Gradient RequiresGradient)
        (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
        decoderAttentionMaskGradient)
     (Unify
        (Layout LayoutType)
        (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
        decoderAttentionMaskLayout)
     (Unify
        (Device (DeviceType Nat))
        (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
        decoderAttentionMaskDevice)
     (Unify
        (DataType DType)
        (Seq
           (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
           dataType)
        decoderAttentionMaskDataType)
     (BroadcastShapesF
        (TransposeF
           ('SelectDim ('ByIndex 1))
           ('SelectDim ('ByIndex 2))
           (TransposeF
              ('SelectDim ('ByIndex 2))
              ('SelectDim ('ByIndex 3))
              (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)))
        (UnsqueezeF ('SelectDim ('ByIndex 1)) decoderAttentionMaskShape)))
-&gt; (Tensor
      (Or
         (Gradient RequiresGradient)
         (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
         decoderAttentionMaskGradient)
      (Unify
         (Layout LayoutType)
         (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
         decoderAttentionMaskLayout)
      (Unify
         (Device (DeviceType Nat))
         (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
         decoderAttentionMaskDevice)
      (Unify
         (DataType DType)
         (Seq
            (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
            dataType)
         decoderAttentionMaskDataType)
      (BroadcastShapesF
         (TransposeF
            ('SelectDim ('ByIndex 1))
            ('SelectDim ('ByIndex 2))
            (TransposeF
               ('SelectDim ('ByIndex 2))
               ('SelectDim ('ByIndex 3))
               (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)))
         (UnsqueezeF ('SelectDim ('ByIndex 1)) decoderAttentionMaskShape))
    -&gt; IxStateT
         m
         (Generator dropoutGeneratorOutputDevice)
         (Generator stackGeneratorOutputDevice)
         stackOutput)
-&gt; IxStateT
     m
     (Generator dropoutGeneratorOutputDevice)
     (Generator stackGeneratorOutputDevice)
     stackOutput
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="hs-special">(</span><span> </span><span class="hs-glyph">\</span><span id="local-6989586621679808415"><span class="annot"><span class="annottext">Tensor
  (Or
     (Gradient RequiresGradient)
     (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
     decoderAttentionMaskGradient)
  (Unify
     (Layout LayoutType)
     (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
     decoderAttentionMaskLayout)
  (Unify
     (Device (DeviceType Nat))
     (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
     decoderAttentionMaskDevice)
  (Unify
     (DataType DType)
     (Seq
        (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
        dataType)
     decoderAttentionMaskDataType)
  (BroadcastShapesF
     (TransposeF
        ('SelectDim ('ByIndex 1))
        ('SelectDim ('ByIndex 2))
        (TransposeF
           ('SelectDim ('ByIndex 2))
           ('SelectDim ('ByIndex 3))
           (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)))
     (UnsqueezeF ('SelectDim ('ByIndex 1)) decoderAttentionMaskShape))
</span><a href="#local-6989586621679808415"><span class="hs-identifier hs-var">decoderAttentionBias'</span></a></span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-656"></span><span>                                </span><span class="annot"><span class="annottext">(Generator dropoutGeneratorOutputDevice
 -&gt; m (stackOutput, Generator stackGeneratorOutputDevice))
-&gt; IxStateT
     m
     (Generator dropoutGeneratorOutputDevice)
     (Generator stackGeneratorOutputDevice)
     stackOutput
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator dropoutGeneratorOutputDevice
  -&gt; m (stackOutput, Generator stackGeneratorOutputDevice))
 -&gt; IxStateT
      m
      (Generator dropoutGeneratorOutputDevice)
      (Generator stackGeneratorOutputDevice)
      stackOutput)
-&gt; (Generator dropoutGeneratorOutputDevice
    -&gt; m (stackOutput, Generator stackGeneratorOutputDevice))
-&gt; IxStateT
     m
     (Generator dropoutGeneratorOutputDevice)
     (Generator stackGeneratorOutputDevice)
     stackOutput
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-657"></span><span>                                  </span><span class="annot"><span class="annottext">TransformerDecoderStack
  'ByT5
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  decoderInputEmbedDim
  encoderOutputEmbedDim
  ffnDim
-&gt; (dropoutOutput, encoderOutput,
    Tensor
      (Or
         (Gradient RequiresGradient)
         (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
         decoderAttentionMaskGradient)
      (Unify
         (Layout LayoutType)
         (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
         decoderAttentionMaskLayout)
      (Unify
         (Device (DeviceType Nat))
         (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
         decoderAttentionMaskDevice)
      (Unify
         (DataType DType)
         (Seq
            (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
            dataType)
         decoderAttentionMaskDataType)
      (BroadcastShapesF
         (TransposeF
            ('SelectDim ('ByIndex 1))
            ('SelectDim ('ByIndex 2))
            (TransposeF
               ('SelectDim ('ByIndex 2))
               ('SelectDim ('ByIndex 3))
               (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)))
         (UnsqueezeF ('SelectDim ('ByIndex 1)) decoderAttentionMaskShape)),
    Tensor
      crossAttentionMaskGradient
      crossAttentionMaskLayout
      crossAttentionMaskDevice
      crossAttentionMaskDataType
      (UnsqueezeF ('SelectDim ('ByIndex 1)) crossAttentionMaskShape))
-&gt; Generator dropoutGeneratorOutputDevice
-&gt; m (stackOutput, Generator stackGeneratorOutputDevice)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: * -&gt; *).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span>
</span><span id="line-658"></span><span>                                    </span><span class="annot"><span class="annottext">TransformerDecoderStack
  'ByT5
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  decoderInputEmbedDim
  encoderOutputEmbedDim
  ffnDim
TDStackF
  'ByT5
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  decoderInputEmbedDim
  encoderOutputEmbedDim
  ffnDim
</span><a href="#local-6989586621679808429"><span class="hs-identifier hs-var">tdStack</span></a></span><span>
</span><span id="line-659"></span><span>                                    </span><span class="hs-special">(</span><span> </span><span class="annot"><span class="annottext">dropoutOutput
</span><a href="#local-6989586621679808416"><span class="hs-identifier hs-var">decoderInput'</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-660"></span><span>                                      </span><span class="annot"><span class="annottext">encoderOutput
</span><a href="#local-6989586621679808423"><span class="hs-identifier hs-var">encoderOutput</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-661"></span><span>                                      </span><span class="annot"><span class="annottext">Tensor
  (Or
     (Gradient RequiresGradient)
     (Or (Gradient RequiresGradient) gradient decoderRelPosGradient)
     decoderAttentionMaskGradient)
  (Unify
     (Layout LayoutType)
     (Unify (Layout LayoutType) ('Layout 'Dense) decoderRelPosLayout)
     decoderAttentionMaskLayout)
  (Unify
     (Device (DeviceType Nat))
     (Unify (Device (DeviceType Nat)) device decoderRelPosDevice)
     decoderAttentionMaskDevice)
  (Unify
     (DataType DType)
     (Seq
        (Unify (DataType DType) decoderRelPosDataType ('DataType 'Int64))
        dataType)
     decoderAttentionMaskDataType)
  (BroadcastShapesF
     (TransposeF
        ('SelectDim ('ByIndex 1))
        ('SelectDim ('ByIndex 2))
        (TransposeF
           ('SelectDim ('ByIndex 2))
           ('SelectDim ('ByIndex 3))
           (EmbeddingF ('Shape '[posEncDim, headDim]) decoderRelPosShape)))
     (UnsqueezeF ('SelectDim ('ByIndex 1)) decoderAttentionMaskShape))
</span><a href="#local-6989586621679808415"><span class="hs-identifier hs-var">decoderAttentionBias'</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-662"></span><span>                                      </span><span class="annot"><span class="annottext">Tensor
  crossAttentionMaskGradient
  crossAttentionMaskLayout
  crossAttentionMaskDevice
  crossAttentionMaskDataType
  (UnsqueezeF ('SelectDim ('ByIndex 1)) crossAttentionMaskShape)
</span><a href="#local-6989586621679808417"><span class="hs-identifier hs-var">crossAttentionBias</span></a></span><span>
</span><span id="line-663"></span><span>                                    </span><span class="hs-special">)</span><span>
</span><span id="line-664"></span><span>                            </span><span class="hs-special">)</span><span>
</span><span id="line-665"></span><span>                 </span><span class="hs-special">)</span><span>
</span><span id="line-666"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator stackGeneratorOutputDevice)
  stackOutput
-&gt; (stackOutput
    -&gt; IxStateT
         m
         (Generator stackGeneratorOutputDevice)
         (Generator layerNormGeneratorOutputDevice)
         layerNormOutput)
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator layerNormGeneratorOutputDevice)
     layerNormOutput
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(Generator stackGeneratorOutputDevice
 -&gt; m (layerNormOutput, Generator layerNormGeneratorOutputDevice))
-&gt; IxStateT
     m
     (Generator stackGeneratorOutputDevice)
     (Generator layerNormGeneratorOutputDevice)
     layerNormOutput
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator stackGeneratorOutputDevice
  -&gt; m (layerNormOutput, Generator layerNormGeneratorOutputDevice))
 -&gt; IxStateT
      m
      (Generator stackGeneratorOutputDevice)
      (Generator layerNormGeneratorOutputDevice)
      layerNormOutput)
-&gt; (stackOutput
    -&gt; Generator stackGeneratorOutputDevice
    -&gt; m (layerNormOutput, Generator layerNormGeneratorOutputDevice))
-&gt; stackOutput
-&gt; IxStateT
     m
     (Generator stackGeneratorOutputDevice)
     (Generator layerNormGeneratorOutputDevice)
     layerNormOutput
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">LayerNorm
  'WithoutBias
  gradient
  device
  dataType
  ('Shape '[decoderInputEmbedDim])
-&gt; stackOutput
-&gt; Generator stackGeneratorOutputDevice
-&gt; m (layerNormOutput, Generator layerNormGeneratorOutputDevice)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: * -&gt; *).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">LayerNorm
  'WithoutBias
  gradient
  device
  dataType
  ('Shape '[decoderInputEmbedDim])
TDLayerNormF 'ByT5 gradient device dataType decoderInputEmbedDim
</span><a href="#local-6989586621679808427"><span class="hs-identifier hs-var">tdLayerNorm</span></a></span><span>
</span><span id="line-667"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator layerNormGeneratorOutputDevice)
  layerNormOutput
-&gt; (layerNormOutput
    -&gt; IxStateT
         m
         (Generator layerNormGeneratorOutputDevice)
         (Generator generatorOutputDevice)
         output)
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorOutputDevice)
     output
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(Generator layerNormGeneratorOutputDevice
 -&gt; m (output, Generator generatorOutputDevice))
-&gt; IxStateT
     m
     (Generator layerNormGeneratorOutputDevice)
     (Generator generatorOutputDevice)
     output
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator layerNormGeneratorOutputDevice
  -&gt; m (output, Generator generatorOutputDevice))
 -&gt; IxStateT
      m
      (Generator layerNormGeneratorOutputDevice)
      (Generator generatorOutputDevice)
      output)
-&gt; (layerNormOutput
    -&gt; Generator layerNormGeneratorOutputDevice
    -&gt; m (output, Generator generatorOutputDevice))
-&gt; layerNormOutput
-&gt; IxStateT
     m
     (Generator layerNormGeneratorOutputDevice)
     (Generator generatorOutputDevice)
     output
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Dropout
-&gt; layerNormOutput
-&gt; Generator layerNormGeneratorOutputDevice
-&gt; m (output, Generator generatorOutputDevice)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: * -&gt; *).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">Dropout
TDDropoutF 'ByT5
</span><a href="#local-6989586621679808426"><span class="hs-identifier hs-var">tdDropout</span></a></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span>
</span><span id="line-668"></span><span>
</span><span id="line-669"></span><span class="hs-comment">-- | 'HasForward' instance for @TransformerDecoder numLayers 'BART@.</span><span>
</span><span id="line-670"></span><span class="hs-comment">--</span><span>
</span><span id="line-671"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-672"></span><span class="hs-comment">-- &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;  &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;  &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;  &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;  &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;</span><span>
</span><span id="line-673"></span><span class="hs-comment">-- &#9474; decoderInput &#9474;  &#9474; decoderPos &#9474;  &#9474; encoderOutput &#9474;  &#9474; decoderAttentionMask &#9474;  &#9474; crossAttentionMask &#9474;</span><span>
</span><span id="line-674"></span><span class="hs-comment">-- &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;  &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;  &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;  &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;  &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-675"></span><span class="hs-comment">--        &#9474;                 &#9474;                &#9474;                     &#9474;                         &#9474;</span><span>
</span><span id="line-676"></span><span class="hs-comment">--        &#9474;                 &#9660;                &#9474;                     &#9474;                         &#9474;</span><span>
</span><span id="line-677"></span><span class="hs-comment">--        &#9474;             tdPosEnc             &#9474;                     &#9474;                         &#9474;</span><span>
</span><span id="line-678"></span><span class="hs-comment">--        &#9474;                 &#9474;                &#9474;                     &#9474;                         &#9474;</span><span>
</span><span id="line-679"></span><span class="hs-comment">--        &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9658;add&#9668;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;                &#9474;                     &#9474;                         &#9474;</span><span>
</span><span id="line-680"></span><span class="hs-comment">--                 &#9474;                         &#9474;                     &#9474;                         &#9474;</span><span>
</span><span id="line-681"></span><span class="hs-comment">--                 &#9660;                         &#9474;                     &#9474;                         &#9474;</span><span>
</span><span id="line-682"></span><span class="hs-comment">--          tdEmbedLayerNorm                 &#9474;                     &#9474;                         &#9474;</span><span>
</span><span id="line-683"></span><span class="hs-comment">--                 &#9660;                         &#9474;                     &#9660;                         &#9660;</span><span>
</span><span id="line-684"></span><span class="hs-comment">--             tdDropout                     &#9474;                 unsqueeze                 unsqueeze</span><span>
</span><span id="line-685"></span><span class="hs-comment">--                 &#9660;                         &#9474;                     &#9474;                         &#9474;</span><span>
</span><span id="line-686"></span><span class="hs-comment">--              tdStack&#9668;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;&#9668;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;&#9668;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-687"></span><span class="hs-comment">--                 &#9474;</span><span>
</span><span id="line-688"></span><span class="hs-comment">--                 &#9660;</span><span>
</span><span id="line-689"></span><span class="hs-comment">--            &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;</span><span>
</span><span id="line-690"></span><span class="hs-comment">--            &#9474; output &#9474;</span><span>
</span><span id="line-691"></span><span class="hs-comment">--            &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-692"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-693"></span><span id="local-6989586621679808377"><span id="local-6989586621679808378"><span id="local-6989586621679808379"><span id="local-6989586621679808380"><span id="local-6989586621679808381"><span id="local-6989586621679808382"><span id="local-6989586621679808383"><span id="local-6989586621679808384"><span id="local-6989586621679808385"><span id="local-6989586621679808386"><span id="local-6989586621679808387"><span id="local-6989586621679808388"><span id="local-6989586621679808389"><span id="local-6989586621679808390"><span id="local-6989586621679808391"><span id="local-6989586621679808392"><span id="local-6989586621679808393"><span id="local-6989586621679808394"><span id="local-6989586621679808395"><span id="local-6989586621679808396"><span id="local-6989586621679808397"><span id="local-6989586621679808398"><span id="local-6989586621679808399"><span id="local-6989586621679808400"><span id="local-6989586621679808401"><span id="local-6989586621679808402"><span id="local-6989586621679808403"><span id="local-6989586621679808404"><span id="local-6989586621679808405"><span id="local-6989586621679808406"><span id="local-6989586621679808407"><span id="local-6989586621679808408"><span id="local-6989586621679808409"><span id="local-6989586621679808410"><span id="local-6989586621679808411"><span id="local-6989586621679808412"><span id="local-6989586621679808413"><span id="local-6989586621679808414"><span class="hs-keyword">instance</span><span>
</span><span id="line-694"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-695"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TDEmbedLayerNormF"><span class="hs-identifier hs-type">TDEmbedLayerNormF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808414"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808413"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808412"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808411"><span class="hs-identifier hs-type">decoderInputEmbedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-696"></span><span>      </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-697"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679808410"><span class="hs-identifier hs-type">decoderInputGradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808414"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808409"><span class="hs-identifier hs-type">decoderPosGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-698"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679808408"><span class="hs-identifier hs-type">decoderInputLayout</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Dense"><span class="hs-identifier hs-type">Dense</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808407"><span class="hs-identifier hs-type">decoderPosLayout</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-699"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679808406"><span class="hs-identifier hs-type">decoderInputDevice</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808413"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808405"><span class="hs-identifier hs-type">decoderPosDevice</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-700"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679808404"><span class="hs-identifier hs-type">decoderInputDataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Seq"><span class="hs-identifier hs-type">Seq</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679808403"><span class="hs-identifier hs-type">decoderPosDataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#Int64"><span class="hs-identifier hs-type">Int64</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679808412"><span class="hs-identifier hs-type">dataType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-701"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#BroadcastShapesF"><span class="hs-identifier hs-type">BroadcastShapesF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808402"><span class="hs-identifier hs-type">decoderInputShape</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Functional.Sparse.html#EmbeddingF"><span class="hs-identifier hs-type">EmbeddingF</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679808401"><span class="hs-identifier hs-type">posEncDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679808411"><span class="hs-identifier hs-type">decoderInputEmbedDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679808400"><span class="hs-identifier hs-type">decoderPosShape</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-702"></span><span>      </span><span class="hs-special">)</span><span>
</span><span id="line-703"></span><span>      </span><span class="annot"><a href="#local-6989586621679808399"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-704"></span><span>      </span><span class="annot"><a href="#local-6989586621679808398"><span class="hs-identifier hs-type">layerNormOutput</span></a></span><span>
</span><span id="line-705"></span><span>      </span><span class="annot"><a href="#local-6989586621679808399"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-706"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-707"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TDDropoutF"><span class="hs-identifier hs-type">TDDropoutF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-708"></span><span>      </span><span class="annot"><a href="#local-6989586621679808398"><span class="hs-identifier hs-type">layerNormOutput</span></a></span><span>
</span><span id="line-709"></span><span>      </span><span class="annot"><a href="#local-6989586621679808399"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-710"></span><span>      </span><span class="annot"><a href="#local-6989586621679808397"><span class="hs-identifier hs-type">dropoutOutput</span></a></span><span>
</span><span id="line-711"></span><span>      </span><span class="annot"><a href="#local-6989586621679808396"><span class="hs-identifier hs-type">dropoutGeneratorOutputDevice</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-712"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-713"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TDStackF"><span class="hs-identifier hs-type">TDStackF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808395"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808414"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808413"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808412"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808394"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808393"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808392"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808411"><span class="hs-identifier hs-type">decoderInputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808391"><span class="hs-identifier hs-type">encoderOutputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808390"><span class="hs-identifier hs-type">ffnDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-714"></span><span>      </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="#local-6989586621679808397"><span class="hs-identifier hs-type">dropoutOutput</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-715"></span><span>        </span><span class="annot"><a href="#local-6989586621679808389"><span class="hs-identifier hs-type">encoderOutput</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-716"></span><span>        </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-717"></span><span>          </span><span class="annot"><a href="#local-6989586621679808388"><span class="hs-identifier hs-type">decoderAttentionMaskGradient</span></a></span><span>
</span><span id="line-718"></span><span>          </span><span class="annot"><a href="#local-6989586621679808387"><span class="hs-identifier hs-type">decoderAttentionMaskLayout</span></a></span><span>
</span><span id="line-719"></span><span>          </span><span class="annot"><a href="#local-6989586621679808386"><span class="hs-identifier hs-type">decoderAttentionMaskDevice</span></a></span><span>
</span><span id="line-720"></span><span>          </span><span class="annot"><a href="#local-6989586621679808385"><span class="hs-identifier hs-type">decoderAttentionMaskDataType</span></a></span><span>
</span><span id="line-721"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#UnsqueezeF"><span class="hs-identifier hs-type">UnsqueezeF</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679808384"><span class="hs-identifier hs-type">decoderAttentionMaskShape</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-722"></span><span>        </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-723"></span><span>          </span><span class="annot"><a href="#local-6989586621679808383"><span class="hs-identifier hs-type">crossAttentionMaskGradient</span></a></span><span>
</span><span id="line-724"></span><span>          </span><span class="annot"><a href="#local-6989586621679808382"><span class="hs-identifier hs-type">crossAttentionMaskLayout</span></a></span><span>
</span><span id="line-725"></span><span>          </span><span class="annot"><a href="#local-6989586621679808381"><span class="hs-identifier hs-type">crossAttentionMaskDevice</span></a></span><span>
</span><span id="line-726"></span><span>          </span><span class="annot"><a href="#local-6989586621679808380"><span class="hs-identifier hs-type">crossAttentionMaskDataType</span></a></span><span>
</span><span id="line-727"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#UnsqueezeF"><span class="hs-identifier hs-type">UnsqueezeF</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679808379"><span class="hs-identifier hs-type">crossAttentionMaskShape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-728"></span><span>      </span><span class="hs-special">)</span><span>
</span><span id="line-729"></span><span>      </span><span class="annot"><a href="#local-6989586621679808396"><span class="hs-identifier hs-type">dropoutGeneratorOutputDevice</span></a></span><span>
</span><span id="line-730"></span><span>      </span><span class="annot"><a href="#local-6989586621679808378"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-731"></span><span>      </span><span class="annot"><a href="#local-6989586621679808377"><span class="hs-identifier hs-type">generatorOutputDevice</span></a></span><span>
</span><span id="line-732"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-733"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-734"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TransformerDecoder"><span class="hs-identifier hs-type">TransformerDecoder</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808395"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808414"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808413"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808412"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808394"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808393"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808392"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808411"><span class="hs-identifier hs-type">decoderInputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808391"><span class="hs-identifier hs-type">encoderOutputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808390"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808401"><span class="hs-identifier hs-type">posEncDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-735"></span><span>    </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808410"><span class="hs-identifier hs-type">decoderInputGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808408"><span class="hs-identifier hs-type">decoderInputLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808406"><span class="hs-identifier hs-type">decoderInputDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808404"><span class="hs-identifier hs-type">decoderInputDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808402"><span class="hs-identifier hs-type">decoderInputShape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-736"></span><span>      </span><span class="annot"><a href="#local-6989586621679808389"><span class="hs-identifier hs-type">encoderOutput</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-737"></span><span>      </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808409"><span class="hs-identifier hs-type">decoderPosGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808407"><span class="hs-identifier hs-type">decoderPosLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808405"><span class="hs-identifier hs-type">decoderPosDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808403"><span class="hs-identifier hs-type">decoderPosDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808400"><span class="hs-identifier hs-type">decoderPosShape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-738"></span><span>      </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808388"><span class="hs-identifier hs-type">decoderAttentionMaskGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808387"><span class="hs-identifier hs-type">decoderAttentionMaskLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808386"><span class="hs-identifier hs-type">decoderAttentionMaskDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808385"><span class="hs-identifier hs-type">decoderAttentionMaskDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808384"><span class="hs-identifier hs-type">decoderAttentionMaskShape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-739"></span><span>      </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808383"><span class="hs-identifier hs-type">crossAttentionMaskGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808382"><span class="hs-identifier hs-type">crossAttentionMaskLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808381"><span class="hs-identifier hs-type">crossAttentionMaskDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808380"><span class="hs-identifier hs-type">crossAttentionMaskDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808379"><span class="hs-identifier hs-type">crossAttentionMaskShape</span></a></span><span>
</span><span id="line-740"></span><span>    </span><span class="hs-special">)</span><span>
</span><span id="line-741"></span><span>    </span><span class="annot"><a href="#local-6989586621679808399"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-742"></span><span>    </span><span class="annot"><a href="#local-6989586621679808378"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-743"></span><span>    </span><span class="annot"><a href="#local-6989586621679808377"><span class="hs-identifier hs-type">generatorOutputDevice</span></a></span><span>
</span><span id="line-744"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-745"></span><span>  </span><span id="local-6989586621679808375"><span class="annot"><span class="annottext">forward :: TransformerDecoder
  'BART
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  decoderInputEmbedDim
  encoderOutputEmbedDim
  ffnDim
  posEncDim
-&gt; (Tensor
      decoderInputGradient
      decoderInputLayout
      decoderInputDevice
      decoderInputDataType
      decoderInputShape,
    encoderOutput,
    Tensor
      decoderPosGradient
      decoderPosLayout
      decoderPosDevice
      decoderPosDataType
      decoderPosShape,
    Tensor
      decoderAttentionMaskGradient
      decoderAttentionMaskLayout
      decoderAttentionMaskDevice
      decoderAttentionMaskDataType
      decoderAttentionMaskShape,
    Tensor
      crossAttentionMaskGradient
      crossAttentionMaskLayout
      crossAttentionMaskDevice
      crossAttentionMaskDataType
      crossAttentionMaskShape)
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="#local-6989586621679808375"><span class="hs-identifier hs-var hs-var hs-var hs-var">forward</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TransformerDecoder"><span class="hs-identifier hs-type">TransformerDecoder</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#GTransformerDecoder"><span class="hs-identifier hs-type">GTransformerDecoder</span></a></span><span> </span><span class="hs-special">{</span><span id="local-6989586621679808370"><span id="local-6989586621679808371"><span id="local-6989586621679808372"><span id="local-6989586621679808373"><span id="local-6989586621679808374"><span class="annot"><span class="annottext">TDPosEncF
  'BART
  gradient
  device
  dataType
  headDim
  decoderInputEmbedDim
  posEncDim
TDDropoutF 'BART
TDLayerNormF 'BART gradient device dataType decoderInputEmbedDim
TDEmbedLayerNormF
  'BART gradient device dataType decoderInputEmbedDim
TDStackF
  'BART
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  decoderInputEmbedDim
  encoderOutputEmbedDim
  ffnDim
tdPosEnc :: TDPosEncF
  'BART
  gradient
  device
  dataType
  headDim
  decoderInputEmbedDim
  posEncDim
tdDropout :: TDDropoutF 'BART
tdLayerNorm :: TDLayerNormF 'BART gradient device dataType decoderInputEmbedDim
tdEmbedLayerNorm :: TDEmbedLayerNormF
  'BART gradient device dataType decoderInputEmbedDim
tdStack :: TDStackF
  'BART
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  decoderInputEmbedDim
  encoderOutputEmbedDim
  ffnDim
tdPosEnc :: forall stack embedLayerNorm layerNorm dropout posEnc.
GTransformerDecoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; posEnc
tdDropout :: forall stack embedLayerNorm layerNorm dropout posEnc.
GTransformerDecoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; dropout
tdLayerNorm :: forall stack embedLayerNorm layerNorm dropout posEnc.
GTransformerDecoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; layerNorm
tdEmbedLayerNorm :: forall stack embedLayerNorm layerNorm dropout posEnc.
GTransformerDecoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; embedLayerNorm
tdStack :: forall stack embedLayerNorm layerNorm dropout posEnc.
GTransformerDecoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; stack
</span><a href="#local-6989586621679808370"><span class="hs-glyph hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">..</span></a></span></span></span></span></span></span><span class="hs-special">}</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679808369"><span class="annot"><span class="annottext">Tensor
  decoderInputGradient
  decoderInputLayout
  decoderInputDevice
  decoderInputDataType
  decoderInputShape
</span><a href="#local-6989586621679808369"><span class="hs-identifier hs-var">decoderInput</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679808368"><span class="annot"><span class="annottext">encoderOutput
</span><a href="#local-6989586621679808368"><span class="hs-identifier hs-var">encoderOutput</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679808367"><span class="annot"><span class="annottext">Tensor
  decoderPosGradient
  decoderPosLayout
  decoderPosDevice
  decoderPosDataType
  decoderPosShape
</span><a href="#local-6989586621679808367"><span class="hs-identifier hs-var">decoderPos</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679808366"><span class="annot"><span class="annottext">Tensor
  decoderAttentionMaskGradient
  decoderAttentionMaskLayout
  decoderAttentionMaskDevice
  decoderAttentionMaskDataType
  decoderAttentionMaskShape
</span><a href="#local-6989586621679808366"><span class="hs-identifier hs-var">decoderAttentionMask</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679808365"><span class="annot"><span class="annottext">Tensor
  crossAttentionMaskGradient
  crossAttentionMaskLayout
  crossAttentionMaskDevice
  crossAttentionMaskDataType
  crossAttentionMaskShape
</span><a href="#local-6989586621679808365"><span class="hs-identifier hs-var">crossAttentionMask</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-746"></span><span>    </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679808364"><span class="annot"><span class="annottext">decoderAttentionBias :: Tensor
  decoderAttentionMaskGradient
  decoderAttentionMaskLayout
  decoderAttentionMaskDevice
  decoderAttentionMaskDataType
  (UnsqueezeF ('SelectDim ('ByIndex 1)) decoderAttentionMaskShape)
</span><a href="#local-6989586621679808364"><span class="hs-identifier hs-var hs-var">decoderAttentionBias</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor
  decoderAttentionMaskGradient
  decoderAttentionMaskLayout
  decoderAttentionMaskDevice
  decoderAttentionMaskDataType
  decoderAttentionMaskShape
-&gt; Tensor
     decoderAttentionMaskGradient
     decoderAttentionMaskLayout
     decoderAttentionMaskDevice
     decoderAttentionMaskDataType
     (UnsqueezeF ('SelectDim ('ByIndex 1)) decoderAttentionMaskShape)
forall (selectDim :: SelectDim (By Symbol Nat))
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]).
(shape' ~ UnsqueezeF selectDim shape, SingI selectDim) =&gt;
Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape'
</span><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#unsqueeze"><span class="hs-identifier hs-var">unsqueeze</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
  decoderAttentionMaskGradient
  decoderAttentionMaskLayout
  decoderAttentionMaskDevice
  decoderAttentionMaskDataType
  decoderAttentionMaskShape
</span><a href="#local-6989586621679808366"><span class="hs-identifier hs-var">decoderAttentionMask</span></a></span><span>
</span><span id="line-747"></span><span>        </span><span id="local-6989586621679808363"><span class="annot"><span class="annottext">crossAttentionBias :: Tensor
  crossAttentionMaskGradient
  crossAttentionMaskLayout
  crossAttentionMaskDevice
  crossAttentionMaskDataType
  (UnsqueezeF ('SelectDim ('ByIndex 1)) crossAttentionMaskShape)
</span><a href="#local-6989586621679808363"><span class="hs-identifier hs-var hs-var">crossAttentionBias</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor
  crossAttentionMaskGradient
  crossAttentionMaskLayout
  crossAttentionMaskDevice
  crossAttentionMaskDataType
  crossAttentionMaskShape
-&gt; Tensor
     crossAttentionMaskGradient
     crossAttentionMaskLayout
     crossAttentionMaskDevice
     crossAttentionMaskDataType
     (UnsqueezeF ('SelectDim ('ByIndex 1)) crossAttentionMaskShape)
forall (selectDim :: SelectDim (By Symbol Nat))
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]).
(shape' ~ UnsqueezeF selectDim shape, SingI selectDim) =&gt;
Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape'
</span><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#unsqueeze"><span class="hs-identifier hs-var">unsqueeze</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
  crossAttentionMaskGradient
  crossAttentionMaskLayout
  crossAttentionMaskDevice
  crossAttentionMaskDataType
  crossAttentionMaskShape
</span><a href="#local-6989586621679808365"><span class="hs-identifier hs-var">crossAttentionMask</span></a></span><span>
</span><span id="line-748"></span><span>     </span><span class="hs-keyword">in</span><span> </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorOutputDevice)
  output
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
forall (m :: * -&gt; *) i j a. IxStateT m i j a -&gt; i -&gt; m (a, j)
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var hs-var">runIxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">(IxStateT
   m
   (Generator generatorDevice)
   (Generator generatorOutputDevice)
   output
 -&gt; Generator generatorDevice
 -&gt; m (output, Generator generatorOutputDevice))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorOutputDevice)
     output
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-749"></span><span>          </span><span class="annot"><span class="annottext">Tensor
  decoderPosGradient
  decoderPosLayout
  decoderPosDevice
  decoderPosDataType
  decoderPosShape
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     (Tensor
        decoderPosGradient
        decoderPosLayout
        decoderPosDevice
        decoderPosDataType
        decoderPosShape)
forall k (m :: k -&gt; k -&gt; * -&gt; *) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  decoderPosGradient
  decoderPosLayout
  decoderPosDevice
  decoderPosDataType
  decoderPosShape
</span><a href="#local-6989586621679808367"><span class="hs-identifier hs-var">decoderPos</span></a></span><span>
</span><span id="line-750"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorDevice)
  (Tensor
     decoderPosGradient
     decoderPosLayout
     decoderPosDevice
     decoderPosDataType
     decoderPosShape)
-&gt; (Tensor
      decoderPosGradient
      decoderPosLayout
      decoderPosDevice
      decoderPosDataType
      decoderPosShape
    -&gt; IxStateT
         m
         (Generator generatorDevice)
         (Generator generatorDevice)
         (Tensor
            (Or (Gradient RequiresGradient) gradient decoderPosGradient)
            (Unify (Layout LayoutType) ('Layout 'Dense) decoderPosLayout)
            (Unify (Device (DeviceType Nat)) device decoderPosDevice)
            (Seq
               (Unify (DataType DType) decoderPosDataType ('DataType 'Int64))
               dataType)
            (EmbeddingF
               ('Shape '[posEncDim, decoderInputEmbedDim]) decoderPosShape)))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     (Tensor
        (Or (Gradient RequiresGradient) gradient decoderPosGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) decoderPosLayout)
        (Unify (Device (DeviceType Nat)) device decoderPosDevice)
        (Seq
           (Unify (DataType DType) decoderPosDataType ('DataType 'Int64))
           dataType)
        (EmbeddingF
           ('Shape '[posEncDim, decoderInputEmbedDim]) decoderPosShape))
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(Generator generatorDevice
 -&gt; m (Tensor
         (Or (Gradient RequiresGradient) gradient decoderPosGradient)
         (Unify (Layout LayoutType) ('Layout 'Dense) decoderPosLayout)
         (Unify (Device (DeviceType Nat)) device decoderPosDevice)
         (Seq
            (Unify (DataType DType) decoderPosDataType ('DataType 'Int64))
            dataType)
         (EmbeddingF
            ('Shape '[posEncDim, decoderInputEmbedDim]) decoderPosShape),
       Generator generatorDevice))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     (Tensor
        (Or (Gradient RequiresGradient) gradient decoderPosGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) decoderPosLayout)
        (Unify (Device (DeviceType Nat)) device decoderPosDevice)
        (Seq
           (Unify (DataType DType) decoderPosDataType ('DataType 'Int64))
           dataType)
        (EmbeddingF
           ('Shape '[posEncDim, decoderInputEmbedDim]) decoderPosShape))
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator generatorDevice
  -&gt; m (Tensor
          (Or (Gradient RequiresGradient) gradient decoderPosGradient)
          (Unify (Layout LayoutType) ('Layout 'Dense) decoderPosLayout)
          (Unify (Device (DeviceType Nat)) device decoderPosDevice)
          (Seq
             (Unify (DataType DType) decoderPosDataType ('DataType 'Int64))
             dataType)
          (EmbeddingF
             ('Shape '[posEncDim, decoderInputEmbedDim]) decoderPosShape),
        Generator generatorDevice))
 -&gt; IxStateT
      m
      (Generator generatorDevice)
      (Generator generatorDevice)
      (Tensor
         (Or (Gradient RequiresGradient) gradient decoderPosGradient)
         (Unify (Layout LayoutType) ('Layout 'Dense) decoderPosLayout)
         (Unify (Device (DeviceType Nat)) device decoderPosDevice)
         (Seq
            (Unify (DataType DType) decoderPosDataType ('DataType 'Int64))
            dataType)
         (EmbeddingF
            ('Shape '[posEncDim, decoderInputEmbedDim]) decoderPosShape)))
-&gt; (Tensor
      decoderPosGradient
      decoderPosLayout
      decoderPosDevice
      decoderPosDataType
      decoderPosShape
    -&gt; Generator generatorDevice
    -&gt; m (Tensor
            (Or (Gradient RequiresGradient) gradient decoderPosGradient)
            (Unify (Layout LayoutType) ('Layout 'Dense) decoderPosLayout)
            (Unify (Device (DeviceType Nat)) device decoderPosDevice)
            (Seq
               (Unify (DataType DType) decoderPosDataType ('DataType 'Int64))
               dataType)
            (EmbeddingF
               ('Shape '[posEncDim, decoderInputEmbedDim]) decoderPosShape),
          Generator generatorDevice))
-&gt; Tensor
     decoderPosGradient
     decoderPosLayout
     decoderPosDevice
     decoderPosDataType
     decoderPosShape
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     (Tensor
        (Or (Gradient RequiresGradient) gradient decoderPosGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) decoderPosLayout)
        (Unify (Device (DeviceType Nat)) device decoderPosDevice)
        (Seq
           (Unify (DataType DType) decoderPosDataType ('DataType 'Int64))
           dataType)
        (EmbeddingF
           ('Shape '[posEncDim, decoderInputEmbedDim]) decoderPosShape))
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Embedding
  gradient
  ('Layout 'Dense)
  device
  dataType
  posEncDim
  decoderInputEmbedDim
  'Nothing
-&gt; Tensor
     decoderPosGradient
     decoderPosLayout
     decoderPosDevice
     decoderPosDataType
     decoderPosShape
-&gt; Generator generatorDevice
-&gt; m (Tensor
        (Or (Gradient RequiresGradient) gradient decoderPosGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) decoderPosLayout)
        (Unify (Device (DeviceType Nat)) device decoderPosDevice)
        (Seq
           (Unify (DataType DType) decoderPosDataType ('DataType 'Int64))
           dataType)
        (EmbeddingF
           ('Shape '[posEncDim, decoderInputEmbedDim]) decoderPosShape),
      Generator generatorDevice)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: * -&gt; *).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">Embedding
  gradient
  ('Layout 'Dense)
  device
  dataType
  posEncDim
  decoderInputEmbedDim
  'Nothing
TDPosEncF
  'BART
  gradient
  device
  dataType
  headDim
  decoderInputEmbedDim
  posEncDim
</span><a href="#local-6989586621679808370"><span class="hs-identifier hs-var">tdPosEnc</span></a></span><span>
</span><span id="line-751"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorDevice)
  (Tensor
     (Or (Gradient RequiresGradient) gradient decoderPosGradient)
     (Unify (Layout LayoutType) ('Layout 'Dense) decoderPosLayout)
     (Unify (Device (DeviceType Nat)) device decoderPosDevice)
     (Seq
        (Unify (DataType DType) decoderPosDataType ('DataType 'Int64))
        dataType)
     (EmbeddingF
        ('Shape '[posEncDim, decoderInputEmbedDim]) decoderPosShape))
-&gt; (Tensor
      (Or (Gradient RequiresGradient) gradient decoderPosGradient)
      (Unify (Layout LayoutType) ('Layout 'Dense) decoderPosLayout)
      (Unify (Device (DeviceType Nat)) device decoderPosDevice)
      (Seq
         (Unify (DataType DType) decoderPosDataType ('DataType 'Int64))
         dataType)
      (EmbeddingF
         ('Shape '[posEncDim, decoderInputEmbedDim]) decoderPosShape)
    -&gt; IxStateT
         m
         (Generator generatorDevice)
         (Generator generatorDevice)
         (Tensor
            (Or
               (Gradient RequiresGradient)
               decoderInputGradient
               (Or (Gradient RequiresGradient) gradient decoderPosGradient))
            (Unify
               (Layout LayoutType)
               decoderInputLayout
               (Unify (Layout LayoutType) ('Layout 'Dense) decoderPosLayout))
            (Unify
               (Device (DeviceType Nat))
               decoderInputDevice
               (Unify (Device (DeviceType Nat)) device decoderPosDevice))
            (Unify
               (DataType DType)
               decoderInputDataType
               (Seq
                  (Unify (DataType DType) decoderPosDataType ('DataType 'Int64))
                  dataType))
            (BroadcastShapesF
               decoderInputShape
               (EmbeddingF
                  ('Shape '[posEncDim, decoderInputEmbedDim]) decoderPosShape))))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     (Tensor
        (Or
           (Gradient RequiresGradient)
           decoderInputGradient
           (Or (Gradient RequiresGradient) gradient decoderPosGradient))
        (Unify
           (Layout LayoutType)
           decoderInputLayout
           (Unify (Layout LayoutType) ('Layout 'Dense) decoderPosLayout))
        (Unify
           (Device (DeviceType Nat))
           decoderInputDevice
           (Unify (Device (DeviceType Nat)) device decoderPosDevice))
        (Unify
           (DataType DType)
           decoderInputDataType
           (Seq
              (Unify (DataType DType) decoderPosDataType ('DataType 'Int64))
              dataType))
        (BroadcastShapesF
           decoderInputShape
           (EmbeddingF
              ('Shape '[posEncDim, decoderInputEmbedDim]) decoderPosShape)))
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  (Or
     (Gradient RequiresGradient)
     decoderInputGradient
     (Or (Gradient RequiresGradient) gradient decoderPosGradient))
  (Unify
     (Layout LayoutType)
     decoderInputLayout
     (Unify (Layout LayoutType) ('Layout 'Dense) decoderPosLayout))
  (Unify
     (Device (DeviceType Nat))
     decoderInputDevice
     (Unify (Device (DeviceType Nat)) device decoderPosDevice))
  (Unify
     (DataType DType)
     decoderInputDataType
     (Seq
        (Unify (DataType DType) decoderPosDataType ('DataType 'Int64))
        dataType))
  (BroadcastShapesF
     decoderInputShape
     (EmbeddingF
        ('Shape '[posEncDim, decoderInputEmbedDim]) decoderPosShape))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     (Tensor
        (Or
           (Gradient RequiresGradient)
           decoderInputGradient
           (Or (Gradient RequiresGradient) gradient decoderPosGradient))
        (Unify
           (Layout LayoutType)
           decoderInputLayout
           (Unify (Layout LayoutType) ('Layout 'Dense) decoderPosLayout))
        (Unify
           (Device (DeviceType Nat))
           decoderInputDevice
           (Unify (Device (DeviceType Nat)) device decoderPosDevice))
        (Unify
           (DataType DType)
           decoderInputDataType
           (Seq
              (Unify (DataType DType) decoderPosDataType ('DataType 'Int64))
              dataType))
        (BroadcastShapesF
           decoderInputShape
           (EmbeddingF
              ('Shape '[posEncDim, decoderInputEmbedDim]) decoderPosShape)))
forall k (m :: k -&gt; k -&gt; * -&gt; *) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">(Tensor
   (Or
      (Gradient RequiresGradient)
      decoderInputGradient
      (Or (Gradient RequiresGradient) gradient decoderPosGradient))
   (Unify
      (Layout LayoutType)
      decoderInputLayout
      (Unify (Layout LayoutType) ('Layout 'Dense) decoderPosLayout))
   (Unify
      (Device (DeviceType Nat))
      decoderInputDevice
      (Unify (Device (DeviceType Nat)) device decoderPosDevice))
   (Unify
      (DataType DType)
      decoderInputDataType
      (Seq
         (Unify (DataType DType) decoderPosDataType ('DataType 'Int64))
         dataType))
   (BroadcastShapesF
      decoderInputShape
      (EmbeddingF
         ('Shape '[posEncDim, decoderInputEmbedDim]) decoderPosShape))
 -&gt; IxStateT
      m
      (Generator generatorDevice)
      (Generator generatorDevice)
      (Tensor
         (Or
            (Gradient RequiresGradient)
            decoderInputGradient
            (Or (Gradient RequiresGradient) gradient decoderPosGradient))
         (Unify
            (Layout LayoutType)
            decoderInputLayout
            (Unify (Layout LayoutType) ('Layout 'Dense) decoderPosLayout))
         (Unify
            (Device (DeviceType Nat))
            decoderInputDevice
            (Unify (Device (DeviceType Nat)) device decoderPosDevice))
         (Unify
            (DataType DType)
            decoderInputDataType
            (Seq
               (Unify (DataType DType) decoderPosDataType ('DataType 'Int64))
               dataType))
         (BroadcastShapesF
            decoderInputShape
            (EmbeddingF
               ('Shape '[posEncDim, decoderInputEmbedDim]) decoderPosShape))))
-&gt; (Tensor
      (Or (Gradient RequiresGradient) gradient decoderPosGradient)
      (Unify (Layout LayoutType) ('Layout 'Dense) decoderPosLayout)
      (Unify (Device (DeviceType Nat)) device decoderPosDevice)
      (Seq
         (Unify (DataType DType) decoderPosDataType ('DataType 'Int64))
         dataType)
      (EmbeddingF
         ('Shape '[posEncDim, decoderInputEmbedDim]) decoderPosShape)
    -&gt; Tensor
         (Or
            (Gradient RequiresGradient)
            decoderInputGradient
            (Or (Gradient RequiresGradient) gradient decoderPosGradient))
         (Unify
            (Layout LayoutType)
            decoderInputLayout
            (Unify (Layout LayoutType) ('Layout 'Dense) decoderPosLayout))
         (Unify
            (Device (DeviceType Nat))
            decoderInputDevice
            (Unify (Device (DeviceType Nat)) device decoderPosDevice))
         (Unify
            (DataType DType)
            decoderInputDataType
            (Seq
               (Unify (DataType DType) decoderPosDataType ('DataType 'Int64))
               dataType))
         (BroadcastShapesF
            decoderInputShape
            (EmbeddingF
               ('Shape '[posEncDim, decoderInputEmbedDim]) decoderPosShape)))
-&gt; Tensor
     (Or (Gradient RequiresGradient) gradient decoderPosGradient)
     (Unify (Layout LayoutType) ('Layout 'Dense) decoderPosLayout)
     (Unify (Device (DeviceType Nat)) device decoderPosDevice)
     (Seq
        (Unify (DataType DType) decoderPosDataType ('DataType 'Int64))
        dataType)
     (EmbeddingF
        ('Shape '[posEncDim, decoderInputEmbedDim]) decoderPosShape)
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     (Tensor
        (Or
           (Gradient RequiresGradient)
           decoderInputGradient
           (Or (Gradient RequiresGradient) gradient decoderPosGradient))
        (Unify
           (Layout LayoutType)
           decoderInputLayout
           (Unify (Layout LayoutType) ('Layout 'Dense) decoderPosLayout))
        (Unify
           (Device (DeviceType Nat))
           decoderInputDevice
           (Unify (Device (DeviceType Nat)) device decoderPosDevice))
        (Unify
           (DataType DType)
           decoderInputDataType
           (Seq
              (Unify (DataType DType) decoderPosDataType ('DataType 'Int64))
              dataType))
        (BroadcastShapesF
           decoderInputShape
           (EmbeddingF
              ('Shape '[posEncDim, decoderInputEmbedDim]) decoderPosShape)))
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Tensor
  decoderInputGradient
  decoderInputLayout
  decoderInputDevice
  decoderInputDataType
  decoderInputShape
</span><a href="#local-6989586621679808369"><span class="hs-identifier hs-var">decoderInput</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  decoderInputGradient
  decoderInputLayout
  decoderInputDevice
  decoderInputDataType
  decoderInputShape
-&gt; Tensor
     (Or (Gradient RequiresGradient) gradient decoderPosGradient)
     (Unify (Layout LayoutType) ('Layout 'Dense) decoderPosLayout)
     (Unify (Device (DeviceType Nat)) device decoderPosDevice)
     (Seq
        (Unify (DataType DType) decoderPosDataType ('DataType 'Int64))
        dataType)
     (EmbeddingF
        ('Shape '[posEncDim, decoderInputEmbedDim]) decoderPosShape)
-&gt; Tensor
     (decoderInputGradient
      &lt;|&gt; Or (Gradient RequiresGradient) gradient decoderPosGradient)
     (decoderInputLayout
      &lt;+&gt; Unify (Layout LayoutType) ('Layout 'Dense) decoderPosLayout)
     (decoderInputDevice
      &lt;+&gt; Unify (Device (DeviceType Nat)) device decoderPosDevice)
     (decoderInputDataType
      &lt;+&gt; Seq
            (Unify (DataType DType) decoderPosDataType ('DataType 'Int64))
            dataType)
     (BroadcastShapesF
        decoderInputShape
        (EmbeddingF
           ('Shape '[posEncDim, decoderInputEmbedDim]) decoderPosShape))
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (gradient' :: Gradient RequiresGradient)
       (layout' :: Layout LayoutType) (device' :: Device (DeviceType Nat))
       (dataType' :: DataType DType)
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]).
Tensor gradient layout device dataType shape
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; Tensor
     (gradient &lt;|&gt; gradient')
     (layout &lt;+&gt; layout')
     (device &lt;+&gt; device')
     (dataType &lt;+&gt; dataType')
     (BroadcastShapesF shape shape')
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#add"><span class="hs-operator hs-var">`add`</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-752"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorDevice)
  (Tensor
     (Or
        (Gradient RequiresGradient)
        decoderInputGradient
        (Or (Gradient RequiresGradient) gradient decoderPosGradient))
     (Unify
        (Layout LayoutType)
        decoderInputLayout
        (Unify (Layout LayoutType) ('Layout 'Dense) decoderPosLayout))
     (Unify
        (Device (DeviceType Nat))
        decoderInputDevice
        (Unify (Device (DeviceType Nat)) device decoderPosDevice))
     (Unify
        (DataType DType)
        decoderInputDataType
        (Seq
           (Unify (DataType DType) decoderPosDataType ('DataType 'Int64))
           dataType))
     (BroadcastShapesF
        decoderInputShape
        (EmbeddingF
           ('Shape '[posEncDim, decoderInputEmbedDim]) decoderPosShape)))
-&gt; (Tensor
      (Or
         (Gradient RequiresGradient)
         decoderInputGradient
         (Or (Gradient RequiresGradient) gradient decoderPosGradient))
      (Unify
         (Layout LayoutType)
         decoderInputLayout
         (Unify (Layout LayoutType) ('Layout 'Dense) decoderPosLayout))
      (Unify
         (Device (DeviceType Nat))
         decoderInputDevice
         (Unify (Device (DeviceType Nat)) device decoderPosDevice))
      (Unify
         (DataType DType)
         decoderInputDataType
         (Seq
            (Unify (DataType DType) decoderPosDataType ('DataType 'Int64))
            dataType))
      (BroadcastShapesF
         decoderInputShape
         (EmbeddingF
            ('Shape '[posEncDim, decoderInputEmbedDim]) decoderPosShape))
    -&gt; IxStateT
         m
         (Generator generatorDevice)
         (Generator generatorDevice)
         layerNormOutput)
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     layerNormOutput
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(Generator generatorDevice
 -&gt; m (layerNormOutput, Generator generatorDevice))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     layerNormOutput
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator generatorDevice
  -&gt; m (layerNormOutput, Generator generatorDevice))
 -&gt; IxStateT
      m
      (Generator generatorDevice)
      (Generator generatorDevice)
      layerNormOutput)
-&gt; (Tensor
      (Or
         (Gradient RequiresGradient)
         decoderInputGradient
         (Or (Gradient RequiresGradient) gradient decoderPosGradient))
      (Unify
         (Layout LayoutType)
         decoderInputLayout
         (Unify (Layout LayoutType) ('Layout 'Dense) decoderPosLayout))
      (Unify
         (Device (DeviceType Nat))
         decoderInputDevice
         (Unify (Device (DeviceType Nat)) device decoderPosDevice))
      (Unify
         (DataType DType)
         decoderInputDataType
         (Seq
            (Unify (DataType DType) decoderPosDataType ('DataType 'Int64))
            dataType))
      (BroadcastShapesF
         decoderInputShape
         (EmbeddingF
            ('Shape '[posEncDim, decoderInputEmbedDim]) decoderPosShape))
    -&gt; Generator generatorDevice
    -&gt; m (layerNormOutput, Generator generatorDevice))
-&gt; Tensor
     (Or
        (Gradient RequiresGradient)
        decoderInputGradient
        (Or (Gradient RequiresGradient) gradient decoderPosGradient))
     (Unify
        (Layout LayoutType)
        decoderInputLayout
        (Unify (Layout LayoutType) ('Layout 'Dense) decoderPosLayout))
     (Unify
        (Device (DeviceType Nat))
        decoderInputDevice
        (Unify (Device (DeviceType Nat)) device decoderPosDevice))
     (Unify
        (DataType DType)
        decoderInputDataType
        (Seq
           (Unify (DataType DType) decoderPosDataType ('DataType 'Int64))
           dataType))
     (BroadcastShapesF
        decoderInputShape
        (EmbeddingF
           ('Shape '[posEncDim, decoderInputEmbedDim]) decoderPosShape))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     layerNormOutput
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">LayerNorm
  'WithBias gradient device dataType ('Shape '[decoderInputEmbedDim])
-&gt; Tensor
     (Or
        (Gradient RequiresGradient)
        decoderInputGradient
        (Or (Gradient RequiresGradient) gradient decoderPosGradient))
     (Unify
        (Layout LayoutType)
        decoderInputLayout
        (Unify (Layout LayoutType) ('Layout 'Dense) decoderPosLayout))
     (Unify
        (Device (DeviceType Nat))
        decoderInputDevice
        (Unify (Device (DeviceType Nat)) device decoderPosDevice))
     (Unify
        (DataType DType)
        decoderInputDataType
        (Seq
           (Unify (DataType DType) decoderPosDataType ('DataType 'Int64))
           dataType))
     (BroadcastShapesF
        decoderInputShape
        (EmbeddingF
           ('Shape '[posEncDim, decoderInputEmbedDim]) decoderPosShape))
-&gt; Generator generatorDevice
-&gt; m (layerNormOutput, Generator generatorDevice)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: * -&gt; *).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">LayerNorm
  'WithBias gradient device dataType ('Shape '[decoderInputEmbedDim])
TDEmbedLayerNormF
  'BART gradient device dataType decoderInputEmbedDim
</span><a href="#local-6989586621679808373"><span class="hs-identifier hs-var">tdEmbedLayerNorm</span></a></span><span>
</span><span id="line-753"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorDevice)
  layerNormOutput
-&gt; (layerNormOutput
    -&gt; IxStateT
         m
         (Generator generatorDevice)
         (Generator dropoutGeneratorOutputDevice)
         dropoutOutput)
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator dropoutGeneratorOutputDevice)
     dropoutOutput
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(Generator generatorDevice
 -&gt; m (dropoutOutput, Generator dropoutGeneratorOutputDevice))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator dropoutGeneratorOutputDevice)
     dropoutOutput
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator generatorDevice
  -&gt; m (dropoutOutput, Generator dropoutGeneratorOutputDevice))
 -&gt; IxStateT
      m
      (Generator generatorDevice)
      (Generator dropoutGeneratorOutputDevice)
      dropoutOutput)
-&gt; (layerNormOutput
    -&gt; Generator generatorDevice
    -&gt; m (dropoutOutput, Generator dropoutGeneratorOutputDevice))
-&gt; layerNormOutput
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator dropoutGeneratorOutputDevice)
     dropoutOutput
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Dropout
-&gt; layerNormOutput
-&gt; Generator generatorDevice
-&gt; m (dropoutOutput, Generator dropoutGeneratorOutputDevice)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: * -&gt; *).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">Dropout
TDDropoutF 'BART
</span><a href="#local-6989586621679808371"><span class="hs-identifier hs-var">tdDropout</span></a></span><span>
</span><span id="line-754"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator dropoutGeneratorOutputDevice)
  dropoutOutput
-&gt; (dropoutOutput
    -&gt; IxStateT
         m
         (Generator dropoutGeneratorOutputDevice)
         (Generator generatorOutputDevice)
         output)
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorOutputDevice)
     output
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="hs-special">(</span><span> </span><span class="hs-glyph">\</span><span id="local-6989586621679808362"><span class="annot"><span class="annottext">dropoutOutput
</span><a href="#local-6989586621679808362"><span class="hs-identifier hs-var">decoderInput'</span></a></span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-755"></span><span>                     </span><span class="annot"><span class="annottext">(Generator dropoutGeneratorOutputDevice
 -&gt; m (output, Generator generatorOutputDevice))
-&gt; IxStateT
     m
     (Generator dropoutGeneratorOutputDevice)
     (Generator generatorOutputDevice)
     output
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator dropoutGeneratorOutputDevice
  -&gt; m (output, Generator generatorOutputDevice))
 -&gt; IxStateT
      m
      (Generator dropoutGeneratorOutputDevice)
      (Generator generatorOutputDevice)
      output)
-&gt; (Generator dropoutGeneratorOutputDevice
    -&gt; m (output, Generator generatorOutputDevice))
-&gt; IxStateT
     m
     (Generator dropoutGeneratorOutputDevice)
     (Generator generatorOutputDevice)
     output
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-756"></span><span>                       </span><span class="annot"><span class="annottext">TransformerDecoderStack
  'BART
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  decoderInputEmbedDim
  encoderOutputEmbedDim
  ffnDim
-&gt; (dropoutOutput, encoderOutput,
    Tensor
      decoderAttentionMaskGradient
      decoderAttentionMaskLayout
      decoderAttentionMaskDevice
      decoderAttentionMaskDataType
      (UnsqueezeF ('SelectDim ('ByIndex 1)) decoderAttentionMaskShape),
    Tensor
      crossAttentionMaskGradient
      crossAttentionMaskLayout
      crossAttentionMaskDevice
      crossAttentionMaskDataType
      (UnsqueezeF ('SelectDim ('ByIndex 1)) crossAttentionMaskShape))
-&gt; Generator dropoutGeneratorOutputDevice
-&gt; m (output, Generator generatorOutputDevice)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: * -&gt; *).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span>
</span><span id="line-757"></span><span>                         </span><span class="annot"><span class="annottext">TransformerDecoderStack
  'BART
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  decoderInputEmbedDim
  encoderOutputEmbedDim
  ffnDim
TDStackF
  'BART
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  decoderInputEmbedDim
  encoderOutputEmbedDim
  ffnDim
</span><a href="#local-6989586621679808374"><span class="hs-identifier hs-var">tdStack</span></a></span><span>
</span><span id="line-758"></span><span>                         </span><span class="hs-special">(</span><span> </span><span class="annot"><span class="annottext">dropoutOutput
</span><a href="#local-6989586621679808362"><span class="hs-identifier hs-var">decoderInput'</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-759"></span><span>                           </span><span class="annot"><span class="annottext">encoderOutput
</span><a href="#local-6989586621679808368"><span class="hs-identifier hs-var">encoderOutput</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-760"></span><span>                           </span><span class="annot"><span class="annottext">Tensor
  decoderAttentionMaskGradient
  decoderAttentionMaskLayout
  decoderAttentionMaskDevice
  decoderAttentionMaskDataType
  (UnsqueezeF ('SelectDim ('ByIndex 1)) decoderAttentionMaskShape)
</span><a href="#local-6989586621679808364"><span class="hs-identifier hs-var">decoderAttentionBias</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-761"></span><span>                           </span><span class="annot"><span class="annottext">Tensor
  crossAttentionMaskGradient
  crossAttentionMaskLayout
  crossAttentionMaskDevice
  crossAttentionMaskDataType
  (UnsqueezeF ('SelectDim ('ByIndex 1)) crossAttentionMaskShape)
</span><a href="#local-6989586621679808363"><span class="hs-identifier hs-var">crossAttentionBias</span></a></span><span>
</span><span id="line-762"></span><span>                         </span><span class="hs-special">)</span><span>
</span><span id="line-763"></span><span>                 </span><span class="hs-special">)</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span>
</span><span id="line-764"></span><span>
</span><span id="line-765"></span><span class="hs-comment">-- | 'HasForward' instance for @TransformerDecoder numLayers 'MBART@.</span><span>
</span><span id="line-766"></span><span class="hs-comment">--</span><span>
</span><span id="line-767"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-768"></span><span class="hs-comment">-- &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;  &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;  &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;  &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;  &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;</span><span>
</span><span id="line-769"></span><span class="hs-comment">-- &#9474; decoderInput &#9474;  &#9474; decoderPos &#9474;  &#9474; encoderOutput &#9474;  &#9474; decoderAttentionMask &#9474;  &#9474; crossAttentionMask &#9474;</span><span>
</span><span id="line-770"></span><span class="hs-comment">-- &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;  &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;  &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;  &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;  &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-771"></span><span class="hs-comment">--        &#9474;                 &#9474;                &#9474;                     &#9474;                         &#9474;</span><span>
</span><span id="line-772"></span><span class="hs-comment">--        &#9474;                 &#9660;                &#9474;                     &#9474;                         &#9474;</span><span>
</span><span id="line-773"></span><span class="hs-comment">--        &#9474;             tdPosEnc             &#9474;                     &#9474;                         &#9474;</span><span>
</span><span id="line-774"></span><span class="hs-comment">--        &#9474;                 &#9474;                &#9474;                     &#9474;                         &#9474;</span><span>
</span><span id="line-775"></span><span class="hs-comment">--        &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9658;add&#9668;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;                &#9474;                     &#9474;                         &#9474;</span><span>
</span><span id="line-776"></span><span class="hs-comment">--                 &#9474;                         &#9474;                     &#9474;                         &#9474;</span><span>
</span><span id="line-777"></span><span class="hs-comment">--                 &#9660;                         &#9474;                     &#9474;                         &#9474;</span><span>
</span><span id="line-778"></span><span class="hs-comment">--          tdEmbedLayerNorm                 &#9474;                     &#9474;                         &#9474;</span><span>
</span><span id="line-779"></span><span class="hs-comment">--                 &#9660;                         &#9474;                     &#9660;                         &#9660;</span><span>
</span><span id="line-780"></span><span class="hs-comment">--             tdDropout                     &#9474;                 unsqueeze                 unsqueeze</span><span>
</span><span id="line-781"></span><span class="hs-comment">--                 &#9660;                         &#9474;                     &#9474;                         &#9474;</span><span>
</span><span id="line-782"></span><span class="hs-comment">--              tdStack&#9668;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;&#9668;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;&#9668;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-783"></span><span class="hs-comment">--                 &#9660;</span><span>
</span><span id="line-784"></span><span class="hs-comment">--            tdLayerNorm</span><span>
</span><span id="line-785"></span><span class="hs-comment">--                 &#9474;</span><span>
</span><span id="line-786"></span><span class="hs-comment">--                 &#9660;</span><span>
</span><span id="line-787"></span><span class="hs-comment">--            &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;</span><span>
</span><span id="line-788"></span><span class="hs-comment">--            &#9474; output &#9474;</span><span>
</span><span id="line-789"></span><span class="hs-comment">--            &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-790"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-791"></span><span>
</span><span id="line-792"></span><span class="hs-comment">-- | 'HasForward' instance for @TransformerDecoder numLayers 'Pegasus@.</span><span>
</span><span id="line-793"></span><span class="hs-comment">--</span><span>
</span><span id="line-794"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-795"></span><span class="hs-comment">-- &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;  &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;  &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;  &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;  &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;</span><span>
</span><span id="line-796"></span><span class="hs-comment">-- &#9474; decoderInput &#9474;  &#9474; decoderPos &#9474;  &#9474; encoderOutput &#9474;  &#9474; decoderAttentionMask &#9474;  &#9474; crossAttentionMask &#9474;</span><span>
</span><span id="line-797"></span><span class="hs-comment">-- &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;  &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;  &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;  &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;  &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-798"></span><span class="hs-comment">--        &#9474;                 &#9474;                &#9474;                     &#9474;                         &#9474;</span><span>
</span><span id="line-799"></span><span class="hs-comment">--        &#9474;                 &#9660;                &#9474;                     &#9474;                         &#9474;</span><span>
</span><span id="line-800"></span><span class="hs-comment">--        &#9474;             tdPosEnc             &#9474;                     &#9474;                         &#9474;</span><span>
</span><span id="line-801"></span><span class="hs-comment">--        &#9474;                 &#9474;                &#9474;                     &#9474;                         &#9474;</span><span>
</span><span id="line-802"></span><span class="hs-comment">--        &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9658;add&#9668;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;                &#9474;                     &#9474;                         &#9474;</span><span>
</span><span id="line-803"></span><span class="hs-comment">--                 &#9474;                         &#9474;                     &#9474;                         &#9474;</span><span>
</span><span id="line-804"></span><span class="hs-comment">--                 &#9660;                         &#9474;                     &#9660;                         &#9660;</span><span>
</span><span id="line-805"></span><span class="hs-comment">--             tdDropout                     &#9474;                 unsqueeze                 unsqueeze</span><span>
</span><span id="line-806"></span><span class="hs-comment">--                 &#9660;                         &#9474;                     &#9474;                         &#9474;</span><span>
</span><span id="line-807"></span><span class="hs-comment">--              tdStack&#9668;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;&#9668;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;&#9668;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-808"></span><span class="hs-comment">--                 &#9660;</span><span>
</span><span id="line-809"></span><span class="hs-comment">--            tdLayerNorm</span><span>
</span><span id="line-810"></span><span class="hs-comment">--                 &#9474;</span><span>
</span><span id="line-811"></span><span class="hs-comment">--                 &#9660;</span><span>
</span><span id="line-812"></span><span class="hs-comment">--            &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;</span><span>
</span><span id="line-813"></span><span class="hs-comment">--            &#9474; output &#9474;</span><span>
</span><span id="line-814"></span><span class="hs-comment">--            &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-815"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-816"></span><span id="local-6989586621679808324"><span id="local-6989586621679808325"><span id="local-6989586621679808326"><span id="local-6989586621679808327"><span id="local-6989586621679808328"><span id="local-6989586621679808329"><span id="local-6989586621679808330"><span id="local-6989586621679808331"><span id="local-6989586621679808332"><span id="local-6989586621679808333"><span id="local-6989586621679808334"><span id="local-6989586621679808335"><span id="local-6989586621679808336"><span id="local-6989586621679808337"><span id="local-6989586621679808338"><span id="local-6989586621679808339"><span id="local-6989586621679808340"><span id="local-6989586621679808341"><span id="local-6989586621679808342"><span id="local-6989586621679808343"><span id="local-6989586621679808344"><span id="local-6989586621679808345"><span id="local-6989586621679808346"><span id="local-6989586621679808347"><span id="local-6989586621679808348"><span id="local-6989586621679808349"><span id="local-6989586621679808350"><span id="local-6989586621679808351"><span id="local-6989586621679808352"><span id="local-6989586621679808353"><span id="local-6989586621679808354"><span id="local-6989586621679808355"><span id="local-6989586621679808356"><span id="local-6989586621679808357"><span id="local-6989586621679808358"><span id="local-6989586621679808359"><span id="local-6989586621679808360"><span id="local-6989586621679808361"><span class="hs-keyword">instance</span><span>
</span><span id="line-817"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-818"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TDDropoutF"><span class="hs-identifier hs-type">TDDropoutF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#Pegasus"><span class="hs-identifier hs-type">Pegasus</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-819"></span><span>      </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-820"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679808361"><span class="hs-identifier hs-type">decoderInputGradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808360"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808359"><span class="hs-identifier hs-type">decoderPosGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-821"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679808358"><span class="hs-identifier hs-type">decoderInputLayout</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Dense"><span class="hs-identifier hs-type">Dense</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808357"><span class="hs-identifier hs-type">decoderPosLayout</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-822"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679808356"><span class="hs-identifier hs-type">decoderInputDevice</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808355"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808354"><span class="hs-identifier hs-type">decoderPosDevice</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-823"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679808353"><span class="hs-identifier hs-type">decoderInputDataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Seq"><span class="hs-identifier hs-type">Seq</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679808352"><span class="hs-identifier hs-type">decoderPosDataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#Int64"><span class="hs-identifier hs-type">Int64</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679808351"><span class="hs-identifier hs-type">dataType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-824"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#BroadcastShapesF"><span class="hs-identifier hs-type">BroadcastShapesF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808350"><span class="hs-identifier hs-type">decoderInputShape</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Functional.Sparse.html#EmbeddingF"><span class="hs-identifier hs-type">EmbeddingF</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679808349"><span class="hs-identifier hs-type">posEncDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679808348"><span class="hs-identifier hs-type">decoderInputEmbedDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679808347"><span class="hs-identifier hs-type">decoderPosShape</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-825"></span><span>      </span><span class="hs-special">)</span><span>
</span><span id="line-826"></span><span>      </span><span class="annot"><a href="#local-6989586621679808346"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-827"></span><span>      </span><span class="annot"><a href="#local-6989586621679808345"><span class="hs-identifier hs-type">dropoutOutput</span></a></span><span>
</span><span id="line-828"></span><span>      </span><span class="annot"><a href="#local-6989586621679808344"><span class="hs-identifier hs-type">dropoutGeneratorOutputDevice</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-829"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-830"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TDStackF"><span class="hs-identifier hs-type">TDStackF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#Pegasus"><span class="hs-identifier hs-type">Pegasus</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808343"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808360"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808355"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808351"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808342"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808341"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808340"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808348"><span class="hs-identifier hs-type">decoderInputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808339"><span class="hs-identifier hs-type">encoderOutputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808338"><span class="hs-identifier hs-type">ffnDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-831"></span><span>      </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="#local-6989586621679808345"><span class="hs-identifier hs-type">dropoutOutput</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-832"></span><span>        </span><span class="annot"><a href="#local-6989586621679808337"><span class="hs-identifier hs-type">encoderOutput</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-833"></span><span>        </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-834"></span><span>          </span><span class="annot"><a href="#local-6989586621679808336"><span class="hs-identifier hs-type">decoderAttentionMaskGradient</span></a></span><span>
</span><span id="line-835"></span><span>          </span><span class="annot"><a href="#local-6989586621679808335"><span class="hs-identifier hs-type">decoderAttentionMaskLayout</span></a></span><span>
</span><span id="line-836"></span><span>          </span><span class="annot"><a href="#local-6989586621679808334"><span class="hs-identifier hs-type">decoderAttentionMaskDevice</span></a></span><span>
</span><span id="line-837"></span><span>          </span><span class="annot"><a href="#local-6989586621679808333"><span class="hs-identifier hs-type">decoderAttentionMaskDataType</span></a></span><span>
</span><span id="line-838"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#UnsqueezeF"><span class="hs-identifier hs-type">UnsqueezeF</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679808332"><span class="hs-identifier hs-type">decoderAttentionMaskShape</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-839"></span><span>        </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-840"></span><span>          </span><span class="annot"><a href="#local-6989586621679808331"><span class="hs-identifier hs-type">crossAttentionMaskGradient</span></a></span><span>
</span><span id="line-841"></span><span>          </span><span class="annot"><a href="#local-6989586621679808330"><span class="hs-identifier hs-type">crossAttentionMaskLayout</span></a></span><span>
</span><span id="line-842"></span><span>          </span><span class="annot"><a href="#local-6989586621679808329"><span class="hs-identifier hs-type">crossAttentionMaskDevice</span></a></span><span>
</span><span id="line-843"></span><span>          </span><span class="annot"><a href="#local-6989586621679808328"><span class="hs-identifier hs-type">crossAttentionMaskDataType</span></a></span><span>
</span><span id="line-844"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#UnsqueezeF"><span class="hs-identifier hs-type">UnsqueezeF</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679808327"><span class="hs-identifier hs-type">crossAttentionMaskShape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-845"></span><span>      </span><span class="hs-special">)</span><span>
</span><span id="line-846"></span><span>      </span><span class="annot"><a href="#local-6989586621679808344"><span class="hs-identifier hs-type">dropoutGeneratorOutputDevice</span></a></span><span>
</span><span id="line-847"></span><span>      </span><span class="annot"><a href="#local-6989586621679808326"><span class="hs-identifier hs-type">stackOutput</span></a></span><span>
</span><span id="line-848"></span><span>      </span><span class="annot"><a href="#local-6989586621679808325"><span class="hs-identifier hs-type">generatorOutputDevice</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-849"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-850"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TDLayerNormF"><span class="hs-identifier hs-type">TDLayerNormF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#Pegasus"><span class="hs-identifier hs-type">Pegasus</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808360"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808355"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808351"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808348"><span class="hs-identifier hs-type">decoderInputEmbedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-851"></span><span>      </span><span class="annot"><a href="#local-6989586621679808326"><span class="hs-identifier hs-type">stackOutput</span></a></span><span>
</span><span id="line-852"></span><span>      </span><span class="annot"><a href="#local-6989586621679808325"><span class="hs-identifier hs-type">generatorOutputDevice</span></a></span><span>
</span><span id="line-853"></span><span>      </span><span class="annot"><a href="#local-6989586621679808324"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-854"></span><span>      </span><span class="annot"><a href="#local-6989586621679808325"><span class="hs-identifier hs-type">generatorOutputDevice</span></a></span><span>
</span><span id="line-855"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-856"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-857"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TransformerDecoder"><span class="hs-identifier hs-type">TransformerDecoder</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#Pegasus"><span class="hs-identifier hs-type">Pegasus</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808343"><span class="hs-identifier hs-type">numLayers</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808360"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808355"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808351"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808342"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808341"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808340"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808348"><span class="hs-identifier hs-type">decoderInputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808339"><span class="hs-identifier hs-type">encoderOutputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808338"><span class="hs-identifier hs-type">ffnDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808349"><span class="hs-identifier hs-type">posEncDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-858"></span><span>    </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808361"><span class="hs-identifier hs-type">decoderInputGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808358"><span class="hs-identifier hs-type">decoderInputLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808356"><span class="hs-identifier hs-type">decoderInputDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808353"><span class="hs-identifier hs-type">decoderInputDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808350"><span class="hs-identifier hs-type">decoderInputShape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-859"></span><span>      </span><span class="annot"><a href="#local-6989586621679808337"><span class="hs-identifier hs-type">encoderOutput</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-860"></span><span>      </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808359"><span class="hs-identifier hs-type">decoderPosGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808357"><span class="hs-identifier hs-type">decoderPosLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808354"><span class="hs-identifier hs-type">decoderPosDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808352"><span class="hs-identifier hs-type">decoderPosDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808347"><span class="hs-identifier hs-type">decoderPosShape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-861"></span><span>      </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808336"><span class="hs-identifier hs-type">decoderAttentionMaskGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808335"><span class="hs-identifier hs-type">decoderAttentionMaskLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808334"><span class="hs-identifier hs-type">decoderAttentionMaskDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808333"><span class="hs-identifier hs-type">decoderAttentionMaskDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808332"><span class="hs-identifier hs-type">decoderAttentionMaskShape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-862"></span><span>      </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808331"><span class="hs-identifier hs-type">crossAttentionMaskGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808330"><span class="hs-identifier hs-type">crossAttentionMaskLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808329"><span class="hs-identifier hs-type">crossAttentionMaskDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808328"><span class="hs-identifier hs-type">crossAttentionMaskDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679808327"><span class="hs-identifier hs-type">crossAttentionMaskShape</span></a></span><span>
</span><span id="line-863"></span><span>    </span><span class="hs-special">)</span><span>
</span><span id="line-864"></span><span>    </span><span class="annot"><a href="#local-6989586621679808346"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-865"></span><span>    </span><span class="annot"><a href="#local-6989586621679808324"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-866"></span><span>    </span><span class="annot"><a href="#local-6989586621679808325"><span class="hs-identifier hs-type">generatorOutputDevice</span></a></span><span>
</span><span id="line-867"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-868"></span><span>  </span><span id="local-6989586621679808322"><span class="annot"><span class="annottext">forward :: TransformerDecoder
  'Pegasus
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  decoderInputEmbedDim
  encoderOutputEmbedDim
  ffnDim
  posEncDim
-&gt; (Tensor
      decoderInputGradient
      decoderInputLayout
      decoderInputDevice
      decoderInputDataType
      decoderInputShape,
    encoderOutput,
    Tensor
      decoderPosGradient
      decoderPosLayout
      decoderPosDevice
      decoderPosDataType
      decoderPosShape,
    Tensor
      decoderAttentionMaskGradient
      decoderAttentionMaskLayout
      decoderAttentionMaskDevice
      decoderAttentionMaskDataType
      decoderAttentionMaskShape,
    Tensor
      crossAttentionMaskGradient
      crossAttentionMaskLayout
      crossAttentionMaskDevice
      crossAttentionMaskDataType
      crossAttentionMaskShape)
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="#local-6989586621679808322"><span class="hs-identifier hs-var hs-var hs-var hs-var">forward</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#TransformerDecoder"><span class="hs-identifier hs-type">TransformerDecoder</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Decoder.html#GTransformerDecoder"><span class="hs-identifier hs-type">GTransformerDecoder</span></a></span><span> </span><span class="hs-special">{</span><span id="local-6989586621679808317"><span id="local-6989586621679808318"><span id="local-6989586621679808319"><span id="local-6989586621679808320"><span id="local-6989586621679808321"><span class="annot"><span class="annottext">TDPosEncF
  'Pegasus
  gradient
  device
  dataType
  headDim
  decoderInputEmbedDim
  posEncDim
TDDropoutF 'Pegasus
TDLayerNormF 'Pegasus gradient device dataType decoderInputEmbedDim
TDEmbedLayerNormF
  'Pegasus gradient device dataType decoderInputEmbedDim
TDStackF
  'Pegasus
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  decoderInputEmbedDim
  encoderOutputEmbedDim
  ffnDim
tdPosEnc :: TDPosEncF
  'Pegasus
  gradient
  device
  dataType
  headDim
  decoderInputEmbedDim
  posEncDim
tdDropout :: TDDropoutF 'Pegasus
tdLayerNorm :: TDLayerNormF 'Pegasus gradient device dataType decoderInputEmbedDim
tdEmbedLayerNorm :: TDEmbedLayerNormF
  'Pegasus gradient device dataType decoderInputEmbedDim
tdStack :: TDStackF
  'Pegasus
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  decoderInputEmbedDim
  encoderOutputEmbedDim
  ffnDim
tdPosEnc :: forall stack embedLayerNorm layerNorm dropout posEnc.
GTransformerDecoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; posEnc
tdDropout :: forall stack embedLayerNorm layerNorm dropout posEnc.
GTransformerDecoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; dropout
tdLayerNorm :: forall stack embedLayerNorm layerNorm dropout posEnc.
GTransformerDecoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; layerNorm
tdEmbedLayerNorm :: forall stack embedLayerNorm layerNorm dropout posEnc.
GTransformerDecoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; embedLayerNorm
tdStack :: forall stack embedLayerNorm layerNorm dropout posEnc.
GTransformerDecoder stack embedLayerNorm layerNorm dropout posEnc
-&gt; stack
</span><a href="#local-6989586621679808317"><span class="hs-glyph hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">..</span></a></span></span></span></span></span></span><span class="hs-special">}</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679808316"><span class="annot"><span class="annottext">Tensor
  decoderInputGradient
  decoderInputLayout
  decoderInputDevice
  decoderInputDataType
  decoderInputShape
</span><a href="#local-6989586621679808316"><span class="hs-identifier hs-var">decoderInput</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679808315"><span class="annot"><span class="annottext">encoderOutput
</span><a href="#local-6989586621679808315"><span class="hs-identifier hs-var">encoderOutput</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679808314"><span class="annot"><span class="annottext">Tensor
  decoderPosGradient
  decoderPosLayout
  decoderPosDevice
  decoderPosDataType
  decoderPosShape
</span><a href="#local-6989586621679808314"><span class="hs-identifier hs-var">decoderPos</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679808313"><span class="annot"><span class="annottext">Tensor
  decoderAttentionMaskGradient
  decoderAttentionMaskLayout
  decoderAttentionMaskDevice
  decoderAttentionMaskDataType
  decoderAttentionMaskShape
</span><a href="#local-6989586621679808313"><span class="hs-identifier hs-var">decoderAttentionMask</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679808312"><span class="annot"><span class="annottext">Tensor
  crossAttentionMaskGradient
  crossAttentionMaskLayout
  crossAttentionMaskDevice
  crossAttentionMaskDataType
  crossAttentionMaskShape
</span><a href="#local-6989586621679808312"><span class="hs-identifier hs-var">crossAttentionMask</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-869"></span><span>    </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679808311"><span class="annot"><span class="annottext">decoderAttentionBias :: Tensor
  decoderAttentionMaskGradient
  decoderAttentionMaskLayout
  decoderAttentionMaskDevice
  decoderAttentionMaskDataType
  (UnsqueezeF ('SelectDim ('ByIndex 1)) decoderAttentionMaskShape)
</span><a href="#local-6989586621679808311"><span class="hs-identifier hs-var hs-var">decoderAttentionBias</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor
  decoderAttentionMaskGradient
  decoderAttentionMaskLayout
  decoderAttentionMaskDevice
  decoderAttentionMaskDataType
  decoderAttentionMaskShape
-&gt; Tensor
     decoderAttentionMaskGradient
     decoderAttentionMaskLayout
     decoderAttentionMaskDevice
     decoderAttentionMaskDataType
     (UnsqueezeF ('SelectDim ('ByIndex 1)) decoderAttentionMaskShape)
forall (selectDim :: SelectDim (By Symbol Nat))
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]).
(shape' ~ UnsqueezeF selectDim shape, SingI selectDim) =&gt;
Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape'
</span><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#unsqueeze"><span class="hs-identifier hs-var">unsqueeze</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
  decoderAttentionMaskGradient
  decoderAttentionMaskLayout
  decoderAttentionMaskDevice
  decoderAttentionMaskDataType
  decoderAttentionMaskShape
</span><a href="#local-6989586621679808313"><span class="hs-identifier hs-var">decoderAttentionMask</span></a></span><span>
</span><span id="line-870"></span><span>        </span><span id="local-6989586621679808310"><span class="annot"><span class="annottext">crossAttentionBias :: Tensor
  crossAttentionMaskGradient
  crossAttentionMaskLayout
  crossAttentionMaskDevice
  crossAttentionMaskDataType
  (UnsqueezeF ('SelectDim ('ByIndex 1)) crossAttentionMaskShape)
</span><a href="#local-6989586621679808310"><span class="hs-identifier hs-var hs-var">crossAttentionBias</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor
  crossAttentionMaskGradient
  crossAttentionMaskLayout
  crossAttentionMaskDevice
  crossAttentionMaskDataType
  crossAttentionMaskShape
-&gt; Tensor
     crossAttentionMaskGradient
     crossAttentionMaskLayout
     crossAttentionMaskDevice
     crossAttentionMaskDataType
     (UnsqueezeF ('SelectDim ('ByIndex 1)) crossAttentionMaskShape)
forall (selectDim :: SelectDim (By Symbol Nat))
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]).
(shape' ~ UnsqueezeF selectDim shape, SingI selectDim) =&gt;
Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape'
</span><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#unsqueeze"><span class="hs-identifier hs-var">unsqueeze</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
  crossAttentionMaskGradient
  crossAttentionMaskLayout
  crossAttentionMaskDevice
  crossAttentionMaskDataType
  crossAttentionMaskShape
</span><a href="#local-6989586621679808312"><span class="hs-identifier hs-var">crossAttentionMask</span></a></span><span>
</span><span id="line-871"></span><span>     </span><span class="hs-keyword">in</span><span> </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorOutputDevice)
  output
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
forall (m :: * -&gt; *) i j a. IxStateT m i j a -&gt; i -&gt; m (a, j)
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var hs-var">runIxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">(IxStateT
   m
   (Generator generatorDevice)
   (Generator generatorOutputDevice)
   output
 -&gt; Generator generatorDevice
 -&gt; m (output, Generator generatorOutputDevice))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorOutputDevice)
     output
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-872"></span><span>          </span><span class="annot"><span class="annottext">Tensor
  decoderPosGradient
  decoderPosLayout
  decoderPosDevice
  decoderPosDataType
  decoderPosShape
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     (Tensor
        decoderPosGradient
        decoderPosLayout
        decoderPosDevice
        decoderPosDataType
        decoderPosShape)
forall k (m :: k -&gt; k -&gt; * -&gt; *) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  decoderPosGradient
  decoderPosLayout
  decoderPosDevice
  decoderPosDataType
  decoderPosShape
</span><a href="#local-6989586621679808314"><span class="hs-identifier hs-var">decoderPos</span></a></span><span>
</span><span id="line-873"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorDevice)
  (Tensor
     decoderPosGradient
     decoderPosLayout
     decoderPosDevice
     decoderPosDataType
     decoderPosShape)
-&gt; (Tensor
      decoderPosGradient
      decoderPosLayout
      decoderPosDevice
      decoderPosDataType
      decoderPosShape
    -&gt; IxStateT
         m
         (Generator generatorDevice)
         (Generator generatorDevice)
         (Tensor
            (Or (Gradient RequiresGradient) gradient decoderPosGradient)
            (Unify (Layout LayoutType) ('Layout 'Dense) decoderPosLayout)
            (Unify (Device (DeviceType Nat)) device decoderPosDevice)
            (Seq
               (Unify (DataType DType) decoderPosDataType ('DataType 'Int64))
               dataType)
            (EmbeddingF
               ('Shape '[posEncDim, decoderInputEmbedDim]) decoderPosShape)))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     (Tensor
        (Or (Gradient RequiresGradient) gradient decoderPosGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) decoderPosLayout)
        (Unify (Device (DeviceType Nat)) device decoderPosDevice)
        (Seq
           (Unify (DataType DType) decoderPosDataType ('DataType 'Int64))
           dataType)
        (EmbeddingF
           ('Shape '[posEncDim, decoderInputEmbedDim]) decoderPosShape))
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(Generator generatorDevice
 -&gt; m (Tensor
         (Or (Gradient RequiresGradient) gradient decoderPosGradient)
         (Unify (Layout LayoutType) ('Layout 'Dense) decoderPosLayout)
         (Unify (Device (DeviceType Nat)) device decoderPosDevice)
         (Seq
            (Unify (DataType DType) decoderPosDataType ('DataType 'Int64))
            dataType)
         (EmbeddingF
            ('Shape '[posEncDim, decoderInputEmbedDim]) decoderPosShape),
       Generator generatorDevice))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     (Tensor
        (Or (Gradient RequiresGradient) gradient decoderPosGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) decoderPosLayout)
        (Unify (Device (DeviceType Nat)) device decoderPosDevice)
        (Seq
           (Unify (DataType DType) decoderPosDataType ('DataType 'Int64))
           dataType)
        (EmbeddingF
           ('Shape '[posEncDim, decoderInputEmbedDim]) decoderPosShape))
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator generatorDevice
  -&gt; m (Tensor
          (Or (Gradient RequiresGradient) gradient decoderPosGradient)
          (Unify (Layout LayoutType) ('Layout 'Dense) decoderPosLayout)
          (Unify (Device (DeviceType Nat)) device decoderPosDevice)
          (Seq
             (Unify (DataType DType) decoderPosDataType ('DataType 'Int64))
             dataType)
          (EmbeddingF
             ('Shape '[posEncDim, decoderInputEmbedDim]) decoderPosShape),
        Generator generatorDevice))
 -&gt; IxStateT
      m
      (Generator generatorDevice)
      (Generator generatorDevice)
      (Tensor
         (Or (Gradient RequiresGradient) gradient decoderPosGradient)
         (Unify (Layout LayoutType) ('Layout 'Dense) decoderPosLayout)
         (Unify (Device (DeviceType Nat)) device decoderPosDevice)
         (Seq
            (Unify (DataType DType) decoderPosDataType ('DataType 'Int64))
            dataType)
         (EmbeddingF
            ('Shape '[posEncDim, decoderInputEmbedDim]) decoderPosShape)))
-&gt; (Tensor
      decoderPosGradient
      decoderPosLayout
      decoderPosDevice
      decoderPosDataType
      decoderPosShape
    -&gt; Generator generatorDevice
    -&gt; m (Tensor
            (Or (Gradient RequiresGradient) gradient decoderPosGradient)
            (Unify (Layout LayoutType) ('Layout 'Dense) decoderPosLayout)
            (Unify (Device (DeviceType Nat)) device decoderPosDevice)
            (Seq
               (Unify (DataType DType) decoderPosDataType ('DataType 'Int64))
               dataType)
            (EmbeddingF
               ('Shape '[posEncDim, decoderInputEmbedDim]) decoderPosShape),
          Generator generatorDevice))
-&gt; Tensor
     decoderPosGradient
     decoderPosLayout
     decoderPosDevice
     decoderPosDataType
     decoderPosShape
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     (Tensor
        (Or (Gradient RequiresGradient) gradient decoderPosGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) decoderPosLayout)
        (Unify (Device (DeviceType Nat)) device decoderPosDevice)
        (Seq
           (Unify (DataType DType) decoderPosDataType ('DataType 'Int64))
           dataType)
        (EmbeddingF
           ('Shape '[posEncDim, decoderInputEmbedDim]) decoderPosShape))
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Embedding
  gradient
  ('Layout 'Dense)
  device
  dataType
  posEncDim
  decoderInputEmbedDim
  'Nothing
-&gt; Tensor
     decoderPosGradient
     decoderPosLayout
     decoderPosDevice
     decoderPosDataType
     decoderPosShape
-&gt; Generator generatorDevice
-&gt; m (Tensor
        (Or (Gradient RequiresGradient) gradient decoderPosGradient)
        (Unify (Layout LayoutType) ('Layout 'Dense) decoderPosLayout)
        (Unify (Device (DeviceType Nat)) device decoderPosDevice)
        (Seq
           (Unify (DataType DType) decoderPosDataType ('DataType 'Int64))
           dataType)
        (EmbeddingF
           ('Shape '[posEncDim, decoderInputEmbedDim]) decoderPosShape),
      Generator generatorDevice)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: * -&gt; *).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">Embedding
  gradient
  ('Layout 'Dense)
  device
  dataType
  posEncDim
  decoderInputEmbedDim
  'Nothing
TDPosEncF
  'Pegasus
  gradient
  device
  dataType
  headDim
  decoderInputEmbedDim
  posEncDim
</span><a href="#local-6989586621679808317"><span class="hs-identifier hs-var">tdPosEnc</span></a></span><span>
</span><span id="line-874"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorDevice)
  (Tensor
     (Or (Gradient RequiresGradient) gradient decoderPosGradient)
     (Unify (Layout LayoutType) ('Layout 'Dense) decoderPosLayout)
     (Unify (Device (DeviceType Nat)) device decoderPosDevice)
     (Seq
        (Unify (DataType DType) decoderPosDataType ('DataType 'Int64))
        dataType)
     (EmbeddingF
        ('Shape '[posEncDim, decoderInputEmbedDim]) decoderPosShape))
-&gt; (Tensor
      (Or (Gradient RequiresGradient) gradient decoderPosGradient)
      (Unify (Layout LayoutType) ('Layout 'Dense) decoderPosLayout)
      (Unify (Device (DeviceType Nat)) device decoderPosDevice)
      (Seq
         (Unify (DataType DType) decoderPosDataType ('DataType 'Int64))
         dataType)
      (EmbeddingF
         ('Shape '[posEncDim, decoderInputEmbedDim]) decoderPosShape)
    -&gt; IxStateT
         m
         (Generator generatorDevice)
         (Generator generatorDevice)
         (Tensor
            (Or
               (Gradient RequiresGradient)
               decoderInputGradient
               (Or (Gradient RequiresGradient) gradient decoderPosGradient))
            (Unify
               (Layout LayoutType)
               decoderInputLayout
               (Unify (Layout LayoutType) ('Layout 'Dense) decoderPosLayout))
            (Unify
               (Device (DeviceType Nat))
               decoderInputDevice
               (Unify (Device (DeviceType Nat)) device decoderPosDevice))
            (Unify
               (DataType DType)
               decoderInputDataType
               (Seq
                  (Unify (DataType DType) decoderPosDataType ('DataType 'Int64))
                  dataType))
            (BroadcastShapesF
               decoderInputShape
               (EmbeddingF
                  ('Shape '[posEncDim, decoderInputEmbedDim]) decoderPosShape))))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     (Tensor
        (Or
           (Gradient RequiresGradient)
           decoderInputGradient
           (Or (Gradient RequiresGradient) gradient decoderPosGradient))
        (Unify
           (Layout LayoutType)
           decoderInputLayout
           (Unify (Layout LayoutType) ('Layout 'Dense) decoderPosLayout))
        (Unify
           (Device (DeviceType Nat))
           decoderInputDevice
           (Unify (Device (DeviceType Nat)) device decoderPosDevice))
        (Unify
           (DataType DType)
           decoderInputDataType
           (Seq
              (Unify (DataType DType) decoderPosDataType ('DataType 'Int64))
              dataType))
        (BroadcastShapesF
           decoderInputShape
           (EmbeddingF
              ('Shape '[posEncDim, decoderInputEmbedDim]) decoderPosShape)))
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  (Or
     (Gradient RequiresGradient)
     decoderInputGradient
     (Or (Gradient RequiresGradient) gradient decoderPosGradient))
  (Unify
     (Layout LayoutType)
     decoderInputLayout
     (Unify (Layout LayoutType) ('Layout 'Dense) decoderPosLayout))
  (Unify
     (Device (DeviceType Nat))
     decoderInputDevice
     (Unify (Device (DeviceType Nat)) device decoderPosDevice))
  (Unify
     (DataType DType)
     decoderInputDataType
     (Seq
        (Unify (DataType DType) decoderPosDataType ('DataType 'Int64))
        dataType))
  (BroadcastShapesF
     decoderInputShape
     (EmbeddingF
        ('Shape '[posEncDim, decoderInputEmbedDim]) decoderPosShape))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     (Tensor
        (Or
           (Gradient RequiresGradient)
           decoderInputGradient
           (Or (Gradient RequiresGradient) gradient decoderPosGradient))
        (Unify
           (Layout LayoutType)
           decoderInputLayout
           (Unify (Layout LayoutType) ('Layout 'Dense) decoderPosLayout))
        (Unify
           (Device (DeviceType Nat))
           decoderInputDevice
           (Unify (Device (DeviceType Nat)) device decoderPosDevice))
        (Unify
           (DataType DType)
           decoderInputDataType
           (Seq
              (Unify (DataType DType) decoderPosDataType ('DataType 'Int64))
              dataType))
        (BroadcastShapesF
           decoderInputShape
           (EmbeddingF
              ('Shape '[posEncDim, decoderInputEmbedDim]) decoderPosShape)))
forall k (m :: k -&gt; k -&gt; * -&gt; *) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">(Tensor
   (Or
      (Gradient RequiresGradient)
      decoderInputGradient
      (Or (Gradient RequiresGradient) gradient decoderPosGradient))
   (Unify
      (Layout LayoutType)
      decoderInputLayout
      (Unify (Layout LayoutType) ('Layout 'Dense) decoderPosLayout))
   (Unify
      (Device (DeviceType Nat))
      decoderInputDevice
      (Unify (Device (DeviceType Nat)) device decoderPosDevice))
   (Unify
      (DataType DType)
      decoderInputDataType
      (Seq
         (Unify (DataType DType) decoderPosDataType ('DataType 'Int64))
         dataType))
   (BroadcastShapesF
      decoderInputShape
      (EmbeddingF
         ('Shape '[posEncDim, decoderInputEmbedDim]) decoderPosShape))
 -&gt; IxStateT
      m
      (Generator generatorDevice)
      (Generator generatorDevice)
      (Tensor
         (Or
            (Gradient RequiresGradient)
            decoderInputGradient
            (Or (Gradient RequiresGradient) gradient decoderPosGradient))
         (Unify
            (Layout LayoutType)
            decoderInputLayout
            (Unify (Layout LayoutType) ('Layout 'Dense) decoderPosLayout))
         (Unify
            (Device (DeviceType Nat))
            decoderInputDevice
            (Unify (Device (DeviceType Nat)) device decoderPosDevice))
         (Unify
            (DataType DType)
            decoderInputDataType
            (Seq
               (Unify (DataType DType) decoderPosDataType ('DataType 'Int64))
               dataType))
         (BroadcastShapesF
            decoderInputShape
            (EmbeddingF
               ('Shape '[posEncDim, decoderInputEmbedDim]) decoderPosShape))))
-&gt; (Tensor
      (Or (Gradient RequiresGradient) gradient decoderPosGradient)
      (Unify (Layout LayoutType) ('Layout 'Dense) decoderPosLayout)
      (Unify (Device (DeviceType Nat)) device decoderPosDevice)
      (Seq
         (Unify (DataType DType) decoderPosDataType ('DataType 'Int64))
         dataType)
      (EmbeddingF
         ('Shape '[posEncDim, decoderInputEmbedDim]) decoderPosShape)
    -&gt; Tensor
         (Or
            (Gradient RequiresGradient)
            decoderInputGradient
            (Or (Gradient RequiresGradient) gradient decoderPosGradient))
         (Unify
            (Layout LayoutType)
            decoderInputLayout
            (Unify (Layout LayoutType) ('Layout 'Dense) decoderPosLayout))
         (Unify
            (Device (DeviceType Nat))
            decoderInputDevice
            (Unify (Device (DeviceType Nat)) device decoderPosDevice))
         (Unify
            (DataType DType)
            decoderInputDataType
            (Seq
               (Unify (DataType DType) decoderPosDataType ('DataType 'Int64))
               dataType))
         (BroadcastShapesF
            decoderInputShape
            (EmbeddingF
               ('Shape '[posEncDim, decoderInputEmbedDim]) decoderPosShape)))
-&gt; Tensor
     (Or (Gradient RequiresGradient) gradient decoderPosGradient)
     (Unify (Layout LayoutType) ('Layout 'Dense) decoderPosLayout)
     (Unify (Device (DeviceType Nat)) device decoderPosDevice)
     (Seq
        (Unify (DataType DType) decoderPosDataType ('DataType 'Int64))
        dataType)
     (EmbeddingF
        ('Shape '[posEncDim, decoderInputEmbedDim]) decoderPosShape)
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     (Tensor
        (Or
           (Gradient RequiresGradient)
           decoderInputGradient
           (Or (Gradient RequiresGradient) gradient decoderPosGradient))
        (Unify
           (Layout LayoutType)
           decoderInputLayout
           (Unify (Layout LayoutType) ('Layout 'Dense) decoderPosLayout))
        (Unify
           (Device (DeviceType Nat))
           decoderInputDevice
           (Unify (Device (DeviceType Nat)) device decoderPosDevice))
        (Unify
           (DataType DType)
           decoderInputDataType
           (Seq
              (Unify (DataType DType) decoderPosDataType ('DataType 'Int64))
              dataType))
        (BroadcastShapesF
           decoderInputShape
           (EmbeddingF
              ('Shape '[posEncDim, decoderInputEmbedDim]) decoderPosShape)))
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Tensor
  decoderInputGradient
  decoderInputLayout
  decoderInputDevice
  decoderInputDataType
  decoderInputShape
</span><a href="#local-6989586621679808316"><span class="hs-identifier hs-var">decoderInput</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  decoderInputGradient
  decoderInputLayout
  decoderInputDevice
  decoderInputDataType
  decoderInputShape
-&gt; Tensor
     (Or (Gradient RequiresGradient) gradient decoderPosGradient)
     (Unify (Layout LayoutType) ('Layout 'Dense) decoderPosLayout)
     (Unify (Device (DeviceType Nat)) device decoderPosDevice)
     (Seq
        (Unify (DataType DType) decoderPosDataType ('DataType 'Int64))
        dataType)
     (EmbeddingF
        ('Shape '[posEncDim, decoderInputEmbedDim]) decoderPosShape)
-&gt; Tensor
     (decoderInputGradient
      &lt;|&gt; Or (Gradient RequiresGradient) gradient decoderPosGradient)
     (decoderInputLayout
      &lt;+&gt; Unify (Layout LayoutType) ('Layout 'Dense) decoderPosLayout)
     (decoderInputDevice
      &lt;+&gt; Unify (Device (DeviceType Nat)) device decoderPosDevice)
     (decoderInputDataType
      &lt;+&gt; Seq
            (Unify (DataType DType) decoderPosDataType ('DataType 'Int64))
            dataType)
     (BroadcastShapesF
        decoderInputShape
        (EmbeddingF
           ('Shape '[posEncDim, decoderInputEmbedDim]) decoderPosShape))
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (gradient' :: Gradient RequiresGradient)
       (layout' :: Layout LayoutType) (device' :: Device (DeviceType Nat))
       (dataType' :: DataType DType)
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]).
Tensor gradient layout device dataType shape
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; Tensor
     (gradient &lt;|&gt; gradient')
     (layout &lt;+&gt; layout')
     (device &lt;+&gt; device')
     (dataType &lt;+&gt; dataType')
     (BroadcastShapesF shape shape')
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#add"><span class="hs-operator hs-var">`add`</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-875"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorDevice)
  (Tensor
     (Or
        (Gradient RequiresGradient)
        decoderInputGradient
        (Or (Gradient RequiresGradient) gradient decoderPosGradient))
     (Unify
        (Layout LayoutType)
        decoderInputLayout
        (Unify (Layout LayoutType) ('Layout 'Dense) decoderPosLayout))
     (Unify
        (Device (DeviceType Nat))
        decoderInputDevice
        (Unify (Device (DeviceType Nat)) device decoderPosDevice))
     (Unify
        (DataType DType)
        decoderInputDataType
        (Seq
           (Unify (DataType DType) decoderPosDataType ('DataType 'Int64))
           dataType))
     (BroadcastShapesF
        decoderInputShape
        (EmbeddingF
           ('Shape '[posEncDim, decoderInputEmbedDim]) decoderPosShape)))
-&gt; (Tensor
      (Or
         (Gradient RequiresGradient)
         decoderInputGradient
         (Or (Gradient RequiresGradient) gradient decoderPosGradient))
      (Unify
         (Layout LayoutType)
         decoderInputLayout
         (Unify (Layout LayoutType) ('Layout 'Dense) decoderPosLayout))
      (Unify
         (Device (DeviceType Nat))
         decoderInputDevice
         (Unify (Device (DeviceType Nat)) device decoderPosDevice))
      (Unify
         (DataType DType)
         decoderInputDataType
         (Seq
            (Unify (DataType DType) decoderPosDataType ('DataType 'Int64))
            dataType))
      (BroadcastShapesF
         decoderInputShape
         (EmbeddingF
            ('Shape '[posEncDim, decoderInputEmbedDim]) decoderPosShape))
    -&gt; IxStateT
         m
         (Generator generatorDevice)
         (Generator dropoutGeneratorOutputDevice)
         dropoutOutput)
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator dropoutGeneratorOutputDevice)
     dropoutOutput
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(Generator generatorDevice
 -&gt; m (dropoutOutput, Generator dropoutGeneratorOutputDevice))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator dropoutGeneratorOutputDevice)
     dropoutOutput
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator generatorDevice
  -&gt; m (dropoutOutput, Generator dropoutGeneratorOutputDevice))
 -&gt; IxStateT
      m
      (Generator generatorDevice)
      (Generator dropoutGeneratorOutputDevice)
      dropoutOutput)
-&gt; (Tensor
      (Or
         (Gradient RequiresGradient)
         decoderInputGradient
         (Or (Gradient RequiresGradient) gradient decoderPosGradient))
      (Unify
         (Layout LayoutType)
         decoderInputLayout
         (Unify (Layout LayoutType) ('Layout 'Dense) decoderPosLayout))
      (Unify
         (Device (DeviceType Nat))
         decoderInputDevice
         (Unify (Device (DeviceType Nat)) device decoderPosDevice))
      (Unify
         (DataType DType)
         decoderInputDataType
         (Seq
            (Unify (DataType DType) decoderPosDataType ('DataType 'Int64))
            dataType))
      (BroadcastShapesF
         decoderInputShape
         (EmbeddingF
            ('Shape '[posEncDim, decoderInputEmbedDim]) decoderPosShape))
    -&gt; Generator generatorDevice
    -&gt; m (dropoutOutput, Generator dropoutGeneratorOutputDevice))
-&gt; Tensor
     (Or
        (Gradient RequiresGradient)
        decoderInputGradient
        (Or (Gradient RequiresGradient) gradient decoderPosGradient))
     (Unify
        (Layout LayoutType)
        decoderInputLayout
        (Unify (Layout LayoutType) ('Layout 'Dense) decoderPosLayout))
     (Unify
        (Device (DeviceType Nat))
        decoderInputDevice
        (Unify (Device (DeviceType Nat)) device decoderPosDevice))
     (Unify
        (DataType DType)
        decoderInputDataType
        (Seq
           (Unify (DataType DType) decoderPosDataType ('DataType 'Int64))
           dataType))
     (BroadcastShapesF
        decoderInputShape
        (EmbeddingF
           ('Shape '[posEncDim, decoderInputEmbedDim]) decoderPosShape))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator dropoutGeneratorOutputDevice)
     dropoutOutput
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Dropout
-&gt; Tensor
     (Or
        (Gradient RequiresGradient)
        decoderInputGradient
        (Or (Gradient RequiresGradient) gradient decoderPosGradient))
     (Unify
        (Layout LayoutType)
        decoderInputLayout
        (Unify (Layout LayoutType) ('Layout 'Dense) decoderPosLayout))
     (Unify
        (Device (DeviceType Nat))
        decoderInputDevice
        (Unify (Device (DeviceType Nat)) device decoderPosDevice))
     (Unify
        (DataType DType)
        decoderInputDataType
        (Seq
           (Unify (DataType DType) decoderPosDataType ('DataType 'Int64))
           dataType))
     (BroadcastShapesF
        decoderInputShape
        (EmbeddingF
           ('Shape '[posEncDim, decoderInputEmbedDim]) decoderPosShape))
-&gt; Generator generatorDevice
-&gt; m (dropoutOutput, Generator dropoutGeneratorOutputDevice)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: * -&gt; *).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">Dropout
TDDropoutF 'Pegasus
</span><a href="#local-6989586621679808318"><span class="hs-identifier hs-var">tdDropout</span></a></span><span>
</span><span id="line-876"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator dropoutGeneratorOutputDevice)
  dropoutOutput
-&gt; (dropoutOutput
    -&gt; IxStateT
         m
         (Generator dropoutGeneratorOutputDevice)
         (Generator generatorOutputDevice)
         stackOutput)
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorOutputDevice)
     stackOutput
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="hs-special">(</span><span> </span><span class="hs-glyph">\</span><span id="local-6989586621679808309"><span class="annot"><span class="annottext">dropoutOutput
</span><a href="#local-6989586621679808309"><span class="hs-identifier hs-var">decoderInput'</span></a></span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-877"></span><span>                     </span><span class="annot"><span class="annottext">(Generator dropoutGeneratorOutputDevice
 -&gt; m (stackOutput, Generator generatorOutputDevice))
-&gt; IxStateT
     m
     (Generator dropoutGeneratorOutputDevice)
     (Generator generatorOutputDevice)
     stackOutput
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator dropoutGeneratorOutputDevice
  -&gt; m (stackOutput, Generator generatorOutputDevice))
 -&gt; IxStateT
      m
      (Generator dropoutGeneratorOutputDevice)
      (Generator generatorOutputDevice)
      stackOutput)
-&gt; (Generator dropoutGeneratorOutputDevice
    -&gt; m (stackOutput, Generator generatorOutputDevice))
-&gt; IxStateT
     m
     (Generator dropoutGeneratorOutputDevice)
     (Generator generatorOutputDevice)
     stackOutput
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-878"></span><span>                       </span><span class="annot"><span class="annottext">TransformerDecoderStack
  'Pegasus
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  decoderInputEmbedDim
  encoderOutputEmbedDim
  ffnDim
-&gt; (dropoutOutput, encoderOutput,
    Tensor
      decoderAttentionMaskGradient
      decoderAttentionMaskLayout
      decoderAttentionMaskDevice
      decoderAttentionMaskDataType
      (UnsqueezeF ('SelectDim ('ByIndex 1)) decoderAttentionMaskShape),
    Tensor
      crossAttentionMaskGradient
      crossAttentionMaskLayout
      crossAttentionMaskDevice
      crossAttentionMaskDataType
      (UnsqueezeF ('SelectDim ('ByIndex 1)) crossAttentionMaskShape))
-&gt; Generator dropoutGeneratorOutputDevice
-&gt; m (stackOutput, Generator generatorOutputDevice)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: * -&gt; *).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span>
</span><span id="line-879"></span><span>                         </span><span class="annot"><span class="annottext">TransformerDecoderStack
  'Pegasus
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  decoderInputEmbedDim
  encoderOutputEmbedDim
  ffnDim
TDStackF
  'Pegasus
  numLayers
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  decoderInputEmbedDim
  encoderOutputEmbedDim
  ffnDim
</span><a href="#local-6989586621679808321"><span class="hs-identifier hs-var">tdStack</span></a></span><span>
</span><span id="line-880"></span><span>                         </span><span class="hs-special">(</span><span> </span><span class="annot"><span class="annottext">dropoutOutput
</span><a href="#local-6989586621679808309"><span class="hs-identifier hs-var">decoderInput'</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-881"></span><span>                           </span><span class="annot"><span class="annottext">encoderOutput
</span><a href="#local-6989586621679808315"><span class="hs-identifier hs-var">encoderOutput</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-882"></span><span>                           </span><span class="annot"><span class="annottext">Tensor
  decoderAttentionMaskGradient
  decoderAttentionMaskLayout
  decoderAttentionMaskDevice
  decoderAttentionMaskDataType
  (UnsqueezeF ('SelectDim ('ByIndex 1)) decoderAttentionMaskShape)
</span><a href="#local-6989586621679808311"><span class="hs-identifier hs-var">decoderAttentionBias</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-883"></span><span>                           </span><span class="annot"><span class="annottext">Tensor
  crossAttentionMaskGradient
  crossAttentionMaskLayout
  crossAttentionMaskDevice
  crossAttentionMaskDataType
  (UnsqueezeF ('SelectDim ('ByIndex 1)) crossAttentionMaskShape)
</span><a href="#local-6989586621679808310"><span class="hs-identifier hs-var">crossAttentionBias</span></a></span><span>
</span><span id="line-884"></span><span>                         </span><span class="hs-special">)</span><span>
</span><span id="line-885"></span><span>                 </span><span class="hs-special">)</span><span>
</span><span id="line-886"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorOutputDevice)
  stackOutput
-&gt; (stackOutput
    -&gt; IxStateT
         m
         (Generator generatorOutputDevice)
         (Generator generatorOutputDevice)
         output)
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorOutputDevice)
     output
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(Generator generatorOutputDevice
 -&gt; m (output, Generator generatorOutputDevice))
-&gt; IxStateT
     m
     (Generator generatorOutputDevice)
     (Generator generatorOutputDevice)
     output
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator generatorOutputDevice
  -&gt; m (output, Generator generatorOutputDevice))
 -&gt; IxStateT
      m
      (Generator generatorOutputDevice)
      (Generator generatorOutputDevice)
      output)
-&gt; (stackOutput
    -&gt; Generator generatorOutputDevice
    -&gt; m (output, Generator generatorOutputDevice))
-&gt; stackOutput
-&gt; IxStateT
     m
     (Generator generatorOutputDevice)
     (Generator generatorOutputDevice)
     output
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">LayerNorm
  'WithBias gradient device dataType ('Shape '[decoderInputEmbedDim])
-&gt; stackOutput
-&gt; Generator generatorOutputDevice
-&gt; m (output, Generator generatorOutputDevice)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: * -&gt; *).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">LayerNorm
  'WithBias gradient device dataType ('Shape '[decoderInputEmbedDim])
TDLayerNormF 'Pegasus gradient device dataType decoderInputEmbedDim
</span><a href="#local-6989586621679808319"><span class="hs-identifier hs-var">tdLayerNorm</span></a></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></pre></body></html>