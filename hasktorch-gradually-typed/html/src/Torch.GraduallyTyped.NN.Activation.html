<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><link rel="stylesheet" type="text/css" href="style.css" /><script type="text/javascript" src="highlight.js"></script></head><body><pre><span class="hs-pragma">{-# LANGUAGE DataKinds #-}</span><span>
</span><span id="line-2"></span><span class="hs-pragma">{-# LANGUAGE DeriveGeneric #-}</span><span>
</span><span id="line-3"></span><span class="hs-pragma">{-# LANGUAGE DerivingStrategies #-}</span><span>
</span><span id="line-4"></span><span class="hs-pragma">{-# LANGUAGE FlexibleInstances #-}</span><span>
</span><span id="line-5"></span><span class="hs-pragma">{-# LANGUAGE GADTs #-}</span><span>
</span><span id="line-6"></span><span class="hs-pragma">{-# LANGUAGE KindSignatures #-}</span><span>
</span><span id="line-7"></span><span class="hs-pragma">{-# LANGUAGE MultiParamTypeClasses #-}</span><span>
</span><span id="line-8"></span><span class="hs-pragma">{-# LANGUAGE RankNTypes #-}</span><span>
</span><span id="line-9"></span><span class="hs-pragma">{-# LANGUAGE RecordWildCards #-}</span><span>
</span><span id="line-10"></span><span class="hs-pragma">{-# LANGUAGE ScopedTypeVariables #-}</span><span>
</span><span id="line-11"></span><span class="hs-pragma">{-# LANGUAGE TupleSections #-}</span><span>
</span><span id="line-12"></span><span class="hs-pragma">{-# LANGUAGE TypeApplications #-}</span><span>
</span><span id="line-13"></span><span class="hs-pragma">{-# LANGUAGE TypeFamilies #-}</span><span>
</span><span id="line-14"></span><span class="hs-pragma">{-# LANGUAGE UndecidableInstances #-}</span><span>
</span><span id="line-15"></span><span class="hs-pragma">{-# OPTIONS_GHC -Wall #-}</span><span>
</span><span id="line-16"></span><span>
</span><span id="line-17"></span><span class="hs-keyword">module</span><span> </span><span class="hs-identifier">Torch.GraduallyTyped.NN.Activation</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-18"></span><span>
</span><span id="line-19"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/x3gpcfbfmnj29qsjqcir8xf4ia6lc9sw-ghc-9.0.2-doc/share/doc/ghc/html/libraries/base-4.15.1.0/src"><span class="hs-identifier">GHC.Generics</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/x3gpcfbfmnj29qsjqcir8xf4ia6lc9sw-ghc-9.0.2-doc/share/doc/ghc/html/libraries/base-4.15.1.0/src"><span class="hs-identifier">Generic</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-20"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/x3gpcfbfmnj29qsjqcir8xf4ia6lc9sw-ghc-9.0.2-doc/share/doc/ghc/html/libraries/base-4.15.1.0/src"><span class="hs-identifier">GHC.TypeLits</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/x3gpcfbfmnj29qsjqcir8xf4ia6lc9sw-ghc-9.0.2-doc/share/doc/ghc/html/libraries/ghc-prim-0.7.0/src"><span class="hs-identifier">Nat</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../file:///nix/store/x3gpcfbfmnj29qsjqcir8xf4ia6lc9sw-ghc-9.0.2-doc/share/doc/ghc/html/libraries/ghc-prim-0.7.0/src"><span class="hs-identifier">Symbol</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-21"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html"><span class="hs-identifier">Torch.GraduallyTyped.NN.Class</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier">HasForward</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier">HasInitialize</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasStateDict"><span class="hs-identifier">HasStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier">ModelSpec</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-22"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Functional.Activation.html"><span class="hs-identifier">Torch.GraduallyTyped.NN.Functional.Activation</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Functional.Activation.html#gelu"><span class="hs-identifier">gelu</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Functional.Activation.html#geluNew"><span class="hs-identifier">geluNew</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Functional.Activation.html#relu"><span class="hs-identifier">relu</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-23"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Functional.NonLinearActivation.html"><span class="hs-identifier">Torch.GraduallyTyped.NN.Functional.NonLinearActivation</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Functional.NonLinearActivation.html#SoftmaxF"><span class="hs-identifier">SoftmaxF</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Functional.NonLinearActivation.html#logSoftmax"><span class="hs-identifier">logSoftmax</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Functional.NonLinearActivation.html#softmax"><span class="hs-identifier">softmax</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-24"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html"><span class="hs-identifier">Torch.GraduallyTyped.Prelude</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Catch"><span class="hs-identifier">Catch</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-25"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.html"><span class="hs-identifier">Torch.GraduallyTyped.Shape</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#By"><span class="hs-identifier">By</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SSelectDim"><span class="hs-identifier">SSelectDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier">SelectDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-26"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html"><span class="hs-identifier">Torch.GraduallyTyped.Tensor.MathOperations.Pointwise</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#tanh"><span class="hs-identifier">tanh</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-27"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html"><span class="hs-identifier">Torch.GraduallyTyped.Tensor.Type</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier">Tensor</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-28"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/x3gpcfbfmnj29qsjqcir8xf4ia6lc9sw-ghc-9.0.2-doc/share/doc/ghc/html/libraries/base-4.15.1.0/src"><span class="hs-identifier">Prelude</span></a></span><span> </span><span class="hs-keyword">hiding</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/x3gpcfbfmnj29qsjqcir8xf4ia6lc9sw-ghc-9.0.2-doc/share/doc/ghc/html/libraries/base-4.15.1.0/src"><span class="hs-identifier">tanh</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-29"></span><span>
</span><span id="line-30"></span><span class="hs-comment">-- | 'Softmax' is a non-linear activation function.</span><span>
</span><span id="line-31"></span><span id="local-6989586621679738258"><span id="local-6989586621679738259"></span></span><span class="hs-keyword">data</span><span> </span><span id="Softmax"><span class="annot"><a href="Torch.GraduallyTyped.NN.Activation.html#Softmax"><span class="hs-identifier hs-var">Softmax</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679738502"><span class="annot"><a href="#local-6989586621679738502"><span class="hs-identifier hs-type">selectDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#By"><span class="hs-identifier hs-type">By</span></a></span><span> </span><span class="annot"><a href="../file:///nix/store/x3gpcfbfmnj29qsjqcir8xf4ia6lc9sw-ghc-9.0.2-doc/share/doc/ghc/html/libraries/ghc-prim-0.7.0/src"><span class="hs-identifier hs-type">Symbol</span></a></span><span> </span><span class="annot"><a href="../file:///nix/store/x3gpcfbfmnj29qsjqcir8xf4ia6lc9sw-ghc-9.0.2-doc/share/doc/ghc/html/libraries/ghc-prim-0.7.0/src"><span class="hs-identifier hs-type">Nat</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-32"></span><span>  </span><span id="Softmax"><span class="annot"><a href="Torch.GraduallyTyped.NN.Activation.html#Softmax"><span class="hs-identifier hs-var">Softmax</span></a></span></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-33"></span><span>    </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679738506"><span class="annot"><a href="#local-6989586621679738506"><span class="hs-identifier hs-type">selectDim</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-34"></span><span>    </span><span class="hs-special">{</span><span id="softmaxSelectDim"><span class="annot"><span class="annottext">forall (selectDim :: SelectDim (By Symbol Nat)).
Softmax selectDim -&gt; SSelectDim selectDim
</span><a href="Torch.GraduallyTyped.NN.Activation.html#softmaxSelectDim"><span class="hs-identifier hs-var hs-var">softmaxSelectDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SSelectDim"><span class="hs-identifier hs-type">SSelectDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679738506"><span class="hs-identifier hs-type">selectDim</span></a></span><span class="hs-special">}</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-35"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Activation.html#Softmax"><span class="hs-identifier hs-type">Softmax</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679738506"><span class="hs-identifier hs-type">selectDim</span></a></span><span>
</span><span id="line-36"></span><span>  </span><span class="hs-keyword">deriving</span><span> </span><span class="annot"><span class="hs-keyword">stock</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(forall x. Softmax selectDim -&gt; Rep (Softmax selectDim) x)
-&gt; (forall x. Rep (Softmax selectDim) x -&gt; Softmax selectDim)
-&gt; Generic (Softmax selectDim)
forall x. Rep (Softmax selectDim) x -&gt; Softmax selectDim
forall x. Softmax selectDim -&gt; Rep (Softmax selectDim) x
forall a.
(forall x. a -&gt; Rep a x) -&gt; (forall x. Rep a x -&gt; a) -&gt; Generic a
forall (selectDim :: SelectDim (By Symbol Nat)) x.
Rep (Softmax selectDim) x -&gt; Softmax selectDim
forall (selectDim :: SelectDim (By Symbol Nat)) x.
Softmax selectDim -&gt; Rep (Softmax selectDim) x
$cto :: forall (selectDim :: SelectDim (By Symbol Nat)) x.
Rep (Softmax selectDim) x -&gt; Softmax selectDim
$cfrom :: forall (selectDim :: SelectDim (By Symbol Nat)) x.
Softmax selectDim -&gt; Rep (Softmax selectDim) x
</span><a href="../file:///nix/store/x3gpcfbfmnj29qsjqcir8xf4ia6lc9sw-ghc-9.0.2-doc/share/doc/ghc/html/libraries/base-4.15.1.0/src"><span class="hs-identifier hs-var hs-var hs-var hs-var">Generic</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-37"></span><span>
</span><span id="line-38"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">instance</span><span> </span><span id="ModelSpec"><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier hs-var">ModelSpec</span></a></span></span><span> </span><span id="local-6989586621679738251"><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Activation.html#Softmax"><span class="hs-identifier hs-type">Softmax</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679738251"><span class="hs-identifier hs-type">selectDim</span></a></span><span class="hs-special">)</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Activation.html#Softmax"><span class="hs-identifier hs-type">Softmax</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679738251"><span class="hs-identifier hs-type">selectDim</span></a></span><span>
</span><span id="line-39"></span><span>
</span><span id="line-40"></span><span id="local-6989586621679738487"><span id="local-6989586621679738488"><span class="hs-keyword">instance</span><span>
</span><span id="line-41"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span>
</span><span id="line-42"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Activation.html#Softmax"><span class="hs-identifier hs-type">Softmax</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679738488"><span class="hs-identifier hs-type">selectDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-43"></span><span>    </span><span class="annot"><a href="#local-6989586621679738487"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-44"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Activation.html#Softmax"><span class="hs-identifier hs-type">Softmax</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679738488"><span class="hs-identifier hs-type">selectDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-45"></span><span>    </span><span class="annot"><a href="#local-6989586621679738487"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-46"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-47"></span><span>  </span><span id="local-6989586621679738241"><span class="annot"><span class="annottext">initialize :: forall (m :: * -&gt; *).
MonadThrow m =&gt;
ModelSpec (Softmax selectDim)
-&gt; Generator generatorDevice
-&gt; m (Softmax selectDim, Generator generatorDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#initialize"><span class="hs-identifier hs-var hs-var hs-var hs-var">initialize</span></a></span></span><span> </span><span id="local-6989586621679738239"><span class="annot"><span class="annottext">ModelSpec (Softmax selectDim)
</span><a href="#local-6989586621679738239"><span class="hs-identifier hs-var">spec</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(Softmax selectDim, Generator generatorDevice)
-&gt; m (Softmax selectDim, Generator generatorDevice)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><a href="../file:///nix/store/x3gpcfbfmnj29qsjqcir8xf4ia6lc9sw-ghc-9.0.2-doc/share/doc/ghc/html/libraries/base-4.15.1.0/src"><span class="hs-identifier hs-var">pure</span></a></span><span> </span><span class="annot"><span class="annottext">((Softmax selectDim, Generator generatorDevice)
 -&gt; m (Softmax selectDim, Generator generatorDevice))
-&gt; (Generator generatorDevice
    -&gt; (Softmax selectDim, Generator generatorDevice))
-&gt; Generator generatorDevice
-&gt; m (Softmax selectDim, Generator generatorDevice)
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><a href="../file:///nix/store/x3gpcfbfmnj29qsjqcir8xf4ia6lc9sw-ghc-9.0.2-doc/share/doc/ghc/html/libraries/base-4.15.1.0/src"><span class="hs-operator hs-var">.</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">ModelSpec (Softmax selectDim)
Softmax selectDim
</span><a href="#local-6989586621679738239"><span class="hs-identifier hs-var">spec</span></a></span><span class="hs-special">,</span><span class="hs-special">)</span></span></span><span>
</span><span id="line-48"></span><span>
</span><span id="line-49"></span><span id="local-6989586621679738469"><span class="hs-keyword">instance</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasStateDict"><span class="hs-identifier hs-type">HasStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Activation.html#Softmax"><span class="hs-identifier hs-type">Softmax</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679738469"><span class="hs-identifier hs-type">selectDim</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-50"></span><span>  </span><span id="local-6989586621679738226"><span class="annot"><span class="annottext">fromStateDict :: forall (m :: * -&gt; *).
(MonadIO m, MonadThrow m, MonadState StateDict m) =&gt;
ModelSpec (Softmax selectDim)
-&gt; StateDictKey -&gt; m (Softmax selectDim)
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var hs-var hs-var hs-var">fromStateDict</span></a></span></span><span> </span><span id="local-6989586621679738224"><span class="annot"><span class="annottext">ModelSpec (Softmax selectDim)
</span><a href="#local-6989586621679738224"><span class="hs-identifier hs-var">spec</span></a></span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Softmax selectDim -&gt; m (Softmax selectDim)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><a href="../file:///nix/store/x3gpcfbfmnj29qsjqcir8xf4ia6lc9sw-ghc-9.0.2-doc/share/doc/ghc/html/libraries/base-4.15.1.0/src"><span class="hs-identifier hs-var">pure</span></a></span><span> </span><span class="annot"><span class="annottext">ModelSpec (Softmax selectDim)
Softmax selectDim
</span><a href="#local-6989586621679738224"><span class="hs-identifier hs-var">spec</span></a></span><span>
</span><span id="line-51"></span><span>  </span><span id="local-6989586621679738218"><span class="annot"><span class="annottext">toStateDict :: forall (m :: * -&gt; *).
(MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; Softmax selectDim -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var hs-var hs-var hs-var">toStateDict</span></a></span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="annottext">Softmax selectDim
</span><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">() -&gt; m ()
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><a href="../file:///nix/store/x3gpcfbfmnj29qsjqcir8xf4ia6lc9sw-ghc-9.0.2-doc/share/doc/ghc/html/libraries/base-4.15.1.0/src"><span class="hs-identifier hs-var">pure</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span></span><span>
</span><span id="line-52"></span><span>
</span><span id="line-53"></span><span id="local-6989586621679738428"><span id="local-6989586621679738429"><span id="local-6989586621679738430"><span id="local-6989586621679738431"><span id="local-6989586621679738432"><span id="local-6989586621679738433"><span id="local-6989586621679738434"><span id="local-6989586621679738435"><span id="local-6989586621679738436"><span class="hs-keyword">instance</span><span>
</span><span id="line-54"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="#local-6989586621679738436"><span class="hs-identifier hs-type">shape'</span></a></span><span> </span><span class="annot"><a href="../file:///nix/store/x3gpcfbfmnj29qsjqcir8xf4ia6lc9sw-ghc-9.0.2-doc/share/doc/ghc/html/libraries/ghc-prim-0.7.0/src"><span class="hs-operator hs-type">~</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Functional.NonLinearActivation.html#SoftmaxF"><span class="hs-identifier hs-type">SoftmaxF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679738435"><span class="hs-identifier hs-type">selectDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679738434"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-55"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Catch"><span class="hs-identifier hs-type">Catch</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679738436"><span class="hs-identifier hs-type">shape'</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-56"></span><span>    </span><span class="annot"><a href="#local-6989586621679738433"><span class="hs-identifier hs-type">output</span></a></span><span> </span><span class="annot"><a href="../file:///nix/store/x3gpcfbfmnj29qsjqcir8xf4ia6lc9sw-ghc-9.0.2-doc/share/doc/ghc/html/libraries/ghc-prim-0.7.0/src"><span class="hs-operator hs-type">~</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679738432"><span class="hs-identifier hs-type">requiresGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679738431"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679738430"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679738429"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679738436"><span class="hs-identifier hs-type">shape'</span></a></span><span>
</span><span id="line-57"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-58"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-59"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Activation.html#Softmax"><span class="hs-identifier hs-type">Softmax</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679738435"><span class="hs-identifier hs-type">selectDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-60"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679738432"><span class="hs-identifier hs-type">requiresGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679738431"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679738430"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679738429"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679738434"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-61"></span><span>    </span><span class="annot"><a href="#local-6989586621679738428"><span class="hs-identifier hs-type">generator</span></a></span><span>
</span><span id="line-62"></span><span>    </span><span class="annot"><a href="#local-6989586621679738433"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-63"></span><span>    </span><span class="annot"><a href="#local-6989586621679738428"><span class="hs-identifier hs-type">generator</span></a></span><span>
</span><span id="line-64"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-65"></span><span>  </span><span id="local-6989586621679738195"><span class="annot"><span class="annottext">forward :: forall (m :: * -&gt; *).
MonadThrow m =&gt;
Softmax selectDim
-&gt; Tensor requiresGradient layout device dataType shape
-&gt; Generator generator
-&gt; m (output, Generator generator)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var hs-var hs-var hs-var">forward</span></a></span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Activation.html#Softmax"><span class="hs-identifier hs-type">Softmax</span></a></span><span> </span><span class="hs-special">{</span><span id="local-6989586621679738193"><span class="annot"><span class="annottext">SSelectDim selectDim
softmaxSelectDim :: SSelectDim selectDim
softmaxSelectDim :: forall (selectDim :: SelectDim (By Symbol Nat)).
Softmax selectDim -&gt; SSelectDim selectDim
</span><a href="#local-6989586621679738193"><span class="hs-glyph hs-var hs-var">..</span></a></span></span><span class="hs-special">}</span><span> </span><span id="local-6989586621679738192"><span class="annot"><span class="annottext">Tensor requiresGradient layout device dataType shape
</span><a href="#local-6989586621679738192"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span id="local-6989586621679738191"><span class="annot"><span class="annottext">Generator generator
</span><a href="#local-6989586621679738191"><span class="hs-identifier hs-var">g</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-66"></span><span>    </span><span id="local-6989586621679738190"><span class="annot"><span class="annottext">Tensor requiresGradient layout device dataType shape'
</span><a href="#local-6989586621679738190"><span class="hs-identifier hs-var">r</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">SSelectDim selectDim
-&gt; Tensor requiresGradient layout device dataType shape
-&gt; m (Tensor requiresGradient layout device dataType shape')
forall (selectDim :: SelectDim (By Symbol Nat))
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]) (m :: * -&gt; *).
(MonadThrow m, shape' ~ SoftmaxF selectDim shape, Catch shape') =&gt;
SSelectDim selectDim
-&gt; Tensor gradient layout device dataType shape
-&gt; m (Tensor gradient layout device dataType shape')
</span><a href="Torch.GraduallyTyped.NN.Functional.NonLinearActivation.html#softmax"><span class="hs-identifier hs-var">softmax</span></a></span><span> </span><span class="annot"><span class="annottext">SSelectDim selectDim
</span><a href="#local-6989586621679738193"><span class="hs-identifier hs-var">softmaxSelectDim</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor requiresGradient layout device dataType shape
</span><a href="#local-6989586621679738192"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-67"></span><span>    </span><span class="annot"><span class="annottext">(Tensor requiresGradient layout device dataType shape',
 Generator generator)
-&gt; m (Tensor requiresGradient layout device dataType shape',
      Generator generator)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><a href="../file:///nix/store/x3gpcfbfmnj29qsjqcir8xf4ia6lc9sw-ghc-9.0.2-doc/share/doc/ghc/html/libraries/base-4.15.1.0/src"><span class="hs-identifier hs-var">pure</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Tensor requiresGradient layout device dataType shape'
</span><a href="#local-6989586621679738190"><span class="hs-identifier hs-var">r</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Generator generator
</span><a href="#local-6989586621679738191"><span class="hs-identifier hs-var">g</span></a></span><span class="hs-special">)</span></span></span></span></span></span></span></span></span></span><span>
</span><span id="line-68"></span><span>
</span><span id="line-69"></span><span class="hs-comment">-- | 'LogSoftmax' is a non-linear activation function.</span><span>
</span><span id="line-70"></span><span id="local-6989586621679738188"><span id="local-6989586621679738189"></span></span><span class="hs-keyword">data</span><span> </span><span id="LogSoftmax"><span class="annot"><a href="Torch.GraduallyTyped.NN.Activation.html#LogSoftmax"><span class="hs-identifier hs-var">LogSoftmax</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679738414"><span class="annot"><a href="#local-6989586621679738414"><span class="hs-identifier hs-type">selectDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#By"><span class="hs-identifier hs-type">By</span></a></span><span> </span><span class="annot"><a href="../file:///nix/store/x3gpcfbfmnj29qsjqcir8xf4ia6lc9sw-ghc-9.0.2-doc/share/doc/ghc/html/libraries/ghc-prim-0.7.0/src"><span class="hs-identifier hs-type">Symbol</span></a></span><span> </span><span class="annot"><a href="../file:///nix/store/x3gpcfbfmnj29qsjqcir8xf4ia6lc9sw-ghc-9.0.2-doc/share/doc/ghc/html/libraries/ghc-prim-0.7.0/src"><span class="hs-identifier hs-type">Nat</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-71"></span><span>  </span><span id="LogSoftmax"><span class="annot"><a href="Torch.GraduallyTyped.NN.Activation.html#LogSoftmax"><span class="hs-identifier hs-var">LogSoftmax</span></a></span></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-72"></span><span>    </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679738416"><span class="annot"><a href="#local-6989586621679738416"><span class="hs-identifier hs-type">selectDim</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-73"></span><span>    </span><span class="hs-special">{</span><span id="logSoftmaxSelectDim"><span class="annot"><span class="annottext">forall (selectDim :: SelectDim (By Symbol Nat)).
LogSoftmax selectDim -&gt; SSelectDim selectDim
</span><a href="Torch.GraduallyTyped.NN.Activation.html#logSoftmaxSelectDim"><span class="hs-identifier hs-var hs-var">logSoftmaxSelectDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SSelectDim"><span class="hs-identifier hs-type">SSelectDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679738416"><span class="hs-identifier hs-type">selectDim</span></a></span><span class="hs-special">}</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-74"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Activation.html#LogSoftmax"><span class="hs-identifier hs-type">LogSoftmax</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679738416"><span class="hs-identifier hs-type">selectDim</span></a></span><span>
</span><span id="line-75"></span><span>  </span><span class="hs-keyword">deriving</span><span> </span><span class="annot"><span class="hs-keyword">stock</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(forall x. LogSoftmax selectDim -&gt; Rep (LogSoftmax selectDim) x)
-&gt; (forall x. Rep (LogSoftmax selectDim) x -&gt; LogSoftmax selectDim)
-&gt; Generic (LogSoftmax selectDim)
forall x. Rep (LogSoftmax selectDim) x -&gt; LogSoftmax selectDim
forall x. LogSoftmax selectDim -&gt; Rep (LogSoftmax selectDim) x
forall a.
(forall x. a -&gt; Rep a x) -&gt; (forall x. Rep a x -&gt; a) -&gt; Generic a
forall (selectDim :: SelectDim (By Symbol Nat)) x.
Rep (LogSoftmax selectDim) x -&gt; LogSoftmax selectDim
forall (selectDim :: SelectDim (By Symbol Nat)) x.
LogSoftmax selectDim -&gt; Rep (LogSoftmax selectDim) x
$cto :: forall (selectDim :: SelectDim (By Symbol Nat)) x.
Rep (LogSoftmax selectDim) x -&gt; LogSoftmax selectDim
$cfrom :: forall (selectDim :: SelectDim (By Symbol Nat)) x.
LogSoftmax selectDim -&gt; Rep (LogSoftmax selectDim) x
</span><a href="../file:///nix/store/x3gpcfbfmnj29qsjqcir8xf4ia6lc9sw-ghc-9.0.2-doc/share/doc/ghc/html/libraries/base-4.15.1.0/src"><span class="hs-identifier hs-var hs-var hs-var hs-var">Generic</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-76"></span><span>
</span><span id="line-77"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">instance</span><span> </span><span id="ModelSpec"><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier hs-var">ModelSpec</span></a></span></span><span> </span><span id="local-6989586621679738182"><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Activation.html#LogSoftmax"><span class="hs-identifier hs-type">LogSoftmax</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679738182"><span class="hs-identifier hs-type">selectDim</span></a></span><span class="hs-special">)</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Activation.html#LogSoftmax"><span class="hs-identifier hs-type">LogSoftmax</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679738182"><span class="hs-identifier hs-type">selectDim</span></a></span><span>
</span><span id="line-78"></span><span>
</span><span id="line-79"></span><span id="local-6989586621679738410"><span id="local-6989586621679738411"><span class="hs-keyword">instance</span><span>
</span><span id="line-80"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span>
</span><span id="line-81"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Activation.html#LogSoftmax"><span class="hs-identifier hs-type">LogSoftmax</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679738411"><span class="hs-identifier hs-type">selectDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-82"></span><span>    </span><span class="annot"><a href="#local-6989586621679738410"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-83"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Activation.html#LogSoftmax"><span class="hs-identifier hs-type">LogSoftmax</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679738411"><span class="hs-identifier hs-type">selectDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-84"></span><span>    </span><span class="annot"><a href="#local-6989586621679738410"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-85"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-86"></span><span>  </span><span id="local-6989586621679738175"><span class="annot"><span class="annottext">initialize :: forall (m :: * -&gt; *).
MonadThrow m =&gt;
ModelSpec (LogSoftmax selectDim)
-&gt; Generator generatorDevice
-&gt; m (LogSoftmax selectDim, Generator generatorDevice)
</span><a href="#local-6989586621679738175"><span class="hs-identifier hs-var hs-var hs-var hs-var">initialize</span></a></span></span><span> </span><span id="local-6989586621679738174"><span class="annot"><span class="annottext">ModelSpec (LogSoftmax selectDim)
</span><a href="#local-6989586621679738174"><span class="hs-identifier hs-var">spec</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(LogSoftmax selectDim, Generator generatorDevice)
-&gt; m (LogSoftmax selectDim, Generator generatorDevice)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><a href="../file:///nix/store/x3gpcfbfmnj29qsjqcir8xf4ia6lc9sw-ghc-9.0.2-doc/share/doc/ghc/html/libraries/base-4.15.1.0/src"><span class="hs-identifier hs-var">pure</span></a></span><span> </span><span class="annot"><span class="annottext">((LogSoftmax selectDim, Generator generatorDevice)
 -&gt; m (LogSoftmax selectDim, Generator generatorDevice))
-&gt; (Generator generatorDevice
    -&gt; (LogSoftmax selectDim, Generator generatorDevice))
-&gt; Generator generatorDevice
-&gt; m (LogSoftmax selectDim, Generator generatorDevice)
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><a href="../file:///nix/store/x3gpcfbfmnj29qsjqcir8xf4ia6lc9sw-ghc-9.0.2-doc/share/doc/ghc/html/libraries/base-4.15.1.0/src"><span class="hs-operator hs-var">.</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">ModelSpec (LogSoftmax selectDim)
LogSoftmax selectDim
</span><a href="#local-6989586621679738174"><span class="hs-identifier hs-var">spec</span></a></span><span class="hs-special">,</span><span class="hs-special">)</span></span></span><span>
</span><span id="line-87"></span><span>
</span><span id="line-88"></span><span id="local-6989586621679738407"><span class="hs-keyword">instance</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasStateDict"><span class="hs-identifier hs-type">HasStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Activation.html#LogSoftmax"><span class="hs-identifier hs-type">LogSoftmax</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679738407"><span class="hs-identifier hs-type">selectDim</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-89"></span><span>  </span><span id="local-6989586621679738164"><span class="annot"><span class="annottext">fromStateDict :: forall (m :: * -&gt; *).
(MonadIO m, MonadThrow m, MonadState StateDict m) =&gt;
ModelSpec (LogSoftmax selectDim)
-&gt; StateDictKey -&gt; m (LogSoftmax selectDim)
</span><a href="#local-6989586621679738164"><span class="hs-identifier hs-var hs-var hs-var hs-var">fromStateDict</span></a></span></span><span> </span><span id="local-6989586621679738163"><span class="annot"><span class="annottext">ModelSpec (LogSoftmax selectDim)
</span><a href="#local-6989586621679738163"><span class="hs-identifier hs-var">spec</span></a></span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">LogSoftmax selectDim -&gt; m (LogSoftmax selectDim)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><a href="../file:///nix/store/x3gpcfbfmnj29qsjqcir8xf4ia6lc9sw-ghc-9.0.2-doc/share/doc/ghc/html/libraries/base-4.15.1.0/src"><span class="hs-identifier hs-var">pure</span></a></span><span> </span><span class="annot"><span class="annottext">ModelSpec (LogSoftmax selectDim)
LogSoftmax selectDim
</span><a href="#local-6989586621679738163"><span class="hs-identifier hs-var">spec</span></a></span><span>
</span><span id="line-90"></span><span>  </span><span id="local-6989586621679738157"><span class="annot"><span class="annottext">toStateDict :: forall (m :: * -&gt; *).
(MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; LogSoftmax selectDim -&gt; m ()
</span><a href="#local-6989586621679738157"><span class="hs-identifier hs-var hs-var hs-var hs-var">toStateDict</span></a></span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="annottext">LogSoftmax selectDim
</span><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">() -&gt; m ()
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><a href="../file:///nix/store/x3gpcfbfmnj29qsjqcir8xf4ia6lc9sw-ghc-9.0.2-doc/share/doc/ghc/html/libraries/base-4.15.1.0/src"><span class="hs-identifier hs-var">pure</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span></span><span>
</span><span id="line-91"></span><span>
</span><span id="line-92"></span><span id="local-6989586621679738387"><span id="local-6989586621679738388"><span id="local-6989586621679738389"><span id="local-6989586621679738390"><span id="local-6989586621679738391"><span id="local-6989586621679738392"><span id="local-6989586621679738393"><span id="local-6989586621679738394"><span id="local-6989586621679738395"><span class="hs-keyword">instance</span><span>
</span><span id="line-93"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="#local-6989586621679738395"><span class="hs-identifier hs-type">shape'</span></a></span><span> </span><span class="annot"><a href="../file:///nix/store/x3gpcfbfmnj29qsjqcir8xf4ia6lc9sw-ghc-9.0.2-doc/share/doc/ghc/html/libraries/ghc-prim-0.7.0/src"><span class="hs-operator hs-type">~</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Functional.NonLinearActivation.html#SoftmaxF"><span class="hs-identifier hs-type">SoftmaxF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679738394"><span class="hs-identifier hs-type">selectDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679738393"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-94"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Catch"><span class="hs-identifier hs-type">Catch</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679738395"><span class="hs-identifier hs-type">shape'</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-95"></span><span>    </span><span class="annot"><a href="#local-6989586621679738392"><span class="hs-identifier hs-type">output</span></a></span><span> </span><span class="annot"><a href="../file:///nix/store/x3gpcfbfmnj29qsjqcir8xf4ia6lc9sw-ghc-9.0.2-doc/share/doc/ghc/html/libraries/ghc-prim-0.7.0/src"><span class="hs-operator hs-type">~</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679738391"><span class="hs-identifier hs-type">requiresGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679738390"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679738389"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679738388"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679738395"><span class="hs-identifier hs-type">shape'</span></a></span><span>
</span><span id="line-96"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-97"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-98"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Activation.html#LogSoftmax"><span class="hs-identifier hs-type">LogSoftmax</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679738394"><span class="hs-identifier hs-type">selectDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-99"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679738391"><span class="hs-identifier hs-type">requiresGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679738390"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679738389"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679738388"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679738393"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-100"></span><span>    </span><span class="annot"><a href="#local-6989586621679738387"><span class="hs-identifier hs-type">generator</span></a></span><span>
</span><span id="line-101"></span><span>    </span><span class="annot"><a href="#local-6989586621679738392"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-102"></span><span>    </span><span class="annot"><a href="#local-6989586621679738387"><span class="hs-identifier hs-type">generator</span></a></span><span>
</span><span id="line-103"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-104"></span><span>  </span><span id="local-6989586621679738136"><span class="annot"><span class="annottext">forward :: forall (m :: * -&gt; *).
MonadThrow m =&gt;
LogSoftmax selectDim
-&gt; Tensor requiresGradient layout device dataType shape
-&gt; Generator generator
-&gt; m (output, Generator generator)
</span><a href="#local-6989586621679738136"><span class="hs-identifier hs-var hs-var hs-var hs-var">forward</span></a></span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Activation.html#LogSoftmax"><span class="hs-identifier hs-type">LogSoftmax</span></a></span><span> </span><span class="hs-special">{</span><span id="local-6989586621679738135"><span class="annot"><span class="annottext">SSelectDim selectDim
logSoftmaxSelectDim :: SSelectDim selectDim
logSoftmaxSelectDim :: forall (selectDim :: SelectDim (By Symbol Nat)).
LogSoftmax selectDim -&gt; SSelectDim selectDim
</span><a href="#local-6989586621679738135"><span class="hs-glyph hs-var hs-var">..</span></a></span></span><span class="hs-special">}</span><span> </span><span id="local-6989586621679738134"><span class="annot"><span class="annottext">Tensor requiresGradient layout device dataType shape
</span><a href="#local-6989586621679738134"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span id="local-6989586621679738133"><span class="annot"><span class="annottext">Generator generator
</span><a href="#local-6989586621679738133"><span class="hs-identifier hs-var">g</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-105"></span><span>    </span><span id="local-6989586621679738132"><span class="annot"><span class="annottext">Tensor requiresGradient layout device dataType shape'
</span><a href="#local-6989586621679738132"><span class="hs-identifier hs-var">r</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">SSelectDim selectDim
-&gt; Tensor requiresGradient layout device dataType shape
-&gt; m (Tensor requiresGradient layout device dataType shape')
forall (selectDim :: SelectDim (By Symbol Nat))
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]) (m :: * -&gt; *).
(MonadThrow m, shape' ~ SoftmaxF selectDim shape, Catch shape') =&gt;
SSelectDim selectDim
-&gt; Tensor gradient layout device dataType shape
-&gt; m (Tensor gradient layout device dataType shape')
</span><a href="Torch.GraduallyTyped.NN.Functional.NonLinearActivation.html#logSoftmax"><span class="hs-identifier hs-var">logSoftmax</span></a></span><span> </span><span class="annot"><span class="annottext">SSelectDim selectDim
</span><a href="#local-6989586621679738135"><span class="hs-identifier hs-var">logSoftmaxSelectDim</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor requiresGradient layout device dataType shape
</span><a href="#local-6989586621679738134"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-106"></span><span>    </span><span class="annot"><span class="annottext">(Tensor requiresGradient layout device dataType shape',
 Generator generator)
-&gt; m (Tensor requiresGradient layout device dataType shape',
      Generator generator)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><a href="../file:///nix/store/x3gpcfbfmnj29qsjqcir8xf4ia6lc9sw-ghc-9.0.2-doc/share/doc/ghc/html/libraries/base-4.15.1.0/src"><span class="hs-identifier hs-var">pure</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Tensor requiresGradient layout device dataType shape'
</span><a href="#local-6989586621679738132"><span class="hs-identifier hs-var">r</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Generator generator
</span><a href="#local-6989586621679738133"><span class="hs-identifier hs-var">g</span></a></span><span class="hs-special">)</span></span></span></span></span></span></span></span></span></span><span>
</span><span id="line-107"></span><span>
</span><span id="line-108"></span><span class="hs-comment">-- | 'Relu' is a step-wise linear activation function.</span><span>
</span><span id="line-109"></span><span id="local-6989586621679738130"><span id="local-6989586621679738131"></span></span><span class="hs-keyword">data</span><span> </span><span id="Relu"><span class="annot"><a href="Torch.GraduallyTyped.NN.Activation.html#Relu"><span class="hs-identifier hs-var">Relu</span></a></span></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-110"></span><span>  </span><span id="Relu"><span class="annot"><a href="Torch.GraduallyTyped.NN.Activation.html#Relu"><span class="hs-identifier hs-var">Relu</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Activation.html#Relu"><span class="hs-identifier hs-type">Relu</span></a></span><span>
</span><span id="line-111"></span><span>  </span><span class="hs-keyword">deriving</span><span> </span><span class="annot"><span class="hs-keyword">stock</span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679738125"><span id="local-6989586621679738127"><span class="annot"><span class="annottext">Relu -&gt; Relu -&gt; Bool
(Relu -&gt; Relu -&gt; Bool) -&gt; (Relu -&gt; Relu -&gt; Bool) -&gt; Eq Relu
forall a. (a -&gt; a -&gt; Bool) -&gt; (a -&gt; a -&gt; Bool) -&gt; Eq a
/= :: Relu -&gt; Relu -&gt; Bool
$c/= :: Relu -&gt; Relu -&gt; Bool
== :: Relu -&gt; Relu -&gt; Bool
$c== :: Relu -&gt; Relu -&gt; Bool
</span><a href="../file:///nix/store/x3gpcfbfmnj29qsjqcir8xf4ia6lc9sw-ghc-9.0.2-doc/share/doc/ghc/html/libraries/ghc-prim-0.7.0/src"><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var">Eq</span></a></span></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679738105"><span id="local-6989586621679738107"><span id="local-6989586621679738110"><span id="local-6989586621679738113"><span id="local-6989586621679738116"><span id="local-6989586621679738118"><span id="local-6989586621679738120"><span class="annot"><span class="annottext">Eq Relu
Eq Relu
-&gt; (Relu -&gt; Relu -&gt; Ordering)
-&gt; (Relu -&gt; Relu -&gt; Bool)
-&gt; (Relu -&gt; Relu -&gt; Bool)
-&gt; (Relu -&gt; Relu -&gt; Bool)
-&gt; (Relu -&gt; Relu -&gt; Bool)
-&gt; (Relu -&gt; Relu -&gt; Relu)
-&gt; (Relu -&gt; Relu -&gt; Relu)
-&gt; Ord Relu
Relu -&gt; Relu -&gt; Bool
Relu -&gt; Relu -&gt; Ordering
Relu -&gt; Relu -&gt; Relu
forall a.
Eq a
-&gt; (a -&gt; a -&gt; Ordering)
-&gt; (a -&gt; a -&gt; Bool)
-&gt; (a -&gt; a -&gt; Bool)
-&gt; (a -&gt; a -&gt; Bool)
-&gt; (a -&gt; a -&gt; Bool)
-&gt; (a -&gt; a -&gt; a)
-&gt; (a -&gt; a -&gt; a)
-&gt; Ord a
min :: Relu -&gt; Relu -&gt; Relu
$cmin :: Relu -&gt; Relu -&gt; Relu
max :: Relu -&gt; Relu -&gt; Relu
$cmax :: Relu -&gt; Relu -&gt; Relu
&gt;= :: Relu -&gt; Relu -&gt; Bool
$c&gt;= :: Relu -&gt; Relu -&gt; Bool
&gt; :: Relu -&gt; Relu -&gt; Bool
$c&gt; :: Relu -&gt; Relu -&gt; Bool
&lt;= :: Relu -&gt; Relu -&gt; Bool
$c&lt;= :: Relu -&gt; Relu -&gt; Bool
&lt; :: Relu -&gt; Relu -&gt; Bool
$c&lt; :: Relu -&gt; Relu -&gt; Bool
compare :: Relu -&gt; Relu -&gt; Ordering
$ccompare :: Relu -&gt; Relu -&gt; Ordering
</span><a href="../file:///nix/store/x3gpcfbfmnj29qsjqcir8xf4ia6lc9sw-ghc-9.0.2-doc/share/doc/ghc/html/libraries/ghc-prim-0.7.0/src"><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">Ord</span></a></span></span></span></span></span></span></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679738098"><span id="local-6989586621679738100"><span id="local-6989586621679738102"><span class="annot"><span class="annottext">Int -&gt; Relu -&gt; ShowS
[Relu] -&gt; ShowS
Relu -&gt; String
(Int -&gt; Relu -&gt; ShowS)
-&gt; (Relu -&gt; String) -&gt; ([Relu] -&gt; ShowS) -&gt; Show Relu
forall a.
(Int -&gt; a -&gt; ShowS) -&gt; (a -&gt; String) -&gt; ([a] -&gt; ShowS) -&gt; Show a
showList :: [Relu] -&gt; ShowS
$cshowList :: [Relu] -&gt; ShowS
show :: Relu -&gt; String
$cshow :: Relu -&gt; String
showsPrec :: Int -&gt; Relu -&gt; ShowS
$cshowsPrec :: Int -&gt; Relu -&gt; ShowS
</span><a href="../file:///nix/store/x3gpcfbfmnj29qsjqcir8xf4ia6lc9sw-ghc-9.0.2-doc/share/doc/ghc/html/libraries/base-4.15.1.0/src"><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">Show</span></a></span></span></span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">(forall x. Relu -&gt; Rep Relu x)
-&gt; (forall x. Rep Relu x -&gt; Relu) -&gt; Generic Relu
forall x. Rep Relu x -&gt; Relu
forall x. Relu -&gt; Rep Relu x
forall a.
(forall x. a -&gt; Rep a x) -&gt; (forall x. Rep a x -&gt; a) -&gt; Generic a
$cto :: forall x. Rep Relu x -&gt; Relu
$cfrom :: forall x. Relu -&gt; Rep Relu x
</span><a href="../file:///nix/store/x3gpcfbfmnj29qsjqcir8xf4ia6lc9sw-ghc-9.0.2-doc/share/doc/ghc/html/libraries/base-4.15.1.0/src"><span class="hs-identifier hs-var hs-var hs-var hs-var">Generic</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-112"></span><span>
</span><span id="line-113"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">instance</span><span> </span><span id="ModelSpec"><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier hs-var">ModelSpec</span></a></span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Activation.html#Relu"><span class="hs-identifier hs-type">Relu</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Activation.html#Relu"><span class="hs-identifier hs-type">Relu</span></a></span><span>
</span><span id="line-114"></span><span>
</span><span id="line-115"></span><span id="local-6989586621679738380"><span class="hs-keyword">instance</span><span>
</span><span id="line-116"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span>
</span><span id="line-117"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Activation.html#Relu"><span class="hs-identifier hs-type">Relu</span></a></span><span>
</span><span id="line-118"></span><span>    </span><span class="annot"><a href="#local-6989586621679738380"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-119"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Activation.html#Relu"><span class="hs-identifier hs-type">Relu</span></a></span><span>
</span><span id="line-120"></span><span>    </span><span class="annot"><a href="#local-6989586621679738380"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-121"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-122"></span><span>  </span><span id="local-6989586621679738087"><span class="annot"><span class="annottext">initialize :: forall (m :: * -&gt; *).
MonadThrow m =&gt;
ModelSpec Relu
-&gt; Generator generatorDevice -&gt; m (Relu, Generator generatorDevice)
</span><a href="#local-6989586621679738087"><span class="hs-identifier hs-var hs-var hs-var hs-var">initialize</span></a></span></span><span> </span><span id="local-6989586621679738086"><span class="annot"><span class="annottext">ModelSpec Relu
</span><a href="#local-6989586621679738086"><span class="hs-identifier hs-var">spec</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(Relu, Generator generatorDevice)
-&gt; m (Relu, Generator generatorDevice)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><a href="../file:///nix/store/x3gpcfbfmnj29qsjqcir8xf4ia6lc9sw-ghc-9.0.2-doc/share/doc/ghc/html/libraries/base-4.15.1.0/src"><span class="hs-identifier hs-var">pure</span></a></span><span> </span><span class="annot"><span class="annottext">((Relu, Generator generatorDevice)
 -&gt; m (Relu, Generator generatorDevice))
-&gt; (Generator generatorDevice -&gt; (Relu, Generator generatorDevice))
-&gt; Generator generatorDevice
-&gt; m (Relu, Generator generatorDevice)
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><a href="../file:///nix/store/x3gpcfbfmnj29qsjqcir8xf4ia6lc9sw-ghc-9.0.2-doc/share/doc/ghc/html/libraries/base-4.15.1.0/src"><span class="hs-operator hs-var">.</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">ModelSpec Relu
Relu
</span><a href="#local-6989586621679738086"><span class="hs-identifier hs-var">spec</span></a></span><span class="hs-special">,</span><span class="hs-special">)</span></span><span>
</span><span id="line-123"></span><span>
</span><span id="line-124"></span><span class="hs-keyword">instance</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasStateDict"><span class="hs-identifier hs-type">HasStateDict</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Activation.html#Relu"><span class="hs-identifier hs-type">Relu</span></a></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-125"></span><span>  </span><span id="local-6989586621679738076"><span class="annot"><span class="annottext">fromStateDict :: forall (m :: * -&gt; *).
(MonadIO m, MonadThrow m, MonadState StateDict m) =&gt;
ModelSpec Relu -&gt; StateDictKey -&gt; m Relu
</span><a href="#local-6989586621679738076"><span class="hs-identifier hs-var hs-var hs-var hs-var">fromStateDict</span></a></span></span><span> </span><span id="local-6989586621679738075"><span class="annot"><span class="annottext">ModelSpec Relu
</span><a href="#local-6989586621679738075"><span class="hs-identifier hs-var">spec</span></a></span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Relu -&gt; m Relu
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><a href="../file:///nix/store/x3gpcfbfmnj29qsjqcir8xf4ia6lc9sw-ghc-9.0.2-doc/share/doc/ghc/html/libraries/base-4.15.1.0/src"><span class="hs-identifier hs-var">pure</span></a></span><span> </span><span class="annot"><span class="annottext">ModelSpec Relu
Relu
</span><a href="#local-6989586621679738075"><span class="hs-identifier hs-var">spec</span></a></span><span>
</span><span id="line-126"></span><span>  </span><span id="local-6989586621679738069"><span class="annot"><span class="annottext">toStateDict :: forall (m :: * -&gt; *).
(MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; Relu -&gt; m ()
</span><a href="#local-6989586621679738069"><span class="hs-identifier hs-var hs-var hs-var hs-var">toStateDict</span></a></span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="annottext">Relu
</span><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">() -&gt; m ()
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><a href="../file:///nix/store/x3gpcfbfmnj29qsjqcir8xf4ia6lc9sw-ghc-9.0.2-doc/share/doc/ghc/html/libraries/base-4.15.1.0/src"><span class="hs-identifier hs-var">pure</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-127"></span><span>
</span><span id="line-128"></span><span id="local-6989586621679738365"><span id="local-6989586621679738366"><span id="local-6989586621679738367"><span id="local-6989586621679738368"><span id="local-6989586621679738369"><span id="local-6989586621679738370"><span class="hs-keyword">instance</span><span>
</span><span id="line-129"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-130"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Activation.html#Relu"><span class="hs-identifier hs-type">Relu</span></a></span><span>
</span><span id="line-131"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679738370"><span class="hs-identifier hs-type">requiresGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679738369"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679738368"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679738367"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679738366"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-132"></span><span>    </span><span class="annot"><a href="#local-6989586621679738365"><span class="hs-identifier hs-type">generator</span></a></span><span>
</span><span id="line-133"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679738370"><span class="hs-identifier hs-type">requiresGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679738369"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679738368"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679738367"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679738366"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-134"></span><span>    </span><span class="annot"><a href="#local-6989586621679738365"><span class="hs-identifier hs-type">generator</span></a></span><span>
</span><span id="line-135"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-136"></span><span>  </span><span id="local-6989586621679738062"><span class="annot"><span class="annottext">forward :: forall (m :: * -&gt; *).
MonadThrow m =&gt;
Relu
-&gt; Tensor requiresGradient layout device dataType shape
-&gt; Generator generator
-&gt; m (Tensor requiresGradient layout device dataType shape,
      Generator generator)
</span><a href="#local-6989586621679738062"><span class="hs-identifier hs-var hs-var hs-var hs-var">forward</span></a></span></span><span> </span><span class="annot"><span class="annottext">Relu
</span><a href="Torch.GraduallyTyped.NN.Activation.html#Relu"><span class="hs-identifier hs-var">Relu</span></a></span><span> </span><span id="local-6989586621679738061"><span class="annot"><span class="annottext">Tensor requiresGradient layout device dataType shape
</span><a href="#local-6989586621679738061"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(Tensor requiresGradient layout device dataType shape,
 Generator generator)
-&gt; m (Tensor requiresGradient layout device dataType shape,
      Generator generator)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><a href="../file:///nix/store/x3gpcfbfmnj29qsjqcir8xf4ia6lc9sw-ghc-9.0.2-doc/share/doc/ghc/html/libraries/base-4.15.1.0/src"><span class="hs-identifier hs-var">pure</span></a></span><span> </span><span class="annot"><span class="annottext">((Tensor requiresGradient layout device dataType shape,
  Generator generator)
 -&gt; m (Tensor requiresGradient layout device dataType shape,
       Generator generator))
-&gt; (Generator generator
    -&gt; (Tensor requiresGradient layout device dataType shape,
        Generator generator))
-&gt; Generator generator
-&gt; m (Tensor requiresGradient layout device dataType shape,
      Generator generator)
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><a href="../file:///nix/store/x3gpcfbfmnj29qsjqcir8xf4ia6lc9sw-ghc-9.0.2-doc/share/doc/ghc/html/libraries/base-4.15.1.0/src"><span class="hs-operator hs-var">.</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Tensor requiresGradient layout device dataType shape
-&gt; Tensor requiresGradient layout device dataType shape
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.NN.Functional.Activation.html#relu"><span class="hs-identifier hs-var">relu</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor requiresGradient layout device dataType shape
</span><a href="#local-6989586621679738061"><span class="hs-identifier hs-var">input</span></a></span><span class="hs-special">,</span><span class="hs-special">)</span></span></span></span></span></span></span><span>
</span><span id="line-137"></span><span>
</span><span id="line-138"></span><span class="hs-comment">-- | 'Gelu' is a non-linear activation function.</span><span>
</span><span id="line-139"></span><span id="local-6989586621679738059"><span id="local-6989586621679738060"></span></span><span class="hs-keyword">data</span><span> </span><span id="Gelu"><span class="annot"><a href="Torch.GraduallyTyped.NN.Activation.html#Gelu"><span class="hs-identifier hs-var">Gelu</span></a></span></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-140"></span><span>  </span><span id="Gelu"><span class="annot"><a href="Torch.GraduallyTyped.NN.Activation.html#Gelu"><span class="hs-identifier hs-var">Gelu</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Activation.html#Gelu"><span class="hs-identifier hs-type">Gelu</span></a></span><span>
</span><span id="line-141"></span><span>  </span><span class="hs-keyword">deriving</span><span> </span><span class="annot"><span class="hs-keyword">stock</span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679738054"><span id="local-6989586621679738056"><span class="annot"><span class="annottext">Gelu -&gt; Gelu -&gt; Bool
(Gelu -&gt; Gelu -&gt; Bool) -&gt; (Gelu -&gt; Gelu -&gt; Bool) -&gt; Eq Gelu
forall a. (a -&gt; a -&gt; Bool) -&gt; (a -&gt; a -&gt; Bool) -&gt; Eq a
/= :: Gelu -&gt; Gelu -&gt; Bool
$c/= :: Gelu -&gt; Gelu -&gt; Bool
== :: Gelu -&gt; Gelu -&gt; Bool
$c== :: Gelu -&gt; Gelu -&gt; Bool
</span><a href="../file:///nix/store/x3gpcfbfmnj29qsjqcir8xf4ia6lc9sw-ghc-9.0.2-doc/share/doc/ghc/html/libraries/ghc-prim-0.7.0/src"><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var">Eq</span></a></span></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679738035"><span id="local-6989586621679738037"><span id="local-6989586621679738040"><span id="local-6989586621679738043"><span id="local-6989586621679738046"><span id="local-6989586621679738048"><span id="local-6989586621679738050"><span class="annot"><span class="annottext">Eq Gelu
Eq Gelu
-&gt; (Gelu -&gt; Gelu -&gt; Ordering)
-&gt; (Gelu -&gt; Gelu -&gt; Bool)
-&gt; (Gelu -&gt; Gelu -&gt; Bool)
-&gt; (Gelu -&gt; Gelu -&gt; Bool)
-&gt; (Gelu -&gt; Gelu -&gt; Bool)
-&gt; (Gelu -&gt; Gelu -&gt; Gelu)
-&gt; (Gelu -&gt; Gelu -&gt; Gelu)
-&gt; Ord Gelu
Gelu -&gt; Gelu -&gt; Bool
Gelu -&gt; Gelu -&gt; Ordering
Gelu -&gt; Gelu -&gt; Gelu
forall a.
Eq a
-&gt; (a -&gt; a -&gt; Ordering)
-&gt; (a -&gt; a -&gt; Bool)
-&gt; (a -&gt; a -&gt; Bool)
-&gt; (a -&gt; a -&gt; Bool)
-&gt; (a -&gt; a -&gt; Bool)
-&gt; (a -&gt; a -&gt; a)
-&gt; (a -&gt; a -&gt; a)
-&gt; Ord a
min :: Gelu -&gt; Gelu -&gt; Gelu
$cmin :: Gelu -&gt; Gelu -&gt; Gelu
max :: Gelu -&gt; Gelu -&gt; Gelu
$cmax :: Gelu -&gt; Gelu -&gt; Gelu
&gt;= :: Gelu -&gt; Gelu -&gt; Bool
$c&gt;= :: Gelu -&gt; Gelu -&gt; Bool
&gt; :: Gelu -&gt; Gelu -&gt; Bool
$c&gt; :: Gelu -&gt; Gelu -&gt; Bool
&lt;= :: Gelu -&gt; Gelu -&gt; Bool
$c&lt;= :: Gelu -&gt; Gelu -&gt; Bool
&lt; :: Gelu -&gt; Gelu -&gt; Bool
$c&lt; :: Gelu -&gt; Gelu -&gt; Bool
compare :: Gelu -&gt; Gelu -&gt; Ordering
$ccompare :: Gelu -&gt; Gelu -&gt; Ordering
</span><a href="../file:///nix/store/x3gpcfbfmnj29qsjqcir8xf4ia6lc9sw-ghc-9.0.2-doc/share/doc/ghc/html/libraries/ghc-prim-0.7.0/src"><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">Ord</span></a></span></span></span></span></span></span></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679738029"><span id="local-6989586621679738031"><span id="local-6989586621679738033"><span class="annot"><span class="annottext">Int -&gt; Gelu -&gt; ShowS
[Gelu] -&gt; ShowS
Gelu -&gt; String
(Int -&gt; Gelu -&gt; ShowS)
-&gt; (Gelu -&gt; String) -&gt; ([Gelu] -&gt; ShowS) -&gt; Show Gelu
forall a.
(Int -&gt; a -&gt; ShowS) -&gt; (a -&gt; String) -&gt; ([a] -&gt; ShowS) -&gt; Show a
showList :: [Gelu] -&gt; ShowS
$cshowList :: [Gelu] -&gt; ShowS
show :: Gelu -&gt; String
$cshow :: Gelu -&gt; String
showsPrec :: Int -&gt; Gelu -&gt; ShowS
$cshowsPrec :: Int -&gt; Gelu -&gt; ShowS
</span><a href="../file:///nix/store/x3gpcfbfmnj29qsjqcir8xf4ia6lc9sw-ghc-9.0.2-doc/share/doc/ghc/html/libraries/base-4.15.1.0/src"><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">Show</span></a></span></span></span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">(forall x. Gelu -&gt; Rep Gelu x)
-&gt; (forall x. Rep Gelu x -&gt; Gelu) -&gt; Generic Gelu
forall x. Rep Gelu x -&gt; Gelu
forall x. Gelu -&gt; Rep Gelu x
forall a.
(forall x. a -&gt; Rep a x) -&gt; (forall x. Rep a x -&gt; a) -&gt; Generic a
$cto :: forall x. Rep Gelu x -&gt; Gelu
$cfrom :: forall x. Gelu -&gt; Rep Gelu x
</span><a href="../file:///nix/store/x3gpcfbfmnj29qsjqcir8xf4ia6lc9sw-ghc-9.0.2-doc/share/doc/ghc/html/libraries/base-4.15.1.0/src"><span class="hs-identifier hs-var hs-var hs-var hs-var">Generic</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-142"></span><span>
</span><span id="line-143"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">instance</span><span> </span><span id="ModelSpec"><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier hs-var">ModelSpec</span></a></span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Activation.html#Gelu"><span class="hs-identifier hs-type">Gelu</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Activation.html#Gelu"><span class="hs-identifier hs-type">Gelu</span></a></span><span>
</span><span id="line-144"></span><span>
</span><span id="line-145"></span><span id="local-6989586621679738357"><span class="hs-keyword">instance</span><span>
</span><span id="line-146"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span>
</span><span id="line-147"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Activation.html#Gelu"><span class="hs-identifier hs-type">Gelu</span></a></span><span>
</span><span id="line-148"></span><span>    </span><span class="annot"><a href="#local-6989586621679738357"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-149"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Activation.html#Gelu"><span class="hs-identifier hs-type">Gelu</span></a></span><span>
</span><span id="line-150"></span><span>    </span><span class="annot"><a href="#local-6989586621679738357"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-151"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-152"></span><span>  </span><span id="local-6989586621679738019"><span class="annot"><span class="annottext">initialize :: forall (m :: * -&gt; *).
MonadThrow m =&gt;
ModelSpec Gelu
-&gt; Generator generatorDevice -&gt; m (Gelu, Generator generatorDevice)
</span><a href="#local-6989586621679738019"><span class="hs-identifier hs-var hs-var hs-var hs-var">initialize</span></a></span></span><span> </span><span id="local-6989586621679738018"><span class="annot"><span class="annottext">ModelSpec Gelu
</span><a href="#local-6989586621679738018"><span class="hs-identifier hs-var">spec</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(Gelu, Generator generatorDevice)
-&gt; m (Gelu, Generator generatorDevice)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><a href="../file:///nix/store/x3gpcfbfmnj29qsjqcir8xf4ia6lc9sw-ghc-9.0.2-doc/share/doc/ghc/html/libraries/base-4.15.1.0/src"><span class="hs-identifier hs-var">pure</span></a></span><span> </span><span class="annot"><span class="annottext">((Gelu, Generator generatorDevice)
 -&gt; m (Gelu, Generator generatorDevice))
-&gt; (Generator generatorDevice -&gt; (Gelu, Generator generatorDevice))
-&gt; Generator generatorDevice
-&gt; m (Gelu, Generator generatorDevice)
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><a href="../file:///nix/store/x3gpcfbfmnj29qsjqcir8xf4ia6lc9sw-ghc-9.0.2-doc/share/doc/ghc/html/libraries/base-4.15.1.0/src"><span class="hs-operator hs-var">.</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">ModelSpec Gelu
Gelu
</span><a href="#local-6989586621679738018"><span class="hs-identifier hs-var">spec</span></a></span><span class="hs-special">,</span><span class="hs-special">)</span></span><span>
</span><span id="line-153"></span><span>
</span><span id="line-154"></span><span class="hs-keyword">instance</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasStateDict"><span class="hs-identifier hs-type">HasStateDict</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Activation.html#Gelu"><span class="hs-identifier hs-type">Gelu</span></a></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-155"></span><span>  </span><span id="local-6989586621679738008"><span class="annot"><span class="annottext">fromStateDict :: forall (m :: * -&gt; *).
(MonadIO m, MonadThrow m, MonadState StateDict m) =&gt;
ModelSpec Gelu -&gt; StateDictKey -&gt; m Gelu
</span><a href="#local-6989586621679738008"><span class="hs-identifier hs-var hs-var hs-var hs-var">fromStateDict</span></a></span></span><span> </span><span id="local-6989586621679738007"><span class="annot"><span class="annottext">ModelSpec Gelu
</span><a href="#local-6989586621679738007"><span class="hs-identifier hs-var">spec</span></a></span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Gelu -&gt; m Gelu
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><a href="../file:///nix/store/x3gpcfbfmnj29qsjqcir8xf4ia6lc9sw-ghc-9.0.2-doc/share/doc/ghc/html/libraries/base-4.15.1.0/src"><span class="hs-identifier hs-var">pure</span></a></span><span> </span><span class="annot"><span class="annottext">ModelSpec Gelu
Gelu
</span><a href="#local-6989586621679738007"><span class="hs-identifier hs-var">spec</span></a></span><span>
</span><span id="line-156"></span><span>  </span><span id="local-6989586621679738001"><span class="annot"><span class="annottext">toStateDict :: forall (m :: * -&gt; *).
(MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; Gelu -&gt; m ()
</span><a href="#local-6989586621679738001"><span class="hs-identifier hs-var hs-var hs-var hs-var">toStateDict</span></a></span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="annottext">Gelu
</span><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">() -&gt; m ()
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><a href="../file:///nix/store/x3gpcfbfmnj29qsjqcir8xf4ia6lc9sw-ghc-9.0.2-doc/share/doc/ghc/html/libraries/base-4.15.1.0/src"><span class="hs-identifier hs-var">pure</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-157"></span><span>
</span><span id="line-158"></span><span id="local-6989586621679738342"><span id="local-6989586621679738343"><span id="local-6989586621679738344"><span id="local-6989586621679738345"><span id="local-6989586621679738346"><span id="local-6989586621679738347"><span class="hs-keyword">instance</span><span>
</span><span id="line-159"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-160"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Activation.html#Gelu"><span class="hs-identifier hs-type">Gelu</span></a></span><span>
</span><span id="line-161"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679738347"><span class="hs-identifier hs-type">requiresGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679738346"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679738345"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679738344"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679738343"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-162"></span><span>    </span><span class="annot"><a href="#local-6989586621679738342"><span class="hs-identifier hs-type">generator</span></a></span><span>
</span><span id="line-163"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679738347"><span class="hs-identifier hs-type">requiresGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679738346"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679738345"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679738344"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679738343"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-164"></span><span>    </span><span class="annot"><a href="#local-6989586621679738342"><span class="hs-identifier hs-type">generator</span></a></span><span>
</span><span id="line-165"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-166"></span><span>  </span><span id="local-6989586621679737994"><span class="annot"><span class="annottext">forward :: forall (m :: * -&gt; *).
MonadThrow m =&gt;
Gelu
-&gt; Tensor requiresGradient layout device dataType shape
-&gt; Generator generator
-&gt; m (Tensor requiresGradient layout device dataType shape,
      Generator generator)
</span><a href="#local-6989586621679737994"><span class="hs-identifier hs-var hs-var hs-var hs-var">forward</span></a></span></span><span> </span><span class="annot"><span class="annottext">Gelu
</span><a href="Torch.GraduallyTyped.NN.Activation.html#Gelu"><span class="hs-identifier hs-var">Gelu</span></a></span><span> </span><span id="local-6989586621679737993"><span class="annot"><span class="annottext">Tensor requiresGradient layout device dataType shape
</span><a href="#local-6989586621679737993"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(Tensor requiresGradient layout device dataType shape,
 Generator generator)
-&gt; m (Tensor requiresGradient layout device dataType shape,
      Generator generator)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><a href="../file:///nix/store/x3gpcfbfmnj29qsjqcir8xf4ia6lc9sw-ghc-9.0.2-doc/share/doc/ghc/html/libraries/base-4.15.1.0/src"><span class="hs-identifier hs-var">pure</span></a></span><span> </span><span class="annot"><span class="annottext">((Tensor requiresGradient layout device dataType shape,
  Generator generator)
 -&gt; m (Tensor requiresGradient layout device dataType shape,
       Generator generator))
-&gt; (Generator generator
    -&gt; (Tensor requiresGradient layout device dataType shape,
        Generator generator))
-&gt; Generator generator
-&gt; m (Tensor requiresGradient layout device dataType shape,
      Generator generator)
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><a href="../file:///nix/store/x3gpcfbfmnj29qsjqcir8xf4ia6lc9sw-ghc-9.0.2-doc/share/doc/ghc/html/libraries/base-4.15.1.0/src"><span class="hs-operator hs-var">.</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Tensor requiresGradient layout device dataType shape
-&gt; Tensor requiresGradient layout device dataType shape
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.NN.Functional.Activation.html#gelu"><span class="hs-identifier hs-var">gelu</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor requiresGradient layout device dataType shape
</span><a href="#local-6989586621679737993"><span class="hs-identifier hs-var">input</span></a></span><span class="hs-special">,</span><span class="hs-special">)</span></span></span></span></span></span></span><span>
</span><span id="line-167"></span><span>
</span><span id="line-168"></span><span class="hs-comment">-- | 'GeluNew' is a non-linear activation function.</span><span>
</span><span id="line-169"></span><span class="hs-comment">-- It is a modified version of the 'Gelu' function.</span><span>
</span><span id="line-170"></span><span id="local-6989586621679737991"><span id="local-6989586621679737992"></span></span><span class="hs-keyword">data</span><span> </span><span id="GeluNew"><span class="annot"><a href="Torch.GraduallyTyped.NN.Activation.html#GeluNew"><span class="hs-identifier hs-var">GeluNew</span></a></span></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-171"></span><span>  </span><span id="GeluNew"><span class="annot"><a href="Torch.GraduallyTyped.NN.Activation.html#GeluNew"><span class="hs-identifier hs-var">GeluNew</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Activation.html#GeluNew"><span class="hs-identifier hs-type">GeluNew</span></a></span><span>
</span><span id="line-172"></span><span>  </span><span class="hs-keyword">deriving</span><span> </span><span class="annot"><span class="hs-keyword">stock</span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679737986"><span id="local-6989586621679737988"><span class="annot"><span class="annottext">GeluNew -&gt; GeluNew -&gt; Bool
(GeluNew -&gt; GeluNew -&gt; Bool)
-&gt; (GeluNew -&gt; GeluNew -&gt; Bool) -&gt; Eq GeluNew
forall a. (a -&gt; a -&gt; Bool) -&gt; (a -&gt; a -&gt; Bool) -&gt; Eq a
/= :: GeluNew -&gt; GeluNew -&gt; Bool
$c/= :: GeluNew -&gt; GeluNew -&gt; Bool
== :: GeluNew -&gt; GeluNew -&gt; Bool
$c== :: GeluNew -&gt; GeluNew -&gt; Bool
</span><a href="../file:///nix/store/x3gpcfbfmnj29qsjqcir8xf4ia6lc9sw-ghc-9.0.2-doc/share/doc/ghc/html/libraries/ghc-prim-0.7.0/src"><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var">Eq</span></a></span></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679737967"><span id="local-6989586621679737969"><span id="local-6989586621679737972"><span id="local-6989586621679737975"><span id="local-6989586621679737978"><span id="local-6989586621679737980"><span id="local-6989586621679737982"><span class="annot"><span class="annottext">Eq GeluNew
Eq GeluNew
-&gt; (GeluNew -&gt; GeluNew -&gt; Ordering)
-&gt; (GeluNew -&gt; GeluNew -&gt; Bool)
-&gt; (GeluNew -&gt; GeluNew -&gt; Bool)
-&gt; (GeluNew -&gt; GeluNew -&gt; Bool)
-&gt; (GeluNew -&gt; GeluNew -&gt; Bool)
-&gt; (GeluNew -&gt; GeluNew -&gt; GeluNew)
-&gt; (GeluNew -&gt; GeluNew -&gt; GeluNew)
-&gt; Ord GeluNew
GeluNew -&gt; GeluNew -&gt; Bool
GeluNew -&gt; GeluNew -&gt; Ordering
GeluNew -&gt; GeluNew -&gt; GeluNew
forall a.
Eq a
-&gt; (a -&gt; a -&gt; Ordering)
-&gt; (a -&gt; a -&gt; Bool)
-&gt; (a -&gt; a -&gt; Bool)
-&gt; (a -&gt; a -&gt; Bool)
-&gt; (a -&gt; a -&gt; Bool)
-&gt; (a -&gt; a -&gt; a)
-&gt; (a -&gt; a -&gt; a)
-&gt; Ord a
min :: GeluNew -&gt; GeluNew -&gt; GeluNew
$cmin :: GeluNew -&gt; GeluNew -&gt; GeluNew
max :: GeluNew -&gt; GeluNew -&gt; GeluNew
$cmax :: GeluNew -&gt; GeluNew -&gt; GeluNew
&gt;= :: GeluNew -&gt; GeluNew -&gt; Bool
$c&gt;= :: GeluNew -&gt; GeluNew -&gt; Bool
&gt; :: GeluNew -&gt; GeluNew -&gt; Bool
$c&gt; :: GeluNew -&gt; GeluNew -&gt; Bool
&lt;= :: GeluNew -&gt; GeluNew -&gt; Bool
$c&lt;= :: GeluNew -&gt; GeluNew -&gt; Bool
&lt; :: GeluNew -&gt; GeluNew -&gt; Bool
$c&lt; :: GeluNew -&gt; GeluNew -&gt; Bool
compare :: GeluNew -&gt; GeluNew -&gt; Ordering
$ccompare :: GeluNew -&gt; GeluNew -&gt; Ordering
</span><a href="../file:///nix/store/x3gpcfbfmnj29qsjqcir8xf4ia6lc9sw-ghc-9.0.2-doc/share/doc/ghc/html/libraries/ghc-prim-0.7.0/src"><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">Ord</span></a></span></span></span></span></span></span></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679737961"><span id="local-6989586621679737963"><span id="local-6989586621679737965"><span class="annot"><span class="annottext">Int -&gt; GeluNew -&gt; ShowS
[GeluNew] -&gt; ShowS
GeluNew -&gt; String
(Int -&gt; GeluNew -&gt; ShowS)
-&gt; (GeluNew -&gt; String) -&gt; ([GeluNew] -&gt; ShowS) -&gt; Show GeluNew
forall a.
(Int -&gt; a -&gt; ShowS) -&gt; (a -&gt; String) -&gt; ([a] -&gt; ShowS) -&gt; Show a
showList :: [GeluNew] -&gt; ShowS
$cshowList :: [GeluNew] -&gt; ShowS
show :: GeluNew -&gt; String
$cshow :: GeluNew -&gt; String
showsPrec :: Int -&gt; GeluNew -&gt; ShowS
$cshowsPrec :: Int -&gt; GeluNew -&gt; ShowS
</span><a href="../file:///nix/store/x3gpcfbfmnj29qsjqcir8xf4ia6lc9sw-ghc-9.0.2-doc/share/doc/ghc/html/libraries/base-4.15.1.0/src"><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">Show</span></a></span></span></span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">(forall x. GeluNew -&gt; Rep GeluNew x)
-&gt; (forall x. Rep GeluNew x -&gt; GeluNew) -&gt; Generic GeluNew
forall x. Rep GeluNew x -&gt; GeluNew
forall x. GeluNew -&gt; Rep GeluNew x
forall a.
(forall x. a -&gt; Rep a x) -&gt; (forall x. Rep a x -&gt; a) -&gt; Generic a
$cto :: forall x. Rep GeluNew x -&gt; GeluNew
$cfrom :: forall x. GeluNew -&gt; Rep GeluNew x
</span><a href="../file:///nix/store/x3gpcfbfmnj29qsjqcir8xf4ia6lc9sw-ghc-9.0.2-doc/share/doc/ghc/html/libraries/base-4.15.1.0/src"><span class="hs-identifier hs-var hs-var hs-var hs-var">Generic</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-173"></span><span>
</span><span id="line-174"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">instance</span><span> </span><span id="ModelSpec"><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier hs-var">ModelSpec</span></a></span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Activation.html#GeluNew"><span class="hs-identifier hs-type">GeluNew</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Activation.html#GeluNew"><span class="hs-identifier hs-type">GeluNew</span></a></span><span>
</span><span id="line-175"></span><span>
</span><span id="line-176"></span><span id="local-6989586621679738339"><span class="hs-keyword">instance</span><span>
</span><span id="line-177"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span>
</span><span id="line-178"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Activation.html#GeluNew"><span class="hs-identifier hs-type">GeluNew</span></a></span><span>
</span><span id="line-179"></span><span>    </span><span class="annot"><a href="#local-6989586621679738339"><span class="hs-identifier hs-type">generator</span></a></span><span>
</span><span id="line-180"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Activation.html#GeluNew"><span class="hs-identifier hs-type">GeluNew</span></a></span><span>
</span><span id="line-181"></span><span>    </span><span class="annot"><a href="#local-6989586621679738339"><span class="hs-identifier hs-type">generator</span></a></span><span>
</span><span id="line-182"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-183"></span><span>  </span><span id="local-6989586621679737951"><span class="annot"><span class="annottext">initialize :: forall (m :: * -&gt; *).
MonadThrow m =&gt;
ModelSpec GeluNew
-&gt; Generator generator -&gt; m (GeluNew, Generator generator)
</span><a href="#local-6989586621679737951"><span class="hs-identifier hs-var hs-var hs-var hs-var">initialize</span></a></span></span><span> </span><span id="local-6989586621679737950"><span class="annot"><span class="annottext">ModelSpec GeluNew
</span><a href="#local-6989586621679737950"><span class="hs-identifier hs-var">spec</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(GeluNew, Generator generator) -&gt; m (GeluNew, Generator generator)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><a href="../file:///nix/store/x3gpcfbfmnj29qsjqcir8xf4ia6lc9sw-ghc-9.0.2-doc/share/doc/ghc/html/libraries/base-4.15.1.0/src"><span class="hs-identifier hs-var">pure</span></a></span><span> </span><span class="annot"><span class="annottext">((GeluNew, Generator generator)
 -&gt; m (GeluNew, Generator generator))
-&gt; (Generator generator -&gt; (GeluNew, Generator generator))
-&gt; Generator generator
-&gt; m (GeluNew, Generator generator)
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><a href="../file:///nix/store/x3gpcfbfmnj29qsjqcir8xf4ia6lc9sw-ghc-9.0.2-doc/share/doc/ghc/html/libraries/base-4.15.1.0/src"><span class="hs-operator hs-var">.</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">ModelSpec GeluNew
GeluNew
</span><a href="#local-6989586621679737950"><span class="hs-identifier hs-var">spec</span></a></span><span class="hs-special">,</span><span class="hs-special">)</span></span><span>
</span><span id="line-184"></span><span>
</span><span id="line-185"></span><span class="hs-keyword">instance</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasStateDict"><span class="hs-identifier hs-type">HasStateDict</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Activation.html#GeluNew"><span class="hs-identifier hs-type">GeluNew</span></a></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-186"></span><span>  </span><span id="local-6989586621679737940"><span class="annot"><span class="annottext">fromStateDict :: forall (m :: * -&gt; *).
(MonadIO m, MonadThrow m, MonadState StateDict m) =&gt;
ModelSpec GeluNew -&gt; StateDictKey -&gt; m GeluNew
</span><a href="#local-6989586621679737940"><span class="hs-identifier hs-var hs-var hs-var hs-var">fromStateDict</span></a></span></span><span> </span><span id="local-6989586621679737939"><span class="annot"><span class="annottext">ModelSpec GeluNew
</span><a href="#local-6989586621679737939"><span class="hs-identifier hs-var">spec</span></a></span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">GeluNew -&gt; m GeluNew
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><a href="../file:///nix/store/x3gpcfbfmnj29qsjqcir8xf4ia6lc9sw-ghc-9.0.2-doc/share/doc/ghc/html/libraries/base-4.15.1.0/src"><span class="hs-identifier hs-var">pure</span></a></span><span> </span><span class="annot"><span class="annottext">ModelSpec GeluNew
GeluNew
</span><a href="#local-6989586621679737939"><span class="hs-identifier hs-var">spec</span></a></span><span>
</span><span id="line-187"></span><span>  </span><span id="local-6989586621679737933"><span class="annot"><span class="annottext">toStateDict :: forall (m :: * -&gt; *).
(MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; GeluNew -&gt; m ()
</span><a href="#local-6989586621679737933"><span class="hs-identifier hs-var hs-var hs-var hs-var">toStateDict</span></a></span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="annottext">GeluNew
</span><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">() -&gt; m ()
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><a href="../file:///nix/store/x3gpcfbfmnj29qsjqcir8xf4ia6lc9sw-ghc-9.0.2-doc/share/doc/ghc/html/libraries/base-4.15.1.0/src"><span class="hs-identifier hs-var">pure</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-188"></span><span>
</span><span id="line-189"></span><span id="local-6989586621679738324"><span id="local-6989586621679738325"><span id="local-6989586621679738326"><span id="local-6989586621679738327"><span id="local-6989586621679738328"><span id="local-6989586621679738329"><span class="hs-keyword">instance</span><span>
</span><span id="line-190"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-191"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Activation.html#GeluNew"><span class="hs-identifier hs-type">GeluNew</span></a></span><span>
</span><span id="line-192"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679738329"><span class="hs-identifier hs-type">requiresGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679738328"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679738327"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679738326"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679738325"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-193"></span><span>    </span><span class="annot"><a href="#local-6989586621679738324"><span class="hs-identifier hs-type">generator</span></a></span><span>
</span><span id="line-194"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679738329"><span class="hs-identifier hs-type">requiresGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679738328"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679738327"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679738326"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679738325"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-195"></span><span>    </span><span class="annot"><a href="#local-6989586621679738324"><span class="hs-identifier hs-type">generator</span></a></span><span>
</span><span id="line-196"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-197"></span><span>  </span><span id="local-6989586621679737924"><span class="annot"><span class="annottext">forward :: forall (m :: * -&gt; *).
MonadThrow m =&gt;
GeluNew
-&gt; Tensor requiresGradient layout device dataType shape
-&gt; Generator generator
-&gt; m (Tensor requiresGradient layout device dataType shape,
      Generator generator)
</span><a href="#local-6989586621679737924"><span class="hs-identifier hs-var hs-var hs-var hs-var">forward</span></a></span></span><span> </span><span class="annot"><span class="annottext">GeluNew
</span><a href="Torch.GraduallyTyped.NN.Activation.html#GeluNew"><span class="hs-identifier hs-var">GeluNew</span></a></span><span> </span><span id="local-6989586621679737923"><span class="annot"><span class="annottext">Tensor requiresGradient layout device dataType shape
</span><a href="#local-6989586621679737923"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span id="local-6989586621679737922"><span class="annot"><span class="annottext">Generator generator
</span><a href="#local-6989586621679737922"><span class="hs-identifier hs-var">g</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-198"></span><span>    </span><span id="local-6989586621679737921"><span class="annot"><span class="annottext">Tensor requiresGradient layout device dataType shape
</span><a href="#local-6989586621679737921"><span class="hs-identifier hs-var">output</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">Tensor requiresGradient layout device dataType shape
-&gt; m (Tensor requiresGradient layout device dataType shape)
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]) (m :: * -&gt; *).
MonadThrow m =&gt;
Tensor gradient layout device dataType shape
-&gt; m (Tensor gradient layout device dataType shape)
</span><a href="Torch.GraduallyTyped.NN.Functional.Activation.html#geluNew"><span class="hs-identifier hs-var">geluNew</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor requiresGradient layout device dataType shape
</span><a href="#local-6989586621679737923"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-199"></span><span>    </span><span class="annot"><span class="annottext">(Tensor requiresGradient layout device dataType shape,
 Generator generator)
-&gt; m (Tensor requiresGradient layout device dataType shape,
      Generator generator)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><a href="../file:///nix/store/x3gpcfbfmnj29qsjqcir8xf4ia6lc9sw-ghc-9.0.2-doc/share/doc/ghc/html/libraries/base-4.15.1.0/src"><span class="hs-identifier hs-var">pure</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Tensor requiresGradient layout device dataType shape
</span><a href="#local-6989586621679737921"><span class="hs-identifier hs-var">output</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Generator generator
</span><a href="#local-6989586621679737922"><span class="hs-identifier hs-var">g</span></a></span><span class="hs-special">)</span></span></span></span></span></span></span><span>
</span><span id="line-200"></span><span>
</span><span id="line-201"></span><span class="hs-comment">-- | 'Tanh' is a non-linear activation function.</span><span>
</span><span id="line-202"></span><span id="local-6989586621679737919"><span id="local-6989586621679737920"></span></span><span class="hs-keyword">data</span><span> </span><span id="Tanh"><span class="annot"><a href="Torch.GraduallyTyped.NN.Activation.html#Tanh"><span class="hs-identifier hs-var">Tanh</span></a></span></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-203"></span><span>  </span><span id="Tanh"><span class="annot"><a href="Torch.GraduallyTyped.NN.Activation.html#Tanh"><span class="hs-identifier hs-var">Tanh</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Activation.html#Tanh"><span class="hs-identifier hs-type">Tanh</span></a></span><span>
</span><span id="line-204"></span><span>  </span><span class="hs-keyword">deriving</span><span> </span><span class="annot"><span class="hs-keyword">stock</span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679737914"><span id="local-6989586621679737916"><span class="annot"><span class="annottext">Tanh -&gt; Tanh -&gt; Bool
(Tanh -&gt; Tanh -&gt; Bool) -&gt; (Tanh -&gt; Tanh -&gt; Bool) -&gt; Eq Tanh
forall a. (a -&gt; a -&gt; Bool) -&gt; (a -&gt; a -&gt; Bool) -&gt; Eq a
/= :: Tanh -&gt; Tanh -&gt; Bool
$c/= :: Tanh -&gt; Tanh -&gt; Bool
== :: Tanh -&gt; Tanh -&gt; Bool
$c== :: Tanh -&gt; Tanh -&gt; Bool
</span><a href="../file:///nix/store/x3gpcfbfmnj29qsjqcir8xf4ia6lc9sw-ghc-9.0.2-doc/share/doc/ghc/html/libraries/ghc-prim-0.7.0/src"><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var">Eq</span></a></span></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679737895"><span id="local-6989586621679737897"><span id="local-6989586621679737900"><span id="local-6989586621679737903"><span id="local-6989586621679737906"><span id="local-6989586621679737908"><span id="local-6989586621679737910"><span class="annot"><span class="annottext">Eq Tanh
Eq Tanh
-&gt; (Tanh -&gt; Tanh -&gt; Ordering)
-&gt; (Tanh -&gt; Tanh -&gt; Bool)
-&gt; (Tanh -&gt; Tanh -&gt; Bool)
-&gt; (Tanh -&gt; Tanh -&gt; Bool)
-&gt; (Tanh -&gt; Tanh -&gt; Bool)
-&gt; (Tanh -&gt; Tanh -&gt; Tanh)
-&gt; (Tanh -&gt; Tanh -&gt; Tanh)
-&gt; Ord Tanh
Tanh -&gt; Tanh -&gt; Bool
Tanh -&gt; Tanh -&gt; Ordering
Tanh -&gt; Tanh -&gt; Tanh
forall a.
Eq a
-&gt; (a -&gt; a -&gt; Ordering)
-&gt; (a -&gt; a -&gt; Bool)
-&gt; (a -&gt; a -&gt; Bool)
-&gt; (a -&gt; a -&gt; Bool)
-&gt; (a -&gt; a -&gt; Bool)
-&gt; (a -&gt; a -&gt; a)
-&gt; (a -&gt; a -&gt; a)
-&gt; Ord a
min :: Tanh -&gt; Tanh -&gt; Tanh
$cmin :: Tanh -&gt; Tanh -&gt; Tanh
max :: Tanh -&gt; Tanh -&gt; Tanh
$cmax :: Tanh -&gt; Tanh -&gt; Tanh
&gt;= :: Tanh -&gt; Tanh -&gt; Bool
$c&gt;= :: Tanh -&gt; Tanh -&gt; Bool
&gt; :: Tanh -&gt; Tanh -&gt; Bool
$c&gt; :: Tanh -&gt; Tanh -&gt; Bool
&lt;= :: Tanh -&gt; Tanh -&gt; Bool
$c&lt;= :: Tanh -&gt; Tanh -&gt; Bool
&lt; :: Tanh -&gt; Tanh -&gt; Bool
$c&lt; :: Tanh -&gt; Tanh -&gt; Bool
compare :: Tanh -&gt; Tanh -&gt; Ordering
$ccompare :: Tanh -&gt; Tanh -&gt; Ordering
</span><a href="../file:///nix/store/x3gpcfbfmnj29qsjqcir8xf4ia6lc9sw-ghc-9.0.2-doc/share/doc/ghc/html/libraries/ghc-prim-0.7.0/src"><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">Ord</span></a></span></span></span></span></span></span></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679737889"><span id="local-6989586621679737891"><span id="local-6989586621679737893"><span class="annot"><span class="annottext">Int -&gt; Tanh -&gt; ShowS
[Tanh] -&gt; ShowS
Tanh -&gt; String
(Int -&gt; Tanh -&gt; ShowS)
-&gt; (Tanh -&gt; String) -&gt; ([Tanh] -&gt; ShowS) -&gt; Show Tanh
forall a.
(Int -&gt; a -&gt; ShowS) -&gt; (a -&gt; String) -&gt; ([a] -&gt; ShowS) -&gt; Show a
showList :: [Tanh] -&gt; ShowS
$cshowList :: [Tanh] -&gt; ShowS
show :: Tanh -&gt; String
$cshow :: Tanh -&gt; String
showsPrec :: Int -&gt; Tanh -&gt; ShowS
$cshowsPrec :: Int -&gt; Tanh -&gt; ShowS
</span><a href="../file:///nix/store/x3gpcfbfmnj29qsjqcir8xf4ia6lc9sw-ghc-9.0.2-doc/share/doc/ghc/html/libraries/base-4.15.1.0/src"><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">Show</span></a></span></span></span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">(forall x. Tanh -&gt; Rep Tanh x)
-&gt; (forall x. Rep Tanh x -&gt; Tanh) -&gt; Generic Tanh
forall x. Rep Tanh x -&gt; Tanh
forall x. Tanh -&gt; Rep Tanh x
forall a.
(forall x. a -&gt; Rep a x) -&gt; (forall x. Rep a x -&gt; a) -&gt; Generic a
$cto :: forall x. Rep Tanh x -&gt; Tanh
$cfrom :: forall x. Tanh -&gt; Rep Tanh x
</span><a href="../file:///nix/store/x3gpcfbfmnj29qsjqcir8xf4ia6lc9sw-ghc-9.0.2-doc/share/doc/ghc/html/libraries/base-4.15.1.0/src"><span class="hs-identifier hs-var hs-var hs-var hs-var">Generic</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-205"></span><span>
</span><span id="line-206"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">instance</span><span> </span><span id="ModelSpec"><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier hs-var">ModelSpec</span></a></span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Activation.html#Tanh"><span class="hs-identifier hs-type">Tanh</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Activation.html#Tanh"><span class="hs-identifier hs-type">Tanh</span></a></span><span>
</span><span id="line-207"></span><span>
</span><span id="line-208"></span><span id="local-6989586621679738315"><span class="hs-keyword">instance</span><span>
</span><span id="line-209"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span>
</span><span id="line-210"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Activation.html#Tanh"><span class="hs-identifier hs-type">Tanh</span></a></span><span>
</span><span id="line-211"></span><span>    </span><span class="annot"><a href="#local-6989586621679738315"><span class="hs-identifier hs-type">generator</span></a></span><span>
</span><span id="line-212"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Activation.html#Tanh"><span class="hs-identifier hs-type">Tanh</span></a></span><span>
</span><span id="line-213"></span><span>    </span><span class="annot"><a href="#local-6989586621679738315"><span class="hs-identifier hs-type">generator</span></a></span><span>
</span><span id="line-214"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-215"></span><span>  </span><span id="local-6989586621679737879"><span class="annot"><span class="annottext">initialize :: forall (m :: * -&gt; *).
MonadThrow m =&gt;
ModelSpec Tanh
-&gt; Generator generator -&gt; m (Tanh, Generator generator)
</span><a href="#local-6989586621679737879"><span class="hs-identifier hs-var hs-var hs-var hs-var">initialize</span></a></span></span><span> </span><span id="local-6989586621679737878"><span class="annot"><span class="annottext">ModelSpec Tanh
</span><a href="#local-6989586621679737878"><span class="hs-identifier hs-var">spec</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(Tanh, Generator generator) -&gt; m (Tanh, Generator generator)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><a href="../file:///nix/store/x3gpcfbfmnj29qsjqcir8xf4ia6lc9sw-ghc-9.0.2-doc/share/doc/ghc/html/libraries/base-4.15.1.0/src"><span class="hs-identifier hs-var">pure</span></a></span><span> </span><span class="annot"><span class="annottext">((Tanh, Generator generator) -&gt; m (Tanh, Generator generator))
-&gt; (Generator generator -&gt; (Tanh, Generator generator))
-&gt; Generator generator
-&gt; m (Tanh, Generator generator)
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><a href="../file:///nix/store/x3gpcfbfmnj29qsjqcir8xf4ia6lc9sw-ghc-9.0.2-doc/share/doc/ghc/html/libraries/base-4.15.1.0/src"><span class="hs-operator hs-var">.</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">ModelSpec Tanh
Tanh
</span><a href="#local-6989586621679737878"><span class="hs-identifier hs-var">spec</span></a></span><span class="hs-special">,</span><span class="hs-special">)</span></span><span>
</span><span id="line-216"></span><span>
</span><span id="line-217"></span><span class="hs-keyword">instance</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasStateDict"><span class="hs-identifier hs-type">HasStateDict</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Activation.html#Tanh"><span class="hs-identifier hs-type">Tanh</span></a></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-218"></span><span>  </span><span id="local-6989586621679737868"><span class="annot"><span class="annottext">fromStateDict :: forall (m :: * -&gt; *).
(MonadIO m, MonadThrow m, MonadState StateDict m) =&gt;
ModelSpec Tanh -&gt; StateDictKey -&gt; m Tanh
</span><a href="#local-6989586621679737868"><span class="hs-identifier hs-var hs-var hs-var hs-var">fromStateDict</span></a></span></span><span> </span><span id="local-6989586621679737867"><span class="annot"><span class="annottext">ModelSpec Tanh
</span><a href="#local-6989586621679737867"><span class="hs-identifier hs-var">spec</span></a></span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tanh -&gt; m Tanh
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><a href="../file:///nix/store/x3gpcfbfmnj29qsjqcir8xf4ia6lc9sw-ghc-9.0.2-doc/share/doc/ghc/html/libraries/base-4.15.1.0/src"><span class="hs-identifier hs-var">pure</span></a></span><span> </span><span class="annot"><span class="annottext">ModelSpec Tanh
Tanh
</span><a href="#local-6989586621679737867"><span class="hs-identifier hs-var">spec</span></a></span><span>
</span><span id="line-219"></span><span>  </span><span id="local-6989586621679737861"><span class="annot"><span class="annottext">toStateDict :: forall (m :: * -&gt; *).
(MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; Tanh -&gt; m ()
</span><a href="#local-6989586621679737861"><span class="hs-identifier hs-var hs-var hs-var hs-var">toStateDict</span></a></span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="annottext">Tanh
</span><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">() -&gt; m ()
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><a href="../file:///nix/store/x3gpcfbfmnj29qsjqcir8xf4ia6lc9sw-ghc-9.0.2-doc/share/doc/ghc/html/libraries/base-4.15.1.0/src"><span class="hs-identifier hs-var">pure</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-220"></span><span>
</span><span id="line-221"></span><span id="local-6989586621679738300"><span id="local-6989586621679738301"><span id="local-6989586621679738302"><span id="local-6989586621679738303"><span id="local-6989586621679738304"><span id="local-6989586621679738305"><span class="hs-keyword">instance</span><span>
</span><span id="line-222"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-223"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Activation.html#Tanh"><span class="hs-identifier hs-type">Tanh</span></a></span><span>
</span><span id="line-224"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679738305"><span class="hs-identifier hs-type">requiresGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679738304"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679738303"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679738302"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679738301"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-225"></span><span>    </span><span class="annot"><a href="#local-6989586621679738300"><span class="hs-identifier hs-type">generator</span></a></span><span>
</span><span id="line-226"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679738305"><span class="hs-identifier hs-type">requiresGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679738304"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679738303"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679738302"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679738301"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-227"></span><span>    </span><span class="annot"><a href="#local-6989586621679738300"><span class="hs-identifier hs-type">generator</span></a></span><span>
</span><span id="line-228"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-229"></span><span>  </span><span id="local-6989586621679737854"><span class="annot"><span class="annottext">forward :: forall (m :: * -&gt; *).
MonadThrow m =&gt;
Tanh
-&gt; Tensor requiresGradient layout device dataType shape
-&gt; Generator generator
-&gt; m (Tensor requiresGradient layout device dataType shape,
      Generator generator)
</span><a href="#local-6989586621679737854"><span class="hs-identifier hs-var hs-var hs-var hs-var">forward</span></a></span></span><span> </span><span class="annot"><span class="annottext">Tanh
</span><a href="Torch.GraduallyTyped.NN.Activation.html#Tanh"><span class="hs-identifier hs-var">Tanh</span></a></span><span> </span><span id="local-6989586621679737853"><span class="annot"><span class="annottext">Tensor requiresGradient layout device dataType shape
</span><a href="#local-6989586621679737853"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(Tensor requiresGradient layout device dataType shape,
 Generator generator)
-&gt; m (Tensor requiresGradient layout device dataType shape,
      Generator generator)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><a href="../file:///nix/store/x3gpcfbfmnj29qsjqcir8xf4ia6lc9sw-ghc-9.0.2-doc/share/doc/ghc/html/libraries/base-4.15.1.0/src"><span class="hs-identifier hs-var">pure</span></a></span><span> </span><span class="annot"><span class="annottext">((Tensor requiresGradient layout device dataType shape,
  Generator generator)
 -&gt; m (Tensor requiresGradient layout device dataType shape,
       Generator generator))
-&gt; (Generator generator
    -&gt; (Tensor requiresGradient layout device dataType shape,
        Generator generator))
-&gt; Generator generator
-&gt; m (Tensor requiresGradient layout device dataType shape,
      Generator generator)
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><a href="../file:///nix/store/x3gpcfbfmnj29qsjqcir8xf4ia6lc9sw-ghc-9.0.2-doc/share/doc/ghc/html/libraries/base-4.15.1.0/src"><span class="hs-operator hs-var">.</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Tensor requiresGradient layout device dataType shape
-&gt; Tensor requiresGradient layout device dataType shape
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#tanh"><span class="hs-identifier hs-var">tanh</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor requiresGradient layout device dataType shape
</span><a href="#local-6989586621679737853"><span class="hs-identifier hs-var">input</span></a></span><span class="hs-special">,</span><span class="hs-special">)</span></span></span></span></span></span></span><span>
</span><span id="line-230"></span></pre></body></html>