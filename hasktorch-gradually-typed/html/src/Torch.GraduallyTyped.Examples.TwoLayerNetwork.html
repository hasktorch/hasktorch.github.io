<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><link rel="stylesheet" type="text/css" href="style.css" /><script type="text/javascript" src="highlight.js"></script></head><body><pre><span class="hs-pragma">{-# LANGUAGE DataKinds #-}</span><span>
</span><span id="line-2"></span><span class="hs-pragma">{-# LANGUAGE DeriveGeneric #-}</span><span>
</span><span id="line-3"></span><span class="hs-pragma">{-# LANGUAGE DerivingStrategies #-}</span><span>
</span><span id="line-4"></span><span class="hs-pragma">{-# LANGUAGE FlexibleContexts #-}</span><span>
</span><span id="line-5"></span><span class="hs-pragma">{-# LANGUAGE FlexibleInstances #-}</span><span>
</span><span id="line-6"></span><span class="hs-pragma">{-# LANGUAGE GADTs #-}</span><span>
</span><span id="line-7"></span><span class="hs-pragma">{-# LANGUAGE MultiParamTypeClasses #-}</span><span>
</span><span id="line-8"></span><span class="hs-pragma">{-# LANGUAGE NamedFieldPuns #-}</span><span>
</span><span id="line-9"></span><span class="hs-pragma">{-# LANGUAGE OverloadedStrings #-}</span><span>
</span><span id="line-10"></span><span class="hs-pragma">{-# LANGUAGE PartialTypeSignatures #-}</span><span>
</span><span id="line-11"></span><span class="hs-pragma">{-# LANGUAGE RankNTypes #-}</span><span>
</span><span id="line-12"></span><span class="hs-pragma">{-# LANGUAGE RecordWildCards #-}</span><span>
</span><span id="line-13"></span><span class="hs-pragma">{-# LANGUAGE ScopedTypeVariables #-}</span><span>
</span><span id="line-14"></span><span class="hs-pragma">{-# LANGUAGE TypeApplications #-}</span><span>
</span><span id="line-15"></span><span class="hs-pragma">{-# LANGUAGE TypeFamilies #-}</span><span>
</span><span id="line-16"></span><span class="hs-pragma">{-# LANGUAGE TypeOperators #-}</span><span>
</span><span id="line-17"></span><span class="hs-pragma">{-# LANGUAGE UndecidableInstances #-}</span><span>
</span><span id="line-18"></span><span>
</span><span id="line-19"></span><span class="hs-keyword">module</span><span> </span><span class="hs-identifier">Torch.GraduallyTyped.Examples.TwoLayerNetwork</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-20"></span><span>
</span><span id="line-21"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/48s8mi00b2kvxgar4z446h72vmm1c3v3-lens-lib-lens-5.0.1-haddock-doc/share/doc/lens/html/src"><span class="hs-identifier">Control.Lens</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/48s8mi00b2kvxgar4z446h72vmm1c3v3-lens-lib-lens-5.0.1-haddock-doc/share/doc/lens/html/src"><span class="hs-identifier">element</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../file:///nix/store/48s8mi00b2kvxgar4z446h72vmm1c3v3-lens-lib-lens-5.0.1-haddock-doc/share/doc/lens/html/src"><span class="hs-operator">(^?)</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-22"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">Control.Monad</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier">replicateM</span></span><span class="hs-special">)</span><span>
</span><span id="line-23"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">Control.Monad.Cont</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier">ContT</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier">runContT</span></span><span class="hs-special">)</span><span>
</span><span id="line-24"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">Control.Monad.IO.Class</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier">MonadIO</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier">liftIO</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-25"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">Control.Monad.State</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier">MonadState</span></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier">StateT</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier">evalStateT</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier">gets</span></span><span class="hs-special">)</span><span>
</span><span id="line-26"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">Control.Monad.Trans</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier">MonadTrans</span></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-27"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/h1pd6gy8cjy2zwwf9bl5ni48j4q56732-normaldistribution-lib-normaldistribution-1.1.0.3-haddock-doc/share/doc/normaldistribution/html/src"><span class="hs-identifier">Data.Random.Normal</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/h1pd6gy8cjy2zwwf9bl5ni48j4q56732-normaldistribution-lib-normaldistribution-1.1.0.3-haddock-doc/share/doc/normaldistribution/html/src"><span class="hs-identifier">normal</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-28"></span><span class="hs-keyword">import</span><span> </span><span class="hs-keyword">qualified</span><span> </span><span class="annot"><span class="hs-identifier">Data.Set</span></span><span> </span><span class="hs-keyword">as</span><span> </span><span class="annot"><span class="hs-identifier">Set</span></span><span>
</span><span id="line-29"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">Data.Text</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier">Text</span></span><span class="hs-special">)</span><span>
</span><span id="line-30"></span><span class="hs-keyword">import</span><span> </span><span class="hs-keyword">qualified</span><span> </span><span class="annot"><a href="../file:///nix/store/33j53czfh9iaqr8w1k6rjcna7zg8rw55-vector-sized-lib-vector-sized-1.4.3.1-haddock-doc/share/doc/vector-sized/html/src"><span class="hs-identifier">Data.Vector.Sized</span></a></span><span> </span><span class="hs-keyword">as</span><span> </span><span class="annot"><span class="hs-identifier">VS</span></span><span>
</span><span id="line-31"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">GHC.Generics</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier">Generic</span></span><span class="hs-special">)</span><span>
</span><span id="line-32"></span><span class="hs-keyword">import</span><span> </span><span class="hs-keyword">qualified</span><span> </span><span class="annot"><a href="../file:///nix/store/2275zkfvd9na2mx7hmkq7wzrgjyxz84l-pipes-lib-pipes-4.3.15-haddock-doc/share/doc/pipes/html/src"><span class="hs-identifier">Pipes</span></a></span><span> </span><span class="hs-keyword">as</span><span> </span><span class="annot"><span class="hs-identifier">P</span></span><span>
</span><span id="line-33"></span><span class="hs-keyword">import</span><span> </span><span class="hs-keyword">qualified</span><span> </span><span class="annot"><a href="../file:///nix/store/gi3ii02mxr2l6qd73gq29asx1kn1yvi3-pipes-concurrency-lib-pipes-concurrency-2.0.12-haddock-doc/share/doc/pipes-concurrency/html/src"><span class="hs-identifier">Pipes.Concurrent</span></a></span><span> </span><span class="hs-keyword">as</span><span> </span><span class="annot"><span class="hs-identifier">P</span></span><span>
</span><span id="line-34"></span><span class="hs-keyword">import</span><span> </span><span class="hs-keyword">qualified</span><span> </span><span class="annot"><a href="../file:///nix/store/2275zkfvd9na2mx7hmkq7wzrgjyxz84l-pipes-lib-pipes-4.3.15-haddock-doc/share/doc/pipes/html/src"><span class="hs-identifier">Pipes.Prelude</span></a></span><span> </span><span class="hs-keyword">as</span><span> </span><span class="annot"><span class="hs-identifier">P</span></span><span>
</span><span id="line-35"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/fv40valsp1qi9dy3snb8jgiq0a9h8rjk-random-lib-random-1.2.0-haddock-doc/share/doc/random/html/src"><span class="hs-identifier">System.Random</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/fv40valsp1qi9dy3snb8jgiq0a9h8rjk-random-lib-random-1.2.0-haddock-doc/share/doc/random/html/src"><span class="hs-identifier">Random</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../file:///nix/store/fv40valsp1qi9dy3snb8jgiq0a9h8rjk-random-lib-random-1.2.0-haddock-doc/share/doc/random/html/src"><span class="hs-identifier">RandomGen</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../file:///nix/store/fv40valsp1qi9dy3snb8jgiq0a9h8rjk-random-lib-random-1.2.0-haddock-doc/share/doc/random/html/src"><span class="hs-identifier">getStdGen</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-36"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.html"><span class="hs-identifier">Torch.GraduallyTyped</span></a></span><span>
</span><span id="line-37"></span><span>
</span><span id="line-38"></span><span class="hs-comment">-- | Compute the sine cardinal (sinc) function,</span><span>
</span><span id="line-39"></span><span class="hs-comment">-- see https://mathworld.wolfram.com/SincFunction.html.</span><span>
</span><span id="line-40"></span><span id="local-6989586621679664133"><span class="annot"><a href="Torch.GraduallyTyped.Examples.TwoLayerNetwork.html#sinc"><span class="hs-identifier hs-type">sinc</span></a></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Floating</span></span><span> </span><span class="annot"><a href="#local-6989586621679664133"><span class="hs-identifier hs-type">a</span></a></span><span> </span><span class="hs-glyph">=&gt;</span><span> </span><span class="annot"><a href="#local-6989586621679664133"><span class="hs-identifier hs-type">a</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="#local-6989586621679664133"><span class="hs-identifier hs-type">a</span></a></span></span><span>
</span><span id="line-41"></span><span id="sinc"><span class="annot"><span class="annottext">sinc :: a -&gt; a
</span><a href="Torch.GraduallyTyped.Examples.TwoLayerNetwork.html#sinc"><span class="hs-identifier hs-var hs-var">sinc</span></a></span></span><span> </span><span id="local-6989586621679664131"><span class="annot"><span class="annottext">a
</span><a href="#local-6989586621679664131"><span class="hs-identifier hs-var">a</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">a -&gt; a
forall a. Floating a =&gt; a -&gt; a
</span><span class="hs-identifier hs-var">Prelude.sin</span></span><span> </span><span class="annot"><span class="annottext">a
</span><a href="#local-6989586621679664131"><span class="hs-identifier hs-var">a</span></a></span><span> </span><span class="annot"><span class="annottext">a -&gt; a -&gt; a
forall a. Fractional a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">/</span></span><span> </span><span class="annot"><span class="annottext">a
</span><a href="#local-6989586621679664131"><span class="hs-identifier hs-var">a</span></a></span><span>
</span><span id="line-42"></span><span>
</span><span id="line-43"></span><span class="hs-comment">-- | Compute the sine cardinal (sinc) function and add normally distributed noise</span><span>
</span><span id="line-44"></span><span class="hs-comment">-- of strength epsilon. We use the 'normal' function from 'Data.Random.Normal'</span><span>
</span><span id="line-45"></span><span class="hs-comment">-- which requires a random number generator with 'RandomGen' instance.</span><span>
</span><span id="line-46"></span><span id="local-6989586621679664475"><span id="local-6989586621679664476"><span class="annot"><a href="Torch.GraduallyTyped.Examples.TwoLayerNetwork.html#noisySinc"><span class="hs-identifier hs-type">noisySinc</span></a></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">Floating</span></span><span> </span><span class="annot"><a href="#local-6989586621679664476"><span class="hs-identifier hs-type">a</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../file:///nix/store/fv40valsp1qi9dy3snb8jgiq0a9h8rjk-random-lib-random-1.2.0-haddock-doc/share/doc/random/html/src"><span class="hs-identifier hs-type">Random</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679664476"><span class="hs-identifier hs-type">a</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../file:///nix/store/fv40valsp1qi9dy3snb8jgiq0a9h8rjk-random-lib-random-1.2.0-haddock-doc/share/doc/random/html/src"><span class="hs-identifier hs-type">RandomGen</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679664475"><span class="hs-identifier hs-type">g</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span> </span><span class="annot"><a href="#local-6989586621679664476"><span class="hs-identifier hs-type">a</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="#local-6989586621679664476"><span class="hs-identifier hs-type">a</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="#local-6989586621679664475"><span class="hs-identifier hs-type">g</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679664476"><span class="hs-identifier hs-type">a</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679664475"><span class="hs-identifier hs-type">g</span></a></span><span class="hs-special">)</span></span></span><span>
</span><span id="line-47"></span><span id="noisySinc"><span class="annot"><span class="annottext">noisySinc :: a -&gt; a -&gt; g -&gt; (a, g)
</span><a href="Torch.GraduallyTyped.Examples.TwoLayerNetwork.html#noisySinc"><span class="hs-identifier hs-var hs-var">noisySinc</span></a></span></span><span> </span><span id="local-6989586621679664127"><span class="annot"><span class="annottext">a
</span><a href="#local-6989586621679664127"><span class="hs-identifier hs-var">eps</span></a></span></span><span> </span><span id="local-6989586621679664126"><span class="annot"><span class="annottext">a
</span><a href="#local-6989586621679664126"><span class="hs-identifier hs-var">a</span></a></span></span><span> </span><span id="local-6989586621679664125"><span class="annot"><span class="annottext">g
</span><a href="#local-6989586621679664125"><span class="hs-identifier hs-var">g</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">let</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679664124"><span class="annot"><span class="annottext">a
</span><a href="#local-6989586621679664124"><span class="hs-identifier hs-var">noise</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679664123"><span class="annot"><span class="annottext">g
</span><a href="#local-6989586621679664123"><span class="hs-identifier hs-var">g'</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">g -&gt; (a, g)
forall g a. (RandomGen g, Random a, Floating a) =&gt; g -&gt; (a, g)
</span><a href="../file:///nix/store/h1pd6gy8cjy2zwwf9bl5ni48j4q56732-normaldistribution-lib-normaldistribution-1.1.0.3-haddock-doc/share/doc/normaldistribution/html/src"><span class="hs-identifier hs-var">normal</span></a></span><span> </span><span class="annot"><span class="annottext">g
</span><a href="#local-6989586621679664125"><span class="hs-identifier hs-var">g</span></a></span><span> </span><span class="hs-keyword">in</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">a -&gt; a
forall a. Floating a =&gt; a -&gt; a
</span><a href="Torch.GraduallyTyped.Examples.TwoLayerNetwork.html#sinc"><span class="hs-identifier hs-var">sinc</span></a></span><span> </span><span class="annot"><span class="annottext">a
</span><a href="#local-6989586621679664126"><span class="hs-identifier hs-var">a</span></a></span><span> </span><span class="annot"><span class="annottext">a -&gt; a -&gt; a
forall a. Num a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">+</span></span><span> </span><span class="annot"><span class="annottext">a
</span><a href="#local-6989586621679664127"><span class="hs-identifier hs-var">eps</span></a></span><span> </span><span class="annot"><span class="annottext">a -&gt; a -&gt; a
forall a. Num a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">*</span></span><span> </span><span class="annot"><span class="annottext">a
</span><a href="#local-6989586621679664124"><span class="hs-identifier hs-var">noise</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">g
</span><a href="#local-6989586621679664123"><span class="hs-identifier hs-var">g'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-48"></span><span>
</span><span id="line-49"></span><span class="hs-comment">-- | Datatype to represent a dataset of sine cardinal (sinc) inputs and outputs.</span><span>
</span><span id="line-50"></span><span class="hs-comment">-- The 'name' field is used to identify the split of the dataset.</span><span>
</span><span id="line-51"></span><span class="hs-keyword">data</span><span> </span><span id="SincData"><span class="annot"><a href="Torch.GraduallyTyped.Examples.TwoLayerNetwork.html#SincData"><span class="hs-identifier hs-var">SincData</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span id="SincData"><span class="annot"><a href="Torch.GraduallyTyped.Examples.TwoLayerNetwork.html#SincData"><span class="hs-identifier hs-var">SincData</span></a></span></span><span> </span><span class="hs-special">{</span><span id="name"><span class="annot"><span class="annottext">SincData -&gt; Text
</span><a href="Torch.GraduallyTyped.Examples.TwoLayerNetwork.html#name"><span class="hs-identifier hs-var hs-var">name</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Text</span></span><span class="hs-special">,</span><span> </span><span id="unSincData"><span class="annot"><span class="annottext">SincData -&gt; [(Float, Float)]
</span><a href="Torch.GraduallyTyped.Examples.TwoLayerNetwork.html#unSincData"><span class="hs-identifier hs-var hs-var">unSincData</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">Float</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Float</span></span><span class="hs-special">)</span><span class="hs-special">]</span><span class="hs-special">}</span><span> </span><span class="hs-keyword">deriving</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679664114"><span id="local-6989586621679664116"><span class="annot"><span class="annottext">SincData -&gt; SincData -&gt; Bool
(SincData -&gt; SincData -&gt; Bool)
-&gt; (SincData -&gt; SincData -&gt; Bool) -&gt; Eq SincData
forall a. (a -&gt; a -&gt; Bool) -&gt; (a -&gt; a -&gt; Bool) -&gt; Eq a
/= :: SincData -&gt; SincData -&gt; Bool
$c/= :: SincData -&gt; SincData -&gt; Bool
== :: SincData -&gt; SincData -&gt; Bool
$c== :: SincData -&gt; SincData -&gt; Bool
</span><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var">Eq</span></span></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679664098"><span id="local-6989586621679664100"><span id="local-6989586621679664102"><span id="local-6989586621679664104"><span id="local-6989586621679664106"><span id="local-6989586621679664108"><span id="local-6989586621679664110"><span class="annot"><span class="annottext">Eq SincData
Eq SincData
-&gt; (SincData -&gt; SincData -&gt; Ordering)
-&gt; (SincData -&gt; SincData -&gt; Bool)
-&gt; (SincData -&gt; SincData -&gt; Bool)
-&gt; (SincData -&gt; SincData -&gt; Bool)
-&gt; (SincData -&gt; SincData -&gt; Bool)
-&gt; (SincData -&gt; SincData -&gt; SincData)
-&gt; (SincData -&gt; SincData -&gt; SincData)
-&gt; Ord SincData
SincData -&gt; SincData -&gt; Bool
SincData -&gt; SincData -&gt; Ordering
SincData -&gt; SincData -&gt; SincData
forall a.
Eq a
-&gt; (a -&gt; a -&gt; Ordering)
-&gt; (a -&gt; a -&gt; Bool)
-&gt; (a -&gt; a -&gt; Bool)
-&gt; (a -&gt; a -&gt; Bool)
-&gt; (a -&gt; a -&gt; Bool)
-&gt; (a -&gt; a -&gt; a)
-&gt; (a -&gt; a -&gt; a)
-&gt; Ord a
min :: SincData -&gt; SincData -&gt; SincData
$cmin :: SincData -&gt; SincData -&gt; SincData
max :: SincData -&gt; SincData -&gt; SincData
$cmax :: SincData -&gt; SincData -&gt; SincData
&gt;= :: SincData -&gt; SincData -&gt; Bool
$c&gt;= :: SincData -&gt; SincData -&gt; Bool
&gt; :: SincData -&gt; SincData -&gt; Bool
$c&gt; :: SincData -&gt; SincData -&gt; Bool
&lt;= :: SincData -&gt; SincData -&gt; Bool
$c&lt;= :: SincData -&gt; SincData -&gt; Bool
&lt; :: SincData -&gt; SincData -&gt; Bool
$c&lt; :: SincData -&gt; SincData -&gt; Bool
compare :: SincData -&gt; SincData -&gt; Ordering
$ccompare :: SincData -&gt; SincData -&gt; Ordering
$cp1Ord :: Eq SincData
</span><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">Ord</span></span></span></span></span></span></span></span></span><span class="hs-special">)</span><span>
</span><span id="line-52"></span><span>
</span><span id="line-53"></span><span class="hs-comment">-- | Create a dataset of noisy sine cardinal (sinc) values of a desired size.</span><span>
</span><span id="line-54"></span><span id="local-6989586621679664225"><span id="local-6989586621679664226"><span class="annot"><a href="Torch.GraduallyTyped.Examples.TwoLayerNetwork.html#mkSincData"><span class="hs-identifier hs-type">mkSincData</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-55"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/fv40valsp1qi9dy3snb8jgiq0a9h8rjk-random-lib-random-1.2.0-haddock-doc/share/doc/random/html/src"><span class="hs-identifier hs-type">RandomGen</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679664226"><span class="hs-identifier hs-type">g</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Monad</span></span><span> </span><span class="annot"><a href="#local-6989586621679664225"><span class="hs-identifier hs-type">m</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-56"></span><span>  </span><span class="hs-comment">-- | name of the dataset</span><span>
</span><span id="line-57"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">Text</span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-58"></span><span>  </span><span class="hs-comment">-- | number of samples</span><span>
</span><span id="line-59"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-60"></span><span>  </span><span class="hs-comment">-- | dataset in the state monad over the random generator</span><span>
</span><span id="line-61"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">StateT</span></span><span> </span><span class="annot"><a href="#local-6989586621679664226"><span class="hs-identifier hs-type">g</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679664225"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Examples.TwoLayerNetwork.html#SincData"><span class="hs-identifier hs-type">SincData</span></a></span></span></span><span>
</span><span id="line-62"></span><span id="mkSincData"><span class="annot"><span class="annottext">mkSincData :: Text -&gt; Int -&gt; StateT g m SincData
</span><a href="Torch.GraduallyTyped.Examples.TwoLayerNetwork.html#mkSincData"><span class="hs-identifier hs-var hs-var">mkSincData</span></a></span></span><span> </span><span id="local-6989586621679664095"><span class="annot"><span class="annottext">Text
</span><a href="#local-6989586621679664095"><span class="hs-identifier hs-var">name'</span></a></span></span><span> </span><span id="local-6989586621679664094"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679664094"><span class="hs-identifier hs-var">size</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-63"></span><span>  </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679664093"><span class="annot"><span class="annottext">next' :: StateT g m (Float, Float)
</span><a href="#local-6989586621679664093"><span class="hs-identifier hs-var hs-var">next'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-64"></span><span>        </span><span id="local-6989586621679664092"><span class="annot"><span class="annottext">Float
</span><a href="#local-6989586621679664092"><span class="hs-identifier hs-var">x</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Float -&gt; Float -&gt; Float
forall a. Num a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">*</span></span><span> </span><span class="annot"><span class="annottext">Float
</span><span class="hs-number">20</span></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">(Float -&gt; Float) -&gt; StateT g m Float -&gt; StateT g m Float
forall (f :: * -&gt; *) a b. Functor f =&gt; (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;$&gt;</span></span><span> </span><span class="annot"><span class="annottext">(g -&gt; (Float, g)) -&gt; StateT g m Float
forall s (m :: * -&gt; *) a. MonadState s m =&gt; (s -&gt; (a, s)) -&gt; m a
</span><span class="hs-identifier hs-var">state</span></span><span> </span><span class="annot"><span class="annottext">g -&gt; (Float, g)
forall g a. (RandomGen g, Random a, Floating a) =&gt; g -&gt; (a, g)
</span><a href="../file:///nix/store/h1pd6gy8cjy2zwwf9bl5ni48j4q56732-normaldistribution-lib-normaldistribution-1.1.0.3-haddock-doc/share/doc/normaldistribution/html/src"><span class="hs-identifier hs-var">normal</span></a></span><span>
</span><span id="line-65"></span><span>        </span><span id="local-6989586621679664089"><span class="annot"><span class="annottext">Float
</span><a href="#local-6989586621679664089"><span class="hs-identifier hs-var">y</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">(g -&gt; (Float, g)) -&gt; StateT g m Float
forall s (m :: * -&gt; *) a. MonadState s m =&gt; (s -&gt; (a, s)) -&gt; m a
</span><span class="hs-identifier hs-var">state</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Float -&gt; Float -&gt; g -&gt; (Float, g)
forall a g.
(Floating a, Random a, RandomGen g) =&gt;
a -&gt; a -&gt; g -&gt; (a, g)
</span><a href="Torch.GraduallyTyped.Examples.TwoLayerNetwork.html#noisySinc"><span class="hs-identifier hs-var">noisySinc</span></a></span><span> </span><span class="annot"><span class="annottext">Float
</span><span class="hs-number">0.05</span></span><span> </span><span class="annot"><span class="annottext">Float
</span><a href="#local-6989586621679664092"><span class="hs-identifier hs-var">x</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-66"></span><span>        </span><span class="annot"><span class="annottext">(Float, Float) -&gt; StateT g m (Float, Float)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Float
</span><a href="#local-6989586621679664092"><span class="hs-identifier hs-var">x</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Float
</span><a href="#local-6989586621679664089"><span class="hs-identifier hs-var">y</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-67"></span><span>   </span><span class="hs-keyword">in</span><span> </span><span class="annot"><span class="annottext">Text -&gt; [(Float, Float)] -&gt; SincData
</span><a href="Torch.GraduallyTyped.Examples.TwoLayerNetwork.html#SincData"><span class="hs-identifier hs-var">SincData</span></a></span><span> </span><span class="annot"><span class="annottext">Text
</span><a href="#local-6989586621679664095"><span class="hs-identifier hs-var">name'</span></a></span><span> </span><span class="annot"><span class="annottext">([(Float, Float)] -&gt; SincData)
-&gt; StateT g m [(Float, Float)] -&gt; StateT g m SincData
forall (f :: * -&gt; *) a b. Functor f =&gt; (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;$&gt;</span></span><span> </span><span class="annot"><span class="annottext">Int -&gt; StateT g m (Float, Float) -&gt; StateT g m [(Float, Float)]
forall (m :: * -&gt; *) a. Applicative m =&gt; Int -&gt; m a -&gt; m [a]
</span><span class="hs-identifier hs-var">replicateM</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679664094"><span class="hs-identifier hs-var">size</span></a></span><span> </span><span class="annot"><span class="annottext">StateT g m (Float, Float)
</span><a href="#local-6989586621679664093"><span class="hs-identifier hs-var">next'</span></a></span><span>
</span><span id="line-68"></span><span>
</span><span id="line-69"></span><span class="hs-comment">-- | 'Dataset' instance used for streaming sine cardinal (sinc) examples.</span><span>
</span><span id="line-70"></span><span class="hs-keyword">instance</span><span> </span><span class="annot"><a href="../../../../hasktorch/html/src"><span class="hs-identifier hs-type">Dataset</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">IO</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Examples.TwoLayerNetwork.html#SincData"><span class="hs-identifier hs-type">SincData</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">Float</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Float</span></span><span class="hs-special">)</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-71"></span><span>  </span><span id="local-6989586621679664084"><span class="annot"><span class="annottext">getItem :: SincData -&gt; Int -&gt; IO (Float, Float)
</span><a href="../../../../hasktorch/html/src"><span class="hs-identifier hs-var hs-var hs-var hs-var">getItem</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Examples.TwoLayerNetwork.html#SincData"><span class="hs-identifier hs-type">SincData</span></a></span><span> </span><span class="annot"><span class="annottext">Text
</span><span class="hs-identifier">_</span></span><span> </span><span id="local-6989586621679664082"><span class="annot"><span class="annottext">[(Float, Float)]
</span><a href="#local-6989586621679664082"><span class="hs-identifier hs-var">d</span></a></span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679664081"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679664081"><span class="hs-identifier hs-var">k</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Float, Float)
-&gt; ((Float, Float) -&gt; IO (Float, Float))
-&gt; Maybe (Float, Float)
-&gt; IO (Float, Float)
forall b a. b -&gt; (a -&gt; b) -&gt; Maybe a -&gt; b
</span><span class="hs-identifier hs-var">maybe</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">String -&gt; IO (Float, Float)
forall (m :: * -&gt; *) a. MonadFail m =&gt; String -&gt; m a
</span><span class="hs-identifier hs-var">fail</span></span><span> </span><span class="annot"><span class="annottext">String
</span><span class="hs-string">&quot;invalid key&quot;</span></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">(Float, Float) -&gt; IO (Float, Float)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">(Maybe (Float, Float) -&gt; IO (Float, Float))
-&gt; Maybe (Float, Float) -&gt; IO (Float, Float)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">[(Float, Float)]
</span><a href="#local-6989586621679664082"><span class="hs-identifier hs-var">d</span></a></span><span> </span><span class="annot"><span class="annottext">[(Float, Float)]
-&gt; Getting (First (Float, Float)) [(Float, Float)] (Float, Float)
-&gt; Maybe (Float, Float)
forall s a. s -&gt; Getting (First a) s a -&gt; Maybe a
</span><a href="../file:///nix/store/48s8mi00b2kvxgar4z446h72vmm1c3v3-lens-lib-lens-5.0.1-haddock-doc/share/doc/lens/html/src"><span class="hs-operator hs-var">^?</span></a></span><span> </span><span class="annot"><span class="annottext">Int -&gt; IndexedTraversal' Int [(Float, Float)] (Float, Float)
forall (t :: * -&gt; *) a.
Traversable t =&gt;
Int -&gt; IndexedTraversal' Int (t a) a
</span><a href="../file:///nix/store/48s8mi00b2kvxgar4z446h72vmm1c3v3-lens-lib-lens-5.0.1-haddock-doc/share/doc/lens/html/src"><span class="hs-identifier hs-var">element</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679664081"><span class="hs-identifier hs-var">k</span></a></span><span>
</span><span id="line-72"></span><span>  </span><span id="local-6989586621679664079"><span class="annot"><span class="annottext">keys :: SincData -&gt; Set Int
</span><a href="../../../../hasktorch/html/src"><span class="hs-identifier hs-var hs-var hs-var hs-var">keys</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Examples.TwoLayerNetwork.html#SincData"><span class="hs-identifier hs-type">SincData</span></a></span><span> </span><span class="annot"><span class="annottext">Text
</span><span class="hs-identifier">_</span></span><span> </span><span id="local-6989586621679664077"><span class="annot"><span class="annottext">[(Float, Float)]
</span><a href="#local-6989586621679664077"><span class="hs-identifier hs-var">d</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">[Int] -&gt; Set Int
forall a. Ord a =&gt; [a] -&gt; Set a
</span><span class="hs-identifier hs-var">Set.fromList</span></span><span> </span><span class="hs-special">[</span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">0</span></span><span> </span><span class="hs-glyph">..</span><span> </span><span class="annot"><span class="annottext">[(Float, Float)] -&gt; Int
forall (t :: * -&gt; *) a. Foldable t =&gt; t a -&gt; Int
</span><span class="hs-identifier hs-var">Prelude.length</span></span><span> </span><span class="annot"><span class="annottext">[(Float, Float)]
</span><a href="#local-6989586621679664077"><span class="hs-identifier hs-var">d</span></a></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Int
forall a. Num a =&gt; a -&gt; a -&gt; a
</span><span class="hs-glyph hs-var">-</span></span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">1</span></span><span class="hs-special">]</span><span>
</span><span id="line-73"></span><span>
</span><span id="line-74"></span><span class="hs-comment">-- | Data type to represent a simple two-layer neural network.</span><span>
</span><span id="line-75"></span><span class="hs-comment">-- It is a product type of two layer types, @fstLayer@ and @sndLayer@,</span><span>
</span><span id="line-76"></span><span class="hs-comment">-- an activation function, @activation@, and a dropout layer, @dropout@.</span><span>
</span><span id="line-77"></span><span id="local-6989586621679664073"><span id="local-6989586621679664074"></span></span><span class="hs-keyword">newtype</span><span> </span><span id="TwoLayerNetwork"><span class="annot"><a href="Torch.GraduallyTyped.Examples.TwoLayerNetwork.html#TwoLayerNetwork"><span class="hs-identifier hs-var">TwoLayerNetwork</span></a></span></span><span> </span><span id="local-6989586621679664374"><span class="annot"><a href="#local-6989586621679664374"><span class="hs-identifier hs-type">fstLayer</span></a></span></span><span> </span><span id="local-6989586621679664373"><span class="annot"><a href="#local-6989586621679664373"><span class="hs-identifier hs-type">activation</span></a></span></span><span> </span><span id="local-6989586621679664372"><span class="annot"><a href="#local-6989586621679664372"><span class="hs-identifier hs-type">dropout</span></a></span></span><span> </span><span id="local-6989586621679664371"><span class="annot"><a href="#local-6989586621679664371"><span class="hs-identifier hs-type">sndLayer</span></a></span></span><span>
</span><span id="line-78"></span><span>  </span><span class="hs-glyph">=</span><span> </span><span id="TwoLayerNetwork"><span class="annot"><a href="Torch.GraduallyTyped.Examples.TwoLayerNetwork.html#TwoLayerNetwork"><span class="hs-identifier hs-var">TwoLayerNetwork</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelStack"><span class="hs-identifier hs-type">ModelStack</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679664374"><span class="hs-identifier hs-type">fstLayer</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679664373"><span class="hs-identifier hs-type">activation</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679664372"><span class="hs-identifier hs-type">dropout</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679664371"><span class="hs-identifier hs-type">sndLayer</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-79"></span><span>  </span><span class="hs-keyword">deriving</span><span> </span><span class="annot"><span class="hs-keyword">stock</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">(forall x.
 TwoLayerNetwork fstLayer activation dropout sndLayer
 -&gt; Rep (TwoLayerNetwork fstLayer activation dropout sndLayer) x)
-&gt; (forall x.
    Rep (TwoLayerNetwork fstLayer activation dropout sndLayer) x
    -&gt; TwoLayerNetwork fstLayer activation dropout sndLayer)
-&gt; Generic (TwoLayerNetwork fstLayer activation dropout sndLayer)
forall x.
Rep (TwoLayerNetwork fstLayer activation dropout sndLayer) x
-&gt; TwoLayerNetwork fstLayer activation dropout sndLayer
forall x.
TwoLayerNetwork fstLayer activation dropout sndLayer
-&gt; Rep (TwoLayerNetwork fstLayer activation dropout sndLayer) x
forall a.
(forall x. a -&gt; Rep a x) -&gt; (forall x. Rep a x -&gt; a) -&gt; Generic a
forall fstLayer activation dropout sndLayer x.
Rep (TwoLayerNetwork fstLayer activation dropout sndLayer) x
-&gt; TwoLayerNetwork fstLayer activation dropout sndLayer
forall fstLayer activation dropout sndLayer x.
TwoLayerNetwork fstLayer activation dropout sndLayer
-&gt; Rep (TwoLayerNetwork fstLayer activation dropout sndLayer) x
$cto :: forall fstLayer activation dropout sndLayer x.
Rep (TwoLayerNetwork fstLayer activation dropout sndLayer) x
-&gt; TwoLayerNetwork fstLayer activation dropout sndLayer
$cfrom :: forall fstLayer activation dropout sndLayer x.
TwoLayerNetwork fstLayer activation dropout sndLayer
-&gt; Rep (TwoLayerNetwork fstLayer activation dropout sndLayer) x
</span><span class="hs-identifier hs-var hs-var hs-var hs-var">Generic</span></span><span class="hs-special">)</span><span>
</span><span id="line-80"></span><span>
</span><span id="line-81"></span><span class="hs-comment">-- | The specification of a two-layer network is the product of the</span><span>
</span><span id="line-82"></span><span class="hs-comment">-- specifications of its two layers and the activation function.</span><span>
</span><span id="line-83"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">instance</span><span>
</span><span id="line-84"></span><span>  </span><span id="ModelSpec"><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier hs-var">ModelSpec</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Examples.TwoLayerNetwork.html#TwoLayerNetwork"><span class="hs-identifier hs-type">TwoLayerNetwork</span></a></span><span> </span><span id="local-6989586621679664068"><span class="annot"><a href="#local-6989586621679664068"><span class="hs-identifier hs-type hs-type">fstLayer</span></a></span></span><span> </span><span id="local-6989586621679664067"><span class="annot"><a href="#local-6989586621679664067"><span class="hs-identifier hs-type hs-type">activation</span></a></span></span><span> </span><span id="local-6989586621679664066"><span class="annot"><a href="#local-6989586621679664066"><span class="hs-identifier hs-type hs-type">dropout</span></a></span></span><span> </span><span id="local-6989586621679664065"><span class="annot"><a href="#local-6989586621679664065"><span class="hs-identifier hs-type hs-type">sndLayer</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-85"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Examples.TwoLayerNetwork.html#TwoLayerNetwork"><span class="hs-identifier hs-type">TwoLayerNetwork</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier hs-type">ModelSpec</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679664068"><span class="hs-identifier hs-type">fstLayer</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier hs-type">ModelSpec</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679664067"><span class="hs-identifier hs-type">activation</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier hs-type">ModelSpec</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679664066"><span class="hs-identifier hs-type">dropout</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier hs-type">ModelSpec</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679664065"><span class="hs-identifier hs-type">sndLayer</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-86"></span><span>
</span><span id="line-87"></span><span class="hs-comment">-- | To initialize a two-layer network,</span><span>
</span><span id="line-88"></span><span class="hs-comment">-- we need its specification and a random generator.</span><span>
</span><span id="line-89"></span><span class="hs-comment">-- The random generator is used to initialize the weights of the network.</span><span>
</span><span id="line-90"></span><span class="hs-comment">-- The specification is used to determine the properties of the two neural layers,</span><span>
</span><span id="line-91"></span><span class="hs-comment">-- the activation function, and the dropout layer.</span><span>
</span><span id="line-92"></span><span class="hs-comment">-- The four components are initialized separately and then combined into a single</span><span>
</span><span id="line-93"></span><span class="hs-comment">-- network.</span><span>
</span><span id="line-94"></span><span id="local-6989586621679664055"><span id="local-6989586621679664056"><span id="local-6989586621679664057"><span id="local-6989586621679664058"><span id="local-6989586621679664059"><span id="local-6989586621679664060"><span id="local-6989586621679664061"><span id="local-6989586621679664062"><span id="local-6989586621679664063"><span id="local-6989586621679664064"><span class="hs-keyword">instance</span><span>
</span><span id="line-95"></span><span>  </span><span id="local-6989586621679664053"><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span>
</span><span id="line-96"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelStack"><span class="hs-identifier hs-type">ModelStack</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679664064"><span class="hs-identifier hs-type">fstLayer</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679664063"><span class="hs-identifier hs-type">activation</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679664062"><span class="hs-identifier hs-type">dropout</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679664061"><span class="hs-identifier hs-type">sndLayer</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-97"></span><span>    </span><span class="annot"><a href="#local-6989586621679664060"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-98"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelStack"><span class="hs-identifier hs-type">ModelStack</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679664059"><span class="hs-identifier hs-type">fstLayer'</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679664058"><span class="hs-identifier hs-type">activation'</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679664057"><span class="hs-identifier hs-type">dropout'</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679664056"><span class="hs-identifier hs-type">sndLayer'</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-99"></span><span>    </span><span class="annot"><a href="#local-6989586621679664055"><span class="hs-identifier hs-type">generatorOutputDevice</span></a></span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-100"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span>
</span><span id="line-101"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Examples.TwoLayerNetwork.html#TwoLayerNetwork"><span class="hs-identifier hs-type">TwoLayerNetwork</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679664064"><span class="hs-identifier hs-type">fstLayer</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679664063"><span class="hs-identifier hs-type">activation</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679664062"><span class="hs-identifier hs-type">dropout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679664061"><span class="hs-identifier hs-type">sndLayer</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-102"></span><span>    </span><span class="annot"><a href="#local-6989586621679664060"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-103"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Examples.TwoLayerNetwork.html#TwoLayerNetwork"><span class="hs-identifier hs-type">TwoLayerNetwork</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679664059"><span class="hs-identifier hs-type">fstLayer'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679664058"><span class="hs-identifier hs-type">activation'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679664057"><span class="hs-identifier hs-type">dropout'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679664056"><span class="hs-identifier hs-type">sndLayer'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-104"></span><span>    </span><span class="annot"><a href="#local-6989586621679664055"><span class="hs-identifier hs-type">generatorOutputDevice</span></a></span></span></span></span></span></span></span></span></span></span></span></span><span>
</span><span id="line-105"></span><span>
</span><span id="line-106"></span><span class="hs-comment">-- | @HasStateDict@ instance for a two-layer network.</span><span>
</span><span id="line-107"></span><span class="hs-comment">-- It allows for conversion of a two-layer network into a state dictionary and back.</span><span>
</span><span id="line-108"></span><span class="hs-comment">--</span><span>
</span><span id="line-109"></span><span class="hs-comment">-- To create a two-layer network from a state dictionary,</span><span>
</span><span id="line-110"></span><span class="hs-comment">-- we need to first create its two neural layers, the activation function, and the dropout layer from the state dictionary.</span><span>
</span><span id="line-111"></span><span class="hs-comment">-- Afterwards, we combine the four components into a single network.</span><span>
</span><span id="line-112"></span><span class="hs-comment">--</span><span>
</span><span id="line-113"></span><span class="hs-comment">-- The state dictionary of the two-layer network is the union of the</span><span>
</span><span id="line-114"></span><span class="hs-comment">-- state dictionaries its layers.</span><span>
</span><span id="line-115"></span><span id="local-6989586621679664048"><span id="local-6989586621679664049"><span id="local-6989586621679664050"><span id="local-6989586621679664051"><span class="hs-keyword">instance</span><span>
</span><span id="line-116"></span><span>  </span><span id="local-6989586621679664044"><span id="local-6989586621679664046"><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasStateDict"><span class="hs-identifier hs-type">HasStateDict</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679664051"><span class="hs-identifier hs-type">fstLayer</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasStateDict"><span class="hs-identifier hs-type">HasStateDict</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679664050"><span class="hs-identifier hs-type">activation</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasStateDict"><span class="hs-identifier hs-type">HasStateDict</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679664049"><span class="hs-identifier hs-type">dropout</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasStateDict"><span class="hs-identifier hs-type">HasStateDict</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679664048"><span class="hs-identifier hs-type">sndLayer</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-117"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasStateDict"><span class="hs-identifier hs-type">HasStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Examples.TwoLayerNetwork.html#TwoLayerNetwork"><span class="hs-identifier hs-type">TwoLayerNetwork</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679664051"><span class="hs-identifier hs-type">fstLayer</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679664050"><span class="hs-identifier hs-type">activation</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679664049"><span class="hs-identifier hs-type">dropout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679664048"><span class="hs-identifier hs-type">sndLayer</span></a></span><span class="hs-special">)</span></span></span></span></span></span></span><span>
</span><span id="line-118"></span><span>
</span><span id="line-119"></span><span class="hs-comment">-- | Specifies the type of the two-layer network.</span><span>
</span><span id="line-120"></span><span class="hs-keyword">type</span><span> </span><span id="TwoLayerNetworkF"><span class="annot"><a href="Torch.GraduallyTyped.Examples.TwoLayerNetwork.html#TwoLayerNetworkF"><span class="hs-identifier hs-var">TwoLayerNetworkF</span></a></span></span><span> </span><span id="local-6989586621679664042"><span class="annot"><a href="#local-6989586621679664042"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679664041"><span class="annot"><a href="#local-6989586621679664041"><span class="hs-identifier hs-type">hasDropout</span></a></span></span><span> </span><span id="local-6989586621679664040"><span class="annot"><a href="#local-6989586621679664040"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679664039"><span class="annot"><a href="#local-6989586621679664039"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679664038"><span class="annot"><a href="#local-6989586621679664038"><span class="hs-identifier hs-type">inputDim</span></a></span></span><span> </span><span id="local-6989586621679664037"><span class="annot"><a href="#local-6989586621679664037"><span class="hs-identifier hs-type">outputDim</span></a></span></span><span> </span><span id="local-6989586621679664036"><span class="annot"><a href="#local-6989586621679664036"><span class="hs-identifier hs-type">hiddenDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-121"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-type">NamedModel</span></a></span><span>
</span><span id="line-122"></span><span>    </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Examples.TwoLayerNetwork.html#TwoLayerNetwork"><span class="hs-identifier hs-type">TwoLayerNetwork</span></a></span><span>
</span><span id="line-123"></span><span>        </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-type">NamedModel</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Linear.html#GLinearF"><span class="hs-identifier hs-type">GLinearF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Type.html#WithBias"><span class="hs-identifier hs-type">WithBias</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679664042"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679664040"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679664039"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679664038"><span class="hs-identifier hs-type">inputDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679664036"><span class="hs-identifier hs-type">hiddenDim</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-124"></span><span>        </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Activation.html#Tanh"><span class="hs-identifier hs-type">Tanh</span></a></span><span>
</span><span id="line-125"></span><span>        </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Examples.TwoLayerNetwork.html#TLNDropoutF"><span class="hs-identifier hs-type">TLNDropoutF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679664041"><span class="hs-identifier hs-type">hasDropout</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-126"></span><span>        </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-type">NamedModel</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Linear.html#GLinearF"><span class="hs-identifier hs-type">GLinearF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Type.html#WithBias"><span class="hs-identifier hs-type">WithBias</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679664042"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679664040"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679664039"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679664036"><span class="hs-identifier hs-type">hiddenDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679664037"><span class="hs-identifier hs-type">outputDim</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-127"></span><span>    </span><span class="hs-special">)</span><span>
</span><span id="line-128"></span><span>
</span><span id="line-129"></span><span class="hs-comment">-- | Specifies the type of the dropout layer</span><span>
</span><span id="line-130"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span> </span><span id="TLNDropoutF"><span class="annot"><a href="Torch.GraduallyTyped.Examples.TwoLayerNetwork.html#TLNDropoutF"><span class="hs-identifier hs-var">TLNDropoutF</span></a></span></span><span> </span><span id="local-6989586621679664035"><span class="annot"><a href="#local-6989586621679664035"><span class="hs-identifier hs-type">hasDropout</span></a></span></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-131"></span><span>  </span><span id="TLNDropoutF"><span class="annot"><a href="Torch.GraduallyTyped.Examples.TwoLayerNetwork.html#TLNDropoutF"><span class="hs-identifier hs-var">TLNDropoutF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Type.html#WithDropout"><span class="hs-identifier hs-type">WithDropout</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Dropout.html#Dropout"><span class="hs-identifier hs-type">Dropout</span></a></span><span>
</span><span id="line-132"></span><span>  </span><span id="TLNDropoutF"><span class="annot"><a href="Torch.GraduallyTyped.Examples.TwoLayerNetwork.html#TLNDropoutF"><span class="hs-identifier hs-var">TLNDropoutF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Type.html#WithoutDropout"><span class="hs-identifier hs-type">WithoutDropout</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-133"></span><span>
</span><span id="line-134"></span><span class="hs-comment">-- | Creates a value that specifies the parameters of a two-layer neural network.</span><span>
</span><span id="line-135"></span><span class="annot"><a href="Torch.GraduallyTyped.Examples.TwoLayerNetwork.html#twoLayerNetworkSpec"><span class="hs-identifier hs-type">twoLayerNetworkSpec</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-136"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679664255"><span class="annot"><a href="#local-6989586621679664255"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679664254"><span class="annot"><a href="#local-6989586621679664254"><span class="hs-identifier hs-type">hasDropout</span></a></span></span><span> </span><span id="local-6989586621679664253"><span class="annot"><a href="#local-6989586621679664253"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679664252"><span class="annot"><a href="#local-6989586621679664252"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679664251"><span class="annot"><a href="#local-6989586621679664251"><span class="hs-identifier hs-type">inputDim</span></a></span></span><span> </span><span id="local-6989586621679664250"><span class="annot"><a href="#local-6989586621679664250"><span class="hs-identifier hs-type">outputDim</span></a></span></span><span> </span><span id="local-6989586621679664249"><span class="annot"><a href="#local-6989586621679664249"><span class="hs-identifier hs-type">hiddenDim</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-137"></span><span>  </span><span class="hs-comment">-- | whether or not to compute gradients for the parametrs</span><span>
</span><span id="line-138"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier hs-type">SGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679664255"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-139"></span><span>  </span><span class="hs-comment">-- | whether or not to use dropout</span><span>
</span><span id="line-140"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Type.html#SHasDropout"><span class="hs-identifier hs-type">SHasDropout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679664254"><span class="hs-identifier hs-type">hasDropout</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-141"></span><span>  </span><span class="hs-comment">-- | which device to use</span><span>
</span><span id="line-142"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#SDevice"><span class="hs-identifier hs-type">SDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679664253"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-143"></span><span>  </span><span class="hs-comment">-- | which data type to use</span><span>
</span><span id="line-144"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier hs-type">SDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679664252"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-145"></span><span>  </span><span class="hs-comment">-- | input dimension</span><span>
</span><span id="line-146"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679664251"><span class="hs-identifier hs-type">inputDim</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-147"></span><span>  </span><span class="hs-comment">-- | output dimension</span><span>
</span><span id="line-148"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679664250"><span class="hs-identifier hs-type">outputDim</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-149"></span><span>  </span><span class="hs-comment">-- | hidden dimension</span><span>
</span><span id="line-150"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679664249"><span class="hs-identifier hs-type">hiddenDim</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-151"></span><span>  </span><span class="hs-comment">-- | dropout rate</span><span>
</span><span id="line-152"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-153"></span><span>  </span><span class="hs-comment">-- | specification for the network</span><span>
</span><span id="line-154"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier hs-type">ModelSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Examples.TwoLayerNetwork.html#TwoLayerNetworkF"><span class="hs-identifier hs-type">TwoLayerNetworkF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679664255"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679664254"><span class="hs-identifier hs-type">hasDropout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679664253"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679664252"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679664251"><span class="hs-identifier hs-type">inputDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679664250"><span class="hs-identifier hs-type">outputDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679664249"><span class="hs-identifier hs-type">hiddenDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-155"></span><span id="twoLayerNetworkSpec"><span class="annot"><span class="annottext">twoLayerNetworkSpec :: SGradient gradient
-&gt; SHasDropout hasDropout
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim inputDim
-&gt; SDim outputDim
-&gt; SDim hiddenDim
-&gt; Double
-&gt; ModelSpec
     (TwoLayerNetworkF
        gradient hasDropout device dataType inputDim outputDim hiddenDim)
</span><a href="Torch.GraduallyTyped.Examples.TwoLayerNetwork.html#twoLayerNetworkSpec"><span class="hs-identifier hs-var hs-var">twoLayerNetworkSpec</span></a></span></span><span> </span><span id="local-6989586621679664033"><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679664033"><span class="hs-identifier hs-var">gradient</span></a></span></span><span> </span><span id="local-6989586621679664032"><span class="annot"><span class="annottext">SHasDropout hasDropout
</span><a href="#local-6989586621679664032"><span class="hs-identifier hs-var">hasDropout</span></a></span></span><span> </span><span id="local-6989586621679664031"><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679664031"><span class="hs-identifier hs-var">device</span></a></span></span><span> </span><span id="local-6989586621679664030"><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679664030"><span class="hs-identifier hs-var">dataType</span></a></span></span><span> </span><span id="local-6989586621679664029"><span class="annot"><span class="annottext">SDim inputDim
</span><a href="#local-6989586621679664029"><span class="hs-identifier hs-var">inputDim</span></a></span></span><span> </span><span id="local-6989586621679664028"><span class="annot"><span class="annottext">SDim outputDim
</span><a href="#local-6989586621679664028"><span class="hs-identifier hs-var">outputDim</span></a></span></span><span> </span><span id="local-6989586621679664027"><span class="annot"><span class="annottext">SDim hiddenDim
</span><a href="#local-6989586621679664027"><span class="hs-identifier hs-var">hiddenDim</span></a></span></span><span> </span><span id="local-6989586621679664026"><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679664026"><span class="hs-identifier hs-var">dropoutP</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-156"></span><span>  </span><span class="annot"><span class="annottext">Text
</span><span class="hs-string">&quot;twoLayerNetwork&quot;</span></span><span>
</span><span id="line-157"></span><span>    </span><span class="annot"><span class="annottext">Text
-&gt; TwoLayerNetwork
     (NamedModel
        (GLinear
           (NamedModel
              (TensorSpec
                 gradient
                 ('Layout 'Dense)
                 device
                 dataType
                 ('Shape '[hiddenDim, inputDim])))
           (NamedModel
              (TensorSpec
                 gradient ('Layout 'Dense) device dataType ('Shape '[hiddenDim])))))
     Tanh
     (ModelSpec (TLNDropoutF hasDropout))
     (NamedModel
        (GLinear
           (NamedModel
              (TensorSpec
                 gradient
                 ('Layout 'Dense)
                 device
                 dataType
                 ('Shape '[outputDim, hiddenDim])))
           (NamedModel
              (TensorSpec
                 gradient ('Layout 'Dense) device dataType ('Shape '[outputDim])))))
-&gt; NamedModel
     (TwoLayerNetwork
        (NamedModel
           (GLinear
              (NamedModel
                 (TensorSpec
                    gradient
                    ('Layout 'Dense)
                    device
                    dataType
                    ('Shape '[hiddenDim, inputDim])))
              (NamedModel
                 (TensorSpec
                    gradient ('Layout 'Dense) device dataType ('Shape '[hiddenDim])))))
        Tanh
        (ModelSpec (TLNDropoutF hasDropout))
        (NamedModel
           (GLinear
              (NamedModel
                 (TensorSpec
                    gradient
                    ('Layout 'Dense)
                    device
                    dataType
                    ('Shape '[outputDim, hiddenDim])))
              (NamedModel
                 (TensorSpec
                    gradient
                    ('Layout 'Dense)
                    device
                    dataType
                    ('Shape '[outputDim]))))))
forall model. Text -&gt; model -&gt; NamedModel model
</span><a href="Torch.GraduallyTyped.NN.Class.html#%3A%3A%3E"><span class="hs-operator hs-var">::&gt;</span></a></span><span> </span><span class="annot"><span class="annottext">ModelStack
  '[NamedModel
      (GLinear
         (NamedModel
            (TensorSpec
               gradient
               ('Layout 'Dense)
               device
               dataType
               ('Shape '[hiddenDim, inputDim])))
         (NamedModel
            (TensorSpec
               gradient ('Layout 'Dense) device dataType ('Shape '[hiddenDim])))),
    Tanh, ModelSpec (TLNDropoutF hasDropout),
    NamedModel
      (GLinear
         (NamedModel
            (TensorSpec
               gradient
               ('Layout 'Dense)
               device
               dataType
               ('Shape '[outputDim, hiddenDim])))
         (NamedModel
            (TensorSpec
               gradient ('Layout 'Dense) device dataType ('Shape '[outputDim]))))]
-&gt; TwoLayerNetwork
     (NamedModel
        (GLinear
           (NamedModel
              (TensorSpec
                 gradient
                 ('Layout 'Dense)
                 device
                 dataType
                 ('Shape '[hiddenDim, inputDim])))
           (NamedModel
              (TensorSpec
                 gradient ('Layout 'Dense) device dataType ('Shape '[hiddenDim])))))
     Tanh
     (ModelSpec (TLNDropoutF hasDropout))
     (NamedModel
        (GLinear
           (NamedModel
              (TensorSpec
                 gradient
                 ('Layout 'Dense)
                 device
                 dataType
                 ('Shape '[outputDim, hiddenDim])))
           (NamedModel
              (TensorSpec
                 gradient ('Layout 'Dense) device dataType ('Shape '[outputDim])))))
forall fstLayer activation dropout sndLayer.
ModelStack '[fstLayer, activation, dropout, sndLayer]
-&gt; TwoLayerNetwork fstLayer activation dropout sndLayer
</span><a href="Torch.GraduallyTyped.Examples.TwoLayerNetwork.html#TwoLayerNetwork"><span class="hs-identifier hs-var">TwoLayerNetwork</span></a></span><span>
</span><span id="line-158"></span><span>      </span><span class="hs-special">(</span><span> </span><span class="annot"><span class="annottext">ListToTuple
  '[NamedModel
      (GLinear
         (NamedModel
            (TensorSpec
               gradient
               ('Layout 'Dense)
               device
               dataType
               ('Shape '[hiddenDim, inputDim])))
         (NamedModel
            (TensorSpec
               gradient ('Layout 'Dense) device dataType ('Shape '[hiddenDim])))),
    Tanh, ModelSpec (TLNDropoutF hasDropout),
    NamedModel
      (GLinear
         (NamedModel
            (TensorSpec
               gradient
               ('Layout 'Dense)
               device
               dataType
               ('Shape '[outputDim, hiddenDim])))
         (NamedModel
            (TensorSpec
               gradient ('Layout 'Dense) device dataType ('Shape '[outputDim]))))]
-&gt; ModelStack
     '[NamedModel
         (GLinear
            (NamedModel
               (TensorSpec
                  gradient
                  ('Layout 'Dense)
                  device
                  dataType
                  ('Shape '[hiddenDim, inputDim])))
            (NamedModel
               (TensorSpec
                  gradient ('Layout 'Dense) device dataType ('Shape '[hiddenDim])))),
       Tanh, ModelSpec (TLNDropoutF hasDropout),
       NamedModel
         (GLinear
            (NamedModel
               (TensorSpec
                  gradient
                  ('Layout 'Dense)
                  device
                  dataType
                  ('Shape '[outputDim, hiddenDim])))
            (NamedModel
               (TensorSpec
                  gradient ('Layout 'Dense) device dataType ('Shape '[outputDim]))))]
forall (models :: [*]). ListToTuple models -&gt; ModelStack models
</span><a href="Torch.GraduallyTyped.NN.Class.html#ModelStack"><span class="hs-identifier hs-var">ModelStack</span></a></span><span>
</span><span id="line-159"></span><span>          </span><span class="hs-special">(</span><span> </span><span class="annot"><span class="annottext">Text
</span><span class="hs-string">&quot;fstLayer&quot;</span></span><span> </span><span class="annot"><span class="annottext">Text
-&gt; GLinear
     (NamedModel
        (TensorSpec
           gradient
           ('Layout 'Dense)
           device
           dataType
           ('Shape '[hiddenDim, inputDim])))
     (NamedModel
        (TensorSpec
           gradient ('Layout 'Dense) device dataType ('Shape '[hiddenDim])))
-&gt; NamedModel
     (GLinear
        (NamedModel
           (TensorSpec
              gradient
              ('Layout 'Dense)
              device
              dataType
              ('Shape '[hiddenDim, inputDim])))
        (NamedModel
           (TensorSpec
              gradient ('Layout 'Dense) device dataType ('Shape '[hiddenDim]))))
forall model. Text -&gt; model -&gt; NamedModel model
</span><a href="Torch.GraduallyTyped.NN.Class.html#%3A%3A%3E"><span class="hs-operator hs-var">::&gt;</span></a></span><span> </span><span class="annot"><span class="annottext">SHasBias 'WithBias
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim inputDim
-&gt; SDim hiddenDim
-&gt; ModelSpec
     (GLinearF 'WithBias gradient device dataType inputDim hiddenDim)
forall (hasBias :: HasBias) (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (inputDim :: Dim (Name Symbol) (Size Nat))
       (outputDim :: Dim (Name Symbol) (Size Nat)).
SHasBias hasBias
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim inputDim
-&gt; SDim outputDim
-&gt; ModelSpec
     (GLinearF hasBias gradient device dataType inputDim outputDim)
</span><a href="Torch.GraduallyTyped.NN.Linear.html#linearSpec"><span class="hs-identifier hs-var">linearSpec</span></a></span><span> </span><span class="annot"><span class="annottext">SHasBias 'WithBias
</span><a href="Torch.GraduallyTyped.NN.Type.html#SWithBias"><span class="hs-identifier hs-var">SWithBias</span></a></span><span> </span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679664033"><span class="hs-identifier hs-var">gradient</span></a></span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679664031"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679664030"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="annot"><span class="annottext">SDim inputDim
</span><a href="#local-6989586621679664029"><span class="hs-identifier hs-var">inputDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim hiddenDim
</span><a href="#local-6989586621679664027"><span class="hs-identifier hs-var">hiddenDim</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-160"></span><span>            </span><span class="annot"><span class="annottext">Tanh
</span><a href="Torch.GraduallyTyped.NN.Activation.html#Tanh"><span class="hs-identifier hs-var">Tanh</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-161"></span><span>            </span><span class="hs-keyword">case</span><span> </span><span class="annot"><span class="annottext">SHasDropout hasDropout
</span><a href="#local-6989586621679664032"><span class="hs-identifier hs-var">hasDropout</span></a></span><span> </span><span class="hs-keyword">of</span><span>
</span><span id="line-162"></span><span>              </span><span class="annot"><span class="annottext">SHasDropout hasDropout
</span><a href="Torch.GraduallyTyped.NN.Type.html#SWithDropout"><span class="hs-identifier hs-var">SWithDropout</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">Double -&gt; Dropout
</span><a href="Torch.GraduallyTyped.NN.Dropout.html#Dropout"><span class="hs-identifier hs-var">Dropout</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679664026"><span class="hs-identifier hs-var">dropoutP</span></a></span><span>
</span><span id="line-163"></span><span>              </span><span class="annot"><span class="annottext">SHasDropout hasDropout
</span><a href="Torch.GraduallyTyped.NN.Type.html#SWithoutDropout"><span class="hs-identifier hs-var">SWithoutDropout</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-164"></span><span>            </span><span class="annot"><span class="annottext">Text
</span><span class="hs-string">&quot;sndLayer&quot;</span></span><span> </span><span class="annot"><span class="annottext">Text
-&gt; GLinear
     (NamedModel
        (TensorSpec
           gradient
           ('Layout 'Dense)
           device
           dataType
           ('Shape '[outputDim, hiddenDim])))
     (NamedModel
        (TensorSpec
           gradient ('Layout 'Dense) device dataType ('Shape '[outputDim])))
-&gt; NamedModel
     (GLinear
        (NamedModel
           (TensorSpec
              gradient
              ('Layout 'Dense)
              device
              dataType
              ('Shape '[outputDim, hiddenDim])))
        (NamedModel
           (TensorSpec
              gradient ('Layout 'Dense) device dataType ('Shape '[outputDim]))))
forall model. Text -&gt; model -&gt; NamedModel model
</span><a href="Torch.GraduallyTyped.NN.Class.html#%3A%3A%3E"><span class="hs-operator hs-var">::&gt;</span></a></span><span> </span><span class="annot"><span class="annottext">SHasBias 'WithBias
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim hiddenDim
-&gt; SDim outputDim
-&gt; ModelSpec
     (GLinearF 'WithBias gradient device dataType hiddenDim outputDim)
forall (hasBias :: HasBias) (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (inputDim :: Dim (Name Symbol) (Size Nat))
       (outputDim :: Dim (Name Symbol) (Size Nat)).
SHasBias hasBias
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim inputDim
-&gt; SDim outputDim
-&gt; ModelSpec
     (GLinearF hasBias gradient device dataType inputDim outputDim)
</span><a href="Torch.GraduallyTyped.NN.Linear.html#linearSpec"><span class="hs-identifier hs-var">linearSpec</span></a></span><span> </span><span class="annot"><span class="annottext">SHasBias 'WithBias
</span><a href="Torch.GraduallyTyped.NN.Type.html#SWithBias"><span class="hs-identifier hs-var">SWithBias</span></a></span><span> </span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679664033"><span class="hs-identifier hs-var">gradient</span></a></span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679664031"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679664030"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="annot"><span class="annottext">SDim hiddenDim
</span><a href="#local-6989586621679664027"><span class="hs-identifier hs-var">hiddenDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim outputDim
</span><a href="#local-6989586621679664028"><span class="hs-identifier hs-var">outputDim</span></a></span><span>
</span><span id="line-165"></span><span>          </span><span class="hs-special">)</span><span>
</span><span id="line-166"></span><span>      </span><span class="hs-special">)</span><span>
</span><span id="line-167"></span><span>
</span><span id="line-168"></span><span class="hs-comment">-- | 'HasForward' instance used to define the forward pass of the model.</span><span>
</span><span id="line-169"></span><span class="hs-comment">-- The forward pass is defined as the composition of the forward passes of the two layers.</span><span>
</span><span id="line-170"></span><span class="hs-comment">-- A forward pass is a function that takes a two-layer network, an input tensor, and a random generator,</span><span>
</span><span id="line-171"></span><span class="hs-comment">-- and returns the output tensor and the updated generator.</span><span>
</span><span id="line-172"></span><span class="hs-comment">-- A nonlinearity, @tanh@, is applied to the output of the first layer.</span><span>
</span><span id="line-173"></span><span class="hs-comment">-- The input to the second layer is the output of the nonlinearity.</span><span>
</span><span id="line-174"></span><span id="local-6989586621679664008"><span id="local-6989586621679664009"><span id="local-6989586621679664010"><span id="local-6989586621679664011"><span id="local-6989586621679664012"><span id="local-6989586621679664013"><span id="local-6989586621679664014"><span id="local-6989586621679664015"><span id="local-6989586621679664016"><span id="local-6989586621679664017"><span class="hs-keyword">instance</span><span>
</span><span id="line-175"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-176"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelStack"><span class="hs-identifier hs-type">ModelStack</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679664017"><span class="hs-identifier hs-type">fstLayer</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679664016"><span class="hs-identifier hs-type">activation</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679664015"><span class="hs-identifier hs-type">dropout</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679664014"><span class="hs-identifier hs-type">sndLayer</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-177"></span><span>      </span><span class="annot"><a href="#local-6989586621679664013"><span class="hs-identifier hs-type">input</span></a></span><span>
</span><span id="line-178"></span><span>      </span><span class="annot"><a href="#local-6989586621679664012"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-179"></span><span>      </span><span class="annot"><a href="#local-6989586621679664011"><span class="hs-identifier hs-type">prediction</span></a></span><span>
</span><span id="line-180"></span><span>      </span><span class="annot"><a href="#local-6989586621679664010"><span class="hs-identifier hs-type">generatorOutputDevice</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-181"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Loss.html#MSELoss"><span class="hs-identifier hs-type">MSELoss</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679664011"><span class="hs-identifier hs-type">prediction</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679664009"><span class="hs-identifier hs-type">target</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679664010"><span class="hs-identifier hs-type">generatorOutputDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679664008"><span class="hs-identifier hs-type">output</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679664010"><span class="hs-identifier hs-type">generatorOutputDevice</span></a></span><span>
</span><span id="line-182"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-183"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-184"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Examples.TwoLayerNetwork.html#TwoLayerNetwork"><span class="hs-identifier hs-type">TwoLayerNetwork</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679664017"><span class="hs-identifier hs-type">fstLayer</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679664016"><span class="hs-identifier hs-type">activation</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679664015"><span class="hs-identifier hs-type">dropout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679664014"><span class="hs-identifier hs-type">sndLayer</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-185"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679664013"><span class="hs-identifier hs-type">input</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679664009"><span class="hs-identifier hs-type">target</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-186"></span><span>    </span><span class="annot"><a href="#local-6989586621679664012"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-187"></span><span>    </span><span class="annot"><a href="#local-6989586621679664008"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-188"></span><span>    </span><span class="annot"><a href="#local-6989586621679664010"><span class="hs-identifier hs-type">generatorOutputDevice</span></a></span><span>
</span><span id="line-189"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-190"></span><span>  </span><span id="local-6989586621679664005"><span class="annot"><span class="annottext">forward :: TwoLayerNetwork fstLayer activation dropout sndLayer
-&gt; (input, target)
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var hs-var hs-var hs-var">forward</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Examples.TwoLayerNetwork.html#TwoLayerNetwork"><span class="hs-identifier hs-type">TwoLayerNetwork</span></a></span><span> </span><span id="local-6989586621679664003"><span class="annot"><span class="annottext">ModelStack '[fstLayer, activation, dropout, sndLayer]
</span><a href="#local-6989586621679664003"><span class="hs-identifier hs-var">modelStack</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679664002"><span class="annot"><span class="annottext">input
</span><a href="#local-6989586621679664002"><span class="hs-identifier hs-var">input</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679664001"><span class="annot"><span class="annottext">target
</span><a href="#local-6989586621679664001"><span class="hs-identifier hs-var">target</span></a></span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679664000"><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679664000"><span class="hs-identifier hs-var">g</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-191"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679663999"><span class="annot"><span class="annottext">prediction
</span><a href="#local-6989586621679663999"><span class="hs-identifier hs-var">prediction</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679663998"><span class="annot"><span class="annottext">Generator generatorOutputDevice
</span><a href="#local-6989586621679663998"><span class="hs-identifier hs-var">g'</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">ModelStack '[fstLayer, activation, dropout, sndLayer]
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (prediction, Generator generatorOutputDevice)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: * -&gt; *).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">ModelStack '[fstLayer, activation, dropout, sndLayer]
</span><a href="#local-6989586621679664003"><span class="hs-identifier hs-var">modelStack</span></a></span><span> </span><span class="annot"><span class="annottext">input
</span><a href="#local-6989586621679664002"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679664000"><span class="hs-identifier hs-var">g</span></a></span><span>
</span><span id="line-192"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679663997"><span class="annot"><span class="annottext">output
</span><a href="#local-6989586621679663997"><span class="hs-identifier hs-var">loss</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679663996"><span class="annot"><span class="annottext">Generator generatorOutputDevice
</span><a href="#local-6989586621679663996"><span class="hs-identifier hs-var">g''</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">MSELoss
-&gt; (prediction, target)
-&gt; Generator generatorOutputDevice
-&gt; m (output, Generator generatorOutputDevice)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: * -&gt; *).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">MSELoss
</span><a href="Torch.GraduallyTyped.NN.Loss.html#MSELoss"><span class="hs-identifier hs-var">MSELoss</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">prediction
</span><a href="#local-6989586621679663999"><span class="hs-identifier hs-var">prediction</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">target
</span><a href="#local-6989586621679664001"><span class="hs-identifier hs-var">target</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Generator generatorOutputDevice
</span><a href="#local-6989586621679663998"><span class="hs-identifier hs-var">g'</span></a></span><span>
</span><span id="line-193"></span><span>    </span><span class="annot"><span class="annottext">(output, Generator generatorOutputDevice)
-&gt; m (output, Generator generatorOutputDevice)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">output
</span><a href="#local-6989586621679663997"><span class="hs-identifier hs-var">loss</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Generator generatorOutputDevice
</span><a href="#local-6989586621679663996"><span class="hs-identifier hs-var">g''</span></a></span><span class="hs-special">)</span></span></span></span></span></span></span></span></span></span></span><span>
</span><span id="line-194"></span><span>
</span><span id="line-195"></span><span class="hs-comment">-- | Data type for monitoring the training and evaluation losses.</span><span>
</span><span id="line-196"></span><span class="hs-keyword">data</span><span> </span><span id="Monitor"><span class="annot"><a href="Torch.GraduallyTyped.Examples.TwoLayerNetwork.html#Monitor"><span class="hs-identifier hs-var">Monitor</span></a></span></span><span>
</span><span id="line-197"></span><span>  </span><span class="hs-glyph">=</span><span> </span><span class="hs-comment">-- | monitor for training loss</span><span>
</span><span id="line-198"></span><span>    </span><span id="TrainingMonitor"><span class="annot"><a href="Torch.GraduallyTyped.Examples.TwoLayerNetwork.html#TrainingMonitor"><span class="hs-identifier hs-var">TrainingMonitor</span></a></span></span><span> </span><span class="hs-special">{</span><span id="mtLoss"><span class="annot"><span class="annottext">Monitor -&gt; Float
</span><a href="Torch.GraduallyTyped.Examples.TwoLayerNetwork.html#mtLoss"><span class="hs-identifier hs-var hs-var">mtLoss</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Float</span></span><span class="hs-special">,</span><span> </span><span id="mtEpoch"><span class="annot"><span class="annottext">Monitor -&gt; Int
</span><a href="Torch.GraduallyTyped.Examples.TwoLayerNetwork.html#mtEpoch"><span class="hs-identifier hs-var hs-var">mtEpoch</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">}</span><span>
</span><span id="line-199"></span><span>  </span><span class="hs-glyph">|</span><span> </span><span class="hs-comment">-- | monitor for evaluation loss</span><span>
</span><span id="line-200"></span><span>    </span><span id="EvaluationMonitor"><span class="annot"><a href="Torch.GraduallyTyped.Examples.TwoLayerNetwork.html#EvaluationMonitor"><span class="hs-identifier hs-var">EvaluationMonitor</span></a></span></span><span> </span><span class="hs-special">{</span><span id="meLoss"><span class="annot"><span class="annottext">Monitor -&gt; Float
</span><a href="Torch.GraduallyTyped.Examples.TwoLayerNetwork.html#meLoss"><span class="hs-identifier hs-var hs-var">meLoss</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Float</span></span><span class="hs-special">,</span><span> </span><span id="meEpoch"><span class="annot"><span class="annottext">Monitor -&gt; Int
</span><a href="Torch.GraduallyTyped.Examples.TwoLayerNetwork.html#meEpoch"><span class="hs-identifier hs-var hs-var">meEpoch</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">}</span><span>
</span><span id="line-201"></span><span>  </span><span class="hs-keyword">deriving</span><span> </span><span class="annot"><span class="hs-keyword">stock</span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679663983"><span id="local-6989586621679663985"><span id="local-6989586621679663987"><span class="annot"><span class="annottext">Int -&gt; Monitor -&gt; ShowS
[Monitor] -&gt; ShowS
Monitor -&gt; String
(Int -&gt; Monitor -&gt; ShowS)
-&gt; (Monitor -&gt; String) -&gt; ([Monitor] -&gt; ShowS) -&gt; Show Monitor
forall a.
(Int -&gt; a -&gt; ShowS) -&gt; (a -&gt; String) -&gt; ([a] -&gt; ShowS) -&gt; Show a
showList :: [Monitor] -&gt; ShowS
$cshowList :: [Monitor] -&gt; ShowS
show :: Monitor -&gt; String
$cshow :: Monitor -&gt; String
showsPrec :: Int -&gt; Monitor -&gt; ShowS
$cshowsPrec :: Int -&gt; Monitor -&gt; ShowS
</span><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">Show</span></span></span></span></span><span class="hs-special">)</span><span>
</span><span id="line-202"></span><span>
</span><span id="line-203"></span><span class="hs-comment">-- | A simple monitor that prints the training and evaluation losses to stdout.</span><span>
</span><span id="line-204"></span><span id="local-6989586621679664143"><span id="local-6989586621679664144"><span class="annot"><a href="Torch.GraduallyTyped.Examples.TwoLayerNetwork.html#monitor"><span class="hs-identifier hs-type">monitor</span></a></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">MonadIO</span></span><span> </span><span class="annot"><a href="#local-6989586621679664144"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="hs-glyph">=&gt;</span><span> </span><span class="annot"><a href="../file:///nix/store/2275zkfvd9na2mx7hmkq7wzrgjyxz84l-pipes-lib-pipes-4.3.15-haddock-doc/share/doc/pipes/html/src"><span class="hs-identifier hs-type">P.Consumer</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Examples.TwoLayerNetwork.html#Monitor"><span class="hs-identifier hs-type">Monitor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679664144"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679664143"><span class="hs-identifier hs-type">r</span></a></span></span></span><span>
</span><span id="line-205"></span><span id="monitor"><span class="annot"><span class="annottext">monitor :: Consumer Monitor m r
</span><a href="Torch.GraduallyTyped.Examples.TwoLayerNetwork.html#monitor"><span class="hs-identifier hs-var hs-var">monitor</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(Monitor -&gt; String) -&gt; Pipe Monitor String m r
forall (m :: * -&gt; *) a b r. Functor m =&gt; (a -&gt; b) -&gt; Pipe a b m r
</span><a href="../file:///nix/store/2275zkfvd9na2mx7hmkq7wzrgjyxz84l-pipes-lib-pipes-4.3.15-haddock-doc/share/doc/pipes/html/src"><span class="hs-identifier hs-var">P.map</span></a></span><span> </span><span class="annot"><span class="annottext">Monitor -&gt; String
forall a. Show a =&gt; a -&gt; String
</span><span class="hs-identifier hs-var">show</span></span><span> </span><span class="annot"><span class="annottext">Pipe Monitor String m r
-&gt; Proxy () String () X m r -&gt; Consumer Monitor m r
forall (m :: * -&gt; *) a' a b r c' c.
Functor m =&gt;
Proxy a' a () b m r -&gt; Proxy () b c' c m r -&gt; Proxy a' a c' c m r
</span><a href="../file:///nix/store/2275zkfvd9na2mx7hmkq7wzrgjyxz84l-pipes-lib-pipes-4.3.15-haddock-doc/share/doc/pipes/html/src"><span class="hs-operator hs-var">P.&gt;-&gt;</span></a></span><span> </span><span class="annot"><span class="annottext">Proxy () String () X m r
forall (m :: * -&gt; *) r. MonadIO m =&gt; Consumer' String m r
</span><a href="../file:///nix/store/2275zkfvd9na2mx7hmkq7wzrgjyxz84l-pipes-lib-pipes-4.3.15-haddock-doc/share/doc/pipes/html/src"><span class="hs-identifier hs-var">P.stdoutLn'</span></a></span><span>
</span><span id="line-206"></span><span>
</span><span id="line-207"></span><span class="hs-comment">-- | Collate a stream of examples into batches.</span><span>
</span><span id="line-208"></span><span class="hs-comment">-- The returned batches are of the form @(input, target)@,</span><span>
</span><span id="line-209"></span><span class="hs-comment">-- where @(input, target)@ is a pair of tensors.</span><span>
</span><span id="line-210"></span><span class="hs-comment">-- @input@ and @target@ are both of shape:</span><span>
</span><span id="line-211"></span><span class="hs-comment">--</span><span>
</span><span id="line-212"></span><span class="hs-comment">-- &gt; Dim (SName @&quot;*&quot;) (UncheckedSize batchSize) :|: Dim (SName @&quot;*&quot;) (SSize @1) :|: SNil</span><span>
</span><span id="line-213"></span><span class="hs-comment">--</span><span>
</span><span id="line-214"></span><span class="hs-comment">-- where @batchSize@ is the number of examples in the batch.</span><span>
</span><span id="line-215"></span><span class="annot"><a href="Torch.GraduallyTyped.Examples.TwoLayerNetwork.html#collate"><span class="hs-identifier hs-type">collate</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-216"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679664239"><span class="annot"><a href="#local-6989586621679664239"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679664237"><span class="annot"><a href="#local-6989586621679664237"><span class="hs-identifier hs-type">r</span></a></span></span><span> </span><span id="local-6989586621679664240"><span class="annot"><a href="#local-6989586621679664240"><span class="hs-identifier hs-type">input</span></a></span></span><span> </span><span id="local-6989586621679664238"><span class="annot"><a href="#local-6989586621679664238"><span class="hs-identifier hs-type">target</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-217"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="#local-6989586621679664240"><span class="hs-identifier hs-type">input</span></a></span><span>
</span><span id="line-218"></span><span>      </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-219"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#WithoutGradient"><span class="hs-identifier hs-type">WithoutGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-220"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Dense"><span class="hs-identifier hs-type">Dense</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-221"></span><span>          </span><span class="annot"><a href="#local-6989586621679664239"><span class="hs-identifier hs-type">device</span></a></span><span>
</span><span id="line-222"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#Float"><span class="hs-identifier hs-type">Float</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-223"></span><span>          </span><span class="hs-special">(</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span>
</span><span id="line-224"></span><span>              </span><span class="hs-special">'</span><span class="hs-special">[</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#UncheckedSize"><span class="hs-identifier hs-type">UncheckedSize</span></a></span><span class="hs-special">,</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">]</span><span>
</span><span id="line-225"></span><span>          </span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-226"></span><span>    </span><span class="annot"><a href="#local-6989586621679664238"><span class="hs-identifier hs-type">target</span></a></span><span>
</span><span id="line-227"></span><span>      </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-228"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#WithoutGradient"><span class="hs-identifier hs-type">WithoutGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-229"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Dense"><span class="hs-identifier hs-type">Dense</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-230"></span><span>          </span><span class="annot"><a href="#local-6989586621679664239"><span class="hs-identifier hs-type">device</span></a></span><span>
</span><span id="line-231"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#Float"><span class="hs-identifier hs-type">Float</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-232"></span><span>          </span><span class="hs-special">(</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span>
</span><span id="line-233"></span><span>              </span><span class="hs-special">'</span><span class="hs-special">[</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#UncheckedSize"><span class="hs-identifier hs-type">UncheckedSize</span></a></span><span class="hs-special">,</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">]</span><span>
</span><span id="line-234"></span><span>          </span><span class="hs-special">)</span><span>
</span><span id="line-235"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-236"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#SDevice"><span class="hs-identifier hs-type">SDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679664239"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-237"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-238"></span><span>  </span><span class="annot"><a href="../file:///nix/store/2275zkfvd9na2mx7hmkq7wzrgjyxz84l-pipes-lib-pipes-4.3.15-haddock-doc/share/doc/pipes/html/src"><span class="hs-identifier hs-type">P.ListT</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">IO</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">Float</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Float</span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-239"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">ContT</span></span><span> </span><span class="annot"><a href="#local-6989586621679664237"><span class="hs-identifier hs-type">r</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">IO</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/2275zkfvd9na2mx7hmkq7wzrgjyxz84l-pipes-lib-pipes-4.3.15-haddock-doc/share/doc/pipes/html/src"><span class="hs-identifier hs-type">P.ListT</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">IO</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679664240"><span class="hs-identifier hs-type">input</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679664238"><span class="hs-identifier hs-type">target</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-240"></span><span id="collate"><span class="annot"><span class="annottext">collate :: SDevice device
-&gt; Int
-&gt; ListT IO (Float, Float)
-&gt; ContT r IO (ListT IO (input, target))
</span><a href="Torch.GraduallyTyped.Examples.TwoLayerNetwork.html#collate"><span class="hs-identifier hs-var hs-var">collate</span></a></span></span><span> </span><span id="local-6989586621679663975"><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679663975"><span class="hs-identifier hs-var">device</span></a></span></span><span> </span><span id="local-6989586621679663974"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679663974"><span class="hs-identifier hs-var">batchSize</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-241"></span><span>  </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679663973"><span class="annot"><span class="annottext">collateFn :: [(Float, Float)]
-&gt; Maybe
     (Tensor
        ('Gradient 'WithoutGradient)
        ('Layout 'Dense)
        device
        ('DataType 'Float)
        ('Shape
           '[ 'Dim ('Name &quot;*&quot;) 'UncheckedSize, 'Dim ('Name &quot;*&quot;) ('Size 1)]),
      Tensor
        ('Gradient 'WithoutGradient)
        ('Layout 'Dense)
        device
        ('DataType 'Float)
        ('Shape
           '[ 'Dim ('Name &quot;*&quot;) 'UncheckedSize, 'Dim ('Name &quot;*&quot;) ('Size 1)]))
</span><a href="#local-6989586621679663973"><span class="hs-identifier hs-var hs-var">collateFn</span></a></span></span><span> </span><span id="local-6989586621679663972"><span class="annot"><span class="annottext">[(Float, Float)]
</span><a href="#local-6989586621679663972"><span class="hs-identifier hs-var">chunk</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-242"></span><span>        </span><span class="hs-keyword">let</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679663971"><span class="annot"><span class="annottext">[Float]
</span><a href="#local-6989586621679663971"><span class="hs-identifier hs-var">xs</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679663970"><span class="annot"><span class="annottext">[Float]
</span><a href="#local-6989586621679663970"><span class="hs-identifier hs-var">ys</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">[(Float, Float)] -&gt; ([Float], [Float])
forall a b. [(a, b)] -&gt; ([a], [b])
</span><span class="hs-identifier hs-var">unzip</span></span><span> </span><span class="annot"><span class="annottext">[(Float, Float)]
</span><a href="#local-6989586621679663972"><span class="hs-identifier hs-var">chunk</span></a></span><span>
</span><span id="line-243"></span><span>            </span><span id="local-6989586621679663968"><span class="annot"><span class="annottext">xs' :: [Vector 1 Float]
</span><a href="#local-6989586621679663968"><span class="hs-identifier hs-var hs-var">xs'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Float -&gt; Vector 1 Float
forall a. a -&gt; Vector 1 a
</span><a href="../file:///nix/store/33j53czfh9iaqr8w1k6rjcna7zg8rw55-vector-sized-lib-vector-sized-1.4.3.1-haddock-doc/share/doc/vector-sized/html/src"><span class="hs-identifier hs-var">VS.singleton</span></a></span><span> </span><span class="annot"><span class="annottext">(Float -&gt; Vector 1 Float) -&gt; [Float] -&gt; [Vector 1 Float]
forall (f :: * -&gt; *) a b. Functor f =&gt; (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;$&gt;</span></span><span> </span><span class="annot"><span class="annottext">[Float]
</span><a href="#local-6989586621679663971"><span class="hs-identifier hs-var">xs</span></a></span><span>
</span><span id="line-244"></span><span>            </span><span id="local-6989586621679663966"><span class="annot"><span class="annottext">ys' :: [Vector 1 Float]
</span><a href="#local-6989586621679663966"><span class="hs-identifier hs-var hs-var">ys'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Float -&gt; Vector 1 Float
forall a. a -&gt; Vector 1 a
</span><a href="../file:///nix/store/33j53czfh9iaqr8w1k6rjcna7zg8rw55-vector-sized-lib-vector-sized-1.4.3.1-haddock-doc/share/doc/vector-sized/html/src"><span class="hs-identifier hs-var">VS.singleton</span></a></span><span> </span><span class="annot"><span class="annottext">(Float -&gt; Vector 1 Float) -&gt; [Float] -&gt; [Vector 1 Float]
forall (f :: * -&gt; *) a b. Functor f =&gt; (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;$&gt;</span></span><span> </span><span class="annot"><span class="annottext">[Float]
</span><a href="#local-6989586621679663970"><span class="hs-identifier hs-var">ys</span></a></span><span>
</span><span id="line-245"></span><span>            </span><span id="local-6989586621679663965"><span class="annot"><span class="annottext">sToTensor' :: [Vector 1 Float]
-&gt; Maybe
     (Tensor
        ('Gradient 'WithoutGradient)
        ('Layout 'Dense)
        device
        ('DataType 'Float)
        ('Shape
           '[ 'Dim ('Name &quot;*&quot;) 'UncheckedSize, 'Dim ('Name &quot;*&quot;) ('Size 1)]))
</span><a href="#local-6989586621679663965"><span class="hs-identifier hs-var hs-var">sToTensor'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SGradient ('Gradient 'WithoutGradient)
-&gt; SLayout ('Layout 'Dense)
-&gt; SDevice device
-&gt; [Vector 1 Float]
-&gt; Maybe
     (Tensor
        ('Gradient 'WithoutGradient)
        ('Layout 'Dense)
        device
        ('DataType 'Float)
        ('Shape
           '[ 'Dim ('Name &quot;*&quot;) 'UncheckedSize, 'Dim ('Name &quot;*&quot;) ('Size 1)]))
forall a (dType :: DType) (dims :: [Dim (Name Symbol) (Size Nat)])
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (m :: * -&gt; *).
(TensorLike a dType dims, MonadThrow m) =&gt;
SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; a
-&gt; m (Tensor
        gradient layout device ('DataType dType) ('Shape dims))
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sToTensor"><span class="hs-identifier hs-var">sToTensor</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SRequiresGradient 'WithoutGradient
-&gt; SGradient ('Gradient 'WithoutGradient)
forall (requiresGradient :: RequiresGradient).
SRequiresGradient requiresGradient
-&gt; SGradient ('Gradient requiresGradient)
</span><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier hs-var">SGradient</span></a></span><span> </span><span class="annot"><span class="annottext">SRequiresGradient 'WithoutGradient
</span><a href="Torch.GraduallyTyped.RequiresGradient.html#SWithoutGradient"><span class="hs-identifier hs-var">SWithoutGradient</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SLayoutType 'Dense -&gt; SLayout ('Layout 'Dense)
forall (layoutType :: LayoutType).
SLayoutType layoutType -&gt; SLayout ('Layout layoutType)
</span><a href="Torch.GraduallyTyped.Layout.html#SLayout"><span class="hs-identifier hs-var">SLayout</span></a></span><span> </span><span class="annot"><span class="annottext">SLayoutType 'Dense
</span><a href="Torch.GraduallyTyped.Layout.html#SDense"><span class="hs-identifier hs-var">SDense</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679663975"><span class="hs-identifier hs-var">device</span></a></span><span>
</span><span id="line-246"></span><span>         </span><span class="hs-keyword">in</span><span> </span><span class="hs-special">(</span><span class="hs-special">,</span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">(Tensor
   ('Gradient 'WithoutGradient)
   ('Layout 'Dense)
   device
   ('DataType 'Float)
   ('Shape
      '[ 'Dim ('Name &quot;*&quot;) 'UncheckedSize, 'Dim ('Name &quot;*&quot;) ('Size 1)])
 -&gt; Tensor
      ('Gradient 'WithoutGradient)
      ('Layout 'Dense)
      device
      ('DataType 'Float)
      ('Shape
         '[ 'Dim ('Name &quot;*&quot;) 'UncheckedSize, 'Dim ('Name &quot;*&quot;) ('Size 1)])
 -&gt; (Tensor
       ('Gradient 'WithoutGradient)
       ('Layout 'Dense)
       device
       ('DataType 'Float)
       ('Shape
          '[ 'Dim ('Name &quot;*&quot;) 'UncheckedSize, 'Dim ('Name &quot;*&quot;) ('Size 1)]),
     Tensor
       ('Gradient 'WithoutGradient)
       ('Layout 'Dense)
       device
       ('DataType 'Float)
       ('Shape
          '[ 'Dim ('Name &quot;*&quot;) 'UncheckedSize, 'Dim ('Name &quot;*&quot;) ('Size 1)])))
-&gt; Maybe
     (Tensor
        ('Gradient 'WithoutGradient)
        ('Layout 'Dense)
        device
        ('DataType 'Float)
        ('Shape
           '[ 'Dim ('Name &quot;*&quot;) 'UncheckedSize, 'Dim ('Name &quot;*&quot;) ('Size 1)]))
-&gt; Maybe
     (Tensor
        ('Gradient 'WithoutGradient)
        ('Layout 'Dense)
        device
        ('DataType 'Float)
        ('Shape
           '[ 'Dim ('Name &quot;*&quot;) 'UncheckedSize, 'Dim ('Name &quot;*&quot;) ('Size 1)])
      -&gt; (Tensor
            ('Gradient 'WithoutGradient)
            ('Layout 'Dense)
            device
            ('DataType 'Float)
            ('Shape
               '[ 'Dim ('Name &quot;*&quot;) 'UncheckedSize, 'Dim ('Name &quot;*&quot;) ('Size 1)]),
          Tensor
            ('Gradient 'WithoutGradient)
            ('Layout 'Dense)
            device
            ('DataType 'Float)
            ('Shape
               '[ 'Dim ('Name &quot;*&quot;) 'UncheckedSize, 'Dim ('Name &quot;*&quot;) ('Size 1)])))
forall (f :: * -&gt; *) a b. Functor f =&gt; (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;$&gt;</span></span><span> </span><span class="annot"><span class="annottext">[Vector 1 Float]
-&gt; Maybe
     (Tensor
        ('Gradient 'WithoutGradient)
        ('Layout 'Dense)
        device
        ('DataType 'Float)
        ('Shape
           '[ 'Dim ('Name &quot;*&quot;) 'UncheckedSize, 'Dim ('Name &quot;*&quot;) ('Size 1)]))
</span><a href="#local-6989586621679663965"><span class="hs-identifier hs-var">sToTensor'</span></a></span><span> </span><span class="annot"><span class="annottext">[Vector 1 Float]
</span><a href="#local-6989586621679663968"><span class="hs-identifier hs-var">xs'</span></a></span><span> </span><span class="annot"><span class="annottext">Maybe
  (Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     device
     ('DataType 'Float)
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) 'UncheckedSize, 'Dim ('Name &quot;*&quot;) ('Size 1)])
   -&gt; (Tensor
         ('Gradient 'WithoutGradient)
         ('Layout 'Dense)
         device
         ('DataType 'Float)
         ('Shape
            '[ 'Dim ('Name &quot;*&quot;) 'UncheckedSize, 'Dim ('Name &quot;*&quot;) ('Size 1)]),
       Tensor
         ('Gradient 'WithoutGradient)
         ('Layout 'Dense)
         device
         ('DataType 'Float)
         ('Shape
            '[ 'Dim ('Name &quot;*&quot;) 'UncheckedSize, 'Dim ('Name &quot;*&quot;) ('Size 1)])))
-&gt; Maybe
     (Tensor
        ('Gradient 'WithoutGradient)
        ('Layout 'Dense)
        device
        ('DataType 'Float)
        ('Shape
           '[ 'Dim ('Name &quot;*&quot;) 'UncheckedSize, 'Dim ('Name &quot;*&quot;) ('Size 1)]))
-&gt; Maybe
     (Tensor
        ('Gradient 'WithoutGradient)
        ('Layout 'Dense)
        device
        ('DataType 'Float)
        ('Shape
           '[ 'Dim ('Name &quot;*&quot;) 'UncheckedSize, 'Dim ('Name &quot;*&quot;) ('Size 1)]),
      Tensor
        ('Gradient 'WithoutGradient)
        ('Layout 'Dense)
        device
        ('DataType 'Float)
        ('Shape
           '[ 'Dim ('Name &quot;*&quot;) 'UncheckedSize, 'Dim ('Name &quot;*&quot;) ('Size 1)]))
forall (f :: * -&gt; *) a b. Applicative f =&gt; f (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;*&gt;</span></span><span> </span><span class="annot"><span class="annottext">[Vector 1 Float]
-&gt; Maybe
     (Tensor
        ('Gradient 'WithoutGradient)
        ('Layout 'Dense)
        device
        ('DataType 'Float)
        ('Shape
           '[ 'Dim ('Name &quot;*&quot;) 'UncheckedSize, 'Dim ('Name &quot;*&quot;) ('Size 1)]))
</span><a href="#local-6989586621679663965"><span class="hs-identifier hs-var">sToTensor'</span></a></span><span> </span><span class="annot"><span class="annottext">[Vector 1 Float]
</span><a href="#local-6989586621679663966"><span class="hs-identifier hs-var">ys'</span></a></span><span>
</span><span id="line-247"></span><span>   </span><span class="hs-keyword">in</span><span> </span><span class="annot"><span class="annottext">Buffer
  (Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     device
     ('DataType 'Float)
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) 'UncheckedSize, 'Dim ('Name &quot;*&quot;) ('Size 1)]),
   Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     device
     ('DataType 'Float)
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) 'UncheckedSize, 'Dim ('Name &quot;*&quot;) ('Size 1)]))
-&gt; Int
-&gt; ([(Float, Float)]
    -&gt; Maybe
         (Tensor
            ('Gradient 'WithoutGradient)
            ('Layout 'Dense)
            device
            ('DataType 'Float)
            ('Shape
               '[ 'Dim ('Name &quot;*&quot;) 'UncheckedSize, 'Dim ('Name &quot;*&quot;) ('Size 1)]),
          Tensor
            ('Gradient 'WithoutGradient)
            ('Layout 'Dense)
            device
            ('DataType 'Float)
            ('Shape
               '[ 'Dim ('Name &quot;*&quot;) 'UncheckedSize, 'Dim ('Name &quot;*&quot;) ('Size 1)])))
-&gt; ListT IO (Float, Float)
-&gt; ContT
     r
     IO
     (ListT
        IO
        (Tensor
           ('Gradient 'WithoutGradient)
           ('Layout 'Dense)
           device
           ('DataType 'Float)
           ('Shape
              '[ 'Dim ('Name &quot;*&quot;) 'UncheckedSize, 'Dim ('Name &quot;*&quot;) ('Size 1)]),
         Tensor
           ('Gradient 'WithoutGradient)
           ('Layout 'Dense)
           device
           ('DataType 'Float)
           ('Shape
              '[ 'Dim ('Name &quot;*&quot;) 'UncheckedSize, 'Dim ('Name &quot;*&quot;) ('Size 1)])))
forall (m :: * -&gt; *) batch sample r.
(MonadIO m, MonadBaseControl IO m) =&gt;
Buffer batch
-&gt; Int
-&gt; ([sample] -&gt; Maybe batch)
-&gt; ListT m sample
-&gt; ContT r m (ListT m batch)
</span><a href="../../../../hasktorch/html/src"><span class="hs-identifier hs-var">bufferedCollate</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Int
-&gt; Buffer
     (Tensor
        ('Gradient 'WithoutGradient)
        ('Layout 'Dense)
        device
        ('DataType 'Float)
        ('Shape
           '[ 'Dim ('Name &quot;*&quot;) 'UncheckedSize, 'Dim ('Name &quot;*&quot;) ('Size 1)]),
      Tensor
        ('Gradient 'WithoutGradient)
        ('Layout 'Dense)
        device
        ('DataType 'Float)
        ('Shape
           '[ 'Dim ('Name &quot;*&quot;) 'UncheckedSize, 'Dim ('Name &quot;*&quot;) ('Size 1)]))
forall a. Int -&gt; Buffer a
</span><a href="../file:///nix/store/gi3ii02mxr2l6qd73gq29asx1kn1yvi3-pipes-concurrency-lib-pipes-concurrency-2.0.12-haddock-doc/share/doc/pipes-concurrency/html/src"><span class="hs-identifier hs-var">P.bounded</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">1</span></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679663974"><span class="hs-identifier hs-var">batchSize</span></a></span><span> </span><span class="annot"><span class="annottext">[(Float, Float)]
-&gt; Maybe
     (Tensor
        ('Gradient 'WithoutGradient)
        ('Layout 'Dense)
        device
        ('DataType 'Float)
        ('Shape
           '[ 'Dim ('Name &quot;*&quot;) 'UncheckedSize, 'Dim ('Name &quot;*&quot;) ('Size 1)]),
      Tensor
        ('Gradient 'WithoutGradient)
        ('Layout 'Dense)
        device
        ('DataType 'Float)
        ('Shape
           '[ 'Dim ('Name &quot;*&quot;) 'UncheckedSize, 'Dim ('Name &quot;*&quot;) ('Size 1)]))
</span><a href="#local-6989586621679663973"><span class="hs-identifier hs-var">collateFn</span></a></span><span>
</span><span id="line-248"></span><span>
</span><span id="line-249"></span><span class="hs-comment">-- | Run the two-layer network training loop on a toy dataset.</span><span>
</span><span id="line-250"></span><span class="annot"><a href="Torch.GraduallyTyped.Examples.TwoLayerNetwork.html#runTwoLayerNetworkExample"><span class="hs-identifier hs-type">runTwoLayerNetworkExample</span></a></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">IO</span></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-251"></span><span id="runTwoLayerNetworkExample"><span class="annot"><span class="annottext">runTwoLayerNetworkExample :: IO ()
</span><a href="Torch.GraduallyTyped.Examples.TwoLayerNetwork.html#runTwoLayerNetworkExample"><span class="hs-identifier hs-var hs-var">runTwoLayerNetworkExample</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-252"></span><span>  </span><span class="hs-keyword">let</span><span> </span><span class="hs-comment">-- seed for the random number generator</span><span>
</span><span id="line-253"></span><span>      </span><span id="local-6989586621679663956"><span class="annot"><span class="annottext">seed :: Word64
</span><a href="#local-6989586621679663956"><span class="hs-identifier hs-var hs-var">seed</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Word64
</span><span class="hs-number">0</span></span><span>
</span><span id="line-254"></span><span>
</span><span id="line-255"></span><span>  </span><span class="hs-keyword">let</span><span> </span><span class="hs-comment">-- compute device</span><span>
</span><span id="line-256"></span><span>      </span><span id="local-6989586621679663955"><span class="annot"><span class="annottext">device :: SDevice ('Device 'CPU)
</span><a href="#local-6989586621679663955"><span class="hs-identifier hs-var hs-var">device</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SDeviceType 'CPU -&gt; SDevice ('Device 'CPU)
forall (deviceType :: DeviceType Nat).
SDeviceType deviceType -&gt; SDevice ('Device deviceType)
</span><a href="Torch.GraduallyTyped.Device.html#SDevice"><span class="hs-identifier hs-var">SDevice</span></a></span><span> </span><span class="annot"><span class="annottext">SDeviceType 'CPU
</span><a href="Torch.GraduallyTyped.Device.html#SCPU"><span class="hs-identifier hs-var">SCPU</span></a></span><span>
</span><span id="line-257"></span><span>
</span><span id="line-258"></span><span>  </span><span class="hs-keyword">let</span><span> </span><span class="hs-comment">-- input dimension of the network</span><span>
</span><span id="line-259"></span><span>      </span><span id="local-6989586621679663952"><span class="annot"><span class="annottext">inputDim :: SDim ('Dim ('Name &quot;*&quot;) ('Size 1))
</span><a href="#local-6989586621679663952"><span class="hs-identifier hs-var hs-var">inputDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SNoName"><span class="hs-identifier hs-var">SNoName</span></a></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize ('Size 1) -&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 1))
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownNat 1 =&gt; SSize ('Size 1)
forall (size :: Nat). KnownNat size =&gt; SSize ('Size size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier hs-var">SSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">1</span></span><span>
</span><span id="line-260"></span><span>      </span><span class="hs-comment">-- output dimension of the network</span><span>
</span><span id="line-261"></span><span>      </span><span id="local-6989586621679663948"><span class="annot"><span class="annottext">outputDim :: SDim ('Dim ('Name &quot;*&quot;) ('Size 1))
</span><a href="#local-6989586621679663948"><span class="hs-identifier hs-var hs-var">outputDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SNoName"><span class="hs-identifier hs-var">SNoName</span></a></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize ('Size 1) -&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 1))
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownNat 1 =&gt; SSize ('Size 1)
forall (size :: Nat). KnownNat size =&gt; SSize ('Size size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier hs-var">SSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">1</span></span><span>
</span><span id="line-262"></span><span>      </span><span class="hs-comment">-- hidden dimension of the network</span><span>
</span><span id="line-263"></span><span>      </span><span id="local-6989586621679663947"><span class="annot"><span class="annottext">hiddenDim :: SDim ('Dim ('Name &quot;*&quot;) ('Size 100))
</span><a href="#local-6989586621679663947"><span class="hs-identifier hs-var hs-var">hiddenDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SNoName"><span class="hs-identifier hs-var">SNoName</span></a></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize ('Size 100) -&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 100))
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownNat 100 =&gt; SSize ('Size 100)
forall (size :: Nat). KnownNat size =&gt; SSize ('Size size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier hs-var">SSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">100</span></span><span>
</span><span id="line-264"></span><span>
</span><span id="line-265"></span><span>  </span><span class="hs-keyword">let</span><span> </span><span class="hs-comment">-- create the model specifications</span><span>
</span><span id="line-266"></span><span>      </span><span id="local-6989586621679663946"><span class="annot"><span class="annottext">mkModelSpec :: SRequiresGradient requiresGradient
-&gt; SHasDropout hasDropout
-&gt; ModelSpec
     (TwoLayerNetworkF
        ('Gradient requiresGradient)
        hasDropout
        ('Device 'CPU)
        ('DataType 'Float)
        ('Dim ('Name &quot;*&quot;) ('Size 1))
        ('Dim ('Name &quot;*&quot;) ('Size 1))
        ('Dim ('Name &quot;*&quot;) ('Size 100)))
</span><a href="#local-6989586621679663946"><span class="hs-identifier hs-var hs-var">mkModelSpec</span></a></span></span><span> </span><span id="local-6989586621679663945"><span class="annot"><span class="annottext">SRequiresGradient requiresGradient
</span><a href="#local-6989586621679663945"><span class="hs-identifier hs-var">hasGradient</span></a></span></span><span> </span><span id="local-6989586621679663944"><span class="annot"><span class="annottext">SHasDropout hasDropout
</span><a href="#local-6989586621679663944"><span class="hs-identifier hs-var">hasDropout</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-267"></span><span>        </span><span class="annot"><span class="annottext">SGradient ('Gradient requiresGradient)
-&gt; SHasDropout hasDropout
-&gt; SDevice ('Device 'CPU)
-&gt; SDataType ('DataType 'Float)
-&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 1))
-&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 1))
-&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 100))
-&gt; Double
-&gt; ModelSpec
     (TwoLayerNetworkF
        ('Gradient requiresGradient)
        hasDropout
        ('Device 'CPU)
        ('DataType 'Float)
        ('Dim ('Name &quot;*&quot;) ('Size 1))
        ('Dim ('Name &quot;*&quot;) ('Size 1))
        ('Dim ('Name &quot;*&quot;) ('Size 100)))
forall (gradient :: Gradient RequiresGradient)
       (hasDropout :: HasDropout) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (inputDim :: Dim (Name Symbol) (Size Nat))
       (outputDim :: Dim (Name Symbol) (Size Nat))
       (hiddenDim :: Dim (Name Symbol) (Size Nat)).
SGradient gradient
-&gt; SHasDropout hasDropout
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim inputDim
-&gt; SDim outputDim
-&gt; SDim hiddenDim
-&gt; Double
-&gt; ModelSpec
     (TwoLayerNetworkF
        gradient hasDropout device dataType inputDim outputDim hiddenDim)
</span><a href="Torch.GraduallyTyped.Examples.TwoLayerNetwork.html#twoLayerNetworkSpec"><span class="hs-identifier hs-var">twoLayerNetworkSpec</span></a></span><span>
</span><span id="line-268"></span><span>          </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SRequiresGradient requiresGradient
-&gt; SGradient ('Gradient requiresGradient)
forall (requiresGradient :: RequiresGradient).
SRequiresGradient requiresGradient
-&gt; SGradient ('Gradient requiresGradient)
</span><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier hs-var">SGradient</span></a></span><span> </span><span class="annot"><span class="annottext">SRequiresGradient requiresGradient
</span><a href="#local-6989586621679663945"><span class="hs-identifier hs-var">hasGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-269"></span><span>          </span><span class="annot"><span class="annottext">SHasDropout hasDropout
</span><a href="#local-6989586621679663944"><span class="hs-identifier hs-var">hasDropout</span></a></span><span>
</span><span id="line-270"></span><span>          </span><span class="annot"><span class="annottext">SDevice ('Device 'CPU)
</span><a href="#local-6989586621679663955"><span class="hs-identifier hs-var">device</span></a></span><span>
</span><span id="line-271"></span><span>          </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SDType 'Float -&gt; SDataType ('DataType 'Float)
forall (dType :: DType).
SDType dType -&gt; SDataType ('DataType dType)
</span><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier hs-var">SDataType</span></a></span><span> </span><span class="annot"><span class="annottext">SDType 'Float
</span><a href="Torch.GraduallyTyped.DType.html#SFloat"><span class="hs-identifier hs-var">SFloat</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-272"></span><span>          </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 1))
</span><a href="#local-6989586621679663952"><span class="hs-identifier hs-var">inputDim</span></a></span><span>
</span><span id="line-273"></span><span>          </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 1))
</span><a href="#local-6989586621679663948"><span class="hs-identifier hs-var">outputDim</span></a></span><span>
</span><span id="line-274"></span><span>          </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 100))
</span><a href="#local-6989586621679663947"><span class="hs-identifier hs-var">hiddenDim</span></a></span><span>
</span><span id="line-275"></span><span>          </span><span class="annot"><span class="annottext">Double
</span><span class="hs-number">0.1</span></span><span>
</span><span id="line-276"></span><span>      </span><span class="hs-comment">-- during training, we need to turn dropout on and keep track of the gradient</span><span>
</span><span id="line-277"></span><span>      </span><span id="local-6989586621679663941"><span class="annot"><span class="annottext">trainingModelSpec :: NamedModel
  (TwoLayerNetwork
     (NamedModel
        (GLinear
           (NamedModel
              (TensorSpec
                 ('Gradient 'WithGradient)
                 ('Layout 'Dense)
                 ('Device 'CPU)
                 ('DataType 'Float)
                 ('Shape
                    '[ 'Dim ('Name &quot;*&quot;) ('Size 100), 'Dim ('Name &quot;*&quot;) ('Size 1)])))
           (NamedModel
              (TensorSpec
                 ('Gradient 'WithGradient)
                 ('Layout 'Dense)
                 ('Device 'CPU)
                 ('DataType 'Float)
                 ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 100)])))))
     Tanh
     (ModelSpec (TLNDropoutF 'WithDropout))
     (NamedModel
        (GLinear
           (NamedModel
              (TensorSpec
                 ('Gradient 'WithGradient)
                 ('Layout 'Dense)
                 ('Device 'CPU)
                 ('DataType 'Float)
                 ('Shape
                    '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 100)])))
           (NamedModel
              (TensorSpec
                 ('Gradient 'WithGradient)
                 ('Layout 'Dense)
                 ('Device 'CPU)
                 ('DataType 'Float)
                 ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1)]))))))
</span><a href="#local-6989586621679663941"><span class="hs-identifier hs-var hs-var">trainingModelSpec</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SRequiresGradient 'WithGradient
-&gt; SHasDropout 'WithDropout
-&gt; NamedModel
     (TwoLayerNetwork
        (NamedModel
           (GLinear
              (NamedModel
                 (TensorSpec
                    ('Gradient 'WithGradient)
                    ('Layout 'Dense)
                    ('Device 'CPU)
                    ('DataType 'Float)
                    ('Shape
                       '[ 'Dim ('Name &quot;*&quot;) ('Size 100), 'Dim ('Name &quot;*&quot;) ('Size 1)])))
              (NamedModel
                 (TensorSpec
                    ('Gradient 'WithGradient)
                    ('Layout 'Dense)
                    ('Device 'CPU)
                    ('DataType 'Float)
                    ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 100)])))))
        Tanh
        (ModelSpec (TLNDropoutF 'WithDropout))
        (NamedModel
           (GLinear
              (NamedModel
                 (TensorSpec
                    ('Gradient 'WithGradient)
                    ('Layout 'Dense)
                    ('Device 'CPU)
                    ('DataType 'Float)
                    ('Shape
                       '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 100)])))
              (NamedModel
                 (TensorSpec
                    ('Gradient 'WithGradient)
                    ('Layout 'Dense)
                    ('Device 'CPU)
                    ('DataType 'Float)
                    ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1)]))))))
forall (requiresGradient :: RequiresGradient)
       (hasDropout :: HasDropout).
SRequiresGradient requiresGradient
-&gt; SHasDropout hasDropout
-&gt; NamedModel
     (TwoLayerNetwork
        (NamedModel
           (GLinear
              (NamedModel
                 (TensorSpec
                    ('Gradient requiresGradient)
                    ('Layout 'Dense)
                    ('Device 'CPU)
                    ('DataType 'Float)
                    ('Shape
                       '[ 'Dim ('Name &quot;*&quot;) ('Size 100), 'Dim ('Name &quot;*&quot;) ('Size 1)])))
              (NamedModel
                 (TensorSpec
                    ('Gradient requiresGradient)
                    ('Layout 'Dense)
                    ('Device 'CPU)
                    ('DataType 'Float)
                    ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 100)])))))
        Tanh
        (ModelSpec (TLNDropoutF hasDropout))
        (NamedModel
           (GLinear
              (NamedModel
                 (TensorSpec
                    ('Gradient requiresGradient)
                    ('Layout 'Dense)
                    ('Device 'CPU)
                    ('DataType 'Float)
                    ('Shape
                       '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 100)])))
              (NamedModel
                 (TensorSpec
                    ('Gradient requiresGradient)
                    ('Layout 'Dense)
                    ('Device 'CPU)
                    ('DataType 'Float)
                    ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1)]))))))
</span><a href="#local-6989586621679663946"><span class="hs-identifier hs-var">mkModelSpec</span></a></span><span> </span><span class="annot"><span class="annottext">SRequiresGradient 'WithGradient
</span><a href="Torch.GraduallyTyped.RequiresGradient.html#SWithGradient"><span class="hs-identifier hs-var">SWithGradient</span></a></span><span> </span><span class="annot"><span class="annottext">SHasDropout 'WithDropout
</span><a href="Torch.GraduallyTyped.NN.Type.html#SWithDropout"><span class="hs-identifier hs-var">SWithDropout</span></a></span><span>
</span><span id="line-278"></span><span>      </span><span class="hs-comment">-- during evaluation, we don't need to turn dropout on, nor do we need to keep track of the gradient</span><span>
</span><span id="line-279"></span><span>      </span><span id="local-6989586621679663939"><span class="annot"><span class="annottext">evaluationModelSpec :: NamedModel
  (TwoLayerNetwork
     (NamedModel
        (GLinear
           (NamedModel
              (TensorSpec
                 ('Gradient 'WithoutGradient)
                 ('Layout 'Dense)
                 ('Device 'CPU)
                 ('DataType 'Float)
                 ('Shape
                    '[ 'Dim ('Name &quot;*&quot;) ('Size 100), 'Dim ('Name &quot;*&quot;) ('Size 1)])))
           (NamedModel
              (TensorSpec
                 ('Gradient 'WithoutGradient)
                 ('Layout 'Dense)
                 ('Device 'CPU)
                 ('DataType 'Float)
                 ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 100)])))))
     Tanh
     (ModelSpec (TLNDropoutF 'WithoutDropout))
     (NamedModel
        (GLinear
           (NamedModel
              (TensorSpec
                 ('Gradient 'WithoutGradient)
                 ('Layout 'Dense)
                 ('Device 'CPU)
                 ('DataType 'Float)
                 ('Shape
                    '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 100)])))
           (NamedModel
              (TensorSpec
                 ('Gradient 'WithoutGradient)
                 ('Layout 'Dense)
                 ('Device 'CPU)
                 ('DataType 'Float)
                 ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1)]))))))
</span><a href="#local-6989586621679663939"><span class="hs-identifier hs-var hs-var">evaluationModelSpec</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SRequiresGradient 'WithoutGradient
-&gt; SHasDropout 'WithoutDropout
-&gt; NamedModel
     (TwoLayerNetwork
        (NamedModel
           (GLinear
              (NamedModel
                 (TensorSpec
                    ('Gradient 'WithoutGradient)
                    ('Layout 'Dense)
                    ('Device 'CPU)
                    ('DataType 'Float)
                    ('Shape
                       '[ 'Dim ('Name &quot;*&quot;) ('Size 100), 'Dim ('Name &quot;*&quot;) ('Size 1)])))
              (NamedModel
                 (TensorSpec
                    ('Gradient 'WithoutGradient)
                    ('Layout 'Dense)
                    ('Device 'CPU)
                    ('DataType 'Float)
                    ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 100)])))))
        Tanh
        (ModelSpec (TLNDropoutF 'WithoutDropout))
        (NamedModel
           (GLinear
              (NamedModel
                 (TensorSpec
                    ('Gradient 'WithoutGradient)
                    ('Layout 'Dense)
                    ('Device 'CPU)
                    ('DataType 'Float)
                    ('Shape
                       '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 100)])))
              (NamedModel
                 (TensorSpec
                    ('Gradient 'WithoutGradient)
                    ('Layout 'Dense)
                    ('Device 'CPU)
                    ('DataType 'Float)
                    ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1)]))))))
forall (requiresGradient :: RequiresGradient)
       (hasDropout :: HasDropout).
SRequiresGradient requiresGradient
-&gt; SHasDropout hasDropout
-&gt; NamedModel
     (TwoLayerNetwork
        (NamedModel
           (GLinear
              (NamedModel
                 (TensorSpec
                    ('Gradient requiresGradient)
                    ('Layout 'Dense)
                    ('Device 'CPU)
                    ('DataType 'Float)
                    ('Shape
                       '[ 'Dim ('Name &quot;*&quot;) ('Size 100), 'Dim ('Name &quot;*&quot;) ('Size 1)])))
              (NamedModel
                 (TensorSpec
                    ('Gradient requiresGradient)
                    ('Layout 'Dense)
                    ('Device 'CPU)
                    ('DataType 'Float)
                    ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 100)])))))
        Tanh
        (ModelSpec (TLNDropoutF hasDropout))
        (NamedModel
           (GLinear
              (NamedModel
                 (TensorSpec
                    ('Gradient requiresGradient)
                    ('Layout 'Dense)
                    ('Device 'CPU)
                    ('DataType 'Float)
                    ('Shape
                       '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 100)])))
              (NamedModel
                 (TensorSpec
                    ('Gradient requiresGradient)
                    ('Layout 'Dense)
                    ('Device 'CPU)
                    ('DataType 'Float)
                    ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1)]))))))
</span><a href="#local-6989586621679663946"><span class="hs-identifier hs-var">mkModelSpec</span></a></span><span> </span><span class="annot"><span class="annottext">SRequiresGradient 'WithoutGradient
</span><a href="Torch.GraduallyTyped.RequiresGradient.html#SWithoutGradient"><span class="hs-identifier hs-var">SWithoutGradient</span></a></span><span> </span><span class="annot"><span class="annottext">SHasDropout 'WithoutDropout
</span><a href="Torch.GraduallyTyped.NN.Type.html#SWithoutDropout"><span class="hs-identifier hs-var">SWithoutDropout</span></a></span><span>
</span><span id="line-280"></span><span>
</span><span id="line-281"></span><span>  </span><span class="hs-comment">-- create a Torch random generator from the seed</span><span>
</span><span id="line-282"></span><span>  </span><span id="local-6989586621679663938"><span class="annot"><span class="annottext">Generator ('Device 'CPU)
</span><a href="#local-6989586621679663938"><span class="hs-identifier hs-var">g0</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">SDevice ('Device 'CPU) -&gt; Word64 -&gt; IO (Generator ('Device 'CPU))
forall (m :: * -&gt; *) (device :: Device (DeviceType Nat)).
MonadThrow m =&gt;
SDevice device -&gt; Word64 -&gt; m (Generator device)
</span><a href="Torch.GraduallyTyped.Random.html#sMkGenerator"><span class="hs-identifier hs-var">sMkGenerator</span></a></span><span> </span><span class="annot"><span class="annottext">SDevice ('Device 'CPU)
</span><a href="#local-6989586621679663955"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">Word64
</span><a href="#local-6989586621679663956"><span class="hs-identifier hs-var">seed</span></a></span><span>
</span><span id="line-283"></span><span>
</span><span id="line-284"></span><span>  </span><span class="hs-comment">-- initialize the model from the model specification using the generator</span><span>
</span><span id="line-285"></span><span>  </span><span class="hs-special">(</span><span id="local-6989586621679663936"><span class="annot"><span class="annottext">NamedModel
  (TwoLayerNetwork
     (NamedModel
        (GLinear
           (NamedModel
              (Tensor
                 ('Gradient 'WithGradient)
                 ('Layout 'Dense)
                 ('Device 'CPU)
                 ('DataType 'Float)
                 ('Shape
                    '[ 'Dim ('Name &quot;*&quot;) ('Size 100), 'Dim ('Name &quot;*&quot;) ('Size 1)])))
           (NamedModel
              (Tensor
                 ('Gradient 'WithGradient)
                 ('Layout 'Dense)
                 ('Device 'CPU)
                 ('DataType 'Float)
                 ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 100)])))))
     Tanh
     Dropout
     (NamedModel
        (GLinear
           (NamedModel
              (Tensor
                 ('Gradient 'WithGradient)
                 ('Layout 'Dense)
                 ('Device 'CPU)
                 ('DataType 'Float)
                 ('Shape
                    '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 100)])))
           (NamedModel
              (Tensor
                 ('Gradient 'WithGradient)
                 ('Layout 'Dense)
                 ('Device 'CPU)
                 ('DataType 'Float)
                 ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1)]))))))
</span><a href="#local-6989586621679663936"><span class="hs-identifier hs-var">model</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679663935"><span class="annot"><span class="annottext">Generator ('Device 'CPU)
</span><a href="#local-6989586621679663935"><span class="hs-identifier hs-var">g1</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (NamedModel
     (TwoLayerNetwork
        (NamedModel
           (GLinear
              (NamedModel
                 (Tensor
                    ('Gradient 'WithGradient)
                    ('Layout 'Dense)
                    ('Device 'CPU)
                    ('DataType 'Float)
                    ('Shape
                       '[ 'Dim ('Name &quot;*&quot;) ('Size 100), 'Dim ('Name &quot;*&quot;) ('Size 1)])))
              (NamedModel
                 (Tensor
                    ('Gradient 'WithGradient)
                    ('Layout 'Dense)
                    ('Device 'CPU)
                    ('DataType 'Float)
                    ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 100)])))))
        Tanh
        Dropout
        (NamedModel
           (GLinear
              (NamedModel
                 (Tensor
                    ('Gradient 'WithGradient)
                    ('Layout 'Dense)
                    ('Device 'CPU)
                    ('DataType 'Float)
                    ('Shape
                       '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 100)])))
              (NamedModel
                 (Tensor
                    ('Gradient 'WithGradient)
                    ('Layout 'Dense)
                    ('Device 'CPU)
                    ('DataType 'Float)
                    ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1)])))))))
-&gt; Generator ('Device 'CPU)
-&gt; IO
     (NamedModel
        (TwoLayerNetwork
           (NamedModel
              (GLinear
                 (NamedModel
                    (Tensor
                       ('Gradient 'WithGradient)
                       ('Layout 'Dense)
                       ('Device 'CPU)
                       ('DataType 'Float)
                       ('Shape
                          '[ 'Dim ('Name &quot;*&quot;) ('Size 100), 'Dim ('Name &quot;*&quot;) ('Size 1)])))
                 (NamedModel
                    (Tensor
                       ('Gradient 'WithGradient)
                       ('Layout 'Dense)
                       ('Device 'CPU)
                       ('DataType 'Float)
                       ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 100)])))))
           Tanh
           Dropout
           (NamedModel
              (GLinear
                 (NamedModel
                    (Tensor
                       ('Gradient 'WithGradient)
                       ('Layout 'Dense)
                       ('Device 'CPU)
                       ('DataType 'Float)
                       ('Shape
                          '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 100)])))
                 (NamedModel
                    (Tensor
                       ('Gradient 'WithGradient)
                       ('Layout 'Dense)
                       ('Device 'CPU)
                       ('DataType 'Float)
                       ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1)])))))),
      Generator ('Device 'CPU))
forall model (generatorDevice :: Device (DeviceType Nat)) output
       (generatorOutputDevice :: Device (DeviceType Nat)) (m :: * -&gt; *).
(HasInitialize model generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
ModelSpec model
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#initialize"><span class="hs-identifier hs-var">initialize</span></a></span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (NamedModel
     (TwoLayerNetwork
        (NamedModel
           (GLinear
              (NamedModel
                 (Tensor
                    ('Gradient 'WithGradient)
                    ('Layout 'Dense)
                    ('Device 'CPU)
                    ('DataType 'Float)
                    ('Shape
                       '[ 'Dim ('Name &quot;*&quot;) ('Size 100), 'Dim ('Name &quot;*&quot;) ('Size 1)])))
              (NamedModel
                 (Tensor
                    ('Gradient 'WithGradient)
                    ('Layout 'Dense)
                    ('Device 'CPU)
                    ('DataType 'Float)
                    ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 100)])))))
        Tanh
        Dropout
        (NamedModel
           (GLinear
              (NamedModel
                 (Tensor
                    ('Gradient 'WithGradient)
                    ('Layout 'Dense)
                    ('Device 'CPU)
                    ('DataType 'Float)
                    ('Shape
                       '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 100)])))
              (NamedModel
                 (Tensor
                    ('Gradient 'WithGradient)
                    ('Layout 'Dense)
                    ('Device 'CPU)
                    ('DataType 'Float)
                    ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1)])))))))
NamedModel
  (TwoLayerNetwork
     (NamedModel
        (GLinear
           (NamedModel
              (TensorSpec
                 ('Gradient 'WithGradient)
                 ('Layout 'Dense)
                 ('Device 'CPU)
                 ('DataType 'Float)
                 ('Shape
                    '[ 'Dim ('Name &quot;*&quot;) ('Size 100), 'Dim ('Name &quot;*&quot;) ('Size 1)])))
           (NamedModel
              (TensorSpec
                 ('Gradient 'WithGradient)
                 ('Layout 'Dense)
                 ('Device 'CPU)
                 ('DataType 'Float)
                 ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 100)])))))
     Tanh
     Dropout
     (NamedModel
        (GLinear
           (NamedModel
              (TensorSpec
                 ('Gradient 'WithGradient)
                 ('Layout 'Dense)
                 ('Device 'CPU)
                 ('DataType 'Float)
                 ('Shape
                    '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 100)])))
           (NamedModel
              (TensorSpec
                 ('Gradient 'WithGradient)
                 ('Layout 'Dense)
                 ('Device 'CPU)
                 ('DataType 'Float)
                 ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1)]))))))
</span><a href="#local-6989586621679663941"><span class="hs-identifier hs-var">trainingModelSpec</span></a></span><span> </span><span class="annot"><span class="annottext">Generator ('Device 'CPU)
</span><a href="#local-6989586621679663938"><span class="hs-identifier hs-var">g0</span></a></span><span>
</span><span id="line-286"></span><span>
</span><span id="line-287"></span><span>  </span><span class="hs-comment">-- define collation function</span><span>
</span><span id="line-288"></span><span>  </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679663933"><span class="annot"><span class="annottext">collate' :: ListT IO (Float, Float)
-&gt; ContT
     r
     IO
     (ListT
        IO
        (Tensor
           ('Gradient 'WithoutGradient)
           ('Layout 'Dense)
           ('Device 'CPU)
           ('DataType 'Float)
           ('Shape
              '[ 'Dim ('Name &quot;*&quot;) 'UncheckedSize, 'Dim ('Name &quot;*&quot;) ('Size 1)]),
         Tensor
           ('Gradient 'WithoutGradient)
           ('Layout 'Dense)
           ('Device 'CPU)
           ('DataType 'Float)
           ('Shape
              '[ 'Dim ('Name &quot;*&quot;) 'UncheckedSize, 'Dim ('Name &quot;*&quot;) ('Size 1)])))
</span><a href="#local-6989586621679663933"><span class="hs-identifier hs-var hs-var">collate'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-289"></span><span>        </span><span class="hs-keyword">let</span><span> </span><span class="hs-comment">-- batch size</span><span>
</span><span id="line-290"></span><span>            </span><span id="local-6989586621679663932"><span class="annot"><span class="annottext">batchSize :: Int
</span><a href="#local-6989586621679663932"><span class="hs-identifier hs-var hs-var">batchSize</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">100</span></span><span>
</span><span id="line-291"></span><span>         </span><span class="hs-keyword">in</span><span> </span><span class="annot"><span class="annottext">SDevice ('Device 'CPU)
-&gt; Int
-&gt; ListT IO (Float, Float)
-&gt; ContT
     r
     IO
     (ListT
        IO
        (Tensor
           ('Gradient 'WithoutGradient)
           ('Layout 'Dense)
           ('Device 'CPU)
           ('DataType 'Float)
           ('Shape
              '[ 'Dim ('Name &quot;*&quot;) 'UncheckedSize, 'Dim ('Name &quot;*&quot;) ('Size 1)]),
         Tensor
           ('Gradient 'WithoutGradient)
           ('Layout 'Dense)
           ('Device 'CPU)
           ('DataType 'Float)
           ('Shape
              '[ 'Dim ('Name &quot;*&quot;) 'UncheckedSize, 'Dim ('Name &quot;*&quot;) ('Size 1)])))
forall (device :: Device (DeviceType Nat)) r input target.
(input
 ~ Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     device
     ('DataType 'Float)
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) 'UncheckedSize, 'Dim ('Name &quot;*&quot;) ('Size 1)]),
 target
 ~ Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     device
     ('DataType 'Float)
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) 'UncheckedSize,
           'Dim ('Name &quot;*&quot;) ('Size 1)])) =&gt;
SDevice device
-&gt; Int
-&gt; ListT IO (Float, Float)
-&gt; ContT r IO (ListT IO (input, target))
</span><a href="Torch.GraduallyTyped.Examples.TwoLayerNetwork.html#collate"><span class="hs-identifier hs-var">Torch.GraduallyTyped.Examples.TwoLayerNetwork.collate</span></a></span><span> </span><span class="annot"><span class="annottext">SDevice ('Device 'CPU)
</span><a href="#local-6989586621679663955"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679663932"><span class="hs-identifier hs-var">batchSize</span></a></span><span>
</span><span id="line-292"></span><span>
</span><span id="line-293"></span><span>  </span><span class="hs-keyword">let</span><span> </span><span class="hs-comment">-- total number of epochs</span><span>
</span><span id="line-294"></span><span>      </span><span id="local-6989586621679663931"><span class="annot"><span class="annottext">numEpochs :: Int
</span><a href="#local-6989586621679663931"><span class="hs-identifier hs-var hs-var">numEpochs</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">100</span></span><span>
</span><span id="line-295"></span><span>      </span><span class="hs-comment">-- learning rate schedule</span><span>
</span><span id="line-296"></span><span>      </span><span id="local-6989586621679663930"><span class="annot"><span class="annottext">learningRateSchedule :: Int -&gt; Double
</span><a href="#local-6989586621679663930"><span class="hs-identifier hs-var hs-var">learningRateSchedule</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-297"></span><span>        </span><span class="hs-keyword">let</span><span> </span><span class="hs-comment">-- peak learning rate after warmup</span><span>
</span><span id="line-298"></span><span>            </span><span id="local-6989586621679663929"><span class="annot"><span class="annottext">maxLearningRate :: Double
</span><a href="#local-6989586621679663929"><span class="hs-identifier hs-var hs-var">maxLearningRate</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Double
</span><span class="hs-number">1e-2</span></span><span>
</span><span id="line-299"></span><span>            </span><span class="hs-comment">-- learning rate at the end of the schedule</span><span>
</span><span id="line-300"></span><span>            </span><span id="local-6989586621679663928"><span class="annot"><span class="annottext">finalLearningRate :: Double
</span><a href="#local-6989586621679663928"><span class="hs-identifier hs-var hs-var">finalLearningRate</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Double
</span><span class="hs-number">1e-4</span></span><span>
</span><span id="line-301"></span><span>            </span><span class="hs-comment">-- warmup epochs</span><span>
</span><span id="line-302"></span><span>            </span><span id="local-6989586621679663927"><span class="annot"><span class="annottext">numWarmupEpochs :: Int
</span><a href="#local-6989586621679663927"><span class="hs-identifier hs-var hs-var">numWarmupEpochs</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">10</span></span><span>
</span><span id="line-303"></span><span>            </span><span class="hs-comment">-- cooldown epochs</span><span>
</span><span id="line-304"></span><span>            </span><span id="local-6989586621679663926"><span class="annot"><span class="annottext">numCooldownEpochs :: Int
</span><a href="#local-6989586621679663926"><span class="hs-identifier hs-var hs-var">numCooldownEpochs</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">10</span></span><span>
</span><span id="line-305"></span><span>         </span><span class="hs-keyword">in</span><span> </span><span class="annot"><span class="annottext">Double -&gt; Double -&gt; Int -&gt; Int -&gt; Int -&gt; Int -&gt; Double
</span><a href="Torch.GraduallyTyped.LearningRateSchedules.html#singleCycleLearningRateSchedule"><span class="hs-identifier hs-var">singleCycleLearningRateSchedule</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679663929"><span class="hs-identifier hs-var">maxLearningRate</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679663928"><span class="hs-identifier hs-var">finalLearningRate</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679663931"><span class="hs-identifier hs-var">numEpochs</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679663927"><span class="hs-identifier hs-var">numWarmupEpochs</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679663926"><span class="hs-identifier hs-var">numCooldownEpochs</span></a></span><span>
</span><span id="line-306"></span><span>
</span><span id="line-307"></span><span>  </span><span class="hs-comment">-- create the dataset(s) using a Haskell random generator</span><span>
</span><span id="line-308"></span><span>  </span><span class="hs-special">(</span><span id="local-6989586621679663924"><span class="annot"><span class="annottext">SincData
</span><a href="#local-6989586621679663924"><span class="hs-identifier hs-var">trainingData</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679663923"><span class="annot"><span class="annottext">SincData
</span><a href="#local-6989586621679663923"><span class="hs-identifier hs-var">evaluationData</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679663922"><span class="annot"><span class="annottext">DatasetOptions
</span><a href="#local-6989586621679663922"><span class="hs-identifier hs-var">streamingState</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">&lt;-</span><span>
</span><span id="line-309"></span><span>    </span><span class="annot"><span class="annottext">IO StdGen
forall (m :: * -&gt; *). MonadIO m =&gt; m StdGen
</span><a href="../file:///nix/store/fv40valsp1qi9dy3snb8jgiq0a9h8rjk-random-lib-random-1.2.0-haddock-doc/share/doc/random/html/src"><span class="hs-identifier hs-var">getStdGen</span></a></span><span>
</span><span id="line-310"></span><span>      </span><span class="annot"><span class="annottext">IO StdGen
-&gt; (StdGen -&gt; IO (SincData, SincData, DatasetOptions))
-&gt; IO (SincData, SincData, DatasetOptions)
forall (m :: * -&gt; *) a b. Monad m =&gt; m a -&gt; (a -&gt; m b) -&gt; m b
</span><span class="hs-operator hs-var">&gt;&gt;=</span></span><span> </span><span class="annot"><span class="annottext">StateT StdGen IO (SincData, SincData, DatasetOptions)
-&gt; StdGen -&gt; IO (SincData, SincData, DatasetOptions)
forall (m :: * -&gt; *) s a. Monad m =&gt; StateT s m a -&gt; s -&gt; m a
</span><span class="hs-identifier hs-var">evalStateT</span></span><span>
</span><span id="line-311"></span><span>        </span><span class="hs-special">(</span><span> </span><span class="hs-special">(</span><span class="hs-special">,</span><span class="hs-special">,</span><span class="hs-special">)</span><span>
</span><span id="line-312"></span><span>            </span><span class="hs-comment">-- create a dataset of 10000 unique training examples</span><span>
</span><span id="line-313"></span><span>            </span><span class="annot"><span class="annottext">(SincData
 -&gt; SincData
 -&gt; DatasetOptions
 -&gt; (SincData, SincData, DatasetOptions))
-&gt; StateT StdGen IO SincData
-&gt; StateT
     StdGen
     IO
     (SincData
      -&gt; DatasetOptions -&gt; (SincData, SincData, DatasetOptions))
forall (f :: * -&gt; *) a b. Functor f =&gt; (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;$&gt;</span></span><span> </span><span class="annot"><span class="annottext">Text -&gt; Int -&gt; StateT StdGen IO SincData
forall g (m :: * -&gt; *).
(RandomGen g, Monad m) =&gt;
Text -&gt; Int -&gt; StateT g m SincData
</span><a href="Torch.GraduallyTyped.Examples.TwoLayerNetwork.html#mkSincData"><span class="hs-identifier hs-var">mkSincData</span></a></span><span> </span><span class="annot"><span class="annottext">Text
</span><span class="hs-string">&quot;training&quot;</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">10000</span></span><span>
</span><span id="line-314"></span><span>              </span><span class="hs-comment">-- create a dataset of 500 unique evaluation examples</span><span>
</span><span id="line-315"></span><span>              </span><span class="annot"><span class="annottext">StateT
  StdGen
  IO
  (SincData
   -&gt; DatasetOptions -&gt; (SincData, SincData, DatasetOptions))
-&gt; StateT StdGen IO SincData
-&gt; StateT
     StdGen IO (DatasetOptions -&gt; (SincData, SincData, DatasetOptions))
forall (f :: * -&gt; *) a b. Applicative f =&gt; f (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;*&gt;</span></span><span> </span><span class="annot"><span class="annottext">Text -&gt; Int -&gt; StateT StdGen IO SincData
forall g (m :: * -&gt; *).
(RandomGen g, Monad m) =&gt;
Text -&gt; Int -&gt; StateT g m SincData
</span><a href="Torch.GraduallyTyped.Examples.TwoLayerNetwork.html#mkSincData"><span class="hs-identifier hs-var">mkSincData</span></a></span><span> </span><span class="annot"><span class="annottext">Text
</span><span class="hs-string">&quot;evaluation&quot;</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">500</span></span><span>
</span><span id="line-316"></span><span>              </span><span class="hs-comment">-- configure the data loader for random shuffling</span><span>
</span><span id="line-317"></span><span>              </span><span class="annot"><span class="annottext">StateT
  StdGen IO (DatasetOptions -&gt; (SincData, SincData, DatasetOptions))
-&gt; StateT StdGen IO DatasetOptions
-&gt; StateT StdGen IO (SincData, SincData, DatasetOptions)
forall (f :: * -&gt; *) a b. Applicative f =&gt; f (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;*&gt;</span></span><span> </span><span class="annot"><span class="annottext">(StdGen -&gt; DatasetOptions) -&gt; StateT StdGen IO DatasetOptions
forall s (m :: * -&gt; *) a. MonadState s m =&gt; (s -&gt; a) -&gt; m a
</span><span class="hs-identifier hs-var">gets</span></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">\</span><span id="local-6989586621679663921"><span class="annot"><span class="annottext">StdGen
</span><a href="#local-6989586621679663921"><span class="hs-identifier hs-var">stdGen</span></a></span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Int -&gt; DatasetOptions
</span><a href="../../../../hasktorch/html/src"><span class="hs-identifier hs-var">datasetOpts</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">1</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">{</span><span class="annot"><span class="annottext">shuffle :: Sample
</span><a href="../../../../hasktorch/html/src"><span class="hs-identifier hs-var">shuffle</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StdGen -&gt; Sample
forall g. RandomGen g =&gt; g -&gt; Sample
</span><a href="../../../../hasktorch/html/src"><span class="hs-identifier hs-var">Shuffle</span></a></span><span> </span><span class="annot"><span class="annottext">StdGen
</span><a href="#local-6989586621679663921"><span class="hs-identifier hs-var">stdGen</span></a></span><span class="hs-special">}</span><span class="hs-special">)</span><span>
</span><span id="line-318"></span><span>        </span><span class="hs-special">)</span><span>
</span><span id="line-319"></span><span>
</span><span id="line-320"></span><span>  </span><span class="hs-comment">-- create an Adam optimizer with learning rate 1e-4 using the model.</span><span>
</span><span id="line-321"></span><span>  </span><span class="hs-comment">-- the optimizer is responsible for computing the gradient of the loss</span><span>
</span><span id="line-322"></span><span>  </span><span class="hs-comment">-- with respect to the model parameters and updating the model parameters.</span><span>
</span><span id="line-323"></span><span>  </span><span id="local-6989586621679663917"><span class="annot"><span class="annottext">Optimizer
  (NamedModel
     (TwoLayerNetwork
        (NamedModel
           (GLinear
              (NamedModel
                 (Tensor
                    ('Gradient 'WithGradient)
                    ('Layout 'Dense)
                    ('Device 'CPU)
                    ('DataType 'Float)
                    ('Shape
                       '[ 'Dim ('Name &quot;*&quot;) ('Size 100), 'Dim ('Name &quot;*&quot;) ('Size 1)])))
              (NamedModel
                 (Tensor
                    ('Gradient 'WithGradient)
                    ('Layout 'Dense)
                    ('Device 'CPU)
                    ('DataType 'Float)
                    ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 100)])))))
        Tanh
        Dropout
        (NamedModel
           (GLinear
              (NamedModel
                 (Tensor
                    ('Gradient 'WithGradient)
                    ('Layout 'Dense)
                    ('Device 'CPU)
                    ('DataType 'Float)
                    ('Shape
                       '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 100)])))
              (NamedModel
                 (Tensor
                    ('Gradient 'WithGradient)
                    ('Layout 'Dense)
                    ('Device 'CPU)
                    ('DataType 'Float)
                    ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1)])))))))
</span><a href="#local-6989586621679663917"><span class="hs-identifier hs-var">optim</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">IO
  (Optimizer
     (NamedModel
        (TwoLayerNetwork
           (NamedModel
              (GLinear
                 (NamedModel
                    (Tensor
                       ('Gradient 'WithGradient)
                       ('Layout 'Dense)
                       ('Device 'CPU)
                       ('DataType 'Float)
                       ('Shape
                          '[ 'Dim ('Name &quot;*&quot;) ('Size 100), 'Dim ('Name &quot;*&quot;) ('Size 1)])))
                 (NamedModel
                    (Tensor
                       ('Gradient 'WithGradient)
                       ('Layout 'Dense)
                       ('Device 'CPU)
                       ('DataType 'Float)
                       ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 100)])))))
           Tanh
           Dropout
           (NamedModel
              (GLinear
                 (NamedModel
                    (Tensor
                       ('Gradient 'WithGradient)
                       ('Layout 'Dense)
                       ('Device 'CPU)
                       ('DataType 'Float)
                       ('Shape
                          '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 100)])))
                 (NamedModel
                    (Tensor
                       ('Gradient 'WithGradient)
                       ('Layout 'Dense)
                       ('Device 'CPU)
                       ('DataType 'Float)
                       ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1)]))))))))
-&gt; IO
     (Optimizer
        (NamedModel
           (TwoLayerNetwork
              (NamedModel
                 (GLinear
                    (NamedModel
                       (Tensor
                          ('Gradient 'WithGradient)
                          ('Layout 'Dense)
                          ('Device 'CPU)
                          ('DataType 'Float)
                          ('Shape
                             '[ 'Dim ('Name &quot;*&quot;) ('Size 100), 'Dim ('Name &quot;*&quot;) ('Size 1)])))
                    (NamedModel
                       (Tensor
                          ('Gradient 'WithGradient)
                          ('Layout 'Dense)
                          ('Device 'CPU)
                          ('DataType 'Float)
                          ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 100)])))))
              Tanh
              Dropout
              (NamedModel
                 (GLinear
                    (NamedModel
                       (Tensor
                          ('Gradient 'WithGradient)
                          ('Layout 'Dense)
                          ('Device 'CPU)
                          ('DataType 'Float)
                          ('Shape
                             '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 100)])))
                    (NamedModel
                       (Tensor
                          ('Gradient 'WithGradient)
                          ('Layout 'Dense)
                          ('Device 'CPU)
                          ('DataType 'Float)
                          ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1)]))))))))
forall (m :: * -&gt; *) a. MonadIO m =&gt; IO a -&gt; m a
</span><span class="hs-identifier hs-var">liftIO</span></span><span> </span><span class="annot"><span class="annottext">(IO
   (Optimizer
      (NamedModel
         (TwoLayerNetwork
            (NamedModel
               (GLinear
                  (NamedModel
                     (Tensor
                        ('Gradient 'WithGradient)
                        ('Layout 'Dense)
                        ('Device 'CPU)
                        ('DataType 'Float)
                        ('Shape
                           '[ 'Dim ('Name &quot;*&quot;) ('Size 100), 'Dim ('Name &quot;*&quot;) ('Size 1)])))
                  (NamedModel
                     (Tensor
                        ('Gradient 'WithGradient)
                        ('Layout 'Dense)
                        ('Device 'CPU)
                        ('DataType 'Float)
                        ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 100)])))))
            Tanh
            Dropout
            (NamedModel
               (GLinear
                  (NamedModel
                     (Tensor
                        ('Gradient 'WithGradient)
                        ('Layout 'Dense)
                        ('Device 'CPU)
                        ('DataType 'Float)
                        ('Shape
                           '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 100)])))
                  (NamedModel
                     (Tensor
                        ('Gradient 'WithGradient)
                        ('Layout 'Dense)
                        ('Device 'CPU)
                        ('DataType 'Float)
                        ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1)]))))))))
 -&gt; IO
      (Optimizer
         (NamedModel
            (TwoLayerNetwork
               (NamedModel
                  (GLinear
                     (NamedModel
                        (Tensor
                           ('Gradient 'WithGradient)
                           ('Layout 'Dense)
                           ('Device 'CPU)
                           ('DataType 'Float)
                           ('Shape
                              '[ 'Dim ('Name &quot;*&quot;) ('Size 100), 'Dim ('Name &quot;*&quot;) ('Size 1)])))
                     (NamedModel
                        (Tensor
                           ('Gradient 'WithGradient)
                           ('Layout 'Dense)
                           ('Device 'CPU)
                           ('DataType 'Float)
                           ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 100)])))))
               Tanh
               Dropout
               (NamedModel
                  (GLinear
                     (NamedModel
                        (Tensor
                           ('Gradient 'WithGradient)
                           ('Layout 'Dense)
                           ('Device 'CPU)
                           ('DataType 'Float)
                           ('Shape
                              '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 100)])))
                     (NamedModel
                        (Tensor
                           ('Gradient 'WithGradient)
                           ('Layout 'Dense)
                           ('Device 'CPU)
                           ('DataType 'Float)
                           ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1)])))))))))
-&gt; IO
     (Optimizer
        (NamedModel
           (TwoLayerNetwork
              (NamedModel
                 (GLinear
                    (NamedModel
                       (Tensor
                          ('Gradient 'WithGradient)
                          ('Layout 'Dense)
                          ('Device 'CPU)
                          ('DataType 'Float)
                          ('Shape
                             '[ 'Dim ('Name &quot;*&quot;) ('Size 100), 'Dim ('Name &quot;*&quot;) ('Size 1)])))
                    (NamedModel
                       (Tensor
                          ('Gradient 'WithGradient)
                          ('Layout 'Dense)
                          ('Device 'CPU)
                          ('DataType 'Float)
                          ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 100)])))))
              Tanh
              Dropout
              (NamedModel
                 (GLinear
                    (NamedModel
                       (Tensor
                          ('Gradient 'WithGradient)
                          ('Layout 'Dense)
                          ('Device 'CPU)
                          ('DataType 'Float)
                          ('Shape
                             '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 100)])))
                    (NamedModel
                       (Tensor
                          ('Gradient 'WithGradient)
                          ('Layout 'Dense)
                          ('Device 'CPU)
                          ('DataType 'Float)
                          ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1)]))))))))
-&gt; IO
     (Optimizer
        (NamedModel
           (TwoLayerNetwork
              (NamedModel
                 (GLinear
                    (NamedModel
                       (Tensor
                          ('Gradient 'WithGradient)
                          ('Layout 'Dense)
                          ('Device 'CPU)
                          ('DataType 'Float)
                          ('Shape
                             '[ 'Dim ('Name &quot;*&quot;) ('Size 100), 'Dim ('Name &quot;*&quot;) ('Size 1)])))
                    (NamedModel
                       (Tensor
                          ('Gradient 'WithGradient)
                          ('Layout 'Dense)
                          ('Device 'CPU)
                          ('DataType 'Float)
                          ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 100)])))))
              Tanh
              Dropout
              (NamedModel
                 (GLinear
                    (NamedModel
                       (Tensor
                          ('Gradient 'WithGradient)
                          ('Layout 'Dense)
                          ('Device 'CPU)
                          ('DataType 'Float)
                          ('Shape
                             '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 100)])))
                    (NamedModel
                       (Tensor
                          ('Gradient 'WithGradient)
                          ('Layout 'Dense)
                          ('Device 'CPU)
                          ('DataType 'Float)
                          ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1)]))))))))
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">AdamOptions
-&gt; NamedModel
     (TwoLayerNetwork
        (NamedModel
           (GLinear
              (NamedModel
                 (Tensor
                    ('Gradient 'WithGradient)
                    ('Layout 'Dense)
                    ('Device 'CPU)
                    ('DataType 'Float)
                    ('Shape
                       '[ 'Dim ('Name &quot;*&quot;) ('Size 100), 'Dim ('Name &quot;*&quot;) ('Size 1)])))
              (NamedModel
                 (Tensor
                    ('Gradient 'WithGradient)
                    ('Layout 'Dense)
                    ('Device 'CPU)
                    ('DataType 'Float)
                    ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 100)])))))
        Tanh
        Dropout
        (NamedModel
           (GLinear
              (NamedModel
                 (Tensor
                    ('Gradient 'WithGradient)
                    ('Layout 'Dense)
                    ('Device 'CPU)
                    ('DataType 'Float)
                    ('Shape
                       '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 100)])))
              (NamedModel
                 (Tensor
                    ('Gradient 'WithGradient)
                    ('Layout 'Dense)
                    ('Device 'CPU)
                    ('DataType 'Float)
                    ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1)]))))))
-&gt; IO
     (Optimizer
        (NamedModel
           (TwoLayerNetwork
              (NamedModel
                 (GLinear
                    (NamedModel
                       (Tensor
                          ('Gradient 'WithGradient)
                          ('Layout 'Dense)
                          ('Device 'CPU)
                          ('DataType 'Float)
                          ('Shape
                             '[ 'Dim ('Name &quot;*&quot;) ('Size 100), 'Dim ('Name &quot;*&quot;) ('Size 1)])))
                    (NamedModel
                       (Tensor
                          ('Gradient 'WithGradient)
                          ('Layout 'Dense)
                          ('Device 'CPU)
                          ('DataType 'Float)
                          ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 100)])))))
              Tanh
              Dropout
              (NamedModel
                 (GLinear
                    (NamedModel
                       (Tensor
                          ('Gradient 'WithGradient)
                          ('Layout 'Dense)
                          ('Device 'CPU)
                          ('DataType 'Float)
                          ('Shape
                             '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 100)])))
                    (NamedModel
                       (Tensor
                          ('Gradient 'WithGradient)
                          ('Layout 'Dense)
                          ('Device 'CPU)
                          ('DataType 'Float)
                          ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1)]))))))))
forall model.
HasStateDict model =&gt;
AdamOptions -&gt; model -&gt; IO (Optimizer model)
</span><a href="Torch.GraduallyTyped.Optim.html#mkAdam"><span class="hs-identifier hs-var">mkAdam</span></a></span><span> </span><span class="annot"><span class="annottext">AdamOptions
</span><a href="Torch.GraduallyTyped.Optim.html#defaultAdamOptions"><span class="hs-identifier hs-var">defaultAdamOptions</span></a></span><span> </span><span class="hs-special">{</span><span class="annot"><span class="annottext">learningRate :: Double
</span><a href="Torch.GraduallyTyped.Optim.html#learningRate"><span class="hs-identifier hs-var">learningRate</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Double
</span><span class="hs-number">1e-4</span></span><span class="hs-special">}</span><span> </span><span class="annot"><span class="annottext">NamedModel
  (TwoLayerNetwork
     (NamedModel
        (GLinear
           (NamedModel
              (Tensor
                 ('Gradient 'WithGradient)
                 ('Layout 'Dense)
                 ('Device 'CPU)
                 ('DataType 'Float)
                 ('Shape
                    '[ 'Dim ('Name &quot;*&quot;) ('Size 100), 'Dim ('Name &quot;*&quot;) ('Size 1)])))
           (NamedModel
              (Tensor
                 ('Gradient 'WithGradient)
                 ('Layout 'Dense)
                 ('Device 'CPU)
                 ('DataType 'Float)
                 ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 100)])))))
     Tanh
     Dropout
     (NamedModel
        (GLinear
           (NamedModel
              (Tensor
                 ('Gradient 'WithGradient)
                 ('Layout 'Dense)
                 ('Device 'CPU)
                 ('DataType 'Float)
                 ('Shape
                    '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 100)])))
           (NamedModel
              (Tensor
                 ('Gradient 'WithGradient)
                 ('Layout 'Dense)
                 ('Device 'CPU)
                 ('DataType 'Float)
                 ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1)]))))))
</span><a href="#local-6989586621679663936"><span class="hs-identifier hs-var">model</span></a></span><span>
</span><span id="line-324"></span><span>
</span><span id="line-325"></span><span>  </span><span class="hs-keyword">let</span><span> </span><span class="hs-comment">-- one epoch of training and evaluation</span><span>
</span><span id="line-326"></span><span>      </span><span id="local-6989586621679663913"><span class="annot"><span class="annottext">step :: (DatasetOptions, Generator ('Device 'CPU))
-&gt; Int
-&gt; Proxy
     X
     ()
     ()
     Monitor
     (ContT () IO)
     (DatasetOptions, Generator ('Device 'CPU))
</span><a href="#local-6989586621679663913"><span class="hs-identifier hs-var hs-var">step</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679663912"><span class="annot"><span class="annottext">DatasetOptions
</span><a href="#local-6989586621679663912"><span class="hs-identifier hs-var">streamingState'</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679663911"><span class="annot"><span class="annottext">Generator ('Device 'CPU)
</span><a href="#local-6989586621679663911"><span class="hs-identifier hs-var">g</span></a></span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679663910"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679663910"><span class="hs-identifier hs-var">epoch</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-327"></span><span>        </span><span class="hs-comment">-- let learningRate = learningRateSchedule epoch</span><span>
</span><span id="line-328"></span><span>        </span><span class="hs-comment">-- ATen.setLearningRate optim learningRate</span><span>
</span><span id="line-329"></span><span>
</span><span id="line-330"></span><span>        </span><span class="hs-comment">-- train for one epoch on the training set</span><span>
</span><span id="line-331"></span><span>        </span><span class="hs-special">(</span><span id="local-6989586621679663909"><span class="annot"><span class="annottext">Generator ('Device 'CPU)
</span><a href="#local-6989586621679663909"><span class="hs-identifier hs-var">g'</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679663908"><span class="annot"><span class="annottext">Sample
</span><a href="#local-6989586621679663908"><span class="hs-identifier hs-var">shuffle</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-332"></span><span>          </span><span class="hs-special">(</span><span id="local-6989586621679663907"><span class="annot"><span class="annottext">ListT IO (Float, Float)
</span><a href="#local-6989586621679663907"><span class="hs-identifier hs-var">trainingStream</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679663906"><span class="annot"><span class="annottext">Sample
</span><a href="#local-6989586621679663906"><span class="hs-identifier hs-var">shuffle</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">ContT () IO (ListT IO (Float, Float), Sample)
-&gt; Proxy
     X () () Monitor (ContT () IO) (ListT IO (Float, Float), Sample)
forall (t :: (* -&gt; *) -&gt; * -&gt; *) (m :: * -&gt; *) a.
(MonadTrans t, Monad m) =&gt;
m a -&gt; t m a
</span><span class="hs-identifier hs-var">P.lift</span></span><span> </span><span class="annot"><span class="annottext">(ContT () IO (ListT IO (Float, Float), Sample)
 -&gt; Proxy
      X () () Monitor (ContT () IO) (ListT IO (Float, Float), Sample))
-&gt; ContT () IO (ListT IO (Float, Float), Sample)
-&gt; Proxy
     X () () Monitor (ContT () IO) (ListT IO (Float, Float), Sample)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">DatasetOptions
-&gt; SincData -&gt; ContT () IO (ListT IO (Float, Float), Sample)
forall (m :: * -&gt; *) dataset k sample r.
(Dataset m dataset k sample, MonadIO m, MonadBaseControl IO m) =&gt;
DatasetOptions -&gt; dataset -&gt; ContT r m (ListT m sample, Sample)
</span><a href="../../../../hasktorch/html/src"><span class="hs-identifier hs-var">streamFromMap</span></a></span><span> </span><span class="annot"><span class="annottext">DatasetOptions
</span><a href="#local-6989586621679663912"><span class="hs-identifier hs-var">streamingState'</span></a></span><span> </span><span class="annot"><span class="annottext">SincData
</span><a href="#local-6989586621679663924"><span class="hs-identifier hs-var">trainingData</span></a></span><span>
</span><span id="line-333"></span><span>          </span><span id="local-6989586621679663903"><span class="annot"><span class="annottext">Either
  (Generator ('Device 'CPU))
  (Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     ('DataType 'Float)
     ('Shape '[]),
   Generator ('Device 'CPU))
</span><a href="#local-6989586621679663903"><span class="hs-identifier hs-var">trainingLoss</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">ContT
  ()
  IO
  (Either
     (Generator ('Device 'CPU))
     (Tensor
        ('Gradient 'WithoutGradient)
        ('Layout 'Dense)
        ('Device 'CPU)
        ('DataType 'Float)
        ('Shape '[]),
      Generator ('Device 'CPU)))
-&gt; Proxy
     X
     ()
     ()
     Monitor
     (ContT () IO)
     (Either
        (Generator ('Device 'CPU))
        (Tensor
           ('Gradient 'WithoutGradient)
           ('Layout 'Dense)
           ('Device 'CPU)
           ('DataType 'Float)
           ('Shape '[]),
         Generator ('Device 'CPU)))
forall (t :: (* -&gt; *) -&gt; * -&gt; *) (m :: * -&gt; *) a.
(MonadTrans t, Monad m) =&gt;
m a -&gt; t m a
</span><span class="hs-identifier hs-var">P.lift</span></span><span> </span><span class="annot"><span class="annottext">(ContT
   ()
   IO
   (Either
      (Generator ('Device 'CPU))
      (Tensor
         ('Gradient 'WithoutGradient)
         ('Layout 'Dense)
         ('Device 'CPU)
         ('DataType 'Float)
         ('Shape '[]),
       Generator ('Device 'CPU)))
 -&gt; Proxy
      X
      ()
      ()
      Monitor
      (ContT () IO)
      (Either
         (Generator ('Device 'CPU))
         (Tensor
            ('Gradient 'WithoutGradient)
            ('Layout 'Dense)
            ('Device 'CPU)
            ('DataType 'Float)
            ('Shape '[]),
          Generator ('Device 'CPU))))
-&gt; ContT
     ()
     IO
     (Either
        (Generator ('Device 'CPU))
        (Tensor
           ('Gradient 'WithoutGradient)
           ('Layout 'Dense)
           ('Device 'CPU)
           ('DataType 'Float)
           ('Shape '[]),
         Generator ('Device 'CPU)))
-&gt; Proxy
     X
     ()
     ()
     Monitor
     (ContT () IO)
     (Either
        (Generator ('Device 'CPU))
        (Tensor
           ('Gradient 'WithoutGradient)
           ('Layout 'Dense)
           ('Device 'CPU)
           ('DataType 'Float)
           ('Shape '[]),
         Generator ('Device 'CPU)))
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-334"></span><span>            </span><span id="local-6989586621679663902"><span class="annot"><span class="annottext">ListT
  IO
  (Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     ('DataType 'Float)
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) 'UncheckedSize, 'Dim ('Name &quot;*&quot;) ('Size 1)]),
   Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     ('DataType 'Float)
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) 'UncheckedSize, 'Dim ('Name &quot;*&quot;) ('Size 1)]))
</span><a href="#local-6989586621679663902"><span class="hs-identifier hs-var">batchedStream</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">ListT IO (Float, Float)
-&gt; ContT
     ()
     IO
     (ListT
        IO
        (Tensor
           ('Gradient 'WithoutGradient)
           ('Layout 'Dense)
           ('Device 'CPU)
           ('DataType 'Float)
           ('Shape
              '[ 'Dim ('Name &quot;*&quot;) 'UncheckedSize, 'Dim ('Name &quot;*&quot;) ('Size 1)]),
         Tensor
           ('Gradient 'WithoutGradient)
           ('Layout 'Dense)
           ('Device 'CPU)
           ('DataType 'Float)
           ('Shape
              '[ 'Dim ('Name &quot;*&quot;) 'UncheckedSize, 'Dim ('Name &quot;*&quot;) ('Size 1)])))
forall r.
ListT IO (Float, Float)
-&gt; ContT
     r
     IO
     (ListT
        IO
        (Tensor
           ('Gradient 'WithoutGradient)
           ('Layout 'Dense)
           ('Device 'CPU)
           ('DataType 'Float)
           ('Shape
              '[ 'Dim ('Name &quot;*&quot;) 'UncheckedSize, 'Dim ('Name &quot;*&quot;) ('Size 1)]),
         Tensor
           ('Gradient 'WithoutGradient)
           ('Layout 'Dense)
           ('Device 'CPU)
           ('DataType 'Float)
           ('Shape
              '[ 'Dim ('Name &quot;*&quot;) 'UncheckedSize, 'Dim ('Name &quot;*&quot;) ('Size 1)])))
</span><a href="#local-6989586621679663933"><span class="hs-identifier hs-var">collate'</span></a></span><span> </span><span class="annot"><span class="annottext">ListT IO (Float, Float)
</span><a href="#local-6989586621679663907"><span class="hs-identifier hs-var">trainingStream</span></a></span><span>
</span><span id="line-335"></span><span>            </span><span class="annot"><span class="annottext">IO
  (Either
     (Generator ('Device 'CPU))
     (Tensor
        ('Gradient 'WithoutGradient)
        ('Layout 'Dense)
        ('Device 'CPU)
        ('DataType 'Float)
        ('Shape '[]),
      Generator ('Device 'CPU)))
-&gt; ContT
     ()
     IO
     (Either
        (Generator ('Device 'CPU))
        (Tensor
           ('Gradient 'WithoutGradient)
           ('Layout 'Dense)
           ('Device 'CPU)
           ('DataType 'Float)
           ('Shape '[]),
         Generator ('Device 'CPU)))
forall (t :: (* -&gt; *) -&gt; * -&gt; *) (m :: * -&gt; *) a.
(MonadTrans t, Monad m) =&gt;
m a -&gt; t m a
</span><span class="hs-identifier hs-var">lift</span></span><span> </span><span class="annot"><span class="annottext">(IO
   (Either
      (Generator ('Device 'CPU))
      (Tensor
         ('Gradient 'WithoutGradient)
         ('Layout 'Dense)
         ('Device 'CPU)
         ('DataType 'Float)
         ('Shape '[]),
       Generator ('Device 'CPU)))
 -&gt; ContT
      ()
      IO
      (Either
         (Generator ('Device 'CPU))
         (Tensor
            ('Gradient 'WithoutGradient)
            ('Layout 'Dense)
            ('Device 'CPU)
            ('DataType 'Float)
            ('Shape '[]),
          Generator ('Device 'CPU))))
-&gt; IO
     (Either
        (Generator ('Device 'CPU))
        (Tensor
           ('Gradient 'WithoutGradient)
           ('Layout 'Dense)
           ('Device 'CPU)
           ('DataType 'Float)
           ('Shape '[]),
         Generator ('Device 'CPU)))
-&gt; ContT
     ()
     IO
     (Either
        (Generator ('Device 'CPU))
        (Tensor
           ('Gradient 'WithoutGradient)
           ('Layout 'Dense)
           ('Device 'CPU)
           ('DataType 'Float)
           ('Shape '[]),
         Generator ('Device 'CPU)))
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">Optimizer
  (NamedModel
     (TwoLayerNetwork
        (NamedModel
           (GLinear
              (NamedModel
                 (Tensor
                    ('Gradient 'WithGradient)
                    ('Layout 'Dense)
                    ('Device 'CPU)
                    ('DataType 'Float)
                    ('Shape
                       '[ 'Dim ('Name &quot;*&quot;) ('Size 100), 'Dim ('Name &quot;*&quot;) ('Size 1)])))
              (NamedModel
                 (Tensor
                    ('Gradient 'WithGradient)
                    ('Layout 'Dense)
                    ('Device 'CPU)
                    ('DataType 'Float)
                    ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 100)])))))
        Tanh
        Dropout
        (NamedModel
           (GLinear
              (NamedModel
                 (Tensor
                    ('Gradient 'WithGradient)
                    ('Layout 'Dense)
                    ('Device 'CPU)
                    ('DataType 'Float)
                    ('Shape
                       '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 100)])))
              (NamedModel
                 (Tensor
                    ('Gradient 'WithGradient)
                    ('Layout 'Dense)
                    ('Device 'CPU)
                    ('DataType 'Float)
                    ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1)])))))))
-&gt; ModelSpec
     (NamedModel
        (TwoLayerNetwork
           (NamedModel
              (GLinear
                 (NamedModel
                    (Tensor
                       ('Gradient 'WithGradient)
                       ('Layout 'Dense)
                       ('Device 'CPU)
                       ('DataType 'Float)
                       ('Shape
                          '[ 'Dim ('Name &quot;*&quot;) ('Size 100), 'Dim ('Name &quot;*&quot;) ('Size 1)])))
                 (NamedModel
                    (Tensor
                       ('Gradient 'WithGradient)
                       ('Layout 'Dense)
                       ('Device 'CPU)
                       ('DataType 'Float)
                       ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 100)])))))
           Tanh
           Dropout
           (NamedModel
              (GLinear
                 (NamedModel
                    (Tensor
                       ('Gradient 'WithGradient)
                       ('Layout 'Dense)
                       ('Device 'CPU)
                       ('DataType 'Float)
                       ('Shape
                          '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 100)])))
                 (NamedModel
                    (Tensor
                       ('Gradient 'WithGradient)
                       ('Layout 'Dense)
                       ('Device 'CPU)
                       ('DataType 'Float)
                       ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1)])))))))
-&gt; ListT
     IO
     (Tensor
        ('Gradient 'WithoutGradient)
        ('Layout 'Dense)
        ('Device 'CPU)
        ('DataType 'Float)
        ('Shape
           '[ 'Dim ('Name &quot;*&quot;) 'UncheckedSize, 'Dim ('Name &quot;*&quot;) ('Size 1)]),
      Tensor
        ('Gradient 'WithoutGradient)
        ('Layout 'Dense)
        ('Device 'CPU)
        ('DataType 'Float)
        ('Shape
           '[ 'Dim ('Name &quot;*&quot;) 'UncheckedSize, 'Dim ('Name &quot;*&quot;) ('Size 1)]))
-&gt; Generator ('Device 'CPU)
-&gt; IO
     (Either
        (Generator ('Device 'CPU))
        (Tensor
           ('Gradient 'WithoutGradient)
           ('Layout 'Dense)
           ('Device 'CPU)
           ('DataType 'Float)
           ('Shape '[]),
         Generator ('Device 'CPU)))
forall (m :: * -&gt; *) model input
       (generatorDevice :: Device (DeviceType Nat))
       (lossGradient :: Gradient RequiresGradient)
       (lossLayout :: Layout LayoutType)
       (lossDataType :: Device (DeviceType Nat))
       (lossDevice :: DataType DType)
       (lossShape :: Shape [Dim (Name Symbol) (Size Nat)])
       (generatorOutputDevice :: Device (DeviceType Nat)).
(MonadIO m, HasStateDict model,
 HasForward
   model
   input
   generatorDevice
   (Tensor lossGradient lossLayout lossDataType lossDevice lossShape)
   generatorOutputDevice,
 HasForward
   model
   input
   generatorOutputDevice
   (Tensor lossGradient lossLayout lossDataType lossDevice lossShape)
   generatorOutputDevice,
 SGetGeneratorDevice generatorDevice,
 SGetGeneratorDevice generatorOutputDevice,
 SGetGradient lossGradient, SGetShape lossShape,
 Catch (lossShape &lt;+&gt; 'Shape '[]),
 Catch (lossGradient &lt;+&gt; 'Gradient 'WithGradient)) =&gt;
Optimizer model
-&gt; ModelSpec model
-&gt; ListT m input
-&gt; Generator generatorDevice
-&gt; m (Either
        (Generator generatorDevice)
        (Tensor
           ('Gradient 'WithoutGradient)
           lossLayout
           lossDataType
           lossDevice
           ('Shape '[]),
         Generator generatorOutputDevice))
</span><a href="Torch.GraduallyTyped.NN.Training.html#train"><span class="hs-identifier hs-var">train</span></a></span><span> </span><span class="annot"><span class="annottext">Optimizer
  (NamedModel
     (TwoLayerNetwork
        (NamedModel
           (GLinear
              (NamedModel
                 (Tensor
                    ('Gradient 'WithGradient)
                    ('Layout 'Dense)
                    ('Device 'CPU)
                    ('DataType 'Float)
                    ('Shape
                       '[ 'Dim ('Name &quot;*&quot;) ('Size 100), 'Dim ('Name &quot;*&quot;) ('Size 1)])))
              (NamedModel
                 (Tensor
                    ('Gradient 'WithGradient)
                    ('Layout 'Dense)
                    ('Device 'CPU)
                    ('DataType 'Float)
                    ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 100)])))))
        Tanh
        Dropout
        (NamedModel
           (GLinear
              (NamedModel
                 (Tensor
                    ('Gradient 'WithGradient)
                    ('Layout 'Dense)
                    ('Device 'CPU)
                    ('DataType 'Float)
                    ('Shape
                       '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 100)])))
              (NamedModel
                 (Tensor
                    ('Gradient 'WithGradient)
                    ('Layout 'Dense)
                    ('Device 'CPU)
                    ('DataType 'Float)
                    ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1)])))))))
</span><a href="#local-6989586621679663917"><span class="hs-identifier hs-var">optim</span></a></span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (NamedModel
     (TwoLayerNetwork
        (NamedModel
           (GLinear
              (NamedModel
                 (Tensor
                    ('Gradient 'WithGradient)
                    ('Layout 'Dense)
                    ('Device 'CPU)
                    ('DataType 'Float)
                    ('Shape
                       '[ 'Dim ('Name &quot;*&quot;) ('Size 100), 'Dim ('Name &quot;*&quot;) ('Size 1)])))
              (NamedModel
                 (Tensor
                    ('Gradient 'WithGradient)
                    ('Layout 'Dense)
                    ('Device 'CPU)
                    ('DataType 'Float)
                    ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 100)])))))
        Tanh
        Dropout
        (NamedModel
           (GLinear
              (NamedModel
                 (Tensor
                    ('Gradient 'WithGradient)
                    ('Layout 'Dense)
                    ('Device 'CPU)
                    ('DataType 'Float)
                    ('Shape
                       '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 100)])))
              (NamedModel
                 (Tensor
                    ('Gradient 'WithGradient)
                    ('Layout 'Dense)
                    ('Device 'CPU)
                    ('DataType 'Float)
                    ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1)])))))))
NamedModel
  (TwoLayerNetwork
     (NamedModel
        (GLinear
           (NamedModel
              (TensorSpec
                 ('Gradient 'WithGradient)
                 ('Layout 'Dense)
                 ('Device 'CPU)
                 ('DataType 'Float)
                 ('Shape
                    '[ 'Dim ('Name &quot;*&quot;) ('Size 100), 'Dim ('Name &quot;*&quot;) ('Size 1)])))
           (NamedModel
              (TensorSpec
                 ('Gradient 'WithGradient)
                 ('Layout 'Dense)
                 ('Device 'CPU)
                 ('DataType 'Float)
                 ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 100)])))))
     Tanh
     Dropout
     (NamedModel
        (GLinear
           (NamedModel
              (TensorSpec
                 ('Gradient 'WithGradient)
                 ('Layout 'Dense)
                 ('Device 'CPU)
                 ('DataType 'Float)
                 ('Shape
                    '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 100)])))
           (NamedModel
              (TensorSpec
                 ('Gradient 'WithGradient)
                 ('Layout 'Dense)
                 ('Device 'CPU)
                 ('DataType 'Float)
                 ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1)]))))))
</span><a href="#local-6989586621679663941"><span class="hs-identifier hs-var">trainingModelSpec</span></a></span><span> </span><span class="annot"><span class="annottext">ListT
  IO
  (Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     ('DataType 'Float)
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) 'UncheckedSize, 'Dim ('Name &quot;*&quot;) ('Size 1)]),
   Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     ('DataType 'Float)
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) 'UncheckedSize, 'Dim ('Name &quot;*&quot;) ('Size 1)]))
</span><a href="#local-6989586621679663902"><span class="hs-identifier hs-var">batchedStream</span></a></span><span> </span><span class="annot"><span class="annottext">Generator ('Device 'CPU)
</span><a href="#local-6989586621679663911"><span class="hs-identifier hs-var">g</span></a></span><span>
</span><span id="line-336"></span><span>          </span><span class="hs-comment">-- returned is either the original generator or</span><span>
</span><span id="line-337"></span><span>          </span><span class="hs-comment">-- a pair of a generator and the average training loss</span><span>
</span><span id="line-338"></span><span>          </span><span class="hs-keyword">case</span><span> </span><span class="annot"><span class="annottext">Either
  (Generator ('Device 'CPU))
  (Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     ('DataType 'Float)
     ('Shape '[]),
   Generator ('Device 'CPU))
</span><a href="#local-6989586621679663903"><span class="hs-identifier hs-var">trainingLoss</span></a></span><span> </span><span class="hs-keyword">of</span><span>
</span><span id="line-339"></span><span>            </span><span class="annot"><span class="hs-identifier hs-type">Left</span></span><span> </span><span id="local-6989586621679663900"><span class="annot"><span class="annottext">Generator ('Device 'CPU)
</span><a href="#local-6989586621679663900"><span class="hs-identifier hs-var">g'</span></a></span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">(Generator ('Device 'CPU), Sample)
-&gt; Proxy
     X () () Monitor (ContT () IO) (Generator ('Device 'CPU), Sample)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Generator ('Device 'CPU)
</span><a href="#local-6989586621679663900"><span class="hs-identifier hs-var">g'</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Sample
</span><a href="#local-6989586621679663906"><span class="hs-identifier hs-var">shuffle</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-340"></span><span>            </span><span class="annot"><span class="hs-identifier hs-type">Right</span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679663899"><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Shape '[])
</span><a href="#local-6989586621679663899"><span class="hs-identifier hs-var">loss</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679663898"><span class="annot"><span class="annottext">Generator ('Device 'CPU)
</span><a href="#local-6989586621679663898"><span class="hs-identifier hs-var">g'</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-341"></span><span>              </span><span class="annot"><span class="annottext">Monitor -&gt; Proxy X () () Monitor (ContT () IO) ()
forall (m :: * -&gt; *) a x' x. Functor m =&gt; a -&gt; Proxy x' x () a m ()
</span><a href="../file:///nix/store/2275zkfvd9na2mx7hmkq7wzrgjyxz84l-pipes-lib-pipes-4.3.15-haddock-doc/share/doc/pipes/html/src"><span class="hs-identifier hs-var">P.yield</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Float -&gt; Int -&gt; Monitor
</span><a href="Torch.GraduallyTyped.Examples.TwoLayerNetwork.html#TrainingMonitor"><span class="hs-identifier hs-var">TrainingMonitor</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Shape '[])
-&gt; Float
forall a (dType :: DType) (dims :: [Dim (Name Symbol) (Size Nat)])
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat)).
TensorLike a dType dims =&gt;
Tensor gradient layout device ('DataType dType) ('Shape dims) -&gt; a
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#fromTensor"><span class="hs-identifier hs-var">fromTensor</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Shape '[])
</span><a href="#local-6989586621679663899"><span class="hs-identifier hs-var">loss</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679663910"><span class="hs-identifier hs-var">epoch</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-342"></span><span>              </span><span class="annot"><span class="annottext">(Generator ('Device 'CPU), Sample)
-&gt; Proxy
     X () () Monitor (ContT () IO) (Generator ('Device 'CPU), Sample)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Generator ('Device 'CPU)
</span><a href="#local-6989586621679663898"><span class="hs-identifier hs-var">g'</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Sample
</span><a href="#local-6989586621679663906"><span class="hs-identifier hs-var">shuffle</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-343"></span><span>
</span><span id="line-344"></span><span>        </span><span class="hs-comment">-- evaluate on the evaluation set</span><span>
</span><span id="line-345"></span><span>        </span><span class="hs-special">(</span><span id="local-6989586621679663895"><span class="annot"><span class="annottext">Generator ('Device 'CPU)
</span><a href="#local-6989586621679663895"><span class="hs-identifier hs-var">g''</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679663894"><span class="annot"><span class="annottext">Sample
</span><a href="#local-6989586621679663894"><span class="hs-identifier hs-var">shuffle'</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-346"></span><span>          </span><span class="hs-special">(</span><span id="local-6989586621679663893"><span class="annot"><span class="annottext">ListT IO (Float, Float)
</span><a href="#local-6989586621679663893"><span class="hs-identifier hs-var">evalStream</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679663892"><span class="annot"><span class="annottext">Sample
</span><a href="#local-6989586621679663892"><span class="hs-identifier hs-var">shuffle'</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">ContT () IO (ListT IO (Float, Float), Sample)
-&gt; Proxy
     X () () Monitor (ContT () IO) (ListT IO (Float, Float), Sample)
forall (t :: (* -&gt; *) -&gt; * -&gt; *) (m :: * -&gt; *) a.
(MonadTrans t, Monad m) =&gt;
m a -&gt; t m a
</span><span class="hs-identifier hs-var">P.lift</span></span><span> </span><span class="annot"><span class="annottext">(ContT () IO (ListT IO (Float, Float), Sample)
 -&gt; Proxy
      X () () Monitor (ContT () IO) (ListT IO (Float, Float), Sample))
-&gt; ContT () IO (ListT IO (Float, Float), Sample)
-&gt; Proxy
     X () () Monitor (ContT () IO) (ListT IO (Float, Float), Sample)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">DatasetOptions
-&gt; SincData -&gt; ContT () IO (ListT IO (Float, Float), Sample)
forall (m :: * -&gt; *) dataset k sample r.
(Dataset m dataset k sample, MonadIO m, MonadBaseControl IO m) =&gt;
DatasetOptions -&gt; dataset -&gt; ContT r m (ListT m sample, Sample)
</span><a href="../../../../hasktorch/html/src"><span class="hs-identifier hs-var">streamFromMap</span></a></span><span> </span><span class="annot"><span class="annottext">DatasetOptions
</span><a href="#local-6989586621679663912"><span class="hs-identifier hs-var">streamingState'</span></a></span><span> </span><span class="hs-special">{</span><span class="annot"><span class="annottext">Sample
shuffle :: Sample
shuffle :: Sample
</span><a href="#local-6989586621679663908"><span class="hs-identifier hs-var hs-var">shuffle</span></a></span><span class="hs-special">}</span><span> </span><span class="annot"><span class="annottext">SincData
</span><a href="#local-6989586621679663923"><span class="hs-identifier hs-var">evaluationData</span></a></span><span>
</span><span id="line-347"></span><span>          </span><span id="local-6989586621679663891"><span class="annot"><span class="annottext">Either
  (Generator ('Device 'CPU))
  (Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     ('DataType 'Float)
     ('Shape '[]),
   Generator ('Device 'CPU))
</span><a href="#local-6989586621679663891"><span class="hs-identifier hs-var">evalLoss</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">ContT
  ()
  IO
  (Either
     (Generator ('Device 'CPU))
     (Tensor
        ('Gradient 'WithoutGradient)
        ('Layout 'Dense)
        ('Device 'CPU)
        ('DataType 'Float)
        ('Shape '[]),
      Generator ('Device 'CPU)))
-&gt; Proxy
     X
     ()
     ()
     Monitor
     (ContT () IO)
     (Either
        (Generator ('Device 'CPU))
        (Tensor
           ('Gradient 'WithoutGradient)
           ('Layout 'Dense)
           ('Device 'CPU)
           ('DataType 'Float)
           ('Shape '[]),
         Generator ('Device 'CPU)))
forall (t :: (* -&gt; *) -&gt; * -&gt; *) (m :: * -&gt; *) a.
(MonadTrans t, Monad m) =&gt;
m a -&gt; t m a
</span><span class="hs-identifier hs-var">P.lift</span></span><span> </span><span class="annot"><span class="annottext">(ContT
   ()
   IO
   (Either
      (Generator ('Device 'CPU))
      (Tensor
         ('Gradient 'WithoutGradient)
         ('Layout 'Dense)
         ('Device 'CPU)
         ('DataType 'Float)
         ('Shape '[]),
       Generator ('Device 'CPU)))
 -&gt; Proxy
      X
      ()
      ()
      Monitor
      (ContT () IO)
      (Either
         (Generator ('Device 'CPU))
         (Tensor
            ('Gradient 'WithoutGradient)
            ('Layout 'Dense)
            ('Device 'CPU)
            ('DataType 'Float)
            ('Shape '[]),
          Generator ('Device 'CPU))))
-&gt; ContT
     ()
     IO
     (Either
        (Generator ('Device 'CPU))
        (Tensor
           ('Gradient 'WithoutGradient)
           ('Layout 'Dense)
           ('Device 'CPU)
           ('DataType 'Float)
           ('Shape '[]),
         Generator ('Device 'CPU)))
-&gt; Proxy
     X
     ()
     ()
     Monitor
     (ContT () IO)
     (Either
        (Generator ('Device 'CPU))
        (Tensor
           ('Gradient 'WithoutGradient)
           ('Layout 'Dense)
           ('Device 'CPU)
           ('DataType 'Float)
           ('Shape '[]),
         Generator ('Device 'CPU)))
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-348"></span><span>            </span><span id="local-6989586621679663890"><span class="annot"><span class="annottext">ListT
  IO
  (Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     ('DataType 'Float)
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) 'UncheckedSize, 'Dim ('Name &quot;*&quot;) ('Size 1)]),
   Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     ('DataType 'Float)
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) 'UncheckedSize, 'Dim ('Name &quot;*&quot;) ('Size 1)]))
</span><a href="#local-6989586621679663890"><span class="hs-identifier hs-var">batchedStream</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">ListT IO (Float, Float)
-&gt; ContT
     ()
     IO
     (ListT
        IO
        (Tensor
           ('Gradient 'WithoutGradient)
           ('Layout 'Dense)
           ('Device 'CPU)
           ('DataType 'Float)
           ('Shape
              '[ 'Dim ('Name &quot;*&quot;) 'UncheckedSize, 'Dim ('Name &quot;*&quot;) ('Size 1)]),
         Tensor
           ('Gradient 'WithoutGradient)
           ('Layout 'Dense)
           ('Device 'CPU)
           ('DataType 'Float)
           ('Shape
              '[ 'Dim ('Name &quot;*&quot;) 'UncheckedSize, 'Dim ('Name &quot;*&quot;) ('Size 1)])))
forall r.
ListT IO (Float, Float)
-&gt; ContT
     r
     IO
     (ListT
        IO
        (Tensor
           ('Gradient 'WithoutGradient)
           ('Layout 'Dense)
           ('Device 'CPU)
           ('DataType 'Float)
           ('Shape
              '[ 'Dim ('Name &quot;*&quot;) 'UncheckedSize, 'Dim ('Name &quot;*&quot;) ('Size 1)]),
         Tensor
           ('Gradient 'WithoutGradient)
           ('Layout 'Dense)
           ('Device 'CPU)
           ('DataType 'Float)
           ('Shape
              '[ 'Dim ('Name &quot;*&quot;) 'UncheckedSize, 'Dim ('Name &quot;*&quot;) ('Size 1)])))
</span><a href="#local-6989586621679663933"><span class="hs-identifier hs-var">collate'</span></a></span><span> </span><span class="annot"><span class="annottext">ListT IO (Float, Float)
</span><a href="#local-6989586621679663893"><span class="hs-identifier hs-var">evalStream</span></a></span><span>
</span><span id="line-349"></span><span>            </span><span class="annot"><span class="annottext">IO
  (Either
     (Generator ('Device 'CPU))
     (Tensor
        ('Gradient 'WithoutGradient)
        ('Layout 'Dense)
        ('Device 'CPU)
        ('DataType 'Float)
        ('Shape '[]),
      Generator ('Device 'CPU)))
-&gt; ContT
     ()
     IO
     (Either
        (Generator ('Device 'CPU))
        (Tensor
           ('Gradient 'WithoutGradient)
           ('Layout 'Dense)
           ('Device 'CPU)
           ('DataType 'Float)
           ('Shape '[]),
         Generator ('Device 'CPU)))
forall (t :: (* -&gt; *) -&gt; * -&gt; *) (m :: * -&gt; *) a.
(MonadTrans t, Monad m) =&gt;
m a -&gt; t m a
</span><span class="hs-identifier hs-var">lift</span></span><span> </span><span class="annot"><span class="annottext">(IO
   (Either
      (Generator ('Device 'CPU))
      (Tensor
         ('Gradient 'WithoutGradient)
         ('Layout 'Dense)
         ('Device 'CPU)
         ('DataType 'Float)
         ('Shape '[]),
       Generator ('Device 'CPU)))
 -&gt; ContT
      ()
      IO
      (Either
         (Generator ('Device 'CPU))
         (Tensor
            ('Gradient 'WithoutGradient)
            ('Layout 'Dense)
            ('Device 'CPU)
            ('DataType 'Float)
            ('Shape '[]),
          Generator ('Device 'CPU))))
-&gt; IO
     (Either
        (Generator ('Device 'CPU))
        (Tensor
           ('Gradient 'WithoutGradient)
           ('Layout 'Dense)
           ('Device 'CPU)
           ('DataType 'Float)
           ('Shape '[]),
         Generator ('Device 'CPU)))
-&gt; ContT
     ()
     IO
     (Either
        (Generator ('Device 'CPU))
        (Tensor
           ('Gradient 'WithoutGradient)
           ('Layout 'Dense)
           ('Device 'CPU)
           ('DataType 'Float)
           ('Shape '[]),
         Generator ('Device 'CPU)))
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-350"></span><span>              </span><span id="local-6989586621679663889"><span class="annot"><span class="annottext">StateDict
</span><a href="#local-6989586621679663889"><span class="hs-identifier hs-var">stateDict</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">Optimizer
  (NamedModel
     (TwoLayerNetwork
        (NamedModel
           (GLinear
              (NamedModel
                 (Tensor
                    ('Gradient 'WithGradient)
                    ('Layout 'Dense)
                    ('Device 'CPU)
                    ('DataType 'Float)
                    ('Shape
                       '[ 'Dim ('Name &quot;*&quot;) ('Size 100), 'Dim ('Name &quot;*&quot;) ('Size 1)])))
              (NamedModel
                 (Tensor
                    ('Gradient 'WithGradient)
                    ('Layout 'Dense)
                    ('Device 'CPU)
                    ('DataType 'Float)
                    ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 100)])))))
        Tanh
        Dropout
        (NamedModel
           (GLinear
              (NamedModel
                 (Tensor
                    ('Gradient 'WithGradient)
                    ('Layout 'Dense)
                    ('Device 'CPU)
                    ('DataType 'Float)
                    ('Shape
                       '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 100)])))
              (NamedModel
                 (Tensor
                    ('Gradient 'WithGradient)
                    ('Layout 'Dense)
                    ('Device 'CPU)
                    ('DataType 'Float)
                    ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1)])))))))
-&gt; IO StateDict
forall model. Optimizer model -&gt; IO StateDict
</span><a href="Torch.GraduallyTyped.Optim.html#getStateDict"><span class="hs-identifier hs-var">getStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">Optimizer
  (NamedModel
     (TwoLayerNetwork
        (NamedModel
           (GLinear
              (NamedModel
                 (Tensor
                    ('Gradient 'WithGradient)
                    ('Layout 'Dense)
                    ('Device 'CPU)
                    ('DataType 'Float)
                    ('Shape
                       '[ 'Dim ('Name &quot;*&quot;) ('Size 100), 'Dim ('Name &quot;*&quot;) ('Size 1)])))
              (NamedModel
                 (Tensor
                    ('Gradient 'WithGradient)
                    ('Layout 'Dense)
                    ('Device 'CPU)
                    ('DataType 'Float)
                    ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 100)])))))
        Tanh
        Dropout
        (NamedModel
           (GLinear
              (NamedModel
                 (Tensor
                    ('Gradient 'WithGradient)
                    ('Layout 'Dense)
                    ('Device 'CPU)
                    ('DataType 'Float)
                    ('Shape
                       '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 100)])))
              (NamedModel
                 (Tensor
                    ('Gradient 'WithGradient)
                    ('Layout 'Dense)
                    ('Device 'CPU)
                    ('DataType 'Float)
                    ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1)])))))))
</span><a href="#local-6989586621679663917"><span class="hs-identifier hs-var">optim</span></a></span><span>
</span><span id="line-351"></span><span>              </span><span id="local-6989586621679663887"><span class="annot"><span class="annottext">NamedModel
  (TwoLayerNetwork
     (NamedModel
        (GLinear
           (NamedModel
              (Tensor
                 ('Gradient 'WithoutGradient)
                 ('Layout 'Dense)
                 ('Device 'CPU)
                 ('DataType 'Float)
                 ('Shape
                    '[ 'Dim ('Name &quot;*&quot;) ('Size 100), 'Dim ('Name &quot;*&quot;) ('Size 1)])))
           (NamedModel
              (Tensor
                 ('Gradient 'WithoutGradient)
                 ('Layout 'Dense)
                 ('Device 'CPU)
                 ('DataType 'Float)
                 ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 100)])))))
     Tanh
     ()
     (NamedModel
        (GLinear
           (NamedModel
              (Tensor
                 ('Gradient 'WithoutGradient)
                 ('Layout 'Dense)
                 ('Device 'CPU)
                 ('DataType 'Float)
                 ('Shape
                    '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 100)])))
           (NamedModel
              (Tensor
                 ('Gradient 'WithoutGradient)
                 ('Layout 'Dense)
                 ('Device 'CPU)
                 ('DataType 'Float)
                 ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1)]))))))
</span><a href="#local-6989586621679663887"><span class="hs-identifier hs-var">evaluationModel</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">(StateT
   StateDict
   IO
   (NamedModel
      (TwoLayerNetwork
         (NamedModel
            (GLinear
               (NamedModel
                  (Tensor
                     ('Gradient 'WithoutGradient)
                     ('Layout 'Dense)
                     ('Device 'CPU)
                     ('DataType 'Float)
                     ('Shape
                        '[ 'Dim ('Name &quot;*&quot;) ('Size 100), 'Dim ('Name &quot;*&quot;) ('Size 1)])))
               (NamedModel
                  (Tensor
                     ('Gradient 'WithoutGradient)
                     ('Layout 'Dense)
                     ('Device 'CPU)
                     ('DataType 'Float)
                     ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 100)])))))
         Tanh
         ()
         (NamedModel
            (GLinear
               (NamedModel
                  (Tensor
                     ('Gradient 'WithoutGradient)
                     ('Layout 'Dense)
                     ('Device 'CPU)
                     ('DataType 'Float)
                     ('Shape
                        '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 100)])))
               (NamedModel
                  (Tensor
                     ('Gradient 'WithoutGradient)
                     ('Layout 'Dense)
                     ('Device 'CPU)
                     ('DataType 'Float)
                     ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1)])))))))
 -&gt; StateDict
 -&gt; IO
      (NamedModel
         (TwoLayerNetwork
            (NamedModel
               (GLinear
                  (NamedModel
                     (Tensor
                        ('Gradient 'WithoutGradient)
                        ('Layout 'Dense)
                        ('Device 'CPU)
                        ('DataType 'Float)
                        ('Shape
                           '[ 'Dim ('Name &quot;*&quot;) ('Size 100), 'Dim ('Name &quot;*&quot;) ('Size 1)])))
                  (NamedModel
                     (Tensor
                        ('Gradient 'WithoutGradient)
                        ('Layout 'Dense)
                        ('Device 'CPU)
                        ('DataType 'Float)
                        ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 100)])))))
            Tanh
            ()
            (NamedModel
               (GLinear
                  (NamedModel
                     (Tensor
                        ('Gradient 'WithoutGradient)
                        ('Layout 'Dense)
                        ('Device 'CPU)
                        ('DataType 'Float)
                        ('Shape
                           '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 100)])))
                  (NamedModel
                     (Tensor
                        ('Gradient 'WithoutGradient)
                        ('Layout 'Dense)
                        ('Device 'CPU)
                        ('DataType 'Float)
                        ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1)]))))))))
-&gt; StateDict
-&gt; StateT
     StateDict
     IO
     (NamedModel
        (TwoLayerNetwork
           (NamedModel
              (GLinear
                 (NamedModel
                    (Tensor
                       ('Gradient 'WithoutGradient)
                       ('Layout 'Dense)
                       ('Device 'CPU)
                       ('DataType 'Float)
                       ('Shape
                          '[ 'Dim ('Name &quot;*&quot;) ('Size 100), 'Dim ('Name &quot;*&quot;) ('Size 1)])))
                 (NamedModel
                    (Tensor
                       ('Gradient 'WithoutGradient)
                       ('Layout 'Dense)
                       ('Device 'CPU)
                       ('DataType 'Float)
                       ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 100)])))))
           Tanh
           ()
           (NamedModel
              (GLinear
                 (NamedModel
                    (Tensor
                       ('Gradient 'WithoutGradient)
                       ('Layout 'Dense)
                       ('Device 'CPU)
                       ('DataType 'Float)
                       ('Shape
                          '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 100)])))
                 (NamedModel
                    (Tensor
                       ('Gradient 'WithoutGradient)
                       ('Layout 'Dense)
                       ('Device 'CPU)
                       ('DataType 'Float)
                       ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1)])))))))
-&gt; IO
     (NamedModel
        (TwoLayerNetwork
           (NamedModel
              (GLinear
                 (NamedModel
                    (Tensor
                       ('Gradient 'WithoutGradient)
                       ('Layout 'Dense)
                       ('Device 'CPU)
                       ('DataType 'Float)
                       ('Shape
                          '[ 'Dim ('Name &quot;*&quot;) ('Size 100), 'Dim ('Name &quot;*&quot;) ('Size 1)])))
                 (NamedModel
                    (Tensor
                       ('Gradient 'WithoutGradient)
                       ('Layout 'Dense)
                       ('Device 'CPU)
                       ('DataType 'Float)
                       ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 100)])))))
           Tanh
           ()
           (NamedModel
              (GLinear
                 (NamedModel
                    (Tensor
                       ('Gradient 'WithoutGradient)
                       ('Layout 'Dense)
                       ('Device 'CPU)
                       ('DataType 'Float)
                       ('Shape
                          '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 100)])))
                 (NamedModel
                    (Tensor
                       ('Gradient 'WithoutGradient)
                       ('Layout 'Dense)
                       ('Device 'CPU)
                       ('DataType 'Float)
                       ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1)])))))))
forall a b c. (a -&gt; b -&gt; c) -&gt; b -&gt; a -&gt; c
</span><span class="hs-identifier hs-var">flip</span></span><span> </span><span class="annot"><span class="annottext">StateT
  StateDict
  IO
  (NamedModel
     (TwoLayerNetwork
        (NamedModel
           (GLinear
              (NamedModel
                 (Tensor
                    ('Gradient 'WithoutGradient)
                    ('Layout 'Dense)
                    ('Device 'CPU)
                    ('DataType 'Float)
                    ('Shape
                       '[ 'Dim ('Name &quot;*&quot;) ('Size 100), 'Dim ('Name &quot;*&quot;) ('Size 1)])))
              (NamedModel
                 (Tensor
                    ('Gradient 'WithoutGradient)
                    ('Layout 'Dense)
                    ('Device 'CPU)
                    ('DataType 'Float)
                    ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 100)])))))
        Tanh
        ()
        (NamedModel
           (GLinear
              (NamedModel
                 (Tensor
                    ('Gradient 'WithoutGradient)
                    ('Layout 'Dense)
                    ('Device 'CPU)
                    ('DataType 'Float)
                    ('Shape
                       '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 100)])))
              (NamedModel
                 (Tensor
                    ('Gradient 'WithoutGradient)
                    ('Layout 'Dense)
                    ('Device 'CPU)
                    ('DataType 'Float)
                    ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1)])))))))
-&gt; StateDict
-&gt; IO
     (NamedModel
        (TwoLayerNetwork
           (NamedModel
              (GLinear
                 (NamedModel
                    (Tensor
                       ('Gradient 'WithoutGradient)
                       ('Layout 'Dense)
                       ('Device 'CPU)
                       ('DataType 'Float)
                       ('Shape
                          '[ 'Dim ('Name &quot;*&quot;) ('Size 100), 'Dim ('Name &quot;*&quot;) ('Size 1)])))
                 (NamedModel
                    (Tensor
                       ('Gradient 'WithoutGradient)
                       ('Layout 'Dense)
                       ('Device 'CPU)
                       ('DataType 'Float)
                       ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 100)])))))
           Tanh
           ()
           (NamedModel
              (GLinear
                 (NamedModel
                    (Tensor
                       ('Gradient 'WithoutGradient)
                       ('Layout 'Dense)
                       ('Device 'CPU)
                       ('DataType 'Float)
                       ('Shape
                          '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 100)])))
                 (NamedModel
                    (Tensor
                       ('Gradient 'WithoutGradient)
                       ('Layout 'Dense)
                       ('Device 'CPU)
                       ('DataType 'Float)
                       ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1)])))))))
forall (m :: * -&gt; *) s a. Monad m =&gt; StateT s m a -&gt; s -&gt; m a
</span><span class="hs-identifier hs-var">evalStateT</span></span><span> </span><span class="annot"><span class="annottext">StateDict
</span><a href="#local-6989586621679663889"><span class="hs-identifier hs-var">stateDict</span></a></span><span> </span><span class="annot"><span class="annottext">(StateT
   StateDict
   IO
   (NamedModel
      (TwoLayerNetwork
         (NamedModel
            (GLinear
               (NamedModel
                  (Tensor
                     ('Gradient 'WithoutGradient)
                     ('Layout 'Dense)
                     ('Device 'CPU)
                     ('DataType 'Float)
                     ('Shape
                        '[ 'Dim ('Name &quot;*&quot;) ('Size 100), 'Dim ('Name &quot;*&quot;) ('Size 1)])))
               (NamedModel
                  (Tensor
                     ('Gradient 'WithoutGradient)
                     ('Layout 'Dense)
                     ('Device 'CPU)
                     ('DataType 'Float)
                     ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 100)])))))
         Tanh
         ()
         (NamedModel
            (GLinear
               (NamedModel
                  (Tensor
                     ('Gradient 'WithoutGradient)
                     ('Layout 'Dense)
                     ('Device 'CPU)
                     ('DataType 'Float)
                     ('Shape
                        '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 100)])))
               (NamedModel
                  (Tensor
                     ('Gradient 'WithoutGradient)
                     ('Layout 'Dense)
                     ('Device 'CPU)
                     ('DataType 'Float)
                     ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1)])))))))
 -&gt; IO
      (NamedModel
         (TwoLayerNetwork
            (NamedModel
               (GLinear
                  (NamedModel
                     (Tensor
                        ('Gradient 'WithoutGradient)
                        ('Layout 'Dense)
                        ('Device 'CPU)
                        ('DataType 'Float)
                        ('Shape
                           '[ 'Dim ('Name &quot;*&quot;) ('Size 100), 'Dim ('Name &quot;*&quot;) ('Size 1)])))
                  (NamedModel
                     (Tensor
                        ('Gradient 'WithoutGradient)
                        ('Layout 'Dense)
                        ('Device 'CPU)
                        ('DataType 'Float)
                        ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 100)])))))
            Tanh
            ()
            (NamedModel
               (GLinear
                  (NamedModel
                     (Tensor
                        ('Gradient 'WithoutGradient)
                        ('Layout 'Dense)
                        ('Device 'CPU)
                        ('DataType 'Float)
                        ('Shape
                           '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 100)])))
                  (NamedModel
                     (Tensor
                        ('Gradient 'WithoutGradient)
                        ('Layout 'Dense)
                        ('Device 'CPU)
                        ('DataType 'Float)
                        ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1)]))))))))
-&gt; StateT
     StateDict
     IO
     (NamedModel
        (TwoLayerNetwork
           (NamedModel
              (GLinear
                 (NamedModel
                    (Tensor
                       ('Gradient 'WithoutGradient)
                       ('Layout 'Dense)
                       ('Device 'CPU)
                       ('DataType 'Float)
                       ('Shape
                          '[ 'Dim ('Name &quot;*&quot;) ('Size 100), 'Dim ('Name &quot;*&quot;) ('Size 1)])))
                 (NamedModel
                    (Tensor
                       ('Gradient 'WithoutGradient)
                       ('Layout 'Dense)
                       ('Device 'CPU)
                       ('DataType 'Float)
                       ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 100)])))))
           Tanh
           ()
           (NamedModel
              (GLinear
                 (NamedModel
                    (Tensor
                       ('Gradient 'WithoutGradient)
                       ('Layout 'Dense)
                       ('Device 'CPU)
                       ('DataType 'Float)
                       ('Shape
                          '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 100)])))
                 (NamedModel
                    (Tensor
                       ('Gradient 'WithoutGradient)
                       ('Layout 'Dense)
                       ('Device 'CPU)
                       ('DataType 'Float)
                       ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1)])))))))
-&gt; IO
     (NamedModel
        (TwoLayerNetwork
           (NamedModel
              (GLinear
                 (NamedModel
                    (Tensor
                       ('Gradient 'WithoutGradient)
                       ('Layout 'Dense)
                       ('Device 'CPU)
                       ('DataType 'Float)
                       ('Shape
                          '[ 'Dim ('Name &quot;*&quot;) ('Size 100), 'Dim ('Name &quot;*&quot;) ('Size 1)])))
                 (NamedModel
                    (Tensor
                       ('Gradient 'WithoutGradient)
                       ('Layout 'Dense)
                       ('Device 'CPU)
                       ('DataType 'Float)
                       ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 100)])))))
           Tanh
           ()
           (NamedModel
              (GLinear
                 (NamedModel
                    (Tensor
                       ('Gradient 'WithoutGradient)
                       ('Layout 'Dense)
                       ('Device 'CPU)
                       ('DataType 'Float)
                       ('Shape
                          '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 100)])))
                 (NamedModel
                    (Tensor
                       ('Gradient 'WithoutGradient)
                       ('Layout 'Dense)
                       ('Device 'CPU)
                       ('DataType 'Float)
                       ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1)])))))))
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (NamedModel
     (TwoLayerNetwork
        (NamedModel
           (GLinear
              (NamedModel
                 (Tensor
                    ('Gradient 'WithoutGradient)
                    ('Layout 'Dense)
                    ('Device 'CPU)
                    ('DataType 'Float)
                    ('Shape
                       '[ 'Dim ('Name &quot;*&quot;) ('Size 100), 'Dim ('Name &quot;*&quot;) ('Size 1)])))
              (NamedModel
                 (Tensor
                    ('Gradient 'WithoutGradient)
                    ('Layout 'Dense)
                    ('Device 'CPU)
                    ('DataType 'Float)
                    ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 100)])))))
        Tanh
        ()
        (NamedModel
           (GLinear
              (NamedModel
                 (Tensor
                    ('Gradient 'WithoutGradient)
                    ('Layout 'Dense)
                    ('Device 'CPU)
                    ('DataType 'Float)
                    ('Shape
                       '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 100)])))
              (NamedModel
                 (Tensor
                    ('Gradient 'WithoutGradient)
                    ('Layout 'Dense)
                    ('Device 'CPU)
                    ('DataType 'Float)
                    ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1)])))))))
-&gt; Text
-&gt; StateT
     StateDict
     IO
     (NamedModel
        (TwoLayerNetwork
           (NamedModel
              (GLinear
                 (NamedModel
                    (Tensor
                       ('Gradient 'WithoutGradient)
                       ('Layout 'Dense)
                       ('Device 'CPU)
                       ('DataType 'Float)
                       ('Shape
                          '[ 'Dim ('Name &quot;*&quot;) ('Size 100), 'Dim ('Name &quot;*&quot;) ('Size 1)])))
                 (NamedModel
                    (Tensor
                       ('Gradient 'WithoutGradient)
                       ('Layout 'Dense)
                       ('Device 'CPU)
                       ('DataType 'Float)
                       ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 100)])))))
           Tanh
           ()
           (NamedModel
              (GLinear
                 (NamedModel
                    (Tensor
                       ('Gradient 'WithoutGradient)
                       ('Layout 'Dense)
                       ('Device 'CPU)
                       ('DataType 'Float)
                       ('Shape
                          '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 100)])))
                 (NamedModel
                    (Tensor
                       ('Gradient 'WithoutGradient)
                       ('Layout 'Dense)
                       ('Device 'CPU)
                       ('DataType 'Float)
                       ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1)])))))))
forall model (m :: * -&gt; *).
(HasStateDict model, MonadIO m, MonadThrow m,
 MonadState StateDict m) =&gt;
ModelSpec model -&gt; Text -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (NamedModel
     (TwoLayerNetwork
        (NamedModel
           (GLinear
              (NamedModel
                 (Tensor
                    ('Gradient 'WithoutGradient)
                    ('Layout 'Dense)
                    ('Device 'CPU)
                    ('DataType 'Float)
                    ('Shape
                       '[ 'Dim ('Name &quot;*&quot;) ('Size 100), 'Dim ('Name &quot;*&quot;) ('Size 1)])))
              (NamedModel
                 (Tensor
                    ('Gradient 'WithoutGradient)
                    ('Layout 'Dense)
                    ('Device 'CPU)
                    ('DataType 'Float)
                    ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 100)])))))
        Tanh
        ()
        (NamedModel
           (GLinear
              (NamedModel
                 (Tensor
                    ('Gradient 'WithoutGradient)
                    ('Layout 'Dense)
                    ('Device 'CPU)
                    ('DataType 'Float)
                    ('Shape
                       '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 100)])))
              (NamedModel
                 (Tensor
                    ('Gradient 'WithoutGradient)
                    ('Layout 'Dense)
                    ('Device 'CPU)
                    ('DataType 'Float)
                    ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1)])))))))
NamedModel
  (TwoLayerNetwork
     (NamedModel
        (GLinear
           (NamedModel
              (TensorSpec
                 ('Gradient 'WithoutGradient)
                 ('Layout 'Dense)
                 ('Device 'CPU)
                 ('DataType 'Float)
                 ('Shape
                    '[ 'Dim ('Name &quot;*&quot;) ('Size 100), 'Dim ('Name &quot;*&quot;) ('Size 1)])))
           (NamedModel
              (TensorSpec
                 ('Gradient 'WithoutGradient)
                 ('Layout 'Dense)
                 ('Device 'CPU)
                 ('DataType 'Float)
                 ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 100)])))))
     Tanh
     ()
     (NamedModel
        (GLinear
           (NamedModel
              (TensorSpec
                 ('Gradient 'WithoutGradient)
                 ('Layout 'Dense)
                 ('Device 'CPU)
                 ('DataType 'Float)
                 ('Shape
                    '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 100)])))
           (NamedModel
              (TensorSpec
                 ('Gradient 'WithoutGradient)
                 ('Layout 'Dense)
                 ('Device 'CPU)
                 ('DataType 'Float)
                 ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1)]))))))
</span><a href="#local-6989586621679663939"><span class="hs-identifier hs-var">evaluationModelSpec</span></a></span><span> </span><span class="annot"><span class="annottext">Text
forall a. Monoid a =&gt; a
</span><span class="hs-identifier hs-var">mempty</span></span><span>
</span><span id="line-352"></span><span>              </span><span class="annot"><span class="annottext">NamedModel
  (TwoLayerNetwork
     (NamedModel
        (GLinear
           (NamedModel
              (Tensor
                 ('Gradient 'WithoutGradient)
                 ('Layout 'Dense)
                 ('Device 'CPU)
                 ('DataType 'Float)
                 ('Shape
                    '[ 'Dim ('Name &quot;*&quot;) ('Size 100), 'Dim ('Name &quot;*&quot;) ('Size 1)])))
           (NamedModel
              (Tensor
                 ('Gradient 'WithoutGradient)
                 ('Layout 'Dense)
                 ('Device 'CPU)
                 ('DataType 'Float)
                 ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 100)])))))
     Tanh
     ()
     (NamedModel
        (GLinear
           (NamedModel
              (Tensor
                 ('Gradient 'WithoutGradient)
                 ('Layout 'Dense)
                 ('Device 'CPU)
                 ('DataType 'Float)
                 ('Shape
                    '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 100)])))
           (NamedModel
              (Tensor
                 ('Gradient 'WithoutGradient)
                 ('Layout 'Dense)
                 ('Device 'CPU)
                 ('DataType 'Float)
                 ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1)]))))))
-&gt; ListT
     IO
     (Tensor
        ('Gradient 'WithoutGradient)
        ('Layout 'Dense)
        ('Device 'CPU)
        ('DataType 'Float)
        ('Shape
           '[ 'Dim ('Name &quot;*&quot;) 'UncheckedSize, 'Dim ('Name &quot;*&quot;) ('Size 1)]),
      Tensor
        ('Gradient 'WithoutGradient)
        ('Layout 'Dense)
        ('Device 'CPU)
        ('DataType 'Float)
        ('Shape
           '[ 'Dim ('Name &quot;*&quot;) 'UncheckedSize, 'Dim ('Name &quot;*&quot;) ('Size 1)]))
-&gt; Generator ('Device 'CPU)
-&gt; IO
     (Either
        (Generator ('Device 'CPU))
        (Tensor
           ('Gradient 'WithoutGradient)
           ('Layout 'Dense)
           ('Device 'CPU)
           ('DataType 'Float)
           ('Shape '[]),
         Generator ('Device 'CPU)))
forall (m :: * -&gt; *) model input
       (generatorDevice :: Device (DeviceType Nat))
       (lossGradient :: Gradient RequiresGradient)
       (lossLayout :: Layout LayoutType)
       (lossDataType :: Device (DeviceType Nat))
       (lossDevice :: DataType DType)
       (lossShape :: Shape [Dim (Name Symbol) (Size Nat)])
       (generatorOutputDevice :: Device (DeviceType Nat)).
(MonadIO m, HasStateDict model,
 HasForward
   model
   input
   generatorDevice
   (Tensor lossGradient lossLayout lossDataType lossDevice lossShape)
   generatorOutputDevice,
 HasForward
   model
   input
   generatorOutputDevice
   (Tensor lossGradient lossLayout lossDataType lossDevice lossShape)
   generatorOutputDevice,
 SGetGradient lossGradient, SGetShape lossShape,
 Catch (lossShape &lt;+&gt; 'Shape '[]),
 Catch (lossGradient &lt;+&gt; 'Gradient 'WithoutGradient)) =&gt;
model
-&gt; ListT m input
-&gt; Generator generatorDevice
-&gt; m (Either
        (Generator generatorDevice)
        (Tensor
           ('Gradient 'WithoutGradient)
           lossLayout
           lossDataType
           lossDevice
           ('Shape '[]),
         Generator generatorOutputDevice))
</span><a href="Torch.GraduallyTyped.NN.Training.html#eval"><span class="hs-identifier hs-var">eval</span></a></span><span> </span><span class="annot"><span class="annottext">NamedModel
  (TwoLayerNetwork
     (NamedModel
        (GLinear
           (NamedModel
              (Tensor
                 ('Gradient 'WithoutGradient)
                 ('Layout 'Dense)
                 ('Device 'CPU)
                 ('DataType 'Float)
                 ('Shape
                    '[ 'Dim ('Name &quot;*&quot;) ('Size 100), 'Dim ('Name &quot;*&quot;) ('Size 1)])))
           (NamedModel
              (Tensor
                 ('Gradient 'WithoutGradient)
                 ('Layout 'Dense)
                 ('Device 'CPU)
                 ('DataType 'Float)
                 ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 100)])))))
     Tanh
     ()
     (NamedModel
        (GLinear
           (NamedModel
              (Tensor
                 ('Gradient 'WithoutGradient)
                 ('Layout 'Dense)
                 ('Device 'CPU)
                 ('DataType 'Float)
                 ('Shape
                    '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 100)])))
           (NamedModel
              (Tensor
                 ('Gradient 'WithoutGradient)
                 ('Layout 'Dense)
                 ('Device 'CPU)
                 ('DataType 'Float)
                 ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1)]))))))
</span><a href="#local-6989586621679663887"><span class="hs-identifier hs-var">evaluationModel</span></a></span><span> </span><span class="annot"><span class="annottext">ListT
  IO
  (Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     ('DataType 'Float)
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) 'UncheckedSize, 'Dim ('Name &quot;*&quot;) ('Size 1)]),
   Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     ('DataType 'Float)
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) 'UncheckedSize, 'Dim ('Name &quot;*&quot;) ('Size 1)]))
</span><a href="#local-6989586621679663890"><span class="hs-identifier hs-var">batchedStream</span></a></span><span> </span><span class="annot"><span class="annottext">Generator ('Device 'CPU)
</span><a href="#local-6989586621679663909"><span class="hs-identifier hs-var">g'</span></a></span><span>
</span><span id="line-353"></span><span>          </span><span class="hs-comment">-- returned is either the original generator or</span><span>
</span><span id="line-354"></span><span>          </span><span class="hs-comment">-- a pair of a generator and the average evaluation loss</span><span>
</span><span id="line-355"></span><span>          </span><span class="hs-keyword">case</span><span> </span><span class="annot"><span class="annottext">Either
  (Generator ('Device 'CPU))
  (Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     ('DataType 'Float)
     ('Shape '[]),
   Generator ('Device 'CPU))
</span><a href="#local-6989586621679663891"><span class="hs-identifier hs-var">evalLoss</span></a></span><span> </span><span class="hs-keyword">of</span><span>
</span><span id="line-356"></span><span>            </span><span class="annot"><span class="hs-identifier hs-type">Left</span></span><span> </span><span id="local-6989586621679663883"><span class="annot"><span class="annottext">Generator ('Device 'CPU)
</span><a href="#local-6989586621679663883"><span class="hs-identifier hs-var">g''</span></a></span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">(Generator ('Device 'CPU), Sample)
-&gt; Proxy
     X () () Monitor (ContT () IO) (Generator ('Device 'CPU), Sample)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Generator ('Device 'CPU)
</span><a href="#local-6989586621679663883"><span class="hs-identifier hs-var">g''</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Sample
</span><a href="#local-6989586621679663892"><span class="hs-identifier hs-var">shuffle'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-357"></span><span>            </span><span class="annot"><span class="hs-identifier hs-type">Right</span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679663882"><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Shape '[])
</span><a href="#local-6989586621679663882"><span class="hs-identifier hs-var">loss</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679663881"><span class="annot"><span class="annottext">Generator ('Device 'CPU)
</span><a href="#local-6989586621679663881"><span class="hs-identifier hs-var">g''</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-358"></span><span>              </span><span class="annot"><span class="annottext">Monitor -&gt; Proxy X () () Monitor (ContT () IO) ()
forall (m :: * -&gt; *) a x' x. Functor m =&gt; a -&gt; Proxy x' x () a m ()
</span><a href="../file:///nix/store/2275zkfvd9na2mx7hmkq7wzrgjyxz84l-pipes-lib-pipes-4.3.15-haddock-doc/share/doc/pipes/html/src"><span class="hs-identifier hs-var">P.yield</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Float -&gt; Int -&gt; Monitor
</span><a href="Torch.GraduallyTyped.Examples.TwoLayerNetwork.html#EvaluationMonitor"><span class="hs-identifier hs-var">EvaluationMonitor</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Shape '[])
-&gt; Float
forall a (dType :: DType) (dims :: [Dim (Name Symbol) (Size Nat)])
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat)).
TensorLike a dType dims =&gt;
Tensor gradient layout device ('DataType dType) ('Shape dims) -&gt; a
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#fromTensor"><span class="hs-identifier hs-var">fromTensor</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Shape '[])
</span><a href="#local-6989586621679663882"><span class="hs-identifier hs-var">loss</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679663910"><span class="hs-identifier hs-var">epoch</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-359"></span><span>              </span><span class="annot"><span class="annottext">(Generator ('Device 'CPU), Sample)
-&gt; Proxy
     X () () Monitor (ContT () IO) (Generator ('Device 'CPU), Sample)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Generator ('Device 'CPU)
</span><a href="#local-6989586621679663881"><span class="hs-identifier hs-var">g''</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Sample
</span><a href="#local-6989586621679663892"><span class="hs-identifier hs-var">shuffle'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-360"></span><span>
</span><span id="line-361"></span><span>        </span><span class="annot"><span class="annottext">(DatasetOptions, Generator ('Device 'CPU))
-&gt; Proxy
     X
     ()
     ()
     Monitor
     (ContT () IO)
     (DatasetOptions, Generator ('Device 'CPU))
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">DatasetOptions
</span><a href="#local-6989586621679663912"><span class="hs-identifier hs-var">streamingState'</span></a></span><span> </span><span class="hs-special">{</span><span class="annot"><span class="annottext">shuffle :: Sample
</span><a href="../../../../hasktorch/html/src"><span class="hs-identifier hs-var">shuffle</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Sample
</span><a href="#local-6989586621679663894"><span class="hs-identifier hs-var">shuffle'</span></a></span><span class="hs-special">}</span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Generator ('Device 'CPU)
</span><a href="#local-6989586621679663895"><span class="hs-identifier hs-var">g''</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-362"></span><span>
</span><span id="line-363"></span><span>  </span><span class="hs-keyword">let</span><span> </span><span class="hs-comment">-- initialize the training loop</span><span>
</span><span id="line-364"></span><span>      </span><span id="local-6989586621679663880"><span class="annot"><span class="annottext">init' :: Proxy
  X
  ()
  ()
  Monitor
  (ContT () IO)
  (DatasetOptions, Generator ('Device 'CPU))
</span><a href="#local-6989586621679663880"><span class="hs-identifier hs-var hs-var">init'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(DatasetOptions, Generator ('Device 'CPU))
-&gt; Proxy
     X
     ()
     ()
     Monitor
     (ContT () IO)
     (DatasetOptions, Generator ('Device 'CPU))
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">DatasetOptions
</span><a href="#local-6989586621679663922"><span class="hs-identifier hs-var">streamingState</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Generator ('Device 'CPU)
</span><a href="#local-6989586621679663935"><span class="hs-identifier hs-var">g1</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-365"></span><span>
</span><span id="line-366"></span><span>  </span><span class="hs-keyword">let</span><span> </span><span class="hs-comment">-- finalize the training loop</span><span>
</span><span id="line-367"></span><span>      </span><span id="local-6989586621679663879"><span class="annot"><span class="annottext">done :: (a, b) -&gt; f ()
</span><a href="#local-6989586621679663879"><span class="hs-identifier hs-var hs-var">done</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679663878"><span class="annot"><span class="annottext">a
</span><a href="#local-6989586621679663878"><span class="hs-identifier hs-var">_streamingState'</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679663877"><span class="annot"><span class="annottext">b
</span><a href="#local-6989586621679663877"><span class="hs-identifier hs-var">_g2</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">() -&gt; f ()
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-368"></span><span>
</span><span id="line-369"></span><span>  </span><span class="hs-comment">-- run the training loop</span><span>
</span><span id="line-370"></span><span>  </span><span class="annot"><span class="annottext">(ContT () IO () -&gt; (() -&gt; IO ()) -&gt; IO ())
-&gt; (() -&gt; IO ()) -&gt; ContT () IO () -&gt; IO ()
forall a b c. (a -&gt; b -&gt; c) -&gt; b -&gt; a -&gt; c
</span><span class="hs-identifier hs-var">flip</span></span><span> </span><span class="annot"><span class="annottext">ContT () IO () -&gt; (() -&gt; IO ()) -&gt; IO ()
forall k (r :: k) (m :: k -&gt; *) a. ContT r m a -&gt; (a -&gt; m r) -&gt; m r
</span><span class="hs-identifier hs-var hs-var">runContT</span></span><span> </span><span class="annot"><span class="annottext">() -&gt; IO ()
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">(ContT () IO () -&gt; IO ())
-&gt; (Effect (ContT () IO) () -&gt; ContT () IO ())
-&gt; Effect (ContT () IO) ()
-&gt; IO ()
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Effect (ContT () IO) () -&gt; ContT () IO ()
forall (m :: * -&gt; *) r. Monad m =&gt; Effect m r -&gt; m r
</span><a href="../file:///nix/store/2275zkfvd9na2mx7hmkq7wzrgjyxz84l-pipes-lib-pipes-4.3.15-haddock-doc/share/doc/pipes/html/src"><span class="hs-identifier hs-var">P.runEffect</span></a></span><span> </span><span class="annot"><span class="annottext">(Effect (ContT () IO) () -&gt; IO ())
-&gt; Effect (ContT () IO) () -&gt; IO ()
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-371"></span><span>    </span><span class="annot"><span class="annottext">((DatasetOptions, Generator ('Device 'CPU))
 -&gt; Int
 -&gt; Proxy
      X
      ()
      ()
      Monitor
      (ContT () IO)
      (DatasetOptions, Generator ('Device 'CPU)))
-&gt; Proxy
     X
     ()
     ()
     Monitor
     (ContT () IO)
     (DatasetOptions, Generator ('Device 'CPU))
-&gt; ((DatasetOptions, Generator ('Device 'CPU))
    -&gt; Proxy X () () Monitor (ContT () IO) ())
-&gt; Producer Int (Proxy X () () Monitor (ContT () IO)) ()
-&gt; Proxy X () () Monitor (ContT () IO) ()
forall (m :: * -&gt; *) x a b.
Monad m =&gt;
(x -&gt; a -&gt; m x) -&gt; m x -&gt; (x -&gt; m b) -&gt; Producer a m () -&gt; m b
</span><a href="../file:///nix/store/2275zkfvd9na2mx7hmkq7wzrgjyxz84l-pipes-lib-pipes-4.3.15-haddock-doc/share/doc/pipes/html/src"><span class="hs-identifier hs-var">P.foldM</span></a></span><span> </span><span class="annot"><span class="annottext">(DatasetOptions, Generator ('Device 'CPU))
-&gt; Int
-&gt; Proxy
     X
     ()
     ()
     Monitor
     (ContT () IO)
     (DatasetOptions, Generator ('Device 'CPU))
</span><a href="#local-6989586621679663913"><span class="hs-identifier hs-var">step</span></a></span><span> </span><span class="annot"><span class="annottext">Proxy
  X
  ()
  ()
  Monitor
  (ContT () IO)
  (DatasetOptions, Generator ('Device 'CPU))
</span><a href="#local-6989586621679663880"><span class="hs-identifier hs-var">init'</span></a></span><span> </span><span class="annot"><span class="annottext">(DatasetOptions, Generator ('Device 'CPU))
-&gt; Proxy X () () Monitor (ContT () IO) ()
forall (f :: * -&gt; *) a b. Applicative f =&gt; (a, b) -&gt; f ()
</span><a href="#local-6989586621679663879"><span class="hs-identifier hs-var">done</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">[Int] -&gt; Producer Int (Proxy X () () Monitor (ContT () IO)) ()
forall (m :: * -&gt; *) (f :: * -&gt; *) a x' x.
(Functor m, Foldable f) =&gt;
f a -&gt; Proxy x' x () a m ()
</span><a href="../file:///nix/store/2275zkfvd9na2mx7hmkq7wzrgjyxz84l-pipes-lib-pipes-4.3.15-haddock-doc/share/doc/pipes/html/src"><span class="hs-identifier hs-var">P.each</span></a></span><span> </span><span class="hs-special">[</span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">1</span></span><span> </span><span class="hs-glyph">..</span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679663931"><span class="hs-identifier hs-var">numEpochs</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-372"></span><span>      </span><span class="annot"><span class="annottext">Proxy X () () Monitor (ContT () IO) ()
-&gt; Proxy () Monitor () X (ContT () IO) ()
-&gt; Effect (ContT () IO) ()
forall (m :: * -&gt; *) a' a b r c' c.
Functor m =&gt;
Proxy a' a () b m r -&gt; Proxy () b c' c m r -&gt; Proxy a' a c' c m r
</span><a href="../file:///nix/store/2275zkfvd9na2mx7hmkq7wzrgjyxz84l-pipes-lib-pipes-4.3.15-haddock-doc/share/doc/pipes/html/src"><span class="hs-operator hs-var">P.&gt;-&gt;</span></a></span><span> </span><span class="annot"><span class="annottext">Proxy () Monitor () X (ContT () IO) ()
forall (m :: * -&gt; *) r. MonadIO m =&gt; Consumer Monitor m r
</span><a href="Torch.GraduallyTyped.Examples.TwoLayerNetwork.html#monitor"><span class="hs-identifier hs-var">monitor</span></a></span><span>
</span><span id="line-373"></span><span>
</span><span id="line-374"></span><span>  </span><span class="hs-comment">-- save the model's state dictionary to a file</span><span>
</span><span id="line-375"></span><span>  </span><span id="local-6989586621679663872"><span class="annot"><span class="annottext">StateDict
</span><a href="#local-6989586621679663872"><span class="hs-identifier hs-var">stateDict'</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">Optimizer
  (NamedModel
     (TwoLayerNetwork
        (NamedModel
           (GLinear
              (NamedModel
                 (Tensor
                    ('Gradient 'WithGradient)
                    ('Layout 'Dense)
                    ('Device 'CPU)
                    ('DataType 'Float)
                    ('Shape
                       '[ 'Dim ('Name &quot;*&quot;) ('Size 100), 'Dim ('Name &quot;*&quot;) ('Size 1)])))
              (NamedModel
                 (Tensor
                    ('Gradient 'WithGradient)
                    ('Layout 'Dense)
                    ('Device 'CPU)
                    ('DataType 'Float)
                    ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 100)])))))
        Tanh
        Dropout
        (NamedModel
           (GLinear
              (NamedModel
                 (Tensor
                    ('Gradient 'WithGradient)
                    ('Layout 'Dense)
                    ('Device 'CPU)
                    ('DataType 'Float)
                    ('Shape
                       '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 100)])))
              (NamedModel
                 (Tensor
                    ('Gradient 'WithGradient)
                    ('Layout 'Dense)
                    ('Device 'CPU)
                    ('DataType 'Float)
                    ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1)])))))))
-&gt; IO StateDict
forall model. Optimizer model -&gt; IO StateDict
</span><a href="Torch.GraduallyTyped.Optim.html#getStateDict"><span class="hs-identifier hs-var">getStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">Optimizer
  (NamedModel
     (TwoLayerNetwork
        (NamedModel
           (GLinear
              (NamedModel
                 (Tensor
                    ('Gradient 'WithGradient)
                    ('Layout 'Dense)
                    ('Device 'CPU)
                    ('DataType 'Float)
                    ('Shape
                       '[ 'Dim ('Name &quot;*&quot;) ('Size 100), 'Dim ('Name &quot;*&quot;) ('Size 1)])))
              (NamedModel
                 (Tensor
                    ('Gradient 'WithGradient)
                    ('Layout 'Dense)
                    ('Device 'CPU)
                    ('DataType 'Float)
                    ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 100)])))))
        Tanh
        Dropout
        (NamedModel
           (GLinear
              (NamedModel
                 (Tensor
                    ('Gradient 'WithGradient)
                    ('Layout 'Dense)
                    ('Device 'CPU)
                    ('DataType 'Float)
                    ('Shape
                       '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 100)])))
              (NamedModel
                 (Tensor
                    ('Gradient 'WithGradient)
                    ('Layout 'Dense)
                    ('Device 'CPU)
                    ('DataType 'Float)
                    ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1)])))))))
</span><a href="#local-6989586621679663917"><span class="hs-identifier hs-var">optim</span></a></span><span>
</span><span id="line-376"></span><span>  </span><span class="annot"><span class="annottext">StateDict -&gt; String -&gt; IO ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#stateDictToFile"><span class="hs-identifier hs-var">stateDictToFile</span></a></span><span> </span><span class="annot"><span class="annottext">StateDict
</span><a href="#local-6989586621679663872"><span class="hs-identifier hs-var">stateDict'</span></a></span><span> </span><span class="annot"><span class="annottext">String
</span><span class="hs-string">&quot;twoLayerNetwork.pt&quot;</span></span><span>
</span><span id="line-377"></span></pre></body></html>