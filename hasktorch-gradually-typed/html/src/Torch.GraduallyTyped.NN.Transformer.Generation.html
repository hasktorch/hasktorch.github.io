<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><link rel="stylesheet" type="text/css" href="style.css" /><script type="text/javascript" src="highlight.js"></script></head><body><pre><span class="hs-pragma">{-# LANGUAGE DataKinds #-}</span><span>
</span><span id="line-2"></span><span class="hs-pragma">{-# LANGUAGE FlexibleContexts #-}</span><span>
</span><span id="line-3"></span><span class="hs-pragma">{-# LANGUAGE GADTs #-}</span><span>
</span><span id="line-4"></span><span class="hs-pragma">{-# LANGUAGE PartialTypeSignatures #-}</span><span>
</span><span id="line-5"></span><span class="hs-pragma">{-# LANGUAGE PatternSynonyms #-}</span><span>
</span><span id="line-6"></span><span class="hs-pragma">{-# LANGUAGE RankNTypes #-}</span><span>
</span><span id="line-7"></span><span class="hs-pragma">{-# LANGUAGE RecordWildCards #-}</span><span>
</span><span id="line-8"></span><span class="hs-pragma">{-# LANGUAGE ScopedTypeVariables #-}</span><span>
</span><span id="line-9"></span><span class="hs-pragma">{-# LANGUAGE TypeApplications #-}</span><span>
</span><span id="line-10"></span><span class="hs-pragma">{-# LANGUAGE TypeFamilies #-}</span><span>
</span><span id="line-11"></span><span class="hs-pragma">{-# LANGUAGE TypeOperators #-}</span><span>
</span><span id="line-12"></span><span>
</span><span id="line-13"></span><span class="hs-keyword">module</span><span> </span><span class="hs-identifier">Torch.GraduallyTyped.NN.Transformer.Generation</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-14"></span><span>
</span><span id="line-15"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/7r27dwy4364cr2x5zc70hzfhbqlgyrxp-lens-lib-lens-5.0.1-haddock-doc/share/doc/lens/html/src"><span class="hs-identifier">Control.Lens</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/7r27dwy4364cr2x5zc70hzfhbqlgyrxp-lens-lib-lens-5.0.1-haddock-doc/share/doc/lens/html/src"><span class="hs-identifier">Lens</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-16"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">Control.Monad.Catch</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier">MonadThrow</span></span><span class="hs-special">)</span><span>
</span><span id="line-17"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">Control.Monad.State</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier">MonadState</span></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-18"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">Data.Function</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier">fix</span></span><span class="hs-special">)</span><span>
</span><span id="line-19"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">Foreign.ForeignPtr</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier">ForeignPtr</span></span><span class="hs-special">)</span><span>
</span><span id="line-20"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html"><span class="hs-identifier">Torch.GraduallyTyped.DType</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier">DType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier">DataType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-21"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Index.Type.html"><span class="hs-identifier">Torch.GraduallyTyped.Index.Type</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Index.Type.html#Index"><span class="hs-identifier">Index</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Index.Type.html#NegativeIndex"><span class="hs-identifier">NegativeIndex</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Index.Type.html#SIndex"><span class="hs-identifier">SIndex</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-22"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderDecoder.html"><span class="hs-identifier">Torch.GraduallyTyped.NN.Transformer.GEncoderDecoder</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderDecoder.html#SimplifiedEncoderDecoderTransformerGenerationInput"><span class="hs-identifier">SimplifiedEncoderDecoderTransformerGenerationInput</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderDecoder.html#SimplifiedEncoderDecoderTransformerOutput"><span class="hs-identifier">SimplifiedEncoderDecoderTransformerOutput</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-23"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html"><span class="hs-identifier">Torch.GraduallyTyped.Prelude</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Catch"><span class="hs-identifier">Catch</span></a></span><span class="hs-special">,</span><span> </span><span class="hs-keyword">pattern</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#%3A%7C%3A"><span class="hs-operator">(:|:)</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-24"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.List.html"><span class="hs-identifier">Torch.GraduallyTyped.Prelude.List</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/5fimh704vh0dpf8xfhffyiz4vcnc02i2-singletons-base-lib-singletons-base-3.0-haddock-doc/share/doc/singletons-base/html/src"><span class="hs-identifier">SList</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/5fimh704vh0dpf8xfhffyiz4vcnc02i2-singletons-base-lib-singletons-base-3.0-haddock-doc/share/doc/singletons-base/html/src"><span class="hs-identifier">SNil</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-25"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html"><span class="hs-identifier">Torch.GraduallyTyped.RequiresGradient</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier">Gradient</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#RequiresGradient"><span class="hs-identifier">RequiresGradient</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier">SGradient</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#SRequiresGradient"><span class="hs-identifier">SRequiresGradient</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-26"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html"><span class="hs-identifier">Torch.GraduallyTyped.Shape.Class</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#BroadcastShapesF"><span class="hs-identifier">BroadcastShapesF</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-27"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html"><span class="hs-identifier">Torch.GraduallyTyped.Shape.Type</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#By"><span class="hs-identifier">By</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SBy"><span class="hs-identifier">SBy</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SSelectDim"><span class="hs-identifier">SSelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier">Shape</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-28"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Indexing.html"><span class="hs-identifier">Torch.GraduallyTyped.Tensor.Indexing</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Indexing.html#IndexDims"><span class="hs-identifier">IndexDims</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Indexing.html#IndexType"><span class="hs-identifier">IndexType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Indexing.html#Indices"><span class="hs-identifier">Indices</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Indexing.html#SIndexType"><span class="hs-identifier">SIndexType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Indexing.html#SIndices"><span class="hs-identifier">SIndices</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Indexing.html#%21"><span class="hs-operator">(!)</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-29"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html"><span class="hs-identifier">Torch.GraduallyTyped.Tensor.IndexingSlicingJoining</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#CatHListF"><span class="hs-identifier">CatHListF</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#HasCat"><span class="hs-identifier">HasCat</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#SqueezeDimF"><span class="hs-identifier">SqueezeDimF</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#UnsqueezeF"><span class="hs-identifier">UnsqueezeF</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#sSqueezeDim"><span class="hs-identifier">sSqueezeDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#sUnsqueeze"><span class="hs-identifier">sUnsqueeze</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-30"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Comparison.html"><span class="hs-identifier">Torch.GraduallyTyped.Tensor.MathOperations.Comparison</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Comparison.html#%2F%3D."><span class="hs-operator">(/=.)</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Comparison.html#%3D%3D."><span class="hs-operator">(==.)</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-31"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html"><span class="hs-identifier">Torch.GraduallyTyped.Tensor.MathOperations.Pointwise</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#mul"><span class="hs-identifier">mul</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#mulScalar"><span class="hs-identifier">mulScalar</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#sub"><span class="hs-identifier">sub</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#subScalar"><span class="hs-identifier">subScalar</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-32"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Reduction.html"><span class="hs-identifier">Torch.GraduallyTyped.Tensor.MathOperations.Reduction</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Reduction.html#ArgmaxF"><span class="hs-identifier">ArgmaxF</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Reduction.html#MaxAllCheckF"><span class="hs-identifier">MaxAllCheckF</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Reduction.html#argmax"><span class="hs-identifier">argmax</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Reduction.html#maxAll"><span class="hs-identifier">maxAll</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-33"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html"><span class="hs-identifier">Torch.GraduallyTyped.Tensor.Type</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetDataType"><span class="hs-identifier">SGetDataType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetDevice"><span class="hs-identifier">SGetDevice</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetDim"><span class="hs-identifier">SGetDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetLayout"><span class="hs-identifier">SGetLayout</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetShape"><span class="hs-identifier">SGetShape</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier">Tensor</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorLike"><span class="hs-identifier">TensorLike</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#sCheckedShape"><span class="hs-identifier">sCheckedShape</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#sSetDataType"><span class="hs-identifier">sSetDataType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-34"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html"><span class="hs-identifier">Torch.GraduallyTyped.Unify</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-keyword">type</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator">(&lt;+&gt;)</span></a></span><span class="hs-special">,</span><span> </span><span class="hs-keyword">type</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator">(&lt;|&gt;)</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-35"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../../../../hasktorch/html/src"><span class="hs-identifier">Torch.HList</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../../../../hasktorch/html/src"><span class="hs-identifier">HList</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../../../../hasktorch/html/src"><span class="hs-identifier">HNil</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="hs-keyword">pattern</span><span> </span><span class="annot"><a href="../../../../hasktorch/html/src"><span class="hs-operator">(:.)</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-36"></span><span class="hs-keyword">import</span><span> </span><span class="hs-keyword">qualified</span><span> </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier">Torch.Internal.Class</span></a></span><span> </span><span class="hs-keyword">as</span><span> </span><span class="annot"><span class="hs-identifier">ATen</span></span><span>
</span><span id="line-37"></span><span class="hs-keyword">import</span><span> </span><span class="hs-keyword">qualified</span><span> </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier">Torch.Internal.Type</span></a></span><span> </span><span class="hs-keyword">as</span><span> </span><span class="annot"><span class="hs-identifier">ATen</span></span><span>
</span><span id="line-38"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">Prelude</span></span><span> </span><span class="hs-keyword">hiding</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier">all</span></span><span class="hs-special">)</span><span>
</span><span id="line-39"></span><span>
</span><span id="line-40"></span><span id="local-6989586621679728613"><span id="local-6989586621679728614"><span id="local-6989586621679728615"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Generation.html#decode"><span class="hs-identifier hs-type">decode</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-41"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">Monad</span></span><span> </span><span class="annot"><a href="#local-6989586621679728615"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-42"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679728614"><span class="hs-identifier hs-type">x</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="#local-6989586621679728613"><span class="hs-identifier hs-type">s</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="#local-6989586621679728615"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">Maybe</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679728614"><span class="hs-identifier hs-type">x</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679728613"><span class="hs-identifier hs-type">s</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-43"></span><span>  </span><span class="annot"><a href="#local-6989586621679728614"><span class="hs-identifier hs-type">x</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-44"></span><span>  </span><span class="annot"><a href="#local-6989586621679728613"><span class="hs-identifier hs-type">s</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-45"></span><span>  </span><span class="annot"><a href="#local-6989586621679728615"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679728614"><span class="hs-identifier hs-type">x</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679728613"><span class="hs-identifier hs-type">s</span></a></span><span class="hs-special">)</span></span></span></span><span>
</span><span id="line-46"></span><span id="decode"><span class="annot"><span class="annottext">decode :: forall (m :: * -&gt; *) x s.
Monad m =&gt;
(x -&gt; s -&gt; m (Maybe (x, s))) -&gt; x -&gt; s -&gt; m (x, s)
</span><a href="Torch.GraduallyTyped.NN.Transformer.Generation.html#decode"><span class="hs-identifier hs-var hs-var">decode</span></a></span></span><span> </span><span id="local-6989586621679728193"><span class="annot"><span class="annottext">x -&gt; s -&gt; m (Maybe (x, s))
</span><a href="#local-6989586621679728193"><span class="hs-identifier hs-var">f</span></a></span></span><span> </span><span id="local-6989586621679728192"><span class="annot"><span class="annottext">x
</span><a href="#local-6989586621679728192"><span class="hs-identifier hs-var">x</span></a></span></span><span> </span><span id="local-6989586621679728191"><span class="annot"><span class="annottext">s
</span><a href="#local-6989586621679728191"><span class="hs-identifier hs-var">s</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-47"></span><span>  </span><span class="annot"><span class="annottext">((((x, s) -&gt; m (x, s)) -&gt; (x, s) -&gt; m (x, s))
 -&gt; (x, s) -&gt; m (x, s))
-&gt; (x, s)
-&gt; (((x, s) -&gt; m (x, s)) -&gt; (x, s) -&gt; m (x, s))
-&gt; m (x, s)
forall a b c. (a -&gt; b -&gt; c) -&gt; b -&gt; a -&gt; c
</span><span class="hs-identifier hs-var">flip</span></span><span> </span><span class="annot"><span class="annottext">(((x, s) -&gt; m (x, s)) -&gt; (x, s) -&gt; m (x, s)) -&gt; (x, s) -&gt; m (x, s)
forall a. (a -&gt; a) -&gt; a
</span><span class="hs-identifier hs-var">fix</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">x
</span><a href="#local-6989586621679728192"><span class="hs-identifier hs-var">x</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">s
</span><a href="#local-6989586621679728191"><span class="hs-identifier hs-var">s</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">((((x, s) -&gt; m (x, s)) -&gt; (x, s) -&gt; m (x, s)) -&gt; m (x, s))
-&gt; (((x, s) -&gt; m (x, s)) -&gt; (x, s) -&gt; m (x, s)) -&gt; m (x, s)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-glyph">\</span><span id="local-6989586621679728189"><span class="annot"><span class="annottext">(x, s) -&gt; m (x, s)
</span><a href="#local-6989586621679728189"><span class="hs-identifier hs-var">loop</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679728188"><span class="annot"><span class="annottext">x
</span><a href="#local-6989586621679728188"><span class="hs-identifier hs-var">x'</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679728187"><span class="annot"><span class="annottext">s
</span><a href="#local-6989586621679728187"><span class="hs-identifier hs-var">s'</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-48"></span><span>    </span><span id="local-6989586621679728186"><span class="annot"><span class="annottext">Maybe (x, s)
</span><a href="#local-6989586621679728186"><span class="hs-identifier hs-var">r</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">x -&gt; s -&gt; m (Maybe (x, s))
</span><a href="#local-6989586621679728193"><span class="hs-identifier hs-var">f</span></a></span><span> </span><span class="annot"><span class="annottext">x
</span><a href="#local-6989586621679728188"><span class="hs-identifier hs-var">x'</span></a></span><span> </span><span class="annot"><span class="annottext">s
</span><a href="#local-6989586621679728187"><span class="hs-identifier hs-var">s'</span></a></span><span>
</span><span id="line-49"></span><span>    </span><span class="hs-keyword">case</span><span> </span><span class="annot"><span class="annottext">Maybe (x, s)
</span><a href="#local-6989586621679728186"><span class="hs-identifier hs-var">r</span></a></span><span> </span><span class="hs-keyword">of</span><span>
</span><span id="line-50"></span><span>      </span><span class="annot"><span class="annottext">Maybe (x, s)
</span><span class="hs-identifier hs-var">Nothing</span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">(x, s) -&gt; m (x, s)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">x
</span><a href="#local-6989586621679728188"><span class="hs-identifier hs-var">x'</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">s
</span><a href="#local-6989586621679728187"><span class="hs-identifier hs-var">s'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-51"></span><span>      </span><span class="annot"><span class="hs-identifier hs-type">Just</span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679728185"><span class="annot"><span class="annottext">x
</span><a href="#local-6989586621679728185"><span class="hs-identifier hs-var">x''</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679728184"><span class="annot"><span class="annottext">s
</span><a href="#local-6989586621679728184"><span class="hs-identifier hs-var">s''</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">(x, s) -&gt; m (x, s)
</span><a href="#local-6989586621679728189"><span class="hs-identifier hs-var">loop</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">x
</span><a href="#local-6989586621679728185"><span class="hs-identifier hs-var">x''</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">s
</span><a href="#local-6989586621679728184"><span class="hs-identifier hs-var">s''</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-52"></span><span>
</span><span id="line-53"></span><span id="local-6989586621679728593"><span id="local-6989586621679728595"><span id="local-6989586621679728596"><span id="local-6989586621679728597"><span id="local-6989586621679728598"><span id="local-6989586621679728599"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Generation.html#sedtOutputToInput"><span class="hs-identifier hs-type">sedtOutputToInput</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-54"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">Monad</span></span><span> </span><span class="annot"><a href="#local-6989586621679728599"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-55"></span><span>  </span><span class="annot"><a href="../file:///nix/store/7r27dwy4364cr2x5zc70hzfhbqlgyrxp-lens-lib-lens-5.0.1-haddock-doc/share/doc/lens/html/src"><span class="hs-identifier hs-type">Lens</span></a></span><span>
</span><span id="line-56"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderDecoder.html#SimplifiedEncoderDecoderTransformerOutput"><span class="hs-identifier hs-type">SimplifiedEncoderDecoderTransformerOutput</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728598"><span class="hs-identifier hs-type">logits</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728597"><span class="hs-identifier hs-type">encoderOutput</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728596"><span class="hs-identifier hs-type">decoderInput</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728595"><span class="hs-identifier hs-type">inputPaddingMask</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-57"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679728599"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderDecoder.html#SimplifiedEncoderDecoderTransformerGenerationInput"><span class="hs-identifier hs-type">SimplifiedEncoderDecoderTransformerGenerationInput</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728593"><span class="hs-identifier hs-type">decoderInput'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728597"><span class="hs-identifier hs-type">encoderOutput</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728595"><span class="hs-identifier hs-type">inputPaddingMask</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-58"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679728598"><span class="hs-identifier hs-type">logits</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679728596"><span class="hs-identifier hs-type">decoderInput</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-59"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679728599"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728593"><span class="hs-identifier hs-type">decoderInput'</span></a></span><span class="hs-special">)</span></span></span></span></span></span></span><span>
</span><span id="line-60"></span><span id="sedtOutputToInput"><span class="annot"><span class="annottext">sedtOutputToInput :: forall (m :: * -&gt; *) logits encoderOutput decoderInput
       inputPaddingMask decoderInput'.
Monad m =&gt;
Lens
  (SimplifiedEncoderDecoderTransformerOutput
     logits encoderOutput decoderInput inputPaddingMask)
  (m (SimplifiedEncoderDecoderTransformerGenerationInput
        decoderInput' encoderOutput inputPaddingMask))
  (logits, decoderInput)
  (m decoderInput')
</span><a href="Torch.GraduallyTyped.NN.Transformer.Generation.html#sedtOutputToInput"><span class="hs-identifier hs-var hs-var">sedtOutputToInput</span></a></span></span><span> </span><span id="local-6989586621679728171"><span class="annot"><span class="annottext">(logits, decoderInput) -&gt; f (m decoderInput')
</span><a href="#local-6989586621679728171"><span class="hs-identifier hs-var">f</span></a></span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderDecoder.html#SimplifiedEncoderDecoderTransformerOutput"><span class="hs-identifier hs-type">SimplifiedEncoderDecoderTransformerOutput</span></a></span><span> </span><span class="hs-special">{</span><span id="local-6989586621679728166"><span id="local-6989586621679728167"><span id="local-6989586621679728168"><span id="local-6989586621679728169"><span class="annot"><span class="annottext">logits
encoderOutput
decoderInput
inputPaddingMask
sedtInputPaddingMask :: forall decoderOutput encoderOutput decoderInput inputPaddingMask.
SimplifiedEncoderDecoderTransformerOutput
  decoderOutput encoderOutput decoderInput inputPaddingMask
-&gt; inputPaddingMask
sedtOriginalDecoderInput :: forall decoderOutput encoderOutput decoderInput inputPaddingMask.
SimplifiedEncoderDecoderTransformerOutput
  decoderOutput encoderOutput decoderInput inputPaddingMask
-&gt; decoderInput
sedtEncoderOutput :: forall decoderOutput encoderOutput decoderInput inputPaddingMask.
SimplifiedEncoderDecoderTransformerOutput
  decoderOutput encoderOutput decoderInput inputPaddingMask
-&gt; encoderOutput
sedtDecoderOutput :: forall decoderOutput encoderOutput decoderInput inputPaddingMask.
SimplifiedEncoderDecoderTransformerOutput
  decoderOutput encoderOutput decoderInput inputPaddingMask
-&gt; decoderOutput
sedtInputPaddingMask :: inputPaddingMask
sedtOriginalDecoderInput :: decoderInput
sedtEncoderOutput :: encoderOutput
sedtDecoderOutput :: logits
</span><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderDecoder.html#sedtInputPaddingMask"><span class="hs-glyph hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">..</span></a></span></span></span></span></span><span class="hs-special">}</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-61"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="hs-glyph">\</span><span id="local-6989586621679728161"><span class="annot"><span class="annottext">m decoderInput'
</span><a href="#local-6989586621679728161"><span class="hs-identifier hs-var">decoderInput'</span></a></span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-62"></span><span>      </span><span class="annot"><span class="annottext">decoderInput'
-&gt; encoderOutput
-&gt; inputPaddingMask
-&gt; SimplifiedEncoderDecoderTransformerGenerationInput
     decoderInput' encoderOutput inputPaddingMask
forall decoderInput encoderOutput inputPaddingMask.
decoderInput
-&gt; encoderOutput
-&gt; inputPaddingMask
-&gt; SimplifiedEncoderDecoderTransformerGenerationInput
     decoderInput encoderOutput inputPaddingMask
</span><a href="Torch.GraduallyTyped.NN.Transformer.GEncoderDecoder.html#SimplifiedEncoderDecoderTransformerGenerationInput"><span class="hs-identifier hs-var">SimplifiedEncoderDecoderTransformerGenerationInput</span></a></span><span>
</span><span id="line-63"></span><span>        </span><span class="annot"><span class="annottext">(decoderInput'
 -&gt; encoderOutput
 -&gt; inputPaddingMask
 -&gt; SimplifiedEncoderDecoderTransformerGenerationInput
      decoderInput' encoderOutput inputPaddingMask)
-&gt; m decoderInput'
-&gt; m (encoderOutput
      -&gt; inputPaddingMask
      -&gt; SimplifiedEncoderDecoderTransformerGenerationInput
           decoderInput' encoderOutput inputPaddingMask)
forall (f :: * -&gt; *) a b. Functor f =&gt; (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;$&gt;</span></span><span> </span><span class="annot"><span class="annottext">m decoderInput'
</span><a href="#local-6989586621679728161"><span class="hs-identifier hs-var">decoderInput'</span></a></span><span> </span><span class="annot"><span class="annottext">m (encoderOutput
   -&gt; inputPaddingMask
   -&gt; SimplifiedEncoderDecoderTransformerGenerationInput
        decoderInput' encoderOutput inputPaddingMask)
-&gt; m encoderOutput
-&gt; m (inputPaddingMask
      -&gt; SimplifiedEncoderDecoderTransformerGenerationInput
           decoderInput' encoderOutput inputPaddingMask)
forall (f :: * -&gt; *) a b. Applicative f =&gt; f (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;*&gt;</span></span><span> </span><span class="annot"><span class="annottext">encoderOutput -&gt; m encoderOutput
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">encoderOutput
</span><a href="#local-6989586621679728168"><span class="hs-identifier hs-var">sedtEncoderOutput</span></a></span><span> </span><span class="annot"><span class="annottext">m (inputPaddingMask
   -&gt; SimplifiedEncoderDecoderTransformerGenerationInput
        decoderInput' encoderOutput inputPaddingMask)
-&gt; m inputPaddingMask
-&gt; m (SimplifiedEncoderDecoderTransformerGenerationInput
        decoderInput' encoderOutput inputPaddingMask)
forall (f :: * -&gt; *) a b. Applicative f =&gt; f (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;*&gt;</span></span><span> </span><span class="annot"><span class="annottext">inputPaddingMask -&gt; m inputPaddingMask
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">inputPaddingMask
</span><a href="#local-6989586621679728166"><span class="hs-identifier hs-var">sedtInputPaddingMask</span></a></span><span>
</span><span id="line-64"></span><span>  </span><span class="hs-special">)</span><span>
</span><span id="line-65"></span><span>    </span><span class="annot"><span class="annottext">(m decoderInput'
 -&gt; m (SimplifiedEncoderDecoderTransformerGenerationInput
         decoderInput' encoderOutput inputPaddingMask))
-&gt; f (m decoderInput')
-&gt; f (m (SimplifiedEncoderDecoderTransformerGenerationInput
           decoderInput' encoderOutput inputPaddingMask))
forall (f :: * -&gt; *) a b. Functor f =&gt; (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;$&gt;</span></span><span> </span><span class="annot"><span class="annottext">(logits, decoderInput) -&gt; f (m decoderInput')
</span><a href="#local-6989586621679728171"><span class="hs-identifier hs-var">f</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">logits
</span><a href="#local-6989586621679728169"><span class="hs-identifier hs-var">sedtDecoderOutput</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">decoderInput
</span><a href="#local-6989586621679728167"><span class="hs-identifier hs-var">sedtOriginalDecoderInput</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-66"></span><span>
</span><span id="line-67"></span><span id="local-6989586621679728532"><span id="local-6989586621679728539"><span id="local-6989586621679728540"><span id="local-6989586621679728541"><span id="local-6989586621679728542"><span id="local-6989586621679728543"><span id="local-6989586621679728544"><span id="local-6989586621679728545"><span id="local-6989586621679728548"><span id="local-6989586621679728552"><span id="local-6989586621679728554"><span id="local-6989586621679728555"><span id="local-6989586621679728556"><span id="local-6989586621679728557"><span id="local-6989586621679728558"><span id="local-6989586621679728559"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Generation.html#prepNext"><span class="hs-identifier hs-type">prepNext</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-68"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="#local-6989586621679728559"><span class="hs-identifier hs-type">logits</span></a></span><span> </span><span class="annot"><span class="hs-operator hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728558"><span class="hs-identifier hs-type">logitsGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728557"><span class="hs-identifier hs-type">logitsLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728556"><span class="hs-identifier hs-type">logitsDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728555"><span class="hs-identifier hs-type">logitsDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728554"><span class="hs-identifier hs-type">logitsShape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-69"></span><span>    </span><span class="annot"><a href="#local-6989586621679728552"><span class="hs-identifier hs-type">ntShape'</span></a></span><span> </span><span class="annot"><span class="hs-operator hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#UnsqueezeF"><span class="hs-identifier hs-type">UnsqueezeF</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679728548"><span class="hs-identifier hs-type">ntShape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-70"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Catch"><span class="hs-identifier hs-type">Catch</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728552"><span class="hs-identifier hs-type">ntShape'</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-71"></span><span>    </span><span class="annot"><a href="#local-6989586621679728545"><span class="hs-identifier hs-type">tensors</span></a></span><span> </span><span class="annot"><span class="hs-operator hs-type">~</span></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679728544"><span class="hs-identifier hs-type">decoderInput</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728543"><span class="hs-identifier hs-type">ntGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728542"><span class="hs-identifier hs-type">ntLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728541"><span class="hs-identifier hs-type">ntDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728540"><span class="hs-identifier hs-type">ntDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728552"><span class="hs-identifier hs-type">ntShape'</span></a></span><span class="hs-special">]</span><span class="hs-special">,</span><span>
</span><span id="line-72"></span><span>    </span><span class="annot"><a href="#local-6989586621679728539"><span class="hs-identifier hs-type">decoderInput'</span></a></span><span> </span><span class="annot"><span class="hs-operator hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#CatHListF"><span class="hs-identifier hs-type">CatHListF</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679728545"><span class="hs-identifier hs-type">tensors</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-73"></span><span>    </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-type">ATen.Castable</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728539"><span class="hs-identifier hs-type">decoderInput'</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">ForeignPtr</span></span><span> </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-type">ATen.Tensor</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-74"></span><span>    </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-type">ATen.Castable</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../../../../hasktorch/html/src"><span class="hs-identifier hs-type">HList</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728545"><span class="hs-identifier hs-type">tensors</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">ForeignPtr</span></span><span> </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-type">ATen.TensorList</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-75"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">MonadThrow</span></span><span> </span><span class="annot"><a href="#local-6989586621679728532"><span class="hs-identifier hs-type">m</span></a></span><span>
</span><span id="line-76"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-77"></span><span>  </span><span class="annot"><a href="../file:///nix/store/7r27dwy4364cr2x5zc70hzfhbqlgyrxp-lens-lib-lens-5.0.1-haddock-doc/share/doc/lens/html/src"><span class="hs-identifier hs-type">Lens</span></a></span><span>
</span><span id="line-78"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679728559"><span class="hs-identifier hs-type">logits</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679728544"><span class="hs-identifier hs-type">decoderInput</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-79"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679728532"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728539"><span class="hs-identifier hs-type">decoderInput'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-80"></span><span>    </span><span class="annot"><a href="#local-6989586621679728559"><span class="hs-identifier hs-type">logits</span></a></span><span>
</span><span id="line-81"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679728532"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728543"><span class="hs-identifier hs-type">ntGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728542"><span class="hs-identifier hs-type">ntLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728541"><span class="hs-identifier hs-type">ntDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728540"><span class="hs-identifier hs-type">ntDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728548"><span class="hs-identifier hs-type">ntShape</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span>
</span><span id="line-82"></span><span id="prepNext"><span class="annot"><span class="annottext">prepNext :: forall logits (logitsGradient :: Gradient RequiresGradient)
       (logitsLayout :: Layout LayoutType)
       (logitsDevice :: Device (DeviceType Nat))
       (logitsDataType :: DataType DType)
       (logitsShape :: Shape [Dim (Name Symbol) (Size Nat)])
       (ntShape' :: Shape [Dim (Name Symbol) (Size Nat)])
       (ntShape :: Shape [Dim (Name Symbol) (Size Nat)]) (tensors :: [*])
       decoderInput (ntGradient :: Gradient RequiresGradient)
       (ntLayout :: Layout LayoutType)
       (ntDevice :: Device (DeviceType Nat))
       (ntDataType :: DataType DType) decoderInput' (m :: * -&gt; *).
(logits
 ~ Tensor
     logitsGradient
     logitsLayout
     logitsDevice
     logitsDataType
     logitsShape,
 ntShape' ~ UnsqueezeF ('SelectDim ('ByIndex 1)) ntShape,
 Catch ntShape',
 tensors
 ~ '[decoderInput,
     Tensor ntGradient ntLayout ntDevice ntDataType ntShape'],
 decoderInput' ~ CatHListF ('SelectDim ('ByIndex 1)) tensors,
 Castable decoderInput' (ForeignPtr Tensor),
 Castable (HList tensors) (ForeignPtr TensorList), MonadThrow m) =&gt;
Lens
  (logits, decoderInput)
  (m decoderInput')
  logits
  (m (Tensor ntGradient ntLayout ntDevice ntDataType ntShape))
</span><a href="Torch.GraduallyTyped.NN.Transformer.Generation.html#prepNext"><span class="hs-identifier hs-var hs-var">prepNext</span></a></span></span><span> </span><span id="local-6989586621679728122"><span class="annot"><span class="annottext">logits
-&gt; f (m (Tensor ntGradient ntLayout ntDevice ntDataType ntShape))
</span><a href="#local-6989586621679728122"><span class="hs-identifier hs-var">f</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679728121"><span class="annot"><span class="annottext">logits
</span><a href="#local-6989586621679728121"><span class="hs-identifier hs-var">logits</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679728120"><span class="annot"><span class="annottext">decoderInput
</span><a href="#local-6989586621679728120"><span class="hs-identifier hs-var">decoderInput</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-83"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="hs-glyph">\</span><span id="local-6989586621679728119"><span class="annot"><span class="annottext">m (Tensor ntGradient ntLayout ntDevice ntDataType ntShape)
</span><a href="#local-6989586621679728119"><span class="hs-identifier hs-var">nextTokens</span></a></span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-84"></span><span>      </span><span id="local-6989586621679728118"><span class="annot"><span class="annottext">Tensor ntGradient ntLayout ntDevice ntDataType ntShape
</span><a href="#local-6989586621679728118"><span class="hs-identifier hs-var">nextTokens'</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">m (Tensor ntGradient ntLayout ntDevice ntDataType ntShape)
</span><a href="#local-6989586621679728119"><span class="hs-identifier hs-var">nextTokens</span></a></span><span>
</span><span id="line-85"></span><span>      </span><span id="local-6989586621679728117"><span class="annot"><span class="annottext">Tensor ntGradient ntLayout ntDevice ntDataType ntShape'
</span><a href="#local-6989586621679728117"><span class="hs-identifier hs-var">nextTokens''</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">SSelectDim ('SelectDim ('ByIndex 1))
-&gt; Tensor ntGradient ntLayout ntDevice ntDataType ntShape
-&gt; m (Tensor ntGradient ntLayout ntDevice ntDataType ntShape')
forall (selectDim :: SelectDim (By Symbol Nat))
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]) (m :: * -&gt; *).
(shape' ~ UnsqueezeF selectDim shape, Catch shape',
 MonadThrow m) =&gt;
SSelectDim selectDim
-&gt; Tensor gradient layout device dataType shape
-&gt; m (Tensor gradient layout device dataType shape')
</span><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#sUnsqueeze"><span class="hs-identifier hs-var">sUnsqueeze</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SBy ('ByIndex 1) -&gt; SSelectDim ('SelectDim ('ByIndex 1))
forall (requiresGradient :: By Symbol Nat).
SBy requiresGradient -&gt; SSelectDim ('SelectDim requiresGradient)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSelectDim"><span class="hs-identifier hs-var">SSelectDim</span></a></span><span> </span><span class="annot"><span class="annottext">(SBy ('ByIndex 1) -&gt; SSelectDim ('SelectDim ('ByIndex 1)))
-&gt; SBy ('ByIndex 1) -&gt; SSelectDim ('SelectDim ('ByIndex 1))
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">forall (requiresGradient :: Nat).
KnownNat requiresGradient =&gt;
SBy ('ByIndex requiresGradient)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SByIndex"><span class="hs-identifier hs-var">SByIndex</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor ntGradient ntLayout ntDevice ntDataType ntShape
</span><a href="#local-6989586621679728118"><span class="hs-identifier hs-var">nextTokens'</span></a></span><span>
</span><span id="line-86"></span><span>      </span><span class="annot"><span class="annottext">SSelectDim ('SelectDim ('ByIndex 1))
-&gt; HList
     '[decoderInput,
       Tensor ntGradient ntLayout ntDevice ntDataType ntShape']
-&gt; m (CatF
        ('SelectDim ('ByIndex 1))
        '[decoderInput,
          Tensor ntGradient ntLayout ntDevice ntDataType ntShape']
        HList)
forall (selectDim :: SelectDim (By Symbol Nat)) k (c :: k -&gt; *)
       (a :: k) (m :: * -&gt; *).
(HasCat selectDim k c a, MonadThrow m) =&gt;
SSelectDim selectDim -&gt; c a -&gt; m (CatF selectDim a c)
</span><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#sCat"><span class="hs-identifier hs-var">sCat</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SBy ('ByIndex 1) -&gt; SSelectDim ('SelectDim ('ByIndex 1))
forall (requiresGradient :: By Symbol Nat).
SBy requiresGradient -&gt; SSelectDim ('SelectDim requiresGradient)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSelectDim"><span class="hs-identifier hs-var">SSelectDim</span></a></span><span> </span><span class="annot"><span class="annottext">(SBy ('ByIndex 1) -&gt; SSelectDim ('SelectDim ('ByIndex 1)))
-&gt; SBy ('ByIndex 1) -&gt; SSelectDim ('SelectDim ('ByIndex 1))
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">forall (requiresGradient :: Nat).
KnownNat requiresGradient =&gt;
SBy ('ByIndex requiresGradient)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SByIndex"><span class="hs-identifier hs-var">SByIndex</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">decoderInput
</span><a href="#local-6989586621679728120"><span class="hs-identifier hs-var">decoderInput</span></a></span><span> </span><span class="annot"><span class="annottext">decoderInput
-&gt; HList '[Tensor ntGradient ntLayout ntDevice ntDataType ntShape']
-&gt; HList
     '[decoderInput,
       Tensor ntGradient ntLayout ntDevice ntDataType ntShape']
forall x (xs :: [*]). x -&gt; HList xs -&gt; HList (x : xs)
</span><a href="../../../../hasktorch/html/src"><span class="hs-operator hs-var">:.</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor ntGradient ntLayout ntDevice ntDataType ntShape'
</span><a href="#local-6989586621679728117"><span class="hs-identifier hs-var">nextTokens''</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor ntGradient ntLayout ntDevice ntDataType ntShape'
-&gt; HList '[]
-&gt; HList '[Tensor ntGradient ntLayout ntDevice ntDataType ntShape']
forall x (xs :: [*]). x -&gt; HList xs -&gt; HList (x : xs)
</span><a href="../../../../hasktorch/html/src"><span class="hs-operator hs-var">:.</span></a></span><span> </span><span class="annot"><span class="annottext">HList '[]
forall k. HList '[]
</span><a href="../../../../hasktorch/html/src"><span class="hs-identifier hs-var">HNil</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-87"></span><span>  </span><span class="hs-special">)</span><span>
</span><span id="line-88"></span><span>    </span><span class="annot"><span class="annottext">(m (Tensor ntGradient ntLayout ntDevice ntDataType ntShape)
 -&gt; m decoderInput')
-&gt; f (m (Tensor ntGradient ntLayout ntDevice ntDataType ntShape))
-&gt; f (m decoderInput')
forall (f :: * -&gt; *) a b. Functor f =&gt; (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;$&gt;</span></span><span> </span><span class="annot"><span class="annottext">logits
-&gt; f (m (Tensor ntGradient ntLayout ntDevice ntDataType ntShape))
</span><a href="#local-6989586621679728122"><span class="hs-identifier hs-var">f</span></a></span><span> </span><span class="annot"><span class="annottext">logits
</span><a href="#local-6989586621679728121"><span class="hs-identifier hs-var">logits</span></a></span><span>
</span><span id="line-89"></span><span>
</span><span id="line-90"></span><span id="local-6989586621679728457"><span id="local-6989586621679728458"><span id="local-6989586621679728464"><span id="local-6989586621679728465"><span id="local-6989586621679728468"><span id="local-6989586621679728473"><span id="local-6989586621679728474"><span id="local-6989586621679728476"><span id="local-6989586621679728478"><span id="local-6989586621679728480"><span id="local-6989586621679728487"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Generation.html#greedyNextTokens"><span class="hs-identifier hs-type">greedyNextTokens</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-91"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="#local-6989586621679728487"><span class="hs-identifier hs-type">nextTokenLogitsShape</span></a></span><span> </span><span class="annot"><span class="hs-operator hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Indexing.html#IndexDims"><span class="hs-identifier hs-type">IndexDims</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Indexing.html#Indices"><span class="hs-identifier hs-type">Indices</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Indexing.html#SliceAll"><span class="hs-identifier hs-type">SliceAll</span></a></span><span class="hs-special">,</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Indexing.html#SliceAt"><span class="hs-identifier hs-type">SliceAt</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Index.Type.html#NegativeIndex"><span class="hs-identifier hs-type">NegativeIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Indexing.html#SliceAll"><span class="hs-identifier hs-type">SliceAll</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679728480"><span class="hs-identifier hs-type">logitsShape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-92"></span><span>    </span><span class="annot"><a href="#local-6989586621679728478"><span class="hs-identifier hs-type">nextTokensShape</span></a></span><span> </span><span class="annot"><span class="hs-operator hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Reduction.html#ArgmaxF"><span class="hs-identifier hs-type">ArgmaxF</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679728487"><span class="hs-identifier hs-type">nextTokenLogitsShape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-93"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Catch"><span class="hs-identifier hs-type">Catch</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728478"><span class="hs-identifier hs-type">nextTokensShape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-94"></span><span>    </span><span class="annot"><a href="#local-6989586621679728476"><span class="hs-identifier hs-type">nextTokensShape'</span></a></span><span> </span><span class="annot"><span class="hs-operator hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#SqueezeDimF"><span class="hs-identifier hs-type">SqueezeDimF</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679728478"><span class="hs-identifier hs-type">nextTokensShape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-95"></span><span>    </span><span class="annot"><a href="#local-6989586621679728474"><span class="hs-identifier hs-type">ntShape</span></a></span><span> </span><span class="annot"><span class="hs-operator hs-type">~</span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679728473"><span class="hs-identifier hs-type">ntDim</span></a></span><span class="hs-special">]</span><span class="hs-special">,</span><span>
</span><span id="line-96"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Catch"><span class="hs-identifier hs-type">Catch</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679728476"><span class="hs-identifier hs-type">nextTokensShape'</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728474"><span class="hs-identifier hs-type">ntShape</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-97"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetShape"><span class="hs-identifier hs-type">SGetShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728476"><span class="hs-identifier hs-type">nextTokensShape'</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-98"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetDim"><span class="hs-identifier hs-type">SGetDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728473"><span class="hs-identifier hs-type">ntDim</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-99"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Catch"><span class="hs-identifier hs-type">Catch</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728473"><span class="hs-identifier hs-type">ntDim</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-100"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Catch"><span class="hs-identifier hs-type">Catch</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728476"><span class="hs-identifier hs-type">nextTokensShape'</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-101"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">MonadThrow</span></span><span> </span><span class="annot"><a href="#local-6989586621679728468"><span class="hs-identifier hs-type">m</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-102"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">MonadState</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#WithoutGradient"><span class="hs-identifier hs-type">WithoutGradient</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679728465"><span class="hs-identifier hs-type">logitsLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728464"><span class="hs-identifier hs-type">logitsDevice</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#Int64"><span class="hs-identifier hs-type">Int64</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679728474"><span class="hs-identifier hs-type">ntShape</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679728468"><span class="hs-identifier hs-type">m</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-103"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetDevice"><span class="hs-identifier hs-type">SGetDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728464"><span class="hs-identifier hs-type">logitsDevice</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-104"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetLayout"><span class="hs-identifier hs-type">SGetLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728465"><span class="hs-identifier hs-type">logitsLayout</span></a></span><span>
</span><span id="line-105"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-106"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-107"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-108"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728458"><span class="hs-identifier hs-type">logitsGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728465"><span class="hs-identifier hs-type">logitsLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728464"><span class="hs-identifier hs-type">logitsDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728457"><span class="hs-identifier hs-type">logitsDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728480"><span class="hs-identifier hs-type">logitsShape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-109"></span><span>  </span><span class="annot"><a href="#local-6989586621679728468"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#WithoutGradient"><span class="hs-identifier hs-type">WithoutGradient</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679728465"><span class="hs-identifier hs-type">logitsLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728464"><span class="hs-identifier hs-type">logitsDevice</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#Int64"><span class="hs-identifier hs-type">Int64</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679728474"><span class="hs-identifier hs-type">ntShape</span></a></span><span class="hs-special">)</span></span></span></span></span></span></span></span></span></span></span></span><span>
</span><span id="line-110"></span><span id="greedyNextTokens"><span class="annot"><span class="annottext">greedyNextTokens :: forall (nextTokenLogitsShape :: Shape
                                  [Dim (Name Symbol) (Size Nat)])
       (logitsShape :: Shape [Dim (Name Symbol) (Size Nat)])
       (nextTokensShape :: Shape [Dim (Name Symbol) (Size Nat)])
       (nextTokensShape' :: Shape [Dim (Name Symbol) (Size Nat)])
       (ntShape :: Shape [Dim (Name Symbol) (Size Nat)])
       (ntDim :: Dim (Name Symbol) (Size Nat)) (m :: * -&gt; *)
       (logitsLayout :: Layout LayoutType)
       (logitsDevice :: Device (DeviceType Nat))
       (logitsGradient :: Gradient RequiresGradient)
       (logitsDataType :: DataType DType).
(nextTokenLogitsShape
 ~ IndexDims
     ('Indices '[ 'SliceAll, 'SliceAt ('NegativeIndex 1), 'SliceAll])
     logitsShape,
 nextTokensShape
 ~ ArgmaxF ('SelectDim ('ByIndex 1)) nextTokenLogitsShape,
 Catch nextTokensShape,
 nextTokensShape'
 ~ SqueezeDimF ('SelectDim ('ByIndex 1)) nextTokensShape,
 ntShape ~ 'Shape '[ntDim], Catch (nextTokensShape' &lt;+&gt; ntShape),
 SGetShape nextTokensShape', SGetDim ntDim, Catch ntDim,
 Catch nextTokensShape', MonadThrow m,
 MonadState
   (Tensor
      ('Gradient 'WithoutGradient)
      logitsLayout
      logitsDevice
      ('DataType 'Int64)
      ntShape)
   m,
 SGetDevice logitsDevice, SGetLayout logitsLayout) =&gt;
Int
-&gt; Int
-&gt; Tensor
     logitsGradient logitsLayout logitsDevice logitsDataType logitsShape
-&gt; m (Tensor
        ('Gradient 'WithoutGradient)
        logitsLayout
        logitsDevice
        ('DataType 'Int64)
        ntShape)
</span><a href="Torch.GraduallyTyped.NN.Transformer.Generation.html#greedyNextTokens"><span class="hs-identifier hs-var hs-var">greedyNextTokens</span></a></span></span><span> </span><span id="local-6989586621679728002"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679728002"><span class="hs-identifier hs-var">padTokenId</span></a></span></span><span> </span><span id="local-6989586621679728001"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679728001"><span class="hs-identifier hs-var">eosTokenId</span></a></span></span><span> </span><span id="local-6989586621679728000"><span class="annot"><span class="annottext">Tensor
  logitsGradient logitsLayout logitsDevice logitsDataType logitsShape
</span><a href="#local-6989586621679728000"><span class="hs-identifier hs-var">logits</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-111"></span><span>  </span><span id="local-6989586621679727999"><span class="annot"><span class="annottext">Tensor
  logitsGradient
  logitsLayout
  logitsDevice
  logitsDataType
  nextTokenLogitsShape
</span><a href="#local-6989586621679727999"><span class="hs-identifier hs-var">nextTokenLogits</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">Tensor
  logitsGradient logitsLayout logitsDevice logitsDataType logitsShape
</span><a href="#local-6989586621679728000"><span class="hs-identifier hs-var">logits</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  logitsGradient logitsLayout logitsDevice logitsDataType logitsShape
-&gt; SIndices
     ('Indices '[ 'SliceAll, 'SliceAt ('NegativeIndex 1), 'SliceAll])
-&gt; m (Tensor
        logitsGradient
        logitsLayout
        logitsDevice
        logitsDataType
        (IndexDims
           ('Indices '[ 'SliceAll, 'SliceAt ('NegativeIndex 1), 'SliceAll])
           logitsShape))
forall (indices :: Indices [IndexType (Index Nat)])
       (requiresGradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]) (m :: * -&gt; *).
MonadThrow m =&gt;
Tensor requiresGradient layout device dataType shape
-&gt; SIndices indices
-&gt; m (Tensor
        requiresGradient layout device dataType (IndexDims indices shape))
</span><a href="Torch.GraduallyTyped.Tensor.Indexing.html#%21"><span class="hs-operator hs-var">!</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[ 'SliceAll, 'SliceAt ('NegativeIndex 1), 'SliceAll]
-&gt; SIndices
     ('Indices '[ 'SliceAll, 'SliceAt ('NegativeIndex 1), 'SliceAll])
forall (requiresGradient :: [IndexType (Index Nat)]).
SList requiresGradient -&gt; SIndices ('Indices requiresGradient)
</span><a href="Torch.GraduallyTyped.Tensor.Indexing.html#SIndices"><span class="hs-identifier hs-var">SIndices</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Sing 'SliceAll
forall a. SIndexType 'SliceAll
</span><a href="Torch.GraduallyTyped.Tensor.Indexing.html#SSliceAll"><span class="hs-identifier hs-var">SSliceAll</span></a></span><span> </span><span class="annot"><span class="annottext">Sing 'SliceAll
-&gt; SList '[ 'SliceAt ('NegativeIndex 1), 'SliceAll]
-&gt; SList '[ 'SliceAll, 'SliceAt ('NegativeIndex 1), 'SliceAll]
forall {a1} (a2 :: a1) (as :: [a1]).
Sing a2 -&gt; SList as -&gt; SList (a2 : as)
</span><a href="Torch.GraduallyTyped.Prelude.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">Sing ('NegativeIndex 1) -&gt; SIndexType ('SliceAt ('NegativeIndex 1))
forall a (requiresGradient :: a).
Sing requiresGradient -&gt; SIndexType ('SliceAt requiresGradient)
</span><a href="Torch.GraduallyTyped.Tensor.Indexing.html#SSliceAt"><span class="hs-identifier hs-var">SSliceAt</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">forall (requiresGradient :: Nat).
KnownNat requiresGradient =&gt;
SIndex ('NegativeIndex requiresGradient)
</span><a href="Torch.GraduallyTyped.Index.Type.html#SNegativeIndex"><span class="hs-identifier hs-var">SNegativeIndex</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Sing ('SliceAt ('NegativeIndex 1))
-&gt; SList '[ 'SliceAll]
-&gt; SList '[ 'SliceAt ('NegativeIndex 1), 'SliceAll]
forall {a1} (a2 :: a1) (as :: [a1]).
Sing a2 -&gt; SList as -&gt; SList (a2 : as)
</span><a href="Torch.GraduallyTyped.Prelude.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">Sing 'SliceAll
forall a. SIndexType 'SliceAll
</span><a href="Torch.GraduallyTyped.Tensor.Indexing.html#SSliceAll"><span class="hs-identifier hs-var">SSliceAll</span></a></span><span> </span><span class="annot"><span class="annottext">Sing 'SliceAll -&gt; SList '[] -&gt; SList '[ 'SliceAll]
forall {a1} (a2 :: a1) (as :: [a1]).
Sing a2 -&gt; SList as -&gt; SList (a2 : as)
</span><a href="Torch.GraduallyTyped.Prelude.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/5fimh704vh0dpf8xfhffyiz4vcnc02i2-singletons-base-lib-singletons-base-3.0-haddock-doc/share/doc/singletons-base/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-112"></span><span>  </span><span id="local-6989586621679727994"><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  logitsLayout
  logitsDevice
  ('DataType 'Int64)
  nextTokensShape
</span><a href="#local-6989586621679727994"><span class="hs-identifier hs-var">nextTokens</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">SSelectDim ('SelectDim ('ByIndex 1))
-&gt; Tensor
     logitsGradient
     logitsLayout
     logitsDevice
     logitsDataType
     nextTokenLogitsShape
-&gt; m (Tensor
        ('Gradient 'WithoutGradient)
        logitsLayout
        logitsDevice
        ('DataType 'Int64)
        nextTokensShape)
forall (selectDims :: SelectDim (By Symbol Nat))
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]) (m :: * -&gt; *).
(MonadThrow m, shape' ~ ArgmaxF selectDims shape, Catch shape') =&gt;
SSelectDim selectDims
-&gt; Tensor gradient layout device dataType shape
-&gt; m (Tensor
        ('Gradient 'WithoutGradient)
        layout
        device
        ('DataType 'Int64)
        shape')
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Reduction.html#argmax"><span class="hs-identifier hs-var">argmax</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SBy ('ByIndex 1) -&gt; SSelectDim ('SelectDim ('ByIndex 1))
forall (requiresGradient :: By Symbol Nat).
SBy requiresGradient -&gt; SSelectDim ('SelectDim requiresGradient)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSelectDim"><span class="hs-identifier hs-var">SSelectDim</span></a></span><span> </span><span class="annot"><span class="annottext">(SBy ('ByIndex 1) -&gt; SSelectDim ('SelectDim ('ByIndex 1)))
-&gt; SBy ('ByIndex 1) -&gt; SSelectDim ('SelectDim ('ByIndex 1))
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">forall (requiresGradient :: Nat).
KnownNat requiresGradient =&gt;
SBy ('ByIndex requiresGradient)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SByIndex"><span class="hs-identifier hs-var">SByIndex</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
  logitsGradient
  logitsLayout
  logitsDevice
  logitsDataType
  nextTokenLogitsShape
</span><a href="#local-6989586621679727999"><span class="hs-identifier hs-var">nextTokenLogits</span></a></span><span>
</span><span id="line-113"></span><span>  </span><span id="local-6989586621679727993"><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  logitsLayout
  logitsDevice
  ('DataType 'Int64)
  nextTokensShape'
</span><a href="#local-6989586621679727993"><span class="hs-identifier hs-var">nextTokens'</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">SSelectDim ('SelectDim ('ByIndex 1))
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     logitsLayout
     logitsDevice
     ('DataType 'Int64)
     nextTokensShape
-&gt; m (Tensor
        ('Gradient 'WithoutGradient)
        logitsLayout
        logitsDevice
        ('DataType 'Int64)
        nextTokensShape')
forall (selectDim :: SelectDim (By Symbol Nat))
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]) (m :: * -&gt; *).
(MonadThrow m, shape' ~ SqueezeDimF selectDim shape,
 Catch shape') =&gt;
SSelectDim selectDim
-&gt; Tensor gradient layout device dataType shape
-&gt; m (Tensor gradient layout device dataType shape')
</span><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#sSqueezeDim"><span class="hs-identifier hs-var">sSqueezeDim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SBy ('ByIndex 1) -&gt; SSelectDim ('SelectDim ('ByIndex 1))
forall (requiresGradient :: By Symbol Nat).
SBy requiresGradient -&gt; SSelectDim ('SelectDim requiresGradient)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSelectDim"><span class="hs-identifier hs-var">SSelectDim</span></a></span><span> </span><span class="annot"><span class="annottext">(SBy ('ByIndex 1) -&gt; SSelectDim ('SelectDim ('ByIndex 1)))
-&gt; SBy ('ByIndex 1) -&gt; SSelectDim ('SelectDim ('ByIndex 1))
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">forall (requiresGradient :: Nat).
KnownNat requiresGradient =&gt;
SBy ('ByIndex requiresGradient)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SByIndex"><span class="hs-identifier hs-var">SByIndex</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  logitsLayout
  logitsDevice
  ('DataType 'Int64)
  nextTokensShape
</span><a href="#local-6989586621679727994"><span class="hs-identifier hs-var">nextTokens</span></a></span><span>
</span><span id="line-114"></span><span>  </span><span id="local-6989586621679727992"><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  logitsLayout
  logitsDevice
  ('DataType 'Int64)
  ('Shape '[ntDim])
</span><a href="#local-6989586621679727992"><span class="hs-identifier hs-var">unfinishedSequences</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">m (Tensor
     ('Gradient 'WithoutGradient)
     logitsLayout
     logitsDevice
     ('DataType 'Int64)
     ('Shape '[ntDim]))
forall s (m :: * -&gt; *). MonadState s m =&gt; m s
</span><span class="hs-identifier hs-var">get</span></span><span>
</span><span id="line-115"></span><span>  </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679727990"><span class="annot"><span class="annottext">usShape :: SShape ('Shape '[ntDim])
</span><a href="#local-6989586621679727990"><span class="hs-identifier hs-var hs-var">usShape</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  logitsLayout
  logitsDevice
  ('DataType 'Int64)
  ('Shape '[ntDim])
-&gt; SShape ('Shape '[ntDim])
forall (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType).
SGetShape shape =&gt;
Tensor gradient layout device dataType shape -&gt; SShape shape
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sGetShape"><span class="hs-identifier hs-var">sGetShape</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  logitsLayout
  logitsDevice
  ('DataType 'Int64)
  ('Shape '[ntDim])
</span><a href="#local-6989586621679727992"><span class="hs-identifier hs-var">unfinishedSequences</span></a></span><span>
</span><span id="line-116"></span><span>  </span><span id="local-6989586621679727988"><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  logitsLayout
  logitsDevice
  ('DataType 'Int64)
  ('Shape '[ntDim])
</span><a href="#local-6989586621679727988"><span class="hs-identifier hs-var">nextTokens''</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">SShape ('Shape '[ntDim])
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     logitsLayout
     logitsDevice
     ('DataType 'Int64)
     nextTokensShape'
-&gt; m (Tensor
        ('Gradient 'WithoutGradient)
        logitsLayout
        logitsDevice
        ('DataType 'Int64)
        ('Shape '[ntDim]))
forall (shape' :: Shape [Dim (Name Symbol) (Size Nat)])
       (m :: * -&gt; *) (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
(SGetShape shape, MonadThrow m, Catch (shape &lt;+&gt; shape')) =&gt;
SShape shape'
-&gt; Tensor gradient layout device dataType shape
-&gt; m (Tensor gradient layout device dataType shape')
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sCheckedShape"><span class="hs-identifier hs-var">sCheckedShape</span></a></span><span> </span><span class="annot"><span class="annottext">SShape ('Shape '[ntDim])
</span><a href="#local-6989586621679727990"><span class="hs-identifier hs-var">usShape</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  logitsLayout
  logitsDevice
  ('DataType 'Int64)
  nextTokensShape'
</span><a href="#local-6989586621679727993"><span class="hs-identifier hs-var">nextTokens'</span></a></span><span>
</span><span id="line-117"></span><span>  </span><span id="local-6989586621679727987"><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  logitsLayout
  logitsDevice
  ('DataType 'Int64)
  ntShape
</span><a href="#local-6989586621679727987"><span class="hs-identifier hs-var">nextTokens'''</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">Int
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     logitsLayout
     logitsDevice
     ('DataType 'Int64)
     ('Shape '[ntDim])
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     logitsLayout
     logitsDevice
     ('DataType 'Int64)
     ('Shape '[ntDim])
-&gt; m (Tensor
        ('Gradient 'WithoutGradient)
        logitsLayout
        logitsDevice
        ('DataType 'Int64)
        ntShape)
forall (m :: * -&gt; *) (kntDataType :: DataType DType)
       (usDataType :: DataType DType) (ntDataType :: DataType DType)
       (kntShape :: Shape [Dim (Name Symbol) (Size Nat)])
       (usShape :: Shape [Dim (Name Symbol) (Size Nat)])
       (ntShape :: Shape [Dim (Name Symbol) (Size Nat)])
       (ntGradient' :: Gradient RequiresGradient)
       (usGradient :: Gradient RequiresGradient)
       (ntGradient :: Gradient RequiresGradient)
       (ntLayout' :: Layout LayoutType) (usLayout :: Layout LayoutType)
       (ntLayout :: Layout LayoutType)
       (ntDevice' :: Device (DeviceType Nat))
       (usDevice :: Device (DeviceType Nat))
       (ntDevice :: Device (DeviceType Nat))
       (ntDataType' :: DataType DType)
       (ntShape' :: Shape [Dim (Name Symbol) (Size Nat)]).
(MonadThrow m, kntDataType ~ (usDataType &lt;+&gt; ntDataType),
 kntShape ~ BroadcastShapesF usShape ntShape, Catch kntShape,
 ntGradient' ~ (usGradient &lt;|&gt; ntGradient),
 ntLayout' ~ ((usLayout &lt;+&gt; ntLayout) &lt;+&gt; usLayout),
 ntDevice' ~ ((usDevice &lt;+&gt; ntDevice) &lt;+&gt; usDevice),
 ntDataType' ~ ((usDataType &lt;+&gt; ntDataType) &lt;+&gt; usDataType),
 ntShape' ~ BroadcastShapesF kntShape usShape, Catch ntShape') =&gt;
Int
-&gt; Tensor usGradient usLayout usDevice usDataType usShape
-&gt; Tensor ntGradient ntLayout ntDevice ntDataType ntShape
-&gt; m (Tensor ntGradient' ntLayout' ntDevice' ntDataType' ntShape')
</span><a href="Torch.GraduallyTyped.NN.Transformer.Generation.html#applyUnfinishedSequences"><span class="hs-identifier hs-var">applyUnfinishedSequences</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679728002"><span class="hs-identifier hs-var">padTokenId</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  logitsLayout
  logitsDevice
  ('DataType 'Int64)
  ('Shape '[ntDim])
</span><a href="#local-6989586621679727992"><span class="hs-identifier hs-var">unfinishedSequences</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  logitsLayout
  logitsDevice
  ('DataType 'Int64)
  ('Shape '[ntDim])
</span><a href="#local-6989586621679727988"><span class="hs-identifier hs-var">nextTokens''</span></a></span><span>
</span><span id="line-118"></span><span>  </span><span id="local-6989586621679727985"><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  logitsLayout
  logitsDevice
  ('DataType 'Int64)
  ('Shape '[ntDim])
</span><a href="#local-6989586621679727985"><span class="hs-identifier hs-var">unfinishedSequences'</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">Int
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     logitsLayout
     logitsDevice
     ('DataType 'Int64)
     ntShape
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     logitsLayout
     logitsDevice
     ('DataType 'Int64)
     ('Shape '[ntDim])
-&gt; m (Tensor
        ('Gradient 'WithoutGradient)
        logitsLayout
        logitsDevice
        ('DataType 'Int64)
        ('Shape '[ntDim]))
forall (ntDataType :: DataType DType)
       (ntShape :: Shape [Dim (Name Symbol) (Size Nat)])
       (usShape' :: Shape [Dim (Name Symbol) (Size Nat)])
       (usDataType :: DataType DType)
       (ntDevice :: Device (DeviceType Nat))
       (ntLayout :: Layout LayoutType) (m :: * -&gt; *)
       (usShape :: Shape [Dim (Name Symbol) (Size Nat)])
       (usGradient :: Gradient RequiresGradient)
       (usGradient' :: Gradient RequiresGradient)
       (usLayout :: Layout LayoutType) (usLayout' :: Layout LayoutType)
       (usDevice :: Device (DeviceType Nat))
       (usDevice' :: Device (DeviceType Nat))
       (ntGradient :: Gradient RequiresGradient).
(Catch (ntDataType &lt;+&gt; 'DataType 'Int64),
 Catch (BroadcastShapesF ntShape ('Shape '[])), Catch usShape',
 SGetDataType usDataType, SGetDevice ntDevice, SGetLayout ntLayout,
 MonadThrow m,
 BroadcastShapesF usShape (BroadcastShapesF ntShape ('Shape '[]))
 ~ usShape',
 (usGradient &lt;|&gt; 'Gradient 'WithoutGradient) ~ usGradient',
 (usLayout &lt;+&gt; ntLayout) ~ usLayout',
 (usDevice &lt;+&gt; ntDevice) ~ usDevice') =&gt;
Int
-&gt; Tensor ntGradient ntLayout ntDevice ntDataType ntShape
-&gt; Tensor usGradient usLayout usDevice usDataType usShape
-&gt; m (Tensor usGradient' usLayout' usDevice' usDataType usShape')
</span><a href="Torch.GraduallyTyped.NN.Transformer.Generation.html#updateUnfinishedSequences"><span class="hs-identifier hs-var">updateUnfinishedSequences</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679728001"><span class="hs-identifier hs-var">eosTokenId</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  logitsLayout
  logitsDevice
  ('DataType 'Int64)
  ntShape
</span><a href="#local-6989586621679727987"><span class="hs-identifier hs-var">nextTokens'''</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  logitsLayout
  logitsDevice
  ('DataType 'Int64)
  ('Shape '[ntDim])
</span><a href="#local-6989586621679727992"><span class="hs-identifier hs-var">unfinishedSequences</span></a></span><span>
</span><span id="line-119"></span><span>  </span><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  logitsLayout
  logitsDevice
  ('DataType 'Int64)
  ('Shape '[ntDim])
-&gt; m ()
forall s (m :: * -&gt; *). MonadState s m =&gt; s -&gt; m ()
</span><span class="hs-identifier hs-var">put</span></span><span> </span><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  logitsLayout
  logitsDevice
  ('DataType 'Int64)
  ('Shape '[ntDim])
</span><a href="#local-6989586621679727985"><span class="hs-identifier hs-var">unfinishedSequences'</span></a></span><span>
</span><span id="line-120"></span><span>  </span><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  logitsLayout
  logitsDevice
  ('DataType 'Int64)
  ntShape
-&gt; m (Tensor
        ('Gradient 'WithoutGradient)
        logitsLayout
        logitsDevice
        ('DataType 'Int64)
        ntShape)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  logitsLayout
  logitsDevice
  ('DataType 'Int64)
  ntShape
</span><a href="#local-6989586621679727987"><span class="hs-identifier hs-var">nextTokens'''</span></a></span><span>
</span><span id="line-121"></span><span>
</span><span id="line-122"></span><span id="local-6989586621679728347"><span id="local-6989586621679728349"><span id="local-6989586621679728350"><span id="local-6989586621679728351"><span id="local-6989586621679728352"><span id="local-6989586621679728353"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Generation.html#allSequencesFinished"><span class="hs-identifier hs-type">allSequencesFinished</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-123"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetLayout"><span class="hs-identifier hs-type">SGetLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728353"><span class="hs-identifier hs-type">usLayout</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-124"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetDevice"><span class="hs-identifier hs-type">SGetDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728352"><span class="hs-identifier hs-type">usDevice</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-125"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">MonadThrow</span></span><span> </span><span class="annot"><a href="#local-6989586621679728351"><span class="hs-identifier hs-type">m</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-126"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Catch"><span class="hs-identifier hs-type">Catch</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679728350"><span class="hs-identifier hs-type">usDataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#Int64"><span class="hs-identifier hs-type">Int64</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-127"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Catch"><span class="hs-identifier hs-type">Catch</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#BroadcastShapesF"><span class="hs-identifier hs-type">BroadcastShapesF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728349"><span class="hs-identifier hs-type">usShape</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="hs-special">]</span><span class="hs-special">)</span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-128"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Reduction.html#MaxAllCheckF"><span class="hs-identifier hs-type">MaxAllCheckF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728349"><span class="hs-identifier hs-type">usShape</span></a></span><span>
</span><span id="line-129"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-130"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728347"><span class="hs-identifier hs-type">usGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728353"><span class="hs-identifier hs-type">usLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728352"><span class="hs-identifier hs-type">usDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728350"><span class="hs-identifier hs-type">usDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728349"><span class="hs-identifier hs-type">usShape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-131"></span><span>  </span><span class="annot"><a href="#local-6989586621679728351"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Bool</span></span></span></span></span></span></span></span><span>
</span><span id="line-132"></span><span id="allSequencesFinished"><span class="annot"><span class="annottext">allSequencesFinished :: forall (usLayout :: Layout LayoutType)
       (usDevice :: Device (DeviceType Nat)) (m :: * -&gt; *)
       (usDataType :: DataType DType)
       (usShape :: Shape [Dim (Name Symbol) (Size Nat)])
       (usGradient :: Gradient RequiresGradient).
(SGetLayout usLayout, SGetDevice usDevice, MonadThrow m,
 Catch (usDataType &lt;+&gt; 'DataType 'Int64),
 Catch (BroadcastShapesF usShape ('Shape '[])),
 MaxAllCheckF usShape) =&gt;
Tensor usGradient usLayout usDevice usDataType usShape -&gt; m Bool
</span><a href="Torch.GraduallyTyped.NN.Transformer.Generation.html#allSequencesFinished"><span class="hs-identifier hs-var hs-var">allSequencesFinished</span></a></span></span><span> </span><span id="local-6989586621679727948"><span class="annot"><span class="annottext">Tensor usGradient usLayout usDevice usDataType usShape
</span><a href="#local-6989586621679727948"><span class="hs-identifier hs-var">unfinishedSequences</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-133"></span><span>  </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679727947"><span class="annot"><span class="annottext">gradient :: SGradient ('Gradient 'WithoutGradient)
</span><a href="#local-6989586621679727947"><span class="hs-identifier hs-var hs-var">gradient</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SRequiresGradient 'WithoutGradient
-&gt; SGradient ('Gradient 'WithoutGradient)
forall (requiresGradient :: RequiresGradient).
SRequiresGradient requiresGradient
-&gt; SGradient ('Gradient requiresGradient)
</span><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier hs-var">SGradient</span></a></span><span> </span><span class="annot"><span class="annottext">SRequiresGradient 'WithoutGradient
</span><a href="Torch.GraduallyTyped.RequiresGradient.html#SWithoutGradient"><span class="hs-identifier hs-var">SWithoutGradient</span></a></span><span>
</span><span id="line-134"></span><span>      </span><span id="local-6989586621679727944"><span class="annot"><span class="annottext">layout :: SLayout usLayout
</span><a href="#local-6989586621679727944"><span class="hs-identifier hs-var hs-var">layout</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor usGradient usLayout usDevice usDataType usShape
-&gt; SLayout usLayout
forall (layout :: Layout LayoutType)
       (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SGetLayout layout =&gt;
Tensor gradient layout device dataType shape -&gt; SLayout layout
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sGetLayout"><span class="hs-identifier hs-var">sGetLayout</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor usGradient usLayout usDevice usDataType usShape
</span><a href="#local-6989586621679727948"><span class="hs-identifier hs-var">unfinishedSequences</span></a></span><span>
</span><span id="line-135"></span><span>      </span><span id="local-6989586621679727942"><span class="annot"><span class="annottext">device :: SDevice usDevice
</span><a href="#local-6989586621679727942"><span class="hs-identifier hs-var hs-var">device</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor usGradient usLayout usDevice usDataType usShape
-&gt; SDevice usDevice
forall (device :: Device (DeviceType Nat))
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SGetDevice device =&gt;
Tensor gradient layout device dataType shape -&gt; SDevice device
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sGetDevice"><span class="hs-identifier hs-var">sGetDevice</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor usGradient usLayout usDevice usDataType usShape
</span><a href="#local-6989586621679727948"><span class="hs-identifier hs-var">unfinishedSequences</span></a></span><span>
</span><span id="line-136"></span><span>  </span><span id="local-6989586621679727940"><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  usLayout
  usDevice
  ('DataType 'Int64)
  ('Shape '[])
</span><a href="#local-6989586621679727940"><span class="hs-identifier hs-var">zero</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">SGradient ('Gradient 'WithoutGradient)
-&gt; SLayout usLayout
-&gt; SDevice usDevice
-&gt; Int
-&gt; m (Tensor
        ('Gradient 'WithoutGradient)
        usLayout
        usDevice
        ('DataType 'Int64)
        ('Shape '[]))
forall a (dType :: DType) (dims :: [Dim (Name Symbol) (Size Nat)])
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (m :: * -&gt; *).
(TensorLike a dType dims, MonadThrow m) =&gt;
SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; a
-&gt; m (Tensor
        gradient layout device ('DataType dType) ('Shape dims))
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sToTensor"><span class="hs-identifier hs-var">sToTensor</span></a></span><span> </span><span class="annot"><span class="annottext">SGradient ('Gradient 'WithoutGradient)
</span><a href="#local-6989586621679727947"><span class="hs-identifier hs-var">gradient</span></a></span><span> </span><span class="annot"><span class="annottext">SLayout usLayout
</span><a href="#local-6989586621679727944"><span class="hs-identifier hs-var">layout</span></a></span><span> </span><span class="annot"><span class="annottext">SDevice usDevice
</span><a href="#local-6989586621679727942"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">0</span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">)</span><span>
</span><span id="line-137"></span><span>  </span><span id="local-6989586621679727938"><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  usLayout
  usDevice
  ('DataType 'Bool)
  ('Shape '[])
</span><a href="#local-6989586621679727938"><span class="hs-identifier hs-var">isZero</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">Tensor usGradient usLayout usDevice usDataType usShape
-&gt; Tensor usGradient usLayout usDevice usDataType ('Shape '[])
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
MaxAllCheckF shape =&gt;
Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType ('Shape '[])
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Reduction.html#maxAll"><span class="hs-identifier hs-var">maxAll</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor usGradient usLayout usDevice usDataType usShape
</span><a href="#local-6989586621679727948"><span class="hs-identifier hs-var">unfinishedSequences</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor usGradient usLayout usDevice usDataType ('Shape '[])
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     usLayout
     usDevice
     ('DataType 'Int64)
     ('Shape '[])
-&gt; m (Tensor
        ('Gradient 'WithoutGradient)
        (usLayout &lt;+&gt; usLayout)
        (usDevice &lt;+&gt; usDevice)
        ('DataType 'Bool)
        ('Shape '[]))
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (gradient' :: Gradient RequiresGradient)
       (layout' :: Layout LayoutType) (device' :: Device (DeviceType Nat))
       (dataType' :: DataType DType)
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)])
       (shape'' :: Shape [Dim (Name Symbol) (Size Nat)]) (m :: * -&gt; *).
(MonadThrow m, Catch (dataType &lt;+&gt; dataType'),
 shape'' ~ BroadcastShapesF shape shape', Catch shape'') =&gt;
Tensor gradient layout device dataType shape
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; m (Tensor
        ('Gradient 'WithoutGradient)
        (layout &lt;+&gt; layout')
        (device &lt;+&gt; device')
        ('DataType 'Bool)
        shape'')
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Comparison.html#%3D%3D."><span class="hs-operator hs-var">==.</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  usLayout
  usDevice
  ('DataType 'Int64)
  ('Shape '[])
</span><a href="#local-6989586621679727940"><span class="hs-identifier hs-var">zero</span></a></span><span>
</span><span id="line-138"></span><span>  </span><span class="annot"><span class="annottext">Bool -&gt; m Bool
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">(Bool -&gt; m Bool) -&gt; Bool -&gt; m Bool
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  usLayout
  usDevice
  ('DataType 'Bool)
  ('Shape '[])
-&gt; Bool
forall a (dType :: DType) (dims :: [Dim (Name Symbol) (Size Nat)])
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat)).
TensorLike a dType dims =&gt;
Tensor gradient layout device ('DataType dType) ('Shape dims) -&gt; a
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#fromTensor"><span class="hs-identifier hs-var">fromTensor</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  usLayout
  usDevice
  ('DataType 'Bool)
  ('Shape '[])
</span><a href="#local-6989586621679727938"><span class="hs-identifier hs-var">isZero</span></a></span><span>
</span><span id="line-139"></span><span>
</span><span id="line-140"></span><span id="local-6989586621679728369"><span id="local-6989586621679728370"><span id="local-6989586621679728371"><span id="local-6989586621679728372"><span id="local-6989586621679728373"><span id="local-6989586621679728374"><span id="local-6989586621679728375"><span id="local-6989586621679728376"><span id="local-6989586621679728377"><span id="local-6989586621679728378"><span id="local-6989586621679728379"><span id="local-6989586621679728380"><span id="local-6989586621679728381"><span id="local-6989586621679728382"><span id="local-6989586621679728383"><span id="local-6989586621679728384"><span id="local-6989586621679728385"><span id="local-6989586621679728386"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Generation.html#applyUnfinishedSequences"><span class="hs-identifier hs-type">applyUnfinishedSequences</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-141"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><span class="hs-identifier hs-type">MonadThrow</span></span><span> </span><span class="annot"><a href="#local-6989586621679728386"><span class="hs-identifier hs-type">m</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-142"></span><span>    </span><span class="annot"><a href="#local-6989586621679728385"><span class="hs-identifier hs-type">kntDataType</span></a></span><span> </span><span class="annot"><span class="hs-operator hs-type">~</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679728384"><span class="hs-identifier hs-type">usDataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728383"><span class="hs-identifier hs-type">ntDataType</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-143"></span><span>    </span><span class="annot"><a href="#local-6989586621679728382"><span class="hs-identifier hs-type">kntShape</span></a></span><span> </span><span class="annot"><span class="hs-operator hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#BroadcastShapesF"><span class="hs-identifier hs-type">BroadcastShapesF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728381"><span class="hs-identifier hs-type">usShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728380"><span class="hs-identifier hs-type">ntShape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-144"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Catch"><span class="hs-identifier hs-type">Catch</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728382"><span class="hs-identifier hs-type">kntShape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-145"></span><span>    </span><span class="annot"><a href="#local-6989586621679728379"><span class="hs-identifier hs-type">ntGradient'</span></a></span><span> </span><span class="annot"><span class="hs-operator hs-type">~</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679728378"><span class="hs-identifier hs-type">usGradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728377"><span class="hs-identifier hs-type">ntGradient</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-146"></span><span>    </span><span class="annot"><a href="#local-6989586621679728376"><span class="hs-identifier hs-type">ntLayout'</span></a></span><span> </span><span class="annot"><span class="hs-operator hs-type">~</span></span><span> </span><span class="hs-special">(</span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679728375"><span class="hs-identifier hs-type">usLayout</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728374"><span class="hs-identifier hs-type">ntLayout</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728375"><span class="hs-identifier hs-type">usLayout</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-147"></span><span>    </span><span class="annot"><a href="#local-6989586621679728373"><span class="hs-identifier hs-type">ntDevice'</span></a></span><span> </span><span class="annot"><span class="hs-operator hs-type">~</span></span><span> </span><span class="hs-special">(</span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679728372"><span class="hs-identifier hs-type">usDevice</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728371"><span class="hs-identifier hs-type">ntDevice</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728372"><span class="hs-identifier hs-type">usDevice</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-148"></span><span>    </span><span class="annot"><a href="#local-6989586621679728370"><span class="hs-identifier hs-type">ntDataType'</span></a></span><span> </span><span class="annot"><span class="hs-operator hs-type">~</span></span><span> </span><span class="hs-special">(</span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679728384"><span class="hs-identifier hs-type">usDataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728383"><span class="hs-identifier hs-type">ntDataType</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728384"><span class="hs-identifier hs-type">usDataType</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-149"></span><span>    </span><span class="annot"><a href="#local-6989586621679728369"><span class="hs-identifier hs-type">ntShape'</span></a></span><span> </span><span class="annot"><span class="hs-operator hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#BroadcastShapesF"><span class="hs-identifier hs-type">BroadcastShapesF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728382"><span class="hs-identifier hs-type">kntShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728381"><span class="hs-identifier hs-type">usShape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-150"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Catch"><span class="hs-identifier hs-type">Catch</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728369"><span class="hs-identifier hs-type">ntShape'</span></a></span><span>
</span><span id="line-151"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-152"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-153"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728378"><span class="hs-identifier hs-type">usGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728375"><span class="hs-identifier hs-type">usLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728372"><span class="hs-identifier hs-type">usDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728384"><span class="hs-identifier hs-type">usDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728381"><span class="hs-identifier hs-type">usShape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-154"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728377"><span class="hs-identifier hs-type">ntGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728374"><span class="hs-identifier hs-type">ntLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728371"><span class="hs-identifier hs-type">ntDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728383"><span class="hs-identifier hs-type">ntDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728380"><span class="hs-identifier hs-type">ntShape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-155"></span><span>  </span><span class="annot"><a href="#local-6989586621679728386"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728379"><span class="hs-identifier hs-type">ntGradient'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728376"><span class="hs-identifier hs-type">ntLayout'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728373"><span class="hs-identifier hs-type">ntDevice'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728370"><span class="hs-identifier hs-type">ntDataType'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728369"><span class="hs-identifier hs-type">ntShape'</span></a></span><span class="hs-special">)</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span>
</span><span id="line-156"></span><span id="applyUnfinishedSequences"><span class="annot"><span class="annottext">applyUnfinishedSequences :: forall (m :: * -&gt; *) (kntDataType :: DataType DType)
       (usDataType :: DataType DType) (ntDataType :: DataType DType)
       (kntShape :: Shape [Dim (Name Symbol) (Size Nat)])
       (usShape :: Shape [Dim (Name Symbol) (Size Nat)])
       (ntShape :: Shape [Dim (Name Symbol) (Size Nat)])
       (ntGradient' :: Gradient RequiresGradient)
       (usGradient :: Gradient RequiresGradient)
       (ntGradient :: Gradient RequiresGradient)
       (ntLayout' :: Layout LayoutType) (usLayout :: Layout LayoutType)
       (ntLayout :: Layout LayoutType)
       (ntDevice' :: Device (DeviceType Nat))
       (usDevice :: Device (DeviceType Nat))
       (ntDevice :: Device (DeviceType Nat))
       (ntDataType' :: DataType DType)
       (ntShape' :: Shape [Dim (Name Symbol) (Size Nat)]).
(MonadThrow m, kntDataType ~ (usDataType &lt;+&gt; ntDataType),
 kntShape ~ BroadcastShapesF usShape ntShape, Catch kntShape,
 ntGradient' ~ (usGradient &lt;|&gt; ntGradient),
 ntLayout' ~ ((usLayout &lt;+&gt; ntLayout) &lt;+&gt; usLayout),
 ntDevice' ~ ((usDevice &lt;+&gt; ntDevice) &lt;+&gt; usDevice),
 ntDataType' ~ ((usDataType &lt;+&gt; ntDataType) &lt;+&gt; usDataType),
 ntShape' ~ BroadcastShapesF kntShape usShape, Catch ntShape') =&gt;
Int
-&gt; Tensor usGradient usLayout usDevice usDataType usShape
-&gt; Tensor ntGradient ntLayout ntDevice ntDataType ntShape
-&gt; m (Tensor ntGradient' ntLayout' ntDevice' ntDataType' ntShape')
</span><a href="Torch.GraduallyTyped.NN.Transformer.Generation.html#applyUnfinishedSequences"><span class="hs-identifier hs-var hs-var">applyUnfinishedSequences</span></a></span></span><span> </span><span id="local-6989586621679727877"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679727877"><span class="hs-identifier hs-var">padTokenId</span></a></span></span><span> </span><span id="local-6989586621679727876"><span class="annot"><span class="annottext">Tensor usGradient usLayout usDevice usDataType usShape
</span><a href="#local-6989586621679727876"><span class="hs-identifier hs-var">unfinishedSequences</span></a></span></span><span> </span><span id="local-6989586621679727875"><span class="annot"><span class="annottext">Tensor ntGradient ntLayout ntDevice ntDataType ntShape
</span><a href="#local-6989586621679727875"><span class="hs-identifier hs-var">nextTokens</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-157"></span><span>  </span><span id="local-6989586621679727874"><span class="annot"><span class="annottext">Tensor
  ntGradient'
  (Unify (Layout LayoutType) usLayout ntLayout)
  (Unify (Device (DeviceType Nat)) usDevice ntDevice)
  kntDataType
  kntShape
</span><a href="#local-6989586621679727874"><span class="hs-identifier hs-var">keptNextTokens</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">Tensor usGradient usLayout usDevice usDataType usShape
</span><a href="#local-6989586621679727876"><span class="hs-identifier hs-var">unfinishedSequences</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor usGradient usLayout usDevice usDataType usShape
-&gt; Tensor ntGradient ntLayout ntDevice ntDataType ntShape
-&gt; m (Tensor
        (usGradient &lt;|&gt; ntGradient)
        (usLayout &lt;+&gt; ntLayout)
        (usDevice &lt;+&gt; ntDevice)
        (usDataType &lt;+&gt; ntDataType)
        kntShape)
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (gradient' :: Gradient RequiresGradient)
       (layout' :: Layout LayoutType) (device' :: Device (DeviceType Nat))
       (dataType' :: DataType DType)
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)])
       (shape'' :: Shape [Dim (Name Symbol) (Size Nat)]) (m :: * -&gt; *).
(MonadThrow m, shape'' ~ BroadcastShapesF shape shape',
 Catch shape'') =&gt;
Tensor gradient layout device dataType shape
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; m (Tensor
        (gradient &lt;|&gt; gradient')
        (layout &lt;+&gt; layout')
        (device &lt;+&gt; device')
        (dataType &lt;+&gt; dataType')
        shape'')
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#mul"><span class="hs-operator hs-var">`mul`</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor ntGradient ntLayout ntDevice ntDataType ntShape
</span><a href="#local-6989586621679727875"><span class="hs-identifier hs-var">nextTokens</span></a></span><span>
</span><span id="line-158"></span><span>  </span><span id="local-6989586621679727873"><span class="annot"><span class="annottext">Tensor usGradient usLayout usDevice usDataType usShape
</span><a href="#local-6989586621679727873"><span class="hs-identifier hs-var">replacedNextTokens</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-159"></span><span>    </span><span id="local-6989586621679727872"><span class="annot"><span class="annottext">Tensor usGradient usLayout usDevice usDataType usShape
</span><a href="#local-6989586621679727872"><span class="hs-identifier hs-var">finishedSequences</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">Tensor usGradient usLayout usDevice usDataType usShape
</span><a href="#local-6989586621679727876"><span class="hs-identifier hs-var">unfinishedSequences</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor usGradient usLayout usDevice usDataType usShape
-&gt; Int
-&gt; m (Tensor usGradient usLayout usDevice usDataType usShape)
forall other (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]) (m :: * -&gt; *).
(Scalar other, MonadThrow m) =&gt;
Tensor gradient layout device dataType shape
-&gt; other -&gt; m (Tensor gradient layout device dataType shape)
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#subScalar"><span class="hs-operator hs-var">`subScalar`</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">1</span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">)</span><span>
</span><span id="line-160"></span><span>    </span><span class="annot"><span class="annottext">Tensor usGradient usLayout usDevice usDataType usShape
</span><a href="#local-6989586621679727872"><span class="hs-identifier hs-var">finishedSequences</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor usGradient usLayout usDevice usDataType usShape
-&gt; Int
-&gt; m (Tensor usGradient usLayout usDevice usDataType usShape)
forall other (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]) (m :: * -&gt; *).
(Scalar other, MonadThrow m) =&gt;
Tensor gradient layout device dataType shape
-&gt; other -&gt; m (Tensor gradient layout device dataType shape)
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#mulScalar"><span class="hs-operator hs-var">`mulScalar`</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679727877"><span class="hs-identifier hs-var">padTokenId</span></a></span><span>
</span><span id="line-161"></span><span>  </span><span class="annot"><span class="annottext">Tensor
  ntGradient'
  (Unify (Layout LayoutType) usLayout ntLayout)
  (Unify (Device (DeviceType Nat)) usDevice ntDevice)
  kntDataType
  kntShape
</span><a href="#local-6989586621679727874"><span class="hs-identifier hs-var">keptNextTokens</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  ntGradient'
  (Unify (Layout LayoutType) usLayout ntLayout)
  (Unify (Device (DeviceType Nat)) usDevice ntDevice)
  kntDataType
  kntShape
-&gt; Tensor usGradient usLayout usDevice usDataType usShape
-&gt; m (Tensor
        (ntGradient' &lt;|&gt; ntGradient')
        (Unify (Layout LayoutType) usLayout ntLayout &lt;+&gt; usLayout)
        (Unify (Device (DeviceType Nat)) usDevice ntDevice &lt;+&gt; usDevice)
        (kntDataType &lt;+&gt; usDataType)
        ntShape')
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (gradient' :: Gradient RequiresGradient)
       (layout' :: Layout LayoutType) (device' :: Device (DeviceType Nat))
       (dataType' :: DataType DType)
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)])
       (shape'' :: Shape [Dim (Name Symbol) (Size Nat)]) (m :: * -&gt; *).
(MonadThrow m, shape'' ~ BroadcastShapesF shape shape',
 Catch shape'') =&gt;
Tensor gradient layout device dataType shape
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; m (Tensor
        (gradient &lt;|&gt; gradient)
        (layout &lt;+&gt; layout')
        (device &lt;+&gt; device')
        (dataType &lt;+&gt; dataType')
        shape'')
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#sub"><span class="hs-operator hs-var">`sub`</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor usGradient usLayout usDevice usDataType usShape
</span><a href="#local-6989586621679727873"><span class="hs-identifier hs-var">replacedNextTokens</span></a></span><span>
</span><span id="line-162"></span><span>
</span><span id="line-163"></span><span id="local-6989586621679728354"><span id="local-6989586621679728355"><span id="local-6989586621679728356"><span id="local-6989586621679728357"><span id="local-6989586621679728358"><span id="local-6989586621679728359"><span id="local-6989586621679728360"><span id="local-6989586621679728361"><span id="local-6989586621679728362"><span id="local-6989586621679728363"><span id="local-6989586621679728364"><span id="local-6989586621679728365"><span id="local-6989586621679728366"><span id="local-6989586621679728367"><span id="local-6989586621679728368"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Generation.html#updateUnfinishedSequences"><span class="hs-identifier hs-type">updateUnfinishedSequences</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-164"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Catch"><span class="hs-identifier hs-type">Catch</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679728368"><span class="hs-identifier hs-type">ntDataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#Int64"><span class="hs-identifier hs-type">Int64</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-165"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Catch"><span class="hs-identifier hs-type">Catch</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#BroadcastShapesF"><span class="hs-identifier hs-type">BroadcastShapesF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728367"><span class="hs-identifier hs-type">ntShape</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="hs-special">]</span><span class="hs-special">)</span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-166"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Catch"><span class="hs-identifier hs-type">Catch</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728366"><span class="hs-identifier hs-type">usShape'</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-167"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetDataType"><span class="hs-identifier hs-type">SGetDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728365"><span class="hs-identifier hs-type">usDataType</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-168"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetDevice"><span class="hs-identifier hs-type">SGetDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728364"><span class="hs-identifier hs-type">ntDevice</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-169"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetLayout"><span class="hs-identifier hs-type">SGetLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728363"><span class="hs-identifier hs-type">ntLayout</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-170"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">MonadThrow</span></span><span> </span><span class="annot"><a href="#local-6989586621679728362"><span class="hs-identifier hs-type">m</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-171"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#BroadcastShapesF"><span class="hs-identifier hs-type">BroadcastShapesF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728361"><span class="hs-identifier hs-type">usShape</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#BroadcastShapesF"><span class="hs-identifier hs-type">BroadcastShapesF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728367"><span class="hs-identifier hs-type">ntShape</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="hs-special">]</span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="annot"><span class="hs-operator hs-type">~</span></span><span> </span><span class="annot"><a href="#local-6989586621679728366"><span class="hs-identifier hs-type">usShape'</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-172"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679728360"><span class="hs-identifier hs-type">usGradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#WithoutGradient"><span class="hs-identifier hs-type">WithoutGradient</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="hs-operator hs-type">~</span></span><span> </span><span class="annot"><a href="#local-6989586621679728359"><span class="hs-identifier hs-type">usGradient'</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-173"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679728358"><span class="hs-identifier hs-type">usLayout</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728363"><span class="hs-identifier hs-type">ntLayout</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="hs-operator hs-type">~</span></span><span> </span><span class="annot"><a href="#local-6989586621679728357"><span class="hs-identifier hs-type">usLayout'</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-174"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679728356"><span class="hs-identifier hs-type">usDevice</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728364"><span class="hs-identifier hs-type">ntDevice</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="hs-operator hs-type">~</span></span><span> </span><span class="annot"><a href="#local-6989586621679728355"><span class="hs-identifier hs-type">usDevice'</span></a></span><span>
</span><span id="line-175"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-176"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-177"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728354"><span class="hs-identifier hs-type">ntGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728363"><span class="hs-identifier hs-type">ntLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728364"><span class="hs-identifier hs-type">ntDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728368"><span class="hs-identifier hs-type">ntDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728367"><span class="hs-identifier hs-type">ntShape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-178"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728360"><span class="hs-identifier hs-type">usGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728358"><span class="hs-identifier hs-type">usLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728356"><span class="hs-identifier hs-type">usDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728365"><span class="hs-identifier hs-type">usDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728361"><span class="hs-identifier hs-type">usShape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-179"></span><span>  </span><span class="annot"><a href="#local-6989586621679728362"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728359"><span class="hs-identifier hs-type">usGradient'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728357"><span class="hs-identifier hs-type">usLayout'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728355"><span class="hs-identifier hs-type">usDevice'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728365"><span class="hs-identifier hs-type">usDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679728366"><span class="hs-identifier hs-type">usShape'</span></a></span><span class="hs-special">)</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span>
</span><span id="line-180"></span><span id="updateUnfinishedSequences"><span class="annot"><span class="annottext">updateUnfinishedSequences :: forall (ntDataType :: DataType DType)
       (ntShape :: Shape [Dim (Name Symbol) (Size Nat)])
       (usShape' :: Shape [Dim (Name Symbol) (Size Nat)])
       (usDataType :: DataType DType)
       (ntDevice :: Device (DeviceType Nat))
       (ntLayout :: Layout LayoutType) (m :: * -&gt; *)
       (usShape :: Shape [Dim (Name Symbol) (Size Nat)])
       (usGradient :: Gradient RequiresGradient)
       (usGradient' :: Gradient RequiresGradient)
       (usLayout :: Layout LayoutType) (usLayout' :: Layout LayoutType)
       (usDevice :: Device (DeviceType Nat))
       (usDevice' :: Device (DeviceType Nat))
       (ntGradient :: Gradient RequiresGradient).
(Catch (ntDataType &lt;+&gt; 'DataType 'Int64),
 Catch (BroadcastShapesF ntShape ('Shape '[])), Catch usShape',
 SGetDataType usDataType, SGetDevice ntDevice, SGetLayout ntLayout,
 MonadThrow m,
 BroadcastShapesF usShape (BroadcastShapesF ntShape ('Shape '[]))
 ~ usShape',
 (usGradient &lt;|&gt; 'Gradient 'WithoutGradient) ~ usGradient',
 (usLayout &lt;+&gt; ntLayout) ~ usLayout',
 (usDevice &lt;+&gt; ntDevice) ~ usDevice') =&gt;
Int
-&gt; Tensor ntGradient ntLayout ntDevice ntDataType ntShape
-&gt; Tensor usGradient usLayout usDevice usDataType usShape
-&gt; m (Tensor usGradient' usLayout' usDevice' usDataType usShape')
</span><a href="Torch.GraduallyTyped.NN.Transformer.Generation.html#updateUnfinishedSequences"><span class="hs-identifier hs-var hs-var">updateUnfinishedSequences</span></a></span></span><span> </span><span id="local-6989586621679727819"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679727819"><span class="hs-identifier hs-var">eosTokenId</span></a></span></span><span> </span><span id="local-6989586621679727818"><span class="annot"><span class="annottext">Tensor ntGradient ntLayout ntDevice ntDataType ntShape
</span><a href="#local-6989586621679727818"><span class="hs-identifier hs-var">nextTokens</span></a></span></span><span> </span><span id="local-6989586621679727817"><span class="annot"><span class="annottext">Tensor usGradient usLayout usDevice usDataType usShape
</span><a href="#local-6989586621679727817"><span class="hs-identifier hs-var">unfinishedSequences</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-181"></span><span>  </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679727816"><span class="annot"><span class="annottext">gradient :: SGradient ('Gradient 'WithoutGradient)
</span><a href="#local-6989586621679727816"><span class="hs-identifier hs-var hs-var">gradient</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SRequiresGradient 'WithoutGradient
-&gt; SGradient ('Gradient 'WithoutGradient)
forall (requiresGradient :: RequiresGradient).
SRequiresGradient requiresGradient
-&gt; SGradient ('Gradient requiresGradient)
</span><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier hs-var">SGradient</span></a></span><span> </span><span class="annot"><span class="annottext">SRequiresGradient 'WithoutGradient
</span><a href="Torch.GraduallyTyped.RequiresGradient.html#SWithoutGradient"><span class="hs-identifier hs-var">SWithoutGradient</span></a></span><span>
</span><span id="line-182"></span><span>      </span><span id="local-6989586621679727815"><span class="annot"><span class="annottext">ntLayout :: SLayout ntLayout
</span><a href="#local-6989586621679727815"><span class="hs-identifier hs-var hs-var">ntLayout</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor ntGradient ntLayout ntDevice ntDataType ntShape
-&gt; SLayout ntLayout
forall (layout :: Layout LayoutType)
       (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SGetLayout layout =&gt;
Tensor gradient layout device dataType shape -&gt; SLayout layout
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sGetLayout"><span class="hs-identifier hs-var">sGetLayout</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor ntGradient ntLayout ntDevice ntDataType ntShape
</span><a href="#local-6989586621679727818"><span class="hs-identifier hs-var">nextTokens</span></a></span><span>
</span><span id="line-183"></span><span>      </span><span id="local-6989586621679727814"><span class="annot"><span class="annottext">ntDevice :: SDevice ntDevice
</span><a href="#local-6989586621679727814"><span class="hs-identifier hs-var hs-var">ntDevice</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor ntGradient ntLayout ntDevice ntDataType ntShape
-&gt; SDevice ntDevice
forall (device :: Device (DeviceType Nat))
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SGetDevice device =&gt;
Tensor gradient layout device dataType shape -&gt; SDevice device
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sGetDevice"><span class="hs-identifier hs-var">sGetDevice</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor ntGradient ntLayout ntDevice ntDataType ntShape
</span><a href="#local-6989586621679727818"><span class="hs-identifier hs-var">nextTokens</span></a></span><span>
</span><span id="line-184"></span><span>      </span><span id="local-6989586621679727813"><span class="annot"><span class="annottext">usDataType :: SDataType usDataType
</span><a href="#local-6989586621679727813"><span class="hs-identifier hs-var hs-var">usDataType</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor usGradient usLayout usDevice usDataType usShape
-&gt; SDataType usDataType
forall (dataType :: DataType DType)
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SGetDataType dataType =&gt;
Tensor gradient layout device dataType shape -&gt; SDataType dataType
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sGetDataType"><span class="hs-identifier hs-var">sGetDataType</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor usGradient usLayout usDevice usDataType usShape
</span><a href="#local-6989586621679727817"><span class="hs-identifier hs-var">unfinishedSequences</span></a></span><span>
</span><span id="line-185"></span><span>  </span><span id="local-6989586621679727811"><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  ntLayout
  ntDevice
  ('DataType 'Int64)
  ('Shape '[])
</span><a href="#local-6989586621679727811"><span class="hs-identifier hs-var">eosTokenId'</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">SGradient ('Gradient 'WithoutGradient)
-&gt; SLayout ntLayout
-&gt; SDevice ntDevice
-&gt; Int
-&gt; m (Tensor
        ('Gradient 'WithoutGradient)
        ntLayout
        ntDevice
        ('DataType 'Int64)
        ('Shape '[]))
forall a (dType :: DType) (dims :: [Dim (Name Symbol) (Size Nat)])
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (m :: * -&gt; *).
(TensorLike a dType dims, MonadThrow m) =&gt;
SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; a
-&gt; m (Tensor
        gradient layout device ('DataType dType) ('Shape dims))
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sToTensor"><span class="hs-identifier hs-var">sToTensor</span></a></span><span> </span><span class="annot"><span class="annottext">SGradient ('Gradient 'WithoutGradient)
</span><a href="#local-6989586621679727816"><span class="hs-identifier hs-var">gradient</span></a></span><span> </span><span class="annot"><span class="annottext">SLayout ntLayout
</span><a href="#local-6989586621679727815"><span class="hs-identifier hs-var">ntLayout</span></a></span><span> </span><span class="annot"><span class="annottext">SDevice ntDevice
</span><a href="#local-6989586621679727814"><span class="hs-identifier hs-var">ntDevice</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679727819"><span class="hs-identifier hs-var">eosTokenId</span></a></span><span>
</span><span id="line-186"></span><span>  </span><span id="local-6989586621679727810"><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  ntLayout
  ntDevice
  ('DataType 'Bool)
  (BroadcastShapesF ntShape ('Shape '[]))
</span><a href="#local-6989586621679727810"><span class="hs-identifier hs-var">isNotEos</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">Tensor ntGradient ntLayout ntDevice ntDataType ntShape
</span><a href="#local-6989586621679727818"><span class="hs-identifier hs-var">nextTokens</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor ntGradient ntLayout ntDevice ntDataType ntShape
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ntLayout
     ntDevice
     ('DataType 'Int64)
     ('Shape '[])
-&gt; m (Tensor
        ('Gradient 'WithoutGradient)
        (ntLayout &lt;+&gt; ntLayout)
        (ntDevice &lt;+&gt; ntDevice)
        ('DataType 'Bool)
        (BroadcastShapesF ntShape ('Shape '[])))
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (gradient' :: Gradient RequiresGradient)
       (layout' :: Layout LayoutType) (device' :: Device (DeviceType Nat))
       (dataType' :: DataType DType)
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)])
       (shape'' :: Shape [Dim (Name Symbol) (Size Nat)]) (m :: * -&gt; *).
(MonadThrow m, Catch (dataType &lt;+&gt; dataType'),
 shape'' ~ BroadcastShapesF shape shape', Catch shape'') =&gt;
Tensor gradient layout device dataType shape
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; m (Tensor
        ('Gradient 'WithoutGradient)
        (layout &lt;+&gt; layout')
        (device &lt;+&gt; device')
        ('DataType 'Bool)
        shape'')
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Comparison.html#%2F%3D."><span class="hs-operator hs-var">/=.</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  ntLayout
  ntDevice
  ('DataType 'Int64)
  ('Shape '[])
</span><a href="#local-6989586621679727811"><span class="hs-identifier hs-var">eosTokenId'</span></a></span><span>
</span><span id="line-187"></span><span>  </span><span id="local-6989586621679727809"><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  ntLayout
  ntDevice
  usDataType
  (BroadcastShapesF ntShape ('Shape '[]))
</span><a href="#local-6989586621679727809"><span class="hs-identifier hs-var">isNotEos'</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">SDataType usDataType
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ntLayout
     ntDevice
     ('DataType 'Bool)
     (BroadcastShapesF ntShape ('Shape '[]))
-&gt; m (Tensor
        ('Gradient 'WithoutGradient)
        ntLayout
        ntDevice
        usDataType
        (BroadcastShapesF ntShape ('Shape '[])))
forall (m :: * -&gt; *) (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType) (dataType' :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
MonadThrow m =&gt;
SDataType dataType
-&gt; Tensor gradient layout device dataType' shape
-&gt; m (Tensor gradient layout device dataType shape)
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sSetDataType"><span class="hs-identifier hs-var">sSetDataType</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType usDataType
</span><a href="#local-6989586621679727813"><span class="hs-identifier hs-var">usDataType</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  ntLayout
  ntDevice
  ('DataType 'Bool)
  (BroadcastShapesF ntShape ('Shape '[]))
</span><a href="#local-6989586621679727810"><span class="hs-identifier hs-var">isNotEos</span></a></span><span>
</span><span id="line-188"></span><span>  </span><span class="annot"><span class="annottext">Tensor usGradient usLayout usDevice usDataType usShape
</span><a href="#local-6989586621679727817"><span class="hs-identifier hs-var">unfinishedSequences</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor usGradient usLayout usDevice usDataType usShape
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ntLayout
     ntDevice
     usDataType
     (BroadcastShapesF ntShape ('Shape '[]))
-&gt; m (Tensor
        (usGradient &lt;|&gt; 'Gradient 'WithoutGradient)
        (usLayout &lt;+&gt; ntLayout)
        (usDevice &lt;+&gt; ntDevice)
        (usDataType &lt;+&gt; usDataType)
        usShape')
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (gradient' :: Gradient RequiresGradient)
       (layout' :: Layout LayoutType) (device' :: Device (DeviceType Nat))
       (dataType' :: DataType DType)
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)])
       (shape'' :: Shape [Dim (Name Symbol) (Size Nat)]) (m :: * -&gt; *).
(MonadThrow m, shape'' ~ BroadcastShapesF shape shape',
 Catch shape'') =&gt;
Tensor gradient layout device dataType shape
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; m (Tensor
        (gradient &lt;|&gt; gradient')
        (layout &lt;+&gt; layout')
        (device &lt;+&gt; device')
        (dataType &lt;+&gt; dataType')
        shape'')
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#mul"><span class="hs-operator hs-var">`mul`</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  ntLayout
  ntDevice
  usDataType
  (BroadcastShapesF ntShape ('Shape '[]))
</span><a href="#local-6989586621679727809"><span class="hs-identifier hs-var">isNotEos'</span></a></span><span>
</span><span id="line-189"></span></pre></body></html>