<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><link rel="stylesheet" type="text/css" href="style.css" /><script type="text/javascript" src="highlight.js"></script></head><body><pre><span class="hs-pragma">{-# LANGUAGE AllowAmbiguousTypes #-}</span><span>
</span><span id="line-2"></span><span class="hs-pragma">{-# LANGUAGE ConstraintKinds #-}</span><span>
</span><span id="line-3"></span><span class="hs-pragma">{-# LANGUAGE DataKinds #-}</span><span>
</span><span id="line-4"></span><span class="hs-pragma">{-# LANGUAGE FlexibleContexts #-}</span><span>
</span><span id="line-5"></span><span class="hs-pragma">{-# LANGUAGE FlexibleInstances #-}</span><span>
</span><span id="line-6"></span><span class="hs-pragma">{-# LANGUAGE GADTs #-}</span><span>
</span><span id="line-7"></span><span class="hs-pragma">{-# LANGUAGE KindSignatures #-}</span><span>
</span><span id="line-8"></span><span class="hs-pragma">{-# LANGUAGE MultiParamTypeClasses #-}</span><span>
</span><span id="line-9"></span><span class="hs-pragma">{-# LANGUAGE PartialTypeSignatures #-}</span><span>
</span><span id="line-10"></span><span class="hs-pragma">{-# LANGUAGE PatternSynonyms #-}</span><span>
</span><span id="line-11"></span><span class="hs-pragma">{-# LANGUAGE RecordWildCards #-}</span><span>
</span><span id="line-12"></span><span class="hs-pragma">{-# LANGUAGE ScopedTypeVariables #-}</span><span>
</span><span id="line-13"></span><span class="hs-pragma">{-# LANGUAGE StandaloneKindSignatures #-}</span><span>
</span><span id="line-14"></span><span class="hs-pragma">{-# LANGUAGE TupleSections #-}</span><span>
</span><span id="line-15"></span><span class="hs-pragma">{-# LANGUAGE TypeApplications #-}</span><span>
</span><span id="line-16"></span><span class="hs-pragma">{-# LANGUAGE TypeFamilies #-}</span><span>
</span><span id="line-17"></span><span class="hs-pragma">{-# LANGUAGE TypeOperators #-}</span><span>
</span><span id="line-18"></span><span class="hs-pragma">{-# LANGUAGE UndecidableInstances #-}</span><span>
</span><span id="line-19"></span><span class="hs-pragma">{-# LANGUAGE NoStarIsType #-}</span><span>
</span><span id="line-20"></span><span class="hs-pragma">{-# OPTIONS_GHC -fplugin TypeLevel.Rewrite
                -fplugin-opt=TypeLevel.Rewrite:Torch.GraduallyTyped.Unify.UnifyRightAssociativeL
                -fplugin-opt=TypeLevel.Rewrite:Torch.GraduallyTyped.Unify.UnifyIdempotenceL2
                -fplugin-opt=TypeLevel.Rewrite:Torch.GraduallyTyped.Unify.UnifyIdempotenceL2C
                -fplugin-opt=TypeLevel.Rewrite:Torch.GraduallyTyped.Unify.UnifyIdempotenceL3
                -fplugin-opt=TypeLevel.Rewrite:Torch.GraduallyTyped.Unify.UnifyIdempotenceL3C
                -fplugin-opt=TypeLevel.Rewrite:Torch.GraduallyTyped.Unify.UnifyIdempotenceL4
                -fplugin-opt=TypeLevel.Rewrite:Torch.GraduallyTyped.Unify.UnifyIdempotenceL4C
                -fplugin-opt=TypeLevel.Rewrite:Torch.GraduallyTyped.Unify.UnifyIdempotenceL5
                -fplugin-opt=TypeLevel.Rewrite:Torch.GraduallyTyped.Unify.UnifyIdempotenceL5C
                -fplugin-opt=TypeLevel.Rewrite:Torch.GraduallyTyped.Unify.UnifyIdempotenceL6
                -fplugin-opt=TypeLevel.Rewrite:Torch.GraduallyTyped.Unify.UnifyIdempotenceL6C
                -fplugin-opt=TypeLevel.Rewrite:Torch.GraduallyTyped.Unify.UnifyIdempotenceL7
                -fplugin-opt=TypeLevel.Rewrite:Torch.GraduallyTyped.Unify.UnifyIdempotenceL7C
                -fplugin-opt=TypeLevel.Rewrite:Torch.GraduallyTyped.Unify.UnifyIdempotenceL8
                -fplugin-opt=TypeLevel.Rewrite:Torch.GraduallyTyped.Unify.UnifyIdempotenceL8C
                -fplugin-opt=TypeLevel.Rewrite:Torch.GraduallyTyped.Unify.UnifyIdempotenceL9
                -fplugin-opt=TypeLevel.Rewrite:Torch.GraduallyTyped.Unify.UnifyIdempotenceL9C
                -fplugin-opt=TypeLevel.Rewrite:Torch.GraduallyTyped.Unify.OrRightAssociativeL
                -fplugin-opt=TypeLevel.Rewrite:Torch.GraduallyTyped.Unify.OrIdempotenceL2
                -fplugin-opt=TypeLevel.Rewrite:Torch.GraduallyTyped.Unify.OrIdempotenceL2C
                -fplugin-opt=TypeLevel.Rewrite:Torch.GraduallyTyped.Unify.OrIdempotenceL3
                -fplugin-opt=TypeLevel.Rewrite:Torch.GraduallyTyped.Unify.OrIdempotenceL3C #-}</span><span>
</span><span id="line-43"></span><span class="hs-pragma">{-# OPTIONS_GHC -v2 -Wall #-}</span><span>
</span><span id="line-44"></span><span>
</span><span id="line-45"></span><span class="hs-keyword">module</span><span> </span><span class="hs-identifier">Torch.GraduallyTyped.NN.Transformer.SelfAttention</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-46"></span><span>
</span><span id="line-47"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier">Control.Monad.Indexed</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier">ireturn</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator">(&gt;&gt;&gt;=)</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-48"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier">Control.Monad.Indexed.State</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier">IxState</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier">IxStateT</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-49"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">Control.Monad.State</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier">evalStateT</span></span><span class="hs-special">)</span><span>
</span><span id="line-50"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier">Data.Functor.Indexed</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator">(&lt;&lt;$&gt;&gt;)</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator">(&lt;&lt;*&gt;&gt;)</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-51"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">Data.Kind</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier">Type</span></span><span class="hs-special">)</span><span>
</span><span id="line-52"></span><span class="hs-keyword">import</span><span> </span><span class="hs-keyword">qualified</span><span> </span><span class="annot"><span class="hs-identifier">Data.Map</span></span><span> </span><span class="hs-keyword">as</span><span> </span><span class="annot"><span class="hs-identifier">Map</span></span><span>
</span><span id="line-53"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">Data.Singletons</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">SingI</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">sing</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-54"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">Data.Singletons.Prelude.List</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">SList</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">SNil</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-55"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">GHC.TypeLits</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier">Nat</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier">Symbol</span></span><span class="hs-special">)</span><span>
</span><span id="line-56"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html"><span class="hs-identifier">Torch.GraduallyTyped.DType</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier">DType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier">DataType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#SDType"><span class="hs-identifier">SDType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier">SDataType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-57"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html"><span class="hs-identifier">Torch.GraduallyTyped.Device</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier">Device</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#DeviceType"><span class="hs-identifier">DeviceType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#SDevice"><span class="hs-identifier">SDevice</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#SDeviceType"><span class="hs-identifier">SDeviceType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-58"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html"><span class="hs-identifier">Torch.GraduallyTyped.Layout</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier">Layout</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#LayoutType"><span class="hs-identifier">LayoutType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#SLayout"><span class="hs-identifier">SLayout</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#SLayoutType"><span class="hs-identifier">SLayoutType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-59"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html"><span class="hs-identifier">Torch.GraduallyTyped.NN.Class</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier">HasForward</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier">HasInitialize</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasStateDict"><span class="hs-identifier">HasStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-60"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Dropout.html"><span class="hs-identifier">Torch.GraduallyTyped.NN.Dropout</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Dropout.html#Dropout"><span class="hs-identifier">Dropout</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-61"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Functional.Normalization.html"><span class="hs-identifier">Torch.GraduallyTyped.NN.Functional.Normalization</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Functional.Normalization.html#LayerNormWithBiasF"><span class="hs-identifier">LayerNormWithBiasF</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-62"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Normalization.html"><span class="hs-identifier">Torch.GraduallyTyped.NN.Normalization</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Normalization.html#LayerNorm"><span class="hs-identifier">LayerNorm</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-63"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.MultiHeadAttention.html"><span class="hs-identifier">Torch.GraduallyTyped.NN.Transformer.MultiHeadAttention</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.MultiHeadAttention.html#MultiHeadAttention"><span class="hs-identifier">MultiHeadAttention</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-64"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html"><span class="hs-identifier">Torch.GraduallyTyped.NN.Transformer.Type</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#STransformerStyle"><span class="hs-identifier">STransformerStyle</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerStyle"><span class="hs-identifier">TransformerStyle</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-65"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Type.html"><span class="hs-identifier">Torch.GraduallyTyped.NN.Type</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Type.html#HasBias"><span class="hs-identifier">HasBias</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-66"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Random.html"><span class="hs-identifier">Torch.GraduallyTyped.Random</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Random.html#Generator"><span class="hs-identifier">Generator</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Random.html#sMkGenerator"><span class="hs-identifier">sMkGenerator</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-67"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html"><span class="hs-identifier">Torch.GraduallyTyped.RequiresGradient</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier">Gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#RequiresGradient"><span class="hs-identifier">RequiresGradient</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier">SGradient</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#SRequiresGradient"><span class="hs-identifier">SRequiresGradient</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-68"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Scalar.html"><span class="hs-identifier">Torch.GraduallyTyped.Scalar</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Scalar.html#Scalar"><span class="hs-identifier">Scalar</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-69"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html"><span class="hs-identifier">Torch.GraduallyTyped.Shape.Class</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#BroadcastShapesF"><span class="hs-identifier">BroadcastShapesF</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-70"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html"><span class="hs-identifier">Torch.GraduallyTyped.Shape.Type</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier">Name</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier">SDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier">SName</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier">SShape</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier">SSize</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier">Shape</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier">Size</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="hs-keyword">pattern</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator">(:&amp;:)</span></a></span><span class="hs-special">,</span><span> </span><span class="hs-keyword">pattern</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator">(:|:)</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-71"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Creation.html"><span class="hs-identifier">Torch.GraduallyTyped.Tensor.Creation</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Creation.html#sOnes"><span class="hs-identifier">sOnes</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-72"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html"><span class="hs-identifier">Torch.GraduallyTyped.Tensor.MathOperations.Pointwise</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#add"><span class="hs-identifier">add</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-73"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html"><span class="hs-identifier">Torch.GraduallyTyped.Tensor.Type</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetDim"><span class="hs-identifier">SGetDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier">Tensor</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-74"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html"><span class="hs-identifier">Torch.GraduallyTyped.Unify</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-keyword">type</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator">(&lt;+&gt;)</span></a></span><span class="hs-special">,</span><span> </span><span class="hs-keyword">type</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator">(&lt;|&gt;)</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-75"></span><span>
</span><span id="line-76"></span><span class="hs-comment">-- | Generic self-attention layer.</span><span>
</span><span id="line-77"></span><span class="hs-comment">-- Needs to be specialized to a given transformer type, e.g. 'T5'.</span><span>
</span><span id="line-78"></span><span class="hs-comment">-- See 'SelfAttention'.</span><span>
</span><span id="line-79"></span><span class="hs-keyword">data</span><span>
</span><span id="line-80"></span><span>  </span><span id="GSelfAttention"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#GSelfAttention"><span class="hs-identifier hs-var">GSelfAttention</span></a></span></span><span>
</span><span id="line-81"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679768969"><span class="annot"><a href="#local-6989586621679768969"><span class="hs-identifier hs-type">mha</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span class="hs-special">)</span><span>
</span><span id="line-82"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679768968"><span class="annot"><a href="#local-6989586621679768968"><span class="hs-identifier hs-type">layerNorm</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span class="hs-special">)</span><span>
</span><span id="line-83"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679768967"><span class="annot"><a href="#local-6989586621679768967"><span class="hs-identifier hs-type">dropout</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span class="hs-special">)</span><span>
</span><span id="line-84"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-85"></span><span>  </span><span id="GSelfAttention"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#GSelfAttention"><span class="hs-identifier hs-var">GSelfAttention</span></a></span></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-86"></span><span>    </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679769317"><span class="annot"><a href="#local-6989586621679769317"><span class="hs-identifier hs-type">mha</span></a></span></span><span> </span><span id="local-6989586621679769316"><span class="annot"><a href="#local-6989586621679769316"><span class="hs-identifier hs-type">layerNorm</span></a></span></span><span> </span><span id="local-6989586621679769315"><span class="annot"><a href="#local-6989586621679769315"><span class="hs-identifier hs-type">dropout</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-87"></span><span>    </span><span class="hs-special">{</span><span> </span><span class="hs-comment">-- | self-attention</span><span>
</span><span id="line-88"></span><span>      </span><span id="saMultiHeadAttention"><span class="annot"><span class="annottext">GSelfAttention mha layerNorm dropout -&gt; mha
</span><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#saMultiHeadAttention"><span class="hs-identifier hs-var hs-var">saMultiHeadAttention</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679769317"><span class="hs-identifier hs-type">mha</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-89"></span><span>      </span><span class="hs-comment">-- | layer norm</span><span>
</span><span id="line-90"></span><span>      </span><span id="saLayerNorm"><span class="annot"><span class="annottext">GSelfAttention mha layerNorm dropout -&gt; layerNorm
</span><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#saLayerNorm"><span class="hs-identifier hs-var hs-var">saLayerNorm</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679769316"><span class="hs-identifier hs-type">layerNorm</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-91"></span><span>      </span><span class="hs-comment">-- | dropout</span><span>
</span><span id="line-92"></span><span>      </span><span id="saDropout"><span class="annot"><span class="annottext">GSelfAttention mha layerNorm dropout -&gt; dropout
</span><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#saDropout"><span class="hs-identifier hs-var hs-var">saDropout</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679769315"><span class="hs-identifier hs-type">dropout</span></a></span><span>
</span><span id="line-93"></span><span>    </span><span class="hs-special">}</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-94"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#GSelfAttention"><span class="hs-identifier hs-type">GSelfAttention</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679769317"><span class="hs-identifier hs-type">mha</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679769316"><span class="hs-identifier hs-type">layerNorm</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679769315"><span class="hs-identifier hs-type">dropout</span></a></span><span>
</span><span id="line-95"></span><span>
</span><span id="line-96"></span><span class="hs-comment">-- | Self-attention layer.</span><span>
</span><span id="line-97"></span><span class="hs-keyword">newtype</span><span>
</span><span id="line-98"></span><span>  </span><span id="SelfAttention"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#SelfAttention"><span class="hs-identifier hs-var">SelfAttention</span></a></span></span><span>
</span><span id="line-99"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679768962"><span class="annot"><a href="#local-6989586621679768962"><span class="hs-identifier hs-type">style</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerStyle"><span class="hs-identifier hs-type">TransformerStyle</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-100"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679768961"><span class="annot"><a href="#local-6989586621679768961"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#RequiresGradient"><span class="hs-identifier hs-type">RequiresGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-101"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679768960"><span class="annot"><a href="#local-6989586621679768960"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier hs-type">Device</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#DeviceType"><span class="hs-identifier hs-type">DeviceType</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-102"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679768959"><span class="annot"><a href="#local-6989586621679768959"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier hs-type">DType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-103"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679768958"><span class="annot"><a href="#local-6989586621679768958"><span class="hs-identifier hs-type">headDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-104"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679768957"><span class="annot"><a href="#local-6989586621679768957"><span class="hs-identifier hs-type">headEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-105"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679768956"><span class="annot"><a href="#local-6989586621679768956"><span class="hs-identifier hs-type">embedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-106"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679768955"><span class="annot"><a href="#local-6989586621679768955"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-107"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679768954"><span class="annot"><a href="#local-6989586621679768954"><span class="hs-identifier hs-type">dropoutP</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span class="hs-special">)</span><span>
</span><span id="line-108"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-109"></span><span>  </span><span id="SelfAttention"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#SelfAttention"><span class="hs-identifier hs-var">SelfAttention</span></a></span></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-110"></span><span>    </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679769282"><span class="annot"><a href="#local-6989586621679769282"><span class="hs-identifier hs-type">style</span></a></span></span><span> </span><span id="local-6989586621679769281"><span class="annot"><a href="#local-6989586621679769281"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679769280"><span class="annot"><a href="#local-6989586621679769280"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679769279"><span class="annot"><a href="#local-6989586621679769279"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679769278"><span class="annot"><a href="#local-6989586621679769278"><span class="hs-identifier hs-type">headDim</span></a></span></span><span> </span><span id="local-6989586621679769277"><span class="annot"><a href="#local-6989586621679769277"><span class="hs-identifier hs-type">headEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679769276"><span class="annot"><a href="#local-6989586621679769276"><span class="hs-identifier hs-type">embedDim</span></a></span></span><span> </span><span id="local-6989586621679769275"><span class="annot"><a href="#local-6989586621679769275"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679769274"><span class="annot"><a href="#local-6989586621679769274"><span class="hs-identifier hs-type">dropoutP</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-111"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#GSelfAttention"><span class="hs-identifier hs-type">GSelfAttention</span></a></span><span>
</span><span id="line-112"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#SAMultiheadAttentionF"><span class="hs-identifier hs-type">SAMultiheadAttentionF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679769282"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679769281"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679769280"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679769279"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679769278"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679769277"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679769276"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679769275"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679769274"><span class="hs-identifier hs-type">dropoutP</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-113"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#SALayerNormF"><span class="hs-identifier hs-type">SALayerNormF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679769282"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679769281"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679769280"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679769279"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679769275"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-114"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#SADropoutF"><span class="hs-identifier hs-type">SADropoutF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679769282"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679769274"><span class="hs-identifier hs-type">dropoutP</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-115"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#SelfAttention"><span class="hs-identifier hs-type">SelfAttention</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679769282"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679769281"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679769280"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679769279"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679769278"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679769277"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679769276"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679769275"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679769274"><span class="hs-identifier hs-type">dropoutP</span></a></span><span>
</span><span id="line-116"></span><span>
</span><span id="line-117"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span>
</span><span id="line-118"></span><span>  </span><span id="SAMultiheadAttentionF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#SAMultiheadAttentionF"><span class="hs-identifier hs-var">SAMultiheadAttentionF</span></a></span></span><span>
</span><span id="line-119"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679768952"><span class="annot"><a href="#local-6989586621679768952"><span class="hs-identifier hs-type">style</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerStyle"><span class="hs-identifier hs-type">TransformerStyle</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-120"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679768951"><span class="annot"><a href="#local-6989586621679768951"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#RequiresGradient"><span class="hs-identifier hs-type">RequiresGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-121"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679768950"><span class="annot"><a href="#local-6989586621679768950"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier hs-type">Device</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#DeviceType"><span class="hs-identifier hs-type">DeviceType</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-122"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679768949"><span class="annot"><a href="#local-6989586621679768949"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier hs-type">DType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-123"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679768948"><span class="annot"><a href="#local-6989586621679768948"><span class="hs-identifier hs-type">headDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-124"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679768947"><span class="annot"><a href="#local-6989586621679768947"><span class="hs-identifier hs-type">headEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-125"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679768946"><span class="annot"><a href="#local-6989586621679768946"><span class="hs-identifier hs-type">embedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-126"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679768945"><span class="annot"><a href="#local-6989586621679768945"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-127"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679768944"><span class="annot"><a href="#local-6989586621679768944"><span class="hs-identifier hs-type">dropoutP</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-128"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span>
</span><span id="line-129"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-130"></span><span>  </span><span id="SAMultiheadAttentionF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#SAMultiheadAttentionF"><span class="hs-identifier hs-var">SAMultiheadAttentionF</span></a></span></span><span> </span><span id="local-6989586621679768943"><span class="annot"><a href="#local-6989586621679768943"><span class="hs-identifier hs-type hs-type">style</span></a></span></span><span> </span><span id="local-6989586621679768942"><span class="annot"><a href="#local-6989586621679768942"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679768941"><span class="annot"><a href="#local-6989586621679768941"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679768940"><span class="annot"><a href="#local-6989586621679768940"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679768939"><span class="annot"><a href="#local-6989586621679768939"><span class="hs-identifier hs-type hs-type">headDim</span></a></span></span><span> </span><span id="local-6989586621679768938"><span class="annot"><a href="#local-6989586621679768938"><span class="hs-identifier hs-type hs-type">headEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679768937"><span class="annot"><a href="#local-6989586621679768937"><span class="hs-identifier hs-type hs-type">embedDim</span></a></span></span><span> </span><span id="local-6989586621679768936"><span class="annot"><a href="#local-6989586621679768936"><span class="hs-identifier hs-type hs-type">queryEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679768935"><span class="annot"><a href="#local-6989586621679768935"><span class="hs-identifier hs-type hs-type">dropoutP</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-131"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.MultiHeadAttention.html#MultiHeadAttention"><span class="hs-identifier hs-type">MultiHeadAttention</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768943"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768942"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768941"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768940"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768939"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768938"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768937"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768936"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768936"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768936"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768935"><span class="hs-identifier hs-type">dropoutP</span></a></span><span>
</span><span id="line-132"></span><span>
</span><span id="line-133"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span>
</span><span id="line-134"></span><span>  </span><span id="SALayerNormF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#SALayerNormF"><span class="hs-identifier hs-var">SALayerNormF</span></a></span></span><span>
</span><span id="line-135"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679768934"><span class="annot"><a href="#local-6989586621679768934"><span class="hs-identifier hs-type">style</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerStyle"><span class="hs-identifier hs-type">TransformerStyle</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-136"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679768933"><span class="annot"><a href="#local-6989586621679768933"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#RequiresGradient"><span class="hs-identifier hs-type">RequiresGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-137"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679768932"><span class="annot"><a href="#local-6989586621679768932"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier hs-type">Device</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#DeviceType"><span class="hs-identifier hs-type">DeviceType</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-138"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679768931"><span class="annot"><a href="#local-6989586621679768931"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier hs-type">DType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-139"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679768930"><span class="annot"><a href="#local-6989586621679768930"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-140"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span>
</span><span id="line-141"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-142"></span><span>  </span><span id="SALayerNormF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#SALayerNormF"><span class="hs-identifier hs-var">SALayerNormF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#T5"><span class="hs-identifier hs-type">T5</span></a></span><span> </span><span id="local-6989586621679768929"><span class="annot"><a href="#local-6989586621679768929"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679768928"><span class="annot"><a href="#local-6989586621679768928"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679768927"><span class="annot"><a href="#local-6989586621679768927"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679768926"><span class="annot"><a href="#local-6989586621679768926"><span class="hs-identifier hs-type hs-type">queryEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Normalization.html#LayerNorm"><span class="hs-identifier hs-type">LayerNorm</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Type.html#WithoutBias"><span class="hs-identifier hs-type">WithoutBias</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768929"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768928"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768927"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679768926"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-143"></span><span>  </span><span id="SALayerNormF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#SALayerNormF"><span class="hs-identifier hs-var">SALayerNormF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ByT5"><span class="hs-identifier hs-type">ByT5</span></a></span><span> </span><span id="local-6989586621679768925"><span class="annot"><a href="#local-6989586621679768925"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679768924"><span class="annot"><a href="#local-6989586621679768924"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679768923"><span class="annot"><a href="#local-6989586621679768923"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679768922"><span class="annot"><a href="#local-6989586621679768922"><span class="hs-identifier hs-type hs-type">queryEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#SALayerNormF"><span class="hs-identifier hs-type">SALayerNormF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#T5"><span class="hs-identifier hs-type">T5</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768925"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768924"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768923"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768922"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span>
</span><span id="line-144"></span><span>  </span><span id="SALayerNormF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#SALayerNormF"><span class="hs-identifier hs-var">SALayerNormF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span> </span><span id="local-6989586621679768921"><span class="annot"><a href="#local-6989586621679768921"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679768920"><span class="annot"><a href="#local-6989586621679768920"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679768919"><span class="annot"><a href="#local-6989586621679768919"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679768918"><span class="annot"><a href="#local-6989586621679768918"><span class="hs-identifier hs-type hs-type">queryEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Normalization.html#LayerNorm"><span class="hs-identifier hs-type">LayerNorm</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Type.html#WithBias"><span class="hs-identifier hs-type">WithBias</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768921"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768920"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768919"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679768918"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-145"></span><span>  </span><span id="SALayerNormF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#SALayerNormF"><span class="hs-identifier hs-var">SALayerNormF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MBART"><span class="hs-identifier hs-type">MBART</span></a></span><span> </span><span id="local-6989586621679768917"><span class="annot"><a href="#local-6989586621679768917"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679768916"><span class="annot"><a href="#local-6989586621679768916"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679768915"><span class="annot"><a href="#local-6989586621679768915"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679768914"><span class="annot"><a href="#local-6989586621679768914"><span class="hs-identifier hs-type hs-type">queryEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#SALayerNormF"><span class="hs-identifier hs-type">SALayerNormF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768917"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768916"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768915"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768914"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span>
</span><span id="line-146"></span><span>  </span><span id="SALayerNormF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#SALayerNormF"><span class="hs-identifier hs-var">SALayerNormF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#Pegasus"><span class="hs-identifier hs-type">Pegasus</span></a></span><span> </span><span id="local-6989586621679768913"><span class="annot"><a href="#local-6989586621679768913"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679768912"><span class="annot"><a href="#local-6989586621679768912"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679768911"><span class="annot"><a href="#local-6989586621679768911"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679768910"><span class="annot"><a href="#local-6989586621679768910"><span class="hs-identifier hs-type hs-type">queryEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#SALayerNormF"><span class="hs-identifier hs-type">SALayerNormF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768913"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768912"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768911"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768910"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span>
</span><span id="line-147"></span><span>  </span><span id="SALayerNormF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#SALayerNormF"><span class="hs-identifier hs-var">SALayerNormF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BERT"><span class="hs-identifier hs-type">BERT</span></a></span><span> </span><span id="local-6989586621679768909"><span class="annot"><a href="#local-6989586621679768909"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679768908"><span class="annot"><a href="#local-6989586621679768908"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679768907"><span class="annot"><a href="#local-6989586621679768907"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679768906"><span class="annot"><a href="#local-6989586621679768906"><span class="hs-identifier hs-type hs-type">queryEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Normalization.html#LayerNorm"><span class="hs-identifier hs-type">LayerNorm</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Type.html#WithBias"><span class="hs-identifier hs-type">WithBias</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768909"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768908"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768907"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679768906"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-148"></span><span>  </span><span id="SALayerNormF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#SALayerNormF"><span class="hs-identifier hs-var">SALayerNormF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#RoBERTa"><span class="hs-identifier hs-type">RoBERTa</span></a></span><span> </span><span id="local-6989586621679768905"><span class="annot"><a href="#local-6989586621679768905"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679768904"><span class="annot"><a href="#local-6989586621679768904"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679768903"><span class="annot"><a href="#local-6989586621679768903"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679768902"><span class="annot"><a href="#local-6989586621679768902"><span class="hs-identifier hs-type hs-type">queryEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#SALayerNormF"><span class="hs-identifier hs-type">SALayerNormF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BERT"><span class="hs-identifier hs-type">BERT</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768905"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768904"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768903"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768902"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span>
</span><span id="line-149"></span><span>
</span><span id="line-150"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span>
</span><span id="line-151"></span><span>  </span><span id="SADropoutF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#SADropoutF"><span class="hs-identifier hs-var">SADropoutF</span></a></span></span><span>
</span><span id="line-152"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679768901"><span class="annot"><a href="#local-6989586621679768901"><span class="hs-identifier hs-type">style</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerStyle"><span class="hs-identifier hs-type">TransformerStyle</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-153"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679768900"><span class="annot"><a href="#local-6989586621679768900"><span class="hs-identifier hs-type">dropoutP</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-154"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span>
</span><span id="line-155"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-156"></span><span>  </span><span id="SADropoutF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#SADropoutF"><span class="hs-identifier hs-var">SADropoutF</span></a></span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span id="local-6989586621679768899"><span class="annot"><a href="#local-6989586621679768899"><span class="hs-identifier hs-type hs-type">dropoutP</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Dropout.html#Dropout"><span class="hs-identifier hs-type">Dropout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768899"><span class="hs-identifier hs-type">dropoutP</span></a></span><span>
</span><span id="line-157"></span><span>
</span><span id="line-158"></span><span id="local-6989586621679768885"><span id="local-6989586621679768886"><span id="local-6989586621679768887"><span id="local-6989586621679768888"><span id="local-6989586621679768889"><span id="local-6989586621679768890"><span id="local-6989586621679768891"><span id="local-6989586621679768892"><span id="local-6989586621679768893"><span id="local-6989586621679768894"><span id="local-6989586621679768895"><span id="local-6989586621679768896"><span id="local-6989586621679768897"><span id="local-6989586621679768898"><span class="hs-keyword">instance</span><span>
</span><span id="line-159"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Scalar.html#Scalar"><span class="hs-identifier hs-type">Scalar</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768898"><span class="hs-identifier hs-type">dropoutP</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-160"></span><span>    </span><span class="annot"><a href="#local-6989586621679768897"><span class="hs-identifier hs-type">multiHeadAttention</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#SAMultiheadAttentionF"><span class="hs-identifier hs-type">SAMultiheadAttentionF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768896"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768895"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768894"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768893"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768892"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768891"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768890"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768889"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768898"><span class="hs-identifier hs-type">dropoutP</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-161"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768897"><span class="hs-identifier hs-type">multiHeadAttention</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier hs-type">SGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768895"><span class="hs-identifier hs-type">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#SDevice"><span class="hs-identifier hs-type">SDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768894"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier hs-type">SDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768893"><span class="hs-identifier hs-type">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768892"><span class="hs-identifier hs-type">headDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768891"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768890"><span class="hs-identifier hs-type">embedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768889"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768889"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768889"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679768898"><span class="hs-identifier hs-type">dropoutP</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679768888"><span class="hs-identifier hs-type">generator</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768887"><span class="hs-identifier hs-type">generator'</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-162"></span><span>    </span><span class="annot"><a href="#local-6989586621679768886"><span class="hs-identifier hs-type">layerNorm</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#SALayerNormF"><span class="hs-identifier hs-type">SALayerNormF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768896"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768895"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768894"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768893"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768889"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-163"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768886"><span class="hs-identifier hs-type">layerNorm</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier hs-type">SGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768895"><span class="hs-identifier hs-type">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#SDevice"><span class="hs-identifier hs-type">SDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768894"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier hs-type">SDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768893"><span class="hs-identifier hs-type">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-type">SShape</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679768889"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679768887"><span class="hs-identifier hs-type">generator'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768887"><span class="hs-identifier hs-type">generator'</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-164"></span><span>    </span><span class="annot"><a href="#local-6989586621679768885"><span class="hs-identifier hs-type">dropout</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#SADropoutF"><span class="hs-identifier hs-type">SADropoutF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768896"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768898"><span class="hs-identifier hs-type">dropoutP</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-165"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768885"><span class="hs-identifier hs-type">dropout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768898"><span class="hs-identifier hs-type">dropoutP</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768887"><span class="hs-identifier hs-type">generator'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768887"><span class="hs-identifier hs-type">generator'</span></a></span><span>
</span><span id="line-166"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-167"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span>
</span><span id="line-168"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#SelfAttention"><span class="hs-identifier hs-type">SelfAttention</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768896"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768895"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768894"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768893"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768892"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768891"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768890"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768889"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768898"><span class="hs-identifier hs-type">dropoutP</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-169"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier hs-type">SGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768895"><span class="hs-identifier hs-type">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#SDevice"><span class="hs-identifier hs-type">SDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768894"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier hs-type">SDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768893"><span class="hs-identifier hs-type">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768892"><span class="hs-identifier hs-type">headDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768891"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768890"><span class="hs-identifier hs-type">embedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768889"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679768898"><span class="hs-identifier hs-type">dropoutP</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span class="hs-special">)</span><span>
</span><span id="line-170"></span><span>    </span><span class="annot"><a href="#local-6989586621679768888"><span class="hs-identifier hs-type">generator</span></a></span><span>
</span><span id="line-171"></span><span>    </span><span class="annot"><a href="#local-6989586621679768887"><span class="hs-identifier hs-type">generator'</span></a></span><span>
</span><span id="line-172"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-173"></span><span>  </span><span id="local-6989586621679768882"><span class="annot"><span class="annottext">initialize :: (SGradient gradient, SDevice device, SDataType dataType,
 SDim headDim, SDim headEmbedDim, SDim embedDim, SDim queryEmbedDim,
 dropoutP, Double)
-&gt; generator
-&gt; (SelfAttention
      style
      gradient
      device
      dataType
      headDim
      headEmbedDim
      embedDim
      queryEmbedDim
      dropoutP,
    generator')
</span><a href="Torch.GraduallyTyped.NN.Class.html#initialize"><span class="hs-identifier hs-var hs-var hs-var hs-var">initialize</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679768880"><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679768880"><span class="hs-identifier hs-var">gradient</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679768879"><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679768879"><span class="hs-identifier hs-var">device</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679768878"><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679768878"><span class="hs-identifier hs-var">dataType</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679768877"><span class="annot"><span class="annottext">SDim headDim
</span><a href="#local-6989586621679768877"><span class="hs-identifier hs-var">headDim</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679768876"><span class="annot"><span class="annottext">SDim headEmbedDim
</span><a href="#local-6989586621679768876"><span class="hs-identifier hs-var">headEmbedDim</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679768875"><span class="annot"><span class="annottext">SDim embedDim
</span><a href="#local-6989586621679768875"><span class="hs-identifier hs-var">embedDim</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679768874"><span class="annot"><span class="annottext">SDim queryEmbedDim
</span><a href="#local-6989586621679768874"><span class="hs-identifier hs-var">queryEmbedDim</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679768873"><span class="annot"><span class="annottext">dropoutP
</span><a href="#local-6989586621679768873"><span class="hs-identifier hs-var">dropoutP</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679768872"><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679768872"><span class="hs-identifier hs-var">eps</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-174"></span><span>    </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679768871"><span class="annot"><span class="annottext">multiHeadAttention :: IxState
  generator
  generator'
  (MultiHeadAttention
     style
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     queryEmbedDim
     queryEmbedDim
     dropoutP)
</span><a href="#local-6989586621679768871"><span class="hs-identifier hs-var hs-var">multiHeadAttention</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(generator
 -&gt; (MultiHeadAttention
       style
       gradient
       device
       dataType
       headDim
       headEmbedDim
       embedDim
       queryEmbedDim
       queryEmbedDim
       queryEmbedDim
       dropoutP,
     generator'))
-&gt; IxState
     generator
     generator'
     (MultiHeadAttention
        style
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        queryEmbedDim
        queryEmbedDim
        queryEmbedDim
        dropoutP)
forall i j a. (i -&gt; (a, j)) -&gt; IxState i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxState</span></a></span><span> </span><span class="annot"><span class="annottext">((generator
  -&gt; (MultiHeadAttention
        style
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        queryEmbedDim
        queryEmbedDim
        queryEmbedDim
        dropoutP,
      generator'))
 -&gt; IxState
      generator
      generator'
      (MultiHeadAttention
         style
         gradient
         device
         dataType
         headDim
         headEmbedDim
         embedDim
         queryEmbedDim
         queryEmbedDim
         queryEmbedDim
         dropoutP))
-&gt; (generator
    -&gt; (MultiHeadAttention
          style
          gradient
          device
          dataType
          headDim
          headEmbedDim
          embedDim
          queryEmbedDim
          queryEmbedDim
          queryEmbedDim
          dropoutP,
        generator'))
-&gt; IxState
     generator
     generator'
     (MultiHeadAttention
        style
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        queryEmbedDim
        queryEmbedDim
        queryEmbedDim
        dropoutP)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(SGradient gradient, SDevice device, SDataType dataType,
 SDim headDim, SDim headEmbedDim, SDim embedDim, SDim queryEmbedDim,
 SDim queryEmbedDim, SDim queryEmbedDim, dropoutP)
-&gt; generator
-&gt; (MultiHeadAttention
      style
      gradient
      device
      dataType
      headDim
      headEmbedDim
      embedDim
      queryEmbedDim
      queryEmbedDim
      queryEmbedDim
      dropoutP,
    generator')
forall model input generator generatorOutput.
HasInitialize model input generator generatorOutput =&gt;
input -&gt; generator -&gt; (model, generatorOutput)
</span><a href="Torch.GraduallyTyped.NN.Class.html#initialize"><span class="hs-identifier hs-var">initialize</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679768880"><span class="hs-identifier hs-var">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679768879"><span class="hs-identifier hs-var">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679768878"><span class="hs-identifier hs-var">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim headDim
</span><a href="#local-6989586621679768877"><span class="hs-identifier hs-var">headDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim headEmbedDim
</span><a href="#local-6989586621679768876"><span class="hs-identifier hs-var">headEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim embedDim
</span><a href="#local-6989586621679768875"><span class="hs-identifier hs-var">embedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim queryEmbedDim
</span><a href="#local-6989586621679768874"><span class="hs-identifier hs-var">queryEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim queryEmbedDim
</span><a href="#local-6989586621679768874"><span class="hs-identifier hs-var">queryEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim queryEmbedDim
</span><a href="#local-6989586621679768874"><span class="hs-identifier hs-var">queryEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">dropoutP
</span><a href="#local-6989586621679768873"><span class="hs-identifier hs-var">dropoutP</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-175"></span><span>        </span><span id="local-6989586621679768869"><span class="annot"><span class="annottext">layerNorm :: IxState generator' generator' layerNorm
</span><a href="#local-6989586621679768869"><span class="hs-identifier hs-var hs-var">layerNorm</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(generator' -&gt; (layerNorm, generator'))
-&gt; IxState generator' generator' layerNorm
forall i j a. (i -&gt; (a, j)) -&gt; IxState i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxState</span></a></span><span> </span><span class="annot"><span class="annottext">((generator' -&gt; (layerNorm, generator'))
 -&gt; IxState generator' generator' layerNorm)
-&gt; (generator' -&gt; (layerNorm, generator'))
-&gt; IxState generator' generator' layerNorm
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(SGradient gradient, SDevice device, SDataType dataType,
 SShape ('Shape '[queryEmbedDim]), Double)
-&gt; generator' -&gt; (layerNorm, generator')
forall model input generator generatorOutput.
HasInitialize model input generator generatorOutput =&gt;
input -&gt; generator -&gt; (model, generatorOutput)
</span><a href="Torch.GraduallyTyped.NN.Class.html#initialize"><span class="hs-identifier hs-var">initialize</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679768880"><span class="hs-identifier hs-var">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679768879"><span class="hs-identifier hs-var">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679768878"><span class="hs-identifier hs-var">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SList '[queryEmbedDim] -&gt; SShape ('Shape '[queryEmbedDim])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList '[queryEmbedDim] -&gt; SShape ('Shape '[queryEmbedDim]))
-&gt; SList '[queryEmbedDim] -&gt; SShape ('Shape '[queryEmbedDim])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SDim queryEmbedDim
</span><a href="#local-6989586621679768874"><span class="hs-identifier hs-var">queryEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim queryEmbedDim -&gt; SList '[] -&gt; SList '[queryEmbedDim]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679768872"><span class="hs-identifier hs-var">eps</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-176"></span><span>        </span><span id="local-6989586621679768867"><span class="annot"><span class="annottext">dropout :: IxState generator' generator' (Dropout dropoutP)
</span><a href="#local-6989586621679768867"><span class="hs-identifier hs-var hs-var">dropout</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(generator' -&gt; (Dropout dropoutP, generator'))
-&gt; IxState generator' generator' (Dropout dropoutP)
forall i j a. (i -&gt; (a, j)) -&gt; IxState i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxState</span></a></span><span> </span><span class="annot"><span class="annottext">((generator' -&gt; (Dropout dropoutP, generator'))
 -&gt; IxState generator' generator' (Dropout dropoutP))
-&gt; (generator' -&gt; (Dropout dropoutP, generator'))
-&gt; IxState generator' generator' (Dropout dropoutP)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">dropoutP -&gt; generator' -&gt; (Dropout dropoutP, generator')
forall model input generator generatorOutput.
HasInitialize model input generator generatorOutput =&gt;
input -&gt; generator -&gt; (model, generatorOutput)
</span><a href="Torch.GraduallyTyped.NN.Class.html#initialize"><span class="hs-identifier hs-var">initialize</span></a></span><span> </span><span class="annot"><span class="annottext">dropoutP
</span><a href="#local-6989586621679768873"><span class="hs-identifier hs-var">dropoutP</span></a></span><span>
</span><span id="line-177"></span><span>     </span><span class="hs-keyword">in</span><span> </span><span class="annot"><span class="annottext">IxState
  generator
  generator'
  (SelfAttention
     style
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     dropoutP)
-&gt; generator
-&gt; (SelfAttention
      style
      gradient
      device
      dataType
      headDim
      headEmbedDim
      embedDim
      queryEmbedDim
      dropoutP,
    generator')
forall i j a. IxState i j a -&gt; i -&gt; (a, j)
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var hs-var">runIxState</span></a></span><span> </span><span class="annot"><span class="annottext">(IxState
   generator
   generator'
   (SelfAttention
      style
      gradient
      device
      dataType
      headDim
      headEmbedDim
      embedDim
      queryEmbedDim
      dropoutP)
 -&gt; generator
 -&gt; (SelfAttention
       style
       gradient
       device
       dataType
       headDim
       headEmbedDim
       embedDim
       queryEmbedDim
       dropoutP,
     generator'))
-&gt; IxState
     generator
     generator'
     (SelfAttention
        style
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        queryEmbedDim
        dropoutP)
-&gt; generator
-&gt; (SelfAttention
      style
      gradient
      device
      dataType
      headDim
      headEmbedDim
      embedDim
      queryEmbedDim
      dropoutP,
    generator')
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-178"></span><span>          </span><span class="hs-special">(</span><span class="annot"><span class="annottext">MultiHeadAttention
  style
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  queryEmbedDim
  queryEmbedDim
  queryEmbedDim
  dropoutP
-&gt; layerNorm
-&gt; Dropout dropoutP
-&gt; GSelfAttention
     (MultiHeadAttention
        style
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        queryEmbedDim
        queryEmbedDim
        queryEmbedDim
        dropoutP)
     layerNorm
     (Dropout dropoutP)
forall mha layerNorm dropout.
mha -&gt; layerNorm -&gt; dropout -&gt; GSelfAttention mha layerNorm dropout
</span><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#GSelfAttention"><span class="hs-identifier hs-var">GSelfAttention</span></a></span><span> </span><span class="annot"><span class="annottext">(MultiHeadAttention
   style
   gradient
   device
   dataType
   headDim
   headEmbedDim
   embedDim
   queryEmbedDim
   queryEmbedDim
   queryEmbedDim
   dropoutP
 -&gt; layerNorm
 -&gt; Dropout dropoutP
 -&gt; GSelfAttention
      (MultiHeadAttention
         style
         gradient
         device
         dataType
         headDim
         headEmbedDim
         embedDim
         queryEmbedDim
         queryEmbedDim
         queryEmbedDim
         dropoutP)
      layerNorm
      (Dropout dropoutP))
-&gt; IxState
     generator
     generator'
     (MultiHeadAttention
        style
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        queryEmbedDim
        queryEmbedDim
        queryEmbedDim
        dropoutP)
-&gt; IxState
     generator
     generator'
     (layerNorm
      -&gt; Dropout dropoutP
      -&gt; GSelfAttention
           (MultiHeadAttention
              style
              gradient
              device
              dataType
              headDim
              headEmbedDim
              embedDim
              queryEmbedDim
              queryEmbedDim
              queryEmbedDim
              dropoutP)
           layerNorm
           (Dropout dropoutP))
forall k1 k2 (f :: k1 -&gt; k2 -&gt; Type -&gt; Type) a b (j :: k1)
       (k3 :: k2).
IxFunctor f =&gt;
(a -&gt; b) -&gt; f j k3 a -&gt; f j k3 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&lt;&lt;$&gt;&gt;</span></a></span><span> </span><span class="annot"><span class="annottext">IxState
  generator
  generator'
  (MultiHeadAttention
     style
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     queryEmbedDim
     queryEmbedDim
     dropoutP)
</span><a href="#local-6989586621679768871"><span class="hs-identifier hs-var">multiHeadAttention</span></a></span><span> </span><span class="annot"><span class="annottext">IxState
  generator
  generator'
  (layerNorm
   -&gt; Dropout dropoutP
   -&gt; GSelfAttention
        (MultiHeadAttention
           style
           gradient
           device
           dataType
           headDim
           headEmbedDim
           embedDim
           queryEmbedDim
           queryEmbedDim
           queryEmbedDim
           dropoutP)
        layerNorm
        (Dropout dropoutP))
-&gt; IxState generator' generator' layerNorm
-&gt; IxState
     generator
     generator'
     (Dropout dropoutP
      -&gt; GSelfAttention
           (MultiHeadAttention
              style
              gradient
              device
              dataType
              headDim
              headEmbedDim
              embedDim
              queryEmbedDim
              queryEmbedDim
              queryEmbedDim
              dropoutP)
           layerNorm
           (Dropout dropoutP))
forall k1 (f :: k1 -&gt; k1 -&gt; Type -&gt; Type) (i :: k1) (j :: k1) a b
       (k2 :: k1).
IxApplicative f =&gt;
f i j (a -&gt; b) -&gt; f j k2 a -&gt; f i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&lt;&lt;*&gt;&gt;</span></a></span><span> </span><span class="annot"><span class="annottext">IxState generator' generator' layerNorm
</span><a href="#local-6989586621679768869"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">IxState
  generator
  generator'
  (Dropout dropoutP
   -&gt; GSelfAttention
        (MultiHeadAttention
           style
           gradient
           device
           dataType
           headDim
           headEmbedDim
           embedDim
           queryEmbedDim
           queryEmbedDim
           queryEmbedDim
           dropoutP)
        layerNorm
        (Dropout dropoutP))
-&gt; IxState generator' generator' (Dropout dropoutP)
-&gt; IxState
     generator
     generator'
     (GSelfAttention
        (MultiHeadAttention
           style
           gradient
           device
           dataType
           headDim
           headEmbedDim
           embedDim
           queryEmbedDim
           queryEmbedDim
           queryEmbedDim
           dropoutP)
        layerNorm
        (Dropout dropoutP))
forall k1 (f :: k1 -&gt; k1 -&gt; Type -&gt; Type) (i :: k1) (j :: k1) a b
       (k2 :: k1).
IxApplicative f =&gt;
f i j (a -&gt; b) -&gt; f j k2 a -&gt; f i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&lt;&lt;*&gt;&gt;</span></a></span><span> </span><span class="annot"><span class="annottext">IxState generator' generator' (Dropout dropoutP)
</span><a href="#local-6989586621679768867"><span class="hs-identifier hs-var">dropout</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-179"></span><span>            </span><span class="annot"><span class="annottext">IxState
  generator
  generator'
  (GSelfAttention
     (MultiHeadAttention
        style
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        queryEmbedDim
        queryEmbedDim
        queryEmbedDim
        dropoutP)
     layerNorm
     (Dropout dropoutP))
-&gt; (GSelfAttention
      (MultiHeadAttention
         style
         gradient
         device
         dataType
         headDim
         headEmbedDim
         embedDim
         queryEmbedDim
         queryEmbedDim
         queryEmbedDim
         dropoutP)
      layerNorm
      (Dropout dropoutP)
    -&gt; IxState
         generator'
         generator'
         (SelfAttention
            style
            gradient
            device
            dataType
            headDim
            headEmbedDim
            embedDim
            queryEmbedDim
            dropoutP))
-&gt; IxState
     generator
     generator'
     (SelfAttention
        style
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        queryEmbedDim
        dropoutP)
forall k1 (m :: k1 -&gt; k1 -&gt; Type -&gt; Type) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">SelfAttention
  style
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  queryEmbedDim
  dropoutP
-&gt; IxState
     generator'
     generator'
     (SelfAttention
        style
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        queryEmbedDim
        dropoutP)
forall k (m :: k -&gt; k -&gt; Type -&gt; Type) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">(SelfAttention
   style
   gradient
   device
   dataType
   headDim
   headEmbedDim
   embedDim
   queryEmbedDim
   dropoutP
 -&gt; IxState
      generator'
      generator'
      (SelfAttention
         style
         gradient
         device
         dataType
         headDim
         headEmbedDim
         embedDim
         queryEmbedDim
         dropoutP))
-&gt; (GSelfAttention
      (MultiHeadAttention
         style
         gradient
         device
         dataType
         headDim
         headEmbedDim
         embedDim
         queryEmbedDim
         queryEmbedDim
         queryEmbedDim
         dropoutP)
      layerNorm
      (Dropout dropoutP)
    -&gt; SelfAttention
         style
         gradient
         device
         dataType
         headDim
         headEmbedDim
         embedDim
         queryEmbedDim
         dropoutP)
-&gt; GSelfAttention
     (MultiHeadAttention
        style
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        queryEmbedDim
        queryEmbedDim
        queryEmbedDim
        dropoutP)
     layerNorm
     (Dropout dropoutP)
-&gt; IxState
     generator'
     generator'
     (SelfAttention
        style
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        queryEmbedDim
        dropoutP)
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">GSelfAttention
  (MultiHeadAttention
     style
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     queryEmbedDim
     queryEmbedDim
     dropoutP)
  layerNorm
  (Dropout dropoutP)
-&gt; SelfAttention
     style
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     dropoutP
forall (style :: TransformerStyle)
       (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (headDim :: Dim (Name Symbol) (Size Nat))
       (headEmbedDim :: Dim (Name Symbol) (Size Nat))
       (embedDim :: Dim (Name Symbol) (Size Nat))
       (queryEmbedDim :: Dim (Name Symbol) (Size Nat)) dropoutP.
GSelfAttention
  (SAMultiheadAttentionF
     style
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     dropoutP)
  (SALayerNormF style gradient device dataType queryEmbedDim)
  (SADropoutF style dropoutP)
-&gt; SelfAttention
     style
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     dropoutP
</span><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#SelfAttention"><span class="hs-identifier hs-var">SelfAttention</span></a></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span>
</span><span id="line-180"></span><span>
</span><span id="line-181"></span><span id="local-6989586621679768856"><span id="local-6989586621679768857"><span id="local-6989586621679768858"><span id="local-6989586621679768859"><span id="local-6989586621679768860"><span id="local-6989586621679768861"><span id="local-6989586621679768862"><span id="local-6989586621679768863"><span id="local-6989586621679768864"><span class="hs-keyword">instance</span><span>
</span><span id="line-182"></span><span>  </span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-type">SingI</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768864"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-183"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasStateDict"><span class="hs-identifier hs-type">HasStateDict</span></a></span><span>
</span><span id="line-184"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#SelfAttention"><span class="hs-identifier hs-type">SelfAttention</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768864"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768863"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768862"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768861"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768860"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768859"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768858"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768857"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768856"><span class="hs-identifier hs-type">dropoutP</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-185"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier hs-type">SGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768863"><span class="hs-identifier hs-type">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#SDevice"><span class="hs-identifier hs-type">SDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768862"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier hs-type">SDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768861"><span class="hs-identifier hs-type">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768860"><span class="hs-identifier hs-type">headDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768859"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768858"><span class="hs-identifier hs-type">embedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768857"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679768856"><span class="hs-identifier hs-type">dropoutP</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span class="hs-special">)</span><span>
</span><span id="line-186"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-187"></span><span>  </span><span id="local-6989586621679768852"><span class="annot"><span class="annottext">fromStateDict :: (SGradient gradient, SDevice device, SDataType dataType,
 SDim headDim, SDim headEmbedDim, SDim embedDim, SDim queryEmbedDim,
 dropoutP, Double)
-&gt; StateDictKey
-&gt; m (SelfAttention
        style
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        queryEmbedDim
        dropoutP)
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var hs-var hs-var hs-var">fromStateDict</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679768850"><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679768850"><span class="hs-identifier hs-var">gradient</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679768849"><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679768849"><span class="hs-identifier hs-var">device</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679768848"><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679768848"><span class="hs-identifier hs-var">dataType</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679768847"><span class="annot"><span class="annottext">SDim headDim
</span><a href="#local-6989586621679768847"><span class="hs-identifier hs-var">headDim</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679768846"><span class="annot"><span class="annottext">SDim headEmbedDim
</span><a href="#local-6989586621679768846"><span class="hs-identifier hs-var">headEmbedDim</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679768845"><span class="annot"><span class="annottext">SDim embedDim
</span><a href="#local-6989586621679768845"><span class="hs-identifier hs-var">embedDim</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679768844"><span class="annot"><span class="annottext">SDim queryEmbedDim
</span><a href="#local-6989586621679768844"><span class="hs-identifier hs-var">queryEmbedDim</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679768843"><span class="annot"><span class="annottext">dropoutP
</span><a href="#local-6989586621679768843"><span class="hs-identifier hs-var">dropoutP</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679768842"><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679768842"><span class="hs-identifier hs-var">eps</span></a></span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679768841"><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679768841"><span class="hs-identifier hs-var">k</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-188"></span><span>    </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679768840"><span class="annot"><span class="annottext">multiHeadAttention :: STransformerStyle style
-&gt; m (MultiHeadAttention
        style
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        queryEmbedDim
        queryEmbedDim
        queryEmbedDim
        dropoutP)
</span><a href="#local-6989586621679768840"><span class="hs-identifier hs-var hs-var">multiHeadAttention</span></a></span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(SGradient gradient, SDevice device, SDataType dataType,
 SDim headDim, SDim headEmbedDim, SDim embedDim, SDim queryEmbedDim,
 SDim queryEmbedDim, SDim queryEmbedDim, dropoutP)
-&gt; StateDictKey
-&gt; m (MultiHeadAttention
        'T5
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        queryEmbedDim
        queryEmbedDim
        queryEmbedDim
        dropoutP)
forall model input (m :: Type -&gt; Type).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
input -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679768850"><span class="hs-identifier hs-var">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679768849"><span class="hs-identifier hs-var">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679768848"><span class="hs-identifier hs-var">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim headDim
</span><a href="#local-6989586621679768847"><span class="hs-identifier hs-var">headDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim headEmbedDim
</span><a href="#local-6989586621679768846"><span class="hs-identifier hs-var">headEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim embedDim
</span><a href="#local-6989586621679768845"><span class="hs-identifier hs-var">embedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim queryEmbedDim
</span><a href="#local-6989586621679768844"><span class="hs-identifier hs-var">queryEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim queryEmbedDim
</span><a href="#local-6989586621679768844"><span class="hs-identifier hs-var">queryEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim queryEmbedDim
</span><a href="#local-6989586621679768844"><span class="hs-identifier hs-var">queryEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">dropoutP
</span><a href="#local-6989586621679768843"><span class="hs-identifier hs-var">dropoutP</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679768841"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;SelfAttention.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-189"></span><span>        </span><span class="annot"><a href="#local-6989586621679768840"><span class="hs-identifier hs-var">multiHeadAttention</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(SGradient gradient, SDevice device, SDataType dataType,
 SDim headDim, SDim headEmbedDim, SDim embedDim, SDim queryEmbedDim,
 SDim queryEmbedDim, SDim queryEmbedDim, dropoutP)
-&gt; StateDictKey
-&gt; m (MultiHeadAttention
        'ByT5
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        queryEmbedDim
        queryEmbedDim
        queryEmbedDim
        dropoutP)
forall model input (m :: Type -&gt; Type).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
input -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679768850"><span class="hs-identifier hs-var">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679768849"><span class="hs-identifier hs-var">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679768848"><span class="hs-identifier hs-var">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim headDim
</span><a href="#local-6989586621679768847"><span class="hs-identifier hs-var">headDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim headEmbedDim
</span><a href="#local-6989586621679768846"><span class="hs-identifier hs-var">headEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim embedDim
</span><a href="#local-6989586621679768845"><span class="hs-identifier hs-var">embedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim queryEmbedDim
</span><a href="#local-6989586621679768844"><span class="hs-identifier hs-var">queryEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim queryEmbedDim
</span><a href="#local-6989586621679768844"><span class="hs-identifier hs-var">queryEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim queryEmbedDim
</span><a href="#local-6989586621679768844"><span class="hs-identifier hs-var">queryEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">dropoutP
</span><a href="#local-6989586621679768843"><span class="hs-identifier hs-var">dropoutP</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679768841"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;SelfAttention.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-190"></span><span>        </span><span class="annot"><a href="#local-6989586621679768840"><span class="hs-identifier hs-var">multiHeadAttention</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(SGradient gradient, SDevice device, SDataType dataType,
 SDim headDim, SDim headEmbedDim, SDim embedDim, SDim queryEmbedDim,
 SDim queryEmbedDim, SDim queryEmbedDim, dropoutP)
-&gt; StateDictKey
-&gt; m (MultiHeadAttention
        'BART
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        queryEmbedDim
        queryEmbedDim
        queryEmbedDim
        dropoutP)
forall model input (m :: Type -&gt; Type).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
input -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679768850"><span class="hs-identifier hs-var">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679768849"><span class="hs-identifier hs-var">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679768848"><span class="hs-identifier hs-var">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim headDim
</span><a href="#local-6989586621679768847"><span class="hs-identifier hs-var">headDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim headEmbedDim
</span><a href="#local-6989586621679768846"><span class="hs-identifier hs-var">headEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim embedDim
</span><a href="#local-6989586621679768845"><span class="hs-identifier hs-var">embedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim queryEmbedDim
</span><a href="#local-6989586621679768844"><span class="hs-identifier hs-var">queryEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim queryEmbedDim
</span><a href="#local-6989586621679768844"><span class="hs-identifier hs-var">queryEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim queryEmbedDim
</span><a href="#local-6989586621679768844"><span class="hs-identifier hs-var">queryEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">dropoutP
</span><a href="#local-6989586621679768843"><span class="hs-identifier hs-var">dropoutP</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679768841"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;self_attn.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-191"></span><span>        </span><span class="annot"><a href="#local-6989586621679768840"><span class="hs-identifier hs-var">multiHeadAttention</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(SGradient gradient, SDevice device, SDataType dataType,
 SDim headDim, SDim headEmbedDim, SDim embedDim, SDim queryEmbedDim,
 SDim queryEmbedDim, SDim queryEmbedDim, dropoutP)
-&gt; StateDictKey
-&gt; m (MultiHeadAttention
        'MBART
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        queryEmbedDim
        queryEmbedDim
        queryEmbedDim
        dropoutP)
forall model input (m :: Type -&gt; Type).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
input -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679768850"><span class="hs-identifier hs-var">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679768849"><span class="hs-identifier hs-var">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679768848"><span class="hs-identifier hs-var">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim headDim
</span><a href="#local-6989586621679768847"><span class="hs-identifier hs-var">headDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim headEmbedDim
</span><a href="#local-6989586621679768846"><span class="hs-identifier hs-var">headEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim embedDim
</span><a href="#local-6989586621679768845"><span class="hs-identifier hs-var">embedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim queryEmbedDim
</span><a href="#local-6989586621679768844"><span class="hs-identifier hs-var">queryEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim queryEmbedDim
</span><a href="#local-6989586621679768844"><span class="hs-identifier hs-var">queryEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim queryEmbedDim
</span><a href="#local-6989586621679768844"><span class="hs-identifier hs-var">queryEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">dropoutP
</span><a href="#local-6989586621679768843"><span class="hs-identifier hs-var">dropoutP</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679768841"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;self_attn.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-192"></span><span>        </span><span class="annot"><a href="#local-6989586621679768840"><span class="hs-identifier hs-var">multiHeadAttention</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(SGradient gradient, SDevice device, SDataType dataType,
 SDim headDim, SDim headEmbedDim, SDim embedDim, SDim queryEmbedDim,
 SDim queryEmbedDim, SDim queryEmbedDim, dropoutP)
-&gt; StateDictKey
-&gt; m (MultiHeadAttention
        'Pegasus
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        queryEmbedDim
        queryEmbedDim
        queryEmbedDim
        dropoutP)
forall model input (m :: Type -&gt; Type).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
input -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679768850"><span class="hs-identifier hs-var">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679768849"><span class="hs-identifier hs-var">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679768848"><span class="hs-identifier hs-var">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim headDim
</span><a href="#local-6989586621679768847"><span class="hs-identifier hs-var">headDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim headEmbedDim
</span><a href="#local-6989586621679768846"><span class="hs-identifier hs-var">headEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim embedDim
</span><a href="#local-6989586621679768845"><span class="hs-identifier hs-var">embedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim queryEmbedDim
</span><a href="#local-6989586621679768844"><span class="hs-identifier hs-var">queryEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim queryEmbedDim
</span><a href="#local-6989586621679768844"><span class="hs-identifier hs-var">queryEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim queryEmbedDim
</span><a href="#local-6989586621679768844"><span class="hs-identifier hs-var">queryEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">dropoutP
</span><a href="#local-6989586621679768843"><span class="hs-identifier hs-var">dropoutP</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679768841"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;self_attn.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-193"></span><span>        </span><span class="annot"><a href="#local-6989586621679768840"><span class="hs-identifier hs-var">multiHeadAttention</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(SGradient gradient, SDevice device, SDataType dataType,
 SDim headDim, SDim headEmbedDim, SDim embedDim, SDim queryEmbedDim,
 SDim queryEmbedDim, SDim queryEmbedDim, dropoutP)
-&gt; StateDictKey
-&gt; m (MultiHeadAttention
        'BERT
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        queryEmbedDim
        queryEmbedDim
        queryEmbedDim
        dropoutP)
forall model input (m :: Type -&gt; Type).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
input -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679768850"><span class="hs-identifier hs-var">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679768849"><span class="hs-identifier hs-var">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679768848"><span class="hs-identifier hs-var">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim headDim
</span><a href="#local-6989586621679768847"><span class="hs-identifier hs-var">headDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim headEmbedDim
</span><a href="#local-6989586621679768846"><span class="hs-identifier hs-var">headEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim embedDim
</span><a href="#local-6989586621679768845"><span class="hs-identifier hs-var">embedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim queryEmbedDim
</span><a href="#local-6989586621679768844"><span class="hs-identifier hs-var">queryEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim queryEmbedDim
</span><a href="#local-6989586621679768844"><span class="hs-identifier hs-var">queryEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim queryEmbedDim
</span><a href="#local-6989586621679768844"><span class="hs-identifier hs-var">queryEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">dropoutP
</span><a href="#local-6989586621679768843"><span class="hs-identifier hs-var">dropoutP</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679768841"><span class="hs-identifier hs-var">k</span></a></span><span>
</span><span id="line-194"></span><span>        </span><span class="annot"><a href="#local-6989586621679768840"><span class="hs-identifier hs-var">multiHeadAttention</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(SGradient gradient, SDevice device, SDataType dataType,
 SDim headDim, SDim headEmbedDim, SDim embedDim, SDim queryEmbedDim,
 SDim queryEmbedDim, SDim queryEmbedDim, dropoutP)
-&gt; StateDictKey
-&gt; m (MultiHeadAttention
        'RoBERTa
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        queryEmbedDim
        queryEmbedDim
        queryEmbedDim
        dropoutP)
forall model input (m :: Type -&gt; Type).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
input -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679768850"><span class="hs-identifier hs-var">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679768849"><span class="hs-identifier hs-var">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679768848"><span class="hs-identifier hs-var">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim headDim
</span><a href="#local-6989586621679768847"><span class="hs-identifier hs-var">headDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim headEmbedDim
</span><a href="#local-6989586621679768846"><span class="hs-identifier hs-var">headEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim embedDim
</span><a href="#local-6989586621679768845"><span class="hs-identifier hs-var">embedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim queryEmbedDim
</span><a href="#local-6989586621679768844"><span class="hs-identifier hs-var">queryEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim queryEmbedDim
</span><a href="#local-6989586621679768844"><span class="hs-identifier hs-var">queryEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim queryEmbedDim
</span><a href="#local-6989586621679768844"><span class="hs-identifier hs-var">queryEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">dropoutP
</span><a href="#local-6989586621679768843"><span class="hs-identifier hs-var">dropoutP</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679768841"><span class="hs-identifier hs-var">k</span></a></span><span>
</span><span id="line-195"></span><span>        </span><span class="annot"><a href="#local-6989586621679768840"><span class="hs-identifier hs-var">multiHeadAttention</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SGPT2"><span class="hs-identifier hs-var">SGPT2</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">m (MultiHeadAttention
     style
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     queryEmbedDim
     queryEmbedDim
     dropoutP)
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-196"></span><span>        </span><span id="local-6989586621679768830"><span class="annot"><span class="annottext">layerNorm :: STransformerStyle style
-&gt; m (SALayerNormF style gradient device dataType queryEmbedDim)
</span><a href="#local-6989586621679768830"><span class="hs-identifier hs-var hs-var">layerNorm</span></a></span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(SGradient gradient, SDevice device, SDataType dataType,
 SShape ('Shape '[queryEmbedDim]), Double)
-&gt; StateDictKey
-&gt; m (LayerNorm
        'WithoutBias gradient device dataType ('Shape '[queryEmbedDim]))
forall model input (m :: Type -&gt; Type).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
input -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679768850"><span class="hs-identifier hs-var">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679768849"><span class="hs-identifier hs-var">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679768848"><span class="hs-identifier hs-var">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SList '[queryEmbedDim] -&gt; SShape ('Shape '[queryEmbedDim])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList '[queryEmbedDim] -&gt; SShape ('Shape '[queryEmbedDim]))
-&gt; SList '[queryEmbedDim] -&gt; SShape ('Shape '[queryEmbedDim])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SDim queryEmbedDim
</span><a href="#local-6989586621679768844"><span class="hs-identifier hs-var">queryEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim queryEmbedDim -&gt; SList '[] -&gt; SList '[queryEmbedDim]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679768842"><span class="hs-identifier hs-var">eps</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679768841"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;layer_norm.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-197"></span><span>        </span><span class="annot"><a href="#local-6989586621679768830"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(SGradient gradient, SDevice device, SDataType dataType,
 SShape ('Shape '[queryEmbedDim]), Double)
-&gt; StateDictKey
-&gt; m (LayerNorm
        'WithoutBias gradient device dataType ('Shape '[queryEmbedDim]))
forall model input (m :: Type -&gt; Type).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
input -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679768850"><span class="hs-identifier hs-var">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679768849"><span class="hs-identifier hs-var">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679768848"><span class="hs-identifier hs-var">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SList '[queryEmbedDim] -&gt; SShape ('Shape '[queryEmbedDim])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList '[queryEmbedDim] -&gt; SShape ('Shape '[queryEmbedDim]))
-&gt; SList '[queryEmbedDim] -&gt; SShape ('Shape '[queryEmbedDim])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SDim queryEmbedDim
</span><a href="#local-6989586621679768844"><span class="hs-identifier hs-var">queryEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim queryEmbedDim -&gt; SList '[] -&gt; SList '[queryEmbedDim]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679768842"><span class="hs-identifier hs-var">eps</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679768841"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;layer_norm.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-198"></span><span>        </span><span class="annot"><a href="#local-6989586621679768830"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(SGradient gradient, SDevice device, SDataType dataType,
 SShape ('Shape '[queryEmbedDim]), Double)
-&gt; StateDictKey
-&gt; m (LayerNorm
        'WithBias gradient device dataType ('Shape '[queryEmbedDim]))
forall model input (m :: Type -&gt; Type).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
input -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679768850"><span class="hs-identifier hs-var">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679768849"><span class="hs-identifier hs-var">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679768848"><span class="hs-identifier hs-var">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SList '[queryEmbedDim] -&gt; SShape ('Shape '[queryEmbedDim])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList '[queryEmbedDim] -&gt; SShape ('Shape '[queryEmbedDim]))
-&gt; SList '[queryEmbedDim] -&gt; SShape ('Shape '[queryEmbedDim])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SDim queryEmbedDim
</span><a href="#local-6989586621679768844"><span class="hs-identifier hs-var">queryEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim queryEmbedDim -&gt; SList '[] -&gt; SList '[queryEmbedDim]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679768842"><span class="hs-identifier hs-var">eps</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679768841"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;self_attn_layer_norm.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-199"></span><span>        </span><span class="annot"><a href="#local-6989586621679768830"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(SGradient gradient, SDevice device, SDataType dataType,
 SShape ('Shape '[queryEmbedDim]), Double)
-&gt; StateDictKey
-&gt; m (LayerNorm
        'WithBias gradient device dataType ('Shape '[queryEmbedDim]))
forall model input (m :: Type -&gt; Type).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
input -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679768850"><span class="hs-identifier hs-var">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679768849"><span class="hs-identifier hs-var">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679768848"><span class="hs-identifier hs-var">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SList '[queryEmbedDim] -&gt; SShape ('Shape '[queryEmbedDim])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList '[queryEmbedDim] -&gt; SShape ('Shape '[queryEmbedDim]))
-&gt; SList '[queryEmbedDim] -&gt; SShape ('Shape '[queryEmbedDim])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SDim queryEmbedDim
</span><a href="#local-6989586621679768844"><span class="hs-identifier hs-var">queryEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim queryEmbedDim -&gt; SList '[] -&gt; SList '[queryEmbedDim]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679768842"><span class="hs-identifier hs-var">eps</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679768841"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;self_attn_layer_norm.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-200"></span><span>        </span><span class="annot"><a href="#local-6989586621679768830"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(SGradient gradient, SDevice device, SDataType dataType,
 SShape ('Shape '[queryEmbedDim]), Double)
-&gt; StateDictKey
-&gt; m (LayerNorm
        'WithBias gradient device dataType ('Shape '[queryEmbedDim]))
forall model input (m :: Type -&gt; Type).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
input -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679768850"><span class="hs-identifier hs-var">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679768849"><span class="hs-identifier hs-var">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679768848"><span class="hs-identifier hs-var">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SList '[queryEmbedDim] -&gt; SShape ('Shape '[queryEmbedDim])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList '[queryEmbedDim] -&gt; SShape ('Shape '[queryEmbedDim]))
-&gt; SList '[queryEmbedDim] -&gt; SShape ('Shape '[queryEmbedDim])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SDim queryEmbedDim
</span><a href="#local-6989586621679768844"><span class="hs-identifier hs-var">queryEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim queryEmbedDim -&gt; SList '[] -&gt; SList '[queryEmbedDim]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679768842"><span class="hs-identifier hs-var">eps</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679768841"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;self_attn_layer_norm.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-201"></span><span>        </span><span class="annot"><a href="#local-6989586621679768830"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(SGradient gradient, SDevice device, SDataType dataType,
 SShape ('Shape '[queryEmbedDim]), Double)
-&gt; StateDictKey
-&gt; m (LayerNorm
        'WithBias gradient device dataType ('Shape '[queryEmbedDim]))
forall model input (m :: Type -&gt; Type).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
input -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679768850"><span class="hs-identifier hs-var">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679768849"><span class="hs-identifier hs-var">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679768848"><span class="hs-identifier hs-var">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SList '[queryEmbedDim] -&gt; SShape ('Shape '[queryEmbedDim])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList '[queryEmbedDim] -&gt; SShape ('Shape '[queryEmbedDim]))
-&gt; SList '[queryEmbedDim] -&gt; SShape ('Shape '[queryEmbedDim])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SDim queryEmbedDim
</span><a href="#local-6989586621679768844"><span class="hs-identifier hs-var">queryEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim queryEmbedDim -&gt; SList '[] -&gt; SList '[queryEmbedDim]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679768842"><span class="hs-identifier hs-var">eps</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679768841"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;output.LayerNorm.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-202"></span><span>        </span><span class="annot"><a href="#local-6989586621679768830"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(SGradient gradient, SDevice device, SDataType dataType,
 SShape ('Shape '[queryEmbedDim]), Double)
-&gt; StateDictKey
-&gt; m (LayerNorm
        'WithBias gradient device dataType ('Shape '[queryEmbedDim]))
forall model input (m :: Type -&gt; Type).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
input -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679768850"><span class="hs-identifier hs-var">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679768849"><span class="hs-identifier hs-var">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679768848"><span class="hs-identifier hs-var">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SList '[queryEmbedDim] -&gt; SShape ('Shape '[queryEmbedDim])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList '[queryEmbedDim] -&gt; SShape ('Shape '[queryEmbedDim]))
-&gt; SList '[queryEmbedDim] -&gt; SShape ('Shape '[queryEmbedDim])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SDim queryEmbedDim
</span><a href="#local-6989586621679768844"><span class="hs-identifier hs-var">queryEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim queryEmbedDim -&gt; SList '[] -&gt; SList '[queryEmbedDim]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679768842"><span class="hs-identifier hs-var">eps</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679768841"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;output.LayerNorm.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-203"></span><span>        </span><span class="annot"><a href="#local-6989586621679768830"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SGPT2"><span class="hs-identifier hs-var">SGPT2</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">m (SALayerNormF style gradient device dataType queryEmbedDim)
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-204"></span><span>        </span><span id="local-6989586621679768829"><span class="annot"><span class="annottext">dropout :: STransformerStyle style -&gt; m (Dropout dropoutP)
</span><a href="#local-6989586621679768829"><span class="hs-identifier hs-var hs-var">dropout</span></a></span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">dropoutP -&gt; StateDictKey -&gt; m (Dropout dropoutP)
forall model input (m :: Type -&gt; Type).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
input -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">dropoutP
</span><a href="#local-6989586621679768843"><span class="hs-identifier hs-var">dropoutP</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679768841"><span class="hs-identifier hs-var">k</span></a></span><span>
</span><span id="line-205"></span><span>     </span><span class="hs-keyword">in</span><span> </span><span class="annot"><span class="annottext">GSelfAttention
  (MultiHeadAttention
     style
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     queryEmbedDim
     queryEmbedDim
     dropoutP)
  (SALayerNormF style gradient device dataType queryEmbedDim)
  (Dropout dropoutP)
-&gt; SelfAttention
     style
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     dropoutP
forall (style :: TransformerStyle)
       (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (headDim :: Dim (Name Symbol) (Size Nat))
       (headEmbedDim :: Dim (Name Symbol) (Size Nat))
       (embedDim :: Dim (Name Symbol) (Size Nat))
       (queryEmbedDim :: Dim (Name Symbol) (Size Nat)) dropoutP.
GSelfAttention
  (SAMultiheadAttentionF
     style
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     dropoutP)
  (SALayerNormF style gradient device dataType queryEmbedDim)
  (SADropoutF style dropoutP)
-&gt; SelfAttention
     style
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     dropoutP
</span><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#SelfAttention"><span class="hs-identifier hs-var">SelfAttention</span></a></span><span>
</span><span id="line-206"></span><span>          </span><span class="annot"><span class="annottext">(GSelfAttention
   (MultiHeadAttention
      style
      gradient
      device
      dataType
      headDim
      headEmbedDim
      embedDim
      queryEmbedDim
      queryEmbedDim
      queryEmbedDim
      dropoutP)
   (SALayerNormF style gradient device dataType queryEmbedDim)
   (Dropout dropoutP)
 -&gt; SelfAttention
      style
      gradient
      device
      dataType
      headDim
      headEmbedDim
      embedDim
      queryEmbedDim
      dropoutP)
-&gt; m (GSelfAttention
        (MultiHeadAttention
           style
           gradient
           device
           dataType
           headDim
           headEmbedDim
           embedDim
           queryEmbedDim
           queryEmbedDim
           queryEmbedDim
           dropoutP)
        (SALayerNormF style gradient device dataType queryEmbedDim)
        (Dropout dropoutP))
-&gt; m (SelfAttention
        style
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        queryEmbedDim
        dropoutP)
forall (f :: Type -&gt; Type) a b. Functor f =&gt; (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;$&gt;</span></span><span> </span><span class="hs-special">(</span><span> </span><span class="annot"><span class="annottext">MultiHeadAttention
  style
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  queryEmbedDim
  queryEmbedDim
  queryEmbedDim
  dropoutP
-&gt; SALayerNormF style gradient device dataType queryEmbedDim
-&gt; Dropout dropoutP
-&gt; GSelfAttention
     (MultiHeadAttention
        style
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        queryEmbedDim
        queryEmbedDim
        queryEmbedDim
        dropoutP)
     (SALayerNormF style gradient device dataType queryEmbedDim)
     (Dropout dropoutP)
forall mha layerNorm dropout.
mha -&gt; layerNorm -&gt; dropout -&gt; GSelfAttention mha layerNorm dropout
</span><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#GSelfAttention"><span class="hs-identifier hs-var">GSelfAttention</span></a></span><span>
</span><span id="line-207"></span><span>                  </span><span class="annot"><span class="annottext">(MultiHeadAttention
   style
   gradient
   device
   dataType
   headDim
   headEmbedDim
   embedDim
   queryEmbedDim
   queryEmbedDim
   queryEmbedDim
   dropoutP
 -&gt; SALayerNormF style gradient device dataType queryEmbedDim
 -&gt; Dropout dropoutP
 -&gt; GSelfAttention
      (MultiHeadAttention
         style
         gradient
         device
         dataType
         headDim
         headEmbedDim
         embedDim
         queryEmbedDim
         queryEmbedDim
         queryEmbedDim
         dropoutP)
      (SALayerNormF style gradient device dataType queryEmbedDim)
      (Dropout dropoutP))
-&gt; m (MultiHeadAttention
        style
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        queryEmbedDim
        queryEmbedDim
        queryEmbedDim
        dropoutP)
-&gt; m (SALayerNormF style gradient device dataType queryEmbedDim
      -&gt; Dropout dropoutP
      -&gt; GSelfAttention
           (MultiHeadAttention
              style
              gradient
              device
              dataType
              headDim
              headEmbedDim
              embedDim
              queryEmbedDim
              queryEmbedDim
              queryEmbedDim
              dropoutP)
           (SALayerNormF style gradient device dataType queryEmbedDim)
           (Dropout dropoutP))
forall (f :: Type -&gt; Type) a b. Functor f =&gt; (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;$&gt;</span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; m (MultiHeadAttention
        style
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        queryEmbedDim
        queryEmbedDim
        queryEmbedDim
        dropoutP)
</span><a href="#local-6989586621679768840"><span class="hs-identifier hs-var">multiHeadAttention</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SingI style =&gt; Sing style
forall k (a :: k). SingI a =&gt; Sing a
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">sing</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679768864"><span class="hs-identifier hs-type">style</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-208"></span><span>                  </span><span class="annot"><span class="annottext">m (SALayerNormF style gradient device dataType queryEmbedDim
   -&gt; Dropout dropoutP
   -&gt; GSelfAttention
        (MultiHeadAttention
           style
           gradient
           device
           dataType
           headDim
           headEmbedDim
           embedDim
           queryEmbedDim
           queryEmbedDim
           queryEmbedDim
           dropoutP)
        (SALayerNormF style gradient device dataType queryEmbedDim)
        (Dropout dropoutP))
-&gt; m (SALayerNormF style gradient device dataType queryEmbedDim)
-&gt; m (Dropout dropoutP
      -&gt; GSelfAttention
           (MultiHeadAttention
              style
              gradient
              device
              dataType
              headDim
              headEmbedDim
              embedDim
              queryEmbedDim
              queryEmbedDim
              queryEmbedDim
              dropoutP)
           (SALayerNormF style gradient device dataType queryEmbedDim)
           (Dropout dropoutP))
forall (f :: Type -&gt; Type) a b.
Applicative f =&gt;
f (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;*&gt;</span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; m (SALayerNormF style gradient device dataType queryEmbedDim)
</span><a href="#local-6989586621679768830"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SingI style =&gt; Sing style
forall k (a :: k). SingI a =&gt; Sing a
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">sing</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679768864"><span class="hs-identifier hs-type">style</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-209"></span><span>                  </span><span class="annot"><span class="annottext">m (Dropout dropoutP
   -&gt; GSelfAttention
        (MultiHeadAttention
           style
           gradient
           device
           dataType
           headDim
           headEmbedDim
           embedDim
           queryEmbedDim
           queryEmbedDim
           queryEmbedDim
           dropoutP)
        (SALayerNormF style gradient device dataType queryEmbedDim)
        (Dropout dropoutP))
-&gt; m (Dropout dropoutP)
-&gt; m (GSelfAttention
        (MultiHeadAttention
           style
           gradient
           device
           dataType
           headDim
           headEmbedDim
           embedDim
           queryEmbedDim
           queryEmbedDim
           queryEmbedDim
           dropoutP)
        (SALayerNormF style gradient device dataType queryEmbedDim)
        (Dropout dropoutP))
forall (f :: Type -&gt; Type) a b.
Applicative f =&gt;
f (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;*&gt;</span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style -&gt; m (Dropout dropoutP)
</span><a href="#local-6989586621679768829"><span class="hs-identifier hs-var">dropout</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SingI style =&gt; Sing style
forall k (a :: k). SingI a =&gt; Sing a
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">sing</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679768864"><span class="hs-identifier hs-type">style</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-210"></span><span>              </span><span class="hs-special">)</span><span>
</span><span id="line-211"></span><span>  </span><span id="local-6989586621679768827"><span class="annot"><span class="annottext">toStateDict :: StateDictKey
-&gt; SelfAttention
     style
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     dropoutP
-&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var hs-var hs-var hs-var">toStateDict</span></a></span></span><span> </span><span id="local-6989586621679768825"><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679768825"><span class="hs-identifier hs-var">k</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#SelfAttention"><span class="hs-identifier hs-type">SelfAttention</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#GSelfAttention"><span class="hs-identifier hs-type">GSelfAttention</span></a></span><span> </span><span class="hs-special">{</span><span id="local-6989586621679768822"><span id="local-6989586621679768823"><span id="local-6989586621679768824"><span class="annot"><span class="annottext">SADropoutF style dropoutP
SALayerNormF style gradient device dataType queryEmbedDim
SAMultiheadAttentionF
  style
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  queryEmbedDim
  dropoutP
saDropout :: SADropoutF style dropoutP
saLayerNorm :: SALayerNormF style gradient device dataType queryEmbedDim
saMultiHeadAttention :: SAMultiheadAttentionF
  style
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  queryEmbedDim
  dropoutP
saDropout :: forall mha layerNorm dropout.
GSelfAttention mha layerNorm dropout -&gt; dropout
saLayerNorm :: forall mha layerNorm dropout.
GSelfAttention mha layerNorm dropout -&gt; layerNorm
saMultiHeadAttention :: forall mha layerNorm dropout.
GSelfAttention mha layerNorm dropout -&gt; mha
</span><a href="#local-6989586621679768822"><span class="hs-glyph hs-var hs-var hs-var hs-var hs-var hs-var">..</span></a></span></span></span></span><span class="hs-special">}</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-212"></span><span>    </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679768821"><span class="annot"><span class="annottext">multiHeadAttention :: STransformerStyle style
-&gt; MultiHeadAttention
     style
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     queryEmbedDim
     queryEmbedDim
     dropoutP
-&gt; m ()
</span><a href="#local-6989586621679768821"><span class="hs-identifier hs-var hs-var">multiHeadAttention</span></a></span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; MultiHeadAttention
     'T5
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     queryEmbedDim
     queryEmbedDim
     dropoutP
-&gt; m ()
forall model input (m :: Type -&gt; Type).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679768825"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;SelfAttention.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-213"></span><span>        </span><span class="annot"><a href="#local-6989586621679768821"><span class="hs-identifier hs-var">multiHeadAttention</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; MultiHeadAttention
     'ByT5
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     queryEmbedDim
     queryEmbedDim
     dropoutP
-&gt; m ()
forall model input (m :: Type -&gt; Type).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679768825"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;SelfAttention.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-214"></span><span>        </span><span class="annot"><a href="#local-6989586621679768821"><span class="hs-identifier hs-var">multiHeadAttention</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; MultiHeadAttention
     'BART
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     queryEmbedDim
     queryEmbedDim
     dropoutP
-&gt; m ()
forall model input (m :: Type -&gt; Type).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679768825"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;self_attn.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-215"></span><span>        </span><span class="annot"><a href="#local-6989586621679768821"><span class="hs-identifier hs-var">multiHeadAttention</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; MultiHeadAttention
     'MBART
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     queryEmbedDim
     queryEmbedDim
     dropoutP
-&gt; m ()
forall model input (m :: Type -&gt; Type).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679768825"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;self_attn.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-216"></span><span>        </span><span class="annot"><a href="#local-6989586621679768821"><span class="hs-identifier hs-var">multiHeadAttention</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; MultiHeadAttention
     'Pegasus
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     queryEmbedDim
     queryEmbedDim
     dropoutP
-&gt; m ()
forall model input (m :: Type -&gt; Type).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679768825"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;self_attn.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-217"></span><span>        </span><span class="annot"><a href="#local-6989586621679768821"><span class="hs-identifier hs-var">multiHeadAttention</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; MultiHeadAttention
     'BERT
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     queryEmbedDim
     queryEmbedDim
     dropoutP
-&gt; m ()
forall model input (m :: Type -&gt; Type).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679768825"><span class="hs-identifier hs-var">k</span></a></span><span>
</span><span id="line-218"></span><span>        </span><span class="annot"><a href="#local-6989586621679768821"><span class="hs-identifier hs-var">multiHeadAttention</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; MultiHeadAttention
     'RoBERTa
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     queryEmbedDim
     queryEmbedDim
     dropoutP
-&gt; m ()
forall model input (m :: Type -&gt; Type).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679768825"><span class="hs-identifier hs-var">k</span></a></span><span>
</span><span id="line-219"></span><span>        </span><span class="annot"><a href="#local-6989586621679768821"><span class="hs-identifier hs-var">multiHeadAttention</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SGPT2"><span class="hs-identifier hs-var">SGPT2</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">MultiHeadAttention
  style
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  queryEmbedDim
  queryEmbedDim
  queryEmbedDim
  dropoutP
-&gt; m ()
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-220"></span><span>        </span><span id="local-6989586621679768820"><span class="annot"><span class="annottext">layerNorm :: STransformerStyle style
-&gt; SALayerNormF style gradient device dataType queryEmbedDim
-&gt; m ()
</span><a href="#local-6989586621679768820"><span class="hs-identifier hs-var hs-var">layerNorm</span></a></span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; LayerNorm
     'WithoutBias gradient device dataType ('Shape '[queryEmbedDim])
-&gt; m ()
forall model input (m :: Type -&gt; Type).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679768825"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;layer_norm.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-221"></span><span>        </span><span class="annot"><a href="#local-6989586621679768820"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; LayerNorm
     'WithoutBias gradient device dataType ('Shape '[queryEmbedDim])
-&gt; m ()
forall model input (m :: Type -&gt; Type).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679768825"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;layer_norm.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-222"></span><span>        </span><span class="annot"><a href="#local-6989586621679768820"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; LayerNorm
     'WithBias gradient device dataType ('Shape '[queryEmbedDim])
-&gt; m ()
forall model input (m :: Type -&gt; Type).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679768825"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;self_attn_layer_norm.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-223"></span><span>        </span><span class="annot"><a href="#local-6989586621679768820"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; LayerNorm
     'WithBias gradient device dataType ('Shape '[queryEmbedDim])
-&gt; m ()
forall model input (m :: Type -&gt; Type).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679768825"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;self_attn_layer_norm.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-224"></span><span>        </span><span class="annot"><a href="#local-6989586621679768820"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; LayerNorm
     'WithBias gradient device dataType ('Shape '[queryEmbedDim])
-&gt; m ()
forall model input (m :: Type -&gt; Type).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679768825"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;self_attn_layer_norm.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-225"></span><span>        </span><span class="annot"><a href="#local-6989586621679768820"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; LayerNorm
     'WithBias gradient device dataType ('Shape '[queryEmbedDim])
-&gt; m ()
forall model input (m :: Type -&gt; Type).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679768825"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;output.LayerNorm.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-226"></span><span>        </span><span class="annot"><a href="#local-6989586621679768820"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; LayerNorm
     'WithBias gradient device dataType ('Shape '[queryEmbedDim])
-&gt; m ()
forall model input (m :: Type -&gt; Type).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679768825"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;output.LayerNorm.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-227"></span><span>        </span><span class="annot"><a href="#local-6989586621679768820"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SGPT2"><span class="hs-identifier hs-var">SGPT2</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SALayerNormF style gradient device dataType queryEmbedDim -&gt; m ()
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-228"></span><span>        </span><span id="local-6989586621679768819"><span class="annot"><span class="annottext">dropout :: STransformerStyle style -&gt; Dropout dropoutP -&gt; m ()
</span><a href="#local-6989586621679768819"><span class="hs-identifier hs-var hs-var">dropout</span></a></span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; Dropout dropoutP -&gt; m ()
forall model input (m :: Type -&gt; Type).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679768825"><span class="hs-identifier hs-var">k</span></a></span><span>
</span><span id="line-229"></span><span>     </span><span class="hs-keyword">in</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-230"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; MultiHeadAttention
     style
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     queryEmbedDim
     queryEmbedDim
     dropoutP
-&gt; m ()
</span><a href="#local-6989586621679768821"><span class="hs-identifier hs-var">multiHeadAttention</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SingI style =&gt; Sing style
forall k (a :: k). SingI a =&gt; Sing a
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">sing</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679768864"><span class="hs-identifier hs-type">style</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">MultiHeadAttention
  style
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  queryEmbedDim
  queryEmbedDim
  queryEmbedDim
  dropoutP
SAMultiheadAttentionF
  style
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  queryEmbedDim
  dropoutP
</span><a href="#local-6989586621679768824"><span class="hs-identifier hs-var">saMultiHeadAttention</span></a></span><span>
</span><span id="line-231"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; SALayerNormF style gradient device dataType queryEmbedDim
-&gt; m ()
</span><a href="#local-6989586621679768820"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SingI style =&gt; Sing style
forall k (a :: k). SingI a =&gt; Sing a
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">sing</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679768864"><span class="hs-identifier hs-type">style</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">SALayerNormF style gradient device dataType queryEmbedDim
</span><a href="#local-6989586621679768823"><span class="hs-identifier hs-var">saLayerNorm</span></a></span><span>
</span><span id="line-232"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">STransformerStyle style -&gt; Dropout dropoutP -&gt; m ()
</span><a href="#local-6989586621679768819"><span class="hs-identifier hs-var">dropout</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SingI style =&gt; Sing style
forall k (a :: k). SingI a =&gt; Sing a
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">sing</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679768864"><span class="hs-identifier hs-type">style</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Dropout dropoutP
SADropoutF style dropoutP
</span><a href="#local-6989586621679768822"><span class="hs-identifier hs-var">saDropout</span></a></span><span>
</span><span id="line-233"></span><span>          </span><span class="annot"><span class="annottext">() -&gt; m ()
forall (f :: Type -&gt; Type) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span></span></span></span></span></span></span></span></span></span><span>
</span><span id="line-234"></span><span>
</span><span id="line-235"></span><span class="hs-comment">-- | 'HasForward' instance for @SelfAttention 'T5@.</span><span>
</span><span id="line-236"></span><span class="hs-comment">--</span><span>
</span><span id="line-237"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-238"></span><span class="hs-comment">-- &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;     &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;</span><span>
</span><span id="line-239"></span><span class="hs-comment">-- &#9474; attentionBias &#9474;     &#9474; query &#9474;</span><span>
</span><span id="line-240"></span><span class="hs-comment">-- &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;     &#9492;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-241"></span><span class="hs-comment">--         &#9474;                 &#9474;</span><span>
</span><span id="line-242"></span><span class="hs-comment">--         &#9474;           &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9524;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;</span><span>
</span><span id="line-243"></span><span class="hs-comment">--         &#9474;           &#9474;           &#9474;</span><span>
</span><span id="line-244"></span><span class="hs-comment">--         &#9474;           &#9660;           &#9474;</span><span>
</span><span id="line-245"></span><span class="hs-comment">--         &#9474;      saLayerNorm      &#9474;</span><span>
</span><span id="line-246"></span><span class="hs-comment">--         &#9474;           &#9474;           &#9474;</span><span>
</span><span id="line-247"></span><span class="hs-comment">--         &#9474;      &#9484;&#9472;&#9472;&#9472;&#9472;&#9532;&#9472;&#9472;&#9472;&#9472;&#9488;      &#9474;</span><span>
</span><span id="line-248"></span><span class="hs-comment">--         &#9474;      &#9474;    &#9474;    &#9474;      &#9474;</span><span>
</span><span id="line-249"></span><span class="hs-comment">--         &#9474;      &#9660;    &#9660;    &#9660;      &#9474;</span><span>
</span><span id="line-250"></span><span class="hs-comment">--         &#9492;&#9472;&#9658;saMultiHeadAttention &#9474;</span><span>
</span><span id="line-251"></span><span class="hs-comment">--                     &#9474;           &#9474;</span><span>
</span><span id="line-252"></span><span class="hs-comment">--                     &#9660;           &#9474;</span><span>
</span><span id="line-253"></span><span class="hs-comment">--                 saDropout       &#9474;</span><span>
</span><span id="line-254"></span><span class="hs-comment">--                     &#9474;           &#9474;</span><span>
</span><span id="line-255"></span><span class="hs-comment">--                     &#9492;&#9472;&#9472;&#9472;&#9658;add&#9668;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-256"></span><span class="hs-comment">--                           &#9474;</span><span>
</span><span id="line-257"></span><span class="hs-comment">--                           &#9660;</span><span>
</span><span id="line-258"></span><span class="hs-comment">--                       &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;</span><span>
</span><span id="line-259"></span><span class="hs-comment">--                       &#9474; query &#9474;</span><span>
</span><span id="line-260"></span><span class="hs-comment">--                       &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-261"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-262"></span><span id="local-6989586621679768792"><span id="local-6989586621679768793"><span id="local-6989586621679768794"><span id="local-6989586621679768795"><span id="local-6989586621679768796"><span id="local-6989586621679768797"><span id="local-6989586621679768798"><span id="local-6989586621679768799"><span id="local-6989586621679768800"><span id="local-6989586621679768801"><span id="local-6989586621679768802"><span id="local-6989586621679768803"><span id="local-6989586621679768804"><span id="local-6989586621679768805"><span id="local-6989586621679768806"><span id="local-6989586621679768807"><span id="local-6989586621679768808"><span id="local-6989586621679768809"><span id="local-6989586621679768810"><span id="local-6989586621679768811"><span id="local-6989586621679768812"><span id="local-6989586621679768813"><span id="local-6989586621679768814"><span id="local-6989586621679768815"><span id="local-6989586621679768816"><span id="local-6989586621679768817"><span id="local-6989586621679768818"><span class="hs-keyword">instance</span><span>
</span><span id="line-263"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetDim"><span class="hs-identifier hs-type">SGetDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768818"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-264"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Scalar.html#Scalar"><span class="hs-identifier hs-type">Scalar</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768817"><span class="hs-identifier hs-type">dropoutP</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-265"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-266"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#SALayerNormF"><span class="hs-identifier hs-type">SALayerNormF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#T5"><span class="hs-identifier hs-type">T5</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768816"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768815"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768814"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768818"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-267"></span><span>      </span><span class="annot"><a href="#local-6989586621679768813"><span class="hs-identifier hs-type">query</span></a></span><span>
</span><span id="line-268"></span><span>      </span><span class="annot"><a href="#local-6989586621679768812"><span class="hs-identifier hs-type">generator</span></a></span><span>
</span><span id="line-269"></span><span>      </span><span class="annot"><a href="#local-6989586621679768811"><span class="hs-identifier hs-type">layerNormOutput</span></a></span><span>
</span><span id="line-270"></span><span>      </span><span class="annot"><a href="#local-6989586621679768812"><span class="hs-identifier hs-type">generator</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-271"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-272"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#SAMultiheadAttentionF"><span class="hs-identifier hs-type">SAMultiheadAttentionF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#T5"><span class="hs-identifier hs-type">T5</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768816"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768815"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768814"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768810"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768809"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768808"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768818"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768817"><span class="hs-identifier hs-type">dropoutP</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-273"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679768811"><span class="hs-identifier hs-type">layerNormOutput</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679768811"><span class="hs-identifier hs-type">layerNormOutput</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679768811"><span class="hs-identifier hs-type">layerNormOutput</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679768807"><span class="hs-identifier hs-type">attentionBias</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-274"></span><span>      </span><span class="annot"><a href="#local-6989586621679768812"><span class="hs-identifier hs-type">generator</span></a></span><span>
</span><span id="line-275"></span><span>      </span><span class="annot"><a href="#local-6989586621679768806"><span class="hs-identifier hs-type">mhaOutput</span></a></span><span>
</span><span id="line-276"></span><span>      </span><span class="annot"><a href="#local-6989586621679768805"><span class="hs-identifier hs-type">mhaGeneratorOutput</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-277"></span><span>    </span><span class="annot"><a href="#local-6989586621679768813"><span class="hs-identifier hs-type">query</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768804"><span class="hs-identifier hs-type">gradient0</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768803"><span class="hs-identifier hs-type">layout0</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768802"><span class="hs-identifier hs-type">device0</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768801"><span class="hs-identifier hs-type">dataType0</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768800"><span class="hs-identifier hs-type">shape0</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-278"></span><span>    </span><span class="annot"><a href="#local-6989586621679768806"><span class="hs-identifier hs-type">mhaOutput</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768799"><span class="hs-identifier hs-type">gradient1</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768798"><span class="hs-identifier hs-type">layout1</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768797"><span class="hs-identifier hs-type">device1</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768796"><span class="hs-identifier hs-type">dataType1</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768795"><span class="hs-identifier hs-type">shape1</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-279"></span><span>    </span><span class="annot"><a href="#local-6989586621679768805"><span class="hs-identifier hs-type">mhaGeneratorOutput</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Random.html#Generator"><span class="hs-identifier hs-type">Generator</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768794"><span class="hs-identifier hs-type">device2</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-280"></span><span>    </span><span class="annot"><a href="#local-6989586621679768793"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-281"></span><span>      </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-282"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679768804"><span class="hs-identifier hs-type">gradient0</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768799"><span class="hs-identifier hs-type">gradient1</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-283"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679768803"><span class="hs-identifier hs-type">layout0</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768798"><span class="hs-identifier hs-type">layout1</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-284"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679768802"><span class="hs-identifier hs-type">device0</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768797"><span class="hs-identifier hs-type">device1</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768794"><span class="hs-identifier hs-type">device2</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-285"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679768801"><span class="hs-identifier hs-type">dataType0</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768796"><span class="hs-identifier hs-type">dataType1</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-286"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#BroadcastShapesF"><span class="hs-identifier hs-type">BroadcastShapesF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768800"><span class="hs-identifier hs-type">shape0</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768795"><span class="hs-identifier hs-type">shape1</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-287"></span><span>    </span><span class="annot"><a href="#local-6989586621679768792"><span class="hs-identifier hs-type">generatorOutput</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Random.html#Generator"><span class="hs-identifier hs-type">Generator</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679768797"><span class="hs-identifier hs-type">device1</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768794"><span class="hs-identifier hs-type">device2</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-288"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-289"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-290"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#SelfAttention"><span class="hs-identifier hs-type">SelfAttention</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#T5"><span class="hs-identifier hs-type">T5</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768816"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768815"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768814"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768810"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768809"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768808"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768818"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768817"><span class="hs-identifier hs-type">dropoutP</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-291"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679768813"><span class="hs-identifier hs-type">query</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679768807"><span class="hs-identifier hs-type">attentionBias</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-292"></span><span>    </span><span class="annot"><a href="#local-6989586621679768812"><span class="hs-identifier hs-type">generator</span></a></span><span>
</span><span id="line-293"></span><span>    </span><span class="annot"><a href="#local-6989586621679768793"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-294"></span><span>    </span><span class="annot"><a href="#local-6989586621679768792"><span class="hs-identifier hs-type">generatorOutput</span></a></span><span>
</span><span id="line-295"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-296"></span><span>  </span><span id="local-6989586621679768789"><span class="annot"><span class="annottext">forward :: SelfAttention
  'T5
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  queryEmbedDim
  dropoutP
-&gt; (query, attentionBias)
-&gt; generator
-&gt; m (output, generatorOutput)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var hs-var hs-var hs-var">forward</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#SelfAttention"><span class="hs-identifier hs-type">SelfAttention</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#GSelfAttention"><span class="hs-identifier hs-type">GSelfAttention</span></a></span><span> </span><span class="hs-special">{</span><span id="local-6989586621679768785"><span id="local-6989586621679768786"><span id="local-6989586621679768787"><span class="annot"><span class="annottext">SADropoutF 'T5 dropoutP
SALayerNormF 'T5 gradient device dataType queryEmbedDim
SAMultiheadAttentionF
  'T5
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  queryEmbedDim
  dropoutP
saDropout :: SADropoutF 'T5 dropoutP
saLayerNorm :: SALayerNormF 'T5 gradient device dataType queryEmbedDim
saMultiHeadAttention :: SAMultiheadAttentionF
  'T5
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  queryEmbedDim
  dropoutP
saDropout :: forall mha layerNorm dropout.
GSelfAttention mha layerNorm dropout -&gt; dropout
saLayerNorm :: forall mha layerNorm dropout.
GSelfAttention mha layerNorm dropout -&gt; layerNorm
saMultiHeadAttention :: forall mha layerNorm dropout.
GSelfAttention mha layerNorm dropout -&gt; mha
</span><a href="#local-6989586621679768785"><span class="hs-glyph hs-var hs-var hs-var hs-var hs-var hs-var">..</span></a></span></span></span></span><span class="hs-special">}</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679768784"><span class="annot"><span class="annottext">query
</span><a href="#local-6989586621679768784"><span class="hs-identifier hs-var">query</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679768783"><span class="annot"><span class="annottext">attentionBias
</span><a href="#local-6989586621679768783"><span class="hs-identifier hs-var">attentionBias</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-297"></span><span>    </span><span class="annot"><span class="annottext">IxStateT m generator generatorOutput output
-&gt; generator -&gt; m (output, generatorOutput)
forall (m :: Type -&gt; Type) i j a. IxStateT m i j a -&gt; i -&gt; m (a, j)
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var hs-var">runIxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">(IxStateT m generator generatorOutput output
 -&gt; generator -&gt; m (output, generatorOutput))
-&gt; IxStateT m generator generatorOutput output
-&gt; generator
-&gt; m (output, generatorOutput)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-298"></span><span>      </span><span class="annot"><span class="annottext">query -&gt; IxStateT m generator generator query
forall k (m :: k -&gt; k -&gt; Type -&gt; Type) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">query
</span><a href="#local-6989586621679768784"><span class="hs-identifier hs-var">query</span></a></span><span>
</span><span id="line-299"></span><span>        </span><span class="annot"><span class="annottext">IxStateT m generator generator query
-&gt; (query -&gt; IxStateT m generator generator layerNormOutput)
-&gt; IxStateT m generator generator layerNormOutput
forall k1 (m :: k1 -&gt; k1 -&gt; Type -&gt; Type) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(generator -&gt; m (layerNormOutput, generator))
-&gt; IxStateT m generator generator layerNormOutput
forall (m :: Type -&gt; Type) i j a.
(i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((generator -&gt; m (layerNormOutput, generator))
 -&gt; IxStateT m generator generator layerNormOutput)
-&gt; (query -&gt; generator -&gt; m (layerNormOutput, generator))
-&gt; query
-&gt; IxStateT m generator generator layerNormOutput
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">LayerNorm
  'WithoutBias gradient device dataType ('Shape '[queryEmbedDim])
-&gt; query -&gt; generator -&gt; m (layerNormOutput, generator)
forall model input generator output generatorOutput
       (m :: Type -&gt; Type).
(HasForward model input generator output generatorOutput,
 MonadThrow m) =&gt;
model -&gt; input -&gt; generator -&gt; m (output, generatorOutput)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">LayerNorm
  'WithoutBias gradient device dataType ('Shape '[queryEmbedDim])
SALayerNormF 'T5 gradient device dataType queryEmbedDim
</span><a href="#local-6989586621679768786"><span class="hs-identifier hs-var">saLayerNorm</span></a></span><span>
</span><span id="line-300"></span><span>        </span><span class="annot"><span class="annottext">IxStateT m generator generator layerNormOutput
-&gt; (layerNormOutput
    -&gt; IxStateT
         m
         generator
         (Generator device2)
         (Tensor gradient1 layout1 device1 dataType1 shape1))
-&gt; IxStateT
     m
     generator
     (Generator device2)
     (Tensor gradient1 layout1 device1 dataType1 shape1)
forall k1 (m :: k1 -&gt; k1 -&gt; Type -&gt; Type) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">\</span><span id="local-6989586621679768780"><span class="annot"><span class="annottext">layerNormOutput
</span><a href="#local-6989586621679768780"><span class="hs-identifier hs-var">query'</span></a></span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">(generator
 -&gt; m (Tensor gradient1 layout1 device1 dataType1 shape1,
       Generator device2))
-&gt; IxStateT
     m
     generator
     (Generator device2)
     (Tensor gradient1 layout1 device1 dataType1 shape1)
forall (m :: Type -&gt; Type) i j a.
(i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((generator
  -&gt; m (Tensor gradient1 layout1 device1 dataType1 shape1,
        Generator device2))
 -&gt; IxStateT
      m
      generator
      (Generator device2)
      (Tensor gradient1 layout1 device1 dataType1 shape1))
-&gt; (generator
    -&gt; m (Tensor gradient1 layout1 device1 dataType1 shape1,
          Generator device2))
-&gt; IxStateT
     m
     generator
     (Generator device2)
     (Tensor gradient1 layout1 device1 dataType1 shape1)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">MultiHeadAttention
  'T5
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  queryEmbedDim
  queryEmbedDim
  queryEmbedDim
  dropoutP
-&gt; (layerNormOutput, layerNormOutput, layerNormOutput,
    attentionBias)
-&gt; generator
-&gt; m (Tensor gradient1 layout1 device1 dataType1 shape1,
      Generator device2)
forall model input generator output generatorOutput
       (m :: Type -&gt; Type).
(HasForward model input generator output generatorOutput,
 MonadThrow m) =&gt;
model -&gt; input -&gt; generator -&gt; m (output, generatorOutput)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">MultiHeadAttention
  'T5
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  queryEmbedDim
  queryEmbedDim
  queryEmbedDim
  dropoutP
SAMultiheadAttentionF
  'T5
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  queryEmbedDim
  dropoutP
</span><a href="#local-6989586621679768787"><span class="hs-identifier hs-var">saMultiHeadAttention</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">layerNormOutput
</span><a href="#local-6989586621679768780"><span class="hs-identifier hs-var">query'</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">layerNormOutput
</span><a href="#local-6989586621679768780"><span class="hs-identifier hs-var">query'</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">layerNormOutput
</span><a href="#local-6989586621679768780"><span class="hs-identifier hs-var">query'</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">attentionBias
</span><a href="#local-6989586621679768783"><span class="hs-identifier hs-var">attentionBias</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-301"></span><span>        </span><span class="annot"><span class="annottext">IxStateT
  m
  generator
  (Generator device2)
  (Tensor gradient1 layout1 device1 dataType1 shape1)
-&gt; (Tensor gradient1 layout1 device1 dataType1 shape1
    -&gt; IxStateT
         m
         (Generator device2)
         generatorOutput
         (Tensor
            gradient1
            layout1
            (Unify (Device (DeviceType Nat)) device1 device2)
            dataType1
            shape1))
-&gt; IxStateT
     m
     generator
     generatorOutput
     (Tensor
        gradient1
        layout1
        (Unify (Device (DeviceType Nat)) device1 device2)
        dataType1
        shape1)
forall k1 (m :: k1 -&gt; k1 -&gt; Type -&gt; Type) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(Generator device2
 -&gt; m (Tensor
         gradient1
         layout1
         (Unify (Device (DeviceType Nat)) device1 device2)
         dataType1
         shape1,
       generatorOutput))
-&gt; IxStateT
     m
     (Generator device2)
     generatorOutput
     (Tensor
        gradient1
        layout1
        (Unify (Device (DeviceType Nat)) device1 device2)
        dataType1
        shape1)
forall (m :: Type -&gt; Type) i j a.
(i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator device2
  -&gt; m (Tensor
          gradient1
          layout1
          (Unify (Device (DeviceType Nat)) device1 device2)
          dataType1
          shape1,
        generatorOutput))
 -&gt; IxStateT
      m
      (Generator device2)
      generatorOutput
      (Tensor
         gradient1
         layout1
         (Unify (Device (DeviceType Nat)) device1 device2)
         dataType1
         shape1))
-&gt; (Tensor gradient1 layout1 device1 dataType1 shape1
    -&gt; Generator device2
    -&gt; m (Tensor
            gradient1
            layout1
            (Unify (Device (DeviceType Nat)) device1 device2)
            dataType1
            shape1,
          generatorOutput))
-&gt; Tensor gradient1 layout1 device1 dataType1 shape1
-&gt; IxStateT
     m
     (Generator device2)
     generatorOutput
     (Tensor
        gradient1
        layout1
        (Unify (Device (DeviceType Nat)) device1 device2)
        dataType1
        shape1)
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Dropout dropoutP
-&gt; Tensor gradient1 layout1 device1 dataType1 shape1
-&gt; Generator device2
-&gt; m (Tensor
        gradient1
        layout1
        (Unify (Device (DeviceType Nat)) device1 device2)
        dataType1
        shape1,
      generatorOutput)
forall model input generator output generatorOutput
       (m :: Type -&gt; Type).
(HasForward model input generator output generatorOutput,
 MonadThrow m) =&gt;
model -&gt; input -&gt; generator -&gt; m (output, generatorOutput)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">Dropout dropoutP
SADropoutF 'T5 dropoutP
</span><a href="#local-6989586621679768785"><span class="hs-identifier hs-var">saDropout</span></a></span><span>
</span><span id="line-302"></span><span>        </span><span class="annot"><span class="annottext">IxStateT
  m
  generator
  generatorOutput
  (Tensor
     gradient1
     layout1
     (Unify (Device (DeviceType Nat)) device1 device2)
     dataType1
     shape1)
-&gt; (Tensor
      gradient1
      layout1
      (Unify (Device (DeviceType Nat)) device1 device2)
      dataType1
      shape1
    -&gt; IxStateT m generatorOutput generatorOutput output)
-&gt; IxStateT m generator generatorOutput output
forall k1 (m :: k1 -&gt; k1 -&gt; Type -&gt; Type) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">output -&gt; IxStateT m generatorOutput generatorOutput output
forall k (m :: k -&gt; k -&gt; Type -&gt; Type) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">(output -&gt; IxStateT m generatorOutput generatorOutput output)
-&gt; (Tensor
      gradient1
      layout1
      (Unify (Device (DeviceType Nat)) device1 device2)
      dataType1
      shape1
    -&gt; output)
-&gt; Tensor
     gradient1
     layout1
     (Unify (Device (DeviceType Nat)) device1 device2)
     dataType1
     shape1
-&gt; IxStateT m generatorOutput generatorOutput output
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">query
Tensor gradient0 layout0 device0 dataType0 shape0
</span><a href="#local-6989586621679768784"><span class="hs-identifier hs-var">query</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient0 layout0 device0 dataType0 shape0
-&gt; Tensor
     gradient1
     layout1
     (Unify (Device (DeviceType Nat)) device1 device2)
     dataType1
     shape1
-&gt; Tensor
     (gradient0 &lt;|&gt; gradient1)
     (layout0 &lt;+&gt; layout1)
     (device0 &lt;+&gt; Unify (Device (DeviceType Nat)) device1 device2)
     (dataType0 &lt;+&gt; dataType1)
     (BroadcastShapesF shape0 shape1)
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (gradient' :: Gradient RequiresGradient)
       (layout' :: Layout LayoutType) (device' :: Device (DeviceType Nat))
       (dataType' :: DataType DType)
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]).
Tensor gradient layout device dataType shape
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; Tensor
     (gradient &lt;|&gt; gradient')
     (layout &lt;+&gt; layout')
     (device &lt;+&gt; device')
     (dataType &lt;+&gt; dataType')
     (BroadcastShapesF shape shape')
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#add"><span class="hs-operator hs-var">`add`</span></a></span><span class="hs-special">)</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span>
</span><span id="line-303"></span><span>
</span><span id="line-304"></span><span id="testSA"><span class="annot"><span class="annottext">testSA :: IO
  (Tensor
     ('Gradient 'WithGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     ('DataType 'Float)
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 4),
           'Dim ('Name &quot;*&quot;) ('Size 512)]))
</span><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#testSA"><span class="hs-identifier hs-var hs-var">testSA</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-305"></span><span>  </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679768778"><span class="annot"><span class="annottext">gradient :: SGradient ('Gradient 'WithGradient)
</span><a href="#local-6989586621679768778"><span class="hs-identifier hs-var hs-var">gradient</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SRequiresGradient 'WithGradient
-&gt; SGradient ('Gradient 'WithGradient)
forall (requiresGradient :: RequiresGradient).
SRequiresGradient requiresGradient
-&gt; SGradient ('Gradient requiresGradient)
</span><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier hs-var">SGradient</span></a></span><span> </span><span class="annot"><span class="annottext">SRequiresGradient 'WithGradient
</span><a href="Torch.GraduallyTyped.RequiresGradient.html#SWithGradient"><span class="hs-identifier hs-var">SWithGradient</span></a></span><span>
</span><span id="line-306"></span><span>      </span><span id="local-6989586621679768775"><span class="annot"><span class="annottext">device :: SDevice ('Device 'CPU)
</span><a href="#local-6989586621679768775"><span class="hs-identifier hs-var hs-var">device</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SDeviceType 'CPU -&gt; SDevice ('Device 'CPU)
forall (deviceType :: DeviceType Nat).
SDeviceType deviceType -&gt; SDevice ('Device deviceType)
</span><a href="Torch.GraduallyTyped.Device.html#SDevice"><span class="hs-identifier hs-var">SDevice</span></a></span><span> </span><span class="annot"><span class="annottext">SDeviceType 'CPU
</span><a href="Torch.GraduallyTyped.Device.html#SCPU"><span class="hs-identifier hs-var">SCPU</span></a></span><span>
</span><span id="line-307"></span><span>      </span><span id="local-6989586621679768772"><span class="annot"><span class="annottext">dataType :: SDataType ('DataType 'Float)
</span><a href="#local-6989586621679768772"><span class="hs-identifier hs-var hs-var">dataType</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SDType 'Float -&gt; SDataType ('DataType 'Float)
forall (dType :: DType).
SDType dType -&gt; SDataType ('DataType dType)
</span><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier hs-var">SDataType</span></a></span><span> </span><span class="annot"><span class="annottext">SDType 'Float
</span><a href="Torch.GraduallyTyped.DType.html#SFloat"><span class="hs-identifier hs-var">SFloat</span></a></span><span>
</span><span id="line-308"></span><span>      </span><span id="local-6989586621679768769"><span class="annot"><span class="annottext">headDim :: SDim ('Dim ('Name &quot;*&quot;) ('Size 8))
</span><a href="#local-6989586621679768769"><span class="hs-identifier hs-var hs-var">headDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize ('Size 8) -&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 8))
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownNat 8 =&gt; SSize ('Size 8)
forall (size :: Nat). KnownNat size =&gt; SSize ('Size size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier hs-var">SSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">8</span></span><span>
</span><span id="line-309"></span><span>      </span><span id="local-6989586621679768766"><span class="annot"><span class="annottext">headEmbedDim :: SDim ('Dim ('Name &quot;*&quot;) ('Size 64))
</span><a href="#local-6989586621679768766"><span class="hs-identifier hs-var hs-var">headEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize ('Size 64) -&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 64))
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownNat 64 =&gt; SSize ('Size 64)
forall (size :: Nat). KnownNat size =&gt; SSize ('Size size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier hs-var">SSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">64</span></span><span>
</span><span id="line-310"></span><span>      </span><span id="local-6989586621679768765"><span class="annot"><span class="annottext">embedDim :: SDim ('Dim ('Name &quot;*&quot;) ('Size 512))
</span><a href="#local-6989586621679768765"><span class="hs-identifier hs-var hs-var">embedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize ('Size 512) -&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 512))
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownNat 512 =&gt; SSize ('Size 512)
forall (size :: Nat). KnownNat size =&gt; SSize ('Size size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier hs-var">SSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">512</span></span><span>
</span><span id="line-311"></span><span>      </span><span id="local-6989586621679768764"><span class="annot"><span class="annottext">queryEmbedDim :: SDim ('Dim ('Name &quot;*&quot;) ('Size 512))
</span><a href="#local-6989586621679768764"><span class="hs-identifier hs-var hs-var">queryEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize ('Size 512) -&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 512))
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownNat 512 =&gt; SSize ('Size 512)
forall (size :: Nat). KnownNat size =&gt; SSize ('Size size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier hs-var">SSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">512</span></span><span>
</span><span id="line-312"></span><span>      </span><span id="local-6989586621679768763"><span class="annot"><span class="annottext">Float
</span><a href="#local-6989586621679768763"><span class="hs-identifier hs-var">dropoutP</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Float</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Float
</span><span class="hs-number">0.0</span></span><span>
</span><span id="line-313"></span><span>      </span><span id="local-6989586621679768762"><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679768762"><span class="hs-identifier hs-var">eps</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Double
</span><span class="hs-number">1e-6</span></span><span>
</span><span id="line-314"></span><span>  </span><span id="local-6989586621679768761"><span class="annot"><span class="annottext">Generator ('Device 'CPU)
</span><a href="#local-6989586621679768761"><span class="hs-identifier hs-var">g</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">SDevice ('Device 'CPU) -&gt; Word64 -&gt; IO (Generator ('Device 'CPU))
forall (device :: Device (DeviceType Nat)).
SDevice device -&gt; Word64 -&gt; IO (Generator device)
</span><a href="Torch.GraduallyTyped.Random.html#sMkGenerator"><span class="hs-identifier hs-var">sMkGenerator</span></a></span><span> </span><span class="annot"><span class="annottext">SDevice ('Device 'CPU)
</span><a href="#local-6989586621679768775"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">Word64
</span><span class="hs-number">0</span></span><span>
</span><span id="line-315"></span><span>  </span><span class="hs-keyword">let</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679768760"><span class="annot"><span class="annottext">SelfAttention
  'T5
  ('Gradient 'WithGradient)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Dim ('Name &quot;*&quot;) ('Size 8))
  ('Dim ('Name &quot;*&quot;) ('Size 64))
  ('Dim ('Name &quot;*&quot;) ('Size 512))
  ('Dim ('Name &quot;*&quot;) ('Size 512))
  Float
</span><a href="#local-6989586621679768760"><span class="hs-identifier hs-var">sa</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679768759"><span class="annot"><span class="annottext">Generator ('Device 'CPU)
</span><a href="#local-6989586621679768759"><span class="hs-identifier hs-var">g'</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-316"></span><span>        </span><span class="annot"><span class="annottext">(SGradient ('Gradient 'WithGradient), SDevice ('Device 'CPU),
 SDataType ('DataType 'Float), SDim ('Dim ('Name &quot;*&quot;) ('Size 8)),
 SDim ('Dim ('Name &quot;*&quot;) ('Size 64)),
 SDim ('Dim ('Name &quot;*&quot;) ('Size 512)),
 SDim ('Dim ('Name &quot;*&quot;) ('Size 512)), Float, Double)
-&gt; Generator ('Device 'CPU)
-&gt; (SelfAttention
      'T5
      ('Gradient 'WithGradient)
      ('Device 'CPU)
      ('DataType 'Float)
      ('Dim ('Name &quot;*&quot;) ('Size 8))
      ('Dim ('Name &quot;*&quot;) ('Size 64))
      ('Dim ('Name &quot;*&quot;) ('Size 512))
      ('Dim ('Name &quot;*&quot;) ('Size 512))
      Float,
    Generator ('Device 'CPU))
forall model input generator generatorOutput.
HasInitialize model input generator generatorOutput =&gt;
input -&gt; generator -&gt; (model, generatorOutput)
</span><a href="Torch.GraduallyTyped.NN.Class.html#initialize"><span class="hs-identifier hs-var">initialize</span></a></span><span>
</span><span id="line-317"></span><span>          </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#SelfAttention"><span class="hs-identifier hs-type">SelfAttention</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#T5"><span class="hs-identifier hs-type">T5</span></a></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span class="hs-special">)</span><span>
</span><span id="line-318"></span><span>          </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SGradient ('Gradient 'WithGradient)
</span><a href="#local-6989586621679768778"><span class="hs-identifier hs-var">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDevice ('Device 'CPU)
</span><a href="#local-6989586621679768775"><span class="hs-identifier hs-var">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDataType ('DataType 'Float)
</span><a href="#local-6989586621679768772"><span class="hs-identifier hs-var">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 8))
</span><a href="#local-6989586621679768769"><span class="hs-identifier hs-var">headDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 64))
</span><a href="#local-6989586621679768766"><span class="hs-identifier hs-var">headEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 512))
</span><a href="#local-6989586621679768765"><span class="hs-identifier hs-var">embedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 512))
</span><a href="#local-6989586621679768764"><span class="hs-identifier hs-var">queryEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Float
</span><a href="#local-6989586621679768763"><span class="hs-identifier hs-var">dropoutP</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679768762"><span class="hs-identifier hs-var">eps</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-319"></span><span>          </span><span class="annot"><span class="annottext">Generator ('Device 'CPU)
</span><a href="#local-6989586621679768761"><span class="hs-identifier hs-var">g</span></a></span><span>
</span><span id="line-320"></span><span>  </span><span id="local-6989586621679768758"><span class="annot"><span class="annottext">SelfAttention
  'T5
  ('Gradient 'WithGradient)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Dim ('Name &quot;*&quot;) ('Size 8))
  ('Dim ('Name &quot;*&quot;) ('Size 64))
  ('Dim ('Name &quot;*&quot;) ('Size 512))
  ('Dim ('Name &quot;*&quot;) ('Size 512))
  Float
</span><a href="#local-6989586621679768758"><span class="hs-identifier hs-var">sa'</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">(StateT
   StateDict
   IO
   (SelfAttention
      'T5
      ('Gradient 'WithGradient)
      ('Device 'CPU)
      ('DataType 'Float)
      ('Dim ('Name &quot;*&quot;) ('Size 8))
      ('Dim ('Name &quot;*&quot;) ('Size 64))
      ('Dim ('Name &quot;*&quot;) ('Size 512))
      ('Dim ('Name &quot;*&quot;) ('Size 512))
      Float)
 -&gt; StateDict
 -&gt; IO
      (SelfAttention
         'T5
         ('Gradient 'WithGradient)
         ('Device 'CPU)
         ('DataType 'Float)
         ('Dim ('Name &quot;*&quot;) ('Size 8))
         ('Dim ('Name &quot;*&quot;) ('Size 64))
         ('Dim ('Name &quot;*&quot;) ('Size 512))
         ('Dim ('Name &quot;*&quot;) ('Size 512))
         Float))
-&gt; StateDict
-&gt; StateT
     StateDict
     IO
     (SelfAttention
        'T5
        ('Gradient 'WithGradient)
        ('Device 'CPU)
        ('DataType 'Float)
        ('Dim ('Name &quot;*&quot;) ('Size 8))
        ('Dim ('Name &quot;*&quot;) ('Size 64))
        ('Dim ('Name &quot;*&quot;) ('Size 512))
        ('Dim ('Name &quot;*&quot;) ('Size 512))
        Float)
-&gt; IO
     (SelfAttention
        'T5
        ('Gradient 'WithGradient)
        ('Device 'CPU)
        ('DataType 'Float)
        ('Dim ('Name &quot;*&quot;) ('Size 8))
        ('Dim ('Name &quot;*&quot;) ('Size 64))
        ('Dim ('Name &quot;*&quot;) ('Size 512))
        ('Dim ('Name &quot;*&quot;) ('Size 512))
        Float)
forall a b c. (a -&gt; b -&gt; c) -&gt; b -&gt; a -&gt; c
</span><span class="hs-identifier hs-var">flip</span></span><span> </span><span class="annot"><span class="annottext">StateT
  StateDict
  IO
  (SelfAttention
     'T5
     ('Gradient 'WithGradient)
     ('Device 'CPU)
     ('DataType 'Float)
     ('Dim ('Name &quot;*&quot;) ('Size 8))
     ('Dim ('Name &quot;*&quot;) ('Size 64))
     ('Dim ('Name &quot;*&quot;) ('Size 512))
     ('Dim ('Name &quot;*&quot;) ('Size 512))
     Float)
-&gt; StateDict
-&gt; IO
     (SelfAttention
        'T5
        ('Gradient 'WithGradient)
        ('Device 'CPU)
        ('DataType 'Float)
        ('Dim ('Name &quot;*&quot;) ('Size 8))
        ('Dim ('Name &quot;*&quot;) ('Size 64))
        ('Dim ('Name &quot;*&quot;) ('Size 512))
        ('Dim ('Name &quot;*&quot;) ('Size 512))
        Float)
forall (m :: Type -&gt; Type) s a. Monad m =&gt; StateT s m a -&gt; s -&gt; m a
</span><span class="hs-identifier hs-var">evalStateT</span></span><span> </span><span class="annot"><span class="annottext">StateDict
forall k a. Map k a
</span><span class="hs-identifier hs-var">Map.empty</span></span><span> </span><span class="annot"><span class="annottext">(StateT
   StateDict
   IO
   (SelfAttention
      'T5
      ('Gradient 'WithGradient)
      ('Device 'CPU)
      ('DataType 'Float)
      ('Dim ('Name &quot;*&quot;) ('Size 8))
      ('Dim ('Name &quot;*&quot;) ('Size 64))
      ('Dim ('Name &quot;*&quot;) ('Size 512))
      ('Dim ('Name &quot;*&quot;) ('Size 512))
      Float)
 -&gt; IO
      (SelfAttention
         'T5
         ('Gradient 'WithGradient)
         ('Device 'CPU)
         ('DataType 'Float)
         ('Dim ('Name &quot;*&quot;) ('Size 8))
         ('Dim ('Name &quot;*&quot;) ('Size 64))
         ('Dim ('Name &quot;*&quot;) ('Size 512))
         ('Dim ('Name &quot;*&quot;) ('Size 512))
         Float))
-&gt; StateT
     StateDict
     IO
     (SelfAttention
        'T5
        ('Gradient 'WithGradient)
        ('Device 'CPU)
        ('DataType 'Float)
        ('Dim ('Name &quot;*&quot;) ('Size 8))
        ('Dim ('Name &quot;*&quot;) ('Size 64))
        ('Dim ('Name &quot;*&quot;) ('Size 512))
        ('Dim ('Name &quot;*&quot;) ('Size 512))
        Float)
-&gt; IO
     (SelfAttention
        'T5
        ('Gradient 'WithGradient)
        ('Device 'CPU)
        ('DataType 'Float)
        ('Dim ('Name &quot;*&quot;) ('Size 8))
        ('Dim ('Name &quot;*&quot;) ('Size 64))
        ('Dim ('Name &quot;*&quot;) ('Size 512))
        ('Dim ('Name &quot;*&quot;) ('Size 512))
        Float)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-321"></span><span>    </span><span class="annot"><span class="annottext">StateDictKey
-&gt; SelfAttention
     'T5
     ('Gradient 'WithGradient)
     ('Device 'CPU)
     ('DataType 'Float)
     ('Dim ('Name &quot;*&quot;) ('Size 8))
     ('Dim ('Name &quot;*&quot;) ('Size 64))
     ('Dim ('Name &quot;*&quot;) ('Size 512))
     ('Dim ('Name &quot;*&quot;) ('Size 512))
     Float
-&gt; StateT StateDict IO ()
forall model input (m :: Type -&gt; Type).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;sa.&quot;</span></span><span> </span><span class="annot"><span class="annottext">SelfAttention
  'T5
  ('Gradient 'WithGradient)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Dim ('Name &quot;*&quot;) ('Size 8))
  ('Dim ('Name &quot;*&quot;) ('Size 64))
  ('Dim ('Name &quot;*&quot;) ('Size 512))
  ('Dim ('Name &quot;*&quot;) ('Size 512))
  Float
</span><a href="#local-6989586621679768760"><span class="hs-identifier hs-var">sa</span></a></span><span>
</span><span id="line-322"></span><span>    </span><span class="annot"><span class="annottext">(SGradient ('Gradient 'WithGradient), SDevice ('Device 'CPU),
 SDataType ('DataType 'Float), SDim ('Dim ('Name &quot;*&quot;) ('Size 8)),
 SDim ('Dim ('Name &quot;*&quot;) ('Size 64)),
 SDim ('Dim ('Name &quot;*&quot;) ('Size 512)),
 SDim ('Dim ('Name &quot;*&quot;) ('Size 512)), Float, Double)
-&gt; StateDictKey
-&gt; StateT
     StateDict
     IO
     (SelfAttention
        'T5
        ('Gradient 'WithGradient)
        ('Device 'CPU)
        ('DataType 'Float)
        ('Dim ('Name &quot;*&quot;) ('Size 8))
        ('Dim ('Name &quot;*&quot;) ('Size 64))
        ('Dim ('Name &quot;*&quot;) ('Size 512))
        ('Dim ('Name &quot;*&quot;) ('Size 512))
        Float)
forall model input (m :: Type -&gt; Type).
(HasStateDict model input, MonadThrow m, MonadState StateDict m) =&gt;
input -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span>
</span><span id="line-323"></span><span>      </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#SelfAttention"><span class="hs-identifier hs-type">SelfAttention</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#T5"><span class="hs-identifier hs-type">T5</span></a></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span class="hs-special">)</span><span>
</span><span id="line-324"></span><span>      </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SGradient ('Gradient 'WithGradient)
</span><a href="#local-6989586621679768778"><span class="hs-identifier hs-var">gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDevice ('Device 'CPU)
</span><a href="#local-6989586621679768775"><span class="hs-identifier hs-var">device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDataType ('DataType 'Float)
</span><a href="#local-6989586621679768772"><span class="hs-identifier hs-var">dataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 8))
</span><a href="#local-6989586621679768769"><span class="hs-identifier hs-var">headDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 64))
</span><a href="#local-6989586621679768766"><span class="hs-identifier hs-var">headEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 512))
</span><a href="#local-6989586621679768765"><span class="hs-identifier hs-var">embedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 512))
</span><a href="#local-6989586621679768764"><span class="hs-identifier hs-var">queryEmbedDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Float
</span><a href="#local-6989586621679768763"><span class="hs-identifier hs-var">dropoutP</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679768762"><span class="hs-identifier hs-var">eps</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-325"></span><span>      </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;sa.&quot;</span></span><span>
</span><span id="line-326"></span><span>  </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679768755"><span class="annot"><span class="annottext">batchDim :: SDim ('Dim ('Name &quot;*&quot;) ('Size 1))
</span><a href="#local-6989586621679768755"><span class="hs-identifier hs-var hs-var">batchDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize ('Size 1) -&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 1))
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownNat 1 =&gt; SSize ('Size 1)
forall (size :: Nat). KnownNat size =&gt; SSize ('Size size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier hs-var">SSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">1</span></span><span>
</span><span id="line-327"></span><span>      </span><span id="local-6989586621679768754"><span class="annot"><span class="annottext">seqDim :: SDim ('Dim ('Name &quot;*&quot;) ('Size 4))
</span><a href="#local-6989586621679768754"><span class="hs-identifier hs-var hs-var">seqDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize ('Size 4) -&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 4))
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownNat 4 =&gt; SSize ('Size 4)
forall (size :: Nat). KnownNat size =&gt; SSize ('Size size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier hs-var">SSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">4</span></span><span>
</span><span id="line-328"></span><span>      </span><span id="local-6989586621679768753"><span class="annot"><span class="annottext">sOnes' :: SDataType dataType
-&gt; SShape shape
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     dataType
     shape
</span><a href="#local-6989586621679768753"><span class="hs-identifier hs-var hs-var">sOnes'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SGradient ('Gradient 'WithoutGradient)
-&gt; SLayout ('Layout 'Dense)
-&gt; SDevice ('Device 'CPU)
-&gt; SDataType dataType
-&gt; SShape shape
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     dataType
     shape
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SShape shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.Creation.html#sOnes"><span class="hs-identifier hs-var">sOnes</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SRequiresGradient 'WithoutGradient
-&gt; SGradient ('Gradient 'WithoutGradient)
forall (requiresGradient :: RequiresGradient).
SRequiresGradient requiresGradient
-&gt; SGradient ('Gradient requiresGradient)
</span><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier hs-var">SGradient</span></a></span><span> </span><span class="annot"><span class="annottext">SRequiresGradient 'WithoutGradient
</span><a href="Torch.GraduallyTyped.RequiresGradient.html#SWithoutGradient"><span class="hs-identifier hs-var">SWithoutGradient</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SLayoutType 'Dense -&gt; SLayout ('Layout 'Dense)
forall (layoutType :: LayoutType).
SLayoutType layoutType -&gt; SLayout ('Layout layoutType)
</span><a href="Torch.GraduallyTyped.Layout.html#SLayout"><span class="hs-identifier hs-var">SLayout</span></a></span><span> </span><span class="annot"><span class="annottext">SLayoutType 'Dense
</span><a href="Torch.GraduallyTyped.Layout.html#SDense"><span class="hs-identifier hs-var">SDense</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">SDevice ('Device 'CPU)
</span><a href="#local-6989586621679768775"><span class="hs-identifier hs-var">device</span></a></span><span>
</span><span id="line-329"></span><span>      </span><span id="local-6989586621679768749"><span class="annot"><span class="annottext">query :: Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 4),
        'Dim ('Name &quot;*&quot;) ('Size 512)])
</span><a href="#local-6989586621679768749"><span class="hs-identifier hs-var hs-var">query</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SDataType ('DataType 'Float)
-&gt; SShape
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 4),
           'Dim ('Name &quot;*&quot;) ('Size 512)])
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     ('DataType 'Float)
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 4),
           'Dim ('Name &quot;*&quot;) ('Size 512)])
forall (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SDataType dataType
-&gt; SShape shape
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     dataType
     shape
</span><a href="#local-6989586621679768753"><span class="hs-identifier hs-var">sOnes'</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType ('DataType 'Float)
</span><a href="#local-6989586621679768772"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SList
  '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 4),
     'Dim ('Name &quot;*&quot;) ('Size 512)]
-&gt; SShape
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 4),
           'Dim ('Name &quot;*&quot;) ('Size 512)])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList
   '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 4),
      'Dim ('Name &quot;*&quot;) ('Size 512)]
 -&gt; SShape
      ('Shape
         '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 4),
            'Dim ('Name &quot;*&quot;) ('Size 512)]))
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 4),
        'Dim ('Name &quot;*&quot;) ('Size 512)]
-&gt; SShape
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 4),
           'Dim ('Name &quot;*&quot;) ('Size 512)])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 1))
</span><a href="#local-6989586621679768755"><span class="hs-identifier hs-var">batchDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 1))
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 4), 'Dim ('Name &quot;*&quot;) ('Size 512)]
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 4),
        'Dim ('Name &quot;*&quot;) ('Size 512)]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 4))
</span><a href="#local-6989586621679768754"><span class="hs-identifier hs-var">seqDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 4))
-&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 512)]
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 4), 'Dim ('Name &quot;*&quot;) ('Size 512)]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 512))
</span><a href="#local-6989586621679768764"><span class="hs-identifier hs-var">queryEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 512))
-&gt; SList '[] -&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 512)]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-330"></span><span>      </span><span id="local-6989586621679768748"><span class="annot"><span class="annottext">attentionBias :: Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 1),
        'Dim ('Name &quot;*&quot;) ('Size 4), 'Dim ('Name &quot;*&quot;) ('Size 4)])
</span><a href="#local-6989586621679768748"><span class="hs-identifier hs-var hs-var">attentionBias</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SDataType ('DataType 'Float)
-&gt; SShape
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 1),
           'Dim ('Name &quot;*&quot;) ('Size 4), 'Dim ('Name &quot;*&quot;) ('Size 4)])
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     ('DataType 'Float)
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 1),
           'Dim ('Name &quot;*&quot;) ('Size 4), 'Dim ('Name &quot;*&quot;) ('Size 4)])
forall (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SDataType dataType
-&gt; SShape shape
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     dataType
     shape
</span><a href="#local-6989586621679768753"><span class="hs-identifier hs-var">sOnes'</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType ('DataType 'Float)
</span><a href="#local-6989586621679768772"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SList
  '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 1),
     'Dim ('Name &quot;*&quot;) ('Size 4), 'Dim ('Name &quot;*&quot;) ('Size 4)]
-&gt; SShape
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 1),
           'Dim ('Name &quot;*&quot;) ('Size 4), 'Dim ('Name &quot;*&quot;) ('Size 4)])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList
   '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 1),
      'Dim ('Name &quot;*&quot;) ('Size 4), 'Dim ('Name &quot;*&quot;) ('Size 4)]
 -&gt; SShape
      ('Shape
         '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 1),
            'Dim ('Name &quot;*&quot;) ('Size 4), 'Dim ('Name &quot;*&quot;) ('Size 4)]))
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 1),
        'Dim ('Name &quot;*&quot;) ('Size 4), 'Dim ('Name &quot;*&quot;) ('Size 4)]
-&gt; SShape
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 1),
           'Dim ('Name &quot;*&quot;) ('Size 4), 'Dim ('Name &quot;*&quot;) ('Size 4)])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 1))
</span><a href="#local-6989586621679768755"><span class="hs-identifier hs-var">batchDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 1))
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 4),
        'Dim ('Name &quot;*&quot;) ('Size 4)]
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 1),
        'Dim ('Name &quot;*&quot;) ('Size 4), 'Dim ('Name &quot;*&quot;) ('Size 4)]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize ('Size 1) -&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 1))
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownNat 1 =&gt; SSize ('Size 1)
forall (size :: Nat). KnownNat size =&gt; SSize ('Size size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier hs-var">SSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">1</span></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 1))
-&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 4), 'Dim ('Name &quot;*&quot;) ('Size 4)]
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 4),
        'Dim ('Name &quot;*&quot;) ('Size 4)]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 4))
</span><a href="#local-6989586621679768754"><span class="hs-identifier hs-var">seqDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 4))
-&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 4)]
-&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 4), 'Dim ('Name &quot;*&quot;) ('Size 4)]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 4))
</span><a href="#local-6989586621679768754"><span class="hs-identifier hs-var">seqDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 4))
-&gt; SList '[] -&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 4)]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-331"></span><span>  </span><span class="hs-special">(</span><span id="local-6989586621679768747"><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 4),
        'Dim ('Name &quot;*&quot;) ('Size 512)])
</span><a href="#local-6989586621679768747"><span class="hs-identifier hs-var">output</span></a></span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Generator ('Device 'CPU)
</span><span class="hs-identifier">_</span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">SelfAttention
  'T5
  ('Gradient 'WithGradient)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Dim ('Name &quot;*&quot;) ('Size 8))
  ('Dim ('Name &quot;*&quot;) ('Size 64))
  ('Dim ('Name &quot;*&quot;) ('Size 512))
  ('Dim ('Name &quot;*&quot;) ('Size 512))
  Float
-&gt; (Tensor
      ('Gradient 'WithoutGradient)
      ('Layout 'Dense)
      ('Device 'CPU)
      ('DataType 'Float)
      ('Shape
         '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 4),
            'Dim ('Name &quot;*&quot;) ('Size 512)]),
    Tensor
      ('Gradient 'WithoutGradient)
      ('Layout 'Dense)
      ('Device 'CPU)
      ('DataType 'Float)
      ('Shape
         '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 1),
            'Dim ('Name &quot;*&quot;) ('Size 4), 'Dim ('Name &quot;*&quot;) ('Size 4)]))
-&gt; Generator ('Device 'CPU)
-&gt; IO
     (Tensor
        ('Gradient 'WithGradient)
        ('Layout 'Dense)
        ('Device 'CPU)
        ('DataType 'Float)
        ('Shape
           '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 4),
              'Dim ('Name &quot;*&quot;) ('Size 512)]),
      Generator ('Device 'CPU))
forall model input generator output generatorOutput
       (m :: Type -&gt; Type).
(HasForward model input generator output generatorOutput,
 MonadThrow m) =&gt;
model -&gt; input -&gt; generator -&gt; m (output, generatorOutput)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">SelfAttention
  'T5
  ('Gradient 'WithGradient)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Dim ('Name &quot;*&quot;) ('Size 8))
  ('Dim ('Name &quot;*&quot;) ('Size 64))
  ('Dim ('Name &quot;*&quot;) ('Size 512))
  ('Dim ('Name &quot;*&quot;) ('Size 512))
  Float
</span><a href="#local-6989586621679768758"><span class="hs-identifier hs-var">sa'</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 4),
        'Dim ('Name &quot;*&quot;) ('Size 512)])
</span><a href="#local-6989586621679768749"><span class="hs-identifier hs-var">query</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 1),
        'Dim ('Name &quot;*&quot;) ('Size 4), 'Dim ('Name &quot;*&quot;) ('Size 4)])
</span><a href="#local-6989586621679768748"><span class="hs-identifier hs-var">attentionBias</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Generator ('Device 'CPU)
</span><a href="#local-6989586621679768759"><span class="hs-identifier hs-var">g'</span></a></span><span>
</span><span id="line-332"></span><span>  </span><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 4),
        'Dim ('Name &quot;*&quot;) ('Size 512)])
-&gt; IO
     (Tensor
        ('Gradient 'WithGradient)
        ('Layout 'Dense)
        ('Device 'CPU)
        ('DataType 'Float)
        ('Shape
           '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 4),
              'Dim ('Name &quot;*&quot;) ('Size 512)]))
forall (f :: Type -&gt; Type) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 4),
        'Dim ('Name &quot;*&quot;) ('Size 512)])
</span><a href="#local-6989586621679768747"><span class="hs-identifier hs-var">output</span></a></span><span>
</span><span id="line-333"></span><span>
</span><span id="line-334"></span><span class="hs-comment">-- | 'HasForward' instance for @SelfAttention 'ByT5@.</span><span>
</span><span id="line-335"></span><span class="hs-comment">--</span><span>
</span><span id="line-336"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-337"></span><span class="hs-comment">-- &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;     &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;</span><span>
</span><span id="line-338"></span><span class="hs-comment">-- &#9474; attentionBias &#9474;     &#9474; query &#9474;</span><span>
</span><span id="line-339"></span><span class="hs-comment">-- &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;     &#9492;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-340"></span><span class="hs-comment">--         &#9474;                 &#9474;</span><span>
</span><span id="line-341"></span><span class="hs-comment">--         &#9474;           &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9524;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;</span><span>
</span><span id="line-342"></span><span class="hs-comment">--         &#9474;           &#9474;           &#9474;</span><span>
</span><span id="line-343"></span><span class="hs-comment">--         &#9474;           &#9660;           &#9474;</span><span>
</span><span id="line-344"></span><span class="hs-comment">--         &#9474;      saLayerNorm      &#9474;</span><span>
</span><span id="line-345"></span><span class="hs-comment">--         &#9474;           &#9474;           &#9474;</span><span>
</span><span id="line-346"></span><span class="hs-comment">--         &#9474;      &#9484;&#9472;&#9472;&#9472;&#9472;&#9532;&#9472;&#9472;&#9472;&#9472;&#9488;      &#9474;</span><span>
</span><span id="line-347"></span><span class="hs-comment">--         &#9474;      &#9474;    &#9474;    &#9474;      &#9474;</span><span>
</span><span id="line-348"></span><span class="hs-comment">--         &#9474;      &#9660;    &#9660;    &#9660;      &#9474;</span><span>
</span><span id="line-349"></span><span class="hs-comment">--         &#9492;&#9472;&#9658;saMultiHeadAttention &#9474;</span><span>
</span><span id="line-350"></span><span class="hs-comment">--                     &#9474;           &#9474;</span><span>
</span><span id="line-351"></span><span class="hs-comment">--                     &#9660;           &#9474;</span><span>
</span><span id="line-352"></span><span class="hs-comment">--                 saDropout       &#9474;</span><span>
</span><span id="line-353"></span><span class="hs-comment">--                     &#9474;           &#9474;</span><span>
</span><span id="line-354"></span><span class="hs-comment">--                     &#9492;&#9472;&#9472;&#9472;&#9658;add&#9668;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-355"></span><span class="hs-comment">--                           &#9474;</span><span>
</span><span id="line-356"></span><span class="hs-comment">--                           &#9660;</span><span>
</span><span id="line-357"></span><span class="hs-comment">--                       &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;</span><span>
</span><span id="line-358"></span><span class="hs-comment">--                       &#9474; query &#9474;</span><span>
</span><span id="line-359"></span><span class="hs-comment">--                       &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-360"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-361"></span><span id="local-6989586621679768720"><span id="local-6989586621679768721"><span id="local-6989586621679768722"><span id="local-6989586621679768723"><span id="local-6989586621679768724"><span id="local-6989586621679768725"><span id="local-6989586621679768726"><span id="local-6989586621679768727"><span id="local-6989586621679768728"><span id="local-6989586621679768729"><span id="local-6989586621679768730"><span id="local-6989586621679768731"><span id="local-6989586621679768732"><span id="local-6989586621679768733"><span id="local-6989586621679768734"><span id="local-6989586621679768735"><span id="local-6989586621679768736"><span id="local-6989586621679768737"><span id="local-6989586621679768738"><span id="local-6989586621679768739"><span id="local-6989586621679768740"><span id="local-6989586621679768741"><span id="local-6989586621679768742"><span id="local-6989586621679768743"><span id="local-6989586621679768744"><span id="local-6989586621679768745"><span id="local-6989586621679768746"><span class="hs-keyword">instance</span><span>
</span><span id="line-362"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetDim"><span class="hs-identifier hs-type">SGetDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768746"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-363"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Scalar.html#Scalar"><span class="hs-identifier hs-type">Scalar</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768745"><span class="hs-identifier hs-type">dropoutP</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-364"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-365"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#SALayerNormF"><span class="hs-identifier hs-type">SALayerNormF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ByT5"><span class="hs-identifier hs-type">ByT5</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768744"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768743"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768742"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768746"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-366"></span><span>      </span><span class="annot"><a href="#local-6989586621679768741"><span class="hs-identifier hs-type">query</span></a></span><span>
</span><span id="line-367"></span><span>      </span><span class="annot"><a href="#local-6989586621679768740"><span class="hs-identifier hs-type">generator</span></a></span><span>
</span><span id="line-368"></span><span>      </span><span class="annot"><a href="#local-6989586621679768739"><span class="hs-identifier hs-type">layerNormOutput</span></a></span><span>
</span><span id="line-369"></span><span>      </span><span class="annot"><a href="#local-6989586621679768740"><span class="hs-identifier hs-type">generator</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-370"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-371"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#SAMultiheadAttentionF"><span class="hs-identifier hs-type">SAMultiheadAttentionF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ByT5"><span class="hs-identifier hs-type">ByT5</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768744"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768743"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768742"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768738"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768737"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768736"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768746"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768745"><span class="hs-identifier hs-type">dropoutP</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-372"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679768739"><span class="hs-identifier hs-type">layerNormOutput</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679768739"><span class="hs-identifier hs-type">layerNormOutput</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679768739"><span class="hs-identifier hs-type">layerNormOutput</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679768735"><span class="hs-identifier hs-type">attentionBias</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-373"></span><span>      </span><span class="annot"><a href="#local-6989586621679768740"><span class="hs-identifier hs-type">generator</span></a></span><span>
</span><span id="line-374"></span><span>      </span><span class="annot"><a href="#local-6989586621679768734"><span class="hs-identifier hs-type">mhaOutput</span></a></span><span>
</span><span id="line-375"></span><span>      </span><span class="annot"><a href="#local-6989586621679768733"><span class="hs-identifier hs-type">mhaGeneratorOutput</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-376"></span><span>    </span><span class="annot"><a href="#local-6989586621679768741"><span class="hs-identifier hs-type">query</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768732"><span class="hs-identifier hs-type">gradient0</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768731"><span class="hs-identifier hs-type">layout0</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768730"><span class="hs-identifier hs-type">device0</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768729"><span class="hs-identifier hs-type">dataType0</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768728"><span class="hs-identifier hs-type">shape0</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-377"></span><span>    </span><span class="annot"><a href="#local-6989586621679768734"><span class="hs-identifier hs-type">mhaOutput</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768727"><span class="hs-identifier hs-type">gradient1</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768726"><span class="hs-identifier hs-type">layout1</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768725"><span class="hs-identifier hs-type">device1</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768724"><span class="hs-identifier hs-type">dataType1</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768723"><span class="hs-identifier hs-type">shape1</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-378"></span><span>    </span><span class="annot"><a href="#local-6989586621679768733"><span class="hs-identifier hs-type">mhaGeneratorOutput</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Random.html#Generator"><span class="hs-identifier hs-type">Generator</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768722"><span class="hs-identifier hs-type">device2</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-379"></span><span>    </span><span class="annot"><a href="#local-6989586621679768721"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-380"></span><span>      </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-381"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679768732"><span class="hs-identifier hs-type">gradient0</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768727"><span class="hs-identifier hs-type">gradient1</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-382"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679768731"><span class="hs-identifier hs-type">layout0</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768726"><span class="hs-identifier hs-type">layout1</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-383"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679768730"><span class="hs-identifier hs-type">device0</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768725"><span class="hs-identifier hs-type">device1</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768722"><span class="hs-identifier hs-type">device2</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-384"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679768729"><span class="hs-identifier hs-type">dataType0</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768724"><span class="hs-identifier hs-type">dataType1</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-385"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#BroadcastShapesF"><span class="hs-identifier hs-type">BroadcastShapesF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768728"><span class="hs-identifier hs-type">shape0</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768723"><span class="hs-identifier hs-type">shape1</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-386"></span><span>    </span><span class="annot"><a href="#local-6989586621679768720"><span class="hs-identifier hs-type">generatorOutput</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Random.html#Generator"><span class="hs-identifier hs-type">Generator</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679768725"><span class="hs-identifier hs-type">device1</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768722"><span class="hs-identifier hs-type">device2</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-387"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-388"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-389"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#SelfAttention"><span class="hs-identifier hs-type">SelfAttention</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ByT5"><span class="hs-identifier hs-type">ByT5</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768744"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768743"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768742"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768738"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768737"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768736"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768746"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768745"><span class="hs-identifier hs-type">dropoutP</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-390"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679768741"><span class="hs-identifier hs-type">query</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679768735"><span class="hs-identifier hs-type">attentionBias</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-391"></span><span>    </span><span class="annot"><a href="#local-6989586621679768740"><span class="hs-identifier hs-type">generator</span></a></span><span>
</span><span id="line-392"></span><span>    </span><span class="annot"><a href="#local-6989586621679768721"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-393"></span><span>    </span><span class="annot"><a href="#local-6989586621679768720"><span class="hs-identifier hs-type">generatorOutput</span></a></span><span>
</span><span id="line-394"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-395"></span><span>  </span><span id="local-6989586621679768718"><span class="annot"><span class="annottext">forward :: SelfAttention
  'ByT5
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  queryEmbedDim
  dropoutP
-&gt; (query, attentionBias)
-&gt; generator
-&gt; m (output, generatorOutput)
</span><a href="#local-6989586621679768718"><span class="hs-identifier hs-var hs-var hs-var hs-var">forward</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#SelfAttention"><span class="hs-identifier hs-type">SelfAttention</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#GSelfAttention"><span class="hs-identifier hs-type">GSelfAttention</span></a></span><span> </span><span class="hs-special">{</span><span id="local-6989586621679768715"><span id="local-6989586621679768716"><span id="local-6989586621679768717"><span class="annot"><span class="annottext">SADropoutF 'ByT5 dropoutP
SALayerNormF 'ByT5 gradient device dataType queryEmbedDim
SAMultiheadAttentionF
  'ByT5
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  queryEmbedDim
  dropoutP
saDropout :: SADropoutF 'ByT5 dropoutP
saLayerNorm :: SALayerNormF 'ByT5 gradient device dataType queryEmbedDim
saMultiHeadAttention :: SAMultiheadAttentionF
  'ByT5
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  queryEmbedDim
  dropoutP
saDropout :: forall mha layerNorm dropout.
GSelfAttention mha layerNorm dropout -&gt; dropout
saLayerNorm :: forall mha layerNorm dropout.
GSelfAttention mha layerNorm dropout -&gt; layerNorm
saMultiHeadAttention :: forall mha layerNorm dropout.
GSelfAttention mha layerNorm dropout -&gt; mha
</span><a href="#local-6989586621679768715"><span class="hs-glyph hs-var hs-var hs-var hs-var hs-var hs-var">..</span></a></span></span></span></span><span class="hs-special">}</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679768714"><span class="annot"><span class="annottext">query
</span><a href="#local-6989586621679768714"><span class="hs-identifier hs-var">query</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679768713"><span class="annot"><span class="annottext">attentionBias
</span><a href="#local-6989586621679768713"><span class="hs-identifier hs-var">attentionBias</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-396"></span><span>    </span><span class="annot"><span class="annottext">IxStateT m generator generatorOutput output
-&gt; generator -&gt; m (output, generatorOutput)
forall (m :: Type -&gt; Type) i j a. IxStateT m i j a -&gt; i -&gt; m (a, j)
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var hs-var">runIxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">(IxStateT m generator generatorOutput output
 -&gt; generator -&gt; m (output, generatorOutput))
-&gt; IxStateT m generator generatorOutput output
-&gt; generator
-&gt; m (output, generatorOutput)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-397"></span><span>      </span><span class="annot"><span class="annottext">query -&gt; IxStateT m generator generator query
forall k (m :: k -&gt; k -&gt; Type -&gt; Type) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">query
</span><a href="#local-6989586621679768714"><span class="hs-identifier hs-var">query</span></a></span><span>
</span><span id="line-398"></span><span>        </span><span class="annot"><span class="annottext">IxStateT m generator generator query
-&gt; (query -&gt; IxStateT m generator generator layerNormOutput)
-&gt; IxStateT m generator generator layerNormOutput
forall k1 (m :: k1 -&gt; k1 -&gt; Type -&gt; Type) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(generator -&gt; m (layerNormOutput, generator))
-&gt; IxStateT m generator generator layerNormOutput
forall (m :: Type -&gt; Type) i j a.
(i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((generator -&gt; m (layerNormOutput, generator))
 -&gt; IxStateT m generator generator layerNormOutput)
-&gt; (query -&gt; generator -&gt; m (layerNormOutput, generator))
-&gt; query
-&gt; IxStateT m generator generator layerNormOutput
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">LayerNorm
  'WithoutBias gradient device dataType ('Shape '[queryEmbedDim])
-&gt; query -&gt; generator -&gt; m (layerNormOutput, generator)
forall model input generator output generatorOutput
       (m :: Type -&gt; Type).
(HasForward model input generator output generatorOutput,
 MonadThrow m) =&gt;
model -&gt; input -&gt; generator -&gt; m (output, generatorOutput)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">LayerNorm
  'WithoutBias gradient device dataType ('Shape '[queryEmbedDim])
SALayerNormF 'ByT5 gradient device dataType queryEmbedDim
</span><a href="#local-6989586621679768716"><span class="hs-identifier hs-var">saLayerNorm</span></a></span><span>
</span><span id="line-399"></span><span>        </span><span class="annot"><span class="annottext">IxStateT m generator generator layerNormOutput
-&gt; (layerNormOutput
    -&gt; IxStateT
         m
         generator
         (Generator device2)
         (Tensor gradient1 layout1 device1 dataType1 shape1))
-&gt; IxStateT
     m
     generator
     (Generator device2)
     (Tensor gradient1 layout1 device1 dataType1 shape1)
forall k1 (m :: k1 -&gt; k1 -&gt; Type -&gt; Type) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">\</span><span id="local-6989586621679768712"><span class="annot"><span class="annottext">layerNormOutput
</span><a href="#local-6989586621679768712"><span class="hs-identifier hs-var">query'</span></a></span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">(generator
 -&gt; m (Tensor gradient1 layout1 device1 dataType1 shape1,
       Generator device2))
-&gt; IxStateT
     m
     generator
     (Generator device2)
     (Tensor gradient1 layout1 device1 dataType1 shape1)
forall (m :: Type -&gt; Type) i j a.
(i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((generator
  -&gt; m (Tensor gradient1 layout1 device1 dataType1 shape1,
        Generator device2))
 -&gt; IxStateT
      m
      generator
      (Generator device2)
      (Tensor gradient1 layout1 device1 dataType1 shape1))
-&gt; (generator
    -&gt; m (Tensor gradient1 layout1 device1 dataType1 shape1,
          Generator device2))
-&gt; IxStateT
     m
     generator
     (Generator device2)
     (Tensor gradient1 layout1 device1 dataType1 shape1)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">MultiHeadAttention
  'ByT5
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  queryEmbedDim
  queryEmbedDim
  queryEmbedDim
  dropoutP
-&gt; (layerNormOutput, layerNormOutput, layerNormOutput,
    attentionBias)
-&gt; generator
-&gt; m (Tensor gradient1 layout1 device1 dataType1 shape1,
      Generator device2)
forall model input generator output generatorOutput
       (m :: Type -&gt; Type).
(HasForward model input generator output generatorOutput,
 MonadThrow m) =&gt;
model -&gt; input -&gt; generator -&gt; m (output, generatorOutput)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">MultiHeadAttention
  'ByT5
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  queryEmbedDim
  queryEmbedDim
  queryEmbedDim
  dropoutP
SAMultiheadAttentionF
  'ByT5
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  queryEmbedDim
  dropoutP
</span><a href="#local-6989586621679768717"><span class="hs-identifier hs-var">saMultiHeadAttention</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">layerNormOutput
</span><a href="#local-6989586621679768712"><span class="hs-identifier hs-var">query'</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">layerNormOutput
</span><a href="#local-6989586621679768712"><span class="hs-identifier hs-var">query'</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">layerNormOutput
</span><a href="#local-6989586621679768712"><span class="hs-identifier hs-var">query'</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">attentionBias
</span><a href="#local-6989586621679768713"><span class="hs-identifier hs-var">attentionBias</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-400"></span><span>        </span><span class="annot"><span class="annottext">IxStateT
  m
  generator
  (Generator device2)
  (Tensor gradient1 layout1 device1 dataType1 shape1)
-&gt; (Tensor gradient1 layout1 device1 dataType1 shape1
    -&gt; IxStateT
         m
         (Generator device2)
         generatorOutput
         (Tensor
            gradient1
            layout1
            (Unify (Device (DeviceType Nat)) device1 device2)
            dataType1
            shape1))
-&gt; IxStateT
     m
     generator
     generatorOutput
     (Tensor
        gradient1
        layout1
        (Unify (Device (DeviceType Nat)) device1 device2)
        dataType1
        shape1)
forall k1 (m :: k1 -&gt; k1 -&gt; Type -&gt; Type) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(Generator device2
 -&gt; m (Tensor
         gradient1
         layout1
         (Unify (Device (DeviceType Nat)) device1 device2)
         dataType1
         shape1,
       generatorOutput))
-&gt; IxStateT
     m
     (Generator device2)
     generatorOutput
     (Tensor
        gradient1
        layout1
        (Unify (Device (DeviceType Nat)) device1 device2)
        dataType1
        shape1)
forall (m :: Type -&gt; Type) i j a.
(i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator device2
  -&gt; m (Tensor
          gradient1
          layout1
          (Unify (Device (DeviceType Nat)) device1 device2)
          dataType1
          shape1,
        generatorOutput))
 -&gt; IxStateT
      m
      (Generator device2)
      generatorOutput
      (Tensor
         gradient1
         layout1
         (Unify (Device (DeviceType Nat)) device1 device2)
         dataType1
         shape1))
-&gt; (Tensor gradient1 layout1 device1 dataType1 shape1
    -&gt; Generator device2
    -&gt; m (Tensor
            gradient1
            layout1
            (Unify (Device (DeviceType Nat)) device1 device2)
            dataType1
            shape1,
          generatorOutput))
-&gt; Tensor gradient1 layout1 device1 dataType1 shape1
-&gt; IxStateT
     m
     (Generator device2)
     generatorOutput
     (Tensor
        gradient1
        layout1
        (Unify (Device (DeviceType Nat)) device1 device2)
        dataType1
        shape1)
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Dropout dropoutP
-&gt; Tensor gradient1 layout1 device1 dataType1 shape1
-&gt; Generator device2
-&gt; m (Tensor
        gradient1
        layout1
        (Unify (Device (DeviceType Nat)) device1 device2)
        dataType1
        shape1,
      generatorOutput)
forall model input generator output generatorOutput
       (m :: Type -&gt; Type).
(HasForward model input generator output generatorOutput,
 MonadThrow m) =&gt;
model -&gt; input -&gt; generator -&gt; m (output, generatorOutput)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">Dropout dropoutP
SADropoutF 'ByT5 dropoutP
</span><a href="#local-6989586621679768715"><span class="hs-identifier hs-var">saDropout</span></a></span><span>
</span><span id="line-401"></span><span>        </span><span class="annot"><span class="annottext">IxStateT
  m
  generator
  generatorOutput
  (Tensor
     gradient1
     layout1
     (Unify (Device (DeviceType Nat)) device1 device2)
     dataType1
     shape1)
-&gt; (Tensor
      gradient1
      layout1
      (Unify (Device (DeviceType Nat)) device1 device2)
      dataType1
      shape1
    -&gt; IxStateT m generatorOutput generatorOutput output)
-&gt; IxStateT m generator generatorOutput output
forall k1 (m :: k1 -&gt; k1 -&gt; Type -&gt; Type) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">output -&gt; IxStateT m generatorOutput generatorOutput output
forall k (m :: k -&gt; k -&gt; Type -&gt; Type) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">(output -&gt; IxStateT m generatorOutput generatorOutput output)
-&gt; (Tensor
      gradient1
      layout1
      (Unify (Device (DeviceType Nat)) device1 device2)
      dataType1
      shape1
    -&gt; output)
-&gt; Tensor
     gradient1
     layout1
     (Unify (Device (DeviceType Nat)) device1 device2)
     dataType1
     shape1
-&gt; IxStateT m generatorOutput generatorOutput output
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">query
Tensor gradient0 layout0 device0 dataType0 shape0
</span><a href="#local-6989586621679768714"><span class="hs-identifier hs-var">query</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient0 layout0 device0 dataType0 shape0
-&gt; Tensor
     gradient1
     layout1
     (Unify (Device (DeviceType Nat)) device1 device2)
     dataType1
     shape1
-&gt; Tensor
     (gradient0 &lt;|&gt; gradient1)
     (layout0 &lt;+&gt; layout1)
     (device0 &lt;+&gt; Unify (Device (DeviceType Nat)) device1 device2)
     (dataType0 &lt;+&gt; dataType1)
     (BroadcastShapesF shape0 shape1)
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (gradient' :: Gradient RequiresGradient)
       (layout' :: Layout LayoutType) (device' :: Device (DeviceType Nat))
       (dataType' :: DataType DType)
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]).
Tensor gradient layout device dataType shape
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; Tensor
     (gradient &lt;|&gt; gradient')
     (layout &lt;+&gt; layout')
     (device &lt;+&gt; device')
     (dataType &lt;+&gt; dataType')
     (BroadcastShapesF shape shape')
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#add"><span class="hs-operator hs-var">`add`</span></a></span><span class="hs-special">)</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span>
</span><span id="line-402"></span><span>
</span><span id="line-403"></span><span class="hs-comment">-- | 'HasForward' instance for @SelfAttention 'BART@.</span><span>
</span><span id="line-404"></span><span class="hs-comment">--</span><span>
</span><span id="line-405"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-406"></span><span class="hs-comment">-- &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;      &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;</span><span>
</span><span id="line-407"></span><span class="hs-comment">-- &#9474; attentionBias &#9474;      &#9474; query &#9474;</span><span>
</span><span id="line-408"></span><span class="hs-comment">-- &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;      &#9492;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-409"></span><span class="hs-comment">--         &#9474;                  &#9474;</span><span>
</span><span id="line-410"></span><span class="hs-comment">--         &#9474;            &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9524;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;</span><span>
</span><span id="line-411"></span><span class="hs-comment">--         &#9474;            &#9474;           &#9474;</span><span>
</span><span id="line-412"></span><span class="hs-comment">--         &#9474;       &#9484;&#9472;&#9472;&#9472;&#9472;&#9532;&#9472;&#9472;&#9472;&#9472;&#9488;      &#9474;</span><span>
</span><span id="line-413"></span><span class="hs-comment">--         &#9474;       &#9474;    &#9474;    &#9474;      &#9474;</span><span>
</span><span id="line-414"></span><span class="hs-comment">--         &#9474;       &#9660;    &#9660;    &#9660;      &#9474;</span><span>
</span><span id="line-415"></span><span class="hs-comment">--         &#9492;&#9472;&#9658;saMultiHeadAttention  &#9474;</span><span>
</span><span id="line-416"></span><span class="hs-comment">--                      &#9474;           &#9474;</span><span>
</span><span id="line-417"></span><span class="hs-comment">--                      &#9660;           &#9474;</span><span>
</span><span id="line-418"></span><span class="hs-comment">--                  saDropout       &#9474;</span><span>
</span><span id="line-419"></span><span class="hs-comment">--                      &#9474;           &#9474;</span><span>
</span><span id="line-420"></span><span class="hs-comment">--                      &#9492;&#9472;&#9472;&#9472;&#9658;add&#9668;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-421"></span><span class="hs-comment">--                            &#9474;</span><span>
</span><span id="line-422"></span><span class="hs-comment">--                            &#9660;</span><span>
</span><span id="line-423"></span><span class="hs-comment">--                       saLayerNorm</span><span>
</span><span id="line-424"></span><span class="hs-comment">--                            &#9474;</span><span>
</span><span id="line-425"></span><span class="hs-comment">--                            &#9660;</span><span>
</span><span id="line-426"></span><span class="hs-comment">--                        &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;</span><span>
</span><span id="line-427"></span><span class="hs-comment">--                        &#9474; query &#9474;</span><span>
</span><span id="line-428"></span><span class="hs-comment">--                        &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-429"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-430"></span><span id="local-6989586621679768688"><span id="local-6989586621679768689"><span id="local-6989586621679768690"><span id="local-6989586621679768691"><span id="local-6989586621679768692"><span id="local-6989586621679768693"><span id="local-6989586621679768694"><span id="local-6989586621679768695"><span id="local-6989586621679768696"><span id="local-6989586621679768697"><span id="local-6989586621679768698"><span id="local-6989586621679768699"><span id="local-6989586621679768700"><span id="local-6989586621679768701"><span id="local-6989586621679768702"><span id="local-6989586621679768703"><span id="local-6989586621679768704"><span id="local-6989586621679768705"><span id="local-6989586621679768706"><span id="local-6989586621679768707"><span id="local-6989586621679768708"><span id="local-6989586621679768709"><span id="local-6989586621679768710"><span id="local-6989586621679768711"><span class="hs-keyword">instance</span><span>
</span><span id="line-431"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetDim"><span class="hs-identifier hs-type">SGetDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768711"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-432"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Scalar.html#Scalar"><span class="hs-identifier hs-type">Scalar</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768710"><span class="hs-identifier hs-type">dropoutP</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-433"></span><span>    </span><span class="annot"><a href="#local-6989586621679768709"><span class="hs-identifier hs-type">query</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768708"><span class="hs-identifier hs-type">queryGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768707"><span class="hs-identifier hs-type">queryLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768706"><span class="hs-identifier hs-type">queryDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768705"><span class="hs-identifier hs-type">queryDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768704"><span class="hs-identifier hs-type">queryShape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-434"></span><span>    </span><span class="annot"><a href="#local-6989586621679768703"><span class="hs-identifier hs-type">attentionBias</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768702"><span class="hs-identifier hs-type">attentionBiasGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768701"><span class="hs-identifier hs-type">attentionBiasLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768700"><span class="hs-identifier hs-type">attentionBiasDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768699"><span class="hs-identifier hs-type">attentionBiasDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768698"><span class="hs-identifier hs-type">attentionBiasShape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-435"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-436"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.MultiHeadAttention.html#MultiHeadAttention"><span class="hs-identifier hs-type">MultiHeadAttention</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768697"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768696"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768695"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768694"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768693"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768692"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768711"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768711"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768711"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768710"><span class="hs-identifier hs-type">dropoutP</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-437"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679768709"><span class="hs-identifier hs-type">query</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679768709"><span class="hs-identifier hs-type">query</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679768709"><span class="hs-identifier hs-type">query</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679768703"><span class="hs-identifier hs-type">attentionBias</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-438"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Random.html#Generator"><span class="hs-identifier hs-type">Generator</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768691"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-439"></span><span>      </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-440"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679768697"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768708"><span class="hs-identifier hs-type">queryGradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768702"><span class="hs-identifier hs-type">attentionBiasGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-441"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Dense"><span class="hs-identifier hs-type">Dense</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768707"><span class="hs-identifier hs-type">queryLayout</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768701"><span class="hs-identifier hs-type">attentionBiasLayout</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-442"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679768696"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768706"><span class="hs-identifier hs-type">queryDevice</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768700"><span class="hs-identifier hs-type">attentionBiasDevice</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768691"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-443"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679768695"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768705"><span class="hs-identifier hs-type">queryDataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768699"><span class="hs-identifier hs-type">attentionBiasDataType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-444"></span><span>          </span><span class="annot"><a href="#local-6989586621679768690"><span class="hs-identifier hs-type">mhaOutputShape</span></a></span><span>
</span><span id="line-445"></span><span>      </span><span class="hs-special">)</span><span>
</span><span id="line-446"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Random.html#Generator"><span class="hs-identifier hs-type">Generator</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679768696"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768706"><span class="hs-identifier hs-type">queryDevice</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768700"><span class="hs-identifier hs-type">attentionBiasDevice</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768691"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-447"></span><span>    </span><span class="annot"><a href="#local-6989586621679768689"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-448"></span><span>      </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-449"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679768697"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768708"><span class="hs-identifier hs-type">queryGradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768702"><span class="hs-identifier hs-type">attentionBiasGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-450"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Dense"><span class="hs-identifier hs-type">Dense</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768707"><span class="hs-identifier hs-type">queryLayout</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768701"><span class="hs-identifier hs-type">attentionBiasLayout</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-451"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679768696"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768706"><span class="hs-identifier hs-type">queryDevice</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768700"><span class="hs-identifier hs-type">attentionBiasDevice</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768691"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-452"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679768695"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768705"><span class="hs-identifier hs-type">queryDataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768699"><span class="hs-identifier hs-type">attentionBiasDataType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-453"></span><span>          </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Functional.Normalization.html#LayerNormWithBiasF"><span class="hs-identifier hs-type">LayerNormWithBiasF</span></a></span><span>
</span><span id="line-454"></span><span>              </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679768711"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-455"></span><span>              </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679768711"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-456"></span><span>              </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#BroadcastShapesF"><span class="hs-identifier hs-type">BroadcastShapesF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768704"><span class="hs-identifier hs-type">queryShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768690"><span class="hs-identifier hs-type">mhaOutputShape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-457"></span><span>          </span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-458"></span><span>    </span><span class="annot"><a href="#local-6989586621679768688"><span class="hs-identifier hs-type">generatorOutput</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Random.html#Generator"><span class="hs-identifier hs-type">Generator</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679768696"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768706"><span class="hs-identifier hs-type">queryDevice</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768700"><span class="hs-identifier hs-type">attentionBiasDevice</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768691"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-459"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-460"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-461"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#SelfAttention"><span class="hs-identifier hs-type">SelfAttention</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768697"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768696"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768695"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768694"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768693"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768692"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768711"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768710"><span class="hs-identifier hs-type">dropoutP</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-462"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679768709"><span class="hs-identifier hs-type">query</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679768703"><span class="hs-identifier hs-type">attentionBias</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-463"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Random.html#Generator"><span class="hs-identifier hs-type">Generator</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768691"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-464"></span><span>    </span><span class="annot"><a href="#local-6989586621679768689"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-465"></span><span>    </span><span class="annot"><a href="#local-6989586621679768688"><span class="hs-identifier hs-type">generatorOutput</span></a></span><span>
</span><span id="line-466"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-467"></span><span>  </span><span id="local-6989586621679768686"><span class="annot"><span class="annottext">forward :: SelfAttention
  'BART
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  queryEmbedDim
  dropoutP
-&gt; (query, attentionBias)
-&gt; Generator generatorDevice
-&gt; m (output, generatorOutput)
</span><a href="#local-6989586621679768686"><span class="hs-identifier hs-var hs-var hs-var hs-var">forward</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#SelfAttention"><span class="hs-identifier hs-type">SelfAttention</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#GSelfAttention"><span class="hs-identifier hs-type">GSelfAttention</span></a></span><span> </span><span class="hs-special">{</span><span id="local-6989586621679768683"><span id="local-6989586621679768684"><span id="local-6989586621679768685"><span class="annot"><span class="annottext">SADropoutF 'BART dropoutP
SALayerNormF 'BART gradient device dataType queryEmbedDim
SAMultiheadAttentionF
  'BART
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  queryEmbedDim
  dropoutP
saDropout :: SADropoutF 'BART dropoutP
saLayerNorm :: SALayerNormF 'BART gradient device dataType queryEmbedDim
saMultiHeadAttention :: SAMultiheadAttentionF
  'BART
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  queryEmbedDim
  dropoutP
saDropout :: forall mha layerNorm dropout.
GSelfAttention mha layerNorm dropout -&gt; dropout
saLayerNorm :: forall mha layerNorm dropout.
GSelfAttention mha layerNorm dropout -&gt; layerNorm
saMultiHeadAttention :: forall mha layerNorm dropout.
GSelfAttention mha layerNorm dropout -&gt; mha
</span><a href="#local-6989586621679768683"><span class="hs-glyph hs-var hs-var hs-var hs-var hs-var hs-var">..</span></a></span></span></span></span><span class="hs-special">}</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679768682"><span class="annot"><span class="annottext">query
</span><a href="#local-6989586621679768682"><span class="hs-identifier hs-var">query</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679768681"><span class="annot"><span class="annottext">attentionBias
</span><a href="#local-6989586621679768681"><span class="hs-identifier hs-var">attentionBias</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-468"></span><span>    </span><span class="annot"><span class="annottext">IxStateT m (Generator generatorDevice) generatorOutput output
-&gt; Generator generatorDevice -&gt; m (output, generatorOutput)
forall (m :: Type -&gt; Type) i j a. IxStateT m i j a -&gt; i -&gt; m (a, j)
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var hs-var">runIxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">(IxStateT m (Generator generatorDevice) generatorOutput output
 -&gt; Generator generatorDevice -&gt; m (output, generatorOutput))
-&gt; IxStateT m (Generator generatorDevice) generatorOutput output
-&gt; Generator generatorDevice
-&gt; m (output, generatorOutput)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-469"></span><span>      </span><span class="annot"><span class="annottext">query
-&gt; IxStateT
     m (Generator generatorDevice) (Generator generatorDevice) query
forall k (m :: k -&gt; k -&gt; Type -&gt; Type) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">query
</span><a href="#local-6989586621679768682"><span class="hs-identifier hs-var">query</span></a></span><span>
</span><span id="line-470"></span><span>        </span><span class="annot"><span class="annottext">IxStateT
  m (Generator generatorDevice) (Generator generatorDevice) query
-&gt; (query
    -&gt; IxStateT
         m
         (Generator generatorDevice)
         (Generator
            (Unify
               (Device (DeviceType Nat))
               device
               (Unify
                  (Device (DeviceType Nat))
                  queryDevice
                  (Unify
                     (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
         (Tensor
            (Or
               (Gradient RequiresGradient)
               gradient
               (Or
                  (Gradient RequiresGradient) queryGradient attentionBiasGradient))
            (Unify
               (Layout LayoutType)
               ('Layout 'Dense)
               (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
            (Unify
               (Device (DeviceType Nat))
               device
               (Unify
                  (Device (DeviceType Nat))
                  queryDevice
                  (Unify
                     (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
            (Unify
               (DataType DType)
               dataType
               (Unify (DataType DType) queryDataType attentionBiasDataType))
            mhaOutputShape))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator
        (Unify
           (Device (DeviceType Nat))
           device
           (Unify
              (Device (DeviceType Nat))
              queryDevice
              (Unify
                 (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
     (Tensor
        (Or
           (Gradient RequiresGradient)
           gradient
           (Or
              (Gradient RequiresGradient) queryGradient attentionBiasGradient))
        (Unify
           (Layout LayoutType)
           ('Layout 'Dense)
           (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
        (Unify
           (Device (DeviceType Nat))
           device
           (Unify
              (Device (DeviceType Nat))
              queryDevice
              (Unify
                 (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
        (Unify
           (DataType DType)
           dataType
           (Unify (DataType DType) queryDataType attentionBiasDataType))
        mhaOutputShape)
forall k1 (m :: k1 -&gt; k1 -&gt; Type -&gt; Type) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">\</span><span id="local-6989586621679768680"><span class="annot"><span class="annottext">query
</span><a href="#local-6989586621679768680"><span class="hs-identifier hs-var">query'</span></a></span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">(Generator generatorDevice
 -&gt; m (Tensor
         (Or
            (Gradient RequiresGradient)
            gradient
            (Or
               (Gradient RequiresGradient) queryGradient attentionBiasGradient))
         (Unify
            (Layout LayoutType)
            ('Layout 'Dense)
            (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
         (Unify
            (Device (DeviceType Nat))
            device
            (Unify
               (Device (DeviceType Nat))
               queryDevice
               (Unify
                  (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
         (Unify
            (DataType DType)
            dataType
            (Unify (DataType DType) queryDataType attentionBiasDataType))
         mhaOutputShape,
       Generator
         (Unify
            (Device (DeviceType Nat))
            device
            (Unify
               (Device (DeviceType Nat))
               queryDevice
               (Unify
                  (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator
        (Unify
           (Device (DeviceType Nat))
           device
           (Unify
              (Device (DeviceType Nat))
              queryDevice
              (Unify
                 (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
     (Tensor
        (Or
           (Gradient RequiresGradient)
           gradient
           (Or
              (Gradient RequiresGradient) queryGradient attentionBiasGradient))
        (Unify
           (Layout LayoutType)
           ('Layout 'Dense)
           (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
        (Unify
           (Device (DeviceType Nat))
           device
           (Unify
              (Device (DeviceType Nat))
              queryDevice
              (Unify
                 (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
        (Unify
           (DataType DType)
           dataType
           (Unify (DataType DType) queryDataType attentionBiasDataType))
        mhaOutputShape)
forall (m :: Type -&gt; Type) i j a.
(i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator generatorDevice
  -&gt; m (Tensor
          (Or
             (Gradient RequiresGradient)
             gradient
             (Or
                (Gradient RequiresGradient) queryGradient attentionBiasGradient))
          (Unify
             (Layout LayoutType)
             ('Layout 'Dense)
             (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
          (Unify
             (Device (DeviceType Nat))
             device
             (Unify
                (Device (DeviceType Nat))
                queryDevice
                (Unify
                   (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
          (Unify
             (DataType DType)
             dataType
             (Unify (DataType DType) queryDataType attentionBiasDataType))
          mhaOutputShape,
        Generator
          (Unify
             (Device (DeviceType Nat))
             device
             (Unify
                (Device (DeviceType Nat))
                queryDevice
                (Unify
                   (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))))
 -&gt; IxStateT
      m
      (Generator generatorDevice)
      (Generator
         (Unify
            (Device (DeviceType Nat))
            device
            (Unify
               (Device (DeviceType Nat))
               queryDevice
               (Unify
                  (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
      (Tensor
         (Or
            (Gradient RequiresGradient)
            gradient
            (Or
               (Gradient RequiresGradient) queryGradient attentionBiasGradient))
         (Unify
            (Layout LayoutType)
            ('Layout 'Dense)
            (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
         (Unify
            (Device (DeviceType Nat))
            device
            (Unify
               (Device (DeviceType Nat))
               queryDevice
               (Unify
                  (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
         (Unify
            (DataType DType)
            dataType
            (Unify (DataType DType) queryDataType attentionBiasDataType))
         mhaOutputShape))
-&gt; (Generator generatorDevice
    -&gt; m (Tensor
            (Or
               (Gradient RequiresGradient)
               gradient
               (Or
                  (Gradient RequiresGradient) queryGradient attentionBiasGradient))
            (Unify
               (Layout LayoutType)
               ('Layout 'Dense)
               (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
            (Unify
               (Device (DeviceType Nat))
               device
               (Unify
                  (Device (DeviceType Nat))
                  queryDevice
                  (Unify
                     (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
            (Unify
               (DataType DType)
               dataType
               (Unify (DataType DType) queryDataType attentionBiasDataType))
            mhaOutputShape,
          Generator
            (Unify
               (Device (DeviceType Nat))
               device
               (Unify
                  (Device (DeviceType Nat))
                  queryDevice
                  (Unify
                     (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator
        (Unify
           (Device (DeviceType Nat))
           device
           (Unify
              (Device (DeviceType Nat))
              queryDevice
              (Unify
                 (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
     (Tensor
        (Or
           (Gradient RequiresGradient)
           gradient
           (Or
              (Gradient RequiresGradient) queryGradient attentionBiasGradient))
        (Unify
           (Layout LayoutType)
           ('Layout 'Dense)
           (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
        (Unify
           (Device (DeviceType Nat))
           device
           (Unify
              (Device (DeviceType Nat))
              queryDevice
              (Unify
                 (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
        (Unify
           (DataType DType)
           dataType
           (Unify (DataType DType) queryDataType attentionBiasDataType))
        mhaOutputShape)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">MultiHeadAttention
  'BART
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  queryEmbedDim
  queryEmbedDim
  queryEmbedDim
  dropoutP
-&gt; (query, query, query, attentionBias)
-&gt; Generator generatorDevice
-&gt; m (Tensor
        (Or
           (Gradient RequiresGradient)
           gradient
           (Or
              (Gradient RequiresGradient) queryGradient attentionBiasGradient))
        (Unify
           (Layout LayoutType)
           ('Layout 'Dense)
           (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
        (Unify
           (Device (DeviceType Nat))
           device
           (Unify
              (Device (DeviceType Nat))
              queryDevice
              (Unify
                 (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
        (Unify
           (DataType DType)
           dataType
           (Unify (DataType DType) queryDataType attentionBiasDataType))
        mhaOutputShape,
      Generator
        (Unify
           (Device (DeviceType Nat))
           device
           (Unify
              (Device (DeviceType Nat))
              queryDevice
              (Unify
                 (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
forall model input generator output generatorOutput
       (m :: Type -&gt; Type).
(HasForward model input generator output generatorOutput,
 MonadThrow m) =&gt;
model -&gt; input -&gt; generator -&gt; m (output, generatorOutput)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">MultiHeadAttention
  'BART
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  queryEmbedDim
  queryEmbedDim
  queryEmbedDim
  dropoutP
SAMultiheadAttentionF
  'BART
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  queryEmbedDim
  dropoutP
</span><a href="#local-6989586621679768685"><span class="hs-identifier hs-var">saMultiHeadAttention</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">query
</span><a href="#local-6989586621679768680"><span class="hs-identifier hs-var">query'</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">query
</span><a href="#local-6989586621679768680"><span class="hs-identifier hs-var">query'</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">query
</span><a href="#local-6989586621679768680"><span class="hs-identifier hs-var">query'</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">attentionBias
</span><a href="#local-6989586621679768681"><span class="hs-identifier hs-var">attentionBias</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-471"></span><span>        </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator
     (Unify
        (Device (DeviceType Nat))
        device
        (Unify
           (Device (DeviceType Nat))
           queryDevice
           (Unify
              (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
  (Tensor
     (Or
        (Gradient RequiresGradient)
        gradient
        (Or
           (Gradient RequiresGradient) queryGradient attentionBiasGradient))
     (Unify
        (Layout LayoutType)
        ('Layout 'Dense)
        (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
     (Unify
        (Device (DeviceType Nat))
        device
        (Unify
           (Device (DeviceType Nat))
           queryDevice
           (Unify
              (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
     (Unify
        (DataType DType)
        dataType
        (Unify (DataType DType) queryDataType attentionBiasDataType))
     mhaOutputShape)
-&gt; (Tensor
      (Or
         (Gradient RequiresGradient)
         gradient
         (Or
            (Gradient RequiresGradient) queryGradient attentionBiasGradient))
      (Unify
         (Layout LayoutType)
         ('Layout 'Dense)
         (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
      (Unify
         (Device (DeviceType Nat))
         device
         (Unify
            (Device (DeviceType Nat))
            queryDevice
            (Unify
               (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
      (Unify
         (DataType DType)
         dataType
         (Unify (DataType DType) queryDataType attentionBiasDataType))
      mhaOutputShape
    -&gt; IxStateT
         m
         (Generator
            (Unify
               (Device (DeviceType Nat))
               device
               (Unify
                  (Device (DeviceType Nat))
                  queryDevice
                  (Unify
                     (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
         (Generator
            (Unify
               (Device (DeviceType Nat))
               device
               (Unify
                  (Device (DeviceType Nat))
                  queryDevice
                  (Unify
                     (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
         (Tensor
            (Or
               (Gradient RequiresGradient)
               gradient
               (Or
                  (Gradient RequiresGradient) queryGradient attentionBiasGradient))
            (Unify
               (Layout LayoutType)
               ('Layout 'Dense)
               (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
            (Unify
               (Device (DeviceType Nat))
               device
               (Unify
                  (Device (DeviceType Nat))
                  queryDevice
                  (Unify
                     (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
            (Unify
               (DataType DType)
               dataType
               (Unify (DataType DType) queryDataType attentionBiasDataType))
            mhaOutputShape))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator
        (Unify
           (Device (DeviceType Nat))
           device
           (Unify
              (Device (DeviceType Nat))
              queryDevice
              (Unify
                 (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
     (Tensor
        (Or
           (Gradient RequiresGradient)
           gradient
           (Or
              (Gradient RequiresGradient) queryGradient attentionBiasGradient))
        (Unify
           (Layout LayoutType)
           ('Layout 'Dense)
           (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
        (Unify
           (Device (DeviceType Nat))
           device
           (Unify
              (Device (DeviceType Nat))
              queryDevice
              (Unify
                 (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
        (Unify
           (DataType DType)
           dataType
           (Unify (DataType DType) queryDataType attentionBiasDataType))
        mhaOutputShape)
forall k1 (m :: k1 -&gt; k1 -&gt; Type -&gt; Type) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(Generator
   (Unify
      (Device (DeviceType Nat))
      device
      (Unify
         (Device (DeviceType Nat))
         queryDevice
         (Unify
            (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
 -&gt; m (Tensor
         (Or
            (Gradient RequiresGradient)
            gradient
            (Or
               (Gradient RequiresGradient) queryGradient attentionBiasGradient))
         (Unify
            (Layout LayoutType)
            ('Layout 'Dense)
            (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
         (Unify
            (Device (DeviceType Nat))
            device
            (Unify
               (Device (DeviceType Nat))
               queryDevice
               (Unify
                  (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
         (Unify
            (DataType DType)
            dataType
            (Unify (DataType DType) queryDataType attentionBiasDataType))
         mhaOutputShape,
       Generator
         (Unify
            (Device (DeviceType Nat))
            device
            (Unify
               (Device (DeviceType Nat))
               queryDevice
               (Unify
                  (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))))
-&gt; IxStateT
     m
     (Generator
        (Unify
           (Device (DeviceType Nat))
           device
           (Unify
              (Device (DeviceType Nat))
              queryDevice
              (Unify
                 (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
     (Generator
        (Unify
           (Device (DeviceType Nat))
           device
           (Unify
              (Device (DeviceType Nat))
              queryDevice
              (Unify
                 (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
     (Tensor
        (Or
           (Gradient RequiresGradient)
           gradient
           (Or
              (Gradient RequiresGradient) queryGradient attentionBiasGradient))
        (Unify
           (Layout LayoutType)
           ('Layout 'Dense)
           (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
        (Unify
           (Device (DeviceType Nat))
           device
           (Unify
              (Device (DeviceType Nat))
              queryDevice
              (Unify
                 (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
        (Unify
           (DataType DType)
           dataType
           (Unify (DataType DType) queryDataType attentionBiasDataType))
        mhaOutputShape)
forall (m :: Type -&gt; Type) i j a.
(i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator
    (Unify
       (Device (DeviceType Nat))
       device
       (Unify
          (Device (DeviceType Nat))
          queryDevice
          (Unify
             (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
  -&gt; m (Tensor
          (Or
             (Gradient RequiresGradient)
             gradient
             (Or
                (Gradient RequiresGradient) queryGradient attentionBiasGradient))
          (Unify
             (Layout LayoutType)
             ('Layout 'Dense)
             (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
          (Unify
             (Device (DeviceType Nat))
             device
             (Unify
                (Device (DeviceType Nat))
                queryDevice
                (Unify
                   (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
          (Unify
             (DataType DType)
             dataType
             (Unify (DataType DType) queryDataType attentionBiasDataType))
          mhaOutputShape,
        Generator
          (Unify
             (Device (DeviceType Nat))
             device
             (Unify
                (Device (DeviceType Nat))
                queryDevice
                (Unify
                   (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))))
 -&gt; IxStateT
      m
      (Generator
         (Unify
            (Device (DeviceType Nat))
            device
            (Unify
               (Device (DeviceType Nat))
               queryDevice
               (Unify
                  (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
      (Generator
         (Unify
            (Device (DeviceType Nat))
            device
            (Unify
               (Device (DeviceType Nat))
               queryDevice
               (Unify
                  (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
      (Tensor
         (Or
            (Gradient RequiresGradient)
            gradient
            (Or
               (Gradient RequiresGradient) queryGradient attentionBiasGradient))
         (Unify
            (Layout LayoutType)
            ('Layout 'Dense)
            (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
         (Unify
            (Device (DeviceType Nat))
            device
            (Unify
               (Device (DeviceType Nat))
               queryDevice
               (Unify
                  (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
         (Unify
            (DataType DType)
            dataType
            (Unify (DataType DType) queryDataType attentionBiasDataType))
         mhaOutputShape))
-&gt; (Tensor
      (Or
         (Gradient RequiresGradient)
         gradient
         (Or
            (Gradient RequiresGradient) queryGradient attentionBiasGradient))
      (Unify
         (Layout LayoutType)
         ('Layout 'Dense)
         (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
      (Unify
         (Device (DeviceType Nat))
         device
         (Unify
            (Device (DeviceType Nat))
            queryDevice
            (Unify
               (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
      (Unify
         (DataType DType)
         dataType
         (Unify (DataType DType) queryDataType attentionBiasDataType))
      mhaOutputShape
    -&gt; Generator
         (Unify
            (Device (DeviceType Nat))
            device
            (Unify
               (Device (DeviceType Nat))
               queryDevice
               (Unify
                  (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
    -&gt; m (Tensor
            (Or
               (Gradient RequiresGradient)
               gradient
               (Or
                  (Gradient RequiresGradient) queryGradient attentionBiasGradient))
            (Unify
               (Layout LayoutType)
               ('Layout 'Dense)
               (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
            (Unify
               (Device (DeviceType Nat))
               device
               (Unify
                  (Device (DeviceType Nat))
                  queryDevice
                  (Unify
                     (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
            (Unify
               (DataType DType)
               dataType
               (Unify (DataType DType) queryDataType attentionBiasDataType))
            mhaOutputShape,
          Generator
            (Unify
               (Device (DeviceType Nat))
               device
               (Unify
                  (Device (DeviceType Nat))
                  queryDevice
                  (Unify
                     (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))))
-&gt; Tensor
     (Or
        (Gradient RequiresGradient)
        gradient
        (Or
           (Gradient RequiresGradient) queryGradient attentionBiasGradient))
     (Unify
        (Layout LayoutType)
        ('Layout 'Dense)
        (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
     (Unify
        (Device (DeviceType Nat))
        device
        (Unify
           (Device (DeviceType Nat))
           queryDevice
           (Unify
              (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
     (Unify
        (DataType DType)
        dataType
        (Unify (DataType DType) queryDataType attentionBiasDataType))
     mhaOutputShape
-&gt; IxStateT
     m
     (Generator
        (Unify
           (Device (DeviceType Nat))
           device
           (Unify
              (Device (DeviceType Nat))
              queryDevice
              (Unify
                 (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
     (Generator
        (Unify
           (Device (DeviceType Nat))
           device
           (Unify
              (Device (DeviceType Nat))
              queryDevice
              (Unify
                 (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
     (Tensor
        (Or
           (Gradient RequiresGradient)
           gradient
           (Or
              (Gradient RequiresGradient) queryGradient attentionBiasGradient))
        (Unify
           (Layout LayoutType)
           ('Layout 'Dense)
           (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
        (Unify
           (Device (DeviceType Nat))
           device
           (Unify
              (Device (DeviceType Nat))
              queryDevice
              (Unify
                 (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
        (Unify
           (DataType DType)
           dataType
           (Unify (DataType DType) queryDataType attentionBiasDataType))
        mhaOutputShape)
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Dropout dropoutP
-&gt; Tensor
     (Or
        (Gradient RequiresGradient)
        gradient
        (Or
           (Gradient RequiresGradient) queryGradient attentionBiasGradient))
     (Unify
        (Layout LayoutType)
        ('Layout 'Dense)
        (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
     (Unify
        (Device (DeviceType Nat))
        device
        (Unify
           (Device (DeviceType Nat))
           queryDevice
           (Unify
              (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
     (Unify
        (DataType DType)
        dataType
        (Unify (DataType DType) queryDataType attentionBiasDataType))
     mhaOutputShape
-&gt; Generator
     (Unify
        (Device (DeviceType Nat))
        device
        (Unify
           (Device (DeviceType Nat))
           queryDevice
           (Unify
              (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
-&gt; m (Tensor
        (Or
           (Gradient RequiresGradient)
           gradient
           (Or
              (Gradient RequiresGradient) queryGradient attentionBiasGradient))
        (Unify
           (Layout LayoutType)
           ('Layout 'Dense)
           (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
        (Unify
           (Device (DeviceType Nat))
           device
           (Unify
              (Device (DeviceType Nat))
              queryDevice
              (Unify
                 (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
        (Unify
           (DataType DType)
           dataType
           (Unify (DataType DType) queryDataType attentionBiasDataType))
        mhaOutputShape,
      Generator
        (Unify
           (Device (DeviceType Nat))
           device
           (Unify
              (Device (DeviceType Nat))
              queryDevice
              (Unify
                 (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
forall model input generator output generatorOutput
       (m :: Type -&gt; Type).
(HasForward model input generator output generatorOutput,
 MonadThrow m) =&gt;
model -&gt; input -&gt; generator -&gt; m (output, generatorOutput)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">Dropout dropoutP
SADropoutF 'BART dropoutP
</span><a href="#local-6989586621679768683"><span class="hs-identifier hs-var">saDropout</span></a></span><span>
</span><span id="line-472"></span><span>        </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator
     (Unify
        (Device (DeviceType Nat))
        device
        (Unify
           (Device (DeviceType Nat))
           queryDevice
           (Unify
              (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
  (Tensor
     (Or
        (Gradient RequiresGradient)
        gradient
        (Or
           (Gradient RequiresGradient) queryGradient attentionBiasGradient))
     (Unify
        (Layout LayoutType)
        ('Layout 'Dense)
        (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
     (Unify
        (Device (DeviceType Nat))
        device
        (Unify
           (Device (DeviceType Nat))
           queryDevice
           (Unify
              (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
     (Unify
        (DataType DType)
        dataType
        (Unify (DataType DType) queryDataType attentionBiasDataType))
     mhaOutputShape)
-&gt; (Tensor
      (Or
         (Gradient RequiresGradient)
         gradient
         (Or
            (Gradient RequiresGradient) queryGradient attentionBiasGradient))
      (Unify
         (Layout LayoutType)
         ('Layout 'Dense)
         (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
      (Unify
         (Device (DeviceType Nat))
         device
         (Unify
            (Device (DeviceType Nat))
            queryDevice
            (Unify
               (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
      (Unify
         (DataType DType)
         dataType
         (Unify (DataType DType) queryDataType attentionBiasDataType))
      mhaOutputShape
    -&gt; IxStateT
         m
         (Generator
            (Unify
               (Device (DeviceType Nat))
               device
               (Unify
                  (Device (DeviceType Nat))
                  queryDevice
                  (Unify
                     (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
         (Generator
            (Unify
               (Device (DeviceType Nat))
               device
               (Unify
                  (Device (DeviceType Nat))
                  queryDevice
                  (Unify
                     (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
         (Tensor
            (Or
               (Gradient RequiresGradient)
               queryGradient
               (Or
                  (Gradient RequiresGradient)
                  gradient
                  (Or
                     (Gradient RequiresGradient) queryGradient attentionBiasGradient)))
            (Unify
               (Layout LayoutType)
               queryLayout
               (Unify
                  (Layout LayoutType)
                  ('Layout 'Dense)
                  (Unify (Layout LayoutType) queryLayout attentionBiasLayout)))
            (Unify
               (Device (DeviceType Nat))
               queryDevice
               (Unify
                  (Device (DeviceType Nat))
                  device
                  (Unify
                     (Device (DeviceType Nat))
                     queryDevice
                     (Unify
                        (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
            (Unify
               (DataType DType)
               queryDataType
               (Unify
                  (DataType DType)
                  dataType
                  (Unify (DataType DType) queryDataType attentionBiasDataType)))
            (BroadcastShapesF queryShape mhaOutputShape)))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator
        (Unify
           (Device (DeviceType Nat))
           device
           (Unify
              (Device (DeviceType Nat))
              queryDevice
              (Unify
                 (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
     (Tensor
        (Or
           (Gradient RequiresGradient)
           queryGradient
           (Or
              (Gradient RequiresGradient)
              gradient
              (Or
                 (Gradient RequiresGradient) queryGradient attentionBiasGradient)))
        (Unify
           (Layout LayoutType)
           queryLayout
           (Unify
              (Layout LayoutType)
              ('Layout 'Dense)
              (Unify (Layout LayoutType) queryLayout attentionBiasLayout)))
        (Unify
           (Device (DeviceType Nat))
           queryDevice
           (Unify
              (Device (DeviceType Nat))
              device
              (Unify
                 (Device (DeviceType Nat))
                 queryDevice
                 (Unify
                    (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
        (Unify
           (DataType DType)
           queryDataType
           (Unify
              (DataType DType)
              dataType
              (Unify (DataType DType) queryDataType attentionBiasDataType)))
        (BroadcastShapesF queryShape mhaOutputShape))
forall k1 (m :: k1 -&gt; k1 -&gt; Type -&gt; Type) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  (Or
     (Gradient RequiresGradient)
     queryGradient
     (Or
        (Gradient RequiresGradient)
        gradient
        (Or
           (Gradient RequiresGradient) queryGradient attentionBiasGradient)))
  (Unify
     (Layout LayoutType)
     queryLayout
     (Unify
        (Layout LayoutType)
        ('Layout 'Dense)
        (Unify (Layout LayoutType) queryLayout attentionBiasLayout)))
  (Unify
     (Device (DeviceType Nat))
     queryDevice
     (Unify
        (Device (DeviceType Nat))
        device
        (Unify
           (Device (DeviceType Nat))
           queryDevice
           (Unify
              (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
  (Unify
     (DataType DType)
     queryDataType
     (Unify
        (DataType DType)
        dataType
        (Unify (DataType DType) queryDataType attentionBiasDataType)))
  (BroadcastShapesF queryShape mhaOutputShape)
-&gt; IxStateT
     m
     (Generator
        (Unify
           (Device (DeviceType Nat))
           device
           (Unify
              (Device (DeviceType Nat))
              queryDevice
              (Unify
                 (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
     (Generator
        (Unify
           (Device (DeviceType Nat))
           device
           (Unify
              (Device (DeviceType Nat))
              queryDevice
              (Unify
                 (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
     (Tensor
        (Or
           (Gradient RequiresGradient)
           queryGradient
           (Or
              (Gradient RequiresGradient)
              gradient
              (Or
                 (Gradient RequiresGradient) queryGradient attentionBiasGradient)))
        (Unify
           (Layout LayoutType)
           queryLayout
           (Unify
              (Layout LayoutType)
              ('Layout 'Dense)
              (Unify (Layout LayoutType) queryLayout attentionBiasLayout)))
        (Unify
           (Device (DeviceType Nat))
           queryDevice
           (Unify
              (Device (DeviceType Nat))
              device
              (Unify
                 (Device (DeviceType Nat))
                 queryDevice
                 (Unify
                    (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
        (Unify
           (DataType DType)
           queryDataType
           (Unify
              (DataType DType)
              dataType
              (Unify (DataType DType) queryDataType attentionBiasDataType)))
        (BroadcastShapesF queryShape mhaOutputShape))
forall k (m :: k -&gt; k -&gt; Type -&gt; Type) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">(Tensor
   (Or
      (Gradient RequiresGradient)
      queryGradient
      (Or
         (Gradient RequiresGradient)
         gradient
         (Or
            (Gradient RequiresGradient) queryGradient attentionBiasGradient)))
   (Unify
      (Layout LayoutType)
      queryLayout
      (Unify
         (Layout LayoutType)
         ('Layout 'Dense)
         (Unify (Layout LayoutType) queryLayout attentionBiasLayout)))
   (Unify
      (Device (DeviceType Nat))
      queryDevice
      (Unify
         (Device (DeviceType Nat))
         device
         (Unify
            (Device (DeviceType Nat))
            queryDevice
            (Unify
               (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
   (Unify
      (DataType DType)
      queryDataType
      (Unify
         (DataType DType)
         dataType
         (Unify (DataType DType) queryDataType attentionBiasDataType)))
   (BroadcastShapesF queryShape mhaOutputShape)
 -&gt; IxStateT
      m
      (Generator
         (Unify
            (Device (DeviceType Nat))
            device
            (Unify
               (Device (DeviceType Nat))
               queryDevice
               (Unify
                  (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
      (Generator
         (Unify
            (Device (DeviceType Nat))
            device
            (Unify
               (Device (DeviceType Nat))
               queryDevice
               (Unify
                  (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
      (Tensor
         (Or
            (Gradient RequiresGradient)
            queryGradient
            (Or
               (Gradient RequiresGradient)
               gradient
               (Or
                  (Gradient RequiresGradient) queryGradient attentionBiasGradient)))
         (Unify
            (Layout LayoutType)
            queryLayout
            (Unify
               (Layout LayoutType)
               ('Layout 'Dense)
               (Unify (Layout LayoutType) queryLayout attentionBiasLayout)))
         (Unify
            (Device (DeviceType Nat))
            queryDevice
            (Unify
               (Device (DeviceType Nat))
               device
               (Unify
                  (Device (DeviceType Nat))
                  queryDevice
                  (Unify
                     (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
         (Unify
            (DataType DType)
            queryDataType
            (Unify
               (DataType DType)
               dataType
               (Unify (DataType DType) queryDataType attentionBiasDataType)))
         (BroadcastShapesF queryShape mhaOutputShape)))
-&gt; (Tensor
      (Or
         (Gradient RequiresGradient)
         gradient
         (Or
            (Gradient RequiresGradient) queryGradient attentionBiasGradient))
      (Unify
         (Layout LayoutType)
         ('Layout 'Dense)
         (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
      (Unify
         (Device (DeviceType Nat))
         device
         (Unify
            (Device (DeviceType Nat))
            queryDevice
            (Unify
               (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
      (Unify
         (DataType DType)
         dataType
         (Unify (DataType DType) queryDataType attentionBiasDataType))
      mhaOutputShape
    -&gt; Tensor
         (Or
            (Gradient RequiresGradient)
            queryGradient
            (Or
               (Gradient RequiresGradient)
               gradient
               (Or
                  (Gradient RequiresGradient) queryGradient attentionBiasGradient)))
         (Unify
            (Layout LayoutType)
            queryLayout
            (Unify
               (Layout LayoutType)
               ('Layout 'Dense)
               (Unify (Layout LayoutType) queryLayout attentionBiasLayout)))
         (Unify
            (Device (DeviceType Nat))
            queryDevice
            (Unify
               (Device (DeviceType Nat))
               device
               (Unify
                  (Device (DeviceType Nat))
                  queryDevice
                  (Unify
                     (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
         (Unify
            (DataType DType)
            queryDataType
            (Unify
               (DataType DType)
               dataType
               (Unify (DataType DType) queryDataType attentionBiasDataType)))
         (BroadcastShapesF queryShape mhaOutputShape))
-&gt; Tensor
     (Or
        (Gradient RequiresGradient)
        gradient
        (Or
           (Gradient RequiresGradient) queryGradient attentionBiasGradient))
     (Unify
        (Layout LayoutType)
        ('Layout 'Dense)
        (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
     (Unify
        (Device (DeviceType Nat))
        device
        (Unify
           (Device (DeviceType Nat))
           queryDevice
           (Unify
              (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
     (Unify
        (DataType DType)
        dataType
        (Unify (DataType DType) queryDataType attentionBiasDataType))
     mhaOutputShape
-&gt; IxStateT
     m
     (Generator
        (Unify
           (Device (DeviceType Nat))
           device
           (Unify
              (Device (DeviceType Nat))
              queryDevice
              (Unify
                 (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
     (Generator
        (Unify
           (Device (DeviceType Nat))
           device
           (Unify
              (Device (DeviceType Nat))
              queryDevice
              (Unify
                 (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
     (Tensor
        (Or
           (Gradient RequiresGradient)
           queryGradient
           (Or
              (Gradient RequiresGradient)
              gradient
              (Or
                 (Gradient RequiresGradient) queryGradient attentionBiasGradient)))
        (Unify
           (Layout LayoutType)
           queryLayout
           (Unify
              (Layout LayoutType)
              ('Layout 'Dense)
              (Unify (Layout LayoutType) queryLayout attentionBiasLayout)))
        (Unify
           (Device (DeviceType Nat))
           queryDevice
           (Unify
              (Device (DeviceType Nat))
              device
              (Unify
                 (Device (DeviceType Nat))
                 queryDevice
                 (Unify
                    (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
        (Unify
           (DataType DType)
           queryDataType
           (Unify
              (DataType DType)
              dataType
              (Unify (DataType DType) queryDataType attentionBiasDataType)))
        (BroadcastShapesF queryShape mhaOutputShape))
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">query
Tensor
  queryGradient queryLayout queryDevice queryDataType queryShape
</span><a href="#local-6989586621679768682"><span class="hs-identifier hs-var">query</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  queryGradient queryLayout queryDevice queryDataType queryShape
-&gt; Tensor
     (Or
        (Gradient RequiresGradient)
        gradient
        (Or
           (Gradient RequiresGradient) queryGradient attentionBiasGradient))
     (Unify
        (Layout LayoutType)
        ('Layout 'Dense)
        (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
     (Unify
        (Device (DeviceType Nat))
        device
        (Unify
           (Device (DeviceType Nat))
           queryDevice
           (Unify
              (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
     (Unify
        (DataType DType)
        dataType
        (Unify (DataType DType) queryDataType attentionBiasDataType))
     mhaOutputShape
-&gt; Tensor
     (queryGradient
      &lt;|&gt; Or
            (Gradient RequiresGradient)
            gradient
            (Or
               (Gradient RequiresGradient) queryGradient attentionBiasGradient))
     (queryLayout
      &lt;+&gt; Unify
            (Layout LayoutType)
            ('Layout 'Dense)
            (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
     (queryDevice
      &lt;+&gt; Unify
            (Device (DeviceType Nat))
            device
            (Unify
               (Device (DeviceType Nat))
               queryDevice
               (Unify
                  (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
     (queryDataType
      &lt;+&gt; Unify
            (DataType DType)
            dataType
            (Unify (DataType DType) queryDataType attentionBiasDataType))
     (BroadcastShapesF queryShape mhaOutputShape)
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (gradient' :: Gradient RequiresGradient)
       (layout' :: Layout LayoutType) (device' :: Device (DeviceType Nat))
       (dataType' :: DataType DType)
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]).
Tensor gradient layout device dataType shape
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; Tensor
     (gradient &lt;|&gt; gradient')
     (layout &lt;+&gt; layout')
     (device &lt;+&gt; device')
     (dataType &lt;+&gt; dataType')
     (BroadcastShapesF shape shape')
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#add"><span class="hs-operator hs-var">`add`</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-473"></span><span>        </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator
     (Unify
        (Device (DeviceType Nat))
        device
        (Unify
           (Device (DeviceType Nat))
           queryDevice
           (Unify
              (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
  (Tensor
     (Or
        (Gradient RequiresGradient)
        queryGradient
        (Or
           (Gradient RequiresGradient)
           gradient
           (Or
              (Gradient RequiresGradient) queryGradient attentionBiasGradient)))
     (Unify
        (Layout LayoutType)
        queryLayout
        (Unify
           (Layout LayoutType)
           ('Layout 'Dense)
           (Unify (Layout LayoutType) queryLayout attentionBiasLayout)))
     (Unify
        (Device (DeviceType Nat))
        queryDevice
        (Unify
           (Device (DeviceType Nat))
           device
           (Unify
              (Device (DeviceType Nat))
              queryDevice
              (Unify
                 (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
     (Unify
        (DataType DType)
        queryDataType
        (Unify
           (DataType DType)
           dataType
           (Unify (DataType DType) queryDataType attentionBiasDataType)))
     (BroadcastShapesF queryShape mhaOutputShape))
-&gt; (Tensor
      (Or
         (Gradient RequiresGradient)
         queryGradient
         (Or
            (Gradient RequiresGradient)
            gradient
            (Or
               (Gradient RequiresGradient) queryGradient attentionBiasGradient)))
      (Unify
         (Layout LayoutType)
         queryLayout
         (Unify
            (Layout LayoutType)
            ('Layout 'Dense)
            (Unify (Layout LayoutType) queryLayout attentionBiasLayout)))
      (Unify
         (Device (DeviceType Nat))
         queryDevice
         (Unify
            (Device (DeviceType Nat))
            device
            (Unify
               (Device (DeviceType Nat))
               queryDevice
               (Unify
                  (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
      (Unify
         (DataType DType)
         queryDataType
         (Unify
            (DataType DType)
            dataType
            (Unify (DataType DType) queryDataType attentionBiasDataType)))
      (BroadcastShapesF queryShape mhaOutputShape)
    -&gt; IxStateT
         m
         (Generator
            (Unify
               (Device (DeviceType Nat))
               device
               (Unify
                  (Device (DeviceType Nat))
                  queryDevice
                  (Unify
                     (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
         generatorOutput
         output)
-&gt; IxStateT m (Generator generatorDevice) generatorOutput output
forall k1 (m :: k1 -&gt; k1 -&gt; Type -&gt; Type) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(Generator
   (Unify
      (Device (DeviceType Nat))
      device
      (Unify
         (Device (DeviceType Nat))
         queryDevice
         (Unify
            (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
 -&gt; m (output, generatorOutput))
-&gt; IxStateT
     m
     (Generator
        (Unify
           (Device (DeviceType Nat))
           device
           (Unify
              (Device (DeviceType Nat))
              queryDevice
              (Unify
                 (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
     generatorOutput
     output
forall (m :: Type -&gt; Type) i j a.
(i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator
    (Unify
       (Device (DeviceType Nat))
       device
       (Unify
          (Device (DeviceType Nat))
          queryDevice
          (Unify
             (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
  -&gt; m (output, generatorOutput))
 -&gt; IxStateT
      m
      (Generator
         (Unify
            (Device (DeviceType Nat))
            device
            (Unify
               (Device (DeviceType Nat))
               queryDevice
               (Unify
                  (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
      generatorOutput
      output)
-&gt; (Tensor
      (Or
         (Gradient RequiresGradient)
         queryGradient
         (Or
            (Gradient RequiresGradient)
            gradient
            (Or
               (Gradient RequiresGradient) queryGradient attentionBiasGradient)))
      (Unify
         (Layout LayoutType)
         queryLayout
         (Unify
            (Layout LayoutType)
            ('Layout 'Dense)
            (Unify (Layout LayoutType) queryLayout attentionBiasLayout)))
      (Unify
         (Device (DeviceType Nat))
         queryDevice
         (Unify
            (Device (DeviceType Nat))
            device
            (Unify
               (Device (DeviceType Nat))
               queryDevice
               (Unify
                  (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
      (Unify
         (DataType DType)
         queryDataType
         (Unify
            (DataType DType)
            dataType
            (Unify (DataType DType) queryDataType attentionBiasDataType)))
      (BroadcastShapesF queryShape mhaOutputShape)
    -&gt; Generator
         (Unify
            (Device (DeviceType Nat))
            device
            (Unify
               (Device (DeviceType Nat))
               queryDevice
               (Unify
                  (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
    -&gt; m (output, generatorOutput))
-&gt; Tensor
     (Or
        (Gradient RequiresGradient)
        queryGradient
        (Or
           (Gradient RequiresGradient)
           gradient
           (Or
              (Gradient RequiresGradient) queryGradient attentionBiasGradient)))
     (Unify
        (Layout LayoutType)
        queryLayout
        (Unify
           (Layout LayoutType)
           ('Layout 'Dense)
           (Unify (Layout LayoutType) queryLayout attentionBiasLayout)))
     (Unify
        (Device (DeviceType Nat))
        queryDevice
        (Unify
           (Device (DeviceType Nat))
           device
           (Unify
              (Device (DeviceType Nat))
              queryDevice
              (Unify
                 (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
     (Unify
        (DataType DType)
        queryDataType
        (Unify
           (DataType DType)
           dataType
           (Unify (DataType DType) queryDataType attentionBiasDataType)))
     (BroadcastShapesF queryShape mhaOutputShape)
-&gt; IxStateT
     m
     (Generator
        (Unify
           (Device (DeviceType Nat))
           device
           (Unify
              (Device (DeviceType Nat))
              queryDevice
              (Unify
                 (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
     generatorOutput
     output
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">LayerNorm
  'WithBias gradient device dataType ('Shape '[queryEmbedDim])
-&gt; Tensor
     (Or
        (Gradient RequiresGradient)
        queryGradient
        (Or
           (Gradient RequiresGradient)
           gradient
           (Or
              (Gradient RequiresGradient) queryGradient attentionBiasGradient)))
     (Unify
        (Layout LayoutType)
        queryLayout
        (Unify
           (Layout LayoutType)
           ('Layout 'Dense)
           (Unify (Layout LayoutType) queryLayout attentionBiasLayout)))
     (Unify
        (Device (DeviceType Nat))
        queryDevice
        (Unify
           (Device (DeviceType Nat))
           device
           (Unify
              (Device (DeviceType Nat))
              queryDevice
              (Unify
                 (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
     (Unify
        (DataType DType)
        queryDataType
        (Unify
           (DataType DType)
           dataType
           (Unify (DataType DType) queryDataType attentionBiasDataType)))
     (BroadcastShapesF queryShape mhaOutputShape)
-&gt; Generator
     (Unify
        (Device (DeviceType Nat))
        device
        (Unify
           (Device (DeviceType Nat))
           queryDevice
           (Unify
              (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
-&gt; m (output, generatorOutput)
forall model input generator output generatorOutput
       (m :: Type -&gt; Type).
(HasForward model input generator output generatorOutput,
 MonadThrow m) =&gt;
model -&gt; input -&gt; generator -&gt; m (output, generatorOutput)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">LayerNorm
  'WithBias gradient device dataType ('Shape '[queryEmbedDim])
SALayerNormF 'BART gradient device dataType queryEmbedDim
</span><a href="#local-6989586621679768684"><span class="hs-identifier hs-var">saLayerNorm</span></a></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span>
</span><span id="line-474"></span><span>
</span><span id="line-475"></span><span class="hs-comment">-- | 'HasForward' instance for @SelfAttention 'BERT@.</span><span>
</span><span id="line-476"></span><span class="hs-comment">--</span><span>
</span><span id="line-477"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-478"></span><span class="hs-comment">-- &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;      &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;</span><span>
</span><span id="line-479"></span><span class="hs-comment">-- &#9474; attentionBias &#9474;      &#9474; query &#9474;</span><span>
</span><span id="line-480"></span><span class="hs-comment">-- &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;      &#9492;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-481"></span><span class="hs-comment">--         &#9474;                  &#9474;</span><span>
</span><span id="line-482"></span><span class="hs-comment">--         &#9474;            &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9524;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;</span><span>
</span><span id="line-483"></span><span class="hs-comment">--         &#9474;            &#9474;           &#9474;</span><span>
</span><span id="line-484"></span><span class="hs-comment">--         &#9474;       &#9484;&#9472;&#9472;&#9472;&#9472;&#9532;&#9472;&#9472;&#9472;&#9472;&#9488;      &#9474;</span><span>
</span><span id="line-485"></span><span class="hs-comment">--         &#9474;       &#9474;    &#9474;    &#9474;      &#9474;</span><span>
</span><span id="line-486"></span><span class="hs-comment">--         &#9474;       &#9660;    &#9660;    &#9660;      &#9474;</span><span>
</span><span id="line-487"></span><span class="hs-comment">--         &#9492;&#9472;&#9658;saMultiHeadAttention  &#9474;</span><span>
</span><span id="line-488"></span><span class="hs-comment">--                      &#9474;           &#9474;</span><span>
</span><span id="line-489"></span><span class="hs-comment">--                      &#9660;           &#9474;</span><span>
</span><span id="line-490"></span><span class="hs-comment">--                  saDropout       &#9474;</span><span>
</span><span id="line-491"></span><span class="hs-comment">--                      &#9474;           &#9474;</span><span>
</span><span id="line-492"></span><span class="hs-comment">--                      &#9492;&#9472;&#9472;&#9472;&#9658;add&#9668;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-493"></span><span class="hs-comment">--                            &#9474;</span><span>
</span><span id="line-494"></span><span class="hs-comment">--                            &#9660;</span><span>
</span><span id="line-495"></span><span class="hs-comment">--                       saLayerNorm</span><span>
</span><span id="line-496"></span><span class="hs-comment">--                            &#9474;</span><span>
</span><span id="line-497"></span><span class="hs-comment">--                            &#9660;</span><span>
</span><span id="line-498"></span><span class="hs-comment">--                        &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;</span><span>
</span><span id="line-499"></span><span class="hs-comment">--                        &#9474; query &#9474;</span><span>
</span><span id="line-500"></span><span class="hs-comment">--                        &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-501"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-502"></span><span id="local-6989586621679768656"><span id="local-6989586621679768657"><span id="local-6989586621679768658"><span id="local-6989586621679768659"><span id="local-6989586621679768660"><span id="local-6989586621679768661"><span id="local-6989586621679768662"><span id="local-6989586621679768663"><span id="local-6989586621679768664"><span id="local-6989586621679768665"><span id="local-6989586621679768666"><span id="local-6989586621679768667"><span id="local-6989586621679768668"><span id="local-6989586621679768669"><span id="local-6989586621679768670"><span id="local-6989586621679768671"><span id="local-6989586621679768672"><span id="local-6989586621679768673"><span id="local-6989586621679768674"><span id="local-6989586621679768675"><span id="local-6989586621679768676"><span id="local-6989586621679768677"><span id="local-6989586621679768678"><span id="local-6989586621679768679"><span class="hs-keyword">instance</span><span>
</span><span id="line-503"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetDim"><span class="hs-identifier hs-type">SGetDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768679"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-504"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Scalar.html#Scalar"><span class="hs-identifier hs-type">Scalar</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768678"><span class="hs-identifier hs-type">dropoutP</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-505"></span><span>    </span><span class="annot"><a href="#local-6989586621679768677"><span class="hs-identifier hs-type">query</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768676"><span class="hs-identifier hs-type">queryGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768675"><span class="hs-identifier hs-type">queryLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768674"><span class="hs-identifier hs-type">queryDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768673"><span class="hs-identifier hs-type">queryDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768672"><span class="hs-identifier hs-type">queryShape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-506"></span><span>    </span><span class="annot"><a href="#local-6989586621679768671"><span class="hs-identifier hs-type">attentionBias</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768670"><span class="hs-identifier hs-type">attentionBiasGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768669"><span class="hs-identifier hs-type">attentionBiasLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768668"><span class="hs-identifier hs-type">attentionBiasDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768667"><span class="hs-identifier hs-type">attentionBiasDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768666"><span class="hs-identifier hs-type">attentionBiasShape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-507"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-508"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.MultiHeadAttention.html#MultiHeadAttention"><span class="hs-identifier hs-type">MultiHeadAttention</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BERT"><span class="hs-identifier hs-type">BERT</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768665"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768664"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768663"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768662"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768661"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768660"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768679"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768679"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768679"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768678"><span class="hs-identifier hs-type">dropoutP</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-509"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679768677"><span class="hs-identifier hs-type">query</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679768677"><span class="hs-identifier hs-type">query</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679768677"><span class="hs-identifier hs-type">query</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679768671"><span class="hs-identifier hs-type">attentionBias</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-510"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Random.html#Generator"><span class="hs-identifier hs-type">Generator</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768659"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-511"></span><span>      </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-512"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679768665"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768676"><span class="hs-identifier hs-type">queryGradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768670"><span class="hs-identifier hs-type">attentionBiasGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-513"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Dense"><span class="hs-identifier hs-type">Dense</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768675"><span class="hs-identifier hs-type">queryLayout</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768669"><span class="hs-identifier hs-type">attentionBiasLayout</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-514"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679768664"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768674"><span class="hs-identifier hs-type">queryDevice</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768668"><span class="hs-identifier hs-type">attentionBiasDevice</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768659"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-515"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679768663"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768673"><span class="hs-identifier hs-type">queryDataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768667"><span class="hs-identifier hs-type">attentionBiasDataType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-516"></span><span>          </span><span class="annot"><a href="#local-6989586621679768658"><span class="hs-identifier hs-type">mhaOutputShape</span></a></span><span>
</span><span id="line-517"></span><span>      </span><span class="hs-special">)</span><span>
</span><span id="line-518"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Random.html#Generator"><span class="hs-identifier hs-type">Generator</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679768664"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768674"><span class="hs-identifier hs-type">queryDevice</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768668"><span class="hs-identifier hs-type">attentionBiasDevice</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768659"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-519"></span><span>    </span><span class="annot"><a href="#local-6989586621679768657"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-520"></span><span>      </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-521"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679768665"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768676"><span class="hs-identifier hs-type">queryGradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768670"><span class="hs-identifier hs-type">attentionBiasGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-522"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Dense"><span class="hs-identifier hs-type">Dense</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768675"><span class="hs-identifier hs-type">queryLayout</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768669"><span class="hs-identifier hs-type">attentionBiasLayout</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-523"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679768664"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768674"><span class="hs-identifier hs-type">queryDevice</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768668"><span class="hs-identifier hs-type">attentionBiasDevice</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768659"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-524"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679768663"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768673"><span class="hs-identifier hs-type">queryDataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768667"><span class="hs-identifier hs-type">attentionBiasDataType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-525"></span><span>          </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Functional.Normalization.html#LayerNormWithBiasF"><span class="hs-identifier hs-type">LayerNormWithBiasF</span></a></span><span>
</span><span id="line-526"></span><span>              </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679768679"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-527"></span><span>              </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679768679"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-528"></span><span>              </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#BroadcastShapesF"><span class="hs-identifier hs-type">BroadcastShapesF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768672"><span class="hs-identifier hs-type">queryShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768658"><span class="hs-identifier hs-type">mhaOutputShape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-529"></span><span>          </span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-530"></span><span>    </span><span class="annot"><a href="#local-6989586621679768656"><span class="hs-identifier hs-type">generatorOutput</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Random.html#Generator"><span class="hs-identifier hs-type">Generator</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679768664"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768674"><span class="hs-identifier hs-type">queryDevice</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768668"><span class="hs-identifier hs-type">attentionBiasDevice</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768659"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-531"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-532"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-533"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#SelfAttention"><span class="hs-identifier hs-type">SelfAttention</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BERT"><span class="hs-identifier hs-type">BERT</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768665"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768664"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768663"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768662"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768661"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768660"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768679"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768678"><span class="hs-identifier hs-type">dropoutP</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-534"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679768677"><span class="hs-identifier hs-type">query</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679768671"><span class="hs-identifier hs-type">attentionBias</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-535"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Random.html#Generator"><span class="hs-identifier hs-type">Generator</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768659"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-536"></span><span>    </span><span class="annot"><a href="#local-6989586621679768657"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-537"></span><span>    </span><span class="annot"><a href="#local-6989586621679768656"><span class="hs-identifier hs-type">generatorOutput</span></a></span><span>
</span><span id="line-538"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-539"></span><span>  </span><span id="local-6989586621679768654"><span class="annot"><span class="annottext">forward :: SelfAttention
  'BERT
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  queryEmbedDim
  dropoutP
-&gt; (query, attentionBias)
-&gt; Generator generatorDevice
-&gt; m (output, generatorOutput)
</span><a href="#local-6989586621679768654"><span class="hs-identifier hs-var hs-var hs-var hs-var">forward</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#SelfAttention"><span class="hs-identifier hs-type">SelfAttention</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#GSelfAttention"><span class="hs-identifier hs-type">GSelfAttention</span></a></span><span> </span><span class="hs-special">{</span><span id="local-6989586621679768651"><span id="local-6989586621679768652"><span id="local-6989586621679768653"><span class="annot"><span class="annottext">SADropoutF 'BERT dropoutP
SALayerNormF 'BERT gradient device dataType queryEmbedDim
SAMultiheadAttentionF
  'BERT
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  queryEmbedDim
  dropoutP
saDropout :: SADropoutF 'BERT dropoutP
saLayerNorm :: SALayerNormF 'BERT gradient device dataType queryEmbedDim
saMultiHeadAttention :: SAMultiheadAttentionF
  'BERT
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  queryEmbedDim
  dropoutP
saDropout :: forall mha layerNorm dropout.
GSelfAttention mha layerNorm dropout -&gt; dropout
saLayerNorm :: forall mha layerNorm dropout.
GSelfAttention mha layerNorm dropout -&gt; layerNorm
saMultiHeadAttention :: forall mha layerNorm dropout.
GSelfAttention mha layerNorm dropout -&gt; mha
</span><a href="#local-6989586621679768651"><span class="hs-glyph hs-var hs-var hs-var hs-var hs-var hs-var">..</span></a></span></span></span></span><span class="hs-special">}</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679768650"><span class="annot"><span class="annottext">query
</span><a href="#local-6989586621679768650"><span class="hs-identifier hs-var">query</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679768649"><span class="annot"><span class="annottext">attentionBias
</span><a href="#local-6989586621679768649"><span class="hs-identifier hs-var">attentionBias</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-540"></span><span>    </span><span class="annot"><span class="annottext">IxStateT m (Generator generatorDevice) generatorOutput output
-&gt; Generator generatorDevice -&gt; m (output, generatorOutput)
forall (m :: Type -&gt; Type) i j a. IxStateT m i j a -&gt; i -&gt; m (a, j)
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var hs-var">runIxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">(IxStateT m (Generator generatorDevice) generatorOutput output
 -&gt; Generator generatorDevice -&gt; m (output, generatorOutput))
-&gt; IxStateT m (Generator generatorDevice) generatorOutput output
-&gt; Generator generatorDevice
-&gt; m (output, generatorOutput)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-541"></span><span>      </span><span class="annot"><span class="annottext">query
-&gt; IxStateT
     m (Generator generatorDevice) (Generator generatorDevice) query
forall k (m :: k -&gt; k -&gt; Type -&gt; Type) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">query
</span><a href="#local-6989586621679768650"><span class="hs-identifier hs-var">query</span></a></span><span>
</span><span id="line-542"></span><span>        </span><span class="annot"><span class="annottext">IxStateT
  m (Generator generatorDevice) (Generator generatorDevice) query
-&gt; (query
    -&gt; IxStateT
         m
         (Generator generatorDevice)
         (Generator
            (Unify
               (Device (DeviceType Nat))
               device
               (Unify
                  (Device (DeviceType Nat))
                  queryDevice
                  (Unify
                     (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
         (Tensor
            (Or
               (Gradient RequiresGradient)
               gradient
               (Or
                  (Gradient RequiresGradient) queryGradient attentionBiasGradient))
            (Unify
               (Layout LayoutType)
               ('Layout 'Dense)
               (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
            (Unify
               (Device (DeviceType Nat))
               device
               (Unify
                  (Device (DeviceType Nat))
                  queryDevice
                  (Unify
                     (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
            (Unify
               (DataType DType)
               dataType
               (Unify (DataType DType) queryDataType attentionBiasDataType))
            mhaOutputShape))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator
        (Unify
           (Device (DeviceType Nat))
           device
           (Unify
              (Device (DeviceType Nat))
              queryDevice
              (Unify
                 (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
     (Tensor
        (Or
           (Gradient RequiresGradient)
           gradient
           (Or
              (Gradient RequiresGradient) queryGradient attentionBiasGradient))
        (Unify
           (Layout LayoutType)
           ('Layout 'Dense)
           (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
        (Unify
           (Device (DeviceType Nat))
           device
           (Unify
              (Device (DeviceType Nat))
              queryDevice
              (Unify
                 (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
        (Unify
           (DataType DType)
           dataType
           (Unify (DataType DType) queryDataType attentionBiasDataType))
        mhaOutputShape)
forall k1 (m :: k1 -&gt; k1 -&gt; Type -&gt; Type) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">\</span><span id="local-6989586621679768648"><span class="annot"><span class="annottext">query
</span><a href="#local-6989586621679768648"><span class="hs-identifier hs-var">query'</span></a></span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">(Generator generatorDevice
 -&gt; m (Tensor
         (Or
            (Gradient RequiresGradient)
            gradient
            (Or
               (Gradient RequiresGradient) queryGradient attentionBiasGradient))
         (Unify
            (Layout LayoutType)
            ('Layout 'Dense)
            (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
         (Unify
            (Device (DeviceType Nat))
            device
            (Unify
               (Device (DeviceType Nat))
               queryDevice
               (Unify
                  (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
         (Unify
            (DataType DType)
            dataType
            (Unify (DataType DType) queryDataType attentionBiasDataType))
         mhaOutputShape,
       Generator
         (Unify
            (Device (DeviceType Nat))
            device
            (Unify
               (Device (DeviceType Nat))
               queryDevice
               (Unify
                  (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator
        (Unify
           (Device (DeviceType Nat))
           device
           (Unify
              (Device (DeviceType Nat))
              queryDevice
              (Unify
                 (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
     (Tensor
        (Or
           (Gradient RequiresGradient)
           gradient
           (Or
              (Gradient RequiresGradient) queryGradient attentionBiasGradient))
        (Unify
           (Layout LayoutType)
           ('Layout 'Dense)
           (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
        (Unify
           (Device (DeviceType Nat))
           device
           (Unify
              (Device (DeviceType Nat))
              queryDevice
              (Unify
                 (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
        (Unify
           (DataType DType)
           dataType
           (Unify (DataType DType) queryDataType attentionBiasDataType))
        mhaOutputShape)
forall (m :: Type -&gt; Type) i j a.
(i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator generatorDevice
  -&gt; m (Tensor
          (Or
             (Gradient RequiresGradient)
             gradient
             (Or
                (Gradient RequiresGradient) queryGradient attentionBiasGradient))
          (Unify
             (Layout LayoutType)
             ('Layout 'Dense)
             (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
          (Unify
             (Device (DeviceType Nat))
             device
             (Unify
                (Device (DeviceType Nat))
                queryDevice
                (Unify
                   (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
          (Unify
             (DataType DType)
             dataType
             (Unify (DataType DType) queryDataType attentionBiasDataType))
          mhaOutputShape,
        Generator
          (Unify
             (Device (DeviceType Nat))
             device
             (Unify
                (Device (DeviceType Nat))
                queryDevice
                (Unify
                   (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))))
 -&gt; IxStateT
      m
      (Generator generatorDevice)
      (Generator
         (Unify
            (Device (DeviceType Nat))
            device
            (Unify
               (Device (DeviceType Nat))
               queryDevice
               (Unify
                  (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
      (Tensor
         (Or
            (Gradient RequiresGradient)
            gradient
            (Or
               (Gradient RequiresGradient) queryGradient attentionBiasGradient))
         (Unify
            (Layout LayoutType)
            ('Layout 'Dense)
            (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
         (Unify
            (Device (DeviceType Nat))
            device
            (Unify
               (Device (DeviceType Nat))
               queryDevice
               (Unify
                  (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
         (Unify
            (DataType DType)
            dataType
            (Unify (DataType DType) queryDataType attentionBiasDataType))
         mhaOutputShape))
-&gt; (Generator generatorDevice
    -&gt; m (Tensor
            (Or
               (Gradient RequiresGradient)
               gradient
               (Or
                  (Gradient RequiresGradient) queryGradient attentionBiasGradient))
            (Unify
               (Layout LayoutType)
               ('Layout 'Dense)
               (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
            (Unify
               (Device (DeviceType Nat))
               device
               (Unify
                  (Device (DeviceType Nat))
                  queryDevice
                  (Unify
                     (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
            (Unify
               (DataType DType)
               dataType
               (Unify (DataType DType) queryDataType attentionBiasDataType))
            mhaOutputShape,
          Generator
            (Unify
               (Device (DeviceType Nat))
               device
               (Unify
                  (Device (DeviceType Nat))
                  queryDevice
                  (Unify
                     (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator
        (Unify
           (Device (DeviceType Nat))
           device
           (Unify
              (Device (DeviceType Nat))
              queryDevice
              (Unify
                 (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
     (Tensor
        (Or
           (Gradient RequiresGradient)
           gradient
           (Or
              (Gradient RequiresGradient) queryGradient attentionBiasGradient))
        (Unify
           (Layout LayoutType)
           ('Layout 'Dense)
           (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
        (Unify
           (Device (DeviceType Nat))
           device
           (Unify
              (Device (DeviceType Nat))
              queryDevice
              (Unify
                 (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
        (Unify
           (DataType DType)
           dataType
           (Unify (DataType DType) queryDataType attentionBiasDataType))
        mhaOutputShape)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">MultiHeadAttention
  'BERT
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  queryEmbedDim
  queryEmbedDim
  queryEmbedDim
  dropoutP
-&gt; (query, query, query, attentionBias)
-&gt; Generator generatorDevice
-&gt; m (Tensor
        (Or
           (Gradient RequiresGradient)
           gradient
           (Or
              (Gradient RequiresGradient) queryGradient attentionBiasGradient))
        (Unify
           (Layout LayoutType)
           ('Layout 'Dense)
           (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
        (Unify
           (Device (DeviceType Nat))
           device
           (Unify
              (Device (DeviceType Nat))
              queryDevice
              (Unify
                 (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
        (Unify
           (DataType DType)
           dataType
           (Unify (DataType DType) queryDataType attentionBiasDataType))
        mhaOutputShape,
      Generator
        (Unify
           (Device (DeviceType Nat))
           device
           (Unify
              (Device (DeviceType Nat))
              queryDevice
              (Unify
                 (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
forall model input generator output generatorOutput
       (m :: Type -&gt; Type).
(HasForward model input generator output generatorOutput,
 MonadThrow m) =&gt;
model -&gt; input -&gt; generator -&gt; m (output, generatorOutput)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">MultiHeadAttention
  'BERT
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  queryEmbedDim
  queryEmbedDim
  queryEmbedDim
  dropoutP
SAMultiheadAttentionF
  'BERT
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  queryEmbedDim
  dropoutP
</span><a href="#local-6989586621679768653"><span class="hs-identifier hs-var">saMultiHeadAttention</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">query
</span><a href="#local-6989586621679768648"><span class="hs-identifier hs-var">query'</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">query
</span><a href="#local-6989586621679768648"><span class="hs-identifier hs-var">query'</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">query
</span><a href="#local-6989586621679768648"><span class="hs-identifier hs-var">query'</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">attentionBias
</span><a href="#local-6989586621679768649"><span class="hs-identifier hs-var">attentionBias</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-543"></span><span>        </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator
     (Unify
        (Device (DeviceType Nat))
        device
        (Unify
           (Device (DeviceType Nat))
           queryDevice
           (Unify
              (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
  (Tensor
     (Or
        (Gradient RequiresGradient)
        gradient
        (Or
           (Gradient RequiresGradient) queryGradient attentionBiasGradient))
     (Unify
        (Layout LayoutType)
        ('Layout 'Dense)
        (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
     (Unify
        (Device (DeviceType Nat))
        device
        (Unify
           (Device (DeviceType Nat))
           queryDevice
           (Unify
              (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
     (Unify
        (DataType DType)
        dataType
        (Unify (DataType DType) queryDataType attentionBiasDataType))
     mhaOutputShape)
-&gt; (Tensor
      (Or
         (Gradient RequiresGradient)
         gradient
         (Or
            (Gradient RequiresGradient) queryGradient attentionBiasGradient))
      (Unify
         (Layout LayoutType)
         ('Layout 'Dense)
         (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
      (Unify
         (Device (DeviceType Nat))
         device
         (Unify
            (Device (DeviceType Nat))
            queryDevice
            (Unify
               (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
      (Unify
         (DataType DType)
         dataType
         (Unify (DataType DType) queryDataType attentionBiasDataType))
      mhaOutputShape
    -&gt; IxStateT
         m
         (Generator
            (Unify
               (Device (DeviceType Nat))
               device
               (Unify
                  (Device (DeviceType Nat))
                  queryDevice
                  (Unify
                     (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
         (Generator
            (Unify
               (Device (DeviceType Nat))
               device
               (Unify
                  (Device (DeviceType Nat))
                  queryDevice
                  (Unify
                     (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
         (Tensor
            (Or
               (Gradient RequiresGradient)
               gradient
               (Or
                  (Gradient RequiresGradient) queryGradient attentionBiasGradient))
            (Unify
               (Layout LayoutType)
               ('Layout 'Dense)
               (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
            (Unify
               (Device (DeviceType Nat))
               device
               (Unify
                  (Device (DeviceType Nat))
                  queryDevice
                  (Unify
                     (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
            (Unify
               (DataType DType)
               dataType
               (Unify (DataType DType) queryDataType attentionBiasDataType))
            mhaOutputShape))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator
        (Unify
           (Device (DeviceType Nat))
           device
           (Unify
              (Device (DeviceType Nat))
              queryDevice
              (Unify
                 (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
     (Tensor
        (Or
           (Gradient RequiresGradient)
           gradient
           (Or
              (Gradient RequiresGradient) queryGradient attentionBiasGradient))
        (Unify
           (Layout LayoutType)
           ('Layout 'Dense)
           (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
        (Unify
           (Device (DeviceType Nat))
           device
           (Unify
              (Device (DeviceType Nat))
              queryDevice
              (Unify
                 (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
        (Unify
           (DataType DType)
           dataType
           (Unify (DataType DType) queryDataType attentionBiasDataType))
        mhaOutputShape)
forall k1 (m :: k1 -&gt; k1 -&gt; Type -&gt; Type) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(Generator
   (Unify
      (Device (DeviceType Nat))
      device
      (Unify
         (Device (DeviceType Nat))
         queryDevice
         (Unify
            (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
 -&gt; m (Tensor
         (Or
            (Gradient RequiresGradient)
            gradient
            (Or
               (Gradient RequiresGradient) queryGradient attentionBiasGradient))
         (Unify
            (Layout LayoutType)
            ('Layout 'Dense)
            (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
         (Unify
            (Device (DeviceType Nat))
            device
            (Unify
               (Device (DeviceType Nat))
               queryDevice
               (Unify
                  (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
         (Unify
            (DataType DType)
            dataType
            (Unify (DataType DType) queryDataType attentionBiasDataType))
         mhaOutputShape,
       Generator
         (Unify
            (Device (DeviceType Nat))
            device
            (Unify
               (Device (DeviceType Nat))
               queryDevice
               (Unify
                  (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))))
-&gt; IxStateT
     m
     (Generator
        (Unify
           (Device (DeviceType Nat))
           device
           (Unify
              (Device (DeviceType Nat))
              queryDevice
              (Unify
                 (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
     (Generator
        (Unify
           (Device (DeviceType Nat))
           device
           (Unify
              (Device (DeviceType Nat))
              queryDevice
              (Unify
                 (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
     (Tensor
        (Or
           (Gradient RequiresGradient)
           gradient
           (Or
              (Gradient RequiresGradient) queryGradient attentionBiasGradient))
        (Unify
           (Layout LayoutType)
           ('Layout 'Dense)
           (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
        (Unify
           (Device (DeviceType Nat))
           device
           (Unify
              (Device (DeviceType Nat))
              queryDevice
              (Unify
                 (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
        (Unify
           (DataType DType)
           dataType
           (Unify (DataType DType) queryDataType attentionBiasDataType))
        mhaOutputShape)
forall (m :: Type -&gt; Type) i j a.
(i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator
    (Unify
       (Device (DeviceType Nat))
       device
       (Unify
          (Device (DeviceType Nat))
          queryDevice
          (Unify
             (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
  -&gt; m (Tensor
          (Or
             (Gradient RequiresGradient)
             gradient
             (Or
                (Gradient RequiresGradient) queryGradient attentionBiasGradient))
          (Unify
             (Layout LayoutType)
             ('Layout 'Dense)
             (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
          (Unify
             (Device (DeviceType Nat))
             device
             (Unify
                (Device (DeviceType Nat))
                queryDevice
                (Unify
                   (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
          (Unify
             (DataType DType)
             dataType
             (Unify (DataType DType) queryDataType attentionBiasDataType))
          mhaOutputShape,
        Generator
          (Unify
             (Device (DeviceType Nat))
             device
             (Unify
                (Device (DeviceType Nat))
                queryDevice
                (Unify
                   (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))))
 -&gt; IxStateT
      m
      (Generator
         (Unify
            (Device (DeviceType Nat))
            device
            (Unify
               (Device (DeviceType Nat))
               queryDevice
               (Unify
                  (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
      (Generator
         (Unify
            (Device (DeviceType Nat))
            device
            (Unify
               (Device (DeviceType Nat))
               queryDevice
               (Unify
                  (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
      (Tensor
         (Or
            (Gradient RequiresGradient)
            gradient
            (Or
               (Gradient RequiresGradient) queryGradient attentionBiasGradient))
         (Unify
            (Layout LayoutType)
            ('Layout 'Dense)
            (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
         (Unify
            (Device (DeviceType Nat))
            device
            (Unify
               (Device (DeviceType Nat))
               queryDevice
               (Unify
                  (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
         (Unify
            (DataType DType)
            dataType
            (Unify (DataType DType) queryDataType attentionBiasDataType))
         mhaOutputShape))
-&gt; (Tensor
      (Or
         (Gradient RequiresGradient)
         gradient
         (Or
            (Gradient RequiresGradient) queryGradient attentionBiasGradient))
      (Unify
         (Layout LayoutType)
         ('Layout 'Dense)
         (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
      (Unify
         (Device (DeviceType Nat))
         device
         (Unify
            (Device (DeviceType Nat))
            queryDevice
            (Unify
               (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
      (Unify
         (DataType DType)
         dataType
         (Unify (DataType DType) queryDataType attentionBiasDataType))
      mhaOutputShape
    -&gt; Generator
         (Unify
            (Device (DeviceType Nat))
            device
            (Unify
               (Device (DeviceType Nat))
               queryDevice
               (Unify
                  (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
    -&gt; m (Tensor
            (Or
               (Gradient RequiresGradient)
               gradient
               (Or
                  (Gradient RequiresGradient) queryGradient attentionBiasGradient))
            (Unify
               (Layout LayoutType)
               ('Layout 'Dense)
               (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
            (Unify
               (Device (DeviceType Nat))
               device
               (Unify
                  (Device (DeviceType Nat))
                  queryDevice
                  (Unify
                     (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
            (Unify
               (DataType DType)
               dataType
               (Unify (DataType DType) queryDataType attentionBiasDataType))
            mhaOutputShape,
          Generator
            (Unify
               (Device (DeviceType Nat))
               device
               (Unify
                  (Device (DeviceType Nat))
                  queryDevice
                  (Unify
                     (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))))
-&gt; Tensor
     (Or
        (Gradient RequiresGradient)
        gradient
        (Or
           (Gradient RequiresGradient) queryGradient attentionBiasGradient))
     (Unify
        (Layout LayoutType)
        ('Layout 'Dense)
        (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
     (Unify
        (Device (DeviceType Nat))
        device
        (Unify
           (Device (DeviceType Nat))
           queryDevice
           (Unify
              (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
     (Unify
        (DataType DType)
        dataType
        (Unify (DataType DType) queryDataType attentionBiasDataType))
     mhaOutputShape
-&gt; IxStateT
     m
     (Generator
        (Unify
           (Device (DeviceType Nat))
           device
           (Unify
              (Device (DeviceType Nat))
              queryDevice
              (Unify
                 (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
     (Generator
        (Unify
           (Device (DeviceType Nat))
           device
           (Unify
              (Device (DeviceType Nat))
              queryDevice
              (Unify
                 (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
     (Tensor
        (Or
           (Gradient RequiresGradient)
           gradient
           (Or
              (Gradient RequiresGradient) queryGradient attentionBiasGradient))
        (Unify
           (Layout LayoutType)
           ('Layout 'Dense)
           (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
        (Unify
           (Device (DeviceType Nat))
           device
           (Unify
              (Device (DeviceType Nat))
              queryDevice
              (Unify
                 (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
        (Unify
           (DataType DType)
           dataType
           (Unify (DataType DType) queryDataType attentionBiasDataType))
        mhaOutputShape)
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Dropout dropoutP
-&gt; Tensor
     (Or
        (Gradient RequiresGradient)
        gradient
        (Or
           (Gradient RequiresGradient) queryGradient attentionBiasGradient))
     (Unify
        (Layout LayoutType)
        ('Layout 'Dense)
        (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
     (Unify
        (Device (DeviceType Nat))
        device
        (Unify
           (Device (DeviceType Nat))
           queryDevice
           (Unify
              (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
     (Unify
        (DataType DType)
        dataType
        (Unify (DataType DType) queryDataType attentionBiasDataType))
     mhaOutputShape
-&gt; Generator
     (Unify
        (Device (DeviceType Nat))
        device
        (Unify
           (Device (DeviceType Nat))
           queryDevice
           (Unify
              (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
-&gt; m (Tensor
        (Or
           (Gradient RequiresGradient)
           gradient
           (Or
              (Gradient RequiresGradient) queryGradient attentionBiasGradient))
        (Unify
           (Layout LayoutType)
           ('Layout 'Dense)
           (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
        (Unify
           (Device (DeviceType Nat))
           device
           (Unify
              (Device (DeviceType Nat))
              queryDevice
              (Unify
                 (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
        (Unify
           (DataType DType)
           dataType
           (Unify (DataType DType) queryDataType attentionBiasDataType))
        mhaOutputShape,
      Generator
        (Unify
           (Device (DeviceType Nat))
           device
           (Unify
              (Device (DeviceType Nat))
              queryDevice
              (Unify
                 (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
forall model input generator output generatorOutput
       (m :: Type -&gt; Type).
(HasForward model input generator output generatorOutput,
 MonadThrow m) =&gt;
model -&gt; input -&gt; generator -&gt; m (output, generatorOutput)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">Dropout dropoutP
SADropoutF 'BERT dropoutP
</span><a href="#local-6989586621679768651"><span class="hs-identifier hs-var">saDropout</span></a></span><span>
</span><span id="line-544"></span><span>        </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator
     (Unify
        (Device (DeviceType Nat))
        device
        (Unify
           (Device (DeviceType Nat))
           queryDevice
           (Unify
              (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
  (Tensor
     (Or
        (Gradient RequiresGradient)
        gradient
        (Or
           (Gradient RequiresGradient) queryGradient attentionBiasGradient))
     (Unify
        (Layout LayoutType)
        ('Layout 'Dense)
        (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
     (Unify
        (Device (DeviceType Nat))
        device
        (Unify
           (Device (DeviceType Nat))
           queryDevice
           (Unify
              (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
     (Unify
        (DataType DType)
        dataType
        (Unify (DataType DType) queryDataType attentionBiasDataType))
     mhaOutputShape)
-&gt; (Tensor
      (Or
         (Gradient RequiresGradient)
         gradient
         (Or
            (Gradient RequiresGradient) queryGradient attentionBiasGradient))
      (Unify
         (Layout LayoutType)
         ('Layout 'Dense)
         (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
      (Unify
         (Device (DeviceType Nat))
         device
         (Unify
            (Device (DeviceType Nat))
            queryDevice
            (Unify
               (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
      (Unify
         (DataType DType)
         dataType
         (Unify (DataType DType) queryDataType attentionBiasDataType))
      mhaOutputShape
    -&gt; IxStateT
         m
         (Generator
            (Unify
               (Device (DeviceType Nat))
               device
               (Unify
                  (Device (DeviceType Nat))
                  queryDevice
                  (Unify
                     (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
         (Generator
            (Unify
               (Device (DeviceType Nat))
               device
               (Unify
                  (Device (DeviceType Nat))
                  queryDevice
                  (Unify
                     (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
         (Tensor
            (Or
               (Gradient RequiresGradient)
               queryGradient
               (Or
                  (Gradient RequiresGradient)
                  gradient
                  (Or
                     (Gradient RequiresGradient) queryGradient attentionBiasGradient)))
            (Unify
               (Layout LayoutType)
               queryLayout
               (Unify
                  (Layout LayoutType)
                  ('Layout 'Dense)
                  (Unify (Layout LayoutType) queryLayout attentionBiasLayout)))
            (Unify
               (Device (DeviceType Nat))
               queryDevice
               (Unify
                  (Device (DeviceType Nat))
                  device
                  (Unify
                     (Device (DeviceType Nat))
                     queryDevice
                     (Unify
                        (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
            (Unify
               (DataType DType)
               queryDataType
               (Unify
                  (DataType DType)
                  dataType
                  (Unify (DataType DType) queryDataType attentionBiasDataType)))
            (BroadcastShapesF queryShape mhaOutputShape)))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator
        (Unify
           (Device (DeviceType Nat))
           device
           (Unify
              (Device (DeviceType Nat))
              queryDevice
              (Unify
                 (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
     (Tensor
        (Or
           (Gradient RequiresGradient)
           queryGradient
           (Or
              (Gradient RequiresGradient)
              gradient
              (Or
                 (Gradient RequiresGradient) queryGradient attentionBiasGradient)))
        (Unify
           (Layout LayoutType)
           queryLayout
           (Unify
              (Layout LayoutType)
              ('Layout 'Dense)
              (Unify (Layout LayoutType) queryLayout attentionBiasLayout)))
        (Unify
           (Device (DeviceType Nat))
           queryDevice
           (Unify
              (Device (DeviceType Nat))
              device
              (Unify
                 (Device (DeviceType Nat))
                 queryDevice
                 (Unify
                    (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
        (Unify
           (DataType DType)
           queryDataType
           (Unify
              (DataType DType)
              dataType
              (Unify (DataType DType) queryDataType attentionBiasDataType)))
        (BroadcastShapesF queryShape mhaOutputShape))
forall k1 (m :: k1 -&gt; k1 -&gt; Type -&gt; Type) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  (Or
     (Gradient RequiresGradient)
     queryGradient
     (Or
        (Gradient RequiresGradient)
        gradient
        (Or
           (Gradient RequiresGradient) queryGradient attentionBiasGradient)))
  (Unify
     (Layout LayoutType)
     queryLayout
     (Unify
        (Layout LayoutType)
        ('Layout 'Dense)
        (Unify (Layout LayoutType) queryLayout attentionBiasLayout)))
  (Unify
     (Device (DeviceType Nat))
     queryDevice
     (Unify
        (Device (DeviceType Nat))
        device
        (Unify
           (Device (DeviceType Nat))
           queryDevice
           (Unify
              (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
  (Unify
     (DataType DType)
     queryDataType
     (Unify
        (DataType DType)
        dataType
        (Unify (DataType DType) queryDataType attentionBiasDataType)))
  (BroadcastShapesF queryShape mhaOutputShape)
-&gt; IxStateT
     m
     (Generator
        (Unify
           (Device (DeviceType Nat))
           device
           (Unify
              (Device (DeviceType Nat))
              queryDevice
              (Unify
                 (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
     (Generator
        (Unify
           (Device (DeviceType Nat))
           device
           (Unify
              (Device (DeviceType Nat))
              queryDevice
              (Unify
                 (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
     (Tensor
        (Or
           (Gradient RequiresGradient)
           queryGradient
           (Or
              (Gradient RequiresGradient)
              gradient
              (Or
                 (Gradient RequiresGradient) queryGradient attentionBiasGradient)))
        (Unify
           (Layout LayoutType)
           queryLayout
           (Unify
              (Layout LayoutType)
              ('Layout 'Dense)
              (Unify (Layout LayoutType) queryLayout attentionBiasLayout)))
        (Unify
           (Device (DeviceType Nat))
           queryDevice
           (Unify
              (Device (DeviceType Nat))
              device
              (Unify
                 (Device (DeviceType Nat))
                 queryDevice
                 (Unify
                    (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
        (Unify
           (DataType DType)
           queryDataType
           (Unify
              (DataType DType)
              dataType
              (Unify (DataType DType) queryDataType attentionBiasDataType)))
        (BroadcastShapesF queryShape mhaOutputShape))
forall k (m :: k -&gt; k -&gt; Type -&gt; Type) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">(Tensor
   (Or
      (Gradient RequiresGradient)
      queryGradient
      (Or
         (Gradient RequiresGradient)
         gradient
         (Or
            (Gradient RequiresGradient) queryGradient attentionBiasGradient)))
   (Unify
      (Layout LayoutType)
      queryLayout
      (Unify
         (Layout LayoutType)
         ('Layout 'Dense)
         (Unify (Layout LayoutType) queryLayout attentionBiasLayout)))
   (Unify
      (Device (DeviceType Nat))
      queryDevice
      (Unify
         (Device (DeviceType Nat))
         device
         (Unify
            (Device (DeviceType Nat))
            queryDevice
            (Unify
               (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
   (Unify
      (DataType DType)
      queryDataType
      (Unify
         (DataType DType)
         dataType
         (Unify (DataType DType) queryDataType attentionBiasDataType)))
   (BroadcastShapesF queryShape mhaOutputShape)
 -&gt; IxStateT
      m
      (Generator
         (Unify
            (Device (DeviceType Nat))
            device
            (Unify
               (Device (DeviceType Nat))
               queryDevice
               (Unify
                  (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
      (Generator
         (Unify
            (Device (DeviceType Nat))
            device
            (Unify
               (Device (DeviceType Nat))
               queryDevice
               (Unify
                  (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
      (Tensor
         (Or
            (Gradient RequiresGradient)
            queryGradient
            (Or
               (Gradient RequiresGradient)
               gradient
               (Or
                  (Gradient RequiresGradient) queryGradient attentionBiasGradient)))
         (Unify
            (Layout LayoutType)
            queryLayout
            (Unify
               (Layout LayoutType)
               ('Layout 'Dense)
               (Unify (Layout LayoutType) queryLayout attentionBiasLayout)))
         (Unify
            (Device (DeviceType Nat))
            queryDevice
            (Unify
               (Device (DeviceType Nat))
               device
               (Unify
                  (Device (DeviceType Nat))
                  queryDevice
                  (Unify
                     (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
         (Unify
            (DataType DType)
            queryDataType
            (Unify
               (DataType DType)
               dataType
               (Unify (DataType DType) queryDataType attentionBiasDataType)))
         (BroadcastShapesF queryShape mhaOutputShape)))
-&gt; (Tensor
      (Or
         (Gradient RequiresGradient)
         gradient
         (Or
            (Gradient RequiresGradient) queryGradient attentionBiasGradient))
      (Unify
         (Layout LayoutType)
         ('Layout 'Dense)
         (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
      (Unify
         (Device (DeviceType Nat))
         device
         (Unify
            (Device (DeviceType Nat))
            queryDevice
            (Unify
               (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
      (Unify
         (DataType DType)
         dataType
         (Unify (DataType DType) queryDataType attentionBiasDataType))
      mhaOutputShape
    -&gt; Tensor
         (Or
            (Gradient RequiresGradient)
            queryGradient
            (Or
               (Gradient RequiresGradient)
               gradient
               (Or
                  (Gradient RequiresGradient) queryGradient attentionBiasGradient)))
         (Unify
            (Layout LayoutType)
            queryLayout
            (Unify
               (Layout LayoutType)
               ('Layout 'Dense)
               (Unify (Layout LayoutType) queryLayout attentionBiasLayout)))
         (Unify
            (Device (DeviceType Nat))
            queryDevice
            (Unify
               (Device (DeviceType Nat))
               device
               (Unify
                  (Device (DeviceType Nat))
                  queryDevice
                  (Unify
                     (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
         (Unify
            (DataType DType)
            queryDataType
            (Unify
               (DataType DType)
               dataType
               (Unify (DataType DType) queryDataType attentionBiasDataType)))
         (BroadcastShapesF queryShape mhaOutputShape))
-&gt; Tensor
     (Or
        (Gradient RequiresGradient)
        gradient
        (Or
           (Gradient RequiresGradient) queryGradient attentionBiasGradient))
     (Unify
        (Layout LayoutType)
        ('Layout 'Dense)
        (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
     (Unify
        (Device (DeviceType Nat))
        device
        (Unify
           (Device (DeviceType Nat))
           queryDevice
           (Unify
              (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
     (Unify
        (DataType DType)
        dataType
        (Unify (DataType DType) queryDataType attentionBiasDataType))
     mhaOutputShape
-&gt; IxStateT
     m
     (Generator
        (Unify
           (Device (DeviceType Nat))
           device
           (Unify
              (Device (DeviceType Nat))
              queryDevice
              (Unify
                 (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
     (Generator
        (Unify
           (Device (DeviceType Nat))
           device
           (Unify
              (Device (DeviceType Nat))
              queryDevice
              (Unify
                 (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
     (Tensor
        (Or
           (Gradient RequiresGradient)
           queryGradient
           (Or
              (Gradient RequiresGradient)
              gradient
              (Or
                 (Gradient RequiresGradient) queryGradient attentionBiasGradient)))
        (Unify
           (Layout LayoutType)
           queryLayout
           (Unify
              (Layout LayoutType)
              ('Layout 'Dense)
              (Unify (Layout LayoutType) queryLayout attentionBiasLayout)))
        (Unify
           (Device (DeviceType Nat))
           queryDevice
           (Unify
              (Device (DeviceType Nat))
              device
              (Unify
                 (Device (DeviceType Nat))
                 queryDevice
                 (Unify
                    (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
        (Unify
           (DataType DType)
           queryDataType
           (Unify
              (DataType DType)
              dataType
              (Unify (DataType DType) queryDataType attentionBiasDataType)))
        (BroadcastShapesF queryShape mhaOutputShape))
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">query
Tensor
  queryGradient queryLayout queryDevice queryDataType queryShape
</span><a href="#local-6989586621679768650"><span class="hs-identifier hs-var">query</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  queryGradient queryLayout queryDevice queryDataType queryShape
-&gt; Tensor
     (Or
        (Gradient RequiresGradient)
        gradient
        (Or
           (Gradient RequiresGradient) queryGradient attentionBiasGradient))
     (Unify
        (Layout LayoutType)
        ('Layout 'Dense)
        (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
     (Unify
        (Device (DeviceType Nat))
        device
        (Unify
           (Device (DeviceType Nat))
           queryDevice
           (Unify
              (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
     (Unify
        (DataType DType)
        dataType
        (Unify (DataType DType) queryDataType attentionBiasDataType))
     mhaOutputShape
-&gt; Tensor
     (queryGradient
      &lt;|&gt; Or
            (Gradient RequiresGradient)
            gradient
            (Or
               (Gradient RequiresGradient) queryGradient attentionBiasGradient))
     (queryLayout
      &lt;+&gt; Unify
            (Layout LayoutType)
            ('Layout 'Dense)
            (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
     (queryDevice
      &lt;+&gt; Unify
            (Device (DeviceType Nat))
            device
            (Unify
               (Device (DeviceType Nat))
               queryDevice
               (Unify
                  (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
     (queryDataType
      &lt;+&gt; Unify
            (DataType DType)
            dataType
            (Unify (DataType DType) queryDataType attentionBiasDataType))
     (BroadcastShapesF queryShape mhaOutputShape)
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (gradient' :: Gradient RequiresGradient)
       (layout' :: Layout LayoutType) (device' :: Device (DeviceType Nat))
       (dataType' :: DataType DType)
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]).
Tensor gradient layout device dataType shape
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; Tensor
     (gradient &lt;|&gt; gradient')
     (layout &lt;+&gt; layout')
     (device &lt;+&gt; device')
     (dataType &lt;+&gt; dataType')
     (BroadcastShapesF shape shape')
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#add"><span class="hs-operator hs-var">`add`</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-545"></span><span>        </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator
     (Unify
        (Device (DeviceType Nat))
        device
        (Unify
           (Device (DeviceType Nat))
           queryDevice
           (Unify
              (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
  (Tensor
     (Or
        (Gradient RequiresGradient)
        queryGradient
        (Or
           (Gradient RequiresGradient)
           gradient
           (Or
              (Gradient RequiresGradient) queryGradient attentionBiasGradient)))
     (Unify
        (Layout LayoutType)
        queryLayout
        (Unify
           (Layout LayoutType)
           ('Layout 'Dense)
           (Unify (Layout LayoutType) queryLayout attentionBiasLayout)))
     (Unify
        (Device (DeviceType Nat))
        queryDevice
        (Unify
           (Device (DeviceType Nat))
           device
           (Unify
              (Device (DeviceType Nat))
              queryDevice
              (Unify
                 (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
     (Unify
        (DataType DType)
        queryDataType
        (Unify
           (DataType DType)
           dataType
           (Unify (DataType DType) queryDataType attentionBiasDataType)))
     (BroadcastShapesF queryShape mhaOutputShape))
-&gt; (Tensor
      (Or
         (Gradient RequiresGradient)
         queryGradient
         (Or
            (Gradient RequiresGradient)
            gradient
            (Or
               (Gradient RequiresGradient) queryGradient attentionBiasGradient)))
      (Unify
         (Layout LayoutType)
         queryLayout
         (Unify
            (Layout LayoutType)
            ('Layout 'Dense)
            (Unify (Layout LayoutType) queryLayout attentionBiasLayout)))
      (Unify
         (Device (DeviceType Nat))
         queryDevice
         (Unify
            (Device (DeviceType Nat))
            device
            (Unify
               (Device (DeviceType Nat))
               queryDevice
               (Unify
                  (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
      (Unify
         (DataType DType)
         queryDataType
         (Unify
            (DataType DType)
            dataType
            (Unify (DataType DType) queryDataType attentionBiasDataType)))
      (BroadcastShapesF queryShape mhaOutputShape)
    -&gt; IxStateT
         m
         (Generator
            (Unify
               (Device (DeviceType Nat))
               device
               (Unify
                  (Device (DeviceType Nat))
                  queryDevice
                  (Unify
                     (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
         generatorOutput
         output)
-&gt; IxStateT m (Generator generatorDevice) generatorOutput output
forall k1 (m :: k1 -&gt; k1 -&gt; Type -&gt; Type) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(Generator
   (Unify
      (Device (DeviceType Nat))
      device
      (Unify
         (Device (DeviceType Nat))
         queryDevice
         (Unify
            (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
 -&gt; m (output, generatorOutput))
-&gt; IxStateT
     m
     (Generator
        (Unify
           (Device (DeviceType Nat))
           device
           (Unify
              (Device (DeviceType Nat))
              queryDevice
              (Unify
                 (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
     generatorOutput
     output
forall (m :: Type -&gt; Type) i j a.
(i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator
    (Unify
       (Device (DeviceType Nat))
       device
       (Unify
          (Device (DeviceType Nat))
          queryDevice
          (Unify
             (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
  -&gt; m (output, generatorOutput))
 -&gt; IxStateT
      m
      (Generator
         (Unify
            (Device (DeviceType Nat))
            device
            (Unify
               (Device (DeviceType Nat))
               queryDevice
               (Unify
                  (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
      generatorOutput
      output)
-&gt; (Tensor
      (Or
         (Gradient RequiresGradient)
         queryGradient
         (Or
            (Gradient RequiresGradient)
            gradient
            (Or
               (Gradient RequiresGradient) queryGradient attentionBiasGradient)))
      (Unify
         (Layout LayoutType)
         queryLayout
         (Unify
            (Layout LayoutType)
            ('Layout 'Dense)
            (Unify (Layout LayoutType) queryLayout attentionBiasLayout)))
      (Unify
         (Device (DeviceType Nat))
         queryDevice
         (Unify
            (Device (DeviceType Nat))
            device
            (Unify
               (Device (DeviceType Nat))
               queryDevice
               (Unify
                  (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
      (Unify
         (DataType DType)
         queryDataType
         (Unify
            (DataType DType)
            dataType
            (Unify (DataType DType) queryDataType attentionBiasDataType)))
      (BroadcastShapesF queryShape mhaOutputShape)
    -&gt; Generator
         (Unify
            (Device (DeviceType Nat))
            device
            (Unify
               (Device (DeviceType Nat))
               queryDevice
               (Unify
                  (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
    -&gt; m (output, generatorOutput))
-&gt; Tensor
     (Or
        (Gradient RequiresGradient)
        queryGradient
        (Or
           (Gradient RequiresGradient)
           gradient
           (Or
              (Gradient RequiresGradient) queryGradient attentionBiasGradient)))
     (Unify
        (Layout LayoutType)
        queryLayout
        (Unify
           (Layout LayoutType)
           ('Layout 'Dense)
           (Unify (Layout LayoutType) queryLayout attentionBiasLayout)))
     (Unify
        (Device (DeviceType Nat))
        queryDevice
        (Unify
           (Device (DeviceType Nat))
           device
           (Unify
              (Device (DeviceType Nat))
              queryDevice
              (Unify
                 (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
     (Unify
        (DataType DType)
        queryDataType
        (Unify
           (DataType DType)
           dataType
           (Unify (DataType DType) queryDataType attentionBiasDataType)))
     (BroadcastShapesF queryShape mhaOutputShape)
-&gt; IxStateT
     m
     (Generator
        (Unify
           (Device (DeviceType Nat))
           device
           (Unify
              (Device (DeviceType Nat))
              queryDevice
              (Unify
                 (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
     generatorOutput
     output
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">LayerNorm
  'WithBias gradient device dataType ('Shape '[queryEmbedDim])
-&gt; Tensor
     (Or
        (Gradient RequiresGradient)
        queryGradient
        (Or
           (Gradient RequiresGradient)
           gradient
           (Or
              (Gradient RequiresGradient) queryGradient attentionBiasGradient)))
     (Unify
        (Layout LayoutType)
        queryLayout
        (Unify
           (Layout LayoutType)
           ('Layout 'Dense)
           (Unify (Layout LayoutType) queryLayout attentionBiasLayout)))
     (Unify
        (Device (DeviceType Nat))
        queryDevice
        (Unify
           (Device (DeviceType Nat))
           device
           (Unify
              (Device (DeviceType Nat))
              queryDevice
              (Unify
                 (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
     (Unify
        (DataType DType)
        queryDataType
        (Unify
           (DataType DType)
           dataType
           (Unify (DataType DType) queryDataType attentionBiasDataType)))
     (BroadcastShapesF queryShape mhaOutputShape)
-&gt; Generator
     (Unify
        (Device (DeviceType Nat))
        device
        (Unify
           (Device (DeviceType Nat))
           queryDevice
           (Unify
              (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
-&gt; m (output, generatorOutput)
forall model input generator output generatorOutput
       (m :: Type -&gt; Type).
(HasForward model input generator output generatorOutput,
 MonadThrow m) =&gt;
model -&gt; input -&gt; generator -&gt; m (output, generatorOutput)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">LayerNorm
  'WithBias gradient device dataType ('Shape '[queryEmbedDim])
SALayerNormF 'BERT gradient device dataType queryEmbedDim
</span><a href="#local-6989586621679768652"><span class="hs-identifier hs-var">saLayerNorm</span></a></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span>
</span><span id="line-546"></span><span>
</span><span id="line-547"></span><span class="hs-comment">-- | 'HasForward' instance for @SelfAttention 'RoBERTa@.</span><span>
</span><span id="line-548"></span><span class="hs-comment">--</span><span>
</span><span id="line-549"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-550"></span><span class="hs-comment">-- &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;      &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;</span><span>
</span><span id="line-551"></span><span class="hs-comment">-- &#9474; attentionBias &#9474;      &#9474; query &#9474;</span><span>
</span><span id="line-552"></span><span class="hs-comment">-- &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;      &#9492;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-553"></span><span class="hs-comment">--         &#9474;                  &#9474;</span><span>
</span><span id="line-554"></span><span class="hs-comment">--         &#9474;            &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9524;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;</span><span>
</span><span id="line-555"></span><span class="hs-comment">--         &#9474;            &#9474;           &#9474;</span><span>
</span><span id="line-556"></span><span class="hs-comment">--         &#9474;       &#9484;&#9472;&#9472;&#9472;&#9472;&#9532;&#9472;&#9472;&#9472;&#9472;&#9488;      &#9474;</span><span>
</span><span id="line-557"></span><span class="hs-comment">--         &#9474;       &#9474;    &#9474;    &#9474;      &#9474;</span><span>
</span><span id="line-558"></span><span class="hs-comment">--         &#9474;       &#9660;    &#9660;    &#9660;      &#9474;</span><span>
</span><span id="line-559"></span><span class="hs-comment">--         &#9492;&#9472;&#9658;saMultiHeadAttention  &#9474;</span><span>
</span><span id="line-560"></span><span class="hs-comment">--                      &#9474;           &#9474;</span><span>
</span><span id="line-561"></span><span class="hs-comment">--                      &#9660;           &#9474;</span><span>
</span><span id="line-562"></span><span class="hs-comment">--                  saDropout       &#9474;</span><span>
</span><span id="line-563"></span><span class="hs-comment">--                      &#9474;           &#9474;</span><span>
</span><span id="line-564"></span><span class="hs-comment">--                      &#9492;&#9472;&#9472;&#9472;&#9658;add&#9668;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-565"></span><span class="hs-comment">--                            &#9474;</span><span>
</span><span id="line-566"></span><span class="hs-comment">--                            &#9660;</span><span>
</span><span id="line-567"></span><span class="hs-comment">--                       saLayerNorm</span><span>
</span><span id="line-568"></span><span class="hs-comment">--                            &#9474;</span><span>
</span><span id="line-569"></span><span class="hs-comment">--                            &#9660;</span><span>
</span><span id="line-570"></span><span class="hs-comment">--                        &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;</span><span>
</span><span id="line-571"></span><span class="hs-comment">--                        &#9474; query &#9474;</span><span>
</span><span id="line-572"></span><span class="hs-comment">--                        &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-573"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-574"></span><span id="local-6989586621679768624"><span id="local-6989586621679768625"><span id="local-6989586621679768626"><span id="local-6989586621679768627"><span id="local-6989586621679768628"><span id="local-6989586621679768629"><span id="local-6989586621679768630"><span id="local-6989586621679768631"><span id="local-6989586621679768632"><span id="local-6989586621679768633"><span id="local-6989586621679768634"><span id="local-6989586621679768635"><span id="local-6989586621679768636"><span id="local-6989586621679768637"><span id="local-6989586621679768638"><span id="local-6989586621679768639"><span id="local-6989586621679768640"><span id="local-6989586621679768641"><span id="local-6989586621679768642"><span id="local-6989586621679768643"><span id="local-6989586621679768644"><span id="local-6989586621679768645"><span id="local-6989586621679768646"><span id="local-6989586621679768647"><span class="hs-keyword">instance</span><span>
</span><span id="line-575"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetDim"><span class="hs-identifier hs-type">SGetDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768647"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-576"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Scalar.html#Scalar"><span class="hs-identifier hs-type">Scalar</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768646"><span class="hs-identifier hs-type">dropoutP</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-577"></span><span>    </span><span class="annot"><a href="#local-6989586621679768645"><span class="hs-identifier hs-type">query</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768644"><span class="hs-identifier hs-type">queryGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768643"><span class="hs-identifier hs-type">queryLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768642"><span class="hs-identifier hs-type">queryDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768641"><span class="hs-identifier hs-type">queryDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768640"><span class="hs-identifier hs-type">queryShape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-578"></span><span>    </span><span class="annot"><a href="#local-6989586621679768639"><span class="hs-identifier hs-type">attentionBias</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768638"><span class="hs-identifier hs-type">attentionBiasGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768637"><span class="hs-identifier hs-type">attentionBiasLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768636"><span class="hs-identifier hs-type">attentionBiasDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768635"><span class="hs-identifier hs-type">attentionBiasDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768634"><span class="hs-identifier hs-type">attentionBiasShape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-579"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-580"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.MultiHeadAttention.html#MultiHeadAttention"><span class="hs-identifier hs-type">MultiHeadAttention</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#RoBERTa"><span class="hs-identifier hs-type">RoBERTa</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768633"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768632"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768631"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768630"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768629"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768628"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768647"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768647"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768647"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768646"><span class="hs-identifier hs-type">dropoutP</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-581"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679768645"><span class="hs-identifier hs-type">query</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679768645"><span class="hs-identifier hs-type">query</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679768645"><span class="hs-identifier hs-type">query</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679768639"><span class="hs-identifier hs-type">attentionBias</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-582"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Random.html#Generator"><span class="hs-identifier hs-type">Generator</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768627"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-583"></span><span>      </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-584"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679768633"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768644"><span class="hs-identifier hs-type">queryGradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768638"><span class="hs-identifier hs-type">attentionBiasGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-585"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Dense"><span class="hs-identifier hs-type">Dense</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768643"><span class="hs-identifier hs-type">queryLayout</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768637"><span class="hs-identifier hs-type">attentionBiasLayout</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-586"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679768632"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768642"><span class="hs-identifier hs-type">queryDevice</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768636"><span class="hs-identifier hs-type">attentionBiasDevice</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768627"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-587"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679768631"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768641"><span class="hs-identifier hs-type">queryDataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768635"><span class="hs-identifier hs-type">attentionBiasDataType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-588"></span><span>          </span><span class="annot"><a href="#local-6989586621679768626"><span class="hs-identifier hs-type">mhaOutputShape</span></a></span><span>
</span><span id="line-589"></span><span>      </span><span class="hs-special">)</span><span>
</span><span id="line-590"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Random.html#Generator"><span class="hs-identifier hs-type">Generator</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679768632"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768642"><span class="hs-identifier hs-type">queryDevice</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768636"><span class="hs-identifier hs-type">attentionBiasDevice</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768627"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-591"></span><span>    </span><span class="annot"><a href="#local-6989586621679768625"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-592"></span><span>      </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-593"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679768633"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768644"><span class="hs-identifier hs-type">queryGradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768638"><span class="hs-identifier hs-type">attentionBiasGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-594"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Dense"><span class="hs-identifier hs-type">Dense</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768643"><span class="hs-identifier hs-type">queryLayout</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768637"><span class="hs-identifier hs-type">attentionBiasLayout</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-595"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679768632"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768642"><span class="hs-identifier hs-type">queryDevice</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768636"><span class="hs-identifier hs-type">attentionBiasDevice</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768627"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-596"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679768631"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768641"><span class="hs-identifier hs-type">queryDataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768635"><span class="hs-identifier hs-type">attentionBiasDataType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-597"></span><span>          </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Functional.Normalization.html#LayerNormWithBiasF"><span class="hs-identifier hs-type">LayerNormWithBiasF</span></a></span><span>
</span><span id="line-598"></span><span>              </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679768647"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-599"></span><span>              </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679768647"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-600"></span><span>              </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#BroadcastShapesF"><span class="hs-identifier hs-type">BroadcastShapesF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768640"><span class="hs-identifier hs-type">queryShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768626"><span class="hs-identifier hs-type">mhaOutputShape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-601"></span><span>          </span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-602"></span><span>    </span><span class="annot"><a href="#local-6989586621679768624"><span class="hs-identifier hs-type">generatorOutput</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Random.html#Generator"><span class="hs-identifier hs-type">Generator</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679768632"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768642"><span class="hs-identifier hs-type">queryDevice</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768636"><span class="hs-identifier hs-type">attentionBiasDevice</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768627"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-603"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-604"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-605"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#SelfAttention"><span class="hs-identifier hs-type">SelfAttention</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#RoBERTa"><span class="hs-identifier hs-type">RoBERTa</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768633"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768632"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768631"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768630"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768629"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768628"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768647"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768646"><span class="hs-identifier hs-type">dropoutP</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-606"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679768645"><span class="hs-identifier hs-type">query</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679768639"><span class="hs-identifier hs-type">attentionBias</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-607"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Random.html#Generator"><span class="hs-identifier hs-type">Generator</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768627"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-608"></span><span>    </span><span class="annot"><a href="#local-6989586621679768625"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-609"></span><span>    </span><span class="annot"><a href="#local-6989586621679768624"><span class="hs-identifier hs-type">generatorOutput</span></a></span><span>
</span><span id="line-610"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-611"></span><span>  </span><span id="local-6989586621679768622"><span class="annot"><span class="annottext">forward :: SelfAttention
  'RoBERTa
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  queryEmbedDim
  dropoutP
-&gt; (query, attentionBias)
-&gt; Generator generatorDevice
-&gt; m (output, generatorOutput)
</span><a href="#local-6989586621679768622"><span class="hs-identifier hs-var hs-var hs-var hs-var">forward</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#SelfAttention"><span class="hs-identifier hs-type">SelfAttention</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#GSelfAttention"><span class="hs-identifier hs-type">GSelfAttention</span></a></span><span> </span><span class="hs-special">{</span><span id="local-6989586621679768619"><span id="local-6989586621679768620"><span id="local-6989586621679768621"><span class="annot"><span class="annottext">SADropoutF 'RoBERTa dropoutP
SALayerNormF 'RoBERTa gradient device dataType queryEmbedDim
SAMultiheadAttentionF
  'RoBERTa
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  queryEmbedDim
  dropoutP
saDropout :: SADropoutF 'RoBERTa dropoutP
saLayerNorm :: SALayerNormF 'RoBERTa gradient device dataType queryEmbedDim
saMultiHeadAttention :: SAMultiheadAttentionF
  'RoBERTa
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  queryEmbedDim
  dropoutP
saDropout :: forall mha layerNorm dropout.
GSelfAttention mha layerNorm dropout -&gt; dropout
saLayerNorm :: forall mha layerNorm dropout.
GSelfAttention mha layerNorm dropout -&gt; layerNorm
saMultiHeadAttention :: forall mha layerNorm dropout.
GSelfAttention mha layerNorm dropout -&gt; mha
</span><a href="#local-6989586621679768619"><span class="hs-glyph hs-var hs-var hs-var hs-var hs-var hs-var">..</span></a></span></span></span></span><span class="hs-special">}</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679768618"><span class="annot"><span class="annottext">query
</span><a href="#local-6989586621679768618"><span class="hs-identifier hs-var">query</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679768617"><span class="annot"><span class="annottext">attentionBias
</span><a href="#local-6989586621679768617"><span class="hs-identifier hs-var">attentionBias</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-612"></span><span>    </span><span class="annot"><span class="annottext">IxStateT m (Generator generatorDevice) generatorOutput output
-&gt; Generator generatorDevice -&gt; m (output, generatorOutput)
forall (m :: Type -&gt; Type) i j a. IxStateT m i j a -&gt; i -&gt; m (a, j)
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var hs-var">runIxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">(IxStateT m (Generator generatorDevice) generatorOutput output
 -&gt; Generator generatorDevice -&gt; m (output, generatorOutput))
-&gt; IxStateT m (Generator generatorDevice) generatorOutput output
-&gt; Generator generatorDevice
-&gt; m (output, generatorOutput)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-613"></span><span>      </span><span class="annot"><span class="annottext">query
-&gt; IxStateT
     m (Generator generatorDevice) (Generator generatorDevice) query
forall k (m :: k -&gt; k -&gt; Type -&gt; Type) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">query
</span><a href="#local-6989586621679768618"><span class="hs-identifier hs-var">query</span></a></span><span>
</span><span id="line-614"></span><span>        </span><span class="annot"><span class="annottext">IxStateT
  m (Generator generatorDevice) (Generator generatorDevice) query
-&gt; (query
    -&gt; IxStateT
         m
         (Generator generatorDevice)
         (Generator
            (Unify
               (Device (DeviceType Nat))
               device
               (Unify
                  (Device (DeviceType Nat))
                  queryDevice
                  (Unify
                     (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
         (Tensor
            (Or
               (Gradient RequiresGradient)
               gradient
               (Or
                  (Gradient RequiresGradient) queryGradient attentionBiasGradient))
            (Unify
               (Layout LayoutType)
               ('Layout 'Dense)
               (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
            (Unify
               (Device (DeviceType Nat))
               device
               (Unify
                  (Device (DeviceType Nat))
                  queryDevice
                  (Unify
                     (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
            (Unify
               (DataType DType)
               dataType
               (Unify (DataType DType) queryDataType attentionBiasDataType))
            mhaOutputShape))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator
        (Unify
           (Device (DeviceType Nat))
           device
           (Unify
              (Device (DeviceType Nat))
              queryDevice
              (Unify
                 (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
     (Tensor
        (Or
           (Gradient RequiresGradient)
           gradient
           (Or
              (Gradient RequiresGradient) queryGradient attentionBiasGradient))
        (Unify
           (Layout LayoutType)
           ('Layout 'Dense)
           (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
        (Unify
           (Device (DeviceType Nat))
           device
           (Unify
              (Device (DeviceType Nat))
              queryDevice
              (Unify
                 (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
        (Unify
           (DataType DType)
           dataType
           (Unify (DataType DType) queryDataType attentionBiasDataType))
        mhaOutputShape)
forall k1 (m :: k1 -&gt; k1 -&gt; Type -&gt; Type) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">\</span><span id="local-6989586621679768616"><span class="annot"><span class="annottext">query
</span><a href="#local-6989586621679768616"><span class="hs-identifier hs-var">query'</span></a></span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">(Generator generatorDevice
 -&gt; m (Tensor
         (Or
            (Gradient RequiresGradient)
            gradient
            (Or
               (Gradient RequiresGradient) queryGradient attentionBiasGradient))
         (Unify
            (Layout LayoutType)
            ('Layout 'Dense)
            (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
         (Unify
            (Device (DeviceType Nat))
            device
            (Unify
               (Device (DeviceType Nat))
               queryDevice
               (Unify
                  (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
         (Unify
            (DataType DType)
            dataType
            (Unify (DataType DType) queryDataType attentionBiasDataType))
         mhaOutputShape,
       Generator
         (Unify
            (Device (DeviceType Nat))
            device
            (Unify
               (Device (DeviceType Nat))
               queryDevice
               (Unify
                  (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator
        (Unify
           (Device (DeviceType Nat))
           device
           (Unify
              (Device (DeviceType Nat))
              queryDevice
              (Unify
                 (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
     (Tensor
        (Or
           (Gradient RequiresGradient)
           gradient
           (Or
              (Gradient RequiresGradient) queryGradient attentionBiasGradient))
        (Unify
           (Layout LayoutType)
           ('Layout 'Dense)
           (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
        (Unify
           (Device (DeviceType Nat))
           device
           (Unify
              (Device (DeviceType Nat))
              queryDevice
              (Unify
                 (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
        (Unify
           (DataType DType)
           dataType
           (Unify (DataType DType) queryDataType attentionBiasDataType))
        mhaOutputShape)
forall (m :: Type -&gt; Type) i j a.
(i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator generatorDevice
  -&gt; m (Tensor
          (Or
             (Gradient RequiresGradient)
             gradient
             (Or
                (Gradient RequiresGradient) queryGradient attentionBiasGradient))
          (Unify
             (Layout LayoutType)
             ('Layout 'Dense)
             (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
          (Unify
             (Device (DeviceType Nat))
             device
             (Unify
                (Device (DeviceType Nat))
                queryDevice
                (Unify
                   (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
          (Unify
             (DataType DType)
             dataType
             (Unify (DataType DType) queryDataType attentionBiasDataType))
          mhaOutputShape,
        Generator
          (Unify
             (Device (DeviceType Nat))
             device
             (Unify
                (Device (DeviceType Nat))
                queryDevice
                (Unify
                   (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))))
 -&gt; IxStateT
      m
      (Generator generatorDevice)
      (Generator
         (Unify
            (Device (DeviceType Nat))
            device
            (Unify
               (Device (DeviceType Nat))
               queryDevice
               (Unify
                  (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
      (Tensor
         (Or
            (Gradient RequiresGradient)
            gradient
            (Or
               (Gradient RequiresGradient) queryGradient attentionBiasGradient))
         (Unify
            (Layout LayoutType)
            ('Layout 'Dense)
            (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
         (Unify
            (Device (DeviceType Nat))
            device
            (Unify
               (Device (DeviceType Nat))
               queryDevice
               (Unify
                  (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
         (Unify
            (DataType DType)
            dataType
            (Unify (DataType DType) queryDataType attentionBiasDataType))
         mhaOutputShape))
-&gt; (Generator generatorDevice
    -&gt; m (Tensor
            (Or
               (Gradient RequiresGradient)
               gradient
               (Or
                  (Gradient RequiresGradient) queryGradient attentionBiasGradient))
            (Unify
               (Layout LayoutType)
               ('Layout 'Dense)
               (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
            (Unify
               (Device (DeviceType Nat))
               device
               (Unify
                  (Device (DeviceType Nat))
                  queryDevice
                  (Unify
                     (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
            (Unify
               (DataType DType)
               dataType
               (Unify (DataType DType) queryDataType attentionBiasDataType))
            mhaOutputShape,
          Generator
            (Unify
               (Device (DeviceType Nat))
               device
               (Unify
                  (Device (DeviceType Nat))
                  queryDevice
                  (Unify
                     (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator
        (Unify
           (Device (DeviceType Nat))
           device
           (Unify
              (Device (DeviceType Nat))
              queryDevice
              (Unify
                 (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
     (Tensor
        (Or
           (Gradient RequiresGradient)
           gradient
           (Or
              (Gradient RequiresGradient) queryGradient attentionBiasGradient))
        (Unify
           (Layout LayoutType)
           ('Layout 'Dense)
           (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
        (Unify
           (Device (DeviceType Nat))
           device
           (Unify
              (Device (DeviceType Nat))
              queryDevice
              (Unify
                 (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
        (Unify
           (DataType DType)
           dataType
           (Unify (DataType DType) queryDataType attentionBiasDataType))
        mhaOutputShape)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">MultiHeadAttention
  'RoBERTa
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  queryEmbedDim
  queryEmbedDim
  queryEmbedDim
  dropoutP
-&gt; (query, query, query, attentionBias)
-&gt; Generator generatorDevice
-&gt; m (Tensor
        (Or
           (Gradient RequiresGradient)
           gradient
           (Or
              (Gradient RequiresGradient) queryGradient attentionBiasGradient))
        (Unify
           (Layout LayoutType)
           ('Layout 'Dense)
           (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
        (Unify
           (Device (DeviceType Nat))
           device
           (Unify
              (Device (DeviceType Nat))
              queryDevice
              (Unify
                 (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
        (Unify
           (DataType DType)
           dataType
           (Unify (DataType DType) queryDataType attentionBiasDataType))
        mhaOutputShape,
      Generator
        (Unify
           (Device (DeviceType Nat))
           device
           (Unify
              (Device (DeviceType Nat))
              queryDevice
              (Unify
                 (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
forall model input generator output generatorOutput
       (m :: Type -&gt; Type).
(HasForward model input generator output generatorOutput,
 MonadThrow m) =&gt;
model -&gt; input -&gt; generator -&gt; m (output, generatorOutput)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">MultiHeadAttention
  'RoBERTa
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  queryEmbedDim
  queryEmbedDim
  queryEmbedDim
  dropoutP
SAMultiheadAttentionF
  'RoBERTa
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  queryEmbedDim
  dropoutP
</span><a href="#local-6989586621679768621"><span class="hs-identifier hs-var">saMultiHeadAttention</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">query
</span><a href="#local-6989586621679768616"><span class="hs-identifier hs-var">query'</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">query
</span><a href="#local-6989586621679768616"><span class="hs-identifier hs-var">query'</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">query
</span><a href="#local-6989586621679768616"><span class="hs-identifier hs-var">query'</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">attentionBias
</span><a href="#local-6989586621679768617"><span class="hs-identifier hs-var">attentionBias</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-615"></span><span>        </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator
     (Unify
        (Device (DeviceType Nat))
        device
        (Unify
           (Device (DeviceType Nat))
           queryDevice
           (Unify
              (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
  (Tensor
     (Or
        (Gradient RequiresGradient)
        gradient
        (Or
           (Gradient RequiresGradient) queryGradient attentionBiasGradient))
     (Unify
        (Layout LayoutType)
        ('Layout 'Dense)
        (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
     (Unify
        (Device (DeviceType Nat))
        device
        (Unify
           (Device (DeviceType Nat))
           queryDevice
           (Unify
              (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
     (Unify
        (DataType DType)
        dataType
        (Unify (DataType DType) queryDataType attentionBiasDataType))
     mhaOutputShape)
-&gt; (Tensor
      (Or
         (Gradient RequiresGradient)
         gradient
         (Or
            (Gradient RequiresGradient) queryGradient attentionBiasGradient))
      (Unify
         (Layout LayoutType)
         ('Layout 'Dense)
         (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
      (Unify
         (Device (DeviceType Nat))
         device
         (Unify
            (Device (DeviceType Nat))
            queryDevice
            (Unify
               (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
      (Unify
         (DataType DType)
         dataType
         (Unify (DataType DType) queryDataType attentionBiasDataType))
      mhaOutputShape
    -&gt; IxStateT
         m
         (Generator
            (Unify
               (Device (DeviceType Nat))
               device
               (Unify
                  (Device (DeviceType Nat))
                  queryDevice
                  (Unify
                     (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
         (Generator
            (Unify
               (Device (DeviceType Nat))
               device
               (Unify
                  (Device (DeviceType Nat))
                  queryDevice
                  (Unify
                     (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
         (Tensor
            (Or
               (Gradient RequiresGradient)
               gradient
               (Or
                  (Gradient RequiresGradient) queryGradient attentionBiasGradient))
            (Unify
               (Layout LayoutType)
               ('Layout 'Dense)
               (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
            (Unify
               (Device (DeviceType Nat))
               device
               (Unify
                  (Device (DeviceType Nat))
                  queryDevice
                  (Unify
                     (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
            (Unify
               (DataType DType)
               dataType
               (Unify (DataType DType) queryDataType attentionBiasDataType))
            mhaOutputShape))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator
        (Unify
           (Device (DeviceType Nat))
           device
           (Unify
              (Device (DeviceType Nat))
              queryDevice
              (Unify
                 (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
     (Tensor
        (Or
           (Gradient RequiresGradient)
           gradient
           (Or
              (Gradient RequiresGradient) queryGradient attentionBiasGradient))
        (Unify
           (Layout LayoutType)
           ('Layout 'Dense)
           (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
        (Unify
           (Device (DeviceType Nat))
           device
           (Unify
              (Device (DeviceType Nat))
              queryDevice
              (Unify
                 (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
        (Unify
           (DataType DType)
           dataType
           (Unify (DataType DType) queryDataType attentionBiasDataType))
        mhaOutputShape)
forall k1 (m :: k1 -&gt; k1 -&gt; Type -&gt; Type) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(Generator
   (Unify
      (Device (DeviceType Nat))
      device
      (Unify
         (Device (DeviceType Nat))
         queryDevice
         (Unify
            (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
 -&gt; m (Tensor
         (Or
            (Gradient RequiresGradient)
            gradient
            (Or
               (Gradient RequiresGradient) queryGradient attentionBiasGradient))
         (Unify
            (Layout LayoutType)
            ('Layout 'Dense)
            (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
         (Unify
            (Device (DeviceType Nat))
            device
            (Unify
               (Device (DeviceType Nat))
               queryDevice
               (Unify
                  (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
         (Unify
            (DataType DType)
            dataType
            (Unify (DataType DType) queryDataType attentionBiasDataType))
         mhaOutputShape,
       Generator
         (Unify
            (Device (DeviceType Nat))
            device
            (Unify
               (Device (DeviceType Nat))
               queryDevice
               (Unify
                  (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))))
-&gt; IxStateT
     m
     (Generator
        (Unify
           (Device (DeviceType Nat))
           device
           (Unify
              (Device (DeviceType Nat))
              queryDevice
              (Unify
                 (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
     (Generator
        (Unify
           (Device (DeviceType Nat))
           device
           (Unify
              (Device (DeviceType Nat))
              queryDevice
              (Unify
                 (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
     (Tensor
        (Or
           (Gradient RequiresGradient)
           gradient
           (Or
              (Gradient RequiresGradient) queryGradient attentionBiasGradient))
        (Unify
           (Layout LayoutType)
           ('Layout 'Dense)
           (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
        (Unify
           (Device (DeviceType Nat))
           device
           (Unify
              (Device (DeviceType Nat))
              queryDevice
              (Unify
                 (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
        (Unify
           (DataType DType)
           dataType
           (Unify (DataType DType) queryDataType attentionBiasDataType))
        mhaOutputShape)
forall (m :: Type -&gt; Type) i j a.
(i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator
    (Unify
       (Device (DeviceType Nat))
       device
       (Unify
          (Device (DeviceType Nat))
          queryDevice
          (Unify
             (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
  -&gt; m (Tensor
          (Or
             (Gradient RequiresGradient)
             gradient
             (Or
                (Gradient RequiresGradient) queryGradient attentionBiasGradient))
          (Unify
             (Layout LayoutType)
             ('Layout 'Dense)
             (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
          (Unify
             (Device (DeviceType Nat))
             device
             (Unify
                (Device (DeviceType Nat))
                queryDevice
                (Unify
                   (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
          (Unify
             (DataType DType)
             dataType
             (Unify (DataType DType) queryDataType attentionBiasDataType))
          mhaOutputShape,
        Generator
          (Unify
             (Device (DeviceType Nat))
             device
             (Unify
                (Device (DeviceType Nat))
                queryDevice
                (Unify
                   (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))))
 -&gt; IxStateT
      m
      (Generator
         (Unify
            (Device (DeviceType Nat))
            device
            (Unify
               (Device (DeviceType Nat))
               queryDevice
               (Unify
                  (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
      (Generator
         (Unify
            (Device (DeviceType Nat))
            device
            (Unify
               (Device (DeviceType Nat))
               queryDevice
               (Unify
                  (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
      (Tensor
         (Or
            (Gradient RequiresGradient)
            gradient
            (Or
               (Gradient RequiresGradient) queryGradient attentionBiasGradient))
         (Unify
            (Layout LayoutType)
            ('Layout 'Dense)
            (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
         (Unify
            (Device (DeviceType Nat))
            device
            (Unify
               (Device (DeviceType Nat))
               queryDevice
               (Unify
                  (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
         (Unify
            (DataType DType)
            dataType
            (Unify (DataType DType) queryDataType attentionBiasDataType))
         mhaOutputShape))
-&gt; (Tensor
      (Or
         (Gradient RequiresGradient)
         gradient
         (Or
            (Gradient RequiresGradient) queryGradient attentionBiasGradient))
      (Unify
         (Layout LayoutType)
         ('Layout 'Dense)
         (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
      (Unify
         (Device (DeviceType Nat))
         device
         (Unify
            (Device (DeviceType Nat))
            queryDevice
            (Unify
               (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
      (Unify
         (DataType DType)
         dataType
         (Unify (DataType DType) queryDataType attentionBiasDataType))
      mhaOutputShape
    -&gt; Generator
         (Unify
            (Device (DeviceType Nat))
            device
            (Unify
               (Device (DeviceType Nat))
               queryDevice
               (Unify
                  (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
    -&gt; m (Tensor
            (Or
               (Gradient RequiresGradient)
               gradient
               (Or
                  (Gradient RequiresGradient) queryGradient attentionBiasGradient))
            (Unify
               (Layout LayoutType)
               ('Layout 'Dense)
               (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
            (Unify
               (Device (DeviceType Nat))
               device
               (Unify
                  (Device (DeviceType Nat))
                  queryDevice
                  (Unify
                     (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
            (Unify
               (DataType DType)
               dataType
               (Unify (DataType DType) queryDataType attentionBiasDataType))
            mhaOutputShape,
          Generator
            (Unify
               (Device (DeviceType Nat))
               device
               (Unify
                  (Device (DeviceType Nat))
                  queryDevice
                  (Unify
                     (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))))
-&gt; Tensor
     (Or
        (Gradient RequiresGradient)
        gradient
        (Or
           (Gradient RequiresGradient) queryGradient attentionBiasGradient))
     (Unify
        (Layout LayoutType)
        ('Layout 'Dense)
        (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
     (Unify
        (Device (DeviceType Nat))
        device
        (Unify
           (Device (DeviceType Nat))
           queryDevice
           (Unify
              (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
     (Unify
        (DataType DType)
        dataType
        (Unify (DataType DType) queryDataType attentionBiasDataType))
     mhaOutputShape
-&gt; IxStateT
     m
     (Generator
        (Unify
           (Device (DeviceType Nat))
           device
           (Unify
              (Device (DeviceType Nat))
              queryDevice
              (Unify
                 (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
     (Generator
        (Unify
           (Device (DeviceType Nat))
           device
           (Unify
              (Device (DeviceType Nat))
              queryDevice
              (Unify
                 (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
     (Tensor
        (Or
           (Gradient RequiresGradient)
           gradient
           (Or
              (Gradient RequiresGradient) queryGradient attentionBiasGradient))
        (Unify
           (Layout LayoutType)
           ('Layout 'Dense)
           (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
        (Unify
           (Device (DeviceType Nat))
           device
           (Unify
              (Device (DeviceType Nat))
              queryDevice
              (Unify
                 (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
        (Unify
           (DataType DType)
           dataType
           (Unify (DataType DType) queryDataType attentionBiasDataType))
        mhaOutputShape)
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Dropout dropoutP
-&gt; Tensor
     (Or
        (Gradient RequiresGradient)
        gradient
        (Or
           (Gradient RequiresGradient) queryGradient attentionBiasGradient))
     (Unify
        (Layout LayoutType)
        ('Layout 'Dense)
        (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
     (Unify
        (Device (DeviceType Nat))
        device
        (Unify
           (Device (DeviceType Nat))
           queryDevice
           (Unify
              (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
     (Unify
        (DataType DType)
        dataType
        (Unify (DataType DType) queryDataType attentionBiasDataType))
     mhaOutputShape
-&gt; Generator
     (Unify
        (Device (DeviceType Nat))
        device
        (Unify
           (Device (DeviceType Nat))
           queryDevice
           (Unify
              (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
-&gt; m (Tensor
        (Or
           (Gradient RequiresGradient)
           gradient
           (Or
              (Gradient RequiresGradient) queryGradient attentionBiasGradient))
        (Unify
           (Layout LayoutType)
           ('Layout 'Dense)
           (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
        (Unify
           (Device (DeviceType Nat))
           device
           (Unify
              (Device (DeviceType Nat))
              queryDevice
              (Unify
                 (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
        (Unify
           (DataType DType)
           dataType
           (Unify (DataType DType) queryDataType attentionBiasDataType))
        mhaOutputShape,
      Generator
        (Unify
           (Device (DeviceType Nat))
           device
           (Unify
              (Device (DeviceType Nat))
              queryDevice
              (Unify
                 (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
forall model input generator output generatorOutput
       (m :: Type -&gt; Type).
(HasForward model input generator output generatorOutput,
 MonadThrow m) =&gt;
model -&gt; input -&gt; generator -&gt; m (output, generatorOutput)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">Dropout dropoutP
SADropoutF 'RoBERTa dropoutP
</span><a href="#local-6989586621679768619"><span class="hs-identifier hs-var">saDropout</span></a></span><span>
</span><span id="line-616"></span><span>        </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator
     (Unify
        (Device (DeviceType Nat))
        device
        (Unify
           (Device (DeviceType Nat))
           queryDevice
           (Unify
              (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
  (Tensor
     (Or
        (Gradient RequiresGradient)
        gradient
        (Or
           (Gradient RequiresGradient) queryGradient attentionBiasGradient))
     (Unify
        (Layout LayoutType)
        ('Layout 'Dense)
        (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
     (Unify
        (Device (DeviceType Nat))
        device
        (Unify
           (Device (DeviceType Nat))
           queryDevice
           (Unify
              (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
     (Unify
        (DataType DType)
        dataType
        (Unify (DataType DType) queryDataType attentionBiasDataType))
     mhaOutputShape)
-&gt; (Tensor
      (Or
         (Gradient RequiresGradient)
         gradient
         (Or
            (Gradient RequiresGradient) queryGradient attentionBiasGradient))
      (Unify
         (Layout LayoutType)
         ('Layout 'Dense)
         (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
      (Unify
         (Device (DeviceType Nat))
         device
         (Unify
            (Device (DeviceType Nat))
            queryDevice
            (Unify
               (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
      (Unify
         (DataType DType)
         dataType
         (Unify (DataType DType) queryDataType attentionBiasDataType))
      mhaOutputShape
    -&gt; IxStateT
         m
         (Generator
            (Unify
               (Device (DeviceType Nat))
               device
               (Unify
                  (Device (DeviceType Nat))
                  queryDevice
                  (Unify
                     (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
         (Generator
            (Unify
               (Device (DeviceType Nat))
               device
               (Unify
                  (Device (DeviceType Nat))
                  queryDevice
                  (Unify
                     (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
         (Tensor
            (Or
               (Gradient RequiresGradient)
               queryGradient
               (Or
                  (Gradient RequiresGradient)
                  gradient
                  (Or
                     (Gradient RequiresGradient) queryGradient attentionBiasGradient)))
            (Unify
               (Layout LayoutType)
               queryLayout
               (Unify
                  (Layout LayoutType)
                  ('Layout 'Dense)
                  (Unify (Layout LayoutType) queryLayout attentionBiasLayout)))
            (Unify
               (Device (DeviceType Nat))
               queryDevice
               (Unify
                  (Device (DeviceType Nat))
                  device
                  (Unify
                     (Device (DeviceType Nat))
                     queryDevice
                     (Unify
                        (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
            (Unify
               (DataType DType)
               queryDataType
               (Unify
                  (DataType DType)
                  dataType
                  (Unify (DataType DType) queryDataType attentionBiasDataType)))
            (BroadcastShapesF queryShape mhaOutputShape)))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator
        (Unify
           (Device (DeviceType Nat))
           device
           (Unify
              (Device (DeviceType Nat))
              queryDevice
              (Unify
                 (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
     (Tensor
        (Or
           (Gradient RequiresGradient)
           queryGradient
           (Or
              (Gradient RequiresGradient)
              gradient
              (Or
                 (Gradient RequiresGradient) queryGradient attentionBiasGradient)))
        (Unify
           (Layout LayoutType)
           queryLayout
           (Unify
              (Layout LayoutType)
              ('Layout 'Dense)
              (Unify (Layout LayoutType) queryLayout attentionBiasLayout)))
        (Unify
           (Device (DeviceType Nat))
           queryDevice
           (Unify
              (Device (DeviceType Nat))
              device
              (Unify
                 (Device (DeviceType Nat))
                 queryDevice
                 (Unify
                    (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
        (Unify
           (DataType DType)
           queryDataType
           (Unify
              (DataType DType)
              dataType
              (Unify (DataType DType) queryDataType attentionBiasDataType)))
        (BroadcastShapesF queryShape mhaOutputShape))
forall k1 (m :: k1 -&gt; k1 -&gt; Type -&gt; Type) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  (Or
     (Gradient RequiresGradient)
     queryGradient
     (Or
        (Gradient RequiresGradient)
        gradient
        (Or
           (Gradient RequiresGradient) queryGradient attentionBiasGradient)))
  (Unify
     (Layout LayoutType)
     queryLayout
     (Unify
        (Layout LayoutType)
        ('Layout 'Dense)
        (Unify (Layout LayoutType) queryLayout attentionBiasLayout)))
  (Unify
     (Device (DeviceType Nat))
     queryDevice
     (Unify
        (Device (DeviceType Nat))
        device
        (Unify
           (Device (DeviceType Nat))
           queryDevice
           (Unify
              (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
  (Unify
     (DataType DType)
     queryDataType
     (Unify
        (DataType DType)
        dataType
        (Unify (DataType DType) queryDataType attentionBiasDataType)))
  (BroadcastShapesF queryShape mhaOutputShape)
-&gt; IxStateT
     m
     (Generator
        (Unify
           (Device (DeviceType Nat))
           device
           (Unify
              (Device (DeviceType Nat))
              queryDevice
              (Unify
                 (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
     (Generator
        (Unify
           (Device (DeviceType Nat))
           device
           (Unify
              (Device (DeviceType Nat))
              queryDevice
              (Unify
                 (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
     (Tensor
        (Or
           (Gradient RequiresGradient)
           queryGradient
           (Or
              (Gradient RequiresGradient)
              gradient
              (Or
                 (Gradient RequiresGradient) queryGradient attentionBiasGradient)))
        (Unify
           (Layout LayoutType)
           queryLayout
           (Unify
              (Layout LayoutType)
              ('Layout 'Dense)
              (Unify (Layout LayoutType) queryLayout attentionBiasLayout)))
        (Unify
           (Device (DeviceType Nat))
           queryDevice
           (Unify
              (Device (DeviceType Nat))
              device
              (Unify
                 (Device (DeviceType Nat))
                 queryDevice
                 (Unify
                    (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
        (Unify
           (DataType DType)
           queryDataType
           (Unify
              (DataType DType)
              dataType
              (Unify (DataType DType) queryDataType attentionBiasDataType)))
        (BroadcastShapesF queryShape mhaOutputShape))
forall k (m :: k -&gt; k -&gt; Type -&gt; Type) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">(Tensor
   (Or
      (Gradient RequiresGradient)
      queryGradient
      (Or
         (Gradient RequiresGradient)
         gradient
         (Or
            (Gradient RequiresGradient) queryGradient attentionBiasGradient)))
   (Unify
      (Layout LayoutType)
      queryLayout
      (Unify
         (Layout LayoutType)
         ('Layout 'Dense)
         (Unify (Layout LayoutType) queryLayout attentionBiasLayout)))
   (Unify
      (Device (DeviceType Nat))
      queryDevice
      (Unify
         (Device (DeviceType Nat))
         device
         (Unify
            (Device (DeviceType Nat))
            queryDevice
            (Unify
               (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
   (Unify
      (DataType DType)
      queryDataType
      (Unify
         (DataType DType)
         dataType
         (Unify (DataType DType) queryDataType attentionBiasDataType)))
   (BroadcastShapesF queryShape mhaOutputShape)
 -&gt; IxStateT
      m
      (Generator
         (Unify
            (Device (DeviceType Nat))
            device
            (Unify
               (Device (DeviceType Nat))
               queryDevice
               (Unify
                  (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
      (Generator
         (Unify
            (Device (DeviceType Nat))
            device
            (Unify
               (Device (DeviceType Nat))
               queryDevice
               (Unify
                  (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
      (Tensor
         (Or
            (Gradient RequiresGradient)
            queryGradient
            (Or
               (Gradient RequiresGradient)
               gradient
               (Or
                  (Gradient RequiresGradient) queryGradient attentionBiasGradient)))
         (Unify
            (Layout LayoutType)
            queryLayout
            (Unify
               (Layout LayoutType)
               ('Layout 'Dense)
               (Unify (Layout LayoutType) queryLayout attentionBiasLayout)))
         (Unify
            (Device (DeviceType Nat))
            queryDevice
            (Unify
               (Device (DeviceType Nat))
               device
               (Unify
                  (Device (DeviceType Nat))
                  queryDevice
                  (Unify
                     (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
         (Unify
            (DataType DType)
            queryDataType
            (Unify
               (DataType DType)
               dataType
               (Unify (DataType DType) queryDataType attentionBiasDataType)))
         (BroadcastShapesF queryShape mhaOutputShape)))
-&gt; (Tensor
      (Or
         (Gradient RequiresGradient)
         gradient
         (Or
            (Gradient RequiresGradient) queryGradient attentionBiasGradient))
      (Unify
         (Layout LayoutType)
         ('Layout 'Dense)
         (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
      (Unify
         (Device (DeviceType Nat))
         device
         (Unify
            (Device (DeviceType Nat))
            queryDevice
            (Unify
               (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
      (Unify
         (DataType DType)
         dataType
         (Unify (DataType DType) queryDataType attentionBiasDataType))
      mhaOutputShape
    -&gt; Tensor
         (Or
            (Gradient RequiresGradient)
            queryGradient
            (Or
               (Gradient RequiresGradient)
               gradient
               (Or
                  (Gradient RequiresGradient) queryGradient attentionBiasGradient)))
         (Unify
            (Layout LayoutType)
            queryLayout
            (Unify
               (Layout LayoutType)
               ('Layout 'Dense)
               (Unify (Layout LayoutType) queryLayout attentionBiasLayout)))
         (Unify
            (Device (DeviceType Nat))
            queryDevice
            (Unify
               (Device (DeviceType Nat))
               device
               (Unify
                  (Device (DeviceType Nat))
                  queryDevice
                  (Unify
                     (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
         (Unify
            (DataType DType)
            queryDataType
            (Unify
               (DataType DType)
               dataType
               (Unify (DataType DType) queryDataType attentionBiasDataType)))
         (BroadcastShapesF queryShape mhaOutputShape))
-&gt; Tensor
     (Or
        (Gradient RequiresGradient)
        gradient
        (Or
           (Gradient RequiresGradient) queryGradient attentionBiasGradient))
     (Unify
        (Layout LayoutType)
        ('Layout 'Dense)
        (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
     (Unify
        (Device (DeviceType Nat))
        device
        (Unify
           (Device (DeviceType Nat))
           queryDevice
           (Unify
              (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
     (Unify
        (DataType DType)
        dataType
        (Unify (DataType DType) queryDataType attentionBiasDataType))
     mhaOutputShape
-&gt; IxStateT
     m
     (Generator
        (Unify
           (Device (DeviceType Nat))
           device
           (Unify
              (Device (DeviceType Nat))
              queryDevice
              (Unify
                 (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
     (Generator
        (Unify
           (Device (DeviceType Nat))
           device
           (Unify
              (Device (DeviceType Nat))
              queryDevice
              (Unify
                 (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
     (Tensor
        (Or
           (Gradient RequiresGradient)
           queryGradient
           (Or
              (Gradient RequiresGradient)
              gradient
              (Or
                 (Gradient RequiresGradient) queryGradient attentionBiasGradient)))
        (Unify
           (Layout LayoutType)
           queryLayout
           (Unify
              (Layout LayoutType)
              ('Layout 'Dense)
              (Unify (Layout LayoutType) queryLayout attentionBiasLayout)))
        (Unify
           (Device (DeviceType Nat))
           queryDevice
           (Unify
              (Device (DeviceType Nat))
              device
              (Unify
                 (Device (DeviceType Nat))
                 queryDevice
                 (Unify
                    (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
        (Unify
           (DataType DType)
           queryDataType
           (Unify
              (DataType DType)
              dataType
              (Unify (DataType DType) queryDataType attentionBiasDataType)))
        (BroadcastShapesF queryShape mhaOutputShape))
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">query
Tensor
  queryGradient queryLayout queryDevice queryDataType queryShape
</span><a href="#local-6989586621679768618"><span class="hs-identifier hs-var">query</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  queryGradient queryLayout queryDevice queryDataType queryShape
-&gt; Tensor
     (Or
        (Gradient RequiresGradient)
        gradient
        (Or
           (Gradient RequiresGradient) queryGradient attentionBiasGradient))
     (Unify
        (Layout LayoutType)
        ('Layout 'Dense)
        (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
     (Unify
        (Device (DeviceType Nat))
        device
        (Unify
           (Device (DeviceType Nat))
           queryDevice
           (Unify
              (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
     (Unify
        (DataType DType)
        dataType
        (Unify (DataType DType) queryDataType attentionBiasDataType))
     mhaOutputShape
-&gt; Tensor
     (queryGradient
      &lt;|&gt; Or
            (Gradient RequiresGradient)
            gradient
            (Or
               (Gradient RequiresGradient) queryGradient attentionBiasGradient))
     (queryLayout
      &lt;+&gt; Unify
            (Layout LayoutType)
            ('Layout 'Dense)
            (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
     (queryDevice
      &lt;+&gt; Unify
            (Device (DeviceType Nat))
            device
            (Unify
               (Device (DeviceType Nat))
               queryDevice
               (Unify
                  (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
     (queryDataType
      &lt;+&gt; Unify
            (DataType DType)
            dataType
            (Unify (DataType DType) queryDataType attentionBiasDataType))
     (BroadcastShapesF queryShape mhaOutputShape)
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (gradient' :: Gradient RequiresGradient)
       (layout' :: Layout LayoutType) (device' :: Device (DeviceType Nat))
       (dataType' :: DataType DType)
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]).
Tensor gradient layout device dataType shape
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; Tensor
     (gradient &lt;|&gt; gradient')
     (layout &lt;+&gt; layout')
     (device &lt;+&gt; device')
     (dataType &lt;+&gt; dataType')
     (BroadcastShapesF shape shape')
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#add"><span class="hs-operator hs-var">`add`</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-617"></span><span>        </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator
     (Unify
        (Device (DeviceType Nat))
        device
        (Unify
           (Device (DeviceType Nat))
           queryDevice
           (Unify
              (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
  (Tensor
     (Or
        (Gradient RequiresGradient)
        queryGradient
        (Or
           (Gradient RequiresGradient)
           gradient
           (Or
              (Gradient RequiresGradient) queryGradient attentionBiasGradient)))
     (Unify
        (Layout LayoutType)
        queryLayout
        (Unify
           (Layout LayoutType)
           ('Layout 'Dense)
           (Unify (Layout LayoutType) queryLayout attentionBiasLayout)))
     (Unify
        (Device (DeviceType Nat))
        queryDevice
        (Unify
           (Device (DeviceType Nat))
           device
           (Unify
              (Device (DeviceType Nat))
              queryDevice
              (Unify
                 (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
     (Unify
        (DataType DType)
        queryDataType
        (Unify
           (DataType DType)
           dataType
           (Unify (DataType DType) queryDataType attentionBiasDataType)))
     (BroadcastShapesF queryShape mhaOutputShape))
-&gt; (Tensor
      (Or
         (Gradient RequiresGradient)
         queryGradient
         (Or
            (Gradient RequiresGradient)
            gradient
            (Or
               (Gradient RequiresGradient) queryGradient attentionBiasGradient)))
      (Unify
         (Layout LayoutType)
         queryLayout
         (Unify
            (Layout LayoutType)
            ('Layout 'Dense)
            (Unify (Layout LayoutType) queryLayout attentionBiasLayout)))
      (Unify
         (Device (DeviceType Nat))
         queryDevice
         (Unify
            (Device (DeviceType Nat))
            device
            (Unify
               (Device (DeviceType Nat))
               queryDevice
               (Unify
                  (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
      (Unify
         (DataType DType)
         queryDataType
         (Unify
            (DataType DType)
            dataType
            (Unify (DataType DType) queryDataType attentionBiasDataType)))
      (BroadcastShapesF queryShape mhaOutputShape)
    -&gt; IxStateT
         m
         (Generator
            (Unify
               (Device (DeviceType Nat))
               device
               (Unify
                  (Device (DeviceType Nat))
                  queryDevice
                  (Unify
                     (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
         generatorOutput
         output)
-&gt; IxStateT m (Generator generatorDevice) generatorOutput output
forall k1 (m :: k1 -&gt; k1 -&gt; Type -&gt; Type) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(Generator
   (Unify
      (Device (DeviceType Nat))
      device
      (Unify
         (Device (DeviceType Nat))
         queryDevice
         (Unify
            (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
 -&gt; m (output, generatorOutput))
-&gt; IxStateT
     m
     (Generator
        (Unify
           (Device (DeviceType Nat))
           device
           (Unify
              (Device (DeviceType Nat))
              queryDevice
              (Unify
                 (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
     generatorOutput
     output
forall (m :: Type -&gt; Type) i j a.
(i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator
    (Unify
       (Device (DeviceType Nat))
       device
       (Unify
          (Device (DeviceType Nat))
          queryDevice
          (Unify
             (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
  -&gt; m (output, generatorOutput))
 -&gt; IxStateT
      m
      (Generator
         (Unify
            (Device (DeviceType Nat))
            device
            (Unify
               (Device (DeviceType Nat))
               queryDevice
               (Unify
                  (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
      generatorOutput
      output)
-&gt; (Tensor
      (Or
         (Gradient RequiresGradient)
         queryGradient
         (Or
            (Gradient RequiresGradient)
            gradient
            (Or
               (Gradient RequiresGradient) queryGradient attentionBiasGradient)))
      (Unify
         (Layout LayoutType)
         queryLayout
         (Unify
            (Layout LayoutType)
            ('Layout 'Dense)
            (Unify (Layout LayoutType) queryLayout attentionBiasLayout)))
      (Unify
         (Device (DeviceType Nat))
         queryDevice
         (Unify
            (Device (DeviceType Nat))
            device
            (Unify
               (Device (DeviceType Nat))
               queryDevice
               (Unify
                  (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
      (Unify
         (DataType DType)
         queryDataType
         (Unify
            (DataType DType)
            dataType
            (Unify (DataType DType) queryDataType attentionBiasDataType)))
      (BroadcastShapesF queryShape mhaOutputShape)
    -&gt; Generator
         (Unify
            (Device (DeviceType Nat))
            device
            (Unify
               (Device (DeviceType Nat))
               queryDevice
               (Unify
                  (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
    -&gt; m (output, generatorOutput))
-&gt; Tensor
     (Or
        (Gradient RequiresGradient)
        queryGradient
        (Or
           (Gradient RequiresGradient)
           gradient
           (Or
              (Gradient RequiresGradient) queryGradient attentionBiasGradient)))
     (Unify
        (Layout LayoutType)
        queryLayout
        (Unify
           (Layout LayoutType)
           ('Layout 'Dense)
           (Unify (Layout LayoutType) queryLayout attentionBiasLayout)))
     (Unify
        (Device (DeviceType Nat))
        queryDevice
        (Unify
           (Device (DeviceType Nat))
           device
           (Unify
              (Device (DeviceType Nat))
              queryDevice
              (Unify
                 (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
     (Unify
        (DataType DType)
        queryDataType
        (Unify
           (DataType DType)
           dataType
           (Unify (DataType DType) queryDataType attentionBiasDataType)))
     (BroadcastShapesF queryShape mhaOutputShape)
-&gt; IxStateT
     m
     (Generator
        (Unify
           (Device (DeviceType Nat))
           device
           (Unify
              (Device (DeviceType Nat))
              queryDevice
              (Unify
                 (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
     generatorOutput
     output
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">LayerNorm
  'WithBias gradient device dataType ('Shape '[queryEmbedDim])
-&gt; Tensor
     (Or
        (Gradient RequiresGradient)
        queryGradient
        (Or
           (Gradient RequiresGradient)
           gradient
           (Or
              (Gradient RequiresGradient) queryGradient attentionBiasGradient)))
     (Unify
        (Layout LayoutType)
        queryLayout
        (Unify
           (Layout LayoutType)
           ('Layout 'Dense)
           (Unify (Layout LayoutType) queryLayout attentionBiasLayout)))
     (Unify
        (Device (DeviceType Nat))
        queryDevice
        (Unify
           (Device (DeviceType Nat))
           device
           (Unify
              (Device (DeviceType Nat))
              queryDevice
              (Unify
                 (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
     (Unify
        (DataType DType)
        queryDataType
        (Unify
           (DataType DType)
           dataType
           (Unify (DataType DType) queryDataType attentionBiasDataType)))
     (BroadcastShapesF queryShape mhaOutputShape)
-&gt; Generator
     (Unify
        (Device (DeviceType Nat))
        device
        (Unify
           (Device (DeviceType Nat))
           queryDevice
           (Unify
              (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
-&gt; m (output, generatorOutput)
forall model input generator output generatorOutput
       (m :: Type -&gt; Type).
(HasForward model input generator output generatorOutput,
 MonadThrow m) =&gt;
model -&gt; input -&gt; generator -&gt; m (output, generatorOutput)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">LayerNorm
  'WithBias gradient device dataType ('Shape '[queryEmbedDim])
SALayerNormF 'RoBERTa gradient device dataType queryEmbedDim
</span><a href="#local-6989586621679768620"><span class="hs-identifier hs-var">saLayerNorm</span></a></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span>
</span><span id="line-618"></span><span>
</span><span id="line-619"></span><span class="hs-comment">-- | 'HasForward' instance for @SelfAttention 'Pegasus@.</span><span>
</span><span id="line-620"></span><span class="hs-comment">--</span><span>
</span><span id="line-621"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-622"></span><span class="hs-comment">-- &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;     &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;</span><span>
</span><span id="line-623"></span><span class="hs-comment">-- &#9474; attentionBias &#9474;     &#9474; query &#9474;</span><span>
</span><span id="line-624"></span><span class="hs-comment">-- &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;     &#9492;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-625"></span><span class="hs-comment">--         &#9474;                 &#9474;</span><span>
</span><span id="line-626"></span><span class="hs-comment">--         &#9474;           &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9524;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;</span><span>
</span><span id="line-627"></span><span class="hs-comment">--         &#9474;           &#9474;           &#9474;</span><span>
</span><span id="line-628"></span><span class="hs-comment">--         &#9474;           &#9660;           &#9474;</span><span>
</span><span id="line-629"></span><span class="hs-comment">--         &#9474;      saLayerNorm      &#9474;</span><span>
</span><span id="line-630"></span><span class="hs-comment">--         &#9474;           &#9474;           &#9474;</span><span>
</span><span id="line-631"></span><span class="hs-comment">--         &#9474;      &#9484;&#9472;&#9472;&#9472;&#9472;&#9532;&#9472;&#9472;&#9472;&#9472;&#9488;      &#9474;</span><span>
</span><span id="line-632"></span><span class="hs-comment">--         &#9474;      &#9474;    &#9474;    &#9474;      &#9474;</span><span>
</span><span id="line-633"></span><span class="hs-comment">--         &#9474;      &#9660;    &#9660;    &#9660;      &#9474;</span><span>
</span><span id="line-634"></span><span class="hs-comment">--         &#9492;&#9472;&#9658;saMultiHeadAttention &#9474;</span><span>
</span><span id="line-635"></span><span class="hs-comment">--                     &#9474;           &#9474;</span><span>
</span><span id="line-636"></span><span class="hs-comment">--                     &#9660;           &#9474;</span><span>
</span><span id="line-637"></span><span class="hs-comment">--                 saDropout       &#9474;</span><span>
</span><span id="line-638"></span><span class="hs-comment">--                     &#9474;           &#9474;</span><span>
</span><span id="line-639"></span><span class="hs-comment">--                     &#9492;&#9472;&#9472;&#9472;&#9658;add&#9668;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-640"></span><span class="hs-comment">--                           &#9474;</span><span>
</span><span id="line-641"></span><span class="hs-comment">--                           &#9660;</span><span>
</span><span id="line-642"></span><span class="hs-comment">--                       &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;</span><span>
</span><span id="line-643"></span><span class="hs-comment">--                       &#9474; query &#9474;</span><span>
</span><span id="line-644"></span><span class="hs-comment">--                       &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-645"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-646"></span><span id="local-6989586621679768586"><span id="local-6989586621679768587"><span id="local-6989586621679768588"><span id="local-6989586621679768589"><span id="local-6989586621679768590"><span id="local-6989586621679768591"><span id="local-6989586621679768592"><span id="local-6989586621679768593"><span id="local-6989586621679768594"><span id="local-6989586621679768595"><span id="local-6989586621679768596"><span id="local-6989586621679768597"><span id="local-6989586621679768598"><span id="local-6989586621679768599"><span id="local-6989586621679768600"><span id="local-6989586621679768601"><span id="local-6989586621679768602"><span id="local-6989586621679768603"><span id="local-6989586621679768604"><span id="local-6989586621679768605"><span id="local-6989586621679768606"><span id="local-6989586621679768607"><span id="local-6989586621679768608"><span id="local-6989586621679768609"><span id="local-6989586621679768610"><span id="local-6989586621679768611"><span id="local-6989586621679768612"><span id="local-6989586621679768613"><span id="local-6989586621679768614"><span id="local-6989586621679768615"><span class="hs-keyword">instance</span><span>
</span><span id="line-647"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetDim"><span class="hs-identifier hs-type">SGetDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768615"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-648"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Scalar.html#Scalar"><span class="hs-identifier hs-type">Scalar</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768614"><span class="hs-identifier hs-type">dropoutP</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-649"></span><span>    </span><span class="annot"><a href="#local-6989586621679768613"><span class="hs-identifier hs-type">query</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768612"><span class="hs-identifier hs-type">queryGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768611"><span class="hs-identifier hs-type">queryLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768610"><span class="hs-identifier hs-type">queryDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768609"><span class="hs-identifier hs-type">queryDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768608"><span class="hs-identifier hs-type">queryShape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-650"></span><span>    </span><span class="annot"><a href="#local-6989586621679768607"><span class="hs-identifier hs-type">attentionBias</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768606"><span class="hs-identifier hs-type">attentionBiasGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768605"><span class="hs-identifier hs-type">attentionBiasLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768604"><span class="hs-identifier hs-type">attentionBiasDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768603"><span class="hs-identifier hs-type">attentionBiasDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768602"><span class="hs-identifier hs-type">attentionBiasShape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-651"></span><span>    </span><span class="annot"><a href="#local-6989586621679768601"><span class="hs-identifier hs-type">normedQueryGradient</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679768600"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768612"><span class="hs-identifier hs-type">queryGradient</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-652"></span><span>    </span><span class="annot"><a href="#local-6989586621679768599"><span class="hs-identifier hs-type">normedQueryLayout</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Dense"><span class="hs-identifier hs-type">Dense</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768611"><span class="hs-identifier hs-type">queryLayout</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-653"></span><span>    </span><span class="annot"><a href="#local-6989586621679768598"><span class="hs-identifier hs-type">normedQueryDevice</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679768597"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768610"><span class="hs-identifier hs-type">queryDevice</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-654"></span><span>    </span><span class="annot"><a href="#local-6989586621679768596"><span class="hs-identifier hs-type">normedQueryDataType</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679768595"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768609"><span class="hs-identifier hs-type">queryDataType</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-655"></span><span>    </span><span class="annot"><a href="#local-6989586621679768594"><span class="hs-identifier hs-type">normedQueryShape</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Functional.Normalization.html#LayerNormWithBiasF"><span class="hs-identifier hs-type">LayerNormWithBiasF</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679768615"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679768615"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679768608"><span class="hs-identifier hs-type">queryShape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-656"></span><span>    </span><span class="annot"><a href="#local-6989586621679768593"><span class="hs-identifier hs-type">normedQuery</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768601"><span class="hs-identifier hs-type">normedQueryGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768599"><span class="hs-identifier hs-type">normedQueryLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768598"><span class="hs-identifier hs-type">normedQueryDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768596"><span class="hs-identifier hs-type">normedQueryDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768594"><span class="hs-identifier hs-type">normedQueryShape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-657"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-658"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.MultiHeadAttention.html#MultiHeadAttention"><span class="hs-identifier hs-type">MultiHeadAttention</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#Pegasus"><span class="hs-identifier hs-type">Pegasus</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768600"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768597"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768595"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768592"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768591"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768590"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768615"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768615"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768615"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768614"><span class="hs-identifier hs-type">dropoutP</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-659"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679768593"><span class="hs-identifier hs-type">normedQuery</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679768593"><span class="hs-identifier hs-type">normedQuery</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679768593"><span class="hs-identifier hs-type">normedQuery</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679768607"><span class="hs-identifier hs-type">attentionBias</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-660"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Random.html#Generator"><span class="hs-identifier hs-type">Generator</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768589"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-661"></span><span>      </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-662"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679768600"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768612"><span class="hs-identifier hs-type">queryGradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768606"><span class="hs-identifier hs-type">attentionBiasGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-663"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Dense"><span class="hs-identifier hs-type">Dense</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768611"><span class="hs-identifier hs-type">queryLayout</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768605"><span class="hs-identifier hs-type">attentionBiasLayout</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-664"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679768597"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768610"><span class="hs-identifier hs-type">queryDevice</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768604"><span class="hs-identifier hs-type">attentionBiasDevice</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768589"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-665"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679768595"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768609"><span class="hs-identifier hs-type">queryDataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768603"><span class="hs-identifier hs-type">attentionBiasDataType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-666"></span><span>          </span><span class="annot"><a href="#local-6989586621679768588"><span class="hs-identifier hs-type">mhaOutputShape</span></a></span><span>
</span><span id="line-667"></span><span>      </span><span class="hs-special">)</span><span>
</span><span id="line-668"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Random.html#Generator"><span class="hs-identifier hs-type">Generator</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679768597"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768610"><span class="hs-identifier hs-type">queryDevice</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768604"><span class="hs-identifier hs-type">attentionBiasDevice</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768589"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-669"></span><span>    </span><span class="annot"><a href="#local-6989586621679768587"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-670"></span><span>      </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-671"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679768612"><span class="hs-identifier hs-type">queryGradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768600"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768606"><span class="hs-identifier hs-type">attentionBiasGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-672"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679768611"><span class="hs-identifier hs-type">queryLayout</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Dense"><span class="hs-identifier hs-type">Dense</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768605"><span class="hs-identifier hs-type">attentionBiasLayout</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-673"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679768610"><span class="hs-identifier hs-type">queryDevice</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768597"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768604"><span class="hs-identifier hs-type">attentionBiasDevice</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768589"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-674"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679768609"><span class="hs-identifier hs-type">queryDataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768595"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768603"><span class="hs-identifier hs-type">attentionBiasDataType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-675"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#BroadcastShapesF"><span class="hs-identifier hs-type">BroadcastShapesF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768608"><span class="hs-identifier hs-type">queryShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768588"><span class="hs-identifier hs-type">mhaOutputShape</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-676"></span><span>    </span><span class="annot"><a href="#local-6989586621679768586"><span class="hs-identifier hs-type">generatorOutput</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Random.html#Generator"><span class="hs-identifier hs-type">Generator</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679768597"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768610"><span class="hs-identifier hs-type">queryDevice</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768604"><span class="hs-identifier hs-type">attentionBiasDevice</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768589"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-677"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-678"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-679"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#SelfAttention"><span class="hs-identifier hs-type">SelfAttention</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#Pegasus"><span class="hs-identifier hs-type">Pegasus</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768600"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768597"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768595"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768592"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768591"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768590"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768615"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768614"><span class="hs-identifier hs-type">dropoutP</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-680"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679768613"><span class="hs-identifier hs-type">query</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679768607"><span class="hs-identifier hs-type">attentionBias</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-681"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Random.html#Generator"><span class="hs-identifier hs-type">Generator</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679768589"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-682"></span><span>    </span><span class="annot"><a href="#local-6989586621679768587"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-683"></span><span>    </span><span class="annot"><a href="#local-6989586621679768586"><span class="hs-identifier hs-type">generatorOutput</span></a></span><span>
</span><span id="line-684"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-685"></span><span>  </span><span id="local-6989586621679768584"><span class="annot"><span class="annottext">forward :: SelfAttention
  'Pegasus
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  queryEmbedDim
  dropoutP
-&gt; (query, attentionBias)
-&gt; Generator generatorDevice
-&gt; m (output, generatorOutput)
</span><a href="#local-6989586621679768584"><span class="hs-identifier hs-var hs-var hs-var hs-var">forward</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#SelfAttention"><span class="hs-identifier hs-type">SelfAttention</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#GSelfAttention"><span class="hs-identifier hs-type">GSelfAttention</span></a></span><span> </span><span class="hs-special">{</span><span id="local-6989586621679768581"><span id="local-6989586621679768582"><span id="local-6989586621679768583"><span class="annot"><span class="annottext">SADropoutF 'Pegasus dropoutP
SALayerNormF 'Pegasus gradient device dataType queryEmbedDim
SAMultiheadAttentionF
  'Pegasus
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  queryEmbedDim
  dropoutP
saDropout :: SADropoutF 'Pegasus dropoutP
saLayerNorm :: SALayerNormF 'Pegasus gradient device dataType queryEmbedDim
saMultiHeadAttention :: SAMultiheadAttentionF
  'Pegasus
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  queryEmbedDim
  dropoutP
saDropout :: forall mha layerNorm dropout.
GSelfAttention mha layerNorm dropout -&gt; dropout
saLayerNorm :: forall mha layerNorm dropout.
GSelfAttention mha layerNorm dropout -&gt; layerNorm
saMultiHeadAttention :: forall mha layerNorm dropout.
GSelfAttention mha layerNorm dropout -&gt; mha
</span><a href="#local-6989586621679768581"><span class="hs-glyph hs-var hs-var hs-var hs-var hs-var hs-var">..</span></a></span></span></span></span><span class="hs-special">}</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679768580"><span class="annot"><span class="annottext">query
</span><a href="#local-6989586621679768580"><span class="hs-identifier hs-var">query</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679768579"><span class="annot"><span class="annottext">attentionBias
</span><a href="#local-6989586621679768579"><span class="hs-identifier hs-var">attentionBias</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-686"></span><span>    </span><span class="annot"><span class="annottext">IxStateT m (Generator generatorDevice) generatorOutput output
-&gt; Generator generatorDevice -&gt; m (output, generatorOutput)
forall (m :: Type -&gt; Type) i j a. IxStateT m i j a -&gt; i -&gt; m (a, j)
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var hs-var">runIxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">(IxStateT m (Generator generatorDevice) generatorOutput output
 -&gt; Generator generatorDevice -&gt; m (output, generatorOutput))
-&gt; IxStateT m (Generator generatorDevice) generatorOutput output
-&gt; Generator generatorDevice
-&gt; m (output, generatorOutput)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-687"></span><span>      </span><span class="annot"><span class="annottext">query
-&gt; IxStateT
     m (Generator generatorDevice) (Generator generatorDevice) query
forall k (m :: k -&gt; k -&gt; Type -&gt; Type) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">query
</span><a href="#local-6989586621679768580"><span class="hs-identifier hs-var">query</span></a></span><span>
</span><span id="line-688"></span><span>        </span><span class="annot"><span class="annottext">IxStateT
  m (Generator generatorDevice) (Generator generatorDevice) query
-&gt; (query
    -&gt; IxStateT
         m
         (Generator generatorDevice)
         (Generator generatorDevice)
         (Tensor
            normedQueryGradient
            normedQueryLayout
            normedQueryDevice
            normedQueryDataType
            normedQueryShape))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     (Tensor
        normedQueryGradient
        normedQueryLayout
        normedQueryDevice
        normedQueryDataType
        normedQueryShape)
forall k1 (m :: k1 -&gt; k1 -&gt; Type -&gt; Type) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(Generator generatorDevice
 -&gt; m (Tensor
         normedQueryGradient
         normedQueryLayout
         normedQueryDevice
         normedQueryDataType
         normedQueryShape,
       Generator generatorDevice))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     (Tensor
        normedQueryGradient
        normedQueryLayout
        normedQueryDevice
        normedQueryDataType
        normedQueryShape)
forall (m :: Type -&gt; Type) i j a.
(i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator generatorDevice
  -&gt; m (Tensor
          normedQueryGradient
          normedQueryLayout
          normedQueryDevice
          normedQueryDataType
          normedQueryShape,
        Generator generatorDevice))
 -&gt; IxStateT
      m
      (Generator generatorDevice)
      (Generator generatorDevice)
      (Tensor
         normedQueryGradient
         normedQueryLayout
         normedQueryDevice
         normedQueryDataType
         normedQueryShape))
-&gt; (query
    -&gt; Generator generatorDevice
    -&gt; m (Tensor
            normedQueryGradient
            normedQueryLayout
            normedQueryDevice
            normedQueryDataType
            normedQueryShape,
          Generator generatorDevice))
-&gt; query
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     (Tensor
        normedQueryGradient
        normedQueryLayout
        normedQueryDevice
        normedQueryDataType
        normedQueryShape)
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">LayerNorm
  'WithBias gradient device dataType ('Shape '[queryEmbedDim])
-&gt; query
-&gt; Generator generatorDevice
-&gt; m (Tensor
        normedQueryGradient
        normedQueryLayout
        normedQueryDevice
        normedQueryDataType
        normedQueryShape,
      Generator generatorDevice)
forall model input generator output generatorOutput
       (m :: Type -&gt; Type).
(HasForward model input generator output generatorOutput,
 MonadThrow m) =&gt;
model -&gt; input -&gt; generator -&gt; m (output, generatorOutput)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">LayerNorm
  'WithBias gradient device dataType ('Shape '[queryEmbedDim])
SALayerNormF 'Pegasus gradient device dataType queryEmbedDim
</span><a href="#local-6989586621679768582"><span class="hs-identifier hs-var">saLayerNorm</span></a></span><span>
</span><span id="line-689"></span><span>        </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorDevice)
  (Tensor
     normedQueryGradient
     normedQueryLayout
     normedQueryDevice
     normedQueryDataType
     normedQueryShape)
-&gt; (Tensor
      normedQueryGradient
      normedQueryLayout
      normedQueryDevice
      normedQueryDataType
      normedQueryShape
    -&gt; IxStateT
         m
         (Generator generatorDevice)
         (Generator
            (Unify
               (Device (DeviceType Nat))
               device
               (Unify
                  (Device (DeviceType Nat))
                  queryDevice
                  (Unify
                     (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
         (Tensor
            (Or
               (Gradient RequiresGradient)
               gradient
               (Or
                  (Gradient RequiresGradient) queryGradient attentionBiasGradient))
            (Unify
               (Layout LayoutType)
               ('Layout 'Dense)
               (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
            (Unify
               (Device (DeviceType Nat))
               device
               (Unify
                  (Device (DeviceType Nat))
                  queryDevice
                  (Unify
                     (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
            (Unify
               (DataType DType)
               dataType
               (Unify (DataType DType) queryDataType attentionBiasDataType))
            mhaOutputShape))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator
        (Unify
           (Device (DeviceType Nat))
           device
           (Unify
              (Device (DeviceType Nat))
              queryDevice
              (Unify
                 (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
     (Tensor
        (Or
           (Gradient RequiresGradient)
           gradient
           (Or
              (Gradient RequiresGradient) queryGradient attentionBiasGradient))
        (Unify
           (Layout LayoutType)
           ('Layout 'Dense)
           (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
        (Unify
           (Device (DeviceType Nat))
           device
           (Unify
              (Device (DeviceType Nat))
              queryDevice
              (Unify
                 (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
        (Unify
           (DataType DType)
           dataType
           (Unify (DataType DType) queryDataType attentionBiasDataType))
        mhaOutputShape)
forall k1 (m :: k1 -&gt; k1 -&gt; Type -&gt; Type) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">\</span><span id="local-6989586621679768578"><span class="annot"><span class="annottext">Tensor
  normedQueryGradient
  normedQueryLayout
  normedQueryDevice
  normedQueryDataType
  normedQueryShape
</span><a href="#local-6989586621679768578"><span class="hs-identifier hs-var">query'</span></a></span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">(Generator generatorDevice
 -&gt; m (Tensor
         (Or
            (Gradient RequiresGradient)
            gradient
            (Or
               (Gradient RequiresGradient) queryGradient attentionBiasGradient))
         (Unify
            (Layout LayoutType)
            ('Layout 'Dense)
            (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
         (Unify
            (Device (DeviceType Nat))
            device
            (Unify
               (Device (DeviceType Nat))
               queryDevice
               (Unify
                  (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
         (Unify
            (DataType DType)
            dataType
            (Unify (DataType DType) queryDataType attentionBiasDataType))
         mhaOutputShape,
       Generator
         (Unify
            (Device (DeviceType Nat))
            device
            (Unify
               (Device (DeviceType Nat))
               queryDevice
               (Unify
                  (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator
        (Unify
           (Device (DeviceType Nat))
           device
           (Unify
              (Device (DeviceType Nat))
              queryDevice
              (Unify
                 (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
     (Tensor
        (Or
           (Gradient RequiresGradient)
           gradient
           (Or
              (Gradient RequiresGradient) queryGradient attentionBiasGradient))
        (Unify
           (Layout LayoutType)
           ('Layout 'Dense)
           (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
        (Unify
           (Device (DeviceType Nat))
           device
           (Unify
              (Device (DeviceType Nat))
              queryDevice
              (Unify
                 (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
        (Unify
           (DataType DType)
           dataType
           (Unify (DataType DType) queryDataType attentionBiasDataType))
        mhaOutputShape)
forall (m :: Type -&gt; Type) i j a.
(i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator generatorDevice
  -&gt; m (Tensor
          (Or
             (Gradient RequiresGradient)
             gradient
             (Or
                (Gradient RequiresGradient) queryGradient attentionBiasGradient))
          (Unify
             (Layout LayoutType)
             ('Layout 'Dense)
             (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
          (Unify
             (Device (DeviceType Nat))
             device
             (Unify
                (Device (DeviceType Nat))
                queryDevice
                (Unify
                   (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
          (Unify
             (DataType DType)
             dataType
             (Unify (DataType DType) queryDataType attentionBiasDataType))
          mhaOutputShape,
        Generator
          (Unify
             (Device (DeviceType Nat))
             device
             (Unify
                (Device (DeviceType Nat))
                queryDevice
                (Unify
                   (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))))
 -&gt; IxStateT
      m
      (Generator generatorDevice)
      (Generator
         (Unify
            (Device (DeviceType Nat))
            device
            (Unify
               (Device (DeviceType Nat))
               queryDevice
               (Unify
                  (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
      (Tensor
         (Or
            (Gradient RequiresGradient)
            gradient
            (Or
               (Gradient RequiresGradient) queryGradient attentionBiasGradient))
         (Unify
            (Layout LayoutType)
            ('Layout 'Dense)
            (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
         (Unify
            (Device (DeviceType Nat))
            device
            (Unify
               (Device (DeviceType Nat))
               queryDevice
               (Unify
                  (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
         (Unify
            (DataType DType)
            dataType
            (Unify (DataType DType) queryDataType attentionBiasDataType))
         mhaOutputShape))
-&gt; (Generator generatorDevice
    -&gt; m (Tensor
            (Or
               (Gradient RequiresGradient)
               gradient
               (Or
                  (Gradient RequiresGradient) queryGradient attentionBiasGradient))
            (Unify
               (Layout LayoutType)
               ('Layout 'Dense)
               (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
            (Unify
               (Device (DeviceType Nat))
               device
               (Unify
                  (Device (DeviceType Nat))
                  queryDevice
                  (Unify
                     (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
            (Unify
               (DataType DType)
               dataType
               (Unify (DataType DType) queryDataType attentionBiasDataType))
            mhaOutputShape,
          Generator
            (Unify
               (Device (DeviceType Nat))
               device
               (Unify
                  (Device (DeviceType Nat))
                  queryDevice
                  (Unify
                     (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator
        (Unify
           (Device (DeviceType Nat))
           device
           (Unify
              (Device (DeviceType Nat))
              queryDevice
              (Unify
                 (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
     (Tensor
        (Or
           (Gradient RequiresGradient)
           gradient
           (Or
              (Gradient RequiresGradient) queryGradient attentionBiasGradient))
        (Unify
           (Layout LayoutType)
           ('Layout 'Dense)
           (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
        (Unify
           (Device (DeviceType Nat))
           device
           (Unify
              (Device (DeviceType Nat))
              queryDevice
              (Unify
                 (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
        (Unify
           (DataType DType)
           dataType
           (Unify (DataType DType) queryDataType attentionBiasDataType))
        mhaOutputShape)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">MultiHeadAttention
  'Pegasus
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  queryEmbedDim
  queryEmbedDim
  queryEmbedDim
  dropoutP
-&gt; (Tensor
      normedQueryGradient
      normedQueryLayout
      normedQueryDevice
      normedQueryDataType
      normedQueryShape,
    Tensor
      normedQueryGradient
      normedQueryLayout
      normedQueryDevice
      normedQueryDataType
      normedQueryShape,
    Tensor
      normedQueryGradient
      normedQueryLayout
      normedQueryDevice
      normedQueryDataType
      normedQueryShape,
    attentionBias)
-&gt; Generator generatorDevice
-&gt; m (Tensor
        (Or
           (Gradient RequiresGradient)
           gradient
           (Or
              (Gradient RequiresGradient) queryGradient attentionBiasGradient))
        (Unify
           (Layout LayoutType)
           ('Layout 'Dense)
           (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
        (Unify
           (Device (DeviceType Nat))
           device
           (Unify
              (Device (DeviceType Nat))
              queryDevice
              (Unify
                 (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
        (Unify
           (DataType DType)
           dataType
           (Unify (DataType DType) queryDataType attentionBiasDataType))
        mhaOutputShape,
      Generator
        (Unify
           (Device (DeviceType Nat))
           device
           (Unify
              (Device (DeviceType Nat))
              queryDevice
              (Unify
                 (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
forall model input generator output generatorOutput
       (m :: Type -&gt; Type).
(HasForward model input generator output generatorOutput,
 MonadThrow m) =&gt;
model -&gt; input -&gt; generator -&gt; m (output, generatorOutput)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">MultiHeadAttention
  'Pegasus
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  queryEmbedDim
  queryEmbedDim
  queryEmbedDim
  dropoutP
SAMultiheadAttentionF
  'Pegasus
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  queryEmbedDim
  dropoutP
</span><a href="#local-6989586621679768583"><span class="hs-identifier hs-var">saMultiHeadAttention</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Tensor
  normedQueryGradient
  normedQueryLayout
  normedQueryDevice
  normedQueryDataType
  normedQueryShape
</span><a href="#local-6989586621679768578"><span class="hs-identifier hs-var">query'</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Tensor
  normedQueryGradient
  normedQueryLayout
  normedQueryDevice
  normedQueryDataType
  normedQueryShape
</span><a href="#local-6989586621679768578"><span class="hs-identifier hs-var">query'</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Tensor
  normedQueryGradient
  normedQueryLayout
  normedQueryDevice
  normedQueryDataType
  normedQueryShape
</span><a href="#local-6989586621679768578"><span class="hs-identifier hs-var">query'</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">attentionBias
</span><a href="#local-6989586621679768579"><span class="hs-identifier hs-var">attentionBias</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-690"></span><span>        </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator
     (Unify
        (Device (DeviceType Nat))
        device
        (Unify
           (Device (DeviceType Nat))
           queryDevice
           (Unify
              (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
  (Tensor
     (Or
        (Gradient RequiresGradient)
        gradient
        (Or
           (Gradient RequiresGradient) queryGradient attentionBiasGradient))
     (Unify
        (Layout LayoutType)
        ('Layout 'Dense)
        (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
     (Unify
        (Device (DeviceType Nat))
        device
        (Unify
           (Device (DeviceType Nat))
           queryDevice
           (Unify
              (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
     (Unify
        (DataType DType)
        dataType
        (Unify (DataType DType) queryDataType attentionBiasDataType))
     mhaOutputShape)
-&gt; (Tensor
      (Or
         (Gradient RequiresGradient)
         gradient
         (Or
            (Gradient RequiresGradient) queryGradient attentionBiasGradient))
      (Unify
         (Layout LayoutType)
         ('Layout 'Dense)
         (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
      (Unify
         (Device (DeviceType Nat))
         device
         (Unify
            (Device (DeviceType Nat))
            queryDevice
            (Unify
               (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
      (Unify
         (DataType DType)
         dataType
         (Unify (DataType DType) queryDataType attentionBiasDataType))
      mhaOutputShape
    -&gt; IxStateT
         m
         (Generator
            (Unify
               (Device (DeviceType Nat))
               device
               (Unify
                  (Device (DeviceType Nat))
                  queryDevice
                  (Unify
                     (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
         generatorOutput
         (Tensor
            (Or
               (Gradient RequiresGradient)
               gradient
               (Or
                  (Gradient RequiresGradient) queryGradient attentionBiasGradient))
            (Unify
               (Layout LayoutType)
               ('Layout 'Dense)
               (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
            (Unify
               (Device (DeviceType Nat))
               device
               (Unify
                  (Device (DeviceType Nat))
                  queryDevice
                  (Unify
                     (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
            (Unify
               (DataType DType)
               dataType
               (Unify (DataType DType) queryDataType attentionBiasDataType))
            mhaOutputShape))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     generatorOutput
     (Tensor
        (Or
           (Gradient RequiresGradient)
           gradient
           (Or
              (Gradient RequiresGradient) queryGradient attentionBiasGradient))
        (Unify
           (Layout LayoutType)
           ('Layout 'Dense)
           (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
        (Unify
           (Device (DeviceType Nat))
           device
           (Unify
              (Device (DeviceType Nat))
              queryDevice
              (Unify
                 (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
        (Unify
           (DataType DType)
           dataType
           (Unify (DataType DType) queryDataType attentionBiasDataType))
        mhaOutputShape)
forall k1 (m :: k1 -&gt; k1 -&gt; Type -&gt; Type) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(Generator
   (Unify
      (Device (DeviceType Nat))
      device
      (Unify
         (Device (DeviceType Nat))
         queryDevice
         (Unify
            (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
 -&gt; m (Tensor
         (Or
            (Gradient RequiresGradient)
            gradient
            (Or
               (Gradient RequiresGradient) queryGradient attentionBiasGradient))
         (Unify
            (Layout LayoutType)
            ('Layout 'Dense)
            (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
         (Unify
            (Device (DeviceType Nat))
            device
            (Unify
               (Device (DeviceType Nat))
               queryDevice
               (Unify
                  (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
         (Unify
            (DataType DType)
            dataType
            (Unify (DataType DType) queryDataType attentionBiasDataType))
         mhaOutputShape,
       generatorOutput))
-&gt; IxStateT
     m
     (Generator
        (Unify
           (Device (DeviceType Nat))
           device
           (Unify
              (Device (DeviceType Nat))
              queryDevice
              (Unify
                 (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
     generatorOutput
     (Tensor
        (Or
           (Gradient RequiresGradient)
           gradient
           (Or
              (Gradient RequiresGradient) queryGradient attentionBiasGradient))
        (Unify
           (Layout LayoutType)
           ('Layout 'Dense)
           (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
        (Unify
           (Device (DeviceType Nat))
           device
           (Unify
              (Device (DeviceType Nat))
              queryDevice
              (Unify
                 (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
        (Unify
           (DataType DType)
           dataType
           (Unify (DataType DType) queryDataType attentionBiasDataType))
        mhaOutputShape)
forall (m :: Type -&gt; Type) i j a.
(i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator
    (Unify
       (Device (DeviceType Nat))
       device
       (Unify
          (Device (DeviceType Nat))
          queryDevice
          (Unify
             (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
  -&gt; m (Tensor
          (Or
             (Gradient RequiresGradient)
             gradient
             (Or
                (Gradient RequiresGradient) queryGradient attentionBiasGradient))
          (Unify
             (Layout LayoutType)
             ('Layout 'Dense)
             (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
          (Unify
             (Device (DeviceType Nat))
             device
             (Unify
                (Device (DeviceType Nat))
                queryDevice
                (Unify
                   (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
          (Unify
             (DataType DType)
             dataType
             (Unify (DataType DType) queryDataType attentionBiasDataType))
          mhaOutputShape,
        generatorOutput))
 -&gt; IxStateT
      m
      (Generator
         (Unify
            (Device (DeviceType Nat))
            device
            (Unify
               (Device (DeviceType Nat))
               queryDevice
               (Unify
                  (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
      generatorOutput
      (Tensor
         (Or
            (Gradient RequiresGradient)
            gradient
            (Or
               (Gradient RequiresGradient) queryGradient attentionBiasGradient))
         (Unify
            (Layout LayoutType)
            ('Layout 'Dense)
            (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
         (Unify
            (Device (DeviceType Nat))
            device
            (Unify
               (Device (DeviceType Nat))
               queryDevice
               (Unify
                  (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
         (Unify
            (DataType DType)
            dataType
            (Unify (DataType DType) queryDataType attentionBiasDataType))
         mhaOutputShape))
-&gt; (Tensor
      (Or
         (Gradient RequiresGradient)
         gradient
         (Or
            (Gradient RequiresGradient) queryGradient attentionBiasGradient))
      (Unify
         (Layout LayoutType)
         ('Layout 'Dense)
         (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
      (Unify
         (Device (DeviceType Nat))
         device
         (Unify
            (Device (DeviceType Nat))
            queryDevice
            (Unify
               (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
      (Unify
         (DataType DType)
         dataType
         (Unify (DataType DType) queryDataType attentionBiasDataType))
      mhaOutputShape
    -&gt; Generator
         (Unify
            (Device (DeviceType Nat))
            device
            (Unify
               (Device (DeviceType Nat))
               queryDevice
               (Unify
                  (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
    -&gt; m (Tensor
            (Or
               (Gradient RequiresGradient)
               gradient
               (Or
                  (Gradient RequiresGradient) queryGradient attentionBiasGradient))
            (Unify
               (Layout LayoutType)
               ('Layout 'Dense)
               (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
            (Unify
               (Device (DeviceType Nat))
               device
               (Unify
                  (Device (DeviceType Nat))
                  queryDevice
                  (Unify
                     (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
            (Unify
               (DataType DType)
               dataType
               (Unify (DataType DType) queryDataType attentionBiasDataType))
            mhaOutputShape,
          generatorOutput))
-&gt; Tensor
     (Or
        (Gradient RequiresGradient)
        gradient
        (Or
           (Gradient RequiresGradient) queryGradient attentionBiasGradient))
     (Unify
        (Layout LayoutType)
        ('Layout 'Dense)
        (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
     (Unify
        (Device (DeviceType Nat))
        device
        (Unify
           (Device (DeviceType Nat))
           queryDevice
           (Unify
              (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
     (Unify
        (DataType DType)
        dataType
        (Unify (DataType DType) queryDataType attentionBiasDataType))
     mhaOutputShape
-&gt; IxStateT
     m
     (Generator
        (Unify
           (Device (DeviceType Nat))
           device
           (Unify
              (Device (DeviceType Nat))
              queryDevice
              (Unify
                 (Device (DeviceType Nat)) attentionBiasDevice generatorDevice))))
     generatorOutput
     (Tensor
        (Or
           (Gradient RequiresGradient)
           gradient
           (Or
              (Gradient RequiresGradient) queryGradient attentionBiasGradient))
        (Unify
           (Layout LayoutType)
           ('Layout 'Dense)
           (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
        (Unify
           (Device (DeviceType Nat))
           device
           (Unify
              (Device (DeviceType Nat))
              queryDevice
              (Unify
                 (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
        (Unify
           (DataType DType)
           dataType
           (Unify (DataType DType) queryDataType attentionBiasDataType))
        mhaOutputShape)
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Dropout dropoutP
-&gt; Tensor
     (Or
        (Gradient RequiresGradient)
        gradient
        (Or
           (Gradient RequiresGradient) queryGradient attentionBiasGradient))
     (Unify
        (Layout LayoutType)
        ('Layout 'Dense)
        (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
     (Unify
        (Device (DeviceType Nat))
        device
        (Unify
           (Device (DeviceType Nat))
           queryDevice
           (Unify
              (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
     (Unify
        (DataType DType)
        dataType
        (Unify (DataType DType) queryDataType attentionBiasDataType))
     mhaOutputShape
-&gt; Generator
     (Unify
        (Device (DeviceType Nat))
        device
        (Unify
           (Device (DeviceType Nat))
           queryDevice
           (Unify
              (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
-&gt; m (Tensor
        (Or
           (Gradient RequiresGradient)
           gradient
           (Or
              (Gradient RequiresGradient) queryGradient attentionBiasGradient))
        (Unify
           (Layout LayoutType)
           ('Layout 'Dense)
           (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
        (Unify
           (Device (DeviceType Nat))
           device
           (Unify
              (Device (DeviceType Nat))
              queryDevice
              (Unify
                 (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
        (Unify
           (DataType DType)
           dataType
           (Unify (DataType DType) queryDataType attentionBiasDataType))
        mhaOutputShape,
      generatorOutput)
forall model input generator output generatorOutput
       (m :: Type -&gt; Type).
(HasForward model input generator output generatorOutput,
 MonadThrow m) =&gt;
model -&gt; input -&gt; generator -&gt; m (output, generatorOutput)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">Dropout dropoutP
SADropoutF 'Pegasus dropoutP
</span><a href="#local-6989586621679768581"><span class="hs-identifier hs-var">saDropout</span></a></span><span>
</span><span id="line-691"></span><span>        </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  generatorOutput
  (Tensor
     (Or
        (Gradient RequiresGradient)
        gradient
        (Or
           (Gradient RequiresGradient) queryGradient attentionBiasGradient))
     (Unify
        (Layout LayoutType)
        ('Layout 'Dense)
        (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
     (Unify
        (Device (DeviceType Nat))
        device
        (Unify
           (Device (DeviceType Nat))
           queryDevice
           (Unify
              (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
     (Unify
        (DataType DType)
        dataType
        (Unify (DataType DType) queryDataType attentionBiasDataType))
     mhaOutputShape)
-&gt; (Tensor
      (Or
         (Gradient RequiresGradient)
         gradient
         (Or
            (Gradient RequiresGradient) queryGradient attentionBiasGradient))
      (Unify
         (Layout LayoutType)
         ('Layout 'Dense)
         (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
      (Unify
         (Device (DeviceType Nat))
         device
         (Unify
            (Device (DeviceType Nat))
            queryDevice
            (Unify
               (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
      (Unify
         (DataType DType)
         dataType
         (Unify (DataType DType) queryDataType attentionBiasDataType))
      mhaOutputShape
    -&gt; IxStateT m generatorOutput generatorOutput output)
-&gt; IxStateT m (Generator generatorDevice) generatorOutput output
forall k1 (m :: k1 -&gt; k1 -&gt; Type -&gt; Type) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">output -&gt; IxStateT m generatorOutput generatorOutput output
forall k (m :: k -&gt; k -&gt; Type -&gt; Type) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">(output -&gt; IxStateT m generatorOutput generatorOutput output)
-&gt; (Tensor
      (Or
         (Gradient RequiresGradient)
         gradient
         (Or
            (Gradient RequiresGradient) queryGradient attentionBiasGradient))
      (Unify
         (Layout LayoutType)
         ('Layout 'Dense)
         (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
      (Unify
         (Device (DeviceType Nat))
         device
         (Unify
            (Device (DeviceType Nat))
            queryDevice
            (Unify
               (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
      (Unify
         (DataType DType)
         dataType
         (Unify (DataType DType) queryDataType attentionBiasDataType))
      mhaOutputShape
    -&gt; output)
-&gt; Tensor
     (Or
        (Gradient RequiresGradient)
        gradient
        (Or
           (Gradient RequiresGradient) queryGradient attentionBiasGradient))
     (Unify
        (Layout LayoutType)
        ('Layout 'Dense)
        (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
     (Unify
        (Device (DeviceType Nat))
        device
        (Unify
           (Device (DeviceType Nat))
           queryDevice
           (Unify
              (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
     (Unify
        (DataType DType)
        dataType
        (Unify (DataType DType) queryDataType attentionBiasDataType))
     mhaOutputShape
-&gt; IxStateT m generatorOutput generatorOutput output
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">query
Tensor
  queryGradient queryLayout queryDevice queryDataType queryShape
</span><a href="#local-6989586621679768580"><span class="hs-identifier hs-var">query</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  queryGradient queryLayout queryDevice queryDataType queryShape
-&gt; Tensor
     (Or
        (Gradient RequiresGradient)
        gradient
        (Or
           (Gradient RequiresGradient) queryGradient attentionBiasGradient))
     (Unify
        (Layout LayoutType)
        ('Layout 'Dense)
        (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
     (Unify
        (Device (DeviceType Nat))
        device
        (Unify
           (Device (DeviceType Nat))
           queryDevice
           (Unify
              (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
     (Unify
        (DataType DType)
        dataType
        (Unify (DataType DType) queryDataType attentionBiasDataType))
     mhaOutputShape
-&gt; Tensor
     (queryGradient
      &lt;|&gt; Or
            (Gradient RequiresGradient)
            gradient
            (Or
               (Gradient RequiresGradient) queryGradient attentionBiasGradient))
     (queryLayout
      &lt;+&gt; Unify
            (Layout LayoutType)
            ('Layout 'Dense)
            (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
     (queryDevice
      &lt;+&gt; Unify
            (Device (DeviceType Nat))
            device
            (Unify
               (Device (DeviceType Nat))
               queryDevice
               (Unify
                  (Device (DeviceType Nat)) attentionBiasDevice generatorDevice)))
     (queryDataType
      &lt;+&gt; Unify
            (DataType DType)
            dataType
            (Unify (DataType DType) queryDataType attentionBiasDataType))
     (BroadcastShapesF queryShape mhaOutputShape)
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (gradient' :: Gradient RequiresGradient)
       (layout' :: Layout LayoutType) (device' :: Device (DeviceType Nat))
       (dataType' :: DataType DType)
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]).
Tensor gradient layout device dataType shape
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; Tensor
     (gradient &lt;|&gt; gradient')
     (layout &lt;+&gt; layout')
     (device &lt;+&gt; device')
     (dataType &lt;+&gt; dataType')
     (BroadcastShapesF shape shape')
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#add"><span class="hs-operator hs-var">`add`</span></a></span><span class="hs-special">)</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span>
</span><span id="line-692"></span></pre></body></html>