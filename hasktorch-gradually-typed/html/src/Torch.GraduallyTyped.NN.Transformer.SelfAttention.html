<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><link rel="stylesheet" type="text/css" href="style.css" /><script type="text/javascript" src="highlight.js"></script></head><body><pre><span class="hs-pragma">{-# LANGUAGE AllowAmbiguousTypes #-}</span><span>
</span><span id="line-2"></span><span class="hs-pragma">{-# LANGUAGE ConstraintKinds #-}</span><span>
</span><span id="line-3"></span><span class="hs-pragma">{-# LANGUAGE DataKinds #-}</span><span>
</span><span id="line-4"></span><span class="hs-pragma">{-# LANGUAGE FlexibleContexts #-}</span><span>
</span><span id="line-5"></span><span class="hs-pragma">{-# LANGUAGE FlexibleInstances #-}</span><span>
</span><span id="line-6"></span><span class="hs-pragma">{-# LANGUAGE GADTs #-}</span><span>
</span><span id="line-7"></span><span class="hs-pragma">{-# LANGUAGE KindSignatures #-}</span><span>
</span><span id="line-8"></span><span class="hs-pragma">{-# LANGUAGE MultiParamTypeClasses #-}</span><span>
</span><span id="line-9"></span><span class="hs-pragma">{-# LANGUAGE PartialTypeSignatures #-}</span><span>
</span><span id="line-10"></span><span class="hs-pragma">{-# LANGUAGE PatternSynonyms #-}</span><span>
</span><span id="line-11"></span><span class="hs-pragma">{-# LANGUAGE RecordWildCards #-}</span><span>
</span><span id="line-12"></span><span class="hs-pragma">{-# LANGUAGE ScopedTypeVariables #-}</span><span>
</span><span id="line-13"></span><span class="hs-pragma">{-# LANGUAGE StandaloneKindSignatures #-}</span><span>
</span><span id="line-14"></span><span class="hs-pragma">{-# LANGUAGE TupleSections #-}</span><span>
</span><span id="line-15"></span><span class="hs-pragma">{-# LANGUAGE TypeApplications #-}</span><span>
</span><span id="line-16"></span><span class="hs-pragma">{-# LANGUAGE TypeFamilies #-}</span><span>
</span><span id="line-17"></span><span class="hs-pragma">{-# LANGUAGE TypeOperators #-}</span><span>
</span><span id="line-18"></span><span class="hs-pragma">{-# LANGUAGE UndecidableInstances #-}</span><span>
</span><span id="line-19"></span><span class="hs-pragma">{-# LANGUAGE NoStarIsType #-}</span><span>
</span><span id="line-20"></span><span class="hs-pragma">{-# OPTIONS_GHC -fplugin TypeLevel.Rewrite
                -fplugin-opt=TypeLevel.Rewrite:Torch.GraduallyTyped.Unify.UnifyRightAssociativeL
                -fplugin-opt=TypeLevel.Rewrite:Torch.GraduallyTyped.Unify.UnifyIdempotenceL2
                -fplugin-opt=TypeLevel.Rewrite:Torch.GraduallyTyped.Unify.UnifyIdempotenceL2C
                -fplugin-opt=TypeLevel.Rewrite:Torch.GraduallyTyped.Unify.UnifyIdempotenceL3
                -fplugin-opt=TypeLevel.Rewrite:Torch.GraduallyTyped.Unify.UnifyIdempotenceL3C
                -fplugin-opt=TypeLevel.Rewrite:Torch.GraduallyTyped.Unify.UnifyIdempotenceL4
                -fplugin-opt=TypeLevel.Rewrite:Torch.GraduallyTyped.Unify.UnifyIdempotenceL4C
                -fplugin-opt=TypeLevel.Rewrite:Torch.GraduallyTyped.Unify.UnifyIdempotenceL5
                -fplugin-opt=TypeLevel.Rewrite:Torch.GraduallyTyped.Unify.UnifyIdempotenceL5C
                -fplugin-opt=TypeLevel.Rewrite:Torch.GraduallyTyped.Unify.UnifyIdempotenceL6
                -fplugin-opt=TypeLevel.Rewrite:Torch.GraduallyTyped.Unify.UnifyIdempotenceL6C
                -fplugin-opt=TypeLevel.Rewrite:Torch.GraduallyTyped.Unify.UnifyIdempotenceL7
                -fplugin-opt=TypeLevel.Rewrite:Torch.GraduallyTyped.Unify.UnifyIdempotenceL7C
                -fplugin-opt=TypeLevel.Rewrite:Torch.GraduallyTyped.Unify.UnifyIdempotenceL8
                -fplugin-opt=TypeLevel.Rewrite:Torch.GraduallyTyped.Unify.UnifyIdempotenceL8C
                -fplugin-opt=TypeLevel.Rewrite:Torch.GraduallyTyped.Unify.UnifyIdempotenceL9
                -fplugin-opt=TypeLevel.Rewrite:Torch.GraduallyTyped.Unify.UnifyIdempotenceL9C
                -fplugin-opt=TypeLevel.Rewrite:Torch.GraduallyTyped.Unify.OrRightAssociativeL
                -fplugin-opt=TypeLevel.Rewrite:Torch.GraduallyTyped.Unify.OrIdempotenceL2
                -fplugin-opt=TypeLevel.Rewrite:Torch.GraduallyTyped.Unify.OrIdempotenceL2C
                -fplugin-opt=TypeLevel.Rewrite:Torch.GraduallyTyped.Unify.OrIdempotenceL3
                -fplugin-opt=TypeLevel.Rewrite:Torch.GraduallyTyped.Unify.OrIdempotenceL3C #-}</span><span>
</span><span id="line-43"></span><span class="hs-pragma">{-# OPTIONS_GHC -v2 -Wall #-}</span><span>
</span><span id="line-44"></span><span>
</span><span id="line-45"></span><span class="hs-keyword">module</span><span> </span><span class="hs-identifier">Torch.GraduallyTyped.NN.Transformer.SelfAttention</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-46"></span><span>
</span><span id="line-47"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier">Control.Monad.Indexed</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier">ireturn</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator">(&gt;&gt;&gt;=)</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-48"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier">Control.Monad.Indexed.State</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier">IxStateT</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-49"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">Control.Monad.State</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier">evalStateT</span></span><span class="hs-special">)</span><span>
</span><span id="line-50"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier">Data.Functor.Indexed</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator">(&lt;&lt;$&gt;&gt;)</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator">(&lt;&lt;*&gt;&gt;)</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-51"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">Data.Kind</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier">Type</span></span><span class="hs-special">)</span><span>
</span><span id="line-52"></span><span class="hs-keyword">import</span><span> </span><span class="hs-keyword">qualified</span><span> </span><span class="annot"><span class="hs-identifier">Data.Map</span></span><span> </span><span class="hs-keyword">as</span><span> </span><span class="annot"><span class="hs-identifier">Map</span></span><span>
</span><span id="line-53"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">Data.Singletons</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">SingI</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">sing</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-54"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">Data.Singletons.Prelude.List</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">SList</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">SNil</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-55"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">GHC.TypeLits</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier">Nat</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier">Symbol</span></span><span class="hs-special">)</span><span>
</span><span id="line-56"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html"><span class="hs-identifier">Torch.GraduallyTyped.DType</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier">DType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier">DataType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#SDType"><span class="hs-identifier">SDType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier">SDataType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-57"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html"><span class="hs-identifier">Torch.GraduallyTyped.Device</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier">Device</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#DeviceType"><span class="hs-identifier">DeviceType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#SDevice"><span class="hs-identifier">SDevice</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#SDeviceType"><span class="hs-identifier">SDeviceType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-58"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html"><span class="hs-identifier">Torch.GraduallyTyped.Layout</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier">Layout</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#LayoutType"><span class="hs-identifier">LayoutType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#SLayout"><span class="hs-identifier">SLayout</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#SLayoutType"><span class="hs-identifier">SLayoutType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-59"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html"><span class="hs-identifier">Torch.GraduallyTyped.NN.Class</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier">HasForward</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier">HasInitialize</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasStateDict"><span class="hs-identifier">HasStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier">ModelSpec</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-60"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Dropout.html"><span class="hs-identifier">Torch.GraduallyTyped.NN.Dropout</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Dropout.html#Dropout"><span class="hs-identifier">Dropout</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-61"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Functional.Normalization.html"><span class="hs-identifier">Torch.GraduallyTyped.NN.Functional.Normalization</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Functional.Normalization.html#LayerNormWithBiasF"><span class="hs-identifier">LayerNormWithBiasF</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-62"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Normalization.html"><span class="hs-identifier">Torch.GraduallyTyped.NN.Normalization</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Normalization.html#LayerNorm"><span class="hs-identifier">LayerNorm</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Normalization.html#LayerNormSpec"><span class="hs-identifier">LayerNormSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-63"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.MultiHeadAttention.html"><span class="hs-identifier">Torch.GraduallyTyped.NN.Transformer.MultiHeadAttention</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.MultiHeadAttention.html#MultiHeadAttention"><span class="hs-identifier">MultiHeadAttention</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.MultiHeadAttention.html#MultiHeadAttentionSpec"><span class="hs-identifier">MultiHeadAttentionSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.MultiHeadAttention.html#MultiHeadAttentionSpec"><span class="hs-identifier">MultiHeadAttentionSpec</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-64"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html"><span class="hs-identifier">Torch.GraduallyTyped.NN.Transformer.Type</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#STransformerStyle"><span class="hs-identifier">STransformerStyle</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerStyle"><span class="hs-identifier">TransformerStyle</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-65"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Type.html"><span class="hs-identifier">Torch.GraduallyTyped.NN.Type</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Type.html#HasBias"><span class="hs-identifier">HasBias</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Type.html#SHasBias"><span class="hs-identifier">SHasBias</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-66"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Random.html"><span class="hs-identifier">Torch.GraduallyTyped.Random</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Random.html#sGeneratorToDevice"><span class="hs-identifier">sGeneratorToDevice</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Random.html#sMkGenerator"><span class="hs-identifier">sMkGenerator</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-67"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html"><span class="hs-identifier">Torch.GraduallyTyped.RequiresGradient</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier">Gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#RequiresGradient"><span class="hs-identifier">RequiresGradient</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier">SGradient</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#SRequiresGradient"><span class="hs-identifier">SRequiresGradient</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-68"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html"><span class="hs-identifier">Torch.GraduallyTyped.Shape.Class</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#BroadcastShapesF"><span class="hs-identifier">BroadcastShapesF</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-69"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html"><span class="hs-identifier">Torch.GraduallyTyped.Shape.Type</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier">Name</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier">SDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier">SName</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier">SShape</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier">SSize</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier">Shape</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier">Size</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="hs-keyword">pattern</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator">(:&amp;:)</span></a></span><span class="hs-special">,</span><span> </span><span class="hs-keyword">pattern</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator">(:|:)</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-70"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Creation.html"><span class="hs-identifier">Torch.GraduallyTyped.Tensor.Creation</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Creation.html#sOnes"><span class="hs-identifier">sOnes</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-71"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html"><span class="hs-identifier">Torch.GraduallyTyped.Tensor.MathOperations.Pointwise</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#add"><span class="hs-identifier">add</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-72"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html"><span class="hs-identifier">Torch.GraduallyTyped.Tensor.Type</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetDim"><span class="hs-identifier">SGetDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier">Tensor</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorSpec"><span class="hs-identifier">TensorSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-73"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html"><span class="hs-identifier">Torch.GraduallyTyped.Unify</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-keyword">type</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator">(&lt;+&gt;)</span></a></span><span class="hs-special">,</span><span> </span><span class="hs-keyword">type</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator">(&lt;|&gt;)</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-74"></span><span>
</span><span id="line-75"></span><span class="hs-comment">-- | Generic self-attention layer.</span><span>
</span><span id="line-76"></span><span class="hs-comment">-- Needs to be specialized to a given transformer type, e.g. 'T5'.</span><span>
</span><span id="line-77"></span><span class="hs-comment">-- See 'SelfAttention'.</span><span>
</span><span id="line-78"></span><span class="hs-keyword">data</span><span>
</span><span id="line-79"></span><span>  </span><span id="GSelfAttention"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#GSelfAttention"><span class="hs-identifier hs-var">GSelfAttention</span></a></span></span><span>
</span><span id="line-80"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679806303"><span class="annot"><a href="#local-6989586621679806303"><span class="hs-identifier hs-type">mha</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span class="hs-special">)</span><span>
</span><span id="line-81"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679806302"><span class="annot"><a href="#local-6989586621679806302"><span class="hs-identifier hs-type">layerNorm</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span class="hs-special">)</span><span>
</span><span id="line-82"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679806301"><span class="annot"><a href="#local-6989586621679806301"><span class="hs-identifier hs-type">dropout</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span class="hs-special">)</span><span>
</span><span id="line-83"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-84"></span><span>  </span><span id="GSelfAttention"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#GSelfAttention"><span class="hs-identifier hs-var">GSelfAttention</span></a></span></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-85"></span><span>    </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679806637"><span class="annot"><a href="#local-6989586621679806637"><span class="hs-identifier hs-type">mha</span></a></span></span><span> </span><span id="local-6989586621679806636"><span class="annot"><a href="#local-6989586621679806636"><span class="hs-identifier hs-type">layerNorm</span></a></span></span><span> </span><span id="local-6989586621679806635"><span class="annot"><a href="#local-6989586621679806635"><span class="hs-identifier hs-type">dropout</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-86"></span><span>    </span><span class="hs-special">{</span><span> </span><span class="hs-comment">-- | self-attention</span><span>
</span><span id="line-87"></span><span>      </span><span id="saMultiHeadAttention"><span class="annot"><span class="annottext">GSelfAttention mha layerNorm dropout -&gt; mha
</span><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#saMultiHeadAttention"><span class="hs-identifier hs-var hs-var">saMultiHeadAttention</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679806637"><span class="hs-identifier hs-type">mha</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-88"></span><span>      </span><span class="hs-comment">-- | layer norm</span><span>
</span><span id="line-89"></span><span>      </span><span id="saLayerNorm"><span class="annot"><span class="annottext">GSelfAttention mha layerNorm dropout -&gt; layerNorm
</span><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#saLayerNorm"><span class="hs-identifier hs-var hs-var">saLayerNorm</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679806636"><span class="hs-identifier hs-type">layerNorm</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-90"></span><span>      </span><span class="hs-comment">-- | dropout</span><span>
</span><span id="line-91"></span><span>      </span><span id="saDropout"><span class="annot"><span class="annottext">GSelfAttention mha layerNorm dropout -&gt; dropout
</span><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#saDropout"><span class="hs-identifier hs-var hs-var">saDropout</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679806635"><span class="hs-identifier hs-type">dropout</span></a></span><span>
</span><span id="line-92"></span><span>    </span><span class="hs-special">}</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-93"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#GSelfAttention"><span class="hs-identifier hs-type">GSelfAttention</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806637"><span class="hs-identifier hs-type">mha</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806636"><span class="hs-identifier hs-type">layerNorm</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806635"><span class="hs-identifier hs-type">dropout</span></a></span><span>
</span><span id="line-94"></span><span>
</span><span id="line-95"></span><span class="hs-comment">-- | Self-attention layer.</span><span>
</span><span id="line-96"></span><span class="hs-keyword">newtype</span><span>
</span><span id="line-97"></span><span>  </span><span id="SelfAttention"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#SelfAttention"><span class="hs-identifier hs-var">SelfAttention</span></a></span></span><span>
</span><span id="line-98"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679806296"><span class="annot"><a href="#local-6989586621679806296"><span class="hs-identifier hs-type">style</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerStyle"><span class="hs-identifier hs-type">TransformerStyle</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-99"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679806295"><span class="annot"><a href="#local-6989586621679806295"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#RequiresGradient"><span class="hs-identifier hs-type">RequiresGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-100"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679806294"><span class="annot"><a href="#local-6989586621679806294"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier hs-type">Device</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#DeviceType"><span class="hs-identifier hs-type">DeviceType</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-101"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679806293"><span class="annot"><a href="#local-6989586621679806293"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier hs-type">DType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-102"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679806292"><span class="annot"><a href="#local-6989586621679806292"><span class="hs-identifier hs-type">headDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-103"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679806291"><span class="annot"><a href="#local-6989586621679806291"><span class="hs-identifier hs-type">headEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-104"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679806290"><span class="annot"><a href="#local-6989586621679806290"><span class="hs-identifier hs-type">embedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-105"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679806289"><span class="annot"><a href="#local-6989586621679806289"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-106"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-107"></span><span>  </span><span id="SelfAttention"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#SelfAttention"><span class="hs-identifier hs-var">SelfAttention</span></a></span></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-108"></span><span>    </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679806605"><span class="annot"><a href="#local-6989586621679806605"><span class="hs-identifier hs-type">style</span></a></span></span><span> </span><span id="local-6989586621679806604"><span class="annot"><a href="#local-6989586621679806604"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679806603"><span class="annot"><a href="#local-6989586621679806603"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679806602"><span class="annot"><a href="#local-6989586621679806602"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679806601"><span class="annot"><a href="#local-6989586621679806601"><span class="hs-identifier hs-type">headDim</span></a></span></span><span> </span><span id="local-6989586621679806600"><span class="annot"><a href="#local-6989586621679806600"><span class="hs-identifier hs-type">headEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679806599"><span class="annot"><a href="#local-6989586621679806599"><span class="hs-identifier hs-type">embedDim</span></a></span></span><span> </span><span id="local-6989586621679806598"><span class="annot"><a href="#local-6989586621679806598"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-109"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#GSelfAttention"><span class="hs-identifier hs-type">GSelfAttention</span></a></span><span>
</span><span id="line-110"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#SAMultiheadAttentionF"><span class="hs-identifier hs-type">SAMultiheadAttentionF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806605"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806604"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806603"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806602"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806601"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806600"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806599"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806598"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-111"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#SALayerNormF"><span class="hs-identifier hs-type">SALayerNormF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806605"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806604"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806603"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806602"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806598"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-112"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#SADropoutF"><span class="hs-identifier hs-type">SADropoutF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806605"><span class="hs-identifier hs-type">style</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-113"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#SelfAttention"><span class="hs-identifier hs-type">SelfAttention</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806605"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806604"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806603"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806602"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806601"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806600"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806599"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806598"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span>
</span><span id="line-114"></span><span>
</span><span id="line-115"></span><span class="hs-keyword">data</span><span>
</span><span id="line-116"></span><span>  </span><span id="SelfAttentionSpec"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#SelfAttentionSpec"><span class="hs-identifier hs-var">SelfAttentionSpec</span></a></span></span><span>
</span><span id="line-117"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679806287"><span class="annot"><a href="#local-6989586621679806287"><span class="hs-identifier hs-type">style</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerStyle"><span class="hs-identifier hs-type">TransformerStyle</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-118"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679806286"><span class="annot"><a href="#local-6989586621679806286"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#RequiresGradient"><span class="hs-identifier hs-type">RequiresGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-119"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679806285"><span class="annot"><a href="#local-6989586621679806285"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier hs-type">Device</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#DeviceType"><span class="hs-identifier hs-type">DeviceType</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-120"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679806284"><span class="annot"><a href="#local-6989586621679806284"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier hs-type">DType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-121"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679806283"><span class="annot"><a href="#local-6989586621679806283"><span class="hs-identifier hs-type">headDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-122"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679806282"><span class="annot"><a href="#local-6989586621679806282"><span class="hs-identifier hs-type">headEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-123"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679806281"><span class="annot"><a href="#local-6989586621679806281"><span class="hs-identifier hs-type">embedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-124"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679806280"><span class="annot"><a href="#local-6989586621679806280"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-125"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-126"></span><span>  </span><span id="SelfAttentionSpec"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#SelfAttentionSpec"><span class="hs-identifier hs-var">SelfAttentionSpec</span></a></span></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-127"></span><span>    </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679806483"><span class="annot"><a href="#local-6989586621679806483"><span class="hs-identifier hs-type">style</span></a></span></span><span> </span><span id="local-6989586621679806482"><span class="annot"><a href="#local-6989586621679806482"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679806481"><span class="annot"><a href="#local-6989586621679806481"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679806480"><span class="annot"><a href="#local-6989586621679806480"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679806479"><span class="annot"><a href="#local-6989586621679806479"><span class="hs-identifier hs-type">headDim</span></a></span></span><span> </span><span id="local-6989586621679806478"><span class="annot"><a href="#local-6989586621679806478"><span class="hs-identifier hs-type">headEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679806477"><span class="annot"><a href="#local-6989586621679806477"><span class="hs-identifier hs-type">embedDim</span></a></span></span><span> </span><span id="local-6989586621679806476"><span class="annot"><a href="#local-6989586621679806476"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-128"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#STransformerStyle"><span class="hs-identifier hs-type">STransformerStyle</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806483"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-129"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier hs-type">SGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806482"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-130"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#SDevice"><span class="hs-identifier hs-type">SDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806481"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-131"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier hs-type">SDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806480"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-132"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806479"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-133"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806478"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-134"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806477"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-135"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806476"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-136"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-137"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-138"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#SelfAttentionSpec"><span class="hs-identifier hs-type">SelfAttentionSpec</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806483"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806482"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806481"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806480"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806479"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806478"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806477"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806476"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span>
</span><span id="line-139"></span><span>
</span><span id="line-140"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">instance</span><span> </span><span id="ModelSpec"><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier hs-var">ModelSpec</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#SelfAttention"><span class="hs-identifier hs-type">SelfAttention</span></a></span><span> </span><span id="local-6989586621679806278"><span class="annot"><a href="#local-6989586621679806278"><span class="hs-identifier hs-type hs-type">style</span></a></span></span><span> </span><span id="local-6989586621679806277"><span class="annot"><a href="#local-6989586621679806277"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679806276"><span class="annot"><a href="#local-6989586621679806276"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679806275"><span class="annot"><a href="#local-6989586621679806275"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679806274"><span class="annot"><a href="#local-6989586621679806274"><span class="hs-identifier hs-type hs-type">headDim</span></a></span></span><span> </span><span id="local-6989586621679806273"><span class="annot"><a href="#local-6989586621679806273"><span class="hs-identifier hs-type hs-type">headEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679806272"><span class="annot"><a href="#local-6989586621679806272"><span class="hs-identifier hs-type hs-type">embedDim</span></a></span></span><span> </span><span id="local-6989586621679806271"><span class="annot"><a href="#local-6989586621679806271"><span class="hs-identifier hs-type hs-type">queryEmbedDim</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#SelfAttentionSpec"><span class="hs-identifier hs-type">SelfAttentionSpec</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806278"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806277"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806276"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806275"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806274"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806273"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806272"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806271"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span>
</span><span id="line-141"></span><span>
</span><span id="line-142"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span>
</span><span id="line-143"></span><span>  </span><span id="SAMultiheadAttentionF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#SAMultiheadAttentionF"><span class="hs-identifier hs-var">SAMultiheadAttentionF</span></a></span></span><span>
</span><span id="line-144"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679806270"><span class="annot"><a href="#local-6989586621679806270"><span class="hs-identifier hs-type">style</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerStyle"><span class="hs-identifier hs-type">TransformerStyle</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-145"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679806269"><span class="annot"><a href="#local-6989586621679806269"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#RequiresGradient"><span class="hs-identifier hs-type">RequiresGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-146"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679806268"><span class="annot"><a href="#local-6989586621679806268"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier hs-type">Device</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#DeviceType"><span class="hs-identifier hs-type">DeviceType</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-147"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679806267"><span class="annot"><a href="#local-6989586621679806267"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier hs-type">DType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-148"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679806266"><span class="annot"><a href="#local-6989586621679806266"><span class="hs-identifier hs-type">headDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-149"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679806265"><span class="annot"><a href="#local-6989586621679806265"><span class="hs-identifier hs-type">headEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-150"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679806264"><span class="annot"><a href="#local-6989586621679806264"><span class="hs-identifier hs-type">embedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-151"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679806263"><span class="annot"><a href="#local-6989586621679806263"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-152"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span>
</span><span id="line-153"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-154"></span><span>  </span><span id="SAMultiheadAttentionF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#SAMultiheadAttentionF"><span class="hs-identifier hs-var">SAMultiheadAttentionF</span></a></span></span><span> </span><span id="local-6989586621679806262"><span class="annot"><a href="#local-6989586621679806262"><span class="hs-identifier hs-type hs-type">style</span></a></span></span><span> </span><span id="local-6989586621679806261"><span class="annot"><a href="#local-6989586621679806261"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679806260"><span class="annot"><a href="#local-6989586621679806260"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679806259"><span class="annot"><a href="#local-6989586621679806259"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679806258"><span class="annot"><a href="#local-6989586621679806258"><span class="hs-identifier hs-type hs-type">headDim</span></a></span></span><span> </span><span id="local-6989586621679806257"><span class="annot"><a href="#local-6989586621679806257"><span class="hs-identifier hs-type hs-type">headEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679806256"><span class="annot"><a href="#local-6989586621679806256"><span class="hs-identifier hs-type hs-type">embedDim</span></a></span></span><span> </span><span id="local-6989586621679806255"><span class="annot"><a href="#local-6989586621679806255"><span class="hs-identifier hs-type hs-type">queryEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-155"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.MultiHeadAttention.html#MultiHeadAttention"><span class="hs-identifier hs-type">MultiHeadAttention</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806262"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806261"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806260"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806259"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806258"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806257"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806256"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806255"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806255"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806255"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span>
</span><span id="line-156"></span><span>
</span><span id="line-157"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span>
</span><span id="line-158"></span><span>  </span><span id="SALayerNormF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#SALayerNormF"><span class="hs-identifier hs-var">SALayerNormF</span></a></span></span><span>
</span><span id="line-159"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679806254"><span class="annot"><a href="#local-6989586621679806254"><span class="hs-identifier hs-type">style</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerStyle"><span class="hs-identifier hs-type">TransformerStyle</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-160"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679806253"><span class="annot"><a href="#local-6989586621679806253"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#RequiresGradient"><span class="hs-identifier hs-type">RequiresGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-161"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679806252"><span class="annot"><a href="#local-6989586621679806252"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier hs-type">Device</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#DeviceType"><span class="hs-identifier hs-type">DeviceType</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-162"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679806251"><span class="annot"><a href="#local-6989586621679806251"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier hs-type">DType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-163"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679806250"><span class="annot"><a href="#local-6989586621679806250"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-164"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span>
</span><span id="line-165"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-166"></span><span>  </span><span id="SALayerNormF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#SALayerNormF"><span class="hs-identifier hs-var">SALayerNormF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#T5"><span class="hs-identifier hs-type">T5</span></a></span><span> </span><span id="local-6989586621679806249"><span class="annot"><a href="#local-6989586621679806249"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679806248"><span class="annot"><a href="#local-6989586621679806248"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679806247"><span class="annot"><a href="#local-6989586621679806247"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679806246"><span class="annot"><a href="#local-6989586621679806246"><span class="hs-identifier hs-type hs-type">queryEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Normalization.html#LayerNorm"><span class="hs-identifier hs-type">LayerNorm</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Type.html#WithoutBias"><span class="hs-identifier hs-type">WithoutBias</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806249"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806248"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806247"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679806246"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-167"></span><span>  </span><span id="SALayerNormF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#SALayerNormF"><span class="hs-identifier hs-var">SALayerNormF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ByT5"><span class="hs-identifier hs-type">ByT5</span></a></span><span> </span><span id="local-6989586621679806245"><span class="annot"><a href="#local-6989586621679806245"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679806244"><span class="annot"><a href="#local-6989586621679806244"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679806243"><span class="annot"><a href="#local-6989586621679806243"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679806242"><span class="annot"><a href="#local-6989586621679806242"><span class="hs-identifier hs-type hs-type">queryEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#SALayerNormF"><span class="hs-identifier hs-type">SALayerNormF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#T5"><span class="hs-identifier hs-type">T5</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806245"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806244"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806243"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806242"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span>
</span><span id="line-168"></span><span>  </span><span id="SALayerNormF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#SALayerNormF"><span class="hs-identifier hs-var">SALayerNormF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span> </span><span id="local-6989586621679806241"><span class="annot"><a href="#local-6989586621679806241"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679806240"><span class="annot"><a href="#local-6989586621679806240"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679806239"><span class="annot"><a href="#local-6989586621679806239"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679806238"><span class="annot"><a href="#local-6989586621679806238"><span class="hs-identifier hs-type hs-type">queryEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Normalization.html#LayerNorm"><span class="hs-identifier hs-type">LayerNorm</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Type.html#WithBias"><span class="hs-identifier hs-type">WithBias</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806241"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806240"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806239"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679806238"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-169"></span><span>  </span><span id="SALayerNormF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#SALayerNormF"><span class="hs-identifier hs-var">SALayerNormF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MBART"><span class="hs-identifier hs-type">MBART</span></a></span><span> </span><span id="local-6989586621679806237"><span class="annot"><a href="#local-6989586621679806237"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679806236"><span class="annot"><a href="#local-6989586621679806236"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679806235"><span class="annot"><a href="#local-6989586621679806235"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679806234"><span class="annot"><a href="#local-6989586621679806234"><span class="hs-identifier hs-type hs-type">queryEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#SALayerNormF"><span class="hs-identifier hs-type">SALayerNormF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806237"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806236"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806235"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806234"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span>
</span><span id="line-170"></span><span>  </span><span id="SALayerNormF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#SALayerNormF"><span class="hs-identifier hs-var">SALayerNormF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#Pegasus"><span class="hs-identifier hs-type">Pegasus</span></a></span><span> </span><span id="local-6989586621679806233"><span class="annot"><a href="#local-6989586621679806233"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679806232"><span class="annot"><a href="#local-6989586621679806232"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679806231"><span class="annot"><a href="#local-6989586621679806231"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679806230"><span class="annot"><a href="#local-6989586621679806230"><span class="hs-identifier hs-type hs-type">queryEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#SALayerNormF"><span class="hs-identifier hs-type">SALayerNormF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806233"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806232"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806231"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806230"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span>
</span><span id="line-171"></span><span>  </span><span id="SALayerNormF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#SALayerNormF"><span class="hs-identifier hs-var">SALayerNormF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BERT"><span class="hs-identifier hs-type">BERT</span></a></span><span> </span><span id="local-6989586621679806229"><span class="annot"><a href="#local-6989586621679806229"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679806228"><span class="annot"><a href="#local-6989586621679806228"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679806227"><span class="annot"><a href="#local-6989586621679806227"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679806226"><span class="annot"><a href="#local-6989586621679806226"><span class="hs-identifier hs-type hs-type">queryEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Normalization.html#LayerNorm"><span class="hs-identifier hs-type">LayerNorm</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Type.html#WithBias"><span class="hs-identifier hs-type">WithBias</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806229"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806228"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806227"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679806226"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-172"></span><span>  </span><span id="SALayerNormF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#SALayerNormF"><span class="hs-identifier hs-var">SALayerNormF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#RoBERTa"><span class="hs-identifier hs-type">RoBERTa</span></a></span><span> </span><span id="local-6989586621679806225"><span class="annot"><a href="#local-6989586621679806225"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679806224"><span class="annot"><a href="#local-6989586621679806224"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679806223"><span class="annot"><a href="#local-6989586621679806223"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679806222"><span class="annot"><a href="#local-6989586621679806222"><span class="hs-identifier hs-type hs-type">queryEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#SALayerNormF"><span class="hs-identifier hs-type">SALayerNormF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BERT"><span class="hs-identifier hs-type">BERT</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806225"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806224"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806223"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806222"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span>
</span><span id="line-173"></span><span>
</span><span id="line-174"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span>
</span><span id="line-175"></span><span>  </span><span id="SADropoutF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#SADropoutF"><span class="hs-identifier hs-var">SADropoutF</span></a></span></span><span>
</span><span id="line-176"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679806221"><span class="annot"><a href="#local-6989586621679806221"><span class="hs-identifier hs-type">style</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerStyle"><span class="hs-identifier hs-type">TransformerStyle</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-177"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span>
</span><span id="line-178"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-179"></span><span>  </span><span id="SADropoutF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#SADropoutF"><span class="hs-identifier hs-var">SADropoutF</span></a></span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Dropout.html#Dropout"><span class="hs-identifier hs-type">Dropout</span></a></span><span>
</span><span id="line-180"></span><span>
</span><span id="line-181"></span><span id="local-6989586621679806209"><span id="local-6989586621679806210"><span id="local-6989586621679806211"><span id="local-6989586621679806212"><span id="local-6989586621679806213"><span id="local-6989586621679806214"><span id="local-6989586621679806215"><span id="local-6989586621679806216"><span id="local-6989586621679806217"><span id="local-6989586621679806218"><span id="local-6989586621679806219"><span id="local-6989586621679806220"><span class="hs-keyword">instance</span><span>
</span><span id="line-182"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="#local-6989586621679806220"><span class="hs-identifier hs-type">multiHeadAttention</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#SAMultiheadAttentionF"><span class="hs-identifier hs-type">SAMultiheadAttentionF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806219"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806218"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806217"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806216"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806215"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806214"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806213"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806212"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-183"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806220"><span class="hs-identifier hs-type">multiHeadAttention</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806217"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806220"><span class="hs-identifier hs-type">multiHeadAttention</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806217"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-184"></span><span>    </span><span class="annot"><a href="#local-6989586621679806211"><span class="hs-identifier hs-type">layerNorm</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#SALayerNormF"><span class="hs-identifier hs-type">SALayerNormF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806219"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806218"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806217"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806216"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806212"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-185"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806211"><span class="hs-identifier hs-type">layerNorm</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806217"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806211"><span class="hs-identifier hs-type">layerNorm</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806217"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-186"></span><span>    </span><span class="annot"><a href="#local-6989586621679806210"><span class="hs-identifier hs-type">dropout</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#SADropoutF"><span class="hs-identifier hs-type">SADropoutF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806219"><span class="hs-identifier hs-type">style</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-187"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806210"><span class="hs-identifier hs-type">dropout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806217"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806210"><span class="hs-identifier hs-type">dropout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806217"><span class="hs-identifier hs-type">device</span></a></span><span>
</span><span id="line-188"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-189"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span>
</span><span id="line-190"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#SelfAttention"><span class="hs-identifier hs-type">SelfAttention</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806219"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806218"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806217"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806216"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806215"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806214"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806213"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806212"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-191"></span><span>    </span><span class="annot"><a href="#local-6989586621679806209"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-192"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#SelfAttention"><span class="hs-identifier hs-type">SelfAttention</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806219"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806218"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806217"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806216"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806215"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806214"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806213"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806212"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-193"></span><span>    </span><span class="annot"><a href="#local-6989586621679806217"><span class="hs-identifier hs-type">device</span></a></span><span>
</span><span id="line-194"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-195"></span><span>  </span><span id="local-6989586621679806206"><span class="annot"><span class="annottext">initialize :: ModelSpec
  (SelfAttention
     style
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim)
-&gt; Generator generatorDevice
-&gt; m (SelfAttention
        style
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        queryEmbedDim,
      Generator device)
</span><a href="Torch.GraduallyTyped.NN.Class.html#initialize"><span class="hs-identifier hs-var hs-var hs-var hs-var">initialize</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#SelfAttentionSpec"><span class="hs-identifier hs-type">SelfAttentionSpec</span></a></span><span> </span><span id="local-6989586621679806204"><span class="annot"><a href="#local-6989586621679806204"><span class="hs-identifier hs-var">style</span></a></span></span><span> </span><span id="local-6989586621679806203"><span class="annot"><a href="#local-6989586621679806203"><span class="hs-identifier hs-var">gradient</span></a></span></span><span> </span><span id="local-6989586621679806202"><span class="annot"><a href="#local-6989586621679806202"><span class="hs-identifier hs-var">device</span></a></span></span><span> </span><span id="local-6989586621679806201"><span class="annot"><a href="#local-6989586621679806201"><span class="hs-identifier hs-var">dataType</span></a></span></span><span> </span><span id="local-6989586621679806200"><span class="annot"><a href="#local-6989586621679806200"><span class="hs-identifier hs-var">headDim</span></a></span></span><span> </span><span id="local-6989586621679806199"><span class="annot"><a href="#local-6989586621679806199"><span class="hs-identifier hs-var">headEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679806198"><span class="annot"><a href="#local-6989586621679806198"><span class="hs-identifier hs-var">embedDim</span></a></span></span><span> </span><span id="local-6989586621679806197"><span class="annot"><a href="#local-6989586621679806197"><span class="hs-identifier hs-var">queryEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679806196"><span class="annot"><a href="#local-6989586621679806196"><span class="hs-identifier hs-var">dropoutP</span></a></span></span><span> </span><span id="local-6989586621679806195"><span class="annot"><a href="#local-6989586621679806195"><span class="hs-identifier hs-var">eps</span></a></span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679806194"><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679806194"><span class="hs-identifier hs-var">generator</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-196"></span><span>    </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679806193"><span class="annot"><span class="annottext">generator' :: Generator device
</span><a href="#local-6989586621679806193"><span class="hs-identifier hs-var hs-var">generator'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SDevice device -&gt; Generator generatorDevice -&gt; Generator device
forall (generatorDevice' :: Device (DeviceType Nat))
       (generatorDevice :: Device (DeviceType Nat)).
SDevice generatorDevice'
-&gt; Generator generatorDevice -&gt; Generator generatorDevice'
</span><a href="Torch.GraduallyTyped.Random.html#sGeneratorToDevice"><span class="hs-identifier hs-var">sGeneratorToDevice</span></a></span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679806202"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679806194"><span class="hs-identifier hs-var">generator</span></a></span><span>
</span><span id="line-197"></span><span>        </span><span id="local-6989586621679806192"><span class="annot"><span class="annottext">multiHeadAttention :: IxStateT
  m
  (Generator device)
  (Generator device)
  (MultiHeadAttention
     style
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     queryEmbedDim
     queryEmbedDim)
</span><a href="#local-6989586621679806192"><span class="hs-identifier hs-var hs-var">multiHeadAttention</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(Generator device
 -&gt; m (MultiHeadAttention
         style
         gradient
         device
         dataType
         headDim
         headEmbedDim
         embedDim
         queryEmbedDim
         queryEmbedDim
         queryEmbedDim,
       Generator device))
-&gt; IxStateT
     m
     (Generator device)
     (Generator device)
     (MultiHeadAttention
        style
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        queryEmbedDim
        queryEmbedDim
        queryEmbedDim)
forall (m :: Type -&gt; Type) i j a.
(i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator device
  -&gt; m (MultiHeadAttention
          style
          gradient
          device
          dataType
          headDim
          headEmbedDim
          embedDim
          queryEmbedDim
          queryEmbedDim
          queryEmbedDim,
        Generator device))
 -&gt; IxStateT
      m
      (Generator device)
      (Generator device)
      (MultiHeadAttention
         style
         gradient
         device
         dataType
         headDim
         headEmbedDim
         embedDim
         queryEmbedDim
         queryEmbedDim
         queryEmbedDim))
-&gt; (MultiHeadAttentionSpec
      style
      gradient
      device
      dataType
      headDim
      headEmbedDim
      embedDim
      queryEmbedDim
      queryEmbedDim
      queryEmbedDim
    -&gt; Generator device
    -&gt; m (MultiHeadAttention
            style
            gradient
            device
            dataType
            headDim
            headEmbedDim
            embedDim
            queryEmbedDim
            queryEmbedDim
            queryEmbedDim,
          Generator device))
-&gt; MultiHeadAttentionSpec
     style
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     queryEmbedDim
     queryEmbedDim
-&gt; IxStateT
     m
     (Generator device)
     (Generator device)
     (MultiHeadAttention
        style
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        queryEmbedDim
        queryEmbedDim
        queryEmbedDim)
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">forall model (generatorDevice :: Device (DeviceType Nat)) output
       (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: Type -&gt; Type).
(HasInitialize model generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
ModelSpec model
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
forall (generatorDevice :: Device (DeviceType Nat)) output
       (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: Type -&gt; Type).
(HasInitialize
   multiHeadAttention generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
ModelSpec multiHeadAttention
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#initialize"><span class="hs-identifier hs-var">initialize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679806220"><span class="hs-identifier hs-type">multiHeadAttention</span></a></span><span> </span><span class="annot"><span class="annottext">(MultiHeadAttentionSpec
   style
   gradient
   device
   dataType
   headDim
   headEmbedDim
   embedDim
   queryEmbedDim
   queryEmbedDim
   queryEmbedDim
 -&gt; IxStateT
      m
      (Generator device)
      (Generator device)
      (MultiHeadAttention
         style
         gradient
         device
         dataType
         headDim
         headEmbedDim
         embedDim
         queryEmbedDim
         queryEmbedDim
         queryEmbedDim))
-&gt; MultiHeadAttentionSpec
     style
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     queryEmbedDim
     queryEmbedDim
-&gt; IxStateT
     m
     (Generator device)
     (Generator device)
     (MultiHeadAttention
        style
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        queryEmbedDim
        queryEmbedDim
        queryEmbedDim)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim headDim
-&gt; SDim headEmbedDim
-&gt; SDim embedDim
-&gt; SDim queryEmbedDim
-&gt; SDim queryEmbedDim
-&gt; SDim queryEmbedDim
-&gt; Double
-&gt; MultiHeadAttentionSpec
     style
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     queryEmbedDim
     queryEmbedDim
forall (style :: TransformerStyle)
       (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (headDim :: Dim (Name Symbol) (Size Nat))
       (headEmbedDim :: Dim (Name Symbol) (Size Nat))
       (embedDim :: Dim (Name Symbol) (Size Nat))
       (queryEmbedDim :: Dim (Name Symbol) (Size Nat))
       (keyEmbedDim :: Dim (Name Symbol) (Size Nat))
       (valueEmbedDim :: Dim (Name Symbol) (Size Nat)).
STransformerStyle style
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim headDim
-&gt; SDim headEmbedDim
-&gt; SDim embedDim
-&gt; SDim queryEmbedDim
-&gt; SDim keyEmbedDim
-&gt; SDim valueEmbedDim
-&gt; Double
-&gt; MultiHeadAttentionSpec
     style
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     keyEmbedDim
     valueEmbedDim
</span><a href="Torch.GraduallyTyped.NN.Transformer.MultiHeadAttention.html#MultiHeadAttentionSpec"><span class="hs-identifier hs-var">MultiHeadAttentionSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="#local-6989586621679806204"><span class="hs-identifier hs-var">style</span></a></span><span> </span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679806203"><span class="hs-identifier hs-var">gradient</span></a></span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679806202"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679806201"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="annot"><span class="annottext">SDim headDim
</span><a href="#local-6989586621679806200"><span class="hs-identifier hs-var">headDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim headEmbedDim
</span><a href="#local-6989586621679806199"><span class="hs-identifier hs-var">headEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim embedDim
</span><a href="#local-6989586621679806198"><span class="hs-identifier hs-var">embedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim queryEmbedDim
</span><a href="#local-6989586621679806197"><span class="hs-identifier hs-var">queryEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim queryEmbedDim
</span><a href="#local-6989586621679806197"><span class="hs-identifier hs-var">queryEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim queryEmbedDim
</span><a href="#local-6989586621679806197"><span class="hs-identifier hs-var">queryEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679806196"><span class="hs-identifier hs-var">dropoutP</span></a></span><span>
</span><span id="line-198"></span><span>        </span><span id="local-6989586621679806189"><span class="annot"><span class="annottext">layerNormWithoutBiasSpec :: LayerNormSpec
  'WithoutBias gradient device dataType ('Shape '[queryEmbedDim])
</span><a href="#local-6989586621679806189"><span class="hs-identifier hs-var hs-var">layerNormWithoutBiasSpec</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SHasBias 'WithoutBias
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SShape ('Shape '[queryEmbedDim])
-&gt; Double
-&gt; LayerNormSpec
     'WithoutBias gradient device dataType ('Shape '[queryEmbedDim])
forall (hasBias :: HasBias) (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (normalizedShape :: Shape [Dim (Name Symbol) (Size Nat)]).
SHasBias hasBias
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SShape normalizedShape
-&gt; Double
-&gt; LayerNormSpec hasBias gradient device dataType normalizedShape
</span><a href="Torch.GraduallyTyped.NN.Normalization.html#LayerNormSpec"><span class="hs-identifier hs-var">LayerNormSpec</span></a></span><span> </span><span class="annot"><span class="annottext">SHasBias 'WithoutBias
</span><a href="Torch.GraduallyTyped.NN.Type.html#SWithoutBias"><span class="hs-identifier hs-var">SWithoutBias</span></a></span><span> </span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679806203"><span class="hs-identifier hs-var">gradient</span></a></span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679806202"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679806201"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SList '[queryEmbedDim] -&gt; SShape ('Shape '[queryEmbedDim])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList '[queryEmbedDim] -&gt; SShape ('Shape '[queryEmbedDim]))
-&gt; SList '[queryEmbedDim] -&gt; SShape ('Shape '[queryEmbedDim])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SDim queryEmbedDim
</span><a href="#local-6989586621679806197"><span class="hs-identifier hs-var">queryEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim queryEmbedDim -&gt; SList '[] -&gt; SList '[queryEmbedDim]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679806195"><span class="hs-identifier hs-var">eps</span></a></span><span>
</span><span id="line-199"></span><span>        </span><span id="local-6989586621679806185"><span class="annot"><span class="annottext">layerNormWithBiasSpec :: LayerNormSpec
  'WithBias gradient device dataType ('Shape '[queryEmbedDim])
</span><a href="#local-6989586621679806185"><span class="hs-identifier hs-var hs-var">layerNormWithBiasSpec</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SHasBias 'WithBias
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SShape ('Shape '[queryEmbedDim])
-&gt; Double
-&gt; LayerNormSpec
     'WithBias gradient device dataType ('Shape '[queryEmbedDim])
forall (hasBias :: HasBias) (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (normalizedShape :: Shape [Dim (Name Symbol) (Size Nat)]).
SHasBias hasBias
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SShape normalizedShape
-&gt; Double
-&gt; LayerNormSpec hasBias gradient device dataType normalizedShape
</span><a href="Torch.GraduallyTyped.NN.Normalization.html#LayerNormSpec"><span class="hs-identifier hs-var">LayerNormSpec</span></a></span><span> </span><span class="annot"><span class="annottext">SHasBias 'WithBias
</span><a href="Torch.GraduallyTyped.NN.Type.html#SWithBias"><span class="hs-identifier hs-var">SWithBias</span></a></span><span> </span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679806203"><span class="hs-identifier hs-var">gradient</span></a></span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679806202"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679806201"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SList '[queryEmbedDim] -&gt; SShape ('Shape '[queryEmbedDim])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList '[queryEmbedDim] -&gt; SShape ('Shape '[queryEmbedDim]))
-&gt; SList '[queryEmbedDim] -&gt; SShape ('Shape '[queryEmbedDim])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SDim queryEmbedDim
</span><a href="#local-6989586621679806197"><span class="hs-identifier hs-var">queryEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim queryEmbedDim -&gt; SList '[] -&gt; SList '[queryEmbedDim]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679806195"><span class="hs-identifier hs-var">eps</span></a></span><span>
</span><span id="line-200"></span><span>        </span><span id="local-6989586621679806183"><span class="annot"><span class="annottext">layerNorm :: IxStateT m (Generator device) (Generator device) layerNorm
</span><a href="#local-6989586621679806183"><span class="hs-identifier hs-var hs-var">layerNorm</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(Generator device -&gt; m (layerNorm, Generator device))
-&gt; IxStateT m (Generator device) (Generator device) layerNorm
forall (m :: Type -&gt; Type) i j a.
(i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator device -&gt; m (layerNorm, Generator device))
 -&gt; IxStateT m (Generator device) (Generator device) layerNorm)
-&gt; (ModelSpec layerNorm
    -&gt; Generator device -&gt; m (layerNorm, Generator device))
-&gt; ModelSpec layerNorm
-&gt; IxStateT m (Generator device) (Generator device) layerNorm
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">forall model (generatorDevice :: Device (DeviceType Nat)) output
       (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: Type -&gt; Type).
(HasInitialize model generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
ModelSpec model
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
forall (generatorDevice :: Device (DeviceType Nat)) output
       (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: Type -&gt; Type).
(HasInitialize
   layerNorm generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
ModelSpec layerNorm
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#initialize"><span class="hs-identifier hs-var">initialize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679806211"><span class="hs-identifier hs-type">layerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">(ModelSpec layerNorm
 -&gt; IxStateT m (Generator device) (Generator device) layerNorm)
-&gt; ModelSpec layerNorm
-&gt; IxStateT m (Generator device) (Generator device) layerNorm
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-keyword">case</span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="#local-6989586621679806204"><span class="hs-identifier hs-var">style</span></a></span><span> </span><span class="hs-keyword">of</span><span>
</span><span id="line-201"></span><span>          </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">ModelSpec layerNorm
LayerNormSpec
  'WithoutBias gradient device dataType ('Shape '[queryEmbedDim])
</span><a href="#local-6989586621679806189"><span class="hs-identifier hs-var">layerNormWithoutBiasSpec</span></a></span><span>
</span><span id="line-202"></span><span>          </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">ModelSpec layerNorm
LayerNormSpec
  'WithoutBias gradient device dataType ('Shape '[queryEmbedDim])
</span><a href="#local-6989586621679806189"><span class="hs-identifier hs-var">layerNormWithoutBiasSpec</span></a></span><span>
</span><span id="line-203"></span><span>          </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">ModelSpec layerNorm
LayerNormSpec
  'WithBias gradient device dataType ('Shape '[queryEmbedDim])
</span><a href="#local-6989586621679806185"><span class="hs-identifier hs-var">layerNormWithBiasSpec</span></a></span><span>
</span><span id="line-204"></span><span>          </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">ModelSpec layerNorm
LayerNormSpec
  'WithBias gradient device dataType ('Shape '[queryEmbedDim])
</span><a href="#local-6989586621679806185"><span class="hs-identifier hs-var">layerNormWithBiasSpec</span></a></span><span>
</span><span id="line-205"></span><span>          </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">ModelSpec layerNorm
LayerNormSpec
  'WithBias gradient device dataType ('Shape '[queryEmbedDim])
</span><a href="#local-6989586621679806185"><span class="hs-identifier hs-var">layerNormWithBiasSpec</span></a></span><span>
</span><span id="line-206"></span><span>          </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">ModelSpec layerNorm
LayerNormSpec
  'WithBias gradient device dataType ('Shape '[queryEmbedDim])
</span><a href="#local-6989586621679806185"><span class="hs-identifier hs-var">layerNormWithBiasSpec</span></a></span><span>
</span><span id="line-207"></span><span>          </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">ModelSpec layerNorm
LayerNormSpec
  'WithBias gradient device dataType ('Shape '[queryEmbedDim])
</span><a href="#local-6989586621679806185"><span class="hs-identifier hs-var">layerNormWithBiasSpec</span></a></span><span>
</span><span id="line-208"></span><span>          </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SGPT2"><span class="hs-identifier hs-var">SGPT2</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">ModelSpec layerNorm
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-209"></span><span>        </span><span id="local-6989586621679806173"><span class="annot"><span class="annottext">dropout :: IxStateT m (Generator device) (Generator device) Dropout
</span><a href="#local-6989586621679806173"><span class="hs-identifier hs-var hs-var">dropout</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(Generator device -&gt; m (Dropout, Generator device))
-&gt; IxStateT m (Generator device) (Generator device) Dropout
forall (m :: Type -&gt; Type) i j a.
(i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator device -&gt; m (Dropout, Generator device))
 -&gt; IxStateT m (Generator device) (Generator device) Dropout)
-&gt; (Dropout -&gt; Generator device -&gt; m (Dropout, Generator device))
-&gt; Dropout
-&gt; IxStateT m (Generator device) (Generator device) Dropout
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">forall model (generatorDevice :: Device (DeviceType Nat)) output
       (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: Type -&gt; Type).
(HasInitialize model generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
ModelSpec model
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
forall (generatorDevice :: Device (DeviceType Nat)) output
       (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: Type -&gt; Type).
(HasInitialize
   dropout generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
ModelSpec dropout
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#initialize"><span class="hs-identifier hs-var">initialize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679806210"><span class="hs-identifier hs-type">dropout</span></a></span><span> </span><span class="annot"><span class="annottext">(Dropout
 -&gt; IxStateT m (Generator device) (Generator device) Dropout)
-&gt; Dropout
-&gt; IxStateT m (Generator device) (Generator device) Dropout
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">Double -&gt; Dropout
</span><a href="Torch.GraduallyTyped.NN.Dropout.html#Dropout"><span class="hs-identifier hs-var">Dropout</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679806196"><span class="hs-identifier hs-var">dropoutP</span></a></span><span>
</span><span id="line-210"></span><span>     </span><span class="hs-keyword">in</span><span> </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator device)
  (Generator device)
  (SelfAttention
     style
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim)
-&gt; Generator device
-&gt; m (SelfAttention
        style
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        queryEmbedDim,
      Generator device)
forall (m :: Type -&gt; Type) i j a. IxStateT m i j a -&gt; i -&gt; m (a, j)
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var hs-var">runIxStateT</span></a></span><span>
</span><span id="line-211"></span><span>          </span><span class="hs-special">(</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">MultiHeadAttention
  style
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  queryEmbedDim
  queryEmbedDim
  queryEmbedDim
-&gt; layerNorm
-&gt; Dropout
-&gt; GSelfAttention
     (MultiHeadAttention
        style
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        queryEmbedDim
        queryEmbedDim
        queryEmbedDim)
     layerNorm
     Dropout
forall mha layerNorm dropout.
mha -&gt; layerNorm -&gt; dropout -&gt; GSelfAttention mha layerNorm dropout
</span><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#GSelfAttention"><span class="hs-identifier hs-var">GSelfAttention</span></a></span><span> </span><span class="annot"><span class="annottext">(MultiHeadAttention
   style
   gradient
   device
   dataType
   headDim
   headEmbedDim
   embedDim
   queryEmbedDim
   queryEmbedDim
   queryEmbedDim
 -&gt; layerNorm
 -&gt; Dropout
 -&gt; GSelfAttention
      (MultiHeadAttention
         style
         gradient
         device
         dataType
         headDim
         headEmbedDim
         embedDim
         queryEmbedDim
         queryEmbedDim
         queryEmbedDim)
      layerNorm
      Dropout)
-&gt; IxStateT
     m
     (Generator device)
     (Generator device)
     (MultiHeadAttention
        style
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        queryEmbedDim
        queryEmbedDim
        queryEmbedDim)
-&gt; IxStateT
     m
     (Generator device)
     (Generator device)
     (layerNorm
      -&gt; Dropout
      -&gt; GSelfAttention
           (MultiHeadAttention
              style
              gradient
              device
              dataType
              headDim
              headEmbedDim
              embedDim
              queryEmbedDim
              queryEmbedDim
              queryEmbedDim)
           layerNorm
           Dropout)
forall k1 k2 (f :: k1 -&gt; k2 -&gt; Type -&gt; Type) a b (j :: k1)
       (k3 :: k2).
IxFunctor f =&gt;
(a -&gt; b) -&gt; f j k3 a -&gt; f j k3 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&lt;&lt;$&gt;&gt;</span></a></span><span> </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator device)
  (Generator device)
  (MultiHeadAttention
     style
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     queryEmbedDim
     queryEmbedDim)
</span><a href="#local-6989586621679806192"><span class="hs-identifier hs-var">multiHeadAttention</span></a></span><span> </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator device)
  (Generator device)
  (layerNorm
   -&gt; Dropout
   -&gt; GSelfAttention
        (MultiHeadAttention
           style
           gradient
           device
           dataType
           headDim
           headEmbedDim
           embedDim
           queryEmbedDim
           queryEmbedDim
           queryEmbedDim)
        layerNorm
        Dropout)
-&gt; IxStateT m (Generator device) (Generator device) layerNorm
-&gt; IxStateT
     m
     (Generator device)
     (Generator device)
     (Dropout
      -&gt; GSelfAttention
           (MultiHeadAttention
              style
              gradient
              device
              dataType
              headDim
              headEmbedDim
              embedDim
              queryEmbedDim
              queryEmbedDim
              queryEmbedDim)
           layerNorm
           Dropout)
forall k1 (f :: k1 -&gt; k1 -&gt; Type -&gt; Type) (i :: k1) (j :: k1) a b
       (k2 :: k1).
IxApplicative f =&gt;
f i j (a -&gt; b) -&gt; f j k2 a -&gt; f i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&lt;&lt;*&gt;&gt;</span></a></span><span> </span><span class="annot"><span class="annottext">IxStateT m (Generator device) (Generator device) layerNorm
</span><a href="#local-6989586621679806183"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator device)
  (Generator device)
  (Dropout
   -&gt; GSelfAttention
        (MultiHeadAttention
           style
           gradient
           device
           dataType
           headDim
           headEmbedDim
           embedDim
           queryEmbedDim
           queryEmbedDim
           queryEmbedDim)
        layerNorm
        Dropout)
-&gt; IxStateT m (Generator device) (Generator device) Dropout
-&gt; IxStateT
     m
     (Generator device)
     (Generator device)
     (GSelfAttention
        (MultiHeadAttention
           style
           gradient
           device
           dataType
           headDim
           headEmbedDim
           embedDim
           queryEmbedDim
           queryEmbedDim
           queryEmbedDim)
        layerNorm
        Dropout)
forall k1 (f :: k1 -&gt; k1 -&gt; Type -&gt; Type) (i :: k1) (j :: k1) a b
       (k2 :: k1).
IxApplicative f =&gt;
f i j (a -&gt; b) -&gt; f j k2 a -&gt; f i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&lt;&lt;*&gt;&gt;</span></a></span><span> </span><span class="annot"><span class="annottext">IxStateT m (Generator device) (Generator device) Dropout
</span><a href="#local-6989586621679806173"><span class="hs-identifier hs-var">dropout</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-212"></span><span>              </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator device)
  (Generator device)
  (GSelfAttention
     (MultiHeadAttention
        style
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        queryEmbedDim
        queryEmbedDim
        queryEmbedDim)
     layerNorm
     Dropout)
-&gt; (GSelfAttention
      (MultiHeadAttention
         style
         gradient
         device
         dataType
         headDim
         headEmbedDim
         embedDim
         queryEmbedDim
         queryEmbedDim
         queryEmbedDim)
      layerNorm
      Dropout
    -&gt; IxStateT
         m
         (Generator device)
         (Generator device)
         (SelfAttention
            style
            gradient
            device
            dataType
            headDim
            headEmbedDim
            embedDim
            queryEmbedDim))
-&gt; IxStateT
     m
     (Generator device)
     (Generator device)
     (SelfAttention
        style
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        queryEmbedDim)
forall k1 (m :: k1 -&gt; k1 -&gt; Type -&gt; Type) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">SelfAttention
  style
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  queryEmbedDim
-&gt; IxStateT
     m
     (Generator device)
     (Generator device)
     (SelfAttention
        style
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        queryEmbedDim)
forall k (m :: k -&gt; k -&gt; Type -&gt; Type) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">(SelfAttention
   style
   gradient
   device
   dataType
   headDim
   headEmbedDim
   embedDim
   queryEmbedDim
 -&gt; IxStateT
      m
      (Generator device)
      (Generator device)
      (SelfAttention
         style
         gradient
         device
         dataType
         headDim
         headEmbedDim
         embedDim
         queryEmbedDim))
-&gt; (GSelfAttention
      (MultiHeadAttention
         style
         gradient
         device
         dataType
         headDim
         headEmbedDim
         embedDim
         queryEmbedDim
         queryEmbedDim
         queryEmbedDim)
      layerNorm
      Dropout
    -&gt; SelfAttention
         style
         gradient
         device
         dataType
         headDim
         headEmbedDim
         embedDim
         queryEmbedDim)
-&gt; GSelfAttention
     (MultiHeadAttention
        style
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        queryEmbedDim
        queryEmbedDim
        queryEmbedDim)
     layerNorm
     Dropout
-&gt; IxStateT
     m
     (Generator device)
     (Generator device)
     (SelfAttention
        style
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        queryEmbedDim)
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">GSelfAttention
  (MultiHeadAttention
     style
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     queryEmbedDim
     queryEmbedDim)
  layerNorm
  Dropout
-&gt; SelfAttention
     style
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
forall (style :: TransformerStyle)
       (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (headDim :: Dim (Name Symbol) (Size Nat))
       (headEmbedDim :: Dim (Name Symbol) (Size Nat))
       (embedDim :: Dim (Name Symbol) (Size Nat))
       (queryEmbedDim :: Dim (Name Symbol) (Size Nat)).
GSelfAttention
  (SAMultiheadAttentionF
     style
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim)
  (SALayerNormF style gradient device dataType queryEmbedDim)
  (SADropoutF style)
-&gt; SelfAttention
     style
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
</span><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#SelfAttention"><span class="hs-identifier hs-var">SelfAttention</span></a></span><span>
</span><span id="line-213"></span><span>          </span><span class="hs-special">)</span><span>
</span><span id="line-214"></span><span>          </span><span class="annot"><span class="annottext">Generator device
</span><a href="#local-6989586621679806193"><span class="hs-identifier hs-var">generator'</span></a></span></span></span></span></span></span></span></span></span></span></span></span></span><span>
</span><span id="line-215"></span><span>
</span><span id="line-216"></span><span id="local-6989586621679806163"><span id="local-6989586621679806164"><span id="local-6989586621679806165"><span id="local-6989586621679806166"><span id="local-6989586621679806167"><span id="local-6989586621679806168"><span id="local-6989586621679806169"><span id="local-6989586621679806170"><span class="hs-keyword">instance</span><span>
</span><span id="line-217"></span><span>  </span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-type">SingI</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806170"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-218"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasStateDict"><span class="hs-identifier hs-type">HasStateDict</span></a></span><span>
</span><span id="line-219"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#SelfAttention"><span class="hs-identifier hs-type">SelfAttention</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806170"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806169"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806168"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806167"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806166"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806165"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806164"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806163"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-220"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-221"></span><span>  </span><span id="local-6989586621679806159"><span class="annot"><span class="annottext">fromStateDict :: ModelSpec
  (SelfAttention
     style
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim)
-&gt; StateDictKey
-&gt; m (SelfAttention
        style
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        queryEmbedDim)
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var hs-var hs-var hs-var">fromStateDict</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#SelfAttentionSpec"><span class="hs-identifier hs-type">SelfAttentionSpec</span></a></span><span> </span><span id="local-6989586621679806157"><span class="annot"><a href="#local-6989586621679806157"><span class="hs-identifier hs-var">style</span></a></span></span><span> </span><span id="local-6989586621679806156"><span class="annot"><a href="#local-6989586621679806156"><span class="hs-identifier hs-var">gradient</span></a></span></span><span> </span><span id="local-6989586621679806155"><span class="annot"><a href="#local-6989586621679806155"><span class="hs-identifier hs-var">device</span></a></span></span><span> </span><span id="local-6989586621679806154"><span class="annot"><a href="#local-6989586621679806154"><span class="hs-identifier hs-var">dataType</span></a></span></span><span> </span><span id="local-6989586621679806153"><span class="annot"><a href="#local-6989586621679806153"><span class="hs-identifier hs-var">headDim</span></a></span></span><span> </span><span id="local-6989586621679806152"><span class="annot"><a href="#local-6989586621679806152"><span class="hs-identifier hs-var">headEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679806151"><span class="annot"><a href="#local-6989586621679806151"><span class="hs-identifier hs-var">embedDim</span></a></span></span><span> </span><span id="local-6989586621679806150"><span class="annot"><a href="#local-6989586621679806150"><span class="hs-identifier hs-var">queryEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679806149"><span class="annot"><a href="#local-6989586621679806149"><span class="hs-identifier hs-var">dropoutP</span></a></span></span><span> </span><span id="local-6989586621679806148"><span class="annot"><a href="#local-6989586621679806148"><span class="hs-identifier hs-var">eps</span></a></span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679806147"><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679806147"><span class="hs-identifier hs-var">k</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-222"></span><span>    </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679806146"><span class="annot"><span class="annottext">multiHeadAttention :: STransformerStyle style
-&gt; m (MultiHeadAttention
        style
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        queryEmbedDim
        queryEmbedDim
        queryEmbedDim)
</span><a href="#local-6989586621679806146"><span class="hs-identifier hs-var hs-var">multiHeadAttention</span></a></span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (MultiHeadAttention
     'T5
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     queryEmbedDim
     queryEmbedDim)
-&gt; StateDictKey
-&gt; m (MultiHeadAttention
        'T5
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        queryEmbedDim
        queryEmbedDim
        queryEmbedDim)
forall model (m :: Type -&gt; Type).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
ModelSpec model -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">STransformerStyle 'T5
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim headDim
-&gt; SDim headEmbedDim
-&gt; SDim embedDim
-&gt; SDim queryEmbedDim
-&gt; SDim queryEmbedDim
-&gt; SDim queryEmbedDim
-&gt; Double
-&gt; MultiHeadAttentionSpec
     'T5
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     queryEmbedDim
     queryEmbedDim
forall (style :: TransformerStyle)
       (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (headDim :: Dim (Name Symbol) (Size Nat))
       (headEmbedDim :: Dim (Name Symbol) (Size Nat))
       (embedDim :: Dim (Name Symbol) (Size Nat))
       (queryEmbedDim :: Dim (Name Symbol) (Size Nat))
       (keyEmbedDim :: Dim (Name Symbol) (Size Nat))
       (valueEmbedDim :: Dim (Name Symbol) (Size Nat)).
STransformerStyle style
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim headDim
-&gt; SDim headEmbedDim
-&gt; SDim embedDim
-&gt; SDim queryEmbedDim
-&gt; SDim keyEmbedDim
-&gt; SDim valueEmbedDim
-&gt; Double
-&gt; MultiHeadAttentionSpec
     style
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     keyEmbedDim
     valueEmbedDim
</span><a href="Torch.GraduallyTyped.NN.Transformer.MultiHeadAttention.html#MultiHeadAttentionSpec"><span class="hs-identifier hs-var">MultiHeadAttentionSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle 'T5
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679806156"><span class="hs-identifier hs-var">gradient</span></a></span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679806155"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679806154"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="annot"><span class="annottext">SDim headDim
</span><a href="#local-6989586621679806153"><span class="hs-identifier hs-var">headDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim headEmbedDim
</span><a href="#local-6989586621679806152"><span class="hs-identifier hs-var">headEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim embedDim
</span><a href="#local-6989586621679806151"><span class="hs-identifier hs-var">embedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim queryEmbedDim
</span><a href="#local-6989586621679806150"><span class="hs-identifier hs-var">queryEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim queryEmbedDim
</span><a href="#local-6989586621679806150"><span class="hs-identifier hs-var">queryEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim queryEmbedDim
</span><a href="#local-6989586621679806150"><span class="hs-identifier hs-var">queryEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679806149"><span class="hs-identifier hs-var">dropoutP</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679806147"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;SelfAttention.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-223"></span><span>        </span><span class="annot"><a href="#local-6989586621679806146"><span class="hs-identifier hs-var">multiHeadAttention</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (MultiHeadAttention
     'ByT5
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     queryEmbedDim
     queryEmbedDim)
-&gt; StateDictKey
-&gt; m (MultiHeadAttention
        'ByT5
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        queryEmbedDim
        queryEmbedDim
        queryEmbedDim)
forall model (m :: Type -&gt; Type).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
ModelSpec model -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">STransformerStyle 'ByT5
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim headDim
-&gt; SDim headEmbedDim
-&gt; SDim embedDim
-&gt; SDim queryEmbedDim
-&gt; SDim queryEmbedDim
-&gt; SDim queryEmbedDim
-&gt; Double
-&gt; MultiHeadAttentionSpec
     'ByT5
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     queryEmbedDim
     queryEmbedDim
forall (style :: TransformerStyle)
       (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (headDim :: Dim (Name Symbol) (Size Nat))
       (headEmbedDim :: Dim (Name Symbol) (Size Nat))
       (embedDim :: Dim (Name Symbol) (Size Nat))
       (queryEmbedDim :: Dim (Name Symbol) (Size Nat))
       (keyEmbedDim :: Dim (Name Symbol) (Size Nat))
       (valueEmbedDim :: Dim (Name Symbol) (Size Nat)).
STransformerStyle style
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim headDim
-&gt; SDim headEmbedDim
-&gt; SDim embedDim
-&gt; SDim queryEmbedDim
-&gt; SDim keyEmbedDim
-&gt; SDim valueEmbedDim
-&gt; Double
-&gt; MultiHeadAttentionSpec
     style
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     keyEmbedDim
     valueEmbedDim
</span><a href="Torch.GraduallyTyped.NN.Transformer.MultiHeadAttention.html#MultiHeadAttentionSpec"><span class="hs-identifier hs-var">MultiHeadAttentionSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle 'ByT5
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span> </span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679806156"><span class="hs-identifier hs-var">gradient</span></a></span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679806155"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679806154"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="annot"><span class="annottext">SDim headDim
</span><a href="#local-6989586621679806153"><span class="hs-identifier hs-var">headDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim headEmbedDim
</span><a href="#local-6989586621679806152"><span class="hs-identifier hs-var">headEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim embedDim
</span><a href="#local-6989586621679806151"><span class="hs-identifier hs-var">embedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim queryEmbedDim
</span><a href="#local-6989586621679806150"><span class="hs-identifier hs-var">queryEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim queryEmbedDim
</span><a href="#local-6989586621679806150"><span class="hs-identifier hs-var">queryEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim queryEmbedDim
</span><a href="#local-6989586621679806150"><span class="hs-identifier hs-var">queryEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679806149"><span class="hs-identifier hs-var">dropoutP</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679806147"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;SelfAttention.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-224"></span><span>        </span><span class="annot"><a href="#local-6989586621679806146"><span class="hs-identifier hs-var">multiHeadAttention</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (MultiHeadAttention
     'BART
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     queryEmbedDim
     queryEmbedDim)
-&gt; StateDictKey
-&gt; m (MultiHeadAttention
        'BART
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        queryEmbedDim
        queryEmbedDim
        queryEmbedDim)
forall model (m :: Type -&gt; Type).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
ModelSpec model -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">STransformerStyle 'BART
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim headDim
-&gt; SDim headEmbedDim
-&gt; SDim embedDim
-&gt; SDim queryEmbedDim
-&gt; SDim queryEmbedDim
-&gt; SDim queryEmbedDim
-&gt; Double
-&gt; MultiHeadAttentionSpec
     'BART
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     queryEmbedDim
     queryEmbedDim
forall (style :: TransformerStyle)
       (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (headDim :: Dim (Name Symbol) (Size Nat))
       (headEmbedDim :: Dim (Name Symbol) (Size Nat))
       (embedDim :: Dim (Name Symbol) (Size Nat))
       (queryEmbedDim :: Dim (Name Symbol) (Size Nat))
       (keyEmbedDim :: Dim (Name Symbol) (Size Nat))
       (valueEmbedDim :: Dim (Name Symbol) (Size Nat)).
STransformerStyle style
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim headDim
-&gt; SDim headEmbedDim
-&gt; SDim embedDim
-&gt; SDim queryEmbedDim
-&gt; SDim keyEmbedDim
-&gt; SDim valueEmbedDim
-&gt; Double
-&gt; MultiHeadAttentionSpec
     style
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     keyEmbedDim
     valueEmbedDim
</span><a href="Torch.GraduallyTyped.NN.Transformer.MultiHeadAttention.html#MultiHeadAttentionSpec"><span class="hs-identifier hs-var">MultiHeadAttentionSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle 'BART
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679806156"><span class="hs-identifier hs-var">gradient</span></a></span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679806155"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679806154"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="annot"><span class="annottext">SDim headDim
</span><a href="#local-6989586621679806153"><span class="hs-identifier hs-var">headDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim headEmbedDim
</span><a href="#local-6989586621679806152"><span class="hs-identifier hs-var">headEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim embedDim
</span><a href="#local-6989586621679806151"><span class="hs-identifier hs-var">embedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim queryEmbedDim
</span><a href="#local-6989586621679806150"><span class="hs-identifier hs-var">queryEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim queryEmbedDim
</span><a href="#local-6989586621679806150"><span class="hs-identifier hs-var">queryEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim queryEmbedDim
</span><a href="#local-6989586621679806150"><span class="hs-identifier hs-var">queryEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679806149"><span class="hs-identifier hs-var">dropoutP</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679806147"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;self_attn.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-225"></span><span>        </span><span class="annot"><a href="#local-6989586621679806146"><span class="hs-identifier hs-var">multiHeadAttention</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (MultiHeadAttention
     'MBART
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     queryEmbedDim
     queryEmbedDim)
-&gt; StateDictKey
-&gt; m (MultiHeadAttention
        'MBART
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        queryEmbedDim
        queryEmbedDim
        queryEmbedDim)
forall model (m :: Type -&gt; Type).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
ModelSpec model -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">STransformerStyle 'MBART
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim headDim
-&gt; SDim headEmbedDim
-&gt; SDim embedDim
-&gt; SDim queryEmbedDim
-&gt; SDim queryEmbedDim
-&gt; SDim queryEmbedDim
-&gt; Double
-&gt; MultiHeadAttentionSpec
     'MBART
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     queryEmbedDim
     queryEmbedDim
forall (style :: TransformerStyle)
       (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (headDim :: Dim (Name Symbol) (Size Nat))
       (headEmbedDim :: Dim (Name Symbol) (Size Nat))
       (embedDim :: Dim (Name Symbol) (Size Nat))
       (queryEmbedDim :: Dim (Name Symbol) (Size Nat))
       (keyEmbedDim :: Dim (Name Symbol) (Size Nat))
       (valueEmbedDim :: Dim (Name Symbol) (Size Nat)).
STransformerStyle style
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim headDim
-&gt; SDim headEmbedDim
-&gt; SDim embedDim
-&gt; SDim queryEmbedDim
-&gt; SDim keyEmbedDim
-&gt; SDim valueEmbedDim
-&gt; Double
-&gt; MultiHeadAttentionSpec
     style
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     keyEmbedDim
     valueEmbedDim
</span><a href="Torch.GraduallyTyped.NN.Transformer.MultiHeadAttention.html#MultiHeadAttentionSpec"><span class="hs-identifier hs-var">MultiHeadAttentionSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle 'MBART
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span> </span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679806156"><span class="hs-identifier hs-var">gradient</span></a></span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679806155"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679806154"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="annot"><span class="annottext">SDim headDim
</span><a href="#local-6989586621679806153"><span class="hs-identifier hs-var">headDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim headEmbedDim
</span><a href="#local-6989586621679806152"><span class="hs-identifier hs-var">headEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim embedDim
</span><a href="#local-6989586621679806151"><span class="hs-identifier hs-var">embedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim queryEmbedDim
</span><a href="#local-6989586621679806150"><span class="hs-identifier hs-var">queryEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim queryEmbedDim
</span><a href="#local-6989586621679806150"><span class="hs-identifier hs-var">queryEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim queryEmbedDim
</span><a href="#local-6989586621679806150"><span class="hs-identifier hs-var">queryEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679806149"><span class="hs-identifier hs-var">dropoutP</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679806147"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;self_attn.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-226"></span><span>        </span><span class="annot"><a href="#local-6989586621679806146"><span class="hs-identifier hs-var">multiHeadAttention</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (MultiHeadAttention
     'Pegasus
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     queryEmbedDim
     queryEmbedDim)
-&gt; StateDictKey
-&gt; m (MultiHeadAttention
        'Pegasus
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        queryEmbedDim
        queryEmbedDim
        queryEmbedDim)
forall model (m :: Type -&gt; Type).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
ModelSpec model -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">STransformerStyle 'Pegasus
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim headDim
-&gt; SDim headEmbedDim
-&gt; SDim embedDim
-&gt; SDim queryEmbedDim
-&gt; SDim queryEmbedDim
-&gt; SDim queryEmbedDim
-&gt; Double
-&gt; MultiHeadAttentionSpec
     'Pegasus
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     queryEmbedDim
     queryEmbedDim
forall (style :: TransformerStyle)
       (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (headDim :: Dim (Name Symbol) (Size Nat))
       (headEmbedDim :: Dim (Name Symbol) (Size Nat))
       (embedDim :: Dim (Name Symbol) (Size Nat))
       (queryEmbedDim :: Dim (Name Symbol) (Size Nat))
       (keyEmbedDim :: Dim (Name Symbol) (Size Nat))
       (valueEmbedDim :: Dim (Name Symbol) (Size Nat)).
STransformerStyle style
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim headDim
-&gt; SDim headEmbedDim
-&gt; SDim embedDim
-&gt; SDim queryEmbedDim
-&gt; SDim keyEmbedDim
-&gt; SDim valueEmbedDim
-&gt; Double
-&gt; MultiHeadAttentionSpec
     style
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     keyEmbedDim
     valueEmbedDim
</span><a href="Torch.GraduallyTyped.NN.Transformer.MultiHeadAttention.html#MultiHeadAttentionSpec"><span class="hs-identifier hs-var">MultiHeadAttentionSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle 'Pegasus
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span> </span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679806156"><span class="hs-identifier hs-var">gradient</span></a></span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679806155"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679806154"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="annot"><span class="annottext">SDim headDim
</span><a href="#local-6989586621679806153"><span class="hs-identifier hs-var">headDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim headEmbedDim
</span><a href="#local-6989586621679806152"><span class="hs-identifier hs-var">headEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim embedDim
</span><a href="#local-6989586621679806151"><span class="hs-identifier hs-var">embedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim queryEmbedDim
</span><a href="#local-6989586621679806150"><span class="hs-identifier hs-var">queryEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim queryEmbedDim
</span><a href="#local-6989586621679806150"><span class="hs-identifier hs-var">queryEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim queryEmbedDim
</span><a href="#local-6989586621679806150"><span class="hs-identifier hs-var">queryEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679806149"><span class="hs-identifier hs-var">dropoutP</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679806147"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;self_attn.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-227"></span><span>        </span><span class="annot"><a href="#local-6989586621679806146"><span class="hs-identifier hs-var">multiHeadAttention</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (MultiHeadAttention
     'BERT
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     queryEmbedDim
     queryEmbedDim)
-&gt; StateDictKey
-&gt; m (MultiHeadAttention
        'BERT
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        queryEmbedDim
        queryEmbedDim
        queryEmbedDim)
forall model (m :: Type -&gt; Type).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
ModelSpec model -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">STransformerStyle 'BERT
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim headDim
-&gt; SDim headEmbedDim
-&gt; SDim embedDim
-&gt; SDim queryEmbedDim
-&gt; SDim queryEmbedDim
-&gt; SDim queryEmbedDim
-&gt; Double
-&gt; MultiHeadAttentionSpec
     'BERT
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     queryEmbedDim
     queryEmbedDim
forall (style :: TransformerStyle)
       (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (headDim :: Dim (Name Symbol) (Size Nat))
       (headEmbedDim :: Dim (Name Symbol) (Size Nat))
       (embedDim :: Dim (Name Symbol) (Size Nat))
       (queryEmbedDim :: Dim (Name Symbol) (Size Nat))
       (keyEmbedDim :: Dim (Name Symbol) (Size Nat))
       (valueEmbedDim :: Dim (Name Symbol) (Size Nat)).
STransformerStyle style
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim headDim
-&gt; SDim headEmbedDim
-&gt; SDim embedDim
-&gt; SDim queryEmbedDim
-&gt; SDim keyEmbedDim
-&gt; SDim valueEmbedDim
-&gt; Double
-&gt; MultiHeadAttentionSpec
     style
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     keyEmbedDim
     valueEmbedDim
</span><a href="Torch.GraduallyTyped.NN.Transformer.MultiHeadAttention.html#MultiHeadAttentionSpec"><span class="hs-identifier hs-var">MultiHeadAttentionSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle 'BERT
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679806156"><span class="hs-identifier hs-var">gradient</span></a></span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679806155"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679806154"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="annot"><span class="annottext">SDim headDim
</span><a href="#local-6989586621679806153"><span class="hs-identifier hs-var">headDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim headEmbedDim
</span><a href="#local-6989586621679806152"><span class="hs-identifier hs-var">headEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim embedDim
</span><a href="#local-6989586621679806151"><span class="hs-identifier hs-var">embedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim queryEmbedDim
</span><a href="#local-6989586621679806150"><span class="hs-identifier hs-var">queryEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim queryEmbedDim
</span><a href="#local-6989586621679806150"><span class="hs-identifier hs-var">queryEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim queryEmbedDim
</span><a href="#local-6989586621679806150"><span class="hs-identifier hs-var">queryEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679806149"><span class="hs-identifier hs-var">dropoutP</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679806147"><span class="hs-identifier hs-var">k</span></a></span><span>
</span><span id="line-228"></span><span>        </span><span class="annot"><a href="#local-6989586621679806146"><span class="hs-identifier hs-var">multiHeadAttention</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (MultiHeadAttention
     'RoBERTa
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     queryEmbedDim
     queryEmbedDim)
-&gt; StateDictKey
-&gt; m (MultiHeadAttention
        'RoBERTa
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        queryEmbedDim
        queryEmbedDim
        queryEmbedDim)
forall model (m :: Type -&gt; Type).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
ModelSpec model -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">STransformerStyle 'RoBERTa
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim headDim
-&gt; SDim headEmbedDim
-&gt; SDim embedDim
-&gt; SDim queryEmbedDim
-&gt; SDim queryEmbedDim
-&gt; SDim queryEmbedDim
-&gt; Double
-&gt; MultiHeadAttentionSpec
     'RoBERTa
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     queryEmbedDim
     queryEmbedDim
forall (style :: TransformerStyle)
       (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (headDim :: Dim (Name Symbol) (Size Nat))
       (headEmbedDim :: Dim (Name Symbol) (Size Nat))
       (embedDim :: Dim (Name Symbol) (Size Nat))
       (queryEmbedDim :: Dim (Name Symbol) (Size Nat))
       (keyEmbedDim :: Dim (Name Symbol) (Size Nat))
       (valueEmbedDim :: Dim (Name Symbol) (Size Nat)).
STransformerStyle style
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim headDim
-&gt; SDim headEmbedDim
-&gt; SDim embedDim
-&gt; SDim queryEmbedDim
-&gt; SDim keyEmbedDim
-&gt; SDim valueEmbedDim
-&gt; Double
-&gt; MultiHeadAttentionSpec
     style
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     keyEmbedDim
     valueEmbedDim
</span><a href="Torch.GraduallyTyped.NN.Transformer.MultiHeadAttention.html#MultiHeadAttentionSpec"><span class="hs-identifier hs-var">MultiHeadAttentionSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle 'RoBERTa
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679806156"><span class="hs-identifier hs-var">gradient</span></a></span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679806155"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679806154"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="annot"><span class="annottext">SDim headDim
</span><a href="#local-6989586621679806153"><span class="hs-identifier hs-var">headDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim headEmbedDim
</span><a href="#local-6989586621679806152"><span class="hs-identifier hs-var">headEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim embedDim
</span><a href="#local-6989586621679806151"><span class="hs-identifier hs-var">embedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim queryEmbedDim
</span><a href="#local-6989586621679806150"><span class="hs-identifier hs-var">queryEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim queryEmbedDim
</span><a href="#local-6989586621679806150"><span class="hs-identifier hs-var">queryEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim queryEmbedDim
</span><a href="#local-6989586621679806150"><span class="hs-identifier hs-var">queryEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679806149"><span class="hs-identifier hs-var">dropoutP</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679806147"><span class="hs-identifier hs-var">k</span></a></span><span>
</span><span id="line-229"></span><span>        </span><span class="annot"><a href="#local-6989586621679806146"><span class="hs-identifier hs-var">multiHeadAttention</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SGPT2"><span class="hs-identifier hs-var">SGPT2</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">m (MultiHeadAttention
     style
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     queryEmbedDim
     queryEmbedDim)
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-230"></span><span>        </span><span id="local-6989586621679806145"><span class="annot"><span class="annottext">layerNorm :: STransformerStyle style
-&gt; m (SALayerNormF style gradient device dataType queryEmbedDim)
</span><a href="#local-6989586621679806145"><span class="hs-identifier hs-var hs-var">layerNorm</span></a></span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (LayerNorm
     'WithoutBias gradient device dataType ('Shape '[queryEmbedDim]))
-&gt; StateDictKey
-&gt; m (LayerNorm
        'WithoutBias gradient device dataType ('Shape '[queryEmbedDim]))
forall model (m :: Type -&gt; Type).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
ModelSpec model -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SHasBias 'WithoutBias
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SShape ('Shape '[queryEmbedDim])
-&gt; Double
-&gt; LayerNormSpec
     'WithoutBias gradient device dataType ('Shape '[queryEmbedDim])
forall (hasBias :: HasBias) (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (normalizedShape :: Shape [Dim (Name Symbol) (Size Nat)]).
SHasBias hasBias
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SShape normalizedShape
-&gt; Double
-&gt; LayerNormSpec hasBias gradient device dataType normalizedShape
</span><a href="Torch.GraduallyTyped.NN.Normalization.html#LayerNormSpec"><span class="hs-identifier hs-var">LayerNormSpec</span></a></span><span> </span><span class="annot"><span class="annottext">SHasBias 'WithoutBias
</span><a href="Torch.GraduallyTyped.NN.Type.html#SWithoutBias"><span class="hs-identifier hs-var">SWithoutBias</span></a></span><span> </span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679806156"><span class="hs-identifier hs-var">gradient</span></a></span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679806155"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679806154"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SList '[queryEmbedDim] -&gt; SShape ('Shape '[queryEmbedDim])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList '[queryEmbedDim] -&gt; SShape ('Shape '[queryEmbedDim]))
-&gt; SList '[queryEmbedDim] -&gt; SShape ('Shape '[queryEmbedDim])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SDim queryEmbedDim
</span><a href="#local-6989586621679806150"><span class="hs-identifier hs-var">queryEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim queryEmbedDim -&gt; SList '[] -&gt; SList '[queryEmbedDim]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679806148"><span class="hs-identifier hs-var">eps</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679806147"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;layer_norm.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-231"></span><span>        </span><span class="annot"><a href="#local-6989586621679806145"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (LayerNorm
     'WithoutBias gradient device dataType ('Shape '[queryEmbedDim]))
-&gt; StateDictKey
-&gt; m (LayerNorm
        'WithoutBias gradient device dataType ('Shape '[queryEmbedDim]))
forall model (m :: Type -&gt; Type).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
ModelSpec model -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SHasBias 'WithoutBias
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SShape ('Shape '[queryEmbedDim])
-&gt; Double
-&gt; LayerNormSpec
     'WithoutBias gradient device dataType ('Shape '[queryEmbedDim])
forall (hasBias :: HasBias) (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (normalizedShape :: Shape [Dim (Name Symbol) (Size Nat)]).
SHasBias hasBias
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SShape normalizedShape
-&gt; Double
-&gt; LayerNormSpec hasBias gradient device dataType normalizedShape
</span><a href="Torch.GraduallyTyped.NN.Normalization.html#LayerNormSpec"><span class="hs-identifier hs-var">LayerNormSpec</span></a></span><span> </span><span class="annot"><span class="annottext">SHasBias 'WithoutBias
</span><a href="Torch.GraduallyTyped.NN.Type.html#SWithoutBias"><span class="hs-identifier hs-var">SWithoutBias</span></a></span><span> </span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679806156"><span class="hs-identifier hs-var">gradient</span></a></span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679806155"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679806154"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SList '[queryEmbedDim] -&gt; SShape ('Shape '[queryEmbedDim])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList '[queryEmbedDim] -&gt; SShape ('Shape '[queryEmbedDim]))
-&gt; SList '[queryEmbedDim] -&gt; SShape ('Shape '[queryEmbedDim])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SDim queryEmbedDim
</span><a href="#local-6989586621679806150"><span class="hs-identifier hs-var">queryEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim queryEmbedDim -&gt; SList '[] -&gt; SList '[queryEmbedDim]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679806148"><span class="hs-identifier hs-var">eps</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679806147"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;layer_norm.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-232"></span><span>        </span><span class="annot"><a href="#local-6989586621679806145"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (LayerNorm
     'WithBias gradient device dataType ('Shape '[queryEmbedDim]))
-&gt; StateDictKey
-&gt; m (LayerNorm
        'WithBias gradient device dataType ('Shape '[queryEmbedDim]))
forall model (m :: Type -&gt; Type).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
ModelSpec model -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SHasBias 'WithBias
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SShape ('Shape '[queryEmbedDim])
-&gt; Double
-&gt; LayerNormSpec
     'WithBias gradient device dataType ('Shape '[queryEmbedDim])
forall (hasBias :: HasBias) (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (normalizedShape :: Shape [Dim (Name Symbol) (Size Nat)]).
SHasBias hasBias
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SShape normalizedShape
-&gt; Double
-&gt; LayerNormSpec hasBias gradient device dataType normalizedShape
</span><a href="Torch.GraduallyTyped.NN.Normalization.html#LayerNormSpec"><span class="hs-identifier hs-var">LayerNormSpec</span></a></span><span> </span><span class="annot"><span class="annottext">SHasBias 'WithBias
</span><a href="Torch.GraduallyTyped.NN.Type.html#SWithBias"><span class="hs-identifier hs-var">SWithBias</span></a></span><span> </span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679806156"><span class="hs-identifier hs-var">gradient</span></a></span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679806155"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679806154"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SList '[queryEmbedDim] -&gt; SShape ('Shape '[queryEmbedDim])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList '[queryEmbedDim] -&gt; SShape ('Shape '[queryEmbedDim]))
-&gt; SList '[queryEmbedDim] -&gt; SShape ('Shape '[queryEmbedDim])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SDim queryEmbedDim
</span><a href="#local-6989586621679806150"><span class="hs-identifier hs-var">queryEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim queryEmbedDim -&gt; SList '[] -&gt; SList '[queryEmbedDim]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679806148"><span class="hs-identifier hs-var">eps</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679806147"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;self_attn_layer_norm.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-233"></span><span>        </span><span class="annot"><a href="#local-6989586621679806145"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (LayerNorm
     'WithBias gradient device dataType ('Shape '[queryEmbedDim]))
-&gt; StateDictKey
-&gt; m (LayerNorm
        'WithBias gradient device dataType ('Shape '[queryEmbedDim]))
forall model (m :: Type -&gt; Type).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
ModelSpec model -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SHasBias 'WithBias
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SShape ('Shape '[queryEmbedDim])
-&gt; Double
-&gt; LayerNormSpec
     'WithBias gradient device dataType ('Shape '[queryEmbedDim])
forall (hasBias :: HasBias) (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (normalizedShape :: Shape [Dim (Name Symbol) (Size Nat)]).
SHasBias hasBias
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SShape normalizedShape
-&gt; Double
-&gt; LayerNormSpec hasBias gradient device dataType normalizedShape
</span><a href="Torch.GraduallyTyped.NN.Normalization.html#LayerNormSpec"><span class="hs-identifier hs-var">LayerNormSpec</span></a></span><span> </span><span class="annot"><span class="annottext">SHasBias 'WithBias
</span><a href="Torch.GraduallyTyped.NN.Type.html#SWithBias"><span class="hs-identifier hs-var">SWithBias</span></a></span><span> </span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679806156"><span class="hs-identifier hs-var">gradient</span></a></span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679806155"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679806154"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SList '[queryEmbedDim] -&gt; SShape ('Shape '[queryEmbedDim])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList '[queryEmbedDim] -&gt; SShape ('Shape '[queryEmbedDim]))
-&gt; SList '[queryEmbedDim] -&gt; SShape ('Shape '[queryEmbedDim])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SDim queryEmbedDim
</span><a href="#local-6989586621679806150"><span class="hs-identifier hs-var">queryEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim queryEmbedDim -&gt; SList '[] -&gt; SList '[queryEmbedDim]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679806148"><span class="hs-identifier hs-var">eps</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679806147"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;self_attn_layer_norm.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-234"></span><span>        </span><span class="annot"><a href="#local-6989586621679806145"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (LayerNorm
     'WithBias gradient device dataType ('Shape '[queryEmbedDim]))
-&gt; StateDictKey
-&gt; m (LayerNorm
        'WithBias gradient device dataType ('Shape '[queryEmbedDim]))
forall model (m :: Type -&gt; Type).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
ModelSpec model -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SHasBias 'WithBias
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SShape ('Shape '[queryEmbedDim])
-&gt; Double
-&gt; LayerNormSpec
     'WithBias gradient device dataType ('Shape '[queryEmbedDim])
forall (hasBias :: HasBias) (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (normalizedShape :: Shape [Dim (Name Symbol) (Size Nat)]).
SHasBias hasBias
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SShape normalizedShape
-&gt; Double
-&gt; LayerNormSpec hasBias gradient device dataType normalizedShape
</span><a href="Torch.GraduallyTyped.NN.Normalization.html#LayerNormSpec"><span class="hs-identifier hs-var">LayerNormSpec</span></a></span><span> </span><span class="annot"><span class="annottext">SHasBias 'WithBias
</span><a href="Torch.GraduallyTyped.NN.Type.html#SWithBias"><span class="hs-identifier hs-var">SWithBias</span></a></span><span> </span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679806156"><span class="hs-identifier hs-var">gradient</span></a></span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679806155"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679806154"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SList '[queryEmbedDim] -&gt; SShape ('Shape '[queryEmbedDim])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList '[queryEmbedDim] -&gt; SShape ('Shape '[queryEmbedDim]))
-&gt; SList '[queryEmbedDim] -&gt; SShape ('Shape '[queryEmbedDim])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SDim queryEmbedDim
</span><a href="#local-6989586621679806150"><span class="hs-identifier hs-var">queryEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim queryEmbedDim -&gt; SList '[] -&gt; SList '[queryEmbedDim]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679806148"><span class="hs-identifier hs-var">eps</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679806147"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;self_attn_layer_norm.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-235"></span><span>        </span><span class="annot"><a href="#local-6989586621679806145"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (LayerNorm
     'WithBias gradient device dataType ('Shape '[queryEmbedDim]))
-&gt; StateDictKey
-&gt; m (LayerNorm
        'WithBias gradient device dataType ('Shape '[queryEmbedDim]))
forall model (m :: Type -&gt; Type).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
ModelSpec model -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SHasBias 'WithBias
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SShape ('Shape '[queryEmbedDim])
-&gt; Double
-&gt; LayerNormSpec
     'WithBias gradient device dataType ('Shape '[queryEmbedDim])
forall (hasBias :: HasBias) (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (normalizedShape :: Shape [Dim (Name Symbol) (Size Nat)]).
SHasBias hasBias
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SShape normalizedShape
-&gt; Double
-&gt; LayerNormSpec hasBias gradient device dataType normalizedShape
</span><a href="Torch.GraduallyTyped.NN.Normalization.html#LayerNormSpec"><span class="hs-identifier hs-var">LayerNormSpec</span></a></span><span> </span><span class="annot"><span class="annottext">SHasBias 'WithBias
</span><a href="Torch.GraduallyTyped.NN.Type.html#SWithBias"><span class="hs-identifier hs-var">SWithBias</span></a></span><span> </span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679806156"><span class="hs-identifier hs-var">gradient</span></a></span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679806155"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679806154"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SList '[queryEmbedDim] -&gt; SShape ('Shape '[queryEmbedDim])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList '[queryEmbedDim] -&gt; SShape ('Shape '[queryEmbedDim]))
-&gt; SList '[queryEmbedDim] -&gt; SShape ('Shape '[queryEmbedDim])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SDim queryEmbedDim
</span><a href="#local-6989586621679806150"><span class="hs-identifier hs-var">queryEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim queryEmbedDim -&gt; SList '[] -&gt; SList '[queryEmbedDim]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679806148"><span class="hs-identifier hs-var">eps</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679806147"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;output.LayerNorm.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-236"></span><span>        </span><span class="annot"><a href="#local-6989586621679806145"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (LayerNorm
     'WithBias gradient device dataType ('Shape '[queryEmbedDim]))
-&gt; StateDictKey
-&gt; m (LayerNorm
        'WithBias gradient device dataType ('Shape '[queryEmbedDim]))
forall model (m :: Type -&gt; Type).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
ModelSpec model -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SHasBias 'WithBias
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SShape ('Shape '[queryEmbedDim])
-&gt; Double
-&gt; LayerNormSpec
     'WithBias gradient device dataType ('Shape '[queryEmbedDim])
forall (hasBias :: HasBias) (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (normalizedShape :: Shape [Dim (Name Symbol) (Size Nat)]).
SHasBias hasBias
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SShape normalizedShape
-&gt; Double
-&gt; LayerNormSpec hasBias gradient device dataType normalizedShape
</span><a href="Torch.GraduallyTyped.NN.Normalization.html#LayerNormSpec"><span class="hs-identifier hs-var">LayerNormSpec</span></a></span><span> </span><span class="annot"><span class="annottext">SHasBias 'WithBias
</span><a href="Torch.GraduallyTyped.NN.Type.html#SWithBias"><span class="hs-identifier hs-var">SWithBias</span></a></span><span> </span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679806156"><span class="hs-identifier hs-var">gradient</span></a></span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679806155"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679806154"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SList '[queryEmbedDim] -&gt; SShape ('Shape '[queryEmbedDim])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList '[queryEmbedDim] -&gt; SShape ('Shape '[queryEmbedDim]))
-&gt; SList '[queryEmbedDim] -&gt; SShape ('Shape '[queryEmbedDim])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SDim queryEmbedDim
</span><a href="#local-6989586621679806150"><span class="hs-identifier hs-var">queryEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim queryEmbedDim -&gt; SList '[] -&gt; SList '[queryEmbedDim]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679806148"><span class="hs-identifier hs-var">eps</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679806147"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;output.LayerNorm.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-237"></span><span>        </span><span class="annot"><a href="#local-6989586621679806145"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SGPT2"><span class="hs-identifier hs-var">SGPT2</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">m (SALayerNormF style gradient device dataType queryEmbedDim)
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-238"></span><span>        </span><span id="local-6989586621679806144"><span class="annot"><span class="annottext">dropout :: STransformerStyle style -&gt; m Dropout
</span><a href="#local-6989586621679806144"><span class="hs-identifier hs-var hs-var">dropout</span></a></span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec Dropout -&gt; StateDictKey -&gt; m Dropout
forall model (m :: Type -&gt; Type).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
ModelSpec model -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Double -&gt; Dropout
</span><a href="Torch.GraduallyTyped.NN.Dropout.html#Dropout"><span class="hs-identifier hs-var">Dropout</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679806149"><span class="hs-identifier hs-var">dropoutP</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679806147"><span class="hs-identifier hs-var">k</span></a></span><span>
</span><span id="line-239"></span><span>     </span><span class="hs-keyword">in</span><span> </span><span class="annot"><span class="annottext">GSelfAttention
  (MultiHeadAttention
     style
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     queryEmbedDim
     queryEmbedDim)
  (SALayerNormF style gradient device dataType queryEmbedDim)
  Dropout
-&gt; SelfAttention
     style
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
forall (style :: TransformerStyle)
       (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (headDim :: Dim (Name Symbol) (Size Nat))
       (headEmbedDim :: Dim (Name Symbol) (Size Nat))
       (embedDim :: Dim (Name Symbol) (Size Nat))
       (queryEmbedDim :: Dim (Name Symbol) (Size Nat)).
GSelfAttention
  (SAMultiheadAttentionF
     style
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim)
  (SALayerNormF style gradient device dataType queryEmbedDim)
  (SADropoutF style)
-&gt; SelfAttention
     style
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
</span><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#SelfAttention"><span class="hs-identifier hs-var">SelfAttention</span></a></span><span>
</span><span id="line-240"></span><span>          </span><span class="annot"><span class="annottext">(GSelfAttention
   (MultiHeadAttention
      style
      gradient
      device
      dataType
      headDim
      headEmbedDim
      embedDim
      queryEmbedDim
      queryEmbedDim
      queryEmbedDim)
   (SALayerNormF style gradient device dataType queryEmbedDim)
   Dropout
 -&gt; SelfAttention
      style
      gradient
      device
      dataType
      headDim
      headEmbedDim
      embedDim
      queryEmbedDim)
-&gt; m (GSelfAttention
        (MultiHeadAttention
           style
           gradient
           device
           dataType
           headDim
           headEmbedDim
           embedDim
           queryEmbedDim
           queryEmbedDim
           queryEmbedDim)
        (SALayerNormF style gradient device dataType queryEmbedDim)
        Dropout)
-&gt; m (SelfAttention
        style
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        queryEmbedDim)
forall (f :: Type -&gt; Type) a b. Functor f =&gt; (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;$&gt;</span></span><span> </span><span class="hs-special">(</span><span> </span><span class="annot"><span class="annottext">MultiHeadAttention
  style
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  queryEmbedDim
  queryEmbedDim
  queryEmbedDim
-&gt; SALayerNormF style gradient device dataType queryEmbedDim
-&gt; Dropout
-&gt; GSelfAttention
     (MultiHeadAttention
        style
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        queryEmbedDim
        queryEmbedDim
        queryEmbedDim)
     (SALayerNormF style gradient device dataType queryEmbedDim)
     Dropout
forall mha layerNorm dropout.
mha -&gt; layerNorm -&gt; dropout -&gt; GSelfAttention mha layerNorm dropout
</span><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#GSelfAttention"><span class="hs-identifier hs-var">GSelfAttention</span></a></span><span>
</span><span id="line-241"></span><span>                  </span><span class="annot"><span class="annottext">(MultiHeadAttention
   style
   gradient
   device
   dataType
   headDim
   headEmbedDim
   embedDim
   queryEmbedDim
   queryEmbedDim
   queryEmbedDim
 -&gt; SALayerNormF style gradient device dataType queryEmbedDim
 -&gt; Dropout
 -&gt; GSelfAttention
      (MultiHeadAttention
         style
         gradient
         device
         dataType
         headDim
         headEmbedDim
         embedDim
         queryEmbedDim
         queryEmbedDim
         queryEmbedDim)
      (SALayerNormF style gradient device dataType queryEmbedDim)
      Dropout)
-&gt; m (MultiHeadAttention
        style
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        queryEmbedDim
        queryEmbedDim
        queryEmbedDim)
-&gt; m (SALayerNormF style gradient device dataType queryEmbedDim
      -&gt; Dropout
      -&gt; GSelfAttention
           (MultiHeadAttention
              style
              gradient
              device
              dataType
              headDim
              headEmbedDim
              embedDim
              queryEmbedDim
              queryEmbedDim
              queryEmbedDim)
           (SALayerNormF style gradient device dataType queryEmbedDim)
           Dropout)
forall (f :: Type -&gt; Type) a b. Functor f =&gt; (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;$&gt;</span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; m (MultiHeadAttention
        style
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        queryEmbedDim
        queryEmbedDim
        queryEmbedDim)
</span><a href="#local-6989586621679806146"><span class="hs-identifier hs-var">multiHeadAttention</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="#local-6989586621679806157"><span class="hs-identifier hs-var">style</span></a></span><span>
</span><span id="line-242"></span><span>                  </span><span class="annot"><span class="annottext">m (SALayerNormF style gradient device dataType queryEmbedDim
   -&gt; Dropout
   -&gt; GSelfAttention
        (MultiHeadAttention
           style
           gradient
           device
           dataType
           headDim
           headEmbedDim
           embedDim
           queryEmbedDim
           queryEmbedDim
           queryEmbedDim)
        (SALayerNormF style gradient device dataType queryEmbedDim)
        Dropout)
-&gt; m (SALayerNormF style gradient device dataType queryEmbedDim)
-&gt; m (Dropout
      -&gt; GSelfAttention
           (MultiHeadAttention
              style
              gradient
              device
              dataType
              headDim
              headEmbedDim
              embedDim
              queryEmbedDim
              queryEmbedDim
              queryEmbedDim)
           (SALayerNormF style gradient device dataType queryEmbedDim)
           Dropout)
forall (f :: Type -&gt; Type) a b.
Applicative f =&gt;
f (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;*&gt;</span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; m (SALayerNormF style gradient device dataType queryEmbedDim)
</span><a href="#local-6989586621679806145"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="#local-6989586621679806157"><span class="hs-identifier hs-var">style</span></a></span><span>
</span><span id="line-243"></span><span>                  </span><span class="annot"><span class="annottext">m (Dropout
   -&gt; GSelfAttention
        (MultiHeadAttention
           style
           gradient
           device
           dataType
           headDim
           headEmbedDim
           embedDim
           queryEmbedDim
           queryEmbedDim
           queryEmbedDim)
        (SALayerNormF style gradient device dataType queryEmbedDim)
        Dropout)
-&gt; m Dropout
-&gt; m (GSelfAttention
        (MultiHeadAttention
           style
           gradient
           device
           dataType
           headDim
           headEmbedDim
           embedDim
           queryEmbedDim
           queryEmbedDim
           queryEmbedDim)
        (SALayerNormF style gradient device dataType queryEmbedDim)
        Dropout)
forall (f :: Type -&gt; Type) a b.
Applicative f =&gt;
f (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;*&gt;</span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style -&gt; m Dropout
</span><a href="#local-6989586621679806144"><span class="hs-identifier hs-var">dropout</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="#local-6989586621679806157"><span class="hs-identifier hs-var">style</span></a></span><span>
</span><span id="line-244"></span><span>              </span><span class="hs-special">)</span><span>
</span><span id="line-245"></span><span>  </span><span id="local-6989586621679806142"><span class="annot"><span class="annottext">toStateDict :: StateDictKey
-&gt; SelfAttention
     style
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
-&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var hs-var hs-var hs-var">toStateDict</span></a></span></span><span> </span><span id="local-6989586621679806140"><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679806140"><span class="hs-identifier hs-var">k</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#SelfAttention"><span class="hs-identifier hs-type">SelfAttention</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#GSelfAttention"><span class="hs-identifier hs-type">GSelfAttention</span></a></span><span> </span><span class="hs-special">{</span><span id="local-6989586621679806137"><span id="local-6989586621679806138"><span id="local-6989586621679806139"><span class="annot"><span class="annottext">SADropoutF style
SALayerNormF style gradient device dataType queryEmbedDim
SAMultiheadAttentionF
  style
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  queryEmbedDim
saDropout :: SADropoutF style
saLayerNorm :: SALayerNormF style gradient device dataType queryEmbedDim
saMultiHeadAttention :: SAMultiheadAttentionF
  style
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  queryEmbedDim
saDropout :: forall mha layerNorm dropout.
GSelfAttention mha layerNorm dropout -&gt; dropout
saLayerNorm :: forall mha layerNorm dropout.
GSelfAttention mha layerNorm dropout -&gt; layerNorm
saMultiHeadAttention :: forall mha layerNorm dropout.
GSelfAttention mha layerNorm dropout -&gt; mha
</span><a href="#local-6989586621679806137"><span class="hs-glyph hs-var hs-var hs-var hs-var hs-var hs-var">..</span></a></span></span></span></span><span class="hs-special">}</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-246"></span><span>    </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679806136"><span class="annot"><span class="annottext">multiHeadAttention :: STransformerStyle style
-&gt; MultiHeadAttention
     style
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     queryEmbedDim
     queryEmbedDim
-&gt; m ()
</span><a href="#local-6989586621679806136"><span class="hs-identifier hs-var hs-var">multiHeadAttention</span></a></span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; MultiHeadAttention
     'T5
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     queryEmbedDim
     queryEmbedDim
-&gt; m ()
forall model (m :: Type -&gt; Type).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679806140"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;SelfAttention.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-247"></span><span>        </span><span class="annot"><a href="#local-6989586621679806136"><span class="hs-identifier hs-var">multiHeadAttention</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; MultiHeadAttention
     'ByT5
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     queryEmbedDim
     queryEmbedDim
-&gt; m ()
forall model (m :: Type -&gt; Type).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679806140"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;SelfAttention.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-248"></span><span>        </span><span class="annot"><a href="#local-6989586621679806136"><span class="hs-identifier hs-var">multiHeadAttention</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; MultiHeadAttention
     'BART
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     queryEmbedDim
     queryEmbedDim
-&gt; m ()
forall model (m :: Type -&gt; Type).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679806140"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;self_attn.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-249"></span><span>        </span><span class="annot"><a href="#local-6989586621679806136"><span class="hs-identifier hs-var">multiHeadAttention</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; MultiHeadAttention
     'MBART
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     queryEmbedDim
     queryEmbedDim
-&gt; m ()
forall model (m :: Type -&gt; Type).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679806140"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;self_attn.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-250"></span><span>        </span><span class="annot"><a href="#local-6989586621679806136"><span class="hs-identifier hs-var">multiHeadAttention</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; MultiHeadAttention
     'Pegasus
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     queryEmbedDim
     queryEmbedDim
-&gt; m ()
forall model (m :: Type -&gt; Type).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679806140"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;self_attn.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-251"></span><span>        </span><span class="annot"><a href="#local-6989586621679806136"><span class="hs-identifier hs-var">multiHeadAttention</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; MultiHeadAttention
     'BERT
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     queryEmbedDim
     queryEmbedDim
-&gt; m ()
forall model (m :: Type -&gt; Type).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679806140"><span class="hs-identifier hs-var">k</span></a></span><span>
</span><span id="line-252"></span><span>        </span><span class="annot"><a href="#local-6989586621679806136"><span class="hs-identifier hs-var">multiHeadAttention</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; MultiHeadAttention
     'RoBERTa
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     queryEmbedDim
     queryEmbedDim
-&gt; m ()
forall model (m :: Type -&gt; Type).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679806140"><span class="hs-identifier hs-var">k</span></a></span><span>
</span><span id="line-253"></span><span>        </span><span class="annot"><a href="#local-6989586621679806136"><span class="hs-identifier hs-var">multiHeadAttention</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SGPT2"><span class="hs-identifier hs-var">SGPT2</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">MultiHeadAttention
  style
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  queryEmbedDim
  queryEmbedDim
  queryEmbedDim
-&gt; m ()
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-254"></span><span>        </span><span id="local-6989586621679806135"><span class="annot"><span class="annottext">layerNorm :: STransformerStyle style
-&gt; SALayerNormF style gradient device dataType queryEmbedDim
-&gt; m ()
</span><a href="#local-6989586621679806135"><span class="hs-identifier hs-var hs-var">layerNorm</span></a></span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; LayerNorm
     'WithoutBias gradient device dataType ('Shape '[queryEmbedDim])
-&gt; m ()
forall model (m :: Type -&gt; Type).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679806140"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;layer_norm.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-255"></span><span>        </span><span class="annot"><a href="#local-6989586621679806135"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; LayerNorm
     'WithoutBias gradient device dataType ('Shape '[queryEmbedDim])
-&gt; m ()
forall model (m :: Type -&gt; Type).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679806140"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;layer_norm.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-256"></span><span>        </span><span class="annot"><a href="#local-6989586621679806135"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; LayerNorm
     'WithBias gradient device dataType ('Shape '[queryEmbedDim])
-&gt; m ()
forall model (m :: Type -&gt; Type).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679806140"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;self_attn_layer_norm.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-257"></span><span>        </span><span class="annot"><a href="#local-6989586621679806135"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; LayerNorm
     'WithBias gradient device dataType ('Shape '[queryEmbedDim])
-&gt; m ()
forall model (m :: Type -&gt; Type).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679806140"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;self_attn_layer_norm.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-258"></span><span>        </span><span class="annot"><a href="#local-6989586621679806135"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; LayerNorm
     'WithBias gradient device dataType ('Shape '[queryEmbedDim])
-&gt; m ()
forall model (m :: Type -&gt; Type).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679806140"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;self_attn_layer_norm.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-259"></span><span>        </span><span class="annot"><a href="#local-6989586621679806135"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; LayerNorm
     'WithBias gradient device dataType ('Shape '[queryEmbedDim])
-&gt; m ()
forall model (m :: Type -&gt; Type).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679806140"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;output.LayerNorm.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-260"></span><span>        </span><span class="annot"><a href="#local-6989586621679806135"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; LayerNorm
     'WithBias gradient device dataType ('Shape '[queryEmbedDim])
-&gt; m ()
forall model (m :: Type -&gt; Type).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679806140"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;output.LayerNorm.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-261"></span><span>        </span><span class="annot"><a href="#local-6989586621679806135"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SGPT2"><span class="hs-identifier hs-var">SGPT2</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SALayerNormF style gradient device dataType queryEmbedDim -&gt; m ()
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-262"></span><span>        </span><span id="local-6989586621679806134"><span class="annot"><span class="annottext">dropout :: STransformerStyle style -&gt; Dropout -&gt; m ()
</span><a href="#local-6989586621679806134"><span class="hs-identifier hs-var hs-var">dropout</span></a></span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; Dropout -&gt; m ()
forall model (m :: Type -&gt; Type).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679806140"><span class="hs-identifier hs-var">k</span></a></span><span>
</span><span id="line-263"></span><span>     </span><span class="hs-keyword">in</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-264"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; MultiHeadAttention
     style
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     queryEmbedDim
     queryEmbedDim
-&gt; m ()
</span><a href="#local-6989586621679806136"><span class="hs-identifier hs-var">multiHeadAttention</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SingI style =&gt; Sing style
forall k (a :: k). SingI a =&gt; Sing a
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">sing</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679806170"><span class="hs-identifier hs-type">style</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">MultiHeadAttention
  style
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  queryEmbedDim
  queryEmbedDim
  queryEmbedDim
SAMultiheadAttentionF
  style
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  queryEmbedDim
</span><a href="#local-6989586621679806139"><span class="hs-identifier hs-var">saMultiHeadAttention</span></a></span><span>
</span><span id="line-265"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; SALayerNormF style gradient device dataType queryEmbedDim
-&gt; m ()
</span><a href="#local-6989586621679806135"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SingI style =&gt; Sing style
forall k (a :: k). SingI a =&gt; Sing a
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">sing</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679806170"><span class="hs-identifier hs-type">style</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">SALayerNormF style gradient device dataType queryEmbedDim
</span><a href="#local-6989586621679806138"><span class="hs-identifier hs-var">saLayerNorm</span></a></span><span>
</span><span id="line-266"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">STransformerStyle style -&gt; Dropout -&gt; m ()
</span><a href="#local-6989586621679806134"><span class="hs-identifier hs-var">dropout</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SingI style =&gt; Sing style
forall k (a :: k). SingI a =&gt; Sing a
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">sing</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679806170"><span class="hs-identifier hs-type">style</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Dropout
SADropoutF style
</span><a href="#local-6989586621679806137"><span class="hs-identifier hs-var">saDropout</span></a></span><span>
</span><span id="line-267"></span><span>          </span><span class="annot"><span class="annottext">() -&gt; m ()
forall (f :: Type -&gt; Type) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span></span></span></span></span></span></span></span></span><span>
</span><span id="line-268"></span><span>
</span><span id="line-269"></span><span class="hs-comment">-- | 'HasForward' instance for @SelfAttention 'T5@.</span><span>
</span><span id="line-270"></span><span class="hs-comment">--</span><span>
</span><span id="line-271"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-272"></span><span class="hs-comment">-- &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;     &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;</span><span>
</span><span id="line-273"></span><span class="hs-comment">-- &#9474; attentionBias &#9474;     &#9474; query &#9474;</span><span>
</span><span id="line-274"></span><span class="hs-comment">-- &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;     &#9492;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-275"></span><span class="hs-comment">--         &#9474;                 &#9474;</span><span>
</span><span id="line-276"></span><span class="hs-comment">--         &#9474;           &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9524;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;</span><span>
</span><span id="line-277"></span><span class="hs-comment">--         &#9474;           &#9474;           &#9474;</span><span>
</span><span id="line-278"></span><span class="hs-comment">--         &#9474;           &#9660;           &#9474;</span><span>
</span><span id="line-279"></span><span class="hs-comment">--         &#9474;      saLayerNorm      &#9474;</span><span>
</span><span id="line-280"></span><span class="hs-comment">--         &#9474;           &#9474;           &#9474;</span><span>
</span><span id="line-281"></span><span class="hs-comment">--         &#9474;      &#9484;&#9472;&#9472;&#9472;&#9472;&#9532;&#9472;&#9472;&#9472;&#9472;&#9488;      &#9474;</span><span>
</span><span id="line-282"></span><span class="hs-comment">--         &#9474;      &#9474;    &#9474;    &#9474;      &#9474;</span><span>
</span><span id="line-283"></span><span class="hs-comment">--         &#9474;      &#9660;    &#9660;    &#9660;      &#9474;</span><span>
</span><span id="line-284"></span><span class="hs-comment">--         &#9492;&#9472;&#9658;saMultiHeadAttention &#9474;</span><span>
</span><span id="line-285"></span><span class="hs-comment">--                     &#9474;           &#9474;</span><span>
</span><span id="line-286"></span><span class="hs-comment">--                     &#9660;           &#9474;</span><span>
</span><span id="line-287"></span><span class="hs-comment">--                 saDropout       &#9474;</span><span>
</span><span id="line-288"></span><span class="hs-comment">--                     &#9474;           &#9474;</span><span>
</span><span id="line-289"></span><span class="hs-comment">--                     &#9492;&#9472;&#9472;&#9472;&#9658;add&#9668;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-290"></span><span class="hs-comment">--                           &#9474;</span><span>
</span><span id="line-291"></span><span class="hs-comment">--                           &#9660;</span><span>
</span><span id="line-292"></span><span class="hs-comment">--                       &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;</span><span>
</span><span id="line-293"></span><span class="hs-comment">--                       &#9474; query &#9474;</span><span>
</span><span id="line-294"></span><span class="hs-comment">--                       &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-295"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-296"></span><span id="local-6989586621679806109"><span id="local-6989586621679806110"><span id="local-6989586621679806111"><span id="local-6989586621679806112"><span id="local-6989586621679806113"><span id="local-6989586621679806114"><span id="local-6989586621679806115"><span id="local-6989586621679806116"><span id="local-6989586621679806117"><span id="local-6989586621679806118"><span id="local-6989586621679806119"><span id="local-6989586621679806120"><span id="local-6989586621679806121"><span id="local-6989586621679806122"><span id="local-6989586621679806123"><span id="local-6989586621679806124"><span id="local-6989586621679806125"><span id="local-6989586621679806126"><span id="local-6989586621679806127"><span id="local-6989586621679806128"><span id="local-6989586621679806129"><span id="local-6989586621679806130"><span id="local-6989586621679806131"><span id="local-6989586621679806132"><span id="local-6989586621679806133"><span class="hs-keyword">instance</span><span>
</span><span id="line-297"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetDim"><span class="hs-identifier hs-type">SGetDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806133"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-298"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-299"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#SALayerNormF"><span class="hs-identifier hs-type">SALayerNormF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#T5"><span class="hs-identifier hs-type">T5</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806132"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806131"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806130"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806133"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-300"></span><span>      </span><span class="annot"><a href="#local-6989586621679806129"><span class="hs-identifier hs-type">query</span></a></span><span>
</span><span id="line-301"></span><span>      </span><span class="annot"><a href="#local-6989586621679806128"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-302"></span><span>      </span><span class="annot"><a href="#local-6989586621679806127"><span class="hs-identifier hs-type">layerNormOutput</span></a></span><span>
</span><span id="line-303"></span><span>      </span><span class="annot"><a href="#local-6989586621679806128"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-304"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-305"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#SAMultiheadAttentionF"><span class="hs-identifier hs-type">SAMultiheadAttentionF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#T5"><span class="hs-identifier hs-type">T5</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806132"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806131"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806130"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806126"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806125"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806124"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806133"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-306"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679806127"><span class="hs-identifier hs-type">layerNormOutput</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679806127"><span class="hs-identifier hs-type">layerNormOutput</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679806127"><span class="hs-identifier hs-type">layerNormOutput</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679806123"><span class="hs-identifier hs-type">attentionBias</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-307"></span><span>      </span><span class="annot"><a href="#local-6989586621679806128"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-308"></span><span>      </span><span class="annot"><a href="#local-6989586621679806122"><span class="hs-identifier hs-type">mhaOutput</span></a></span><span>
</span><span id="line-309"></span><span>      </span><span class="annot"><a href="#local-6989586621679806121"><span class="hs-identifier hs-type">device2</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-310"></span><span>    </span><span class="annot"><a href="#local-6989586621679806129"><span class="hs-identifier hs-type">query</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806120"><span class="hs-identifier hs-type">gradient0</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806119"><span class="hs-identifier hs-type">layout0</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806118"><span class="hs-identifier hs-type">device0</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806117"><span class="hs-identifier hs-type">dataType0</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806116"><span class="hs-identifier hs-type">shape0</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-311"></span><span>    </span><span class="annot"><a href="#local-6989586621679806122"><span class="hs-identifier hs-type">mhaOutput</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806115"><span class="hs-identifier hs-type">gradient1</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806114"><span class="hs-identifier hs-type">layout1</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806113"><span class="hs-identifier hs-type">device1</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806112"><span class="hs-identifier hs-type">dataType1</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806111"><span class="hs-identifier hs-type">shape1</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-312"></span><span>    </span><span class="annot"><a href="#local-6989586621679806110"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-313"></span><span>      </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-314"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679806120"><span class="hs-identifier hs-type">gradient0</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806115"><span class="hs-identifier hs-type">gradient1</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-315"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679806119"><span class="hs-identifier hs-type">layout0</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806114"><span class="hs-identifier hs-type">layout1</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-316"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679806118"><span class="hs-identifier hs-type">device0</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806113"><span class="hs-identifier hs-type">device1</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806121"><span class="hs-identifier hs-type">device2</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-317"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679806117"><span class="hs-identifier hs-type">dataType0</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806112"><span class="hs-identifier hs-type">dataType1</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-318"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#BroadcastShapesF"><span class="hs-identifier hs-type">BroadcastShapesF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806116"><span class="hs-identifier hs-type">shape0</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806111"><span class="hs-identifier hs-type">shape1</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-319"></span><span>    </span><span class="annot"><a href="#local-6989586621679806109"><span class="hs-identifier hs-type">generatorOutputDevice</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679806113"><span class="hs-identifier hs-type">device1</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806121"><span class="hs-identifier hs-type">device2</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-320"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-321"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-322"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#SelfAttention"><span class="hs-identifier hs-type">SelfAttention</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#T5"><span class="hs-identifier hs-type">T5</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806132"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806131"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806130"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806126"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806125"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806124"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806133"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-323"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679806129"><span class="hs-identifier hs-type">query</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679806123"><span class="hs-identifier hs-type">attentionBias</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-324"></span><span>    </span><span class="annot"><a href="#local-6989586621679806128"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-325"></span><span>    </span><span class="annot"><a href="#local-6989586621679806110"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-326"></span><span>    </span><span class="annot"><a href="#local-6989586621679806109"><span class="hs-identifier hs-type">generatorOutputDevice</span></a></span><span>
</span><span id="line-327"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-328"></span><span>  </span><span id="local-6989586621679806106"><span class="annot"><span class="annottext">forward :: SelfAttention
  'T5
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  queryEmbedDim
-&gt; (query, attentionBias)
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var hs-var hs-var hs-var">forward</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#SelfAttention"><span class="hs-identifier hs-type">SelfAttention</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#GSelfAttention"><span class="hs-identifier hs-type">GSelfAttention</span></a></span><span> </span><span class="hs-special">{</span><span id="local-6989586621679806102"><span id="local-6989586621679806103"><span id="local-6989586621679806104"><span class="annot"><span class="annottext">SADropoutF 'T5
SALayerNormF 'T5 gradient device dataType queryEmbedDim
SAMultiheadAttentionF
  'T5
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  queryEmbedDim
saDropout :: SADropoutF 'T5
saLayerNorm :: SALayerNormF 'T5 gradient device dataType queryEmbedDim
saMultiHeadAttention :: SAMultiheadAttentionF
  'T5
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  queryEmbedDim
saDropout :: forall mha layerNorm dropout.
GSelfAttention mha layerNorm dropout -&gt; dropout
saLayerNorm :: forall mha layerNorm dropout.
GSelfAttention mha layerNorm dropout -&gt; layerNorm
saMultiHeadAttention :: forall mha layerNorm dropout.
GSelfAttention mha layerNorm dropout -&gt; mha
</span><a href="#local-6989586621679806102"><span class="hs-glyph hs-var hs-var hs-var hs-var hs-var hs-var">..</span></a></span></span></span></span><span class="hs-special">}</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679806101"><span class="annot"><span class="annottext">query
</span><a href="#local-6989586621679806101"><span class="hs-identifier hs-var">query</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679806100"><span class="annot"><span class="annottext">attentionBias
</span><a href="#local-6989586621679806100"><span class="hs-identifier hs-var">attentionBias</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-329"></span><span>    </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorOutputDevice)
  output
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
forall (m :: Type -&gt; Type) i j a. IxStateT m i j a -&gt; i -&gt; m (a, j)
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var hs-var">runIxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">(IxStateT
   m
   (Generator generatorDevice)
   (Generator generatorOutputDevice)
   output
 -&gt; Generator generatorDevice
 -&gt; m (output, Generator generatorOutputDevice))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorOutputDevice)
     output
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-330"></span><span>      </span><span class="annot"><span class="annottext">query
-&gt; IxStateT
     m (Generator generatorDevice) (Generator generatorDevice) query
forall k (m :: k -&gt; k -&gt; Type -&gt; Type) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">query
</span><a href="#local-6989586621679806101"><span class="hs-identifier hs-var">query</span></a></span><span>
</span><span id="line-331"></span><span>        </span><span class="annot"><span class="annottext">IxStateT
  m (Generator generatorDevice) (Generator generatorDevice) query
-&gt; (query
    -&gt; IxStateT
         m
         (Generator generatorDevice)
         (Generator generatorDevice)
         layerNormOutput)
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     layerNormOutput
forall k1 (m :: k1 -&gt; k1 -&gt; Type -&gt; Type) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(Generator generatorDevice
 -&gt; m (layerNormOutput, Generator generatorDevice))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     layerNormOutput
forall (m :: Type -&gt; Type) i j a.
(i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator generatorDevice
  -&gt; m (layerNormOutput, Generator generatorDevice))
 -&gt; IxStateT
      m
      (Generator generatorDevice)
      (Generator generatorDevice)
      layerNormOutput)
-&gt; (query
    -&gt; Generator generatorDevice
    -&gt; m (layerNormOutput, Generator generatorDevice))
-&gt; query
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     layerNormOutput
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">LayerNorm
  'WithoutBias gradient device dataType ('Shape '[queryEmbedDim])
-&gt; query
-&gt; Generator generatorDevice
-&gt; m (layerNormOutput, Generator generatorDevice)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: Type -&gt; Type).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">LayerNorm
  'WithoutBias gradient device dataType ('Shape '[queryEmbedDim])
SALayerNormF 'T5 gradient device dataType queryEmbedDim
</span><a href="#local-6989586621679806103"><span class="hs-identifier hs-var">saLayerNorm</span></a></span><span>
</span><span id="line-332"></span><span>        </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorDevice)
  layerNormOutput
-&gt; (layerNormOutput
    -&gt; IxStateT
         m
         (Generator generatorDevice)
         (Generator device2)
         (Tensor gradient1 layout1 device1 dataType1 shape1))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator device2)
     (Tensor gradient1 layout1 device1 dataType1 shape1)
forall k1 (m :: k1 -&gt; k1 -&gt; Type -&gt; Type) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">\</span><span id="local-6989586621679806099"><span class="annot"><span class="annottext">layerNormOutput
</span><a href="#local-6989586621679806099"><span class="hs-identifier hs-var">query'</span></a></span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">(Generator generatorDevice
 -&gt; m (Tensor gradient1 layout1 device1 dataType1 shape1,
       Generator device2))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator device2)
     (Tensor gradient1 layout1 device1 dataType1 shape1)
forall (m :: Type -&gt; Type) i j a.
(i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator generatorDevice
  -&gt; m (Tensor gradient1 layout1 device1 dataType1 shape1,
        Generator device2))
 -&gt; IxStateT
      m
      (Generator generatorDevice)
      (Generator device2)
      (Tensor gradient1 layout1 device1 dataType1 shape1))
-&gt; (Generator generatorDevice
    -&gt; m (Tensor gradient1 layout1 device1 dataType1 shape1,
          Generator device2))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator device2)
     (Tensor gradient1 layout1 device1 dataType1 shape1)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">MultiHeadAttention
  'T5
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  queryEmbedDim
  queryEmbedDim
  queryEmbedDim
-&gt; (layerNormOutput, layerNormOutput, layerNormOutput,
    attentionBias)
-&gt; Generator generatorDevice
-&gt; m (Tensor gradient1 layout1 device1 dataType1 shape1,
      Generator device2)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: Type -&gt; Type).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">MultiHeadAttention
  'T5
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  queryEmbedDim
  queryEmbedDim
  queryEmbedDim
SAMultiheadAttentionF
  'T5
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  queryEmbedDim
</span><a href="#local-6989586621679806104"><span class="hs-identifier hs-var">saMultiHeadAttention</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">layerNormOutput
</span><a href="#local-6989586621679806099"><span class="hs-identifier hs-var">query'</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">layerNormOutput
</span><a href="#local-6989586621679806099"><span class="hs-identifier hs-var">query'</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">layerNormOutput
</span><a href="#local-6989586621679806099"><span class="hs-identifier hs-var">query'</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">attentionBias
</span><a href="#local-6989586621679806100"><span class="hs-identifier hs-var">attentionBias</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-333"></span><span>        </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator device2)
  (Tensor gradient1 layout1 device1 dataType1 shape1)
-&gt; (Tensor gradient1 layout1 device1 dataType1 shape1
    -&gt; IxStateT
         m
         (Generator device2)
         (Generator generatorOutputDevice)
         (Tensor gradient1 layout1 generatorOutputDevice dataType1 shape1))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorOutputDevice)
     (Tensor gradient1 layout1 generatorOutputDevice dataType1 shape1)
forall k1 (m :: k1 -&gt; k1 -&gt; Type -&gt; Type) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(Generator device2
 -&gt; m (Tensor
         gradient1 layout1 generatorOutputDevice dataType1 shape1,
       Generator generatorOutputDevice))
-&gt; IxStateT
     m
     (Generator device2)
     (Generator generatorOutputDevice)
     (Tensor gradient1 layout1 generatorOutputDevice dataType1 shape1)
forall (m :: Type -&gt; Type) i j a.
(i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator device2
  -&gt; m (Tensor
          gradient1 layout1 generatorOutputDevice dataType1 shape1,
        Generator generatorOutputDevice))
 -&gt; IxStateT
      m
      (Generator device2)
      (Generator generatorOutputDevice)
      (Tensor gradient1 layout1 generatorOutputDevice dataType1 shape1))
-&gt; (Tensor gradient1 layout1 device1 dataType1 shape1
    -&gt; Generator device2
    -&gt; m (Tensor
            gradient1 layout1 generatorOutputDevice dataType1 shape1,
          Generator generatorOutputDevice))
-&gt; Tensor gradient1 layout1 device1 dataType1 shape1
-&gt; IxStateT
     m
     (Generator device2)
     (Generator generatorOutputDevice)
     (Tensor gradient1 layout1 generatorOutputDevice dataType1 shape1)
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Dropout
-&gt; Tensor gradient1 layout1 device1 dataType1 shape1
-&gt; Generator device2
-&gt; m (Tensor
        gradient1 layout1 generatorOutputDevice dataType1 shape1,
      Generator generatorOutputDevice)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: Type -&gt; Type).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">Dropout
SADropoutF 'T5
</span><a href="#local-6989586621679806102"><span class="hs-identifier hs-var">saDropout</span></a></span><span>
</span><span id="line-334"></span><span>        </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorOutputDevice)
  (Tensor gradient1 layout1 generatorOutputDevice dataType1 shape1)
-&gt; (Tensor gradient1 layout1 generatorOutputDevice dataType1 shape1
    -&gt; IxStateT
         m
         (Generator generatorOutputDevice)
         (Generator generatorOutputDevice)
         output)
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorOutputDevice)
     output
forall k1 (m :: k1 -&gt; k1 -&gt; Type -&gt; Type) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">output
-&gt; IxStateT
     m
     (Generator generatorOutputDevice)
     (Generator generatorOutputDevice)
     output
forall k (m :: k -&gt; k -&gt; Type -&gt; Type) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">(output
 -&gt; IxStateT
      m
      (Generator generatorOutputDevice)
      (Generator generatorOutputDevice)
      output)
-&gt; (Tensor gradient1 layout1 generatorOutputDevice dataType1 shape1
    -&gt; output)
-&gt; Tensor gradient1 layout1 generatorOutputDevice dataType1 shape1
-&gt; IxStateT
     m
     (Generator generatorOutputDevice)
     (Generator generatorOutputDevice)
     output
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">query
Tensor gradient0 layout0 device0 dataType0 shape0
</span><a href="#local-6989586621679806101"><span class="hs-identifier hs-var">query</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient0 layout0 device0 dataType0 shape0
-&gt; Tensor gradient1 layout1 generatorOutputDevice dataType1 shape1
-&gt; Tensor
     (gradient0 &lt;|&gt; gradient1)
     (layout0 &lt;+&gt; layout1)
     (device0 &lt;+&gt; generatorOutputDevice)
     (dataType0 &lt;+&gt; dataType1)
     (BroadcastShapesF shape0 shape1)
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (gradient' :: Gradient RequiresGradient)
       (layout' :: Layout LayoutType) (device' :: Device (DeviceType Nat))
       (dataType' :: DataType DType)
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]).
Tensor gradient layout device dataType shape
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; Tensor
     (gradient &lt;|&gt; gradient')
     (layout &lt;+&gt; layout')
     (device &lt;+&gt; device')
     (dataType &lt;+&gt; dataType')
     (BroadcastShapesF shape shape')
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#add"><span class="hs-operator hs-var">`add`</span></a></span><span class="hs-special">)</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span>
</span><span id="line-335"></span><span>
</span><span id="line-336"></span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#testSA"><span class="hs-identifier hs-type">testSA</span></a></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">IO</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span>
</span><span id="line-337"></span><span id="testSA"><span class="annot"><span class="annottext">testSA :: IO
  (Tensor
     ('Gradient 'WithGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     ('DataType 'Float)
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 4),
           'Dim ('Name &quot;*&quot;) ('Size 512)]))
</span><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#testSA"><span class="hs-identifier hs-var hs-var">testSA</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-338"></span><span>  </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679806097"><span class="annot"><span class="annottext">gradient :: SGradient ('Gradient 'WithGradient)
</span><a href="#local-6989586621679806097"><span class="hs-identifier hs-var hs-var">gradient</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SRequiresGradient 'WithGradient
-&gt; SGradient ('Gradient 'WithGradient)
forall (requiresGradient :: RequiresGradient).
SRequiresGradient requiresGradient
-&gt; SGradient ('Gradient requiresGradient)
</span><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier hs-var">SGradient</span></a></span><span> </span><span class="annot"><span class="annottext">SRequiresGradient 'WithGradient
</span><a href="Torch.GraduallyTyped.RequiresGradient.html#SWithGradient"><span class="hs-identifier hs-var">SWithGradient</span></a></span><span>
</span><span id="line-339"></span><span>      </span><span id="local-6989586621679806094"><span class="annot"><span class="annottext">device :: SDevice ('Device 'CPU)
</span><a href="#local-6989586621679806094"><span class="hs-identifier hs-var hs-var">device</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SDeviceType 'CPU -&gt; SDevice ('Device 'CPU)
forall (deviceType :: DeviceType Nat).
SDeviceType deviceType -&gt; SDevice ('Device deviceType)
</span><a href="Torch.GraduallyTyped.Device.html#SDevice"><span class="hs-identifier hs-var">SDevice</span></a></span><span> </span><span class="annot"><span class="annottext">SDeviceType 'CPU
</span><a href="Torch.GraduallyTyped.Device.html#SCPU"><span class="hs-identifier hs-var">SCPU</span></a></span><span>
</span><span id="line-340"></span><span>      </span><span id="local-6989586621679806091"><span class="annot"><span class="annottext">generatorDevice :: SDevice 'UncheckedDevice
</span><a href="#local-6989586621679806091"><span class="hs-identifier hs-var hs-var">generatorDevice</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">DeviceType Int16 -&gt; SDevice 'UncheckedDevice
</span><a href="Torch.GraduallyTyped.Device.html#SUncheckedDevice"><span class="hs-identifier hs-var">SUncheckedDevice</span></a></span><span> </span><span class="annot"><span class="annottext">DeviceType Int16
forall deviceId. DeviceType deviceId
</span><a href="Torch.GraduallyTyped.Device.html#CPU"><span class="hs-identifier hs-var">CPU</span></a></span><span>
</span><span id="line-341"></span><span>      </span><span id="local-6989586621679806089"><span class="annot"><span class="annottext">dataType :: SDataType ('DataType 'Float)
</span><a href="#local-6989586621679806089"><span class="hs-identifier hs-var hs-var">dataType</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SDType 'Float -&gt; SDataType ('DataType 'Float)
forall (dType :: DType).
SDType dType -&gt; SDataType ('DataType dType)
</span><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier hs-var">SDataType</span></a></span><span> </span><span class="annot"><span class="annottext">SDType 'Float
</span><a href="Torch.GraduallyTyped.DType.html#SFloat"><span class="hs-identifier hs-var">SFloat</span></a></span><span>
</span><span id="line-342"></span><span>      </span><span id="local-6989586621679806086"><span class="annot"><span class="annottext">headDim :: SDim ('Dim ('Name &quot;*&quot;) ('Size 8))
</span><a href="#local-6989586621679806086"><span class="hs-identifier hs-var hs-var">headDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize ('Size 8) -&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 8))
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownNat 8 =&gt; SSize ('Size 8)
forall (size :: Nat). KnownNat size =&gt; SSize ('Size size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier hs-var">SSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">8</span></span><span>
</span><span id="line-343"></span><span>      </span><span id="local-6989586621679806083"><span class="annot"><span class="annottext">headEmbedDim :: SDim ('Dim ('Name &quot;*&quot;) ('Size 64))
</span><a href="#local-6989586621679806083"><span class="hs-identifier hs-var hs-var">headEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize ('Size 64) -&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 64))
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownNat 64 =&gt; SSize ('Size 64)
forall (size :: Nat). KnownNat size =&gt; SSize ('Size size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier hs-var">SSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">64</span></span><span>
</span><span id="line-344"></span><span>      </span><span id="local-6989586621679806082"><span class="annot"><span class="annottext">embedDim :: SDim ('Dim ('Name &quot;*&quot;) ('Size 512))
</span><a href="#local-6989586621679806082"><span class="hs-identifier hs-var hs-var">embedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize ('Size 512) -&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 512))
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownNat 512 =&gt; SSize ('Size 512)
forall (size :: Nat). KnownNat size =&gt; SSize ('Size size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier hs-var">SSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">512</span></span><span>
</span><span id="line-345"></span><span>      </span><span id="local-6989586621679806081"><span class="annot"><span class="annottext">queryEmbedDim :: SDim ('Dim ('Name &quot;*&quot;) ('Size 512))
</span><a href="#local-6989586621679806081"><span class="hs-identifier hs-var hs-var">queryEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize ('Size 512) -&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 512))
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownNat 512 =&gt; SSize ('Size 512)
forall (size :: Nat). KnownNat size =&gt; SSize ('Size size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier hs-var">SSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">512</span></span><span>
</span><span id="line-346"></span><span>      </span><span id="local-6989586621679806080"><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679806080"><span class="hs-identifier hs-var">dropoutP</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Double
</span><span class="hs-number">0.0</span></span><span>
</span><span id="line-347"></span><span>      </span><span id="local-6989586621679806079"><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679806079"><span class="hs-identifier hs-var">eps</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Double
</span><span class="hs-number">1e-6</span></span><span>
</span><span id="line-348"></span><span>  </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679806078"><span class="annot"><span class="annottext">g :: Generator 'UncheckedDevice
</span><a href="#local-6989586621679806078"><span class="hs-identifier hs-var hs-var">g</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SDevice 'UncheckedDevice -&gt; Word64 -&gt; Generator 'UncheckedDevice
forall (device :: Device (DeviceType Nat)).
SDevice device -&gt; Word64 -&gt; Generator device
</span><a href="Torch.GraduallyTyped.Random.html#sMkGenerator"><span class="hs-identifier hs-var">sMkGenerator</span></a></span><span> </span><span class="annot"><span class="annottext">SDevice 'UncheckedDevice
</span><a href="#local-6989586621679806091"><span class="hs-identifier hs-var">generatorDevice</span></a></span><span> </span><span class="annot"><span class="annottext">Word64
</span><span class="hs-number">0</span></span><span>
</span><span id="line-349"></span><span>  </span><span class="hs-special">(</span><span id="local-6989586621679806077"><span class="annot"><span class="annottext">SelfAttention
  'T5
  ('Gradient 'WithGradient)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Dim ('Name &quot;*&quot;) ('Size 8))
  ('Dim ('Name &quot;*&quot;) ('Size 64))
  ('Dim ('Name &quot;*&quot;) ('Size 512))
  ('Dim ('Name &quot;*&quot;) ('Size 512))
</span><a href="#local-6989586621679806077"><span class="hs-identifier hs-var">sa</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679806076"><span class="annot"><span class="annottext">Generator ('Device 'CPU)
</span><a href="#local-6989586621679806076"><span class="hs-identifier hs-var">g'</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">&lt;-</span><span>
</span><span id="line-350"></span><span>    </span><span class="annot"><span class="annottext">ModelSpec
  (SelfAttention
     'T5
     ('Gradient 'WithGradient)
     ('Device 'CPU)
     ('DataType 'Float)
     ('Dim ('Name &quot;*&quot;) ('Size 8))
     ('Dim ('Name &quot;*&quot;) ('Size 64))
     ('Dim ('Name &quot;*&quot;) ('Size 512))
     ('Dim ('Name &quot;*&quot;) ('Size 512)))
-&gt; Generator 'UncheckedDevice
-&gt; IO
     (SelfAttention
        'T5
        ('Gradient 'WithGradient)
        ('Device 'CPU)
        ('DataType 'Float)
        ('Dim ('Name &quot;*&quot;) ('Size 8))
        ('Dim ('Name &quot;*&quot;) ('Size 64))
        ('Dim ('Name &quot;*&quot;) ('Size 512))
        ('Dim ('Name &quot;*&quot;) ('Size 512)),
      Generator ('Device 'CPU))
forall model (generatorDevice :: Device (DeviceType Nat)) output
       (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: Type -&gt; Type).
(HasInitialize model generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
ModelSpec model
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#initialize"><span class="hs-identifier hs-var">initialize</span></a></span><span>
</span><span id="line-351"></span><span>      </span><span class="hs-special">(</span><span class="annot"><span class="annottext">STransformerStyle 'T5
-&gt; SGradient ('Gradient 'WithGradient)
-&gt; SDevice ('Device 'CPU)
-&gt; SDataType ('DataType 'Float)
-&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 8))
-&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 64))
-&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 512))
-&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 512))
-&gt; Double
-&gt; Double
-&gt; SelfAttentionSpec
     'T5
     ('Gradient 'WithGradient)
     ('Device 'CPU)
     ('DataType 'Float)
     ('Dim ('Name &quot;*&quot;) ('Size 8))
     ('Dim ('Name &quot;*&quot;) ('Size 64))
     ('Dim ('Name &quot;*&quot;) ('Size 512))
     ('Dim ('Name &quot;*&quot;) ('Size 512))
forall (style :: TransformerStyle)
       (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (headDim :: Dim (Name Symbol) (Size Nat))
       (headEmbedDim :: Dim (Name Symbol) (Size Nat))
       (embedDim :: Dim (Name Symbol) (Size Nat))
       (queryEmbedDim :: Dim (Name Symbol) (Size Nat)).
STransformerStyle style
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim headDim
-&gt; SDim headEmbedDim
-&gt; SDim embedDim
-&gt; SDim queryEmbedDim
-&gt; Double
-&gt; Double
-&gt; SelfAttentionSpec
     style
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
</span><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#SelfAttentionSpec"><span class="hs-identifier hs-var">SelfAttentionSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle 'T5
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="annot"><span class="annottext">SGradient ('Gradient 'WithGradient)
</span><a href="#local-6989586621679806097"><span class="hs-identifier hs-var">gradient</span></a></span><span> </span><span class="annot"><span class="annottext">SDevice ('Device 'CPU)
</span><a href="#local-6989586621679806094"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType ('DataType 'Float)
</span><a href="#local-6989586621679806089"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 8))
</span><a href="#local-6989586621679806086"><span class="hs-identifier hs-var">headDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 64))
</span><a href="#local-6989586621679806083"><span class="hs-identifier hs-var">headEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 512))
</span><a href="#local-6989586621679806082"><span class="hs-identifier hs-var">embedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 512))
</span><a href="#local-6989586621679806081"><span class="hs-identifier hs-var">queryEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679806080"><span class="hs-identifier hs-var">dropoutP</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679806079"><span class="hs-identifier hs-var">eps</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-352"></span><span>      </span><span class="annot"><span class="annottext">Generator 'UncheckedDevice
</span><a href="#local-6989586621679806078"><span class="hs-identifier hs-var">g</span></a></span><span>
</span><span id="line-353"></span><span>  </span><span id="local-6989586621679806075"><span class="annot"><span class="annottext">SelfAttention
  'T5
  ('Gradient 'WithGradient)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Dim ('Name &quot;*&quot;) ('Size 8))
  ('Dim ('Name &quot;*&quot;) ('Size 64))
  ('Dim ('Name &quot;*&quot;) ('Size 512))
  ('Dim ('Name &quot;*&quot;) ('Size 512))
</span><a href="#local-6989586621679806075"><span class="hs-identifier hs-var">sa'</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">(StateT
   StateDict
   IO
   (SelfAttention
      'T5
      ('Gradient 'WithGradient)
      ('Device 'CPU)
      ('DataType 'Float)
      ('Dim ('Name &quot;*&quot;) ('Size 8))
      ('Dim ('Name &quot;*&quot;) ('Size 64))
      ('Dim ('Name &quot;*&quot;) ('Size 512))
      ('Dim ('Name &quot;*&quot;) ('Size 512)))
 -&gt; StateDict
 -&gt; IO
      (SelfAttention
         'T5
         ('Gradient 'WithGradient)
         ('Device 'CPU)
         ('DataType 'Float)
         ('Dim ('Name &quot;*&quot;) ('Size 8))
         ('Dim ('Name &quot;*&quot;) ('Size 64))
         ('Dim ('Name &quot;*&quot;) ('Size 512))
         ('Dim ('Name &quot;*&quot;) ('Size 512))))
-&gt; StateDict
-&gt; StateT
     StateDict
     IO
     (SelfAttention
        'T5
        ('Gradient 'WithGradient)
        ('Device 'CPU)
        ('DataType 'Float)
        ('Dim ('Name &quot;*&quot;) ('Size 8))
        ('Dim ('Name &quot;*&quot;) ('Size 64))
        ('Dim ('Name &quot;*&quot;) ('Size 512))
        ('Dim ('Name &quot;*&quot;) ('Size 512)))
-&gt; IO
     (SelfAttention
        'T5
        ('Gradient 'WithGradient)
        ('Device 'CPU)
        ('DataType 'Float)
        ('Dim ('Name &quot;*&quot;) ('Size 8))
        ('Dim ('Name &quot;*&quot;) ('Size 64))
        ('Dim ('Name &quot;*&quot;) ('Size 512))
        ('Dim ('Name &quot;*&quot;) ('Size 512)))
forall a b c. (a -&gt; b -&gt; c) -&gt; b -&gt; a -&gt; c
</span><span class="hs-identifier hs-var">flip</span></span><span> </span><span class="annot"><span class="annottext">StateT
  StateDict
  IO
  (SelfAttention
     'T5
     ('Gradient 'WithGradient)
     ('Device 'CPU)
     ('DataType 'Float)
     ('Dim ('Name &quot;*&quot;) ('Size 8))
     ('Dim ('Name &quot;*&quot;) ('Size 64))
     ('Dim ('Name &quot;*&quot;) ('Size 512))
     ('Dim ('Name &quot;*&quot;) ('Size 512)))
-&gt; StateDict
-&gt; IO
     (SelfAttention
        'T5
        ('Gradient 'WithGradient)
        ('Device 'CPU)
        ('DataType 'Float)
        ('Dim ('Name &quot;*&quot;) ('Size 8))
        ('Dim ('Name &quot;*&quot;) ('Size 64))
        ('Dim ('Name &quot;*&quot;) ('Size 512))
        ('Dim ('Name &quot;*&quot;) ('Size 512)))
forall (m :: Type -&gt; Type) s a. Monad m =&gt; StateT s m a -&gt; s -&gt; m a
</span><span class="hs-identifier hs-var">evalStateT</span></span><span> </span><span class="annot"><span class="annottext">StateDict
forall k a. Map k a
</span><span class="hs-identifier hs-var">Map.empty</span></span><span> </span><span class="annot"><span class="annottext">(StateT
   StateDict
   IO
   (SelfAttention
      'T5
      ('Gradient 'WithGradient)
      ('Device 'CPU)
      ('DataType 'Float)
      ('Dim ('Name &quot;*&quot;) ('Size 8))
      ('Dim ('Name &quot;*&quot;) ('Size 64))
      ('Dim ('Name &quot;*&quot;) ('Size 512))
      ('Dim ('Name &quot;*&quot;) ('Size 512)))
 -&gt; IO
      (SelfAttention
         'T5
         ('Gradient 'WithGradient)
         ('Device 'CPU)
         ('DataType 'Float)
         ('Dim ('Name &quot;*&quot;) ('Size 8))
         ('Dim ('Name &quot;*&quot;) ('Size 64))
         ('Dim ('Name &quot;*&quot;) ('Size 512))
         ('Dim ('Name &quot;*&quot;) ('Size 512))))
-&gt; StateT
     StateDict
     IO
     (SelfAttention
        'T5
        ('Gradient 'WithGradient)
        ('Device 'CPU)
        ('DataType 'Float)
        ('Dim ('Name &quot;*&quot;) ('Size 8))
        ('Dim ('Name &quot;*&quot;) ('Size 64))
        ('Dim ('Name &quot;*&quot;) ('Size 512))
        ('Dim ('Name &quot;*&quot;) ('Size 512)))
-&gt; IO
     (SelfAttention
        'T5
        ('Gradient 'WithGradient)
        ('Device 'CPU)
        ('DataType 'Float)
        ('Dim ('Name &quot;*&quot;) ('Size 8))
        ('Dim ('Name &quot;*&quot;) ('Size 64))
        ('Dim ('Name &quot;*&quot;) ('Size 512))
        ('Dim ('Name &quot;*&quot;) ('Size 512)))
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-354"></span><span>    </span><span class="annot"><span class="annottext">StateDictKey
-&gt; SelfAttention
     'T5
     ('Gradient 'WithGradient)
     ('Device 'CPU)
     ('DataType 'Float)
     ('Dim ('Name &quot;*&quot;) ('Size 8))
     ('Dim ('Name &quot;*&quot;) ('Size 64))
     ('Dim ('Name &quot;*&quot;) ('Size 512))
     ('Dim ('Name &quot;*&quot;) ('Size 512))
-&gt; StateT StateDict IO ()
forall model (m :: Type -&gt; Type).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;sa.&quot;</span></span><span> </span><span class="annot"><span class="annottext">SelfAttention
  'T5
  ('Gradient 'WithGradient)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Dim ('Name &quot;*&quot;) ('Size 8))
  ('Dim ('Name &quot;*&quot;) ('Size 64))
  ('Dim ('Name &quot;*&quot;) ('Size 512))
  ('Dim ('Name &quot;*&quot;) ('Size 512))
</span><a href="#local-6989586621679806077"><span class="hs-identifier hs-var">sa</span></a></span><span>
</span><span id="line-355"></span><span>    </span><span class="annot"><span class="annottext">ModelSpec
  (SelfAttention
     'T5
     ('Gradient 'WithGradient)
     ('Device 'CPU)
     ('DataType 'Float)
     ('Dim ('Name &quot;*&quot;) ('Size 8))
     ('Dim ('Name &quot;*&quot;) ('Size 64))
     ('Dim ('Name &quot;*&quot;) ('Size 512))
     ('Dim ('Name &quot;*&quot;) ('Size 512)))
-&gt; StateDictKey
-&gt; StateT
     StateDict
     IO
     (SelfAttention
        'T5
        ('Gradient 'WithGradient)
        ('Device 'CPU)
        ('DataType 'Float)
        ('Dim ('Name &quot;*&quot;) ('Size 8))
        ('Dim ('Name &quot;*&quot;) ('Size 64))
        ('Dim ('Name &quot;*&quot;) ('Size 512))
        ('Dim ('Name &quot;*&quot;) ('Size 512)))
forall model (m :: Type -&gt; Type).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
ModelSpec model -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span>
</span><span id="line-356"></span><span>      </span><span class="hs-special">(</span><span class="annot"><span class="annottext">STransformerStyle 'T5
-&gt; SGradient ('Gradient 'WithGradient)
-&gt; SDevice ('Device 'CPU)
-&gt; SDataType ('DataType 'Float)
-&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 8))
-&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 64))
-&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 512))
-&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 512))
-&gt; Double
-&gt; Double
-&gt; SelfAttentionSpec
     'T5
     ('Gradient 'WithGradient)
     ('Device 'CPU)
     ('DataType 'Float)
     ('Dim ('Name &quot;*&quot;) ('Size 8))
     ('Dim ('Name &quot;*&quot;) ('Size 64))
     ('Dim ('Name &quot;*&quot;) ('Size 512))
     ('Dim ('Name &quot;*&quot;) ('Size 512))
forall (style :: TransformerStyle)
       (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (headDim :: Dim (Name Symbol) (Size Nat))
       (headEmbedDim :: Dim (Name Symbol) (Size Nat))
       (embedDim :: Dim (Name Symbol) (Size Nat))
       (queryEmbedDim :: Dim (Name Symbol) (Size Nat)).
STransformerStyle style
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim headDim
-&gt; SDim headEmbedDim
-&gt; SDim embedDim
-&gt; SDim queryEmbedDim
-&gt; Double
-&gt; Double
-&gt; SelfAttentionSpec
     style
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
</span><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#SelfAttentionSpec"><span class="hs-identifier hs-var">SelfAttentionSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle 'T5
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="annot"><span class="annottext">SGradient ('Gradient 'WithGradient)
</span><a href="#local-6989586621679806097"><span class="hs-identifier hs-var">gradient</span></a></span><span> </span><span class="annot"><span class="annottext">SDevice ('Device 'CPU)
</span><a href="#local-6989586621679806094"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType ('DataType 'Float)
</span><a href="#local-6989586621679806089"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 8))
</span><a href="#local-6989586621679806086"><span class="hs-identifier hs-var">headDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 64))
</span><a href="#local-6989586621679806083"><span class="hs-identifier hs-var">headEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 512))
</span><a href="#local-6989586621679806082"><span class="hs-identifier hs-var">embedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 512))
</span><a href="#local-6989586621679806081"><span class="hs-identifier hs-var">queryEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679806080"><span class="hs-identifier hs-var">dropoutP</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679806079"><span class="hs-identifier hs-var">eps</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-357"></span><span>      </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;sa.&quot;</span></span><span>
</span><span id="line-358"></span><span>  </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679806072"><span class="annot"><span class="annottext">batchDim :: SDim ('Dim ('Name &quot;*&quot;) ('Size 1))
</span><a href="#local-6989586621679806072"><span class="hs-identifier hs-var hs-var">batchDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize ('Size 1) -&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 1))
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownNat 1 =&gt; SSize ('Size 1)
forall (size :: Nat). KnownNat size =&gt; SSize ('Size size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier hs-var">SSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">1</span></span><span>
</span><span id="line-359"></span><span>      </span><span id="local-6989586621679806071"><span class="annot"><span class="annottext">seqDim :: SDim ('Dim ('Name &quot;*&quot;) ('Size 4))
</span><a href="#local-6989586621679806071"><span class="hs-identifier hs-var hs-var">seqDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize ('Size 4) -&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 4))
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownNat 4 =&gt; SSize ('Size 4)
forall (size :: Nat). KnownNat size =&gt; SSize ('Size size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier hs-var">SSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">4</span></span><span>
</span><span id="line-360"></span><span>      </span><span id="local-6989586621679806070"><span class="annot"><span class="annottext">sOnes' :: SDataType dataType
-&gt; SShape shape
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     dataType
     shape
</span><a href="#local-6989586621679806070"><span class="hs-identifier hs-var hs-var">sOnes'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">TensorSpec
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  dataType
  shape
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     dataType
     shape
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
TensorSpec gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.Creation.html#sOnes"><span class="hs-identifier hs-var">sOnes</span></a></span><span> </span><span class="annot"><span class="annottext">(TensorSpec
   ('Gradient 'WithoutGradient)
   ('Layout 'Dense)
   ('Device 'CPU)
   dataType
   shape
 -&gt; Tensor
      ('Gradient 'WithoutGradient)
      ('Layout 'Dense)
      ('Device 'CPU)
      dataType
      shape)
-&gt; (SShape shape
    -&gt; TensorSpec
         ('Gradient 'WithoutGradient)
         ('Layout 'Dense)
         ('Device 'CPU)
         dataType
         shape)
-&gt; SShape shape
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     dataType
     shape
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">((SShape shape
  -&gt; TensorSpec
       ('Gradient 'WithoutGradient)
       ('Layout 'Dense)
       ('Device 'CPU)
       dataType
       shape)
 -&gt; SShape shape
 -&gt; Tensor
      ('Gradient 'WithoutGradient)
      ('Layout 'Dense)
      ('Device 'CPU)
      dataType
      shape)
-&gt; (SDataType dataType
    -&gt; SShape shape
    -&gt; TensorSpec
         ('Gradient 'WithoutGradient)
         ('Layout 'Dense)
         ('Device 'CPU)
         dataType
         shape)
-&gt; SDataType dataType
-&gt; SShape shape
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     dataType
     shape
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">SGradient ('Gradient 'WithoutGradient)
-&gt; SLayout ('Layout 'Dense)
-&gt; SDevice ('Device 'CPU)
-&gt; SDataType dataType
-&gt; SShape shape
-&gt; TensorSpec
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     dataType
     shape
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SShape shape
-&gt; TensorSpec gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorSpec"><span class="hs-identifier hs-var">TensorSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SRequiresGradient 'WithoutGradient
-&gt; SGradient ('Gradient 'WithoutGradient)
forall (requiresGradient :: RequiresGradient).
SRequiresGradient requiresGradient
-&gt; SGradient ('Gradient requiresGradient)
</span><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier hs-var">SGradient</span></a></span><span> </span><span class="annot"><span class="annottext">SRequiresGradient 'WithoutGradient
</span><a href="Torch.GraduallyTyped.RequiresGradient.html#SWithoutGradient"><span class="hs-identifier hs-var">SWithoutGradient</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SLayoutType 'Dense -&gt; SLayout ('Layout 'Dense)
forall (layoutType :: LayoutType).
SLayoutType layoutType -&gt; SLayout ('Layout layoutType)
</span><a href="Torch.GraduallyTyped.Layout.html#SLayout"><span class="hs-identifier hs-var">SLayout</span></a></span><span> </span><span class="annot"><span class="annottext">SLayoutType 'Dense
</span><a href="Torch.GraduallyTyped.Layout.html#SDense"><span class="hs-identifier hs-var">SDense</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">SDevice ('Device 'CPU)
</span><a href="#local-6989586621679806094"><span class="hs-identifier hs-var">device</span></a></span><span>
</span><span id="line-361"></span><span>      </span><span id="local-6989586621679806065"><span class="annot"><span class="annottext">query :: Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 4),
        'Dim ('Name &quot;*&quot;) ('Size 512)])
</span><a href="#local-6989586621679806065"><span class="hs-identifier hs-var hs-var">query</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SDataType ('DataType 'Float)
-&gt; SShape
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 4),
           'Dim ('Name &quot;*&quot;) ('Size 512)])
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     ('DataType 'Float)
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 4),
           'Dim ('Name &quot;*&quot;) ('Size 512)])
forall (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SDataType dataType
-&gt; SShape shape
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     dataType
     shape
</span><a href="#local-6989586621679806070"><span class="hs-identifier hs-var">sOnes'</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType ('DataType 'Float)
</span><a href="#local-6989586621679806089"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SList
  '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 4),
     'Dim ('Name &quot;*&quot;) ('Size 512)]
-&gt; SShape
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 4),
           'Dim ('Name &quot;*&quot;) ('Size 512)])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList
   '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 4),
      'Dim ('Name &quot;*&quot;) ('Size 512)]
 -&gt; SShape
      ('Shape
         '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 4),
            'Dim ('Name &quot;*&quot;) ('Size 512)]))
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 4),
        'Dim ('Name &quot;*&quot;) ('Size 512)]
-&gt; SShape
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 4),
           'Dim ('Name &quot;*&quot;) ('Size 512)])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 1))
</span><a href="#local-6989586621679806072"><span class="hs-identifier hs-var">batchDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 1))
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 4), 'Dim ('Name &quot;*&quot;) ('Size 512)]
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 4),
        'Dim ('Name &quot;*&quot;) ('Size 512)]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 4))
</span><a href="#local-6989586621679806071"><span class="hs-identifier hs-var">seqDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 4))
-&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 512)]
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 4), 'Dim ('Name &quot;*&quot;) ('Size 512)]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 512))
</span><a href="#local-6989586621679806081"><span class="hs-identifier hs-var">queryEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 512))
-&gt; SList '[] -&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 512)]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-362"></span><span>      </span><span id="local-6989586621679806064"><span class="annot"><span class="annottext">attentionBias :: Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 1),
        'Dim ('Name &quot;*&quot;) ('Size 4), 'Dim ('Name &quot;*&quot;) ('Size 4)])
</span><a href="#local-6989586621679806064"><span class="hs-identifier hs-var hs-var">attentionBias</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SDataType ('DataType 'Float)
-&gt; SShape
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 1),
           'Dim ('Name &quot;*&quot;) ('Size 4), 'Dim ('Name &quot;*&quot;) ('Size 4)])
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     ('DataType 'Float)
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 1),
           'Dim ('Name &quot;*&quot;) ('Size 4), 'Dim ('Name &quot;*&quot;) ('Size 4)])
forall (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SDataType dataType
-&gt; SShape shape
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     dataType
     shape
</span><a href="#local-6989586621679806070"><span class="hs-identifier hs-var">sOnes'</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType ('DataType 'Float)
</span><a href="#local-6989586621679806089"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SList
  '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 1),
     'Dim ('Name &quot;*&quot;) ('Size 4), 'Dim ('Name &quot;*&quot;) ('Size 4)]
-&gt; SShape
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 1),
           'Dim ('Name &quot;*&quot;) ('Size 4), 'Dim ('Name &quot;*&quot;) ('Size 4)])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList
   '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 1),
      'Dim ('Name &quot;*&quot;) ('Size 4), 'Dim ('Name &quot;*&quot;) ('Size 4)]
 -&gt; SShape
      ('Shape
         '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 1),
            'Dim ('Name &quot;*&quot;) ('Size 4), 'Dim ('Name &quot;*&quot;) ('Size 4)]))
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 1),
        'Dim ('Name &quot;*&quot;) ('Size 4), 'Dim ('Name &quot;*&quot;) ('Size 4)]
-&gt; SShape
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 1),
           'Dim ('Name &quot;*&quot;) ('Size 4), 'Dim ('Name &quot;*&quot;) ('Size 4)])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 1))
</span><a href="#local-6989586621679806072"><span class="hs-identifier hs-var">batchDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 1))
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 4),
        'Dim ('Name &quot;*&quot;) ('Size 4)]
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 1),
        'Dim ('Name &quot;*&quot;) ('Size 4), 'Dim ('Name &quot;*&quot;) ('Size 4)]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize ('Size 1) -&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 1))
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownNat 1 =&gt; SSize ('Size 1)
forall (size :: Nat). KnownNat size =&gt; SSize ('Size size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier hs-var">SSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">1</span></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 1))
-&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 4), 'Dim ('Name &quot;*&quot;) ('Size 4)]
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 4),
        'Dim ('Name &quot;*&quot;) ('Size 4)]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 4))
</span><a href="#local-6989586621679806071"><span class="hs-identifier hs-var">seqDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 4))
-&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 4)]
-&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 4), 'Dim ('Name &quot;*&quot;) ('Size 4)]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 4))
</span><a href="#local-6989586621679806071"><span class="hs-identifier hs-var">seqDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 4))
-&gt; SList '[] -&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 4)]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-363"></span><span>  </span><span class="hs-special">(</span><span id="local-6989586621679806063"><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 4),
        'Dim ('Name &quot;*&quot;) ('Size 512)])
</span><a href="#local-6989586621679806063"><span class="hs-identifier hs-var">output</span></a></span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Generator ('Device 'CPU)
</span><span class="hs-identifier">_</span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">SelfAttention
  'T5
  ('Gradient 'WithGradient)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Dim ('Name &quot;*&quot;) ('Size 8))
  ('Dim ('Name &quot;*&quot;) ('Size 64))
  ('Dim ('Name &quot;*&quot;) ('Size 512))
  ('Dim ('Name &quot;*&quot;) ('Size 512))
-&gt; (Tensor
      ('Gradient 'WithoutGradient)
      ('Layout 'Dense)
      ('Device 'CPU)
      ('DataType 'Float)
      ('Shape
         '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 4),
            'Dim ('Name &quot;*&quot;) ('Size 512)]),
    Tensor
      ('Gradient 'WithoutGradient)
      ('Layout 'Dense)
      ('Device 'CPU)
      ('DataType 'Float)
      ('Shape
         '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 1),
            'Dim ('Name &quot;*&quot;) ('Size 4), 'Dim ('Name &quot;*&quot;) ('Size 4)]))
-&gt; Generator ('Device 'CPU)
-&gt; IO
     (Tensor
        ('Gradient 'WithGradient)
        ('Layout 'Dense)
        ('Device 'CPU)
        ('DataType 'Float)
        ('Shape
           '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 4),
              'Dim ('Name &quot;*&quot;) ('Size 512)]),
      Generator ('Device 'CPU))
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: Type -&gt; Type).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">SelfAttention
  'T5
  ('Gradient 'WithGradient)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Dim ('Name &quot;*&quot;) ('Size 8))
  ('Dim ('Name &quot;*&quot;) ('Size 64))
  ('Dim ('Name &quot;*&quot;) ('Size 512))
  ('Dim ('Name &quot;*&quot;) ('Size 512))
</span><a href="#local-6989586621679806075"><span class="hs-identifier hs-var">sa'</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 4),
        'Dim ('Name &quot;*&quot;) ('Size 512)])
</span><a href="#local-6989586621679806065"><span class="hs-identifier hs-var">query</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 1),
        'Dim ('Name &quot;*&quot;) ('Size 4), 'Dim ('Name &quot;*&quot;) ('Size 4)])
</span><a href="#local-6989586621679806064"><span class="hs-identifier hs-var">attentionBias</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Generator ('Device 'CPU)
</span><a href="#local-6989586621679806076"><span class="hs-identifier hs-var">g'</span></a></span><span>
</span><span id="line-364"></span><span>  </span><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 4),
        'Dim ('Name &quot;*&quot;) ('Size 512)])
-&gt; IO
     (Tensor
        ('Gradient 'WithGradient)
        ('Layout 'Dense)
        ('Device 'CPU)
        ('DataType 'Float)
        ('Shape
           '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 4),
              'Dim ('Name &quot;*&quot;) ('Size 512)]))
forall (f :: Type -&gt; Type) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 4),
        'Dim ('Name &quot;*&quot;) ('Size 512)])
</span><a href="#local-6989586621679806063"><span class="hs-identifier hs-var">output</span></a></span><span>
</span><span id="line-365"></span><span>
</span><span id="line-366"></span><span class="hs-comment">-- | 'HasForward' instance for @SelfAttention 'ByT5@.</span><span>
</span><span id="line-367"></span><span class="hs-comment">--</span><span>
</span><span id="line-368"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-369"></span><span class="hs-comment">-- &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;     &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;</span><span>
</span><span id="line-370"></span><span class="hs-comment">-- &#9474; attentionBias &#9474;     &#9474; query &#9474;</span><span>
</span><span id="line-371"></span><span class="hs-comment">-- &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;     &#9492;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-372"></span><span class="hs-comment">--         &#9474;                 &#9474;</span><span>
</span><span id="line-373"></span><span class="hs-comment">--         &#9474;           &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9524;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;</span><span>
</span><span id="line-374"></span><span class="hs-comment">--         &#9474;           &#9474;           &#9474;</span><span>
</span><span id="line-375"></span><span class="hs-comment">--         &#9474;           &#9660;           &#9474;</span><span>
</span><span id="line-376"></span><span class="hs-comment">--         &#9474;      saLayerNorm      &#9474;</span><span>
</span><span id="line-377"></span><span class="hs-comment">--         &#9474;           &#9474;           &#9474;</span><span>
</span><span id="line-378"></span><span class="hs-comment">--         &#9474;      &#9484;&#9472;&#9472;&#9472;&#9472;&#9532;&#9472;&#9472;&#9472;&#9472;&#9488;      &#9474;</span><span>
</span><span id="line-379"></span><span class="hs-comment">--         &#9474;      &#9474;    &#9474;    &#9474;      &#9474;</span><span>
</span><span id="line-380"></span><span class="hs-comment">--         &#9474;      &#9660;    &#9660;    &#9660;      &#9474;</span><span>
</span><span id="line-381"></span><span class="hs-comment">--         &#9492;&#9472;&#9658;saMultiHeadAttention &#9474;</span><span>
</span><span id="line-382"></span><span class="hs-comment">--                     &#9474;           &#9474;</span><span>
</span><span id="line-383"></span><span class="hs-comment">--                     &#9660;           &#9474;</span><span>
</span><span id="line-384"></span><span class="hs-comment">--                 saDropout       &#9474;</span><span>
</span><span id="line-385"></span><span class="hs-comment">--                     &#9474;           &#9474;</span><span>
</span><span id="line-386"></span><span class="hs-comment">--                     &#9492;&#9472;&#9472;&#9472;&#9658;add&#9668;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-387"></span><span class="hs-comment">--                           &#9474;</span><span>
</span><span id="line-388"></span><span class="hs-comment">--                           &#9660;</span><span>
</span><span id="line-389"></span><span class="hs-comment">--                       &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;</span><span>
</span><span id="line-390"></span><span class="hs-comment">--                       &#9474; query &#9474;</span><span>
</span><span id="line-391"></span><span class="hs-comment">--                       &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-392"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-393"></span><span id="local-6989586621679806038"><span id="local-6989586621679806039"><span id="local-6989586621679806040"><span id="local-6989586621679806041"><span id="local-6989586621679806042"><span id="local-6989586621679806043"><span id="local-6989586621679806044"><span id="local-6989586621679806045"><span id="local-6989586621679806046"><span id="local-6989586621679806047"><span id="local-6989586621679806048"><span id="local-6989586621679806049"><span id="local-6989586621679806050"><span id="local-6989586621679806051"><span id="local-6989586621679806052"><span id="local-6989586621679806053"><span id="local-6989586621679806054"><span id="local-6989586621679806055"><span id="local-6989586621679806056"><span id="local-6989586621679806057"><span id="local-6989586621679806058"><span id="local-6989586621679806059"><span id="local-6989586621679806060"><span id="local-6989586621679806061"><span id="local-6989586621679806062"><span class="hs-keyword">instance</span><span>
</span><span id="line-394"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetDim"><span class="hs-identifier hs-type">SGetDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806062"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-395"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-396"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#SALayerNormF"><span class="hs-identifier hs-type">SALayerNormF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ByT5"><span class="hs-identifier hs-type">ByT5</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806061"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806060"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806059"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806062"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-397"></span><span>      </span><span class="annot"><a href="#local-6989586621679806058"><span class="hs-identifier hs-type">query</span></a></span><span>
</span><span id="line-398"></span><span>      </span><span class="annot"><a href="#local-6989586621679806057"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-399"></span><span>      </span><span class="annot"><a href="#local-6989586621679806056"><span class="hs-identifier hs-type">layerNormOutput</span></a></span><span>
</span><span id="line-400"></span><span>      </span><span class="annot"><a href="#local-6989586621679806057"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-401"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-402"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#SAMultiheadAttentionF"><span class="hs-identifier hs-type">SAMultiheadAttentionF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ByT5"><span class="hs-identifier hs-type">ByT5</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806061"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806060"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806059"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806055"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806054"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806053"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806062"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-403"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679806056"><span class="hs-identifier hs-type">layerNormOutput</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679806056"><span class="hs-identifier hs-type">layerNormOutput</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679806056"><span class="hs-identifier hs-type">layerNormOutput</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679806052"><span class="hs-identifier hs-type">attentionBias</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-404"></span><span>      </span><span class="annot"><a href="#local-6989586621679806057"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-405"></span><span>      </span><span class="annot"><a href="#local-6989586621679806051"><span class="hs-identifier hs-type">mhaOutput</span></a></span><span>
</span><span id="line-406"></span><span>      </span><span class="annot"><a href="#local-6989586621679806050"><span class="hs-identifier hs-type">device2</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-407"></span><span>    </span><span class="annot"><a href="#local-6989586621679806058"><span class="hs-identifier hs-type">query</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806049"><span class="hs-identifier hs-type">gradient0</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806048"><span class="hs-identifier hs-type">layout0</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806047"><span class="hs-identifier hs-type">device0</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806046"><span class="hs-identifier hs-type">dataType0</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806045"><span class="hs-identifier hs-type">shape0</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-408"></span><span>    </span><span class="annot"><a href="#local-6989586621679806051"><span class="hs-identifier hs-type">mhaOutput</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806044"><span class="hs-identifier hs-type">gradient1</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806043"><span class="hs-identifier hs-type">layout1</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806042"><span class="hs-identifier hs-type">device1</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806041"><span class="hs-identifier hs-type">dataType1</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806040"><span class="hs-identifier hs-type">shape1</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-409"></span><span>    </span><span class="annot"><a href="#local-6989586621679806039"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-410"></span><span>      </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-411"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679806049"><span class="hs-identifier hs-type">gradient0</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806044"><span class="hs-identifier hs-type">gradient1</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-412"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679806048"><span class="hs-identifier hs-type">layout0</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806043"><span class="hs-identifier hs-type">layout1</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-413"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679806047"><span class="hs-identifier hs-type">device0</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806042"><span class="hs-identifier hs-type">device1</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806050"><span class="hs-identifier hs-type">device2</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-414"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679806046"><span class="hs-identifier hs-type">dataType0</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806041"><span class="hs-identifier hs-type">dataType1</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-415"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#BroadcastShapesF"><span class="hs-identifier hs-type">BroadcastShapesF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806045"><span class="hs-identifier hs-type">shape0</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806040"><span class="hs-identifier hs-type">shape1</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-416"></span><span>    </span><span class="annot"><a href="#local-6989586621679806038"><span class="hs-identifier hs-type">generatorOutputDevice</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679806042"><span class="hs-identifier hs-type">device1</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806050"><span class="hs-identifier hs-type">device2</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-417"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-418"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-419"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#SelfAttention"><span class="hs-identifier hs-type">SelfAttention</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ByT5"><span class="hs-identifier hs-type">ByT5</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806061"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806060"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806059"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806055"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806054"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806053"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806062"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-420"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679806058"><span class="hs-identifier hs-type">query</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679806052"><span class="hs-identifier hs-type">attentionBias</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-421"></span><span>    </span><span class="annot"><a href="#local-6989586621679806057"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-422"></span><span>    </span><span class="annot"><a href="#local-6989586621679806039"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-423"></span><span>    </span><span class="annot"><a href="#local-6989586621679806038"><span class="hs-identifier hs-type">generatorOutputDevice</span></a></span><span>
</span><span id="line-424"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-425"></span><span>  </span><span id="local-6989586621679806036"><span class="annot"><span class="annottext">forward :: SelfAttention
  'ByT5
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  queryEmbedDim
-&gt; (query, attentionBias)
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="#local-6989586621679806036"><span class="hs-identifier hs-var hs-var hs-var hs-var">forward</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#SelfAttention"><span class="hs-identifier hs-type">SelfAttention</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#GSelfAttention"><span class="hs-identifier hs-type">GSelfAttention</span></a></span><span> </span><span class="hs-special">{</span><span id="local-6989586621679806033"><span id="local-6989586621679806034"><span id="local-6989586621679806035"><span class="annot"><span class="annottext">SADropoutF 'ByT5
SALayerNormF 'ByT5 gradient device dataType queryEmbedDim
SAMultiheadAttentionF
  'ByT5
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  queryEmbedDim
saDropout :: SADropoutF 'ByT5
saLayerNorm :: SALayerNormF 'ByT5 gradient device dataType queryEmbedDim
saMultiHeadAttention :: SAMultiheadAttentionF
  'ByT5
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  queryEmbedDim
saDropout :: forall mha layerNorm dropout.
GSelfAttention mha layerNorm dropout -&gt; dropout
saLayerNorm :: forall mha layerNorm dropout.
GSelfAttention mha layerNorm dropout -&gt; layerNorm
saMultiHeadAttention :: forall mha layerNorm dropout.
GSelfAttention mha layerNorm dropout -&gt; mha
</span><a href="#local-6989586621679806033"><span class="hs-glyph hs-var hs-var hs-var hs-var hs-var hs-var">..</span></a></span></span></span></span><span class="hs-special">}</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679806032"><span class="annot"><span class="annottext">query
</span><a href="#local-6989586621679806032"><span class="hs-identifier hs-var">query</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679806031"><span class="annot"><span class="annottext">attentionBias
</span><a href="#local-6989586621679806031"><span class="hs-identifier hs-var">attentionBias</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-426"></span><span>    </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorOutputDevice)
  output
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
forall (m :: Type -&gt; Type) i j a. IxStateT m i j a -&gt; i -&gt; m (a, j)
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var hs-var">runIxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">(IxStateT
   m
   (Generator generatorDevice)
   (Generator generatorOutputDevice)
   output
 -&gt; Generator generatorDevice
 -&gt; m (output, Generator generatorOutputDevice))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorOutputDevice)
     output
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-427"></span><span>      </span><span class="annot"><span class="annottext">query
-&gt; IxStateT
     m (Generator generatorDevice) (Generator generatorDevice) query
forall k (m :: k -&gt; k -&gt; Type -&gt; Type) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">query
</span><a href="#local-6989586621679806032"><span class="hs-identifier hs-var">query</span></a></span><span>
</span><span id="line-428"></span><span>        </span><span class="annot"><span class="annottext">IxStateT
  m (Generator generatorDevice) (Generator generatorDevice) query
-&gt; (query
    -&gt; IxStateT
         m
         (Generator generatorDevice)
         (Generator generatorDevice)
         layerNormOutput)
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     layerNormOutput
forall k1 (m :: k1 -&gt; k1 -&gt; Type -&gt; Type) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(Generator generatorDevice
 -&gt; m (layerNormOutput, Generator generatorDevice))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     layerNormOutput
forall (m :: Type -&gt; Type) i j a.
(i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator generatorDevice
  -&gt; m (layerNormOutput, Generator generatorDevice))
 -&gt; IxStateT
      m
      (Generator generatorDevice)
      (Generator generatorDevice)
      layerNormOutput)
-&gt; (query
    -&gt; Generator generatorDevice
    -&gt; m (layerNormOutput, Generator generatorDevice))
-&gt; query
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     layerNormOutput
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">LayerNorm
  'WithoutBias gradient device dataType ('Shape '[queryEmbedDim])
-&gt; query
-&gt; Generator generatorDevice
-&gt; m (layerNormOutput, Generator generatorDevice)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: Type -&gt; Type).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">LayerNorm
  'WithoutBias gradient device dataType ('Shape '[queryEmbedDim])
SALayerNormF 'ByT5 gradient device dataType queryEmbedDim
</span><a href="#local-6989586621679806034"><span class="hs-identifier hs-var">saLayerNorm</span></a></span><span>
</span><span id="line-429"></span><span>        </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorDevice)
  layerNormOutput
-&gt; (layerNormOutput
    -&gt; IxStateT
         m
         (Generator generatorDevice)
         (Generator device2)
         (Tensor gradient1 layout1 device1 dataType1 shape1))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator device2)
     (Tensor gradient1 layout1 device1 dataType1 shape1)
forall k1 (m :: k1 -&gt; k1 -&gt; Type -&gt; Type) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">\</span><span id="local-6989586621679806030"><span class="annot"><span class="annottext">layerNormOutput
</span><a href="#local-6989586621679806030"><span class="hs-identifier hs-var">query'</span></a></span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">(Generator generatorDevice
 -&gt; m (Tensor gradient1 layout1 device1 dataType1 shape1,
       Generator device2))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator device2)
     (Tensor gradient1 layout1 device1 dataType1 shape1)
forall (m :: Type -&gt; Type) i j a.
(i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator generatorDevice
  -&gt; m (Tensor gradient1 layout1 device1 dataType1 shape1,
        Generator device2))
 -&gt; IxStateT
      m
      (Generator generatorDevice)
      (Generator device2)
      (Tensor gradient1 layout1 device1 dataType1 shape1))
-&gt; (Generator generatorDevice
    -&gt; m (Tensor gradient1 layout1 device1 dataType1 shape1,
          Generator device2))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator device2)
     (Tensor gradient1 layout1 device1 dataType1 shape1)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">MultiHeadAttention
  'ByT5
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  queryEmbedDim
  queryEmbedDim
  queryEmbedDim
-&gt; (layerNormOutput, layerNormOutput, layerNormOutput,
    attentionBias)
-&gt; Generator generatorDevice
-&gt; m (Tensor gradient1 layout1 device1 dataType1 shape1,
      Generator device2)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: Type -&gt; Type).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">MultiHeadAttention
  'ByT5
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  queryEmbedDim
  queryEmbedDim
  queryEmbedDim
SAMultiheadAttentionF
  'ByT5
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  queryEmbedDim
</span><a href="#local-6989586621679806035"><span class="hs-identifier hs-var">saMultiHeadAttention</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">layerNormOutput
</span><a href="#local-6989586621679806030"><span class="hs-identifier hs-var">query'</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">layerNormOutput
</span><a href="#local-6989586621679806030"><span class="hs-identifier hs-var">query'</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">layerNormOutput
</span><a href="#local-6989586621679806030"><span class="hs-identifier hs-var">query'</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">attentionBias
</span><a href="#local-6989586621679806031"><span class="hs-identifier hs-var">attentionBias</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-430"></span><span>        </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator device2)
  (Tensor gradient1 layout1 device1 dataType1 shape1)
-&gt; (Tensor gradient1 layout1 device1 dataType1 shape1
    -&gt; IxStateT
         m
         (Generator device2)
         (Generator generatorOutputDevice)
         (Tensor gradient1 layout1 generatorOutputDevice dataType1 shape1))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorOutputDevice)
     (Tensor gradient1 layout1 generatorOutputDevice dataType1 shape1)
forall k1 (m :: k1 -&gt; k1 -&gt; Type -&gt; Type) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(Generator device2
 -&gt; m (Tensor
         gradient1 layout1 generatorOutputDevice dataType1 shape1,
       Generator generatorOutputDevice))
-&gt; IxStateT
     m
     (Generator device2)
     (Generator generatorOutputDevice)
     (Tensor gradient1 layout1 generatorOutputDevice dataType1 shape1)
forall (m :: Type -&gt; Type) i j a.
(i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator device2
  -&gt; m (Tensor
          gradient1 layout1 generatorOutputDevice dataType1 shape1,
        Generator generatorOutputDevice))
 -&gt; IxStateT
      m
      (Generator device2)
      (Generator generatorOutputDevice)
      (Tensor gradient1 layout1 generatorOutputDevice dataType1 shape1))
-&gt; (Tensor gradient1 layout1 device1 dataType1 shape1
    -&gt; Generator device2
    -&gt; m (Tensor
            gradient1 layout1 generatorOutputDevice dataType1 shape1,
          Generator generatorOutputDevice))
-&gt; Tensor gradient1 layout1 device1 dataType1 shape1
-&gt; IxStateT
     m
     (Generator device2)
     (Generator generatorOutputDevice)
     (Tensor gradient1 layout1 generatorOutputDevice dataType1 shape1)
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Dropout
-&gt; Tensor gradient1 layout1 device1 dataType1 shape1
-&gt; Generator device2
-&gt; m (Tensor
        gradient1 layout1 generatorOutputDevice dataType1 shape1,
      Generator generatorOutputDevice)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: Type -&gt; Type).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">Dropout
SADropoutF 'ByT5
</span><a href="#local-6989586621679806033"><span class="hs-identifier hs-var">saDropout</span></a></span><span>
</span><span id="line-431"></span><span>        </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorOutputDevice)
  (Tensor gradient1 layout1 generatorOutputDevice dataType1 shape1)
-&gt; (Tensor gradient1 layout1 generatorOutputDevice dataType1 shape1
    -&gt; IxStateT
         m
         (Generator generatorOutputDevice)
         (Generator generatorOutputDevice)
         output)
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorOutputDevice)
     output
forall k1 (m :: k1 -&gt; k1 -&gt; Type -&gt; Type) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">output
-&gt; IxStateT
     m
     (Generator generatorOutputDevice)
     (Generator generatorOutputDevice)
     output
forall k (m :: k -&gt; k -&gt; Type -&gt; Type) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">(output
 -&gt; IxStateT
      m
      (Generator generatorOutputDevice)
      (Generator generatorOutputDevice)
      output)
-&gt; (Tensor gradient1 layout1 generatorOutputDevice dataType1 shape1
    -&gt; output)
-&gt; Tensor gradient1 layout1 generatorOutputDevice dataType1 shape1
-&gt; IxStateT
     m
     (Generator generatorOutputDevice)
     (Generator generatorOutputDevice)
     output
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">query
Tensor gradient0 layout0 device0 dataType0 shape0
</span><a href="#local-6989586621679806032"><span class="hs-identifier hs-var">query</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient0 layout0 device0 dataType0 shape0
-&gt; Tensor gradient1 layout1 generatorOutputDevice dataType1 shape1
-&gt; Tensor
     (gradient0 &lt;|&gt; gradient1)
     (layout0 &lt;+&gt; layout1)
     (device0 &lt;+&gt; generatorOutputDevice)
     (dataType0 &lt;+&gt; dataType1)
     (BroadcastShapesF shape0 shape1)
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (gradient' :: Gradient RequiresGradient)
       (layout' :: Layout LayoutType) (device' :: Device (DeviceType Nat))
       (dataType' :: DataType DType)
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]).
Tensor gradient layout device dataType shape
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; Tensor
     (gradient &lt;|&gt; gradient')
     (layout &lt;+&gt; layout')
     (device &lt;+&gt; device')
     (dataType &lt;+&gt; dataType')
     (BroadcastShapesF shape shape')
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#add"><span class="hs-operator hs-var">`add`</span></a></span><span class="hs-special">)</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span>
</span><span id="line-432"></span><span>
</span><span id="line-433"></span><span class="hs-comment">-- | 'HasForward' instance for @SelfAttention 'BART@.</span><span>
</span><span id="line-434"></span><span class="hs-comment">--</span><span>
</span><span id="line-435"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-436"></span><span class="hs-comment">-- &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;      &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;</span><span>
</span><span id="line-437"></span><span class="hs-comment">-- &#9474; attentionBias &#9474;      &#9474; query &#9474;</span><span>
</span><span id="line-438"></span><span class="hs-comment">-- &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;      &#9492;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-439"></span><span class="hs-comment">--         &#9474;                  &#9474;</span><span>
</span><span id="line-440"></span><span class="hs-comment">--         &#9474;            &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9524;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;</span><span>
</span><span id="line-441"></span><span class="hs-comment">--         &#9474;            &#9474;           &#9474;</span><span>
</span><span id="line-442"></span><span class="hs-comment">--         &#9474;       &#9484;&#9472;&#9472;&#9472;&#9472;&#9532;&#9472;&#9472;&#9472;&#9472;&#9488;      &#9474;</span><span>
</span><span id="line-443"></span><span class="hs-comment">--         &#9474;       &#9474;    &#9474;    &#9474;      &#9474;</span><span>
</span><span id="line-444"></span><span class="hs-comment">--         &#9474;       &#9660;    &#9660;    &#9660;      &#9474;</span><span>
</span><span id="line-445"></span><span class="hs-comment">--         &#9492;&#9472;&#9658;saMultiHeadAttention  &#9474;</span><span>
</span><span id="line-446"></span><span class="hs-comment">--                      &#9474;           &#9474;</span><span>
</span><span id="line-447"></span><span class="hs-comment">--                      &#9660;           &#9474;</span><span>
</span><span id="line-448"></span><span class="hs-comment">--                  saDropout       &#9474;</span><span>
</span><span id="line-449"></span><span class="hs-comment">--                      &#9474;           &#9474;</span><span>
</span><span id="line-450"></span><span class="hs-comment">--                      &#9492;&#9472;&#9472;&#9472;&#9658;add&#9668;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-451"></span><span class="hs-comment">--                            &#9474;</span><span>
</span><span id="line-452"></span><span class="hs-comment">--                            &#9660;</span><span>
</span><span id="line-453"></span><span class="hs-comment">--                       saLayerNorm</span><span>
</span><span id="line-454"></span><span class="hs-comment">--                            &#9474;</span><span>
</span><span id="line-455"></span><span class="hs-comment">--                            &#9660;</span><span>
</span><span id="line-456"></span><span class="hs-comment">--                        &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;</span><span>
</span><span id="line-457"></span><span class="hs-comment">--                        &#9474; query &#9474;</span><span>
</span><span id="line-458"></span><span class="hs-comment">--                        &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-459"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-460"></span><span id="local-6989586621679806007"><span id="local-6989586621679806008"><span id="local-6989586621679806009"><span id="local-6989586621679806010"><span id="local-6989586621679806011"><span id="local-6989586621679806012"><span id="local-6989586621679806013"><span id="local-6989586621679806014"><span id="local-6989586621679806015"><span id="local-6989586621679806016"><span id="local-6989586621679806017"><span id="local-6989586621679806018"><span id="local-6989586621679806019"><span id="local-6989586621679806020"><span id="local-6989586621679806021"><span id="local-6989586621679806022"><span id="local-6989586621679806023"><span id="local-6989586621679806024"><span id="local-6989586621679806025"><span id="local-6989586621679806026"><span id="local-6989586621679806027"><span id="local-6989586621679806028"><span id="local-6989586621679806029"><span class="hs-keyword">instance</span><span>
</span><span id="line-461"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetDim"><span class="hs-identifier hs-type">SGetDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806029"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-462"></span><span>    </span><span class="annot"><a href="#local-6989586621679806028"><span class="hs-identifier hs-type">query</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806027"><span class="hs-identifier hs-type">queryGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806026"><span class="hs-identifier hs-type">queryLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806025"><span class="hs-identifier hs-type">queryDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806024"><span class="hs-identifier hs-type">queryDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806023"><span class="hs-identifier hs-type">queryShape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-463"></span><span>    </span><span class="annot"><a href="#local-6989586621679806022"><span class="hs-identifier hs-type">attentionBias</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806021"><span class="hs-identifier hs-type">attentionBiasGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806020"><span class="hs-identifier hs-type">attentionBiasLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806019"><span class="hs-identifier hs-type">attentionBiasDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806018"><span class="hs-identifier hs-type">attentionBiasDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806017"><span class="hs-identifier hs-type">attentionBiasShape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-464"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-465"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.MultiHeadAttention.html#MultiHeadAttention"><span class="hs-identifier hs-type">MultiHeadAttention</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806016"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806015"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806014"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806013"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806012"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806011"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806029"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806029"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806029"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-466"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679806028"><span class="hs-identifier hs-type">query</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679806028"><span class="hs-identifier hs-type">query</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679806028"><span class="hs-identifier hs-type">query</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679806022"><span class="hs-identifier hs-type">attentionBias</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-467"></span><span>      </span><span class="annot"><a href="#local-6989586621679806010"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-468"></span><span>      </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-469"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679806016"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806027"><span class="hs-identifier hs-type">queryGradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806021"><span class="hs-identifier hs-type">attentionBiasGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-470"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Dense"><span class="hs-identifier hs-type">Dense</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806026"><span class="hs-identifier hs-type">queryLayout</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806020"><span class="hs-identifier hs-type">attentionBiasLayout</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-471"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679806015"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806025"><span class="hs-identifier hs-type">queryDevice</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806019"><span class="hs-identifier hs-type">attentionBiasDevice</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806010"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-472"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679806014"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806024"><span class="hs-identifier hs-type">queryDataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806018"><span class="hs-identifier hs-type">attentionBiasDataType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-473"></span><span>          </span><span class="annot"><a href="#local-6989586621679806009"><span class="hs-identifier hs-type">mhaOutputShape</span></a></span><span>
</span><span id="line-474"></span><span>      </span><span class="hs-special">)</span><span>
</span><span id="line-475"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679806015"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806025"><span class="hs-identifier hs-type">queryDevice</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806019"><span class="hs-identifier hs-type">attentionBiasDevice</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806010"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-476"></span><span>    </span><span class="annot"><a href="#local-6989586621679806008"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-477"></span><span>      </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-478"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679806016"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806027"><span class="hs-identifier hs-type">queryGradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806021"><span class="hs-identifier hs-type">attentionBiasGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-479"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Dense"><span class="hs-identifier hs-type">Dense</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806026"><span class="hs-identifier hs-type">queryLayout</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806020"><span class="hs-identifier hs-type">attentionBiasLayout</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-480"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679806015"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806025"><span class="hs-identifier hs-type">queryDevice</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806019"><span class="hs-identifier hs-type">attentionBiasDevice</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806010"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-481"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679806014"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806024"><span class="hs-identifier hs-type">queryDataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806018"><span class="hs-identifier hs-type">attentionBiasDataType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-482"></span><span>          </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Functional.Normalization.html#LayerNormWithBiasF"><span class="hs-identifier hs-type">LayerNormWithBiasF</span></a></span><span>
</span><span id="line-483"></span><span>              </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679806029"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-484"></span><span>              </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679806029"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-485"></span><span>              </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#BroadcastShapesF"><span class="hs-identifier hs-type">BroadcastShapesF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806023"><span class="hs-identifier hs-type">queryShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806009"><span class="hs-identifier hs-type">mhaOutputShape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-486"></span><span>          </span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-487"></span><span>    </span><span class="annot"><a href="#local-6989586621679806007"><span class="hs-identifier hs-type">generatorOutputDevice</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679806015"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806025"><span class="hs-identifier hs-type">queryDevice</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806019"><span class="hs-identifier hs-type">attentionBiasDevice</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806010"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-488"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-489"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-490"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#SelfAttention"><span class="hs-identifier hs-type">SelfAttention</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806016"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806015"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806014"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806013"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806012"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806011"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679806029"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-491"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679806028"><span class="hs-identifier hs-type">query</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679806022"><span class="hs-identifier hs-type">attentionBias</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-492"></span><span>    </span><span class="annot"><a href="#local-6989586621679806010"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-493"></span><span>    </span><span class="annot"><a href="#local-6989586621679806008"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-494"></span><span>    </span><span class="annot"><a href="#local-6989586621679806007"><span class="hs-identifier hs-type">generatorOutputDevice</span></a></span><span>
</span><span id="line-495"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-496"></span><span>  </span><span id="local-6989586621679806005"><span class="annot"><span class="annottext">forward :: SelfAttention
  'BART
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  queryEmbedDim
-&gt; (query, attentionBias)
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="#local-6989586621679806005"><span class="hs-identifier hs-var hs-var hs-var hs-var">forward</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#SelfAttention"><span class="hs-identifier hs-type">SelfAttention</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#GSelfAttention"><span class="hs-identifier hs-type">GSelfAttention</span></a></span><span> </span><span class="hs-special">{</span><span id="local-6989586621679806002"><span id="local-6989586621679806003"><span id="local-6989586621679806004"><span class="annot"><span class="annottext">SADropoutF 'BART
SALayerNormF 'BART gradient device dataType queryEmbedDim
SAMultiheadAttentionF
  'BART
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  queryEmbedDim
saDropout :: SADropoutF 'BART
saLayerNorm :: SALayerNormF 'BART gradient device dataType queryEmbedDim
saMultiHeadAttention :: SAMultiheadAttentionF
  'BART
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  queryEmbedDim
saDropout :: forall mha layerNorm dropout.
GSelfAttention mha layerNorm dropout -&gt; dropout
saLayerNorm :: forall mha layerNorm dropout.
GSelfAttention mha layerNorm dropout -&gt; layerNorm
saMultiHeadAttention :: forall mha layerNorm dropout.
GSelfAttention mha layerNorm dropout -&gt; mha
</span><a href="#local-6989586621679806002"><span class="hs-glyph hs-var hs-var hs-var hs-var hs-var hs-var">..</span></a></span></span></span></span><span class="hs-special">}</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679806001"><span class="annot"><span class="annottext">query
</span><a href="#local-6989586621679806001"><span class="hs-identifier hs-var">query</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679806000"><span class="annot"><span class="annottext">attentionBias
</span><a href="#local-6989586621679806000"><span class="hs-identifier hs-var">attentionBias</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-497"></span><span>    </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorOutputDevice)
  output
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
forall (m :: Type -&gt; Type) i j a. IxStateT m i j a -&gt; i -&gt; m (a, j)
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var hs-var">runIxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">(IxStateT
   m
   (Generator generatorDevice)
   (Generator generatorOutputDevice)
   output
 -&gt; Generator generatorDevice
 -&gt; m (output, Generator generatorOutputDevice))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorOutputDevice)
     output
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-498"></span><span>      </span><span class="annot"><span class="annottext">query
-&gt; IxStateT
     m (Generator generatorDevice) (Generator generatorDevice) query
forall k (m :: k -&gt; k -&gt; Type -&gt; Type) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">query
</span><a href="#local-6989586621679806001"><span class="hs-identifier hs-var">query</span></a></span><span>
</span><span id="line-499"></span><span>        </span><span class="annot"><span class="annottext">IxStateT
  m (Generator generatorDevice) (Generator generatorDevice) query
-&gt; (query
    -&gt; IxStateT
         m
         (Generator generatorDevice)
         (Generator generatorOutputDevice)
         (Tensor
            (Or
               (Gradient RequiresGradient)
               gradient
               (Or
                  (Gradient RequiresGradient) queryGradient attentionBiasGradient))
            (Unify
               (Layout LayoutType)
               ('Layout 'Dense)
               (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
            generatorOutputDevice
            (Unify
               (DataType DType)
               dataType
               (Unify (DataType DType) queryDataType attentionBiasDataType))
            mhaOutputShape))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorOutputDevice)
     (Tensor
        (Or
           (Gradient RequiresGradient)
           gradient
           (Or
              (Gradient RequiresGradient) queryGradient attentionBiasGradient))
        (Unify
           (Layout LayoutType)
           ('Layout 'Dense)
           (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
        generatorOutputDevice
        (Unify
           (DataType DType)
           dataType
           (Unify (DataType DType) queryDataType attentionBiasDataType))
        mhaOutputShape)
forall k1 (m :: k1 -&gt; k1 -&gt; Type -&gt; Type) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">\</span><span id="local-6989586621679805999"><span class="annot"><span class="annottext">query
</span><a href="#local-6989586621679805999"><span class="hs-identifier hs-var">query'</span></a></span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">(Generator generatorDevice
 -&gt; m (Tensor
         (Or
            (Gradient RequiresGradient)
            gradient
            (Or
               (Gradient RequiresGradient) queryGradient attentionBiasGradient))
         (Unify
            (Layout LayoutType)
            ('Layout 'Dense)
            (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
         generatorOutputDevice
         (Unify
            (DataType DType)
            dataType
            (Unify (DataType DType) queryDataType attentionBiasDataType))
         mhaOutputShape,
       Generator generatorOutputDevice))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorOutputDevice)
     (Tensor
        (Or
           (Gradient RequiresGradient)
           gradient
           (Or
              (Gradient RequiresGradient) queryGradient attentionBiasGradient))
        (Unify
           (Layout LayoutType)
           ('Layout 'Dense)
           (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
        generatorOutputDevice
        (Unify
           (DataType DType)
           dataType
           (Unify (DataType DType) queryDataType attentionBiasDataType))
        mhaOutputShape)
forall (m :: Type -&gt; Type) i j a.
(i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator generatorDevice
  -&gt; m (Tensor
          (Or
             (Gradient RequiresGradient)
             gradient
             (Or
                (Gradient RequiresGradient) queryGradient attentionBiasGradient))
          (Unify
             (Layout LayoutType)
             ('Layout 'Dense)
             (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
          generatorOutputDevice
          (Unify
             (DataType DType)
             dataType
             (Unify (DataType DType) queryDataType attentionBiasDataType))
          mhaOutputShape,
        Generator generatorOutputDevice))
 -&gt; IxStateT
      m
      (Generator generatorDevice)
      (Generator generatorOutputDevice)
      (Tensor
         (Or
            (Gradient RequiresGradient)
            gradient
            (Or
               (Gradient RequiresGradient) queryGradient attentionBiasGradient))
         (Unify
            (Layout LayoutType)
            ('Layout 'Dense)
            (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
         generatorOutputDevice
         (Unify
            (DataType DType)
            dataType
            (Unify (DataType DType) queryDataType attentionBiasDataType))
         mhaOutputShape))
-&gt; (Generator generatorDevice
    -&gt; m (Tensor
            (Or
               (Gradient RequiresGradient)
               gradient
               (Or
                  (Gradient RequiresGradient) queryGradient attentionBiasGradient))
            (Unify
               (Layout LayoutType)
               ('Layout 'Dense)
               (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
            generatorOutputDevice
            (Unify
               (DataType DType)
               dataType
               (Unify (DataType DType) queryDataType attentionBiasDataType))
            mhaOutputShape,
          Generator generatorOutputDevice))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorOutputDevice)
     (Tensor
        (Or
           (Gradient RequiresGradient)
           gradient
           (Or
              (Gradient RequiresGradient) queryGradient attentionBiasGradient))
        (Unify
           (Layout LayoutType)
           ('Layout 'Dense)
           (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
        generatorOutputDevice
        (Unify
           (DataType DType)
           dataType
           (Unify (DataType DType) queryDataType attentionBiasDataType))
        mhaOutputShape)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">MultiHeadAttention
  'BART
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  queryEmbedDim
  queryEmbedDim
  queryEmbedDim
-&gt; (query, query, query, attentionBias)
-&gt; Generator generatorDevice
-&gt; m (Tensor
        (Or
           (Gradient RequiresGradient)
           gradient
           (Or
              (Gradient RequiresGradient) queryGradient attentionBiasGradient))
        (Unify
           (Layout LayoutType)
           ('Layout 'Dense)
           (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
        generatorOutputDevice
        (Unify
           (DataType DType)
           dataType
           (Unify (DataType DType) queryDataType attentionBiasDataType))
        mhaOutputShape,
      Generator generatorOutputDevice)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: Type -&gt; Type).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">MultiHeadAttention
  'BART
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  queryEmbedDim
  queryEmbedDim
  queryEmbedDim
SAMultiheadAttentionF
  'BART
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  queryEmbedDim
</span><a href="#local-6989586621679806004"><span class="hs-identifier hs-var">saMultiHeadAttention</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">query
</span><a href="#local-6989586621679805999"><span class="hs-identifier hs-var">query'</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">query
</span><a href="#local-6989586621679805999"><span class="hs-identifier hs-var">query'</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">query
</span><a href="#local-6989586621679805999"><span class="hs-identifier hs-var">query'</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">attentionBias
</span><a href="#local-6989586621679806000"><span class="hs-identifier hs-var">attentionBias</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-500"></span><span>        </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorOutputDevice)
  (Tensor
     (Or
        (Gradient RequiresGradient)
        gradient
        (Or
           (Gradient RequiresGradient) queryGradient attentionBiasGradient))
     (Unify
        (Layout LayoutType)
        ('Layout 'Dense)
        (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
     generatorOutputDevice
     (Unify
        (DataType DType)
        dataType
        (Unify (DataType DType) queryDataType attentionBiasDataType))
     mhaOutputShape)
-&gt; (Tensor
      (Or
         (Gradient RequiresGradient)
         gradient
         (Or
            (Gradient RequiresGradient) queryGradient attentionBiasGradient))
      (Unify
         (Layout LayoutType)
         ('Layout 'Dense)
         (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
      generatorOutputDevice
      (Unify
         (DataType DType)
         dataType
         (Unify (DataType DType) queryDataType attentionBiasDataType))
      mhaOutputShape
    -&gt; IxStateT
         m
         (Generator generatorOutputDevice)
         (Generator generatorOutputDevice)
         (Tensor
            (Or
               (Gradient RequiresGradient)
               gradient
               (Or
                  (Gradient RequiresGradient) queryGradient attentionBiasGradient))
            (Unify
               (Layout LayoutType)
               ('Layout 'Dense)
               (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
            generatorOutputDevice
            (Unify
               (DataType DType)
               dataType
               (Unify (DataType DType) queryDataType attentionBiasDataType))
            mhaOutputShape))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorOutputDevice)
     (Tensor
        (Or
           (Gradient RequiresGradient)
           gradient
           (Or
              (Gradient RequiresGradient) queryGradient attentionBiasGradient))
        (Unify
           (Layout LayoutType)
           ('Layout 'Dense)
           (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
        generatorOutputDevice
        (Unify
           (DataType DType)
           dataType
           (Unify (DataType DType) queryDataType attentionBiasDataType))
        mhaOutputShape)
forall k1 (m :: k1 -&gt; k1 -&gt; Type -&gt; Type) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(Generator generatorOutputDevice
 -&gt; m (Tensor
         (Or
            (Gradient RequiresGradient)
            gradient
            (Or
               (Gradient RequiresGradient) queryGradient attentionBiasGradient))
         (Unify
            (Layout LayoutType)
            ('Layout 'Dense)
            (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
         generatorOutputDevice
         (Unify
            (DataType DType)
            dataType
            (Unify (DataType DType) queryDataType attentionBiasDataType))
         mhaOutputShape,
       Generator generatorOutputDevice))
-&gt; IxStateT
     m
     (Generator generatorOutputDevice)
     (Generator generatorOutputDevice)
     (Tensor
        (Or
           (Gradient RequiresGradient)
           gradient
           (Or
              (Gradient RequiresGradient) queryGradient attentionBiasGradient))
        (Unify
           (Layout LayoutType)
           ('Layout 'Dense)
           (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
        generatorOutputDevice
        (Unify
           (DataType DType)
           dataType
           (Unify (DataType DType) queryDataType attentionBiasDataType))
        mhaOutputShape)
forall (m :: Type -&gt; Type) i j a.
(i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator generatorOutputDevice
  -&gt; m (Tensor
          (Or
             (Gradient RequiresGradient)
             gradient
             (Or
                (Gradient RequiresGradient) queryGradient attentionBiasGradient))
          (Unify
             (Layout LayoutType)
             ('Layout 'Dense)
             (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
          generatorOutputDevice
          (Unify
             (DataType DType)
             dataType
             (Unify (DataType DType) queryDataType attentionBiasDataType))
          mhaOutputShape,
        Generator generatorOutputDevice))
 -&gt; IxStateT
      m
      (Generator generatorOutputDevice)
      (Generator generatorOutputDevice)
      (Tensor
         (Or
            (Gradient RequiresGradient)
            gradient
            (Or
               (Gradient RequiresGradient) queryGradient attentionBiasGradient))
         (Unify
            (Layout LayoutType)
            ('Layout 'Dense)
            (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
         generatorOutputDevice
         (Unify
            (DataType DType)
            dataType
            (Unify (DataType DType) queryDataType attentionBiasDataType))
         mhaOutputShape))
-&gt; (Tensor
      (Or
         (Gradient RequiresGradient)
         gradient
         (Or
            (Gradient RequiresGradient) queryGradient attentionBiasGradient))
      (Unify
         (Layout LayoutType)
         ('Layout 'Dense)
         (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
      generatorOutputDevice
      (Unify
         (DataType DType)
         dataType
         (Unify (DataType DType) queryDataType attentionBiasDataType))
      mhaOutputShape
    -&gt; Generator generatorOutputDevice
    -&gt; m (Tensor
            (Or
               (Gradient RequiresGradient)
               gradient
               (Or
                  (Gradient RequiresGradient) queryGradient attentionBiasGradient))
            (Unify
               (Layout LayoutType)
               ('Layout 'Dense)
               (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
            generatorOutputDevice
            (Unify
               (DataType DType)
               dataType
               (Unify (DataType DType) queryDataType attentionBiasDataType))
            mhaOutputShape,
          Generator generatorOutputDevice))
-&gt; Tensor
     (Or
        (Gradient RequiresGradient)
        gradient
        (Or
           (Gradient RequiresGradient) queryGradient attentionBiasGradient))
     (Unify
        (Layout LayoutType)
        ('Layout 'Dense)
        (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
     generatorOutputDevice
     (Unify
        (DataType DType)
        dataType
        (Unify (DataType DType) queryDataType attentionBiasDataType))
     mhaOutputShape
-&gt; IxStateT
     m
     (Generator generatorOutputDevice)
     (Generator generatorOutputDevice)
     (Tensor
        (Or
           (Gradient RequiresGradient)
           gradient
           (Or
              (Gradient RequiresGradient) queryGradient attentionBiasGradient))
        (Unify
           (Layout LayoutType)
           ('Layout 'Dense)
           (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
        generatorOutputDevice
        (Unify
           (DataType DType)
           dataType
           (Unify (DataType DType) queryDataType attentionBiasDataType))
        mhaOutputShape)
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Dropout
-&gt; Tensor
     (Or
        (Gradient RequiresGradient)
        gradient
        (Or
           (Gradient RequiresGradient) queryGradient attentionBiasGradient))
     (Unify
        (Layout LayoutType)
        ('Layout 'Dense)
        (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
     generatorOutputDevice
     (Unify
        (DataType DType)
        dataType
        (Unify (DataType DType) queryDataType attentionBiasDataType))
     mhaOutputShape
-&gt; Generator generatorOutputDevice
-&gt; m (Tensor
        (Or
           (Gradient RequiresGradient)
           gradient
           (Or
              (Gradient RequiresGradient) queryGradient attentionBiasGradient))
        (Unify
           (Layout LayoutType)
           ('Layout 'Dense)
           (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
        generatorOutputDevice
        (Unify
           (DataType DType)
           dataType
           (Unify (DataType DType) queryDataType attentionBiasDataType))
        mhaOutputShape,
      Generator generatorOutputDevice)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: Type -&gt; Type).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">Dropout
SADropoutF 'BART
</span><a href="#local-6989586621679806002"><span class="hs-identifier hs-var">saDropout</span></a></span><span>
</span><span id="line-501"></span><span>        </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorOutputDevice)
  (Tensor
     (Or
        (Gradient RequiresGradient)
        gradient
        (Or
           (Gradient RequiresGradient) queryGradient attentionBiasGradient))
     (Unify
        (Layout LayoutType)
        ('Layout 'Dense)
        (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
     generatorOutputDevice
     (Unify
        (DataType DType)
        dataType
        (Unify (DataType DType) queryDataType attentionBiasDataType))
     mhaOutputShape)
-&gt; (Tensor
      (Or
         (Gradient RequiresGradient)
         gradient
         (Or
            (Gradient RequiresGradient) queryGradient attentionBiasGradient))
      (Unify
         (Layout LayoutType)
         ('Layout 'Dense)
         (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
      generatorOutputDevice
      (Unify
         (DataType DType)
         dataType
         (Unify (DataType DType) queryDataType attentionBiasDataType))
      mhaOutputShape
    -&gt; IxStateT
         m
         (Generator generatorOutputDevice)
         (Generator generatorOutputDevice)
         (Tensor
            (Or
               (Gradient RequiresGradient)
               queryGradient
               (Or
                  (Gradient RequiresGradient)
                  gradient
                  (Or
                     (Gradient RequiresGradient) queryGradient attentionBiasGradient)))
            (Unify
               (Layout LayoutType)
               queryLayout
               (Unify
                  (Layout LayoutType)
                  ('Layout 'Dense)
                  (Unify (Layout LayoutType) queryLayout attentionBiasLayout)))
            (Unify (Device (DeviceType Nat)) queryDevice generatorOutputDevice)
            (Unify
               (DataType DType)
               queryDataType
               (Unify
                  (DataType DType)
                  dataType
                  (Unify (DataType DType) queryDataType attentionBiasDataType)))
            (BroadcastShapesF queryShape mhaOutputShape)))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorOutputDevice)
     (Tensor
        (Or
           (Gradient RequiresGradient)
           queryGradient
           (Or
              (Gradient RequiresGradient)
              gradient
              (Or
                 (Gradient RequiresGradient) queryGradient attentionBiasGradient)))
        (Unify
           (Layout LayoutType)
           queryLayout
           (Unify
              (Layout LayoutType)
              ('Layout 'Dense)
              (Unify (Layout LayoutType) queryLayout attentionBiasLayout)))
        (Unify (Device (DeviceType Nat)) queryDevice generatorOutputDevice)
        (Unify
           (DataType DType)
           queryDataType
           (Unify
              (DataType DType)
              dataType
              (Unify (DataType DType) queryDataType attentionBiasDataType)))
        (BroadcastShapesF queryShape mhaOutputShape))
forall k1 (m :: k1 -&gt; k1 -&gt; Type -&gt; Type) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  (Or
     (Gradient RequiresGradient)
     queryGradient
     (Or
        (Gradient RequiresGradient)
        gradient
        (Or
           (Gradient RequiresGradient) queryGradient attentionBiasGradient)))
  (Unify
     (Layout LayoutType)
     queryLayout
     (Unify
        (Layout LayoutType)
        ('Layout 'Dense)
        (Unify (Layout LayoutType) queryLayout attentionBiasLayout)))
  (Unify (Device (DeviceType Nat)) queryDevice generatorOutputDevice)
  (Unify
     (DataType DType)
     queryDataType
     (Unify
        (DataType DType)
        dataType
        (Unify (DataType DType) queryDataType attentionBiasDataType)))
  (BroadcastShapesF queryShape mhaOutputShape)
-&gt; IxStateT
     m
     (Generator generatorOutputDevice)
     (Generator generatorOutputDevice)
     (Tensor
        (Or
           (Gradient RequiresGradient)
           queryGradient
           (Or
              (Gradient RequiresGradient)
              gradient
              (Or
                 (Gradient RequiresGradient) queryGradient attentionBiasGradient)))
        (Unify
           (Layout LayoutType)
           queryLayout
           (Unify
              (Layout LayoutType)
              ('Layout 'Dense)
              (Unify (Layout LayoutType) queryLayout attentionBiasLayout)))
        (Unify (Device (DeviceType Nat)) queryDevice generatorOutputDevice)
        (Unify
           (DataType DType)
           queryDataType
           (Unify
              (DataType DType)
              dataType
              (Unify (DataType DType) queryDataType attentionBiasDataType)))
        (BroadcastShapesF queryShape mhaOutputShape))
forall k (m :: k -&gt; k -&gt; Type -&gt; Type) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">(Tensor
   (Or
      (Gradient RequiresGradient)
      queryGradient
      (Or
         (Gradient RequiresGradient)
         gradient
         (Or
            (Gradient RequiresGradient) queryGradient attentionBiasGradient)))
   (Unify
      (Layout LayoutType)
      queryLayout
      (Unify
         (Layout LayoutType)
         ('Layout 'Dense)
         (Unify (Layout LayoutType) queryLayout attentionBiasLayout)))
   (Unify (Device (DeviceType Nat)) queryDevice generatorOutputDevice)
   (Unify
      (DataType DType)
      queryDataType
      (Unify
         (DataType DType)
         dataType
         (Unify (DataType DType) queryDataType attentionBiasDataType)))
   (BroadcastShapesF queryShape mhaOutputShape)
 -&gt; IxStateT
      m
      (Generator generatorOutputDevice)
      (Generator generatorOutputDevice)
      (Tensor
         (Or
            (Gradient RequiresGradient)
            queryGradient
            (Or
               (Gradient RequiresGradient)
               gradient
               (Or
                  (Gradient RequiresGradient) queryGradient attentionBiasGradient)))
         (Unify
            (Layout LayoutType)
            queryLayout
            (Unify
               (Layout LayoutType)
               ('Layout 'Dense)
               (Unify (Layout LayoutType) queryLayout attentionBiasLayout)))
         (Unify (Device (DeviceType Nat)) queryDevice generatorOutputDevice)
         (Unify
            (DataType DType)
            queryDataType
            (Unify
               (DataType DType)
               dataType
               (Unify (DataType DType) queryDataType attentionBiasDataType)))
         (BroadcastShapesF queryShape mhaOutputShape)))
-&gt; (Tensor
      (Or
         (Gradient RequiresGradient)
         gradient
         (Or
            (Gradient RequiresGradient) queryGradient attentionBiasGradient))
      (Unify
         (Layout LayoutType)
         ('Layout 'Dense)
         (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
      generatorOutputDevice
      (Unify
         (DataType DType)
         dataType
         (Unify (DataType DType) queryDataType attentionBiasDataType))
      mhaOutputShape
    -&gt; Tensor
         (Or
            (Gradient RequiresGradient)
            queryGradient
            (Or
               (Gradient RequiresGradient)
               gradient
               (Or
                  (Gradient RequiresGradient) queryGradient attentionBiasGradient)))
         (Unify
            (Layout LayoutType)
            queryLayout
            (Unify
               (Layout LayoutType)
               ('Layout 'Dense)
               (Unify (Layout LayoutType) queryLayout attentionBiasLayout)))
         (Unify (Device (DeviceType Nat)) queryDevice generatorOutputDevice)
         (Unify
            (DataType DType)
            queryDataType
            (Unify
               (DataType DType)
               dataType
               (Unify (DataType DType) queryDataType attentionBiasDataType)))
         (BroadcastShapesF queryShape mhaOutputShape))
-&gt; Tensor
     (Or
        (Gradient RequiresGradient)
        gradient
        (Or
           (Gradient RequiresGradient) queryGradient attentionBiasGradient))
     (Unify
        (Layout LayoutType)
        ('Layout 'Dense)
        (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
     generatorOutputDevice
     (Unify
        (DataType DType)
        dataType
        (Unify (DataType DType) queryDataType attentionBiasDataType))
     mhaOutputShape
-&gt; IxStateT
     m
     (Generator generatorOutputDevice)
     (Generator generatorOutputDevice)
     (Tensor
        (Or
           (Gradient RequiresGradient)
           queryGradient
           (Or
              (Gradient RequiresGradient)
              gradient
              (Or
                 (Gradient RequiresGradient) queryGradient attentionBiasGradient)))
        (Unify
           (Layout LayoutType)
           queryLayout
           (Unify
              (Layout LayoutType)
              ('Layout 'Dense)
              (Unify (Layout LayoutType) queryLayout attentionBiasLayout)))
        (Unify (Device (DeviceType Nat)) queryDevice generatorOutputDevice)
        (Unify
           (DataType DType)
           queryDataType
           (Unify
              (DataType DType)
              dataType
              (Unify (DataType DType) queryDataType attentionBiasDataType)))
        (BroadcastShapesF queryShape mhaOutputShape))
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">query
Tensor
  queryGradient queryLayout queryDevice queryDataType queryShape
</span><a href="#local-6989586621679806001"><span class="hs-identifier hs-var">query</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  queryGradient queryLayout queryDevice queryDataType queryShape
-&gt; Tensor
     (Or
        (Gradient RequiresGradient)
        gradient
        (Or
           (Gradient RequiresGradient) queryGradient attentionBiasGradient))
     (Unify
        (Layout LayoutType)
        ('Layout 'Dense)
        (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
     generatorOutputDevice
     (Unify
        (DataType DType)
        dataType
        (Unify (DataType DType) queryDataType attentionBiasDataType))
     mhaOutputShape
-&gt; Tensor
     (queryGradient
      &lt;|&gt; Or
            (Gradient RequiresGradient)
            gradient
            (Or
               (Gradient RequiresGradient) queryGradient attentionBiasGradient))
     (queryLayout
      &lt;+&gt; Unify
            (Layout LayoutType)
            ('Layout 'Dense)
            (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
     (queryDevice &lt;+&gt; generatorOutputDevice)
     (queryDataType
      &lt;+&gt; Unify
            (DataType DType)
            dataType
            (Unify (DataType DType) queryDataType attentionBiasDataType))
     (BroadcastShapesF queryShape mhaOutputShape)
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (gradient' :: Gradient RequiresGradient)
       (layout' :: Layout LayoutType) (device' :: Device (DeviceType Nat))
       (dataType' :: DataType DType)
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]).
Tensor gradient layout device dataType shape
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; Tensor
     (gradient &lt;|&gt; gradient')
     (layout &lt;+&gt; layout')
     (device &lt;+&gt; device')
     (dataType &lt;+&gt; dataType')
     (BroadcastShapesF shape shape')
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#add"><span class="hs-operator hs-var">`add`</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-502"></span><span>        </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorOutputDevice)
  (Tensor
     (Or
        (Gradient RequiresGradient)
        queryGradient
        (Or
           (Gradient RequiresGradient)
           gradient
           (Or
              (Gradient RequiresGradient) queryGradient attentionBiasGradient)))
     (Unify
        (Layout LayoutType)
        queryLayout
        (Unify
           (Layout LayoutType)
           ('Layout 'Dense)
           (Unify (Layout LayoutType) queryLayout attentionBiasLayout)))
     (Unify (Device (DeviceType Nat)) queryDevice generatorOutputDevice)
     (Unify
        (DataType DType)
        queryDataType
        (Unify
           (DataType DType)
           dataType
           (Unify (DataType DType) queryDataType attentionBiasDataType)))
     (BroadcastShapesF queryShape mhaOutputShape))
-&gt; (Tensor
      (Or
         (Gradient RequiresGradient)
         queryGradient
         (Or
            (Gradient RequiresGradient)
            gradient
            (Or
               (Gradient RequiresGradient) queryGradient attentionBiasGradient)))
      (Unify
         (Layout LayoutType)
         queryLayout
         (Unify
            (Layout LayoutType)
            ('Layout 'Dense)
            (Unify (Layout LayoutType) queryLayout attentionBiasLayout)))
      (Unify (Device (DeviceType Nat)) queryDevice generatorOutputDevice)
      (Unify
         (DataType DType)
         queryDataType
         (Unify
            (DataType DType)
            dataType
            (Unify (DataType DType) queryDataType attentionBiasDataType)))
      (BroadcastShapesF queryShape mhaOutputShape)
    -&gt; IxStateT
         m
         (Generator generatorOutputDevice)
         (Generator generatorOutputDevice)
         output)
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorOutputDevice)
     output
forall k1 (m :: k1 -&gt; k1 -&gt; Type -&gt; Type) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(Generator generatorOutputDevice
 -&gt; m (output, Generator generatorOutputDevice))
-&gt; IxStateT
     m
     (Generator generatorOutputDevice)
     (Generator generatorOutputDevice)
     output
forall (m :: Type -&gt; Type) i j a.
(i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator generatorOutputDevice
  -&gt; m (output, Generator generatorOutputDevice))
 -&gt; IxStateT
      m
      (Generator generatorOutputDevice)
      (Generator generatorOutputDevice)
      output)
-&gt; (Tensor
      (Or
         (Gradient RequiresGradient)
         queryGradient
         (Or
            (Gradient RequiresGradient)
            gradient
            (Or
               (Gradient RequiresGradient) queryGradient attentionBiasGradient)))
      (Unify
         (Layout LayoutType)
         queryLayout
         (Unify
            (Layout LayoutType)
            ('Layout 'Dense)
            (Unify (Layout LayoutType) queryLayout attentionBiasLayout)))
      (Unify (Device (DeviceType Nat)) queryDevice generatorOutputDevice)
      (Unify
         (DataType DType)
         queryDataType
         (Unify
            (DataType DType)
            dataType
            (Unify (DataType DType) queryDataType attentionBiasDataType)))
      (BroadcastShapesF queryShape mhaOutputShape)
    -&gt; Generator generatorOutputDevice
    -&gt; m (output, Generator generatorOutputDevice))
-&gt; Tensor
     (Or
        (Gradient RequiresGradient)
        queryGradient
        (Or
           (Gradient RequiresGradient)
           gradient
           (Or
              (Gradient RequiresGradient) queryGradient attentionBiasGradient)))
     (Unify
        (Layout LayoutType)
        queryLayout
        (Unify
           (Layout LayoutType)
           ('Layout 'Dense)
           (Unify (Layout LayoutType) queryLayout attentionBiasLayout)))
     (Unify (Device (DeviceType Nat)) queryDevice generatorOutputDevice)
     (Unify
        (DataType DType)
        queryDataType
        (Unify
           (DataType DType)
           dataType
           (Unify (DataType DType) queryDataType attentionBiasDataType)))
     (BroadcastShapesF queryShape mhaOutputShape)
-&gt; IxStateT
     m
     (Generator generatorOutputDevice)
     (Generator generatorOutputDevice)
     output
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">LayerNorm
  'WithBias gradient device dataType ('Shape '[queryEmbedDim])
-&gt; Tensor
     (Or
        (Gradient RequiresGradient)
        queryGradient
        (Or
           (Gradient RequiresGradient)
           gradient
           (Or
              (Gradient RequiresGradient) queryGradient attentionBiasGradient)))
     (Unify
        (Layout LayoutType)
        queryLayout
        (Unify
           (Layout LayoutType)
           ('Layout 'Dense)
           (Unify (Layout LayoutType) queryLayout attentionBiasLayout)))
     (Unify (Device (DeviceType Nat)) queryDevice generatorOutputDevice)
     (Unify
        (DataType DType)
        queryDataType
        (Unify
           (DataType DType)
           dataType
           (Unify (DataType DType) queryDataType attentionBiasDataType)))
     (BroadcastShapesF queryShape mhaOutputShape)
-&gt; Generator generatorOutputDevice
-&gt; m (output, Generator generatorOutputDevice)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: Type -&gt; Type).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">LayerNorm
  'WithBias gradient device dataType ('Shape '[queryEmbedDim])
SALayerNormF 'BART gradient device dataType queryEmbedDim
</span><a href="#local-6989586621679806003"><span class="hs-identifier hs-var">saLayerNorm</span></a></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span>
</span><span id="line-503"></span><span>
</span><span id="line-504"></span><span class="hs-comment">-- | 'HasForward' instance for @SelfAttention 'BERT@.</span><span>
</span><span id="line-505"></span><span class="hs-comment">--</span><span>
</span><span id="line-506"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-507"></span><span class="hs-comment">-- &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;      &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;</span><span>
</span><span id="line-508"></span><span class="hs-comment">-- &#9474; attentionBias &#9474;      &#9474; query &#9474;</span><span>
</span><span id="line-509"></span><span class="hs-comment">-- &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;      &#9492;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-510"></span><span class="hs-comment">--         &#9474;                  &#9474;</span><span>
</span><span id="line-511"></span><span class="hs-comment">--         &#9474;            &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9524;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;</span><span>
</span><span id="line-512"></span><span class="hs-comment">--         &#9474;            &#9474;           &#9474;</span><span>
</span><span id="line-513"></span><span class="hs-comment">--         &#9474;       &#9484;&#9472;&#9472;&#9472;&#9472;&#9532;&#9472;&#9472;&#9472;&#9472;&#9488;      &#9474;</span><span>
</span><span id="line-514"></span><span class="hs-comment">--         &#9474;       &#9474;    &#9474;    &#9474;      &#9474;</span><span>
</span><span id="line-515"></span><span class="hs-comment">--         &#9474;       &#9660;    &#9660;    &#9660;      &#9474;</span><span>
</span><span id="line-516"></span><span class="hs-comment">--         &#9492;&#9472;&#9658;saMultiHeadAttention  &#9474;</span><span>
</span><span id="line-517"></span><span class="hs-comment">--                      &#9474;           &#9474;</span><span>
</span><span id="line-518"></span><span class="hs-comment">--                      &#9660;           &#9474;</span><span>
</span><span id="line-519"></span><span class="hs-comment">--                  saDropout       &#9474;</span><span>
</span><span id="line-520"></span><span class="hs-comment">--                      &#9474;           &#9474;</span><span>
</span><span id="line-521"></span><span class="hs-comment">--                      &#9492;&#9472;&#9472;&#9472;&#9658;add&#9668;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-522"></span><span class="hs-comment">--                            &#9474;</span><span>
</span><span id="line-523"></span><span class="hs-comment">--                            &#9660;</span><span>
</span><span id="line-524"></span><span class="hs-comment">--                       saLayerNorm</span><span>
</span><span id="line-525"></span><span class="hs-comment">--                            &#9474;</span><span>
</span><span id="line-526"></span><span class="hs-comment">--                            &#9660;</span><span>
</span><span id="line-527"></span><span class="hs-comment">--                        &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;</span><span>
</span><span id="line-528"></span><span class="hs-comment">--                        &#9474; query &#9474;</span><span>
</span><span id="line-529"></span><span class="hs-comment">--                        &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-530"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-531"></span><span id="local-6989586621679805976"><span id="local-6989586621679805977"><span id="local-6989586621679805978"><span id="local-6989586621679805979"><span id="local-6989586621679805980"><span id="local-6989586621679805981"><span id="local-6989586621679805982"><span id="local-6989586621679805983"><span id="local-6989586621679805984"><span id="local-6989586621679805985"><span id="local-6989586621679805986"><span id="local-6989586621679805987"><span id="local-6989586621679805988"><span id="local-6989586621679805989"><span id="local-6989586621679805990"><span id="local-6989586621679805991"><span id="local-6989586621679805992"><span id="local-6989586621679805993"><span id="local-6989586621679805994"><span id="local-6989586621679805995"><span id="local-6989586621679805996"><span id="local-6989586621679805997"><span id="local-6989586621679805998"><span class="hs-keyword">instance</span><span>
</span><span id="line-532"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetDim"><span class="hs-identifier hs-type">SGetDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805998"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-533"></span><span>    </span><span class="annot"><a href="#local-6989586621679805997"><span class="hs-identifier hs-type">query</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805996"><span class="hs-identifier hs-type">queryGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805995"><span class="hs-identifier hs-type">queryLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805994"><span class="hs-identifier hs-type">queryDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805993"><span class="hs-identifier hs-type">queryDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805992"><span class="hs-identifier hs-type">queryShape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-534"></span><span>    </span><span class="annot"><a href="#local-6989586621679805991"><span class="hs-identifier hs-type">attentionBias</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805990"><span class="hs-identifier hs-type">attentionBiasGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805989"><span class="hs-identifier hs-type">attentionBiasLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805988"><span class="hs-identifier hs-type">attentionBiasDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805987"><span class="hs-identifier hs-type">attentionBiasDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805986"><span class="hs-identifier hs-type">attentionBiasShape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-535"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-536"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.MultiHeadAttention.html#MultiHeadAttention"><span class="hs-identifier hs-type">MultiHeadAttention</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BERT"><span class="hs-identifier hs-type">BERT</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805985"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805984"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805983"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805982"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805981"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805980"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805998"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805998"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805998"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-537"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679805997"><span class="hs-identifier hs-type">query</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679805997"><span class="hs-identifier hs-type">query</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679805997"><span class="hs-identifier hs-type">query</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679805991"><span class="hs-identifier hs-type">attentionBias</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-538"></span><span>      </span><span class="annot"><a href="#local-6989586621679805979"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-539"></span><span>      </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-540"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679805985"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805996"><span class="hs-identifier hs-type">queryGradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805990"><span class="hs-identifier hs-type">attentionBiasGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-541"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Dense"><span class="hs-identifier hs-type">Dense</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805995"><span class="hs-identifier hs-type">queryLayout</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805989"><span class="hs-identifier hs-type">attentionBiasLayout</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-542"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679805984"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805994"><span class="hs-identifier hs-type">queryDevice</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805988"><span class="hs-identifier hs-type">attentionBiasDevice</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805979"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-543"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679805983"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805993"><span class="hs-identifier hs-type">queryDataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805987"><span class="hs-identifier hs-type">attentionBiasDataType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-544"></span><span>          </span><span class="annot"><a href="#local-6989586621679805978"><span class="hs-identifier hs-type">mhaOutputShape</span></a></span><span>
</span><span id="line-545"></span><span>      </span><span class="hs-special">)</span><span>
</span><span id="line-546"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679805984"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805994"><span class="hs-identifier hs-type">queryDevice</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805988"><span class="hs-identifier hs-type">attentionBiasDevice</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805979"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-547"></span><span>    </span><span class="annot"><a href="#local-6989586621679805977"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-548"></span><span>      </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-549"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679805985"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805996"><span class="hs-identifier hs-type">queryGradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805990"><span class="hs-identifier hs-type">attentionBiasGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-550"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Dense"><span class="hs-identifier hs-type">Dense</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805995"><span class="hs-identifier hs-type">queryLayout</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805989"><span class="hs-identifier hs-type">attentionBiasLayout</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-551"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679805984"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805994"><span class="hs-identifier hs-type">queryDevice</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805988"><span class="hs-identifier hs-type">attentionBiasDevice</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805979"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-552"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679805983"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805993"><span class="hs-identifier hs-type">queryDataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805987"><span class="hs-identifier hs-type">attentionBiasDataType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-553"></span><span>          </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Functional.Normalization.html#LayerNormWithBiasF"><span class="hs-identifier hs-type">LayerNormWithBiasF</span></a></span><span>
</span><span id="line-554"></span><span>              </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679805998"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-555"></span><span>              </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679805998"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-556"></span><span>              </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#BroadcastShapesF"><span class="hs-identifier hs-type">BroadcastShapesF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805992"><span class="hs-identifier hs-type">queryShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805978"><span class="hs-identifier hs-type">mhaOutputShape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-557"></span><span>          </span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-558"></span><span>    </span><span class="annot"><a href="#local-6989586621679805976"><span class="hs-identifier hs-type">generatorOutputDevice</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679805984"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805994"><span class="hs-identifier hs-type">queryDevice</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805988"><span class="hs-identifier hs-type">attentionBiasDevice</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805979"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-559"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-560"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-561"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#SelfAttention"><span class="hs-identifier hs-type">SelfAttention</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BERT"><span class="hs-identifier hs-type">BERT</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805985"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805984"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805983"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805982"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805981"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805980"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805998"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-562"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679805997"><span class="hs-identifier hs-type">query</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679805991"><span class="hs-identifier hs-type">attentionBias</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-563"></span><span>    </span><span class="annot"><a href="#local-6989586621679805979"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-564"></span><span>    </span><span class="annot"><a href="#local-6989586621679805977"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-565"></span><span>    </span><span class="annot"><a href="#local-6989586621679805976"><span class="hs-identifier hs-type">generatorOutputDevice</span></a></span><span>
</span><span id="line-566"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-567"></span><span>  </span><span id="local-6989586621679805974"><span class="annot"><span class="annottext">forward :: SelfAttention
  'BERT
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  queryEmbedDim
-&gt; (query, attentionBias)
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="#local-6989586621679805974"><span class="hs-identifier hs-var hs-var hs-var hs-var">forward</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#SelfAttention"><span class="hs-identifier hs-type">SelfAttention</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#GSelfAttention"><span class="hs-identifier hs-type">GSelfAttention</span></a></span><span> </span><span class="hs-special">{</span><span id="local-6989586621679805971"><span id="local-6989586621679805972"><span id="local-6989586621679805973"><span class="annot"><span class="annottext">SADropoutF 'BERT
SALayerNormF 'BERT gradient device dataType queryEmbedDim
SAMultiheadAttentionF
  'BERT
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  queryEmbedDim
saDropout :: SADropoutF 'BERT
saLayerNorm :: SALayerNormF 'BERT gradient device dataType queryEmbedDim
saMultiHeadAttention :: SAMultiheadAttentionF
  'BERT
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  queryEmbedDim
saDropout :: forall mha layerNorm dropout.
GSelfAttention mha layerNorm dropout -&gt; dropout
saLayerNorm :: forall mha layerNorm dropout.
GSelfAttention mha layerNorm dropout -&gt; layerNorm
saMultiHeadAttention :: forall mha layerNorm dropout.
GSelfAttention mha layerNorm dropout -&gt; mha
</span><a href="#local-6989586621679805971"><span class="hs-glyph hs-var hs-var hs-var hs-var hs-var hs-var">..</span></a></span></span></span></span><span class="hs-special">}</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679805970"><span class="annot"><span class="annottext">query
</span><a href="#local-6989586621679805970"><span class="hs-identifier hs-var">query</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679805969"><span class="annot"><span class="annottext">attentionBias
</span><a href="#local-6989586621679805969"><span class="hs-identifier hs-var">attentionBias</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-568"></span><span>    </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorOutputDevice)
  output
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
forall (m :: Type -&gt; Type) i j a. IxStateT m i j a -&gt; i -&gt; m (a, j)
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var hs-var">runIxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">(IxStateT
   m
   (Generator generatorDevice)
   (Generator generatorOutputDevice)
   output
 -&gt; Generator generatorDevice
 -&gt; m (output, Generator generatorOutputDevice))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorOutputDevice)
     output
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-569"></span><span>      </span><span class="annot"><span class="annottext">query
-&gt; IxStateT
     m (Generator generatorDevice) (Generator generatorDevice) query
forall k (m :: k -&gt; k -&gt; Type -&gt; Type) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">query
</span><a href="#local-6989586621679805970"><span class="hs-identifier hs-var">query</span></a></span><span>
</span><span id="line-570"></span><span>        </span><span class="annot"><span class="annottext">IxStateT
  m (Generator generatorDevice) (Generator generatorDevice) query
-&gt; (query
    -&gt; IxStateT
         m
         (Generator generatorDevice)
         (Generator generatorOutputDevice)
         (Tensor
            (Or
               (Gradient RequiresGradient)
               gradient
               (Or
                  (Gradient RequiresGradient) queryGradient attentionBiasGradient))
            (Unify
               (Layout LayoutType)
               ('Layout 'Dense)
               (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
            generatorOutputDevice
            (Unify
               (DataType DType)
               dataType
               (Unify (DataType DType) queryDataType attentionBiasDataType))
            mhaOutputShape))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorOutputDevice)
     (Tensor
        (Or
           (Gradient RequiresGradient)
           gradient
           (Or
              (Gradient RequiresGradient) queryGradient attentionBiasGradient))
        (Unify
           (Layout LayoutType)
           ('Layout 'Dense)
           (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
        generatorOutputDevice
        (Unify
           (DataType DType)
           dataType
           (Unify (DataType DType) queryDataType attentionBiasDataType))
        mhaOutputShape)
forall k1 (m :: k1 -&gt; k1 -&gt; Type -&gt; Type) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">\</span><span id="local-6989586621679805968"><span class="annot"><span class="annottext">query
</span><a href="#local-6989586621679805968"><span class="hs-identifier hs-var">query'</span></a></span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">(Generator generatorDevice
 -&gt; m (Tensor
         (Or
            (Gradient RequiresGradient)
            gradient
            (Or
               (Gradient RequiresGradient) queryGradient attentionBiasGradient))
         (Unify
            (Layout LayoutType)
            ('Layout 'Dense)
            (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
         generatorOutputDevice
         (Unify
            (DataType DType)
            dataType
            (Unify (DataType DType) queryDataType attentionBiasDataType))
         mhaOutputShape,
       Generator generatorOutputDevice))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorOutputDevice)
     (Tensor
        (Or
           (Gradient RequiresGradient)
           gradient
           (Or
              (Gradient RequiresGradient) queryGradient attentionBiasGradient))
        (Unify
           (Layout LayoutType)
           ('Layout 'Dense)
           (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
        generatorOutputDevice
        (Unify
           (DataType DType)
           dataType
           (Unify (DataType DType) queryDataType attentionBiasDataType))
        mhaOutputShape)
forall (m :: Type -&gt; Type) i j a.
(i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator generatorDevice
  -&gt; m (Tensor
          (Or
             (Gradient RequiresGradient)
             gradient
             (Or
                (Gradient RequiresGradient) queryGradient attentionBiasGradient))
          (Unify
             (Layout LayoutType)
             ('Layout 'Dense)
             (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
          generatorOutputDevice
          (Unify
             (DataType DType)
             dataType
             (Unify (DataType DType) queryDataType attentionBiasDataType))
          mhaOutputShape,
        Generator generatorOutputDevice))
 -&gt; IxStateT
      m
      (Generator generatorDevice)
      (Generator generatorOutputDevice)
      (Tensor
         (Or
            (Gradient RequiresGradient)
            gradient
            (Or
               (Gradient RequiresGradient) queryGradient attentionBiasGradient))
         (Unify
            (Layout LayoutType)
            ('Layout 'Dense)
            (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
         generatorOutputDevice
         (Unify
            (DataType DType)
            dataType
            (Unify (DataType DType) queryDataType attentionBiasDataType))
         mhaOutputShape))
-&gt; (Generator generatorDevice
    -&gt; m (Tensor
            (Or
               (Gradient RequiresGradient)
               gradient
               (Or
                  (Gradient RequiresGradient) queryGradient attentionBiasGradient))
            (Unify
               (Layout LayoutType)
               ('Layout 'Dense)
               (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
            generatorOutputDevice
            (Unify
               (DataType DType)
               dataType
               (Unify (DataType DType) queryDataType attentionBiasDataType))
            mhaOutputShape,
          Generator generatorOutputDevice))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorOutputDevice)
     (Tensor
        (Or
           (Gradient RequiresGradient)
           gradient
           (Or
              (Gradient RequiresGradient) queryGradient attentionBiasGradient))
        (Unify
           (Layout LayoutType)
           ('Layout 'Dense)
           (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
        generatorOutputDevice
        (Unify
           (DataType DType)
           dataType
           (Unify (DataType DType) queryDataType attentionBiasDataType))
        mhaOutputShape)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">MultiHeadAttention
  'BERT
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  queryEmbedDim
  queryEmbedDim
  queryEmbedDim
-&gt; (query, query, query, attentionBias)
-&gt; Generator generatorDevice
-&gt; m (Tensor
        (Or
           (Gradient RequiresGradient)
           gradient
           (Or
              (Gradient RequiresGradient) queryGradient attentionBiasGradient))
        (Unify
           (Layout LayoutType)
           ('Layout 'Dense)
           (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
        generatorOutputDevice
        (Unify
           (DataType DType)
           dataType
           (Unify (DataType DType) queryDataType attentionBiasDataType))
        mhaOutputShape,
      Generator generatorOutputDevice)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: Type -&gt; Type).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">MultiHeadAttention
  'BERT
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  queryEmbedDim
  queryEmbedDim
  queryEmbedDim
SAMultiheadAttentionF
  'BERT
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  queryEmbedDim
</span><a href="#local-6989586621679805973"><span class="hs-identifier hs-var">saMultiHeadAttention</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">query
</span><a href="#local-6989586621679805968"><span class="hs-identifier hs-var">query'</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">query
</span><a href="#local-6989586621679805968"><span class="hs-identifier hs-var">query'</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">query
</span><a href="#local-6989586621679805968"><span class="hs-identifier hs-var">query'</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">attentionBias
</span><a href="#local-6989586621679805969"><span class="hs-identifier hs-var">attentionBias</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-571"></span><span>        </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorOutputDevice)
  (Tensor
     (Or
        (Gradient RequiresGradient)
        gradient
        (Or
           (Gradient RequiresGradient) queryGradient attentionBiasGradient))
     (Unify
        (Layout LayoutType)
        ('Layout 'Dense)
        (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
     generatorOutputDevice
     (Unify
        (DataType DType)
        dataType
        (Unify (DataType DType) queryDataType attentionBiasDataType))
     mhaOutputShape)
-&gt; (Tensor
      (Or
         (Gradient RequiresGradient)
         gradient
         (Or
            (Gradient RequiresGradient) queryGradient attentionBiasGradient))
      (Unify
         (Layout LayoutType)
         ('Layout 'Dense)
         (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
      generatorOutputDevice
      (Unify
         (DataType DType)
         dataType
         (Unify (DataType DType) queryDataType attentionBiasDataType))
      mhaOutputShape
    -&gt; IxStateT
         m
         (Generator generatorOutputDevice)
         (Generator generatorOutputDevice)
         (Tensor
            (Or
               (Gradient RequiresGradient)
               gradient
               (Or
                  (Gradient RequiresGradient) queryGradient attentionBiasGradient))
            (Unify
               (Layout LayoutType)
               ('Layout 'Dense)
               (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
            generatorOutputDevice
            (Unify
               (DataType DType)
               dataType
               (Unify (DataType DType) queryDataType attentionBiasDataType))
            mhaOutputShape))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorOutputDevice)
     (Tensor
        (Or
           (Gradient RequiresGradient)
           gradient
           (Or
              (Gradient RequiresGradient) queryGradient attentionBiasGradient))
        (Unify
           (Layout LayoutType)
           ('Layout 'Dense)
           (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
        generatorOutputDevice
        (Unify
           (DataType DType)
           dataType
           (Unify (DataType DType) queryDataType attentionBiasDataType))
        mhaOutputShape)
forall k1 (m :: k1 -&gt; k1 -&gt; Type -&gt; Type) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(Generator generatorOutputDevice
 -&gt; m (Tensor
         (Or
            (Gradient RequiresGradient)
            gradient
            (Or
               (Gradient RequiresGradient) queryGradient attentionBiasGradient))
         (Unify
            (Layout LayoutType)
            ('Layout 'Dense)
            (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
         generatorOutputDevice
         (Unify
            (DataType DType)
            dataType
            (Unify (DataType DType) queryDataType attentionBiasDataType))
         mhaOutputShape,
       Generator generatorOutputDevice))
-&gt; IxStateT
     m
     (Generator generatorOutputDevice)
     (Generator generatorOutputDevice)
     (Tensor
        (Or
           (Gradient RequiresGradient)
           gradient
           (Or
              (Gradient RequiresGradient) queryGradient attentionBiasGradient))
        (Unify
           (Layout LayoutType)
           ('Layout 'Dense)
           (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
        generatorOutputDevice
        (Unify
           (DataType DType)
           dataType
           (Unify (DataType DType) queryDataType attentionBiasDataType))
        mhaOutputShape)
forall (m :: Type -&gt; Type) i j a.
(i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator generatorOutputDevice
  -&gt; m (Tensor
          (Or
             (Gradient RequiresGradient)
             gradient
             (Or
                (Gradient RequiresGradient) queryGradient attentionBiasGradient))
          (Unify
             (Layout LayoutType)
             ('Layout 'Dense)
             (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
          generatorOutputDevice
          (Unify
             (DataType DType)
             dataType
             (Unify (DataType DType) queryDataType attentionBiasDataType))
          mhaOutputShape,
        Generator generatorOutputDevice))
 -&gt; IxStateT
      m
      (Generator generatorOutputDevice)
      (Generator generatorOutputDevice)
      (Tensor
         (Or
            (Gradient RequiresGradient)
            gradient
            (Or
               (Gradient RequiresGradient) queryGradient attentionBiasGradient))
         (Unify
            (Layout LayoutType)
            ('Layout 'Dense)
            (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
         generatorOutputDevice
         (Unify
            (DataType DType)
            dataType
            (Unify (DataType DType) queryDataType attentionBiasDataType))
         mhaOutputShape))
-&gt; (Tensor
      (Or
         (Gradient RequiresGradient)
         gradient
         (Or
            (Gradient RequiresGradient) queryGradient attentionBiasGradient))
      (Unify
         (Layout LayoutType)
         ('Layout 'Dense)
         (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
      generatorOutputDevice
      (Unify
         (DataType DType)
         dataType
         (Unify (DataType DType) queryDataType attentionBiasDataType))
      mhaOutputShape
    -&gt; Generator generatorOutputDevice
    -&gt; m (Tensor
            (Or
               (Gradient RequiresGradient)
               gradient
               (Or
                  (Gradient RequiresGradient) queryGradient attentionBiasGradient))
            (Unify
               (Layout LayoutType)
               ('Layout 'Dense)
               (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
            generatorOutputDevice
            (Unify
               (DataType DType)
               dataType
               (Unify (DataType DType) queryDataType attentionBiasDataType))
            mhaOutputShape,
          Generator generatorOutputDevice))
-&gt; Tensor
     (Or
        (Gradient RequiresGradient)
        gradient
        (Or
           (Gradient RequiresGradient) queryGradient attentionBiasGradient))
     (Unify
        (Layout LayoutType)
        ('Layout 'Dense)
        (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
     generatorOutputDevice
     (Unify
        (DataType DType)
        dataType
        (Unify (DataType DType) queryDataType attentionBiasDataType))
     mhaOutputShape
-&gt; IxStateT
     m
     (Generator generatorOutputDevice)
     (Generator generatorOutputDevice)
     (Tensor
        (Or
           (Gradient RequiresGradient)
           gradient
           (Or
              (Gradient RequiresGradient) queryGradient attentionBiasGradient))
        (Unify
           (Layout LayoutType)
           ('Layout 'Dense)
           (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
        generatorOutputDevice
        (Unify
           (DataType DType)
           dataType
           (Unify (DataType DType) queryDataType attentionBiasDataType))
        mhaOutputShape)
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Dropout
-&gt; Tensor
     (Or
        (Gradient RequiresGradient)
        gradient
        (Or
           (Gradient RequiresGradient) queryGradient attentionBiasGradient))
     (Unify
        (Layout LayoutType)
        ('Layout 'Dense)
        (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
     generatorOutputDevice
     (Unify
        (DataType DType)
        dataType
        (Unify (DataType DType) queryDataType attentionBiasDataType))
     mhaOutputShape
-&gt; Generator generatorOutputDevice
-&gt; m (Tensor
        (Or
           (Gradient RequiresGradient)
           gradient
           (Or
              (Gradient RequiresGradient) queryGradient attentionBiasGradient))
        (Unify
           (Layout LayoutType)
           ('Layout 'Dense)
           (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
        generatorOutputDevice
        (Unify
           (DataType DType)
           dataType
           (Unify (DataType DType) queryDataType attentionBiasDataType))
        mhaOutputShape,
      Generator generatorOutputDevice)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: Type -&gt; Type).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">Dropout
SADropoutF 'BERT
</span><a href="#local-6989586621679805971"><span class="hs-identifier hs-var">saDropout</span></a></span><span>
</span><span id="line-572"></span><span>        </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorOutputDevice)
  (Tensor
     (Or
        (Gradient RequiresGradient)
        gradient
        (Or
           (Gradient RequiresGradient) queryGradient attentionBiasGradient))
     (Unify
        (Layout LayoutType)
        ('Layout 'Dense)
        (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
     generatorOutputDevice
     (Unify
        (DataType DType)
        dataType
        (Unify (DataType DType) queryDataType attentionBiasDataType))
     mhaOutputShape)
-&gt; (Tensor
      (Or
         (Gradient RequiresGradient)
         gradient
         (Or
            (Gradient RequiresGradient) queryGradient attentionBiasGradient))
      (Unify
         (Layout LayoutType)
         ('Layout 'Dense)
         (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
      generatorOutputDevice
      (Unify
         (DataType DType)
         dataType
         (Unify (DataType DType) queryDataType attentionBiasDataType))
      mhaOutputShape
    -&gt; IxStateT
         m
         (Generator generatorOutputDevice)
         (Generator generatorOutputDevice)
         (Tensor
            (Or
               (Gradient RequiresGradient)
               queryGradient
               (Or
                  (Gradient RequiresGradient)
                  gradient
                  (Or
                     (Gradient RequiresGradient) queryGradient attentionBiasGradient)))
            (Unify
               (Layout LayoutType)
               queryLayout
               (Unify
                  (Layout LayoutType)
                  ('Layout 'Dense)
                  (Unify (Layout LayoutType) queryLayout attentionBiasLayout)))
            (Unify (Device (DeviceType Nat)) queryDevice generatorOutputDevice)
            (Unify
               (DataType DType)
               queryDataType
               (Unify
                  (DataType DType)
                  dataType
                  (Unify (DataType DType) queryDataType attentionBiasDataType)))
            (BroadcastShapesF queryShape mhaOutputShape)))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorOutputDevice)
     (Tensor
        (Or
           (Gradient RequiresGradient)
           queryGradient
           (Or
              (Gradient RequiresGradient)
              gradient
              (Or
                 (Gradient RequiresGradient) queryGradient attentionBiasGradient)))
        (Unify
           (Layout LayoutType)
           queryLayout
           (Unify
              (Layout LayoutType)
              ('Layout 'Dense)
              (Unify (Layout LayoutType) queryLayout attentionBiasLayout)))
        (Unify (Device (DeviceType Nat)) queryDevice generatorOutputDevice)
        (Unify
           (DataType DType)
           queryDataType
           (Unify
              (DataType DType)
              dataType
              (Unify (DataType DType) queryDataType attentionBiasDataType)))
        (BroadcastShapesF queryShape mhaOutputShape))
forall k1 (m :: k1 -&gt; k1 -&gt; Type -&gt; Type) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  (Or
     (Gradient RequiresGradient)
     queryGradient
     (Or
        (Gradient RequiresGradient)
        gradient
        (Or
           (Gradient RequiresGradient) queryGradient attentionBiasGradient)))
  (Unify
     (Layout LayoutType)
     queryLayout
     (Unify
        (Layout LayoutType)
        ('Layout 'Dense)
        (Unify (Layout LayoutType) queryLayout attentionBiasLayout)))
  (Unify (Device (DeviceType Nat)) queryDevice generatorOutputDevice)
  (Unify
     (DataType DType)
     queryDataType
     (Unify
        (DataType DType)
        dataType
        (Unify (DataType DType) queryDataType attentionBiasDataType)))
  (BroadcastShapesF queryShape mhaOutputShape)
-&gt; IxStateT
     m
     (Generator generatorOutputDevice)
     (Generator generatorOutputDevice)
     (Tensor
        (Or
           (Gradient RequiresGradient)
           queryGradient
           (Or
              (Gradient RequiresGradient)
              gradient
              (Or
                 (Gradient RequiresGradient) queryGradient attentionBiasGradient)))
        (Unify
           (Layout LayoutType)
           queryLayout
           (Unify
              (Layout LayoutType)
              ('Layout 'Dense)
              (Unify (Layout LayoutType) queryLayout attentionBiasLayout)))
        (Unify (Device (DeviceType Nat)) queryDevice generatorOutputDevice)
        (Unify
           (DataType DType)
           queryDataType
           (Unify
              (DataType DType)
              dataType
              (Unify (DataType DType) queryDataType attentionBiasDataType)))
        (BroadcastShapesF queryShape mhaOutputShape))
forall k (m :: k -&gt; k -&gt; Type -&gt; Type) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">(Tensor
   (Or
      (Gradient RequiresGradient)
      queryGradient
      (Or
         (Gradient RequiresGradient)
         gradient
         (Or
            (Gradient RequiresGradient) queryGradient attentionBiasGradient)))
   (Unify
      (Layout LayoutType)
      queryLayout
      (Unify
         (Layout LayoutType)
         ('Layout 'Dense)
         (Unify (Layout LayoutType) queryLayout attentionBiasLayout)))
   (Unify (Device (DeviceType Nat)) queryDevice generatorOutputDevice)
   (Unify
      (DataType DType)
      queryDataType
      (Unify
         (DataType DType)
         dataType
         (Unify (DataType DType) queryDataType attentionBiasDataType)))
   (BroadcastShapesF queryShape mhaOutputShape)
 -&gt; IxStateT
      m
      (Generator generatorOutputDevice)
      (Generator generatorOutputDevice)
      (Tensor
         (Or
            (Gradient RequiresGradient)
            queryGradient
            (Or
               (Gradient RequiresGradient)
               gradient
               (Or
                  (Gradient RequiresGradient) queryGradient attentionBiasGradient)))
         (Unify
            (Layout LayoutType)
            queryLayout
            (Unify
               (Layout LayoutType)
               ('Layout 'Dense)
               (Unify (Layout LayoutType) queryLayout attentionBiasLayout)))
         (Unify (Device (DeviceType Nat)) queryDevice generatorOutputDevice)
         (Unify
            (DataType DType)
            queryDataType
            (Unify
               (DataType DType)
               dataType
               (Unify (DataType DType) queryDataType attentionBiasDataType)))
         (BroadcastShapesF queryShape mhaOutputShape)))
-&gt; (Tensor
      (Or
         (Gradient RequiresGradient)
         gradient
         (Or
            (Gradient RequiresGradient) queryGradient attentionBiasGradient))
      (Unify
         (Layout LayoutType)
         ('Layout 'Dense)
         (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
      generatorOutputDevice
      (Unify
         (DataType DType)
         dataType
         (Unify (DataType DType) queryDataType attentionBiasDataType))
      mhaOutputShape
    -&gt; Tensor
         (Or
            (Gradient RequiresGradient)
            queryGradient
            (Or
               (Gradient RequiresGradient)
               gradient
               (Or
                  (Gradient RequiresGradient) queryGradient attentionBiasGradient)))
         (Unify
            (Layout LayoutType)
            queryLayout
            (Unify
               (Layout LayoutType)
               ('Layout 'Dense)
               (Unify (Layout LayoutType) queryLayout attentionBiasLayout)))
         (Unify (Device (DeviceType Nat)) queryDevice generatorOutputDevice)
         (Unify
            (DataType DType)
            queryDataType
            (Unify
               (DataType DType)
               dataType
               (Unify (DataType DType) queryDataType attentionBiasDataType)))
         (BroadcastShapesF queryShape mhaOutputShape))
-&gt; Tensor
     (Or
        (Gradient RequiresGradient)
        gradient
        (Or
           (Gradient RequiresGradient) queryGradient attentionBiasGradient))
     (Unify
        (Layout LayoutType)
        ('Layout 'Dense)
        (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
     generatorOutputDevice
     (Unify
        (DataType DType)
        dataType
        (Unify (DataType DType) queryDataType attentionBiasDataType))
     mhaOutputShape
-&gt; IxStateT
     m
     (Generator generatorOutputDevice)
     (Generator generatorOutputDevice)
     (Tensor
        (Or
           (Gradient RequiresGradient)
           queryGradient
           (Or
              (Gradient RequiresGradient)
              gradient
              (Or
                 (Gradient RequiresGradient) queryGradient attentionBiasGradient)))
        (Unify
           (Layout LayoutType)
           queryLayout
           (Unify
              (Layout LayoutType)
              ('Layout 'Dense)
              (Unify (Layout LayoutType) queryLayout attentionBiasLayout)))
        (Unify (Device (DeviceType Nat)) queryDevice generatorOutputDevice)
        (Unify
           (DataType DType)
           queryDataType
           (Unify
              (DataType DType)
              dataType
              (Unify (DataType DType) queryDataType attentionBiasDataType)))
        (BroadcastShapesF queryShape mhaOutputShape))
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">query
Tensor
  queryGradient queryLayout queryDevice queryDataType queryShape
</span><a href="#local-6989586621679805970"><span class="hs-identifier hs-var">query</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  queryGradient queryLayout queryDevice queryDataType queryShape
-&gt; Tensor
     (Or
        (Gradient RequiresGradient)
        gradient
        (Or
           (Gradient RequiresGradient) queryGradient attentionBiasGradient))
     (Unify
        (Layout LayoutType)
        ('Layout 'Dense)
        (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
     generatorOutputDevice
     (Unify
        (DataType DType)
        dataType
        (Unify (DataType DType) queryDataType attentionBiasDataType))
     mhaOutputShape
-&gt; Tensor
     (queryGradient
      &lt;|&gt; Or
            (Gradient RequiresGradient)
            gradient
            (Or
               (Gradient RequiresGradient) queryGradient attentionBiasGradient))
     (queryLayout
      &lt;+&gt; Unify
            (Layout LayoutType)
            ('Layout 'Dense)
            (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
     (queryDevice &lt;+&gt; generatorOutputDevice)
     (queryDataType
      &lt;+&gt; Unify
            (DataType DType)
            dataType
            (Unify (DataType DType) queryDataType attentionBiasDataType))
     (BroadcastShapesF queryShape mhaOutputShape)
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (gradient' :: Gradient RequiresGradient)
       (layout' :: Layout LayoutType) (device' :: Device (DeviceType Nat))
       (dataType' :: DataType DType)
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]).
Tensor gradient layout device dataType shape
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; Tensor
     (gradient &lt;|&gt; gradient')
     (layout &lt;+&gt; layout')
     (device &lt;+&gt; device')
     (dataType &lt;+&gt; dataType')
     (BroadcastShapesF shape shape')
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#add"><span class="hs-operator hs-var">`add`</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-573"></span><span>        </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorOutputDevice)
  (Tensor
     (Or
        (Gradient RequiresGradient)
        queryGradient
        (Or
           (Gradient RequiresGradient)
           gradient
           (Or
              (Gradient RequiresGradient) queryGradient attentionBiasGradient)))
     (Unify
        (Layout LayoutType)
        queryLayout
        (Unify
           (Layout LayoutType)
           ('Layout 'Dense)
           (Unify (Layout LayoutType) queryLayout attentionBiasLayout)))
     (Unify (Device (DeviceType Nat)) queryDevice generatorOutputDevice)
     (Unify
        (DataType DType)
        queryDataType
        (Unify
           (DataType DType)
           dataType
           (Unify (DataType DType) queryDataType attentionBiasDataType)))
     (BroadcastShapesF queryShape mhaOutputShape))
-&gt; (Tensor
      (Or
         (Gradient RequiresGradient)
         queryGradient
         (Or
            (Gradient RequiresGradient)
            gradient
            (Or
               (Gradient RequiresGradient) queryGradient attentionBiasGradient)))
      (Unify
         (Layout LayoutType)
         queryLayout
         (Unify
            (Layout LayoutType)
            ('Layout 'Dense)
            (Unify (Layout LayoutType) queryLayout attentionBiasLayout)))
      (Unify (Device (DeviceType Nat)) queryDevice generatorOutputDevice)
      (Unify
         (DataType DType)
         queryDataType
         (Unify
            (DataType DType)
            dataType
            (Unify (DataType DType) queryDataType attentionBiasDataType)))
      (BroadcastShapesF queryShape mhaOutputShape)
    -&gt; IxStateT
         m
         (Generator generatorOutputDevice)
         (Generator generatorOutputDevice)
         output)
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorOutputDevice)
     output
forall k1 (m :: k1 -&gt; k1 -&gt; Type -&gt; Type) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(Generator generatorOutputDevice
 -&gt; m (output, Generator generatorOutputDevice))
-&gt; IxStateT
     m
     (Generator generatorOutputDevice)
     (Generator generatorOutputDevice)
     output
forall (m :: Type -&gt; Type) i j a.
(i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator generatorOutputDevice
  -&gt; m (output, Generator generatorOutputDevice))
 -&gt; IxStateT
      m
      (Generator generatorOutputDevice)
      (Generator generatorOutputDevice)
      output)
-&gt; (Tensor
      (Or
         (Gradient RequiresGradient)
         queryGradient
         (Or
            (Gradient RequiresGradient)
            gradient
            (Or
               (Gradient RequiresGradient) queryGradient attentionBiasGradient)))
      (Unify
         (Layout LayoutType)
         queryLayout
         (Unify
            (Layout LayoutType)
            ('Layout 'Dense)
            (Unify (Layout LayoutType) queryLayout attentionBiasLayout)))
      (Unify (Device (DeviceType Nat)) queryDevice generatorOutputDevice)
      (Unify
         (DataType DType)
         queryDataType
         (Unify
            (DataType DType)
            dataType
            (Unify (DataType DType) queryDataType attentionBiasDataType)))
      (BroadcastShapesF queryShape mhaOutputShape)
    -&gt; Generator generatorOutputDevice
    -&gt; m (output, Generator generatorOutputDevice))
-&gt; Tensor
     (Or
        (Gradient RequiresGradient)
        queryGradient
        (Or
           (Gradient RequiresGradient)
           gradient
           (Or
              (Gradient RequiresGradient) queryGradient attentionBiasGradient)))
     (Unify
        (Layout LayoutType)
        queryLayout
        (Unify
           (Layout LayoutType)
           ('Layout 'Dense)
           (Unify (Layout LayoutType) queryLayout attentionBiasLayout)))
     (Unify (Device (DeviceType Nat)) queryDevice generatorOutputDevice)
     (Unify
        (DataType DType)
        queryDataType
        (Unify
           (DataType DType)
           dataType
           (Unify (DataType DType) queryDataType attentionBiasDataType)))
     (BroadcastShapesF queryShape mhaOutputShape)
-&gt; IxStateT
     m
     (Generator generatorOutputDevice)
     (Generator generatorOutputDevice)
     output
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">LayerNorm
  'WithBias gradient device dataType ('Shape '[queryEmbedDim])
-&gt; Tensor
     (Or
        (Gradient RequiresGradient)
        queryGradient
        (Or
           (Gradient RequiresGradient)
           gradient
           (Or
              (Gradient RequiresGradient) queryGradient attentionBiasGradient)))
     (Unify
        (Layout LayoutType)
        queryLayout
        (Unify
           (Layout LayoutType)
           ('Layout 'Dense)
           (Unify (Layout LayoutType) queryLayout attentionBiasLayout)))
     (Unify (Device (DeviceType Nat)) queryDevice generatorOutputDevice)
     (Unify
        (DataType DType)
        queryDataType
        (Unify
           (DataType DType)
           dataType
           (Unify (DataType DType) queryDataType attentionBiasDataType)))
     (BroadcastShapesF queryShape mhaOutputShape)
-&gt; Generator generatorOutputDevice
-&gt; m (output, Generator generatorOutputDevice)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: Type -&gt; Type).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">LayerNorm
  'WithBias gradient device dataType ('Shape '[queryEmbedDim])
SALayerNormF 'BERT gradient device dataType queryEmbedDim
</span><a href="#local-6989586621679805972"><span class="hs-identifier hs-var">saLayerNorm</span></a></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span>
</span><span id="line-574"></span><span>
</span><span id="line-575"></span><span class="hs-comment">-- | 'HasForward' instance for @SelfAttention 'RoBERTa@.</span><span>
</span><span id="line-576"></span><span class="hs-comment">--</span><span>
</span><span id="line-577"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-578"></span><span class="hs-comment">-- &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;      &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;</span><span>
</span><span id="line-579"></span><span class="hs-comment">-- &#9474; attentionBias &#9474;      &#9474; query &#9474;</span><span>
</span><span id="line-580"></span><span class="hs-comment">-- &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;      &#9492;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-581"></span><span class="hs-comment">--         &#9474;                  &#9474;</span><span>
</span><span id="line-582"></span><span class="hs-comment">--         &#9474;            &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9524;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;</span><span>
</span><span id="line-583"></span><span class="hs-comment">--         &#9474;            &#9474;           &#9474;</span><span>
</span><span id="line-584"></span><span class="hs-comment">--         &#9474;       &#9484;&#9472;&#9472;&#9472;&#9472;&#9532;&#9472;&#9472;&#9472;&#9472;&#9488;      &#9474;</span><span>
</span><span id="line-585"></span><span class="hs-comment">--         &#9474;       &#9474;    &#9474;    &#9474;      &#9474;</span><span>
</span><span id="line-586"></span><span class="hs-comment">--         &#9474;       &#9660;    &#9660;    &#9660;      &#9474;</span><span>
</span><span id="line-587"></span><span class="hs-comment">--         &#9492;&#9472;&#9658;saMultiHeadAttention  &#9474;</span><span>
</span><span id="line-588"></span><span class="hs-comment">--                      &#9474;           &#9474;</span><span>
</span><span id="line-589"></span><span class="hs-comment">--                      &#9660;           &#9474;</span><span>
</span><span id="line-590"></span><span class="hs-comment">--                  saDropout       &#9474;</span><span>
</span><span id="line-591"></span><span class="hs-comment">--                      &#9474;           &#9474;</span><span>
</span><span id="line-592"></span><span class="hs-comment">--                      &#9492;&#9472;&#9472;&#9472;&#9658;add&#9668;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-593"></span><span class="hs-comment">--                            &#9474;</span><span>
</span><span id="line-594"></span><span class="hs-comment">--                            &#9660;</span><span>
</span><span id="line-595"></span><span class="hs-comment">--                       saLayerNorm</span><span>
</span><span id="line-596"></span><span class="hs-comment">--                            &#9474;</span><span>
</span><span id="line-597"></span><span class="hs-comment">--                            &#9660;</span><span>
</span><span id="line-598"></span><span class="hs-comment">--                        &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;</span><span>
</span><span id="line-599"></span><span class="hs-comment">--                        &#9474; query &#9474;</span><span>
</span><span id="line-600"></span><span class="hs-comment">--                        &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-601"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-602"></span><span id="local-6989586621679805945"><span id="local-6989586621679805946"><span id="local-6989586621679805947"><span id="local-6989586621679805948"><span id="local-6989586621679805949"><span id="local-6989586621679805950"><span id="local-6989586621679805951"><span id="local-6989586621679805952"><span id="local-6989586621679805953"><span id="local-6989586621679805954"><span id="local-6989586621679805955"><span id="local-6989586621679805956"><span id="local-6989586621679805957"><span id="local-6989586621679805958"><span id="local-6989586621679805959"><span id="local-6989586621679805960"><span id="local-6989586621679805961"><span id="local-6989586621679805962"><span id="local-6989586621679805963"><span id="local-6989586621679805964"><span id="local-6989586621679805965"><span id="local-6989586621679805966"><span id="local-6989586621679805967"><span class="hs-keyword">instance</span><span>
</span><span id="line-603"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetDim"><span class="hs-identifier hs-type">SGetDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805967"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-604"></span><span>    </span><span class="annot"><a href="#local-6989586621679805966"><span class="hs-identifier hs-type">query</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805965"><span class="hs-identifier hs-type">queryGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805964"><span class="hs-identifier hs-type">queryLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805963"><span class="hs-identifier hs-type">queryDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805962"><span class="hs-identifier hs-type">queryDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805961"><span class="hs-identifier hs-type">queryShape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-605"></span><span>    </span><span class="annot"><a href="#local-6989586621679805960"><span class="hs-identifier hs-type">attentionBias</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805959"><span class="hs-identifier hs-type">attentionBiasGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805958"><span class="hs-identifier hs-type">attentionBiasLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805957"><span class="hs-identifier hs-type">attentionBiasDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805956"><span class="hs-identifier hs-type">attentionBiasDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805955"><span class="hs-identifier hs-type">attentionBiasShape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-606"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-607"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.MultiHeadAttention.html#MultiHeadAttention"><span class="hs-identifier hs-type">MultiHeadAttention</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#RoBERTa"><span class="hs-identifier hs-type">RoBERTa</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805954"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805953"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805952"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805951"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805950"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805949"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805967"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805967"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805967"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-608"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679805966"><span class="hs-identifier hs-type">query</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679805966"><span class="hs-identifier hs-type">query</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679805966"><span class="hs-identifier hs-type">query</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679805960"><span class="hs-identifier hs-type">attentionBias</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-609"></span><span>      </span><span class="annot"><a href="#local-6989586621679805948"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-610"></span><span>      </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-611"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679805954"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805965"><span class="hs-identifier hs-type">queryGradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805959"><span class="hs-identifier hs-type">attentionBiasGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-612"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Dense"><span class="hs-identifier hs-type">Dense</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805964"><span class="hs-identifier hs-type">queryLayout</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805958"><span class="hs-identifier hs-type">attentionBiasLayout</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-613"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679805953"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805963"><span class="hs-identifier hs-type">queryDevice</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805957"><span class="hs-identifier hs-type">attentionBiasDevice</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805948"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-614"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679805952"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805962"><span class="hs-identifier hs-type">queryDataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805956"><span class="hs-identifier hs-type">attentionBiasDataType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-615"></span><span>          </span><span class="annot"><a href="#local-6989586621679805947"><span class="hs-identifier hs-type">mhaOutputShape</span></a></span><span>
</span><span id="line-616"></span><span>      </span><span class="hs-special">)</span><span>
</span><span id="line-617"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679805953"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805963"><span class="hs-identifier hs-type">queryDevice</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805957"><span class="hs-identifier hs-type">attentionBiasDevice</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805948"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-618"></span><span>    </span><span class="annot"><a href="#local-6989586621679805946"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-619"></span><span>      </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-620"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679805954"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805965"><span class="hs-identifier hs-type">queryGradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805959"><span class="hs-identifier hs-type">attentionBiasGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-621"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Dense"><span class="hs-identifier hs-type">Dense</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805964"><span class="hs-identifier hs-type">queryLayout</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805958"><span class="hs-identifier hs-type">attentionBiasLayout</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-622"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679805953"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805963"><span class="hs-identifier hs-type">queryDevice</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805957"><span class="hs-identifier hs-type">attentionBiasDevice</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805948"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-623"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679805952"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805962"><span class="hs-identifier hs-type">queryDataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805956"><span class="hs-identifier hs-type">attentionBiasDataType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-624"></span><span>          </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Functional.Normalization.html#LayerNormWithBiasF"><span class="hs-identifier hs-type">LayerNormWithBiasF</span></a></span><span>
</span><span id="line-625"></span><span>              </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679805967"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-626"></span><span>              </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679805967"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-627"></span><span>              </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#BroadcastShapesF"><span class="hs-identifier hs-type">BroadcastShapesF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805961"><span class="hs-identifier hs-type">queryShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805947"><span class="hs-identifier hs-type">mhaOutputShape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-628"></span><span>          </span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-629"></span><span>    </span><span class="annot"><a href="#local-6989586621679805945"><span class="hs-identifier hs-type">generatorOutputDevice</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679805953"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805963"><span class="hs-identifier hs-type">queryDevice</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805957"><span class="hs-identifier hs-type">attentionBiasDevice</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805948"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-630"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-631"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-632"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#SelfAttention"><span class="hs-identifier hs-type">SelfAttention</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#RoBERTa"><span class="hs-identifier hs-type">RoBERTa</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805954"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805953"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805952"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805951"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805950"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805949"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805967"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-633"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679805966"><span class="hs-identifier hs-type">query</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679805960"><span class="hs-identifier hs-type">attentionBias</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-634"></span><span>    </span><span class="annot"><a href="#local-6989586621679805948"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-635"></span><span>    </span><span class="annot"><a href="#local-6989586621679805946"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-636"></span><span>    </span><span class="annot"><a href="#local-6989586621679805945"><span class="hs-identifier hs-type">generatorOutputDevice</span></a></span><span>
</span><span id="line-637"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-638"></span><span>  </span><span id="local-6989586621679805943"><span class="annot"><span class="annottext">forward :: SelfAttention
  'RoBERTa
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  queryEmbedDim
-&gt; (query, attentionBias)
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="#local-6989586621679805943"><span class="hs-identifier hs-var hs-var hs-var hs-var">forward</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#SelfAttention"><span class="hs-identifier hs-type">SelfAttention</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#GSelfAttention"><span class="hs-identifier hs-type">GSelfAttention</span></a></span><span> </span><span class="hs-special">{</span><span id="local-6989586621679805940"><span id="local-6989586621679805941"><span id="local-6989586621679805942"><span class="annot"><span class="annottext">SADropoutF 'RoBERTa
SALayerNormF 'RoBERTa gradient device dataType queryEmbedDim
SAMultiheadAttentionF
  'RoBERTa
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  queryEmbedDim
saDropout :: SADropoutF 'RoBERTa
saLayerNorm :: SALayerNormF 'RoBERTa gradient device dataType queryEmbedDim
saMultiHeadAttention :: SAMultiheadAttentionF
  'RoBERTa
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  queryEmbedDim
saDropout :: forall mha layerNorm dropout.
GSelfAttention mha layerNorm dropout -&gt; dropout
saLayerNorm :: forall mha layerNorm dropout.
GSelfAttention mha layerNorm dropout -&gt; layerNorm
saMultiHeadAttention :: forall mha layerNorm dropout.
GSelfAttention mha layerNorm dropout -&gt; mha
</span><a href="#local-6989586621679805940"><span class="hs-glyph hs-var hs-var hs-var hs-var hs-var hs-var">..</span></a></span></span></span></span><span class="hs-special">}</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679805939"><span class="annot"><span class="annottext">query
</span><a href="#local-6989586621679805939"><span class="hs-identifier hs-var">query</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679805938"><span class="annot"><span class="annottext">attentionBias
</span><a href="#local-6989586621679805938"><span class="hs-identifier hs-var">attentionBias</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-639"></span><span>    </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorOutputDevice)
  output
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
forall (m :: Type -&gt; Type) i j a. IxStateT m i j a -&gt; i -&gt; m (a, j)
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var hs-var">runIxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">(IxStateT
   m
   (Generator generatorDevice)
   (Generator generatorOutputDevice)
   output
 -&gt; Generator generatorDevice
 -&gt; m (output, Generator generatorOutputDevice))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorOutputDevice)
     output
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-640"></span><span>      </span><span class="annot"><span class="annottext">query
-&gt; IxStateT
     m (Generator generatorDevice) (Generator generatorDevice) query
forall k (m :: k -&gt; k -&gt; Type -&gt; Type) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">query
</span><a href="#local-6989586621679805939"><span class="hs-identifier hs-var">query</span></a></span><span>
</span><span id="line-641"></span><span>        </span><span class="annot"><span class="annottext">IxStateT
  m (Generator generatorDevice) (Generator generatorDevice) query
-&gt; (query
    -&gt; IxStateT
         m
         (Generator generatorDevice)
         (Generator generatorOutputDevice)
         (Tensor
            (Or
               (Gradient RequiresGradient)
               gradient
               (Or
                  (Gradient RequiresGradient) queryGradient attentionBiasGradient))
            (Unify
               (Layout LayoutType)
               ('Layout 'Dense)
               (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
            generatorOutputDevice
            (Unify
               (DataType DType)
               dataType
               (Unify (DataType DType) queryDataType attentionBiasDataType))
            mhaOutputShape))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorOutputDevice)
     (Tensor
        (Or
           (Gradient RequiresGradient)
           gradient
           (Or
              (Gradient RequiresGradient) queryGradient attentionBiasGradient))
        (Unify
           (Layout LayoutType)
           ('Layout 'Dense)
           (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
        generatorOutputDevice
        (Unify
           (DataType DType)
           dataType
           (Unify (DataType DType) queryDataType attentionBiasDataType))
        mhaOutputShape)
forall k1 (m :: k1 -&gt; k1 -&gt; Type -&gt; Type) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">\</span><span id="local-6989586621679805937"><span class="annot"><span class="annottext">query
</span><a href="#local-6989586621679805937"><span class="hs-identifier hs-var">query'</span></a></span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">(Generator generatorDevice
 -&gt; m (Tensor
         (Or
            (Gradient RequiresGradient)
            gradient
            (Or
               (Gradient RequiresGradient) queryGradient attentionBiasGradient))
         (Unify
            (Layout LayoutType)
            ('Layout 'Dense)
            (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
         generatorOutputDevice
         (Unify
            (DataType DType)
            dataType
            (Unify (DataType DType) queryDataType attentionBiasDataType))
         mhaOutputShape,
       Generator generatorOutputDevice))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorOutputDevice)
     (Tensor
        (Or
           (Gradient RequiresGradient)
           gradient
           (Or
              (Gradient RequiresGradient) queryGradient attentionBiasGradient))
        (Unify
           (Layout LayoutType)
           ('Layout 'Dense)
           (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
        generatorOutputDevice
        (Unify
           (DataType DType)
           dataType
           (Unify (DataType DType) queryDataType attentionBiasDataType))
        mhaOutputShape)
forall (m :: Type -&gt; Type) i j a.
(i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator generatorDevice
  -&gt; m (Tensor
          (Or
             (Gradient RequiresGradient)
             gradient
             (Or
                (Gradient RequiresGradient) queryGradient attentionBiasGradient))
          (Unify
             (Layout LayoutType)
             ('Layout 'Dense)
             (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
          generatorOutputDevice
          (Unify
             (DataType DType)
             dataType
             (Unify (DataType DType) queryDataType attentionBiasDataType))
          mhaOutputShape,
        Generator generatorOutputDevice))
 -&gt; IxStateT
      m
      (Generator generatorDevice)
      (Generator generatorOutputDevice)
      (Tensor
         (Or
            (Gradient RequiresGradient)
            gradient
            (Or
               (Gradient RequiresGradient) queryGradient attentionBiasGradient))
         (Unify
            (Layout LayoutType)
            ('Layout 'Dense)
            (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
         generatorOutputDevice
         (Unify
            (DataType DType)
            dataType
            (Unify (DataType DType) queryDataType attentionBiasDataType))
         mhaOutputShape))
-&gt; (Generator generatorDevice
    -&gt; m (Tensor
            (Or
               (Gradient RequiresGradient)
               gradient
               (Or
                  (Gradient RequiresGradient) queryGradient attentionBiasGradient))
            (Unify
               (Layout LayoutType)
               ('Layout 'Dense)
               (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
            generatorOutputDevice
            (Unify
               (DataType DType)
               dataType
               (Unify (DataType DType) queryDataType attentionBiasDataType))
            mhaOutputShape,
          Generator generatorOutputDevice))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorOutputDevice)
     (Tensor
        (Or
           (Gradient RequiresGradient)
           gradient
           (Or
              (Gradient RequiresGradient) queryGradient attentionBiasGradient))
        (Unify
           (Layout LayoutType)
           ('Layout 'Dense)
           (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
        generatorOutputDevice
        (Unify
           (DataType DType)
           dataType
           (Unify (DataType DType) queryDataType attentionBiasDataType))
        mhaOutputShape)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">MultiHeadAttention
  'RoBERTa
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  queryEmbedDim
  queryEmbedDim
  queryEmbedDim
-&gt; (query, query, query, attentionBias)
-&gt; Generator generatorDevice
-&gt; m (Tensor
        (Or
           (Gradient RequiresGradient)
           gradient
           (Or
              (Gradient RequiresGradient) queryGradient attentionBiasGradient))
        (Unify
           (Layout LayoutType)
           ('Layout 'Dense)
           (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
        generatorOutputDevice
        (Unify
           (DataType DType)
           dataType
           (Unify (DataType DType) queryDataType attentionBiasDataType))
        mhaOutputShape,
      Generator generatorOutputDevice)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: Type -&gt; Type).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">MultiHeadAttention
  'RoBERTa
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  queryEmbedDim
  queryEmbedDim
  queryEmbedDim
SAMultiheadAttentionF
  'RoBERTa
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  queryEmbedDim
</span><a href="#local-6989586621679805942"><span class="hs-identifier hs-var">saMultiHeadAttention</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">query
</span><a href="#local-6989586621679805937"><span class="hs-identifier hs-var">query'</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">query
</span><a href="#local-6989586621679805937"><span class="hs-identifier hs-var">query'</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">query
</span><a href="#local-6989586621679805937"><span class="hs-identifier hs-var">query'</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">attentionBias
</span><a href="#local-6989586621679805938"><span class="hs-identifier hs-var">attentionBias</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-642"></span><span>        </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorOutputDevice)
  (Tensor
     (Or
        (Gradient RequiresGradient)
        gradient
        (Or
           (Gradient RequiresGradient) queryGradient attentionBiasGradient))
     (Unify
        (Layout LayoutType)
        ('Layout 'Dense)
        (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
     generatorOutputDevice
     (Unify
        (DataType DType)
        dataType
        (Unify (DataType DType) queryDataType attentionBiasDataType))
     mhaOutputShape)
-&gt; (Tensor
      (Or
         (Gradient RequiresGradient)
         gradient
         (Or
            (Gradient RequiresGradient) queryGradient attentionBiasGradient))
      (Unify
         (Layout LayoutType)
         ('Layout 'Dense)
         (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
      generatorOutputDevice
      (Unify
         (DataType DType)
         dataType
         (Unify (DataType DType) queryDataType attentionBiasDataType))
      mhaOutputShape
    -&gt; IxStateT
         m
         (Generator generatorOutputDevice)
         (Generator generatorOutputDevice)
         (Tensor
            (Or
               (Gradient RequiresGradient)
               gradient
               (Or
                  (Gradient RequiresGradient) queryGradient attentionBiasGradient))
            (Unify
               (Layout LayoutType)
               ('Layout 'Dense)
               (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
            generatorOutputDevice
            (Unify
               (DataType DType)
               dataType
               (Unify (DataType DType) queryDataType attentionBiasDataType))
            mhaOutputShape))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorOutputDevice)
     (Tensor
        (Or
           (Gradient RequiresGradient)
           gradient
           (Or
              (Gradient RequiresGradient) queryGradient attentionBiasGradient))
        (Unify
           (Layout LayoutType)
           ('Layout 'Dense)
           (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
        generatorOutputDevice
        (Unify
           (DataType DType)
           dataType
           (Unify (DataType DType) queryDataType attentionBiasDataType))
        mhaOutputShape)
forall k1 (m :: k1 -&gt; k1 -&gt; Type -&gt; Type) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(Generator generatorOutputDevice
 -&gt; m (Tensor
         (Or
            (Gradient RequiresGradient)
            gradient
            (Or
               (Gradient RequiresGradient) queryGradient attentionBiasGradient))
         (Unify
            (Layout LayoutType)
            ('Layout 'Dense)
            (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
         generatorOutputDevice
         (Unify
            (DataType DType)
            dataType
            (Unify (DataType DType) queryDataType attentionBiasDataType))
         mhaOutputShape,
       Generator generatorOutputDevice))
-&gt; IxStateT
     m
     (Generator generatorOutputDevice)
     (Generator generatorOutputDevice)
     (Tensor
        (Or
           (Gradient RequiresGradient)
           gradient
           (Or
              (Gradient RequiresGradient) queryGradient attentionBiasGradient))
        (Unify
           (Layout LayoutType)
           ('Layout 'Dense)
           (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
        generatorOutputDevice
        (Unify
           (DataType DType)
           dataType
           (Unify (DataType DType) queryDataType attentionBiasDataType))
        mhaOutputShape)
forall (m :: Type -&gt; Type) i j a.
(i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator generatorOutputDevice
  -&gt; m (Tensor
          (Or
             (Gradient RequiresGradient)
             gradient
             (Or
                (Gradient RequiresGradient) queryGradient attentionBiasGradient))
          (Unify
             (Layout LayoutType)
             ('Layout 'Dense)
             (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
          generatorOutputDevice
          (Unify
             (DataType DType)
             dataType
             (Unify (DataType DType) queryDataType attentionBiasDataType))
          mhaOutputShape,
        Generator generatorOutputDevice))
 -&gt; IxStateT
      m
      (Generator generatorOutputDevice)
      (Generator generatorOutputDevice)
      (Tensor
         (Or
            (Gradient RequiresGradient)
            gradient
            (Or
               (Gradient RequiresGradient) queryGradient attentionBiasGradient))
         (Unify
            (Layout LayoutType)
            ('Layout 'Dense)
            (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
         generatorOutputDevice
         (Unify
            (DataType DType)
            dataType
            (Unify (DataType DType) queryDataType attentionBiasDataType))
         mhaOutputShape))
-&gt; (Tensor
      (Or
         (Gradient RequiresGradient)
         gradient
         (Or
            (Gradient RequiresGradient) queryGradient attentionBiasGradient))
      (Unify
         (Layout LayoutType)
         ('Layout 'Dense)
         (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
      generatorOutputDevice
      (Unify
         (DataType DType)
         dataType
         (Unify (DataType DType) queryDataType attentionBiasDataType))
      mhaOutputShape
    -&gt; Generator generatorOutputDevice
    -&gt; m (Tensor
            (Or
               (Gradient RequiresGradient)
               gradient
               (Or
                  (Gradient RequiresGradient) queryGradient attentionBiasGradient))
            (Unify
               (Layout LayoutType)
               ('Layout 'Dense)
               (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
            generatorOutputDevice
            (Unify
               (DataType DType)
               dataType
               (Unify (DataType DType) queryDataType attentionBiasDataType))
            mhaOutputShape,
          Generator generatorOutputDevice))
-&gt; Tensor
     (Or
        (Gradient RequiresGradient)
        gradient
        (Or
           (Gradient RequiresGradient) queryGradient attentionBiasGradient))
     (Unify
        (Layout LayoutType)
        ('Layout 'Dense)
        (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
     generatorOutputDevice
     (Unify
        (DataType DType)
        dataType
        (Unify (DataType DType) queryDataType attentionBiasDataType))
     mhaOutputShape
-&gt; IxStateT
     m
     (Generator generatorOutputDevice)
     (Generator generatorOutputDevice)
     (Tensor
        (Or
           (Gradient RequiresGradient)
           gradient
           (Or
              (Gradient RequiresGradient) queryGradient attentionBiasGradient))
        (Unify
           (Layout LayoutType)
           ('Layout 'Dense)
           (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
        generatorOutputDevice
        (Unify
           (DataType DType)
           dataType
           (Unify (DataType DType) queryDataType attentionBiasDataType))
        mhaOutputShape)
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Dropout
-&gt; Tensor
     (Or
        (Gradient RequiresGradient)
        gradient
        (Or
           (Gradient RequiresGradient) queryGradient attentionBiasGradient))
     (Unify
        (Layout LayoutType)
        ('Layout 'Dense)
        (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
     generatorOutputDevice
     (Unify
        (DataType DType)
        dataType
        (Unify (DataType DType) queryDataType attentionBiasDataType))
     mhaOutputShape
-&gt; Generator generatorOutputDevice
-&gt; m (Tensor
        (Or
           (Gradient RequiresGradient)
           gradient
           (Or
              (Gradient RequiresGradient) queryGradient attentionBiasGradient))
        (Unify
           (Layout LayoutType)
           ('Layout 'Dense)
           (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
        generatorOutputDevice
        (Unify
           (DataType DType)
           dataType
           (Unify (DataType DType) queryDataType attentionBiasDataType))
        mhaOutputShape,
      Generator generatorOutputDevice)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: Type -&gt; Type).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">Dropout
SADropoutF 'RoBERTa
</span><a href="#local-6989586621679805940"><span class="hs-identifier hs-var">saDropout</span></a></span><span>
</span><span id="line-643"></span><span>        </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorOutputDevice)
  (Tensor
     (Or
        (Gradient RequiresGradient)
        gradient
        (Or
           (Gradient RequiresGradient) queryGradient attentionBiasGradient))
     (Unify
        (Layout LayoutType)
        ('Layout 'Dense)
        (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
     generatorOutputDevice
     (Unify
        (DataType DType)
        dataType
        (Unify (DataType DType) queryDataType attentionBiasDataType))
     mhaOutputShape)
-&gt; (Tensor
      (Or
         (Gradient RequiresGradient)
         gradient
         (Or
            (Gradient RequiresGradient) queryGradient attentionBiasGradient))
      (Unify
         (Layout LayoutType)
         ('Layout 'Dense)
         (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
      generatorOutputDevice
      (Unify
         (DataType DType)
         dataType
         (Unify (DataType DType) queryDataType attentionBiasDataType))
      mhaOutputShape
    -&gt; IxStateT
         m
         (Generator generatorOutputDevice)
         (Generator generatorOutputDevice)
         (Tensor
            (Or
               (Gradient RequiresGradient)
               queryGradient
               (Or
                  (Gradient RequiresGradient)
                  gradient
                  (Or
                     (Gradient RequiresGradient) queryGradient attentionBiasGradient)))
            (Unify
               (Layout LayoutType)
               queryLayout
               (Unify
                  (Layout LayoutType)
                  ('Layout 'Dense)
                  (Unify (Layout LayoutType) queryLayout attentionBiasLayout)))
            (Unify (Device (DeviceType Nat)) queryDevice generatorOutputDevice)
            (Unify
               (DataType DType)
               queryDataType
               (Unify
                  (DataType DType)
                  dataType
                  (Unify (DataType DType) queryDataType attentionBiasDataType)))
            (BroadcastShapesF queryShape mhaOutputShape)))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorOutputDevice)
     (Tensor
        (Or
           (Gradient RequiresGradient)
           queryGradient
           (Or
              (Gradient RequiresGradient)
              gradient
              (Or
                 (Gradient RequiresGradient) queryGradient attentionBiasGradient)))
        (Unify
           (Layout LayoutType)
           queryLayout
           (Unify
              (Layout LayoutType)
              ('Layout 'Dense)
              (Unify (Layout LayoutType) queryLayout attentionBiasLayout)))
        (Unify (Device (DeviceType Nat)) queryDevice generatorOutputDevice)
        (Unify
           (DataType DType)
           queryDataType
           (Unify
              (DataType DType)
              dataType
              (Unify (DataType DType) queryDataType attentionBiasDataType)))
        (BroadcastShapesF queryShape mhaOutputShape))
forall k1 (m :: k1 -&gt; k1 -&gt; Type -&gt; Type) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  (Or
     (Gradient RequiresGradient)
     queryGradient
     (Or
        (Gradient RequiresGradient)
        gradient
        (Or
           (Gradient RequiresGradient) queryGradient attentionBiasGradient)))
  (Unify
     (Layout LayoutType)
     queryLayout
     (Unify
        (Layout LayoutType)
        ('Layout 'Dense)
        (Unify (Layout LayoutType) queryLayout attentionBiasLayout)))
  (Unify (Device (DeviceType Nat)) queryDevice generatorOutputDevice)
  (Unify
     (DataType DType)
     queryDataType
     (Unify
        (DataType DType)
        dataType
        (Unify (DataType DType) queryDataType attentionBiasDataType)))
  (BroadcastShapesF queryShape mhaOutputShape)
-&gt; IxStateT
     m
     (Generator generatorOutputDevice)
     (Generator generatorOutputDevice)
     (Tensor
        (Or
           (Gradient RequiresGradient)
           queryGradient
           (Or
              (Gradient RequiresGradient)
              gradient
              (Or
                 (Gradient RequiresGradient) queryGradient attentionBiasGradient)))
        (Unify
           (Layout LayoutType)
           queryLayout
           (Unify
              (Layout LayoutType)
              ('Layout 'Dense)
              (Unify (Layout LayoutType) queryLayout attentionBiasLayout)))
        (Unify (Device (DeviceType Nat)) queryDevice generatorOutputDevice)
        (Unify
           (DataType DType)
           queryDataType
           (Unify
              (DataType DType)
              dataType
              (Unify (DataType DType) queryDataType attentionBiasDataType)))
        (BroadcastShapesF queryShape mhaOutputShape))
forall k (m :: k -&gt; k -&gt; Type -&gt; Type) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">(Tensor
   (Or
      (Gradient RequiresGradient)
      queryGradient
      (Or
         (Gradient RequiresGradient)
         gradient
         (Or
            (Gradient RequiresGradient) queryGradient attentionBiasGradient)))
   (Unify
      (Layout LayoutType)
      queryLayout
      (Unify
         (Layout LayoutType)
         ('Layout 'Dense)
         (Unify (Layout LayoutType) queryLayout attentionBiasLayout)))
   (Unify (Device (DeviceType Nat)) queryDevice generatorOutputDevice)
   (Unify
      (DataType DType)
      queryDataType
      (Unify
         (DataType DType)
         dataType
         (Unify (DataType DType) queryDataType attentionBiasDataType)))
   (BroadcastShapesF queryShape mhaOutputShape)
 -&gt; IxStateT
      m
      (Generator generatorOutputDevice)
      (Generator generatorOutputDevice)
      (Tensor
         (Or
            (Gradient RequiresGradient)
            queryGradient
            (Or
               (Gradient RequiresGradient)
               gradient
               (Or
                  (Gradient RequiresGradient) queryGradient attentionBiasGradient)))
         (Unify
            (Layout LayoutType)
            queryLayout
            (Unify
               (Layout LayoutType)
               ('Layout 'Dense)
               (Unify (Layout LayoutType) queryLayout attentionBiasLayout)))
         (Unify (Device (DeviceType Nat)) queryDevice generatorOutputDevice)
         (Unify
            (DataType DType)
            queryDataType
            (Unify
               (DataType DType)
               dataType
               (Unify (DataType DType) queryDataType attentionBiasDataType)))
         (BroadcastShapesF queryShape mhaOutputShape)))
-&gt; (Tensor
      (Or
         (Gradient RequiresGradient)
         gradient
         (Or
            (Gradient RequiresGradient) queryGradient attentionBiasGradient))
      (Unify
         (Layout LayoutType)
         ('Layout 'Dense)
         (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
      generatorOutputDevice
      (Unify
         (DataType DType)
         dataType
         (Unify (DataType DType) queryDataType attentionBiasDataType))
      mhaOutputShape
    -&gt; Tensor
         (Or
            (Gradient RequiresGradient)
            queryGradient
            (Or
               (Gradient RequiresGradient)
               gradient
               (Or
                  (Gradient RequiresGradient) queryGradient attentionBiasGradient)))
         (Unify
            (Layout LayoutType)
            queryLayout
            (Unify
               (Layout LayoutType)
               ('Layout 'Dense)
               (Unify (Layout LayoutType) queryLayout attentionBiasLayout)))
         (Unify (Device (DeviceType Nat)) queryDevice generatorOutputDevice)
         (Unify
            (DataType DType)
            queryDataType
            (Unify
               (DataType DType)
               dataType
               (Unify (DataType DType) queryDataType attentionBiasDataType)))
         (BroadcastShapesF queryShape mhaOutputShape))
-&gt; Tensor
     (Or
        (Gradient RequiresGradient)
        gradient
        (Or
           (Gradient RequiresGradient) queryGradient attentionBiasGradient))
     (Unify
        (Layout LayoutType)
        ('Layout 'Dense)
        (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
     generatorOutputDevice
     (Unify
        (DataType DType)
        dataType
        (Unify (DataType DType) queryDataType attentionBiasDataType))
     mhaOutputShape
-&gt; IxStateT
     m
     (Generator generatorOutputDevice)
     (Generator generatorOutputDevice)
     (Tensor
        (Or
           (Gradient RequiresGradient)
           queryGradient
           (Or
              (Gradient RequiresGradient)
              gradient
              (Or
                 (Gradient RequiresGradient) queryGradient attentionBiasGradient)))
        (Unify
           (Layout LayoutType)
           queryLayout
           (Unify
              (Layout LayoutType)
              ('Layout 'Dense)
              (Unify (Layout LayoutType) queryLayout attentionBiasLayout)))
        (Unify (Device (DeviceType Nat)) queryDevice generatorOutputDevice)
        (Unify
           (DataType DType)
           queryDataType
           (Unify
              (DataType DType)
              dataType
              (Unify (DataType DType) queryDataType attentionBiasDataType)))
        (BroadcastShapesF queryShape mhaOutputShape))
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">query
Tensor
  queryGradient queryLayout queryDevice queryDataType queryShape
</span><a href="#local-6989586621679805939"><span class="hs-identifier hs-var">query</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  queryGradient queryLayout queryDevice queryDataType queryShape
-&gt; Tensor
     (Or
        (Gradient RequiresGradient)
        gradient
        (Or
           (Gradient RequiresGradient) queryGradient attentionBiasGradient))
     (Unify
        (Layout LayoutType)
        ('Layout 'Dense)
        (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
     generatorOutputDevice
     (Unify
        (DataType DType)
        dataType
        (Unify (DataType DType) queryDataType attentionBiasDataType))
     mhaOutputShape
-&gt; Tensor
     (queryGradient
      &lt;|&gt; Or
            (Gradient RequiresGradient)
            gradient
            (Or
               (Gradient RequiresGradient) queryGradient attentionBiasGradient))
     (queryLayout
      &lt;+&gt; Unify
            (Layout LayoutType)
            ('Layout 'Dense)
            (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
     (queryDevice &lt;+&gt; generatorOutputDevice)
     (queryDataType
      &lt;+&gt; Unify
            (DataType DType)
            dataType
            (Unify (DataType DType) queryDataType attentionBiasDataType))
     (BroadcastShapesF queryShape mhaOutputShape)
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (gradient' :: Gradient RequiresGradient)
       (layout' :: Layout LayoutType) (device' :: Device (DeviceType Nat))
       (dataType' :: DataType DType)
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]).
Tensor gradient layout device dataType shape
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; Tensor
     (gradient &lt;|&gt; gradient')
     (layout &lt;+&gt; layout')
     (device &lt;+&gt; device')
     (dataType &lt;+&gt; dataType')
     (BroadcastShapesF shape shape')
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#add"><span class="hs-operator hs-var">`add`</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-644"></span><span>        </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorOutputDevice)
  (Tensor
     (Or
        (Gradient RequiresGradient)
        queryGradient
        (Or
           (Gradient RequiresGradient)
           gradient
           (Or
              (Gradient RequiresGradient) queryGradient attentionBiasGradient)))
     (Unify
        (Layout LayoutType)
        queryLayout
        (Unify
           (Layout LayoutType)
           ('Layout 'Dense)
           (Unify (Layout LayoutType) queryLayout attentionBiasLayout)))
     (Unify (Device (DeviceType Nat)) queryDevice generatorOutputDevice)
     (Unify
        (DataType DType)
        queryDataType
        (Unify
           (DataType DType)
           dataType
           (Unify (DataType DType) queryDataType attentionBiasDataType)))
     (BroadcastShapesF queryShape mhaOutputShape))
-&gt; (Tensor
      (Or
         (Gradient RequiresGradient)
         queryGradient
         (Or
            (Gradient RequiresGradient)
            gradient
            (Or
               (Gradient RequiresGradient) queryGradient attentionBiasGradient)))
      (Unify
         (Layout LayoutType)
         queryLayout
         (Unify
            (Layout LayoutType)
            ('Layout 'Dense)
            (Unify (Layout LayoutType) queryLayout attentionBiasLayout)))
      (Unify (Device (DeviceType Nat)) queryDevice generatorOutputDevice)
      (Unify
         (DataType DType)
         queryDataType
         (Unify
            (DataType DType)
            dataType
            (Unify (DataType DType) queryDataType attentionBiasDataType)))
      (BroadcastShapesF queryShape mhaOutputShape)
    -&gt; IxStateT
         m
         (Generator generatorOutputDevice)
         (Generator generatorOutputDevice)
         output)
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorOutputDevice)
     output
forall k1 (m :: k1 -&gt; k1 -&gt; Type -&gt; Type) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(Generator generatorOutputDevice
 -&gt; m (output, Generator generatorOutputDevice))
-&gt; IxStateT
     m
     (Generator generatorOutputDevice)
     (Generator generatorOutputDevice)
     output
forall (m :: Type -&gt; Type) i j a.
(i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator generatorOutputDevice
  -&gt; m (output, Generator generatorOutputDevice))
 -&gt; IxStateT
      m
      (Generator generatorOutputDevice)
      (Generator generatorOutputDevice)
      output)
-&gt; (Tensor
      (Or
         (Gradient RequiresGradient)
         queryGradient
         (Or
            (Gradient RequiresGradient)
            gradient
            (Or
               (Gradient RequiresGradient) queryGradient attentionBiasGradient)))
      (Unify
         (Layout LayoutType)
         queryLayout
         (Unify
            (Layout LayoutType)
            ('Layout 'Dense)
            (Unify (Layout LayoutType) queryLayout attentionBiasLayout)))
      (Unify (Device (DeviceType Nat)) queryDevice generatorOutputDevice)
      (Unify
         (DataType DType)
         queryDataType
         (Unify
            (DataType DType)
            dataType
            (Unify (DataType DType) queryDataType attentionBiasDataType)))
      (BroadcastShapesF queryShape mhaOutputShape)
    -&gt; Generator generatorOutputDevice
    -&gt; m (output, Generator generatorOutputDevice))
-&gt; Tensor
     (Or
        (Gradient RequiresGradient)
        queryGradient
        (Or
           (Gradient RequiresGradient)
           gradient
           (Or
              (Gradient RequiresGradient) queryGradient attentionBiasGradient)))
     (Unify
        (Layout LayoutType)
        queryLayout
        (Unify
           (Layout LayoutType)
           ('Layout 'Dense)
           (Unify (Layout LayoutType) queryLayout attentionBiasLayout)))
     (Unify (Device (DeviceType Nat)) queryDevice generatorOutputDevice)
     (Unify
        (DataType DType)
        queryDataType
        (Unify
           (DataType DType)
           dataType
           (Unify (DataType DType) queryDataType attentionBiasDataType)))
     (BroadcastShapesF queryShape mhaOutputShape)
-&gt; IxStateT
     m
     (Generator generatorOutputDevice)
     (Generator generatorOutputDevice)
     output
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">LayerNorm
  'WithBias gradient device dataType ('Shape '[queryEmbedDim])
-&gt; Tensor
     (Or
        (Gradient RequiresGradient)
        queryGradient
        (Or
           (Gradient RequiresGradient)
           gradient
           (Or
              (Gradient RequiresGradient) queryGradient attentionBiasGradient)))
     (Unify
        (Layout LayoutType)
        queryLayout
        (Unify
           (Layout LayoutType)
           ('Layout 'Dense)
           (Unify (Layout LayoutType) queryLayout attentionBiasLayout)))
     (Unify (Device (DeviceType Nat)) queryDevice generatorOutputDevice)
     (Unify
        (DataType DType)
        queryDataType
        (Unify
           (DataType DType)
           dataType
           (Unify (DataType DType) queryDataType attentionBiasDataType)))
     (BroadcastShapesF queryShape mhaOutputShape)
-&gt; Generator generatorOutputDevice
-&gt; m (output, Generator generatorOutputDevice)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: Type -&gt; Type).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">LayerNorm
  'WithBias gradient device dataType ('Shape '[queryEmbedDim])
SALayerNormF 'RoBERTa gradient device dataType queryEmbedDim
</span><a href="#local-6989586621679805941"><span class="hs-identifier hs-var">saLayerNorm</span></a></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span>
</span><span id="line-645"></span><span>
</span><span id="line-646"></span><span class="hs-comment">-- | 'HasForward' instance for @SelfAttention 'Pegasus@.</span><span>
</span><span id="line-647"></span><span class="hs-comment">--</span><span>
</span><span id="line-648"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-649"></span><span class="hs-comment">-- &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;     &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;</span><span>
</span><span id="line-650"></span><span class="hs-comment">-- &#9474; attentionBias &#9474;     &#9474; query &#9474;</span><span>
</span><span id="line-651"></span><span class="hs-comment">-- &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;     &#9492;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-652"></span><span class="hs-comment">--         &#9474;                 &#9474;</span><span>
</span><span id="line-653"></span><span class="hs-comment">--         &#9474;           &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9524;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;</span><span>
</span><span id="line-654"></span><span class="hs-comment">--         &#9474;           &#9474;           &#9474;</span><span>
</span><span id="line-655"></span><span class="hs-comment">--         &#9474;           &#9660;           &#9474;</span><span>
</span><span id="line-656"></span><span class="hs-comment">--         &#9474;      saLayerNorm      &#9474;</span><span>
</span><span id="line-657"></span><span class="hs-comment">--         &#9474;           &#9474;           &#9474;</span><span>
</span><span id="line-658"></span><span class="hs-comment">--         &#9474;      &#9484;&#9472;&#9472;&#9472;&#9472;&#9532;&#9472;&#9472;&#9472;&#9472;&#9488;      &#9474;</span><span>
</span><span id="line-659"></span><span class="hs-comment">--         &#9474;      &#9474;    &#9474;    &#9474;      &#9474;</span><span>
</span><span id="line-660"></span><span class="hs-comment">--         &#9474;      &#9660;    &#9660;    &#9660;      &#9474;</span><span>
</span><span id="line-661"></span><span class="hs-comment">--         &#9492;&#9472;&#9658;saMultiHeadAttention &#9474;</span><span>
</span><span id="line-662"></span><span class="hs-comment">--                     &#9474;           &#9474;</span><span>
</span><span id="line-663"></span><span class="hs-comment">--                     &#9660;           &#9474;</span><span>
</span><span id="line-664"></span><span class="hs-comment">--                 saDropout       &#9474;</span><span>
</span><span id="line-665"></span><span class="hs-comment">--                     &#9474;           &#9474;</span><span>
</span><span id="line-666"></span><span class="hs-comment">--                     &#9492;&#9472;&#9472;&#9472;&#9658;add&#9668;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-667"></span><span class="hs-comment">--                           &#9474;</span><span>
</span><span id="line-668"></span><span class="hs-comment">--                           &#9660;</span><span>
</span><span id="line-669"></span><span class="hs-comment">--                       &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;</span><span>
</span><span id="line-670"></span><span class="hs-comment">--                       &#9474; query &#9474;</span><span>
</span><span id="line-671"></span><span class="hs-comment">--                       &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-672"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-673"></span><span id="local-6989586621679805908"><span id="local-6989586621679805909"><span id="local-6989586621679805910"><span id="local-6989586621679805911"><span id="local-6989586621679805912"><span id="local-6989586621679805913"><span id="local-6989586621679805914"><span id="local-6989586621679805915"><span id="local-6989586621679805916"><span id="local-6989586621679805917"><span id="local-6989586621679805918"><span id="local-6989586621679805919"><span id="local-6989586621679805920"><span id="local-6989586621679805921"><span id="local-6989586621679805922"><span id="local-6989586621679805923"><span id="local-6989586621679805924"><span id="local-6989586621679805925"><span id="local-6989586621679805926"><span id="local-6989586621679805927"><span id="local-6989586621679805928"><span id="local-6989586621679805929"><span id="local-6989586621679805930"><span id="local-6989586621679805931"><span id="local-6989586621679805932"><span id="local-6989586621679805933"><span id="local-6989586621679805934"><span id="local-6989586621679805935"><span id="local-6989586621679805936"><span class="hs-keyword">instance</span><span>
</span><span id="line-674"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetDim"><span class="hs-identifier hs-type">SGetDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805936"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-675"></span><span>    </span><span class="annot"><a href="#local-6989586621679805935"><span class="hs-identifier hs-type">query</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805934"><span class="hs-identifier hs-type">queryGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805933"><span class="hs-identifier hs-type">queryLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805932"><span class="hs-identifier hs-type">queryDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805931"><span class="hs-identifier hs-type">queryDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805930"><span class="hs-identifier hs-type">queryShape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-676"></span><span>    </span><span class="annot"><a href="#local-6989586621679805929"><span class="hs-identifier hs-type">attentionBias</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805928"><span class="hs-identifier hs-type">attentionBiasGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805927"><span class="hs-identifier hs-type">attentionBiasLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805926"><span class="hs-identifier hs-type">attentionBiasDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805925"><span class="hs-identifier hs-type">attentionBiasDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805924"><span class="hs-identifier hs-type">attentionBiasShape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-677"></span><span>    </span><span class="annot"><a href="#local-6989586621679805923"><span class="hs-identifier hs-type">normedQueryGradient</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679805922"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805934"><span class="hs-identifier hs-type">queryGradient</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-678"></span><span>    </span><span class="annot"><a href="#local-6989586621679805921"><span class="hs-identifier hs-type">normedQueryLayout</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Dense"><span class="hs-identifier hs-type">Dense</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805933"><span class="hs-identifier hs-type">queryLayout</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-679"></span><span>    </span><span class="annot"><a href="#local-6989586621679805920"><span class="hs-identifier hs-type">normedQueryDevice</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679805919"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805932"><span class="hs-identifier hs-type">queryDevice</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-680"></span><span>    </span><span class="annot"><a href="#local-6989586621679805918"><span class="hs-identifier hs-type">normedQueryDataType</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679805917"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805931"><span class="hs-identifier hs-type">queryDataType</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-681"></span><span>    </span><span class="annot"><a href="#local-6989586621679805916"><span class="hs-identifier hs-type">normedQueryShape</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Functional.Normalization.html#LayerNormWithBiasF"><span class="hs-identifier hs-type">LayerNormWithBiasF</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679805936"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679805936"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679805930"><span class="hs-identifier hs-type">queryShape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-682"></span><span>    </span><span class="annot"><a href="#local-6989586621679805915"><span class="hs-identifier hs-type">normedQuery</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805923"><span class="hs-identifier hs-type">normedQueryGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805921"><span class="hs-identifier hs-type">normedQueryLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805920"><span class="hs-identifier hs-type">normedQueryDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805918"><span class="hs-identifier hs-type">normedQueryDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805916"><span class="hs-identifier hs-type">normedQueryShape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-683"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-684"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.MultiHeadAttention.html#MultiHeadAttention"><span class="hs-identifier hs-type">MultiHeadAttention</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#Pegasus"><span class="hs-identifier hs-type">Pegasus</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805922"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805919"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805917"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805914"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805913"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805912"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805936"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805936"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805936"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-685"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679805915"><span class="hs-identifier hs-type">normedQuery</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679805915"><span class="hs-identifier hs-type">normedQuery</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679805915"><span class="hs-identifier hs-type">normedQuery</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679805929"><span class="hs-identifier hs-type">attentionBias</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-686"></span><span>      </span><span class="annot"><a href="#local-6989586621679805911"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-687"></span><span>      </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-688"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679805922"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805934"><span class="hs-identifier hs-type">queryGradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805928"><span class="hs-identifier hs-type">attentionBiasGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-689"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Dense"><span class="hs-identifier hs-type">Dense</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805933"><span class="hs-identifier hs-type">queryLayout</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805927"><span class="hs-identifier hs-type">attentionBiasLayout</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-690"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679805919"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805932"><span class="hs-identifier hs-type">queryDevice</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805926"><span class="hs-identifier hs-type">attentionBiasDevice</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805911"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-691"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679805917"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805931"><span class="hs-identifier hs-type">queryDataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805925"><span class="hs-identifier hs-type">attentionBiasDataType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-692"></span><span>          </span><span class="annot"><a href="#local-6989586621679805910"><span class="hs-identifier hs-type">mhaOutputShape</span></a></span><span>
</span><span id="line-693"></span><span>      </span><span class="hs-special">)</span><span>
</span><span id="line-694"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679805919"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805932"><span class="hs-identifier hs-type">queryDevice</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805926"><span class="hs-identifier hs-type">attentionBiasDevice</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805911"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-695"></span><span>    </span><span class="annot"><a href="#local-6989586621679805909"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-696"></span><span>      </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-697"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679805934"><span class="hs-identifier hs-type">queryGradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805922"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805928"><span class="hs-identifier hs-type">attentionBiasGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-698"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679805933"><span class="hs-identifier hs-type">queryLayout</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Dense"><span class="hs-identifier hs-type">Dense</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805927"><span class="hs-identifier hs-type">attentionBiasLayout</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-699"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679805932"><span class="hs-identifier hs-type">queryDevice</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805919"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805926"><span class="hs-identifier hs-type">attentionBiasDevice</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805911"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-700"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679805931"><span class="hs-identifier hs-type">queryDataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805917"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805925"><span class="hs-identifier hs-type">attentionBiasDataType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-701"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#BroadcastShapesF"><span class="hs-identifier hs-type">BroadcastShapesF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805930"><span class="hs-identifier hs-type">queryShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805910"><span class="hs-identifier hs-type">mhaOutputShape</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-702"></span><span>    </span><span class="annot"><a href="#local-6989586621679805908"><span class="hs-identifier hs-type">generatorOutputDevice</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679805919"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805932"><span class="hs-identifier hs-type">queryDevice</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805926"><span class="hs-identifier hs-type">attentionBiasDevice</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805911"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-703"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-704"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-705"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#SelfAttention"><span class="hs-identifier hs-type">SelfAttention</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#Pegasus"><span class="hs-identifier hs-type">Pegasus</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805922"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805919"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805917"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805914"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805913"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805912"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805936"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-706"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679805935"><span class="hs-identifier hs-type">query</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679805929"><span class="hs-identifier hs-type">attentionBias</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-707"></span><span>    </span><span class="annot"><a href="#local-6989586621679805911"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-708"></span><span>    </span><span class="annot"><a href="#local-6989586621679805909"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-709"></span><span>    </span><span class="annot"><a href="#local-6989586621679805908"><span class="hs-identifier hs-type">generatorOutputDevice</span></a></span><span>
</span><span id="line-710"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-711"></span><span>  </span><span id="local-6989586621679805906"><span class="annot"><span class="annottext">forward :: SelfAttention
  'Pegasus
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  queryEmbedDim
-&gt; (query, attentionBias)
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="#local-6989586621679805906"><span class="hs-identifier hs-var hs-var hs-var hs-var">forward</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#SelfAttention"><span class="hs-identifier hs-type">SelfAttention</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.SelfAttention.html#GSelfAttention"><span class="hs-identifier hs-type">GSelfAttention</span></a></span><span> </span><span class="hs-special">{</span><span id="local-6989586621679805903"><span id="local-6989586621679805904"><span id="local-6989586621679805905"><span class="annot"><span class="annottext">SADropoutF 'Pegasus
SALayerNormF 'Pegasus gradient device dataType queryEmbedDim
SAMultiheadAttentionF
  'Pegasus
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  queryEmbedDim
saDropout :: SADropoutF 'Pegasus
saLayerNorm :: SALayerNormF 'Pegasus gradient device dataType queryEmbedDim
saMultiHeadAttention :: SAMultiheadAttentionF
  'Pegasus
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  queryEmbedDim
saDropout :: forall mha layerNorm dropout.
GSelfAttention mha layerNorm dropout -&gt; dropout
saLayerNorm :: forall mha layerNorm dropout.
GSelfAttention mha layerNorm dropout -&gt; layerNorm
saMultiHeadAttention :: forall mha layerNorm dropout.
GSelfAttention mha layerNorm dropout -&gt; mha
</span><a href="#local-6989586621679805903"><span class="hs-glyph hs-var hs-var hs-var hs-var hs-var hs-var">..</span></a></span></span></span></span><span class="hs-special">}</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679805902"><span class="annot"><span class="annottext">query
</span><a href="#local-6989586621679805902"><span class="hs-identifier hs-var">query</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679805901"><span class="annot"><span class="annottext">attentionBias
</span><a href="#local-6989586621679805901"><span class="hs-identifier hs-var">attentionBias</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-712"></span><span>    </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorOutputDevice)
  output
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
forall (m :: Type -&gt; Type) i j a. IxStateT m i j a -&gt; i -&gt; m (a, j)
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var hs-var">runIxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">(IxStateT
   m
   (Generator generatorDevice)
   (Generator generatorOutputDevice)
   output
 -&gt; Generator generatorDevice
 -&gt; m (output, Generator generatorOutputDevice))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorOutputDevice)
     output
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-713"></span><span>      </span><span class="annot"><span class="annottext">query
-&gt; IxStateT
     m (Generator generatorDevice) (Generator generatorDevice) query
forall k (m :: k -&gt; k -&gt; Type -&gt; Type) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">query
</span><a href="#local-6989586621679805902"><span class="hs-identifier hs-var">query</span></a></span><span>
</span><span id="line-714"></span><span>        </span><span class="annot"><span class="annottext">IxStateT
  m (Generator generatorDevice) (Generator generatorDevice) query
-&gt; (query
    -&gt; IxStateT
         m
         (Generator generatorDevice)
         (Generator generatorDevice)
         (Tensor
            normedQueryGradient
            normedQueryLayout
            normedQueryDevice
            normedQueryDataType
            normedQueryShape))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     (Tensor
        normedQueryGradient
        normedQueryLayout
        normedQueryDevice
        normedQueryDataType
        normedQueryShape)
forall k1 (m :: k1 -&gt; k1 -&gt; Type -&gt; Type) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(Generator generatorDevice
 -&gt; m (Tensor
         normedQueryGradient
         normedQueryLayout
         normedQueryDevice
         normedQueryDataType
         normedQueryShape,
       Generator generatorDevice))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     (Tensor
        normedQueryGradient
        normedQueryLayout
        normedQueryDevice
        normedQueryDataType
        normedQueryShape)
forall (m :: Type -&gt; Type) i j a.
(i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator generatorDevice
  -&gt; m (Tensor
          normedQueryGradient
          normedQueryLayout
          normedQueryDevice
          normedQueryDataType
          normedQueryShape,
        Generator generatorDevice))
 -&gt; IxStateT
      m
      (Generator generatorDevice)
      (Generator generatorDevice)
      (Tensor
         normedQueryGradient
         normedQueryLayout
         normedQueryDevice
         normedQueryDataType
         normedQueryShape))
-&gt; (query
    -&gt; Generator generatorDevice
    -&gt; m (Tensor
            normedQueryGradient
            normedQueryLayout
            normedQueryDevice
            normedQueryDataType
            normedQueryShape,
          Generator generatorDevice))
-&gt; query
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     (Tensor
        normedQueryGradient
        normedQueryLayout
        normedQueryDevice
        normedQueryDataType
        normedQueryShape)
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">LayerNorm
  'WithBias gradient device dataType ('Shape '[queryEmbedDim])
-&gt; query
-&gt; Generator generatorDevice
-&gt; m (Tensor
        normedQueryGradient
        normedQueryLayout
        normedQueryDevice
        normedQueryDataType
        normedQueryShape,
      Generator generatorDevice)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: Type -&gt; Type).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">LayerNorm
  'WithBias gradient device dataType ('Shape '[queryEmbedDim])
SALayerNormF 'Pegasus gradient device dataType queryEmbedDim
</span><a href="#local-6989586621679805904"><span class="hs-identifier hs-var">saLayerNorm</span></a></span><span>
</span><span id="line-715"></span><span>        </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorDevice)
  (Tensor
     normedQueryGradient
     normedQueryLayout
     normedQueryDevice
     normedQueryDataType
     normedQueryShape)
-&gt; (Tensor
      normedQueryGradient
      normedQueryLayout
      normedQueryDevice
      normedQueryDataType
      normedQueryShape
    -&gt; IxStateT
         m
         (Generator generatorDevice)
         (Generator generatorOutputDevice)
         (Tensor
            (Or
               (Gradient RequiresGradient)
               gradient
               (Or
                  (Gradient RequiresGradient) queryGradient attentionBiasGradient))
            (Unify
               (Layout LayoutType)
               ('Layout 'Dense)
               (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
            generatorOutputDevice
            (Unify
               (DataType DType)
               dataType
               (Unify (DataType DType) queryDataType attentionBiasDataType))
            mhaOutputShape))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorOutputDevice)
     (Tensor
        (Or
           (Gradient RequiresGradient)
           gradient
           (Or
              (Gradient RequiresGradient) queryGradient attentionBiasGradient))
        (Unify
           (Layout LayoutType)
           ('Layout 'Dense)
           (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
        generatorOutputDevice
        (Unify
           (DataType DType)
           dataType
           (Unify (DataType DType) queryDataType attentionBiasDataType))
        mhaOutputShape)
forall k1 (m :: k1 -&gt; k1 -&gt; Type -&gt; Type) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">\</span><span id="local-6989586621679805900"><span class="annot"><span class="annottext">Tensor
  normedQueryGradient
  normedQueryLayout
  normedQueryDevice
  normedQueryDataType
  normedQueryShape
</span><a href="#local-6989586621679805900"><span class="hs-identifier hs-var">query'</span></a></span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">(Generator generatorDevice
 -&gt; m (Tensor
         (Or
            (Gradient RequiresGradient)
            gradient
            (Or
               (Gradient RequiresGradient) queryGradient attentionBiasGradient))
         (Unify
            (Layout LayoutType)
            ('Layout 'Dense)
            (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
         generatorOutputDevice
         (Unify
            (DataType DType)
            dataType
            (Unify (DataType DType) queryDataType attentionBiasDataType))
         mhaOutputShape,
       Generator generatorOutputDevice))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorOutputDevice)
     (Tensor
        (Or
           (Gradient RequiresGradient)
           gradient
           (Or
              (Gradient RequiresGradient) queryGradient attentionBiasGradient))
        (Unify
           (Layout LayoutType)
           ('Layout 'Dense)
           (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
        generatorOutputDevice
        (Unify
           (DataType DType)
           dataType
           (Unify (DataType DType) queryDataType attentionBiasDataType))
        mhaOutputShape)
forall (m :: Type -&gt; Type) i j a.
(i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator generatorDevice
  -&gt; m (Tensor
          (Or
             (Gradient RequiresGradient)
             gradient
             (Or
                (Gradient RequiresGradient) queryGradient attentionBiasGradient))
          (Unify
             (Layout LayoutType)
             ('Layout 'Dense)
             (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
          generatorOutputDevice
          (Unify
             (DataType DType)
             dataType
             (Unify (DataType DType) queryDataType attentionBiasDataType))
          mhaOutputShape,
        Generator generatorOutputDevice))
 -&gt; IxStateT
      m
      (Generator generatorDevice)
      (Generator generatorOutputDevice)
      (Tensor
         (Or
            (Gradient RequiresGradient)
            gradient
            (Or
               (Gradient RequiresGradient) queryGradient attentionBiasGradient))
         (Unify
            (Layout LayoutType)
            ('Layout 'Dense)
            (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
         generatorOutputDevice
         (Unify
            (DataType DType)
            dataType
            (Unify (DataType DType) queryDataType attentionBiasDataType))
         mhaOutputShape))
-&gt; (Generator generatorDevice
    -&gt; m (Tensor
            (Or
               (Gradient RequiresGradient)
               gradient
               (Or
                  (Gradient RequiresGradient) queryGradient attentionBiasGradient))
            (Unify
               (Layout LayoutType)
               ('Layout 'Dense)
               (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
            generatorOutputDevice
            (Unify
               (DataType DType)
               dataType
               (Unify (DataType DType) queryDataType attentionBiasDataType))
            mhaOutputShape,
          Generator generatorOutputDevice))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorOutputDevice)
     (Tensor
        (Or
           (Gradient RequiresGradient)
           gradient
           (Or
              (Gradient RequiresGradient) queryGradient attentionBiasGradient))
        (Unify
           (Layout LayoutType)
           ('Layout 'Dense)
           (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
        generatorOutputDevice
        (Unify
           (DataType DType)
           dataType
           (Unify (DataType DType) queryDataType attentionBiasDataType))
        mhaOutputShape)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">MultiHeadAttention
  'Pegasus
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  queryEmbedDim
  queryEmbedDim
  queryEmbedDim
-&gt; (Tensor
      normedQueryGradient
      normedQueryLayout
      normedQueryDevice
      normedQueryDataType
      normedQueryShape,
    Tensor
      normedQueryGradient
      normedQueryLayout
      normedQueryDevice
      normedQueryDataType
      normedQueryShape,
    Tensor
      normedQueryGradient
      normedQueryLayout
      normedQueryDevice
      normedQueryDataType
      normedQueryShape,
    attentionBias)
-&gt; Generator generatorDevice
-&gt; m (Tensor
        (Or
           (Gradient RequiresGradient)
           gradient
           (Or
              (Gradient RequiresGradient) queryGradient attentionBiasGradient))
        (Unify
           (Layout LayoutType)
           ('Layout 'Dense)
           (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
        generatorOutputDevice
        (Unify
           (DataType DType)
           dataType
           (Unify (DataType DType) queryDataType attentionBiasDataType))
        mhaOutputShape,
      Generator generatorOutputDevice)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: Type -&gt; Type).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">MultiHeadAttention
  'Pegasus
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  queryEmbedDim
  queryEmbedDim
  queryEmbedDim
SAMultiheadAttentionF
  'Pegasus
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  queryEmbedDim
</span><a href="#local-6989586621679805905"><span class="hs-identifier hs-var">saMultiHeadAttention</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Tensor
  normedQueryGradient
  normedQueryLayout
  normedQueryDevice
  normedQueryDataType
  normedQueryShape
</span><a href="#local-6989586621679805900"><span class="hs-identifier hs-var">query'</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Tensor
  normedQueryGradient
  normedQueryLayout
  normedQueryDevice
  normedQueryDataType
  normedQueryShape
</span><a href="#local-6989586621679805900"><span class="hs-identifier hs-var">query'</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Tensor
  normedQueryGradient
  normedQueryLayout
  normedQueryDevice
  normedQueryDataType
  normedQueryShape
</span><a href="#local-6989586621679805900"><span class="hs-identifier hs-var">query'</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">attentionBias
</span><a href="#local-6989586621679805901"><span class="hs-identifier hs-var">attentionBias</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-716"></span><span>        </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorOutputDevice)
  (Tensor
     (Or
        (Gradient RequiresGradient)
        gradient
        (Or
           (Gradient RequiresGradient) queryGradient attentionBiasGradient))
     (Unify
        (Layout LayoutType)
        ('Layout 'Dense)
        (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
     generatorOutputDevice
     (Unify
        (DataType DType)
        dataType
        (Unify (DataType DType) queryDataType attentionBiasDataType))
     mhaOutputShape)
-&gt; (Tensor
      (Or
         (Gradient RequiresGradient)
         gradient
         (Or
            (Gradient RequiresGradient) queryGradient attentionBiasGradient))
      (Unify
         (Layout LayoutType)
         ('Layout 'Dense)
         (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
      generatorOutputDevice
      (Unify
         (DataType DType)
         dataType
         (Unify (DataType DType) queryDataType attentionBiasDataType))
      mhaOutputShape
    -&gt; IxStateT
         m
         (Generator generatorOutputDevice)
         (Generator generatorOutputDevice)
         (Tensor
            (Or
               (Gradient RequiresGradient)
               gradient
               (Or
                  (Gradient RequiresGradient) queryGradient attentionBiasGradient))
            (Unify
               (Layout LayoutType)
               ('Layout 'Dense)
               (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
            generatorOutputDevice
            (Unify
               (DataType DType)
               dataType
               (Unify (DataType DType) queryDataType attentionBiasDataType))
            mhaOutputShape))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorOutputDevice)
     (Tensor
        (Or
           (Gradient RequiresGradient)
           gradient
           (Or
              (Gradient RequiresGradient) queryGradient attentionBiasGradient))
        (Unify
           (Layout LayoutType)
           ('Layout 'Dense)
           (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
        generatorOutputDevice
        (Unify
           (DataType DType)
           dataType
           (Unify (DataType DType) queryDataType attentionBiasDataType))
        mhaOutputShape)
forall k1 (m :: k1 -&gt; k1 -&gt; Type -&gt; Type) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(Generator generatorOutputDevice
 -&gt; m (Tensor
         (Or
            (Gradient RequiresGradient)
            gradient
            (Or
               (Gradient RequiresGradient) queryGradient attentionBiasGradient))
         (Unify
            (Layout LayoutType)
            ('Layout 'Dense)
            (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
         generatorOutputDevice
         (Unify
            (DataType DType)
            dataType
            (Unify (DataType DType) queryDataType attentionBiasDataType))
         mhaOutputShape,
       Generator generatorOutputDevice))
-&gt; IxStateT
     m
     (Generator generatorOutputDevice)
     (Generator generatorOutputDevice)
     (Tensor
        (Or
           (Gradient RequiresGradient)
           gradient
           (Or
              (Gradient RequiresGradient) queryGradient attentionBiasGradient))
        (Unify
           (Layout LayoutType)
           ('Layout 'Dense)
           (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
        generatorOutputDevice
        (Unify
           (DataType DType)
           dataType
           (Unify (DataType DType) queryDataType attentionBiasDataType))
        mhaOutputShape)
forall (m :: Type -&gt; Type) i j a.
(i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator generatorOutputDevice
  -&gt; m (Tensor
          (Or
             (Gradient RequiresGradient)
             gradient
             (Or
                (Gradient RequiresGradient) queryGradient attentionBiasGradient))
          (Unify
             (Layout LayoutType)
             ('Layout 'Dense)
             (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
          generatorOutputDevice
          (Unify
             (DataType DType)
             dataType
             (Unify (DataType DType) queryDataType attentionBiasDataType))
          mhaOutputShape,
        Generator generatorOutputDevice))
 -&gt; IxStateT
      m
      (Generator generatorOutputDevice)
      (Generator generatorOutputDevice)
      (Tensor
         (Or
            (Gradient RequiresGradient)
            gradient
            (Or
               (Gradient RequiresGradient) queryGradient attentionBiasGradient))
         (Unify
            (Layout LayoutType)
            ('Layout 'Dense)
            (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
         generatorOutputDevice
         (Unify
            (DataType DType)
            dataType
            (Unify (DataType DType) queryDataType attentionBiasDataType))
         mhaOutputShape))
-&gt; (Tensor
      (Or
         (Gradient RequiresGradient)
         gradient
         (Or
            (Gradient RequiresGradient) queryGradient attentionBiasGradient))
      (Unify
         (Layout LayoutType)
         ('Layout 'Dense)
         (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
      generatorOutputDevice
      (Unify
         (DataType DType)
         dataType
         (Unify (DataType DType) queryDataType attentionBiasDataType))
      mhaOutputShape
    -&gt; Generator generatorOutputDevice
    -&gt; m (Tensor
            (Or
               (Gradient RequiresGradient)
               gradient
               (Or
                  (Gradient RequiresGradient) queryGradient attentionBiasGradient))
            (Unify
               (Layout LayoutType)
               ('Layout 'Dense)
               (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
            generatorOutputDevice
            (Unify
               (DataType DType)
               dataType
               (Unify (DataType DType) queryDataType attentionBiasDataType))
            mhaOutputShape,
          Generator generatorOutputDevice))
-&gt; Tensor
     (Or
        (Gradient RequiresGradient)
        gradient
        (Or
           (Gradient RequiresGradient) queryGradient attentionBiasGradient))
     (Unify
        (Layout LayoutType)
        ('Layout 'Dense)
        (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
     generatorOutputDevice
     (Unify
        (DataType DType)
        dataType
        (Unify (DataType DType) queryDataType attentionBiasDataType))
     mhaOutputShape
-&gt; IxStateT
     m
     (Generator generatorOutputDevice)
     (Generator generatorOutputDevice)
     (Tensor
        (Or
           (Gradient RequiresGradient)
           gradient
           (Or
              (Gradient RequiresGradient) queryGradient attentionBiasGradient))
        (Unify
           (Layout LayoutType)
           ('Layout 'Dense)
           (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
        generatorOutputDevice
        (Unify
           (DataType DType)
           dataType
           (Unify (DataType DType) queryDataType attentionBiasDataType))
        mhaOutputShape)
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Dropout
-&gt; Tensor
     (Or
        (Gradient RequiresGradient)
        gradient
        (Or
           (Gradient RequiresGradient) queryGradient attentionBiasGradient))
     (Unify
        (Layout LayoutType)
        ('Layout 'Dense)
        (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
     generatorOutputDevice
     (Unify
        (DataType DType)
        dataType
        (Unify (DataType DType) queryDataType attentionBiasDataType))
     mhaOutputShape
-&gt; Generator generatorOutputDevice
-&gt; m (Tensor
        (Or
           (Gradient RequiresGradient)
           gradient
           (Or
              (Gradient RequiresGradient) queryGradient attentionBiasGradient))
        (Unify
           (Layout LayoutType)
           ('Layout 'Dense)
           (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
        generatorOutputDevice
        (Unify
           (DataType DType)
           dataType
           (Unify (DataType DType) queryDataType attentionBiasDataType))
        mhaOutputShape,
      Generator generatorOutputDevice)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: Type -&gt; Type).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">Dropout
SADropoutF 'Pegasus
</span><a href="#local-6989586621679805903"><span class="hs-identifier hs-var">saDropout</span></a></span><span>
</span><span id="line-717"></span><span>        </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorOutputDevice)
  (Tensor
     (Or
        (Gradient RequiresGradient)
        gradient
        (Or
           (Gradient RequiresGradient) queryGradient attentionBiasGradient))
     (Unify
        (Layout LayoutType)
        ('Layout 'Dense)
        (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
     generatorOutputDevice
     (Unify
        (DataType DType)
        dataType
        (Unify (DataType DType) queryDataType attentionBiasDataType))
     mhaOutputShape)
-&gt; (Tensor
      (Or
         (Gradient RequiresGradient)
         gradient
         (Or
            (Gradient RequiresGradient) queryGradient attentionBiasGradient))
      (Unify
         (Layout LayoutType)
         ('Layout 'Dense)
         (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
      generatorOutputDevice
      (Unify
         (DataType DType)
         dataType
         (Unify (DataType DType) queryDataType attentionBiasDataType))
      mhaOutputShape
    -&gt; IxStateT
         m
         (Generator generatorOutputDevice)
         (Generator generatorOutputDevice)
         output)
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorOutputDevice)
     output
forall k1 (m :: k1 -&gt; k1 -&gt; Type -&gt; Type) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">output
-&gt; IxStateT
     m
     (Generator generatorOutputDevice)
     (Generator generatorOutputDevice)
     output
forall k (m :: k -&gt; k -&gt; Type -&gt; Type) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">(output
 -&gt; IxStateT
      m
      (Generator generatorOutputDevice)
      (Generator generatorOutputDevice)
      output)
-&gt; (Tensor
      (Or
         (Gradient RequiresGradient)
         gradient
         (Or
            (Gradient RequiresGradient) queryGradient attentionBiasGradient))
      (Unify
         (Layout LayoutType)
         ('Layout 'Dense)
         (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
      generatorOutputDevice
      (Unify
         (DataType DType)
         dataType
         (Unify (DataType DType) queryDataType attentionBiasDataType))
      mhaOutputShape
    -&gt; output)
-&gt; Tensor
     (Or
        (Gradient RequiresGradient)
        gradient
        (Or
           (Gradient RequiresGradient) queryGradient attentionBiasGradient))
     (Unify
        (Layout LayoutType)
        ('Layout 'Dense)
        (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
     generatorOutputDevice
     (Unify
        (DataType DType)
        dataType
        (Unify (DataType DType) queryDataType attentionBiasDataType))
     mhaOutputShape
-&gt; IxStateT
     m
     (Generator generatorOutputDevice)
     (Generator generatorOutputDevice)
     output
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">query
Tensor
  queryGradient queryLayout queryDevice queryDataType queryShape
</span><a href="#local-6989586621679805902"><span class="hs-identifier hs-var">query</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  queryGradient queryLayout queryDevice queryDataType queryShape
-&gt; Tensor
     (Or
        (Gradient RequiresGradient)
        gradient
        (Or
           (Gradient RequiresGradient) queryGradient attentionBiasGradient))
     (Unify
        (Layout LayoutType)
        ('Layout 'Dense)
        (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
     generatorOutputDevice
     (Unify
        (DataType DType)
        dataType
        (Unify (DataType DType) queryDataType attentionBiasDataType))
     mhaOutputShape
-&gt; Tensor
     (queryGradient
      &lt;|&gt; Or
            (Gradient RequiresGradient)
            gradient
            (Or
               (Gradient RequiresGradient) queryGradient attentionBiasGradient))
     (queryLayout
      &lt;+&gt; Unify
            (Layout LayoutType)
            ('Layout 'Dense)
            (Unify (Layout LayoutType) queryLayout attentionBiasLayout))
     (queryDevice &lt;+&gt; generatorOutputDevice)
     (queryDataType
      &lt;+&gt; Unify
            (DataType DType)
            dataType
            (Unify (DataType DType) queryDataType attentionBiasDataType))
     (BroadcastShapesF queryShape mhaOutputShape)
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (gradient' :: Gradient RequiresGradient)
       (layout' :: Layout LayoutType) (device' :: Device (DeviceType Nat))
       (dataType' :: DataType DType)
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]).
Tensor gradient layout device dataType shape
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; Tensor
     (gradient &lt;|&gt; gradient')
     (layout &lt;+&gt; layout')
     (device &lt;+&gt; device')
     (dataType &lt;+&gt; dataType')
     (BroadcastShapesF shape shape')
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#add"><span class="hs-operator hs-var">`add`</span></a></span><span class="hs-special">)</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span>
</span><span id="line-718"></span></pre></body></html>