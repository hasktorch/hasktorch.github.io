<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><link rel="stylesheet" type="text/css" href="style.css" /><script type="text/javascript" src="highlight.js"></script></head><body><pre><span id="%24con2tag_LObvx4f6Dxv2bKIcPVdvpH"><span id="%24con2tag_n6qSz24QeM9xXUiwJXqls"></span></span><span class="hs-pragma">{-# LANGUAGE AllowAmbiguousTypes #-}</span><span>
</span><span id="line-2"></span><span class="hs-pragma">{-# LANGUAGE ConstraintKinds #-}</span><span>
</span><span id="line-3"></span><span class="hs-pragma">{-# LANGUAGE DataKinds #-}</span><span>
</span><span id="line-4"></span><span class="hs-pragma">{-# LANGUAGE DeriveGeneric #-}</span><span>
</span><span id="line-5"></span><span class="hs-pragma">{-# LANGUAGE DerivingStrategies #-}</span><span>
</span><span id="line-6"></span><span class="hs-pragma">{-# LANGUAGE FlexibleContexts #-}</span><span>
</span><span id="line-7"></span><span class="hs-pragma">{-# LANGUAGE KindSignatures #-}</span><span>
</span><span id="line-8"></span><span class="hs-pragma">{-# LANGUAGE PartialTypeSignatures #-}</span><span>
</span><span id="line-9"></span><span class="hs-pragma">{-# LANGUAGE QuantifiedConstraints #-}</span><span>
</span><span id="line-10"></span><span class="hs-pragma">{-# LANGUAGE RecordWildCards #-}</span><span>
</span><span id="line-11"></span><span class="hs-pragma">{-# LANGUAGE ScopedTypeVariables #-}</span><span>
</span><span id="line-12"></span><span class="hs-pragma">{-# LANGUAGE TypeApplications #-}</span><span>
</span><span id="line-13"></span><span class="hs-pragma">{-# LANGUAGE TypeFamilies #-}</span><span>
</span><span id="line-14"></span><span class="hs-pragma">{-# LANGUAGE TypeOperators #-}</span><span>
</span><span id="line-15"></span><span class="hs-pragma">{-# OPTIONS_GHC -Wall #-}</span><span>
</span><span id="line-16"></span><span class="hs-pragma">{-# OPTIONS_GHC -Wno-typed-holes #-}</span><span>
</span><span id="line-17"></span><span class="hs-pragma">{-# OPTIONS_GHC -fdefer-typed-holes #-}</span><span>
</span><span id="line-18"></span><span>
</span><span id="line-19"></span><span class="hs-keyword">module</span><span> </span><span class="hs-identifier">Torch.GraduallyTyped.NN.Initialization</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-20"></span><span>
</span><span id="line-21"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier">Control.Monad.Catch</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier">MonadThrow</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-22"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier">Control.Monad.Indexed</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier">IxPointed</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier">ireturn</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator">(&gt;&gt;&gt;=)</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-23"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier">Control.Monad.Indexed.State</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier">IxStateT</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-24"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">GHC.Generics</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier">Generic</span></span><span class="hs-special">)</span><span>
</span><span id="line-25"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Internal.TensorOptions.html"><span class="hs-identifier">Torch.GraduallyTyped.Internal.TensorOptions</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Internal.TensorOptions.html#tensorDims"><span class="hs-identifier">tensorDims</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-26"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Random.html"><span class="hs-identifier">Torch.GraduallyTyped.Random</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Random.html#Generator"><span class="hs-identifier">Generator</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-27"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Scalar.html"><span class="hs-identifier">Torch.GraduallyTyped.Scalar</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Scalar.html#Scalar"><span class="hs-identifier">Scalar</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-28"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.html"><span class="hs-identifier">Torch.GraduallyTyped.Shape</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#dimSize"><span class="hs-identifier">dimSize</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-29"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Creation.html"><span class="hs-identifier">Torch.GraduallyTyped.Tensor.Creation</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Creation.html#sRandn"><span class="hs-identifier">sRandn</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-30"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html"><span class="hs-identifier">Torch.GraduallyTyped.Tensor.MathOperations.Pointwise</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#mulScalar"><span class="hs-identifier">mulScalar</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#subScalar"><span class="hs-identifier">subScalar</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-31"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html"><span class="hs-identifier">Torch.GraduallyTyped.Tensor.Type</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier">Tensor</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorSpec"><span class="hs-identifier">TensorSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-32"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html"><span class="hs-identifier">Torch.GraduallyTyped.Unify</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-keyword">type</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator">(&lt;+&gt;)</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-33"></span><span>
</span><span id="line-34"></span><span class="hs-comment">-- | Note: Identity = linear w/o activation</span><span>
</span><span id="line-35"></span><span id="local-6989586621679800240"><span id="local-6989586621679800241"></span></span><span class="hs-keyword">data</span><span> </span><span id="ForNonLinearity"><span class="annot"><a href="Torch.GraduallyTyped.NN.Initialization.html#ForNonLinearity"><span class="hs-identifier hs-var">ForNonLinearity</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span id="ForIdentity"><span class="annot"><a href="Torch.GraduallyTyped.NN.Initialization.html#ForIdentity"><span class="hs-identifier hs-var">ForIdentity</span></a></span></span><span> </span><span class="hs-glyph">|</span><span> </span><span id="ForSigmoid"><span class="annot"><a href="Torch.GraduallyTyped.NN.Initialization.html#ForSigmoid"><span class="hs-identifier hs-var">ForSigmoid</span></a></span></span><span> </span><span class="hs-glyph">|</span><span> </span><span id="ForTanh"><span class="annot"><a href="Torch.GraduallyTyped.NN.Initialization.html#ForTanh"><span class="hs-identifier hs-var">ForTanh</span></a></span></span><span> </span><span class="hs-glyph">|</span><span> </span><span id="ForRelu"><span class="annot"><a href="Torch.GraduallyTyped.NN.Initialization.html#ForRelu"><span class="hs-identifier hs-var">ForRelu</span></a></span></span><span> </span><span class="hs-glyph">|</span><span> </span><span id="ForLeakyRelu"><span class="annot"><a href="Torch.GraduallyTyped.NN.Initialization.html#ForLeakyRelu"><span class="hs-identifier hs-var">ForLeakyRelu</span></a></span></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Float</span></span><span>
</span><span id="line-36"></span><span>  </span><span class="hs-keyword">deriving</span><span> </span><span class="annot"><span class="hs-keyword">stock</span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679800231"><span id="local-6989586621679800233"><span class="annot"><span class="annottext">ForNonLinearity -&gt; ForNonLinearity -&gt; Bool
(ForNonLinearity -&gt; ForNonLinearity -&gt; Bool)
-&gt; (ForNonLinearity -&gt; ForNonLinearity -&gt; Bool)
-&gt; Eq ForNonLinearity
forall a. (a -&gt; a -&gt; Bool) -&gt; (a -&gt; a -&gt; Bool) -&gt; Eq a
/= :: ForNonLinearity -&gt; ForNonLinearity -&gt; Bool
$c/= :: ForNonLinearity -&gt; ForNonLinearity -&gt; Bool
== :: ForNonLinearity -&gt; ForNonLinearity -&gt; Bool
$c== :: ForNonLinearity -&gt; ForNonLinearity -&gt; Bool
</span><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var">Eq</span></span></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679800215"><span id="local-6989586621679800217"><span id="local-6989586621679800219"><span id="local-6989586621679800221"><span id="local-6989586621679800223"><span id="local-6989586621679800225"><span id="local-6989586621679800227"><span class="annot"><span class="annottext">Eq ForNonLinearity
Eq ForNonLinearity
-&gt; (ForNonLinearity -&gt; ForNonLinearity -&gt; Ordering)
-&gt; (ForNonLinearity -&gt; ForNonLinearity -&gt; Bool)
-&gt; (ForNonLinearity -&gt; ForNonLinearity -&gt; Bool)
-&gt; (ForNonLinearity -&gt; ForNonLinearity -&gt; Bool)
-&gt; (ForNonLinearity -&gt; ForNonLinearity -&gt; Bool)
-&gt; (ForNonLinearity -&gt; ForNonLinearity -&gt; ForNonLinearity)
-&gt; (ForNonLinearity -&gt; ForNonLinearity -&gt; ForNonLinearity)
-&gt; Ord ForNonLinearity
ForNonLinearity -&gt; ForNonLinearity -&gt; Bool
ForNonLinearity -&gt; ForNonLinearity -&gt; Ordering
ForNonLinearity -&gt; ForNonLinearity -&gt; ForNonLinearity
forall a.
Eq a
-&gt; (a -&gt; a -&gt; Ordering)
-&gt; (a -&gt; a -&gt; Bool)
-&gt; (a -&gt; a -&gt; Bool)
-&gt; (a -&gt; a -&gt; Bool)
-&gt; (a -&gt; a -&gt; Bool)
-&gt; (a -&gt; a -&gt; a)
-&gt; (a -&gt; a -&gt; a)
-&gt; Ord a
min :: ForNonLinearity -&gt; ForNonLinearity -&gt; ForNonLinearity
$cmin :: ForNonLinearity -&gt; ForNonLinearity -&gt; ForNonLinearity
max :: ForNonLinearity -&gt; ForNonLinearity -&gt; ForNonLinearity
$cmax :: ForNonLinearity -&gt; ForNonLinearity -&gt; ForNonLinearity
&gt;= :: ForNonLinearity -&gt; ForNonLinearity -&gt; Bool
$c&gt;= :: ForNonLinearity -&gt; ForNonLinearity -&gt; Bool
&gt; :: ForNonLinearity -&gt; ForNonLinearity -&gt; Bool
$c&gt; :: ForNonLinearity -&gt; ForNonLinearity -&gt; Bool
&lt;= :: ForNonLinearity -&gt; ForNonLinearity -&gt; Bool
$c&lt;= :: ForNonLinearity -&gt; ForNonLinearity -&gt; Bool
&lt; :: ForNonLinearity -&gt; ForNonLinearity -&gt; Bool
$c&lt; :: ForNonLinearity -&gt; ForNonLinearity -&gt; Bool
compare :: ForNonLinearity -&gt; ForNonLinearity -&gt; Ordering
$ccompare :: ForNonLinearity -&gt; ForNonLinearity -&gt; Ordering
$cp1Ord :: Eq ForNonLinearity
</span><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">Ord</span></span></span></span></span></span></span></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679800208"><span id="local-6989586621679800210"><span id="local-6989586621679800212"><span class="annot"><span class="annottext">Int -&gt; ForNonLinearity -&gt; ShowS
[ForNonLinearity] -&gt; ShowS
ForNonLinearity -&gt; String
(Int -&gt; ForNonLinearity -&gt; ShowS)
-&gt; (ForNonLinearity -&gt; String)
-&gt; ([ForNonLinearity] -&gt; ShowS)
-&gt; Show ForNonLinearity
forall a.
(Int -&gt; a -&gt; ShowS) -&gt; (a -&gt; String) -&gt; ([a] -&gt; ShowS) -&gt; Show a
showList :: [ForNonLinearity] -&gt; ShowS
$cshowList :: [ForNonLinearity] -&gt; ShowS
show :: ForNonLinearity -&gt; String
$cshow :: ForNonLinearity -&gt; String
showsPrec :: Int -&gt; ForNonLinearity -&gt; ShowS
$cshowsPrec :: Int -&gt; ForNonLinearity -&gt; ShowS
</span><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">Show</span></span></span></span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">(forall x. ForNonLinearity -&gt; Rep ForNonLinearity x)
-&gt; (forall x. Rep ForNonLinearity x -&gt; ForNonLinearity)
-&gt; Generic ForNonLinearity
forall x. Rep ForNonLinearity x -&gt; ForNonLinearity
forall x. ForNonLinearity -&gt; Rep ForNonLinearity x
forall a.
(forall x. a -&gt; Rep a x) -&gt; (forall x. Rep a x -&gt; a) -&gt; Generic a
$cto :: forall x. Rep ForNonLinearity x -&gt; ForNonLinearity
$cfrom :: forall x. ForNonLinearity -&gt; Rep ForNonLinearity x
</span><span class="hs-identifier hs-var hs-var hs-var hs-var">Generic</span></span><span class="hs-special">)</span><span>
</span><span id="line-37"></span><span>
</span><span id="line-38"></span><span id="local-6989586621679800202"><span id="local-6989586621679800203"></span></span><span class="hs-keyword">data</span><span> </span><span id="FanMode"><span class="annot"><a href="Torch.GraduallyTyped.NN.Initialization.html#FanMode"><span class="hs-identifier hs-var">FanMode</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span id="FanIn"><span class="annot"><a href="Torch.GraduallyTyped.NN.Initialization.html#FanIn"><span class="hs-identifier hs-var">FanIn</span></a></span></span><span> </span><span class="hs-glyph">|</span><span> </span><span id="FanOut"><span class="annot"><a href="Torch.GraduallyTyped.NN.Initialization.html#FanOut"><span class="hs-identifier hs-var">FanOut</span></a></span></span><span>
</span><span id="line-39"></span><span>  </span><span class="hs-keyword">deriving</span><span> </span><span class="annot"><span class="hs-keyword">stock</span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679800196"><span id="local-6989586621679800198"><span class="annot"><span class="annottext">FanMode -&gt; FanMode -&gt; Bool
(FanMode -&gt; FanMode -&gt; Bool)
-&gt; (FanMode -&gt; FanMode -&gt; Bool) -&gt; Eq FanMode
forall a. (a -&gt; a -&gt; Bool) -&gt; (a -&gt; a -&gt; Bool) -&gt; Eq a
/= :: FanMode -&gt; FanMode -&gt; Bool
$c/= :: FanMode -&gt; FanMode -&gt; Bool
== :: FanMode -&gt; FanMode -&gt; Bool
$c== :: FanMode -&gt; FanMode -&gt; Bool
</span><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var">Eq</span></span></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679800181"><span id="local-6989586621679800183"><span id="local-6989586621679800185"><span id="local-6989586621679800187"><span id="local-6989586621679800189"><span id="local-6989586621679800191"><span id="local-6989586621679800193"><span class="annot"><span class="annottext">Eq FanMode
Eq FanMode
-&gt; (FanMode -&gt; FanMode -&gt; Ordering)
-&gt; (FanMode -&gt; FanMode -&gt; Bool)
-&gt; (FanMode -&gt; FanMode -&gt; Bool)
-&gt; (FanMode -&gt; FanMode -&gt; Bool)
-&gt; (FanMode -&gt; FanMode -&gt; Bool)
-&gt; (FanMode -&gt; FanMode -&gt; FanMode)
-&gt; (FanMode -&gt; FanMode -&gt; FanMode)
-&gt; Ord FanMode
FanMode -&gt; FanMode -&gt; Bool
FanMode -&gt; FanMode -&gt; Ordering
FanMode -&gt; FanMode -&gt; FanMode
forall a.
Eq a
-&gt; (a -&gt; a -&gt; Ordering)
-&gt; (a -&gt; a -&gt; Bool)
-&gt; (a -&gt; a -&gt; Bool)
-&gt; (a -&gt; a -&gt; Bool)
-&gt; (a -&gt; a -&gt; Bool)
-&gt; (a -&gt; a -&gt; a)
-&gt; (a -&gt; a -&gt; a)
-&gt; Ord a
min :: FanMode -&gt; FanMode -&gt; FanMode
$cmin :: FanMode -&gt; FanMode -&gt; FanMode
max :: FanMode -&gt; FanMode -&gt; FanMode
$cmax :: FanMode -&gt; FanMode -&gt; FanMode
&gt;= :: FanMode -&gt; FanMode -&gt; Bool
$c&gt;= :: FanMode -&gt; FanMode -&gt; Bool
&gt; :: FanMode -&gt; FanMode -&gt; Bool
$c&gt; :: FanMode -&gt; FanMode -&gt; Bool
&lt;= :: FanMode -&gt; FanMode -&gt; Bool
$c&lt;= :: FanMode -&gt; FanMode -&gt; Bool
&lt; :: FanMode -&gt; FanMode -&gt; Bool
$c&lt; :: FanMode -&gt; FanMode -&gt; Bool
compare :: FanMode -&gt; FanMode -&gt; Ordering
$ccompare :: FanMode -&gt; FanMode -&gt; Ordering
$cp1Ord :: Eq FanMode
</span><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">Ord</span></span></span></span></span></span></span></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679800175"><span id="local-6989586621679800177"><span id="local-6989586621679800179"><span class="annot"><span class="annottext">Int -&gt; FanMode -&gt; ShowS
[FanMode] -&gt; ShowS
FanMode -&gt; String
(Int -&gt; FanMode -&gt; ShowS)
-&gt; (FanMode -&gt; String) -&gt; ([FanMode] -&gt; ShowS) -&gt; Show FanMode
forall a.
(Int -&gt; a -&gt; ShowS) -&gt; (a -&gt; String) -&gt; ([a] -&gt; ShowS) -&gt; Show a
showList :: [FanMode] -&gt; ShowS
$cshowList :: [FanMode] -&gt; ShowS
show :: FanMode -&gt; String
$cshow :: FanMode -&gt; String
showsPrec :: Int -&gt; FanMode -&gt; ShowS
$cshowsPrec :: Int -&gt; FanMode -&gt; ShowS
</span><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">Show</span></span></span></span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">(forall x. FanMode -&gt; Rep FanMode x)
-&gt; (forall x. Rep FanMode x -&gt; FanMode) -&gt; Generic FanMode
forall x. Rep FanMode x -&gt; FanMode
forall x. FanMode -&gt; Rep FanMode x
forall a.
(forall x. a -&gt; Rep a x) -&gt; (forall x. Rep a x -&gt; a) -&gt; Generic a
$cto :: forall x. Rep FanMode x -&gt; FanMode
$cfrom :: forall x. FanMode -&gt; Rep FanMode x
</span><span class="hs-identifier hs-var hs-var hs-var hs-var">Generic</span></span><span class="hs-special">)</span><span>
</span><span id="line-40"></span><span>
</span><span id="line-41"></span><span class="annot"><a href="Torch.GraduallyTyped.NN.Initialization.html#errorPrefix"><span class="hs-identifier hs-type">errorPrefix</span></a></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">String</span></span><span>
</span><span id="line-42"></span><span id="errorPrefix"><span class="annot"><span class="annottext">errorPrefix :: String
</span><a href="Torch.GraduallyTyped.NN.Initialization.html#errorPrefix"><span class="hs-identifier hs-var hs-var">errorPrefix</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">String
</span><span class="hs-string">&quot;Error during tensor initialization. &quot;</span></span><span>
</span><span id="line-43"></span><span>
</span><span id="line-44"></span><span class="hs-comment">-- | Gain scaling value for He initialization</span><span>
</span><span id="line-45"></span><span class="annot"><a href="Torch.GraduallyTyped.NN.Initialization.html#calculateGain"><span class="hs-identifier hs-type">calculateGain</span></a></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Initialization.html#ForNonLinearity"><span class="hs-identifier hs-type">ForNonLinearity</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Float</span></span><span>
</span><span id="line-46"></span><span id="calculateGain"><span class="annot"><span class="annottext">calculateGain :: ForNonLinearity -&gt; Float
</span><a href="Torch.GraduallyTyped.NN.Initialization.html#calculateGain"><span class="hs-identifier hs-var hs-var">calculateGain</span></a></span></span><span> </span><span class="annot"><span class="annottext">ForNonLinearity
</span><a href="Torch.GraduallyTyped.NN.Initialization.html#ForIdentity"><span class="hs-identifier hs-var">ForIdentity</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Float
</span><span class="hs-number">1</span></span><span>
</span><span id="line-47"></span><span class="annot"><a href="Torch.GraduallyTyped.NN.Initialization.html#calculateGain"><span class="hs-identifier hs-var">calculateGain</span></a></span><span> </span><span class="annot"><span class="annottext">ForNonLinearity
</span><a href="Torch.GraduallyTyped.NN.Initialization.html#ForSigmoid"><span class="hs-identifier hs-var">ForSigmoid</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Float
</span><span class="hs-number">1</span></span><span>
</span><span id="line-48"></span><span class="annot"><a href="Torch.GraduallyTyped.NN.Initialization.html#calculateGain"><span class="hs-identifier hs-var">calculateGain</span></a></span><span> </span><span class="annot"><span class="annottext">ForNonLinearity
</span><a href="Torch.GraduallyTyped.NN.Initialization.html#ForTanh"><span class="hs-identifier hs-var">ForTanh</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Float
</span><span class="hs-number">5</span></span><span> </span><span class="annot"><span class="annottext">Float -&gt; Float -&gt; Float
forall a. Fractional a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">/</span></span><span> </span><span class="annot"><span class="annottext">Float
</span><span class="hs-number">3</span></span><span>
</span><span id="line-49"></span><span class="annot"><a href="Torch.GraduallyTyped.NN.Initialization.html#calculateGain"><span class="hs-identifier hs-var">calculateGain</span></a></span><span> </span><span class="annot"><span class="annottext">ForNonLinearity
</span><a href="Torch.GraduallyTyped.NN.Initialization.html#ForRelu"><span class="hs-identifier hs-var">ForRelu</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Float -&gt; Float
forall a. Floating a =&gt; a -&gt; a
</span><span class="hs-identifier hs-var">sqrt</span></span><span> </span><span class="annot"><span class="annottext">Float
</span><span class="hs-number">2</span></span><span>
</span><span id="line-50"></span><span class="annot"><a href="Torch.GraduallyTyped.NN.Initialization.html#calculateGain"><span class="hs-identifier hs-var">calculateGain</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Initialization.html#ForLeakyRelu"><span class="hs-identifier hs-type">ForLeakyRelu</span></a></span><span> </span><span id="local-6989586621679800168"><span class="annot"><span class="annottext">Float
</span><a href="#local-6989586621679800168"><span class="hs-identifier hs-var">param</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Float -&gt; Float
forall a. Floating a =&gt; a -&gt; a
</span><span class="hs-identifier hs-var">sqrt</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Float
</span><span class="hs-number">2</span></span><span> </span><span class="annot"><span class="annottext">Float -&gt; Float -&gt; Float
forall a. Fractional a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">/</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Float
</span><span class="hs-number">1</span></span><span> </span><span class="annot"><span class="annottext">Float -&gt; Float -&gt; Float
forall a. Num a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">+</span></span><span> </span><span class="annot"><span class="annottext">Float
</span><a href="#local-6989586621679800168"><span class="hs-identifier hs-var">param</span></a></span><span> </span><span class="annot"><span class="annottext">Float -&gt; Integer -&gt; Float
forall a b. (Fractional a, Integral b) =&gt; a -&gt; b -&gt; a
</span><span class="hs-operator hs-var">^^</span></span><span> </span><span class="annot"><span class="annottext">Integer
</span><span class="hs-number">2</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-51"></span><span>
</span><span id="line-52"></span><span class="hs-comment">-- | Fan-in / Fan-out scaling calculation</span><span>
</span><span id="line-53"></span><span class="annot"><a href="Torch.GraduallyTyped.NN.Initialization.html#calculateFan"><span class="hs-identifier hs-type">calculateFan</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-54"></span><span>  </span><span class="hs-special">[</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">String</span></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Integer</span></span><span class="hs-special">]</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-55"></span><span>  </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier hs-type">Integer</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Integer</span></span><span class="hs-special">)</span><span>
</span><span id="line-56"></span><span id="calculateFan"><span class="annot"><span class="annottext">calculateFan :: [Dim String Integer] -&gt; (Integer, Integer)
</span><a href="Torch.GraduallyTyped.NN.Initialization.html#calculateFan"><span class="hs-identifier hs-var hs-var">calculateFan</span></a></span></span><span> </span><span id="local-6989586621679800164"><span class="annot"><span class="annottext">[Dim String Integer]
</span><a href="#local-6989586621679800164"><span class="hs-identifier hs-var">shape</span></a></span></span><span>
</span><span id="line-57"></span><span>  </span><span class="hs-glyph">|</span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679800163"><span class="hs-identifier hs-var">dimT</span></a></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Bool
forall a. Ord a =&gt; a -&gt; a -&gt; Bool
</span><span class="hs-operator hs-var">&lt;</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">2</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">String -&gt; (Integer, Integer)
forall a. HasCallStack =&gt; String -&gt; a
</span><span class="hs-identifier hs-var">error</span></span><span> </span><span class="annot"><span class="annottext">(String -&gt; (Integer, Integer)) -&gt; String -&gt; (Integer, Integer)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">String
</span><a href="Torch.GraduallyTyped.NN.Initialization.html#errorPrefix"><span class="hs-identifier hs-var">errorPrefix</span></a></span><span> </span><span class="annot"><span class="annottext">String -&gt; ShowS
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">String
</span><span class="hs-string">&quot;Fan in and fan out can not be computed for tensor with fewer than 2 dimensions&quot;</span></span><span>
</span><span id="line-58"></span><span>  </span><span class="hs-glyph">|</span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679800163"><span class="hs-identifier hs-var">dimT</span></a></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Bool
forall a. Eq a =&gt; a -&gt; a -&gt; Bool
</span><span class="hs-operator hs-var">==</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">2</span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-59"></span><span>    </span><span class="hs-special">(</span><span> </span><span class="annot"><span class="annottext">Integer
</span><a href="#local-6989586621679800160"><span class="hs-identifier hs-var">numInputFmaps</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-60"></span><span>      </span><span class="annot"><span class="annottext">Integer
</span><a href="#local-6989586621679800159"><span class="hs-identifier hs-var">numOutputFmaps</span></a></span><span>
</span><span id="line-61"></span><span>    </span><span class="hs-special">)</span><span>
</span><span id="line-62"></span><span>  </span><span class="hs-glyph">|</span><span> </span><span class="annot"><span class="annottext">Bool
</span><span class="hs-identifier hs-var">otherwise</span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-63"></span><span>    </span><span class="hs-special">(</span><span> </span><span class="annot"><span class="annottext">Integer
</span><a href="#local-6989586621679800160"><span class="hs-identifier hs-var">numInputFmaps</span></a></span><span> </span><span class="annot"><span class="annottext">Integer -&gt; Integer -&gt; Integer
forall a. Num a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">*</span></span><span> </span><span class="annot"><span class="annottext">Integer
</span><a href="#local-6989586621679800157"><span class="hs-identifier hs-var">receptiveFieldSize</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-64"></span><span>      </span><span class="annot"><span class="annottext">Integer
</span><a href="#local-6989586621679800159"><span class="hs-identifier hs-var">numOutputFmaps</span></a></span><span> </span><span class="annot"><span class="annottext">Integer -&gt; Integer -&gt; Integer
forall a. Num a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">*</span></span><span> </span><span class="annot"><span class="annottext">Integer
</span><a href="#local-6989586621679800157"><span class="hs-identifier hs-var">receptiveFieldSize</span></a></span><span>
</span><span id="line-65"></span><span>    </span><span class="hs-special">)</span><span>
</span><span id="line-66"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-67"></span><span>    </span><span id="local-6989586621679800163"><span class="annot"><span class="annottext">dimT :: Int
</span><a href="#local-6989586621679800163"><span class="hs-identifier hs-var hs-var">dimT</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">[Dim String Integer] -&gt; Int
forall (t :: * -&gt; *) a. Foldable t =&gt; t a -&gt; Int
</span><span class="hs-identifier hs-var">length</span></span><span> </span><span class="annot"><span class="annottext">[Dim String Integer]
</span><a href="#local-6989586621679800164"><span class="hs-identifier hs-var">shape</span></a></span><span>
</span><span id="line-68"></span><span>    </span><span id="local-6989586621679800159"><span class="annot"><span class="annottext">Integer
</span><a href="#local-6989586621679800159"><span class="hs-identifier hs-var">numOutputFmaps</span></a></span></span><span> </span><span class="annot"><span class="hs-glyph hs-type">:</span></span><span> </span><span id="local-6989586621679800160"><span class="annot"><span class="annottext">Integer
</span><a href="#local-6989586621679800160"><span class="hs-identifier hs-var">numInputFmaps</span></a></span></span><span> </span><span class="annot"><span class="hs-glyph hs-type">:</span></span><span> </span><span class="annot"><span class="annottext">[Integer]
</span><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Dim String Integer -&gt; Integer
forall name size. Dim name size -&gt; size
</span><a href="Torch.GraduallyTyped.Shape.Type.html#dimSize"><span class="hs-identifier hs-var hs-var">dimSize</span></a></span><span> </span><span class="annot"><span class="annottext">(Dim String Integer -&gt; Integer)
-&gt; [Dim String Integer] -&gt; [Integer]
forall (f :: * -&gt; *) a b. Functor f =&gt; (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;$&gt;</span></span><span> </span><span class="annot"><span class="annottext">[Dim String Integer]
</span><a href="#local-6989586621679800164"><span class="hs-identifier hs-var">shape</span></a></span><span>
</span><span id="line-69"></span><span>    </span><span id="local-6989586621679800157"><span class="annot"><span class="annottext">receptiveFieldSize :: Integer
</span><a href="#local-6989586621679800157"><span class="hs-identifier hs-var hs-var">receptiveFieldSize</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">[Integer] -&gt; Integer
forall (t :: * -&gt; *) a. (Foldable t, Num a) =&gt; t a -&gt; a
</span><span class="hs-identifier hs-var">product</span></span><span> </span><span class="annot"><span class="annottext">([Integer] -&gt; Integer) -&gt; [Integer] -&gt; Integer
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">Dim String Integer -&gt; Integer
forall name size. Dim name size -&gt; size
</span><a href="Torch.GraduallyTyped.Shape.Type.html#dimSize"><span class="hs-identifier hs-var hs-var">dimSize</span></a></span><span> </span><span class="annot"><span class="annottext">(Dim String Integer -&gt; Integer)
-&gt; [Dim String Integer] -&gt; [Integer]
forall (f :: * -&gt; *) a b. Functor f =&gt; (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;$&gt;</span></span><span> </span><span class="annot"><span class="annottext">[Dim String Integer] -&gt; [Dim String Integer]
forall a. [a] -&gt; [a]
</span><span class="hs-identifier hs-var">tail</span></span><span> </span><span class="annot"><span class="annottext">[Dim String Integer]
</span><a href="#local-6989586621679800164"><span class="hs-identifier hs-var">shape</span></a></span><span>
</span><span id="line-70"></span><span>
</span><span id="line-71"></span><span class="hs-comment">-- | Xavier uniform initialization</span><span>
</span><span id="line-72"></span><span class="annot"><a href="Torch.GraduallyTyped.NN.Initialization.html#sXavierUniform"><span class="hs-identifier hs-type">sXavierUniform</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-73"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679800151"><span class="annot"><a href="#local-6989586621679800151"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679800150"><span class="annot"><a href="#local-6989586621679800150"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679800149"><span class="annot"><a href="#local-6989586621679800149"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679800148"><span class="annot"><a href="#local-6989586621679800148"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679800147"><span class="annot"><a href="#local-6989586621679800147"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679800146"><span class="annot"><a href="#local-6989586621679800146"><span class="hs-identifier hs-type">gain</span></a></span></span><span> </span><span id="local-6989586621679800145"><span class="annot"><a href="#local-6989586621679800145"><span class="hs-identifier hs-type">generatorDevice</span></a></span></span><span> </span><span id="local-6989586621679800144"><span class="annot"><a href="#local-6989586621679800144"><span class="hs-identifier hs-type">m</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-74"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Num</span></span><span> </span><span class="annot"><a href="#local-6989586621679800146"><span class="hs-identifier hs-type">gain</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-75"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Floating</span></span><span> </span><span class="annot"><a href="#local-6989586621679800146"><span class="hs-identifier hs-type">gain</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-76"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Scalar.html#Scalar"><span class="hs-identifier hs-type">Scalar</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679800146"><span class="hs-identifier hs-type">gain</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-77"></span><span>    </span><span class="annot"><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier hs-type">MonadThrow</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679800144"><span class="hs-identifier hs-type">m</span></a></span><span>
</span><span id="line-78"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-79"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorSpec"><span class="hs-identifier hs-type">TensorSpec</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679800151"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679800150"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679800149"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679800148"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679800147"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-80"></span><span>  </span><span class="annot"><a href="#local-6989586621679800146"><span class="hs-identifier hs-type">gain</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-81"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Random.html#Generator"><span class="hs-identifier hs-type">Generator</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679800145"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-82"></span><span>  </span><span class="annot"><a href="#local-6989586621679800144"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679800151"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679800150"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679800149"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679800145"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679800148"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679800147"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Random.html#Generator"><span class="hs-identifier hs-type">Generator</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679800149"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679800145"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-83"></span><span id="sXavierUniform"><span class="annot"><span class="annottext">sXavierUniform :: TensorSpec gradient layout device dataType shape
-&gt; gain
-&gt; Generator generatorDevice
-&gt; m (Tensor
        gradient layout (device &lt;+&gt; generatorDevice) dataType shape,
      Generator (device &lt;+&gt; generatorDevice))
</span><a href="Torch.GraduallyTyped.NN.Initialization.html#sXavierUniform"><span class="hs-identifier hs-var hs-var">sXavierUniform</span></a></span></span><span> </span><span id="local-6989586621679800143"><span class="annot"><span class="annottext">tensorSpec :: TensorSpec gradient layout device dataType shape
</span><a href="#local-6989586621679800143"><span class="hs-identifier hs-var">tensorSpec</span></a></span></span><span class="hs-glyph">@</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorSpec"><span class="hs-identifier hs-type">TensorSpec</span></a></span><span> </span><span class="hs-special">{</span><span id="local-6989586621679800137"><span id="local-6989586621679800138"><span id="local-6989586621679800139"><span id="local-6989586621679800140"><span id="local-6989586621679800141"><span class="annot"><span class="annottext">SLayout layout
SDevice device
SDataType dataType
SGradient gradient
SShape shape
tsShape :: forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
TensorSpec gradient layout device dataType shape -&gt; SShape shape
tsDataType :: forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
TensorSpec gradient layout device dataType shape
-&gt; SDataType dataType
tsDevice :: forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
TensorSpec gradient layout device dataType shape -&gt; SDevice device
tsLayout :: forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
TensorSpec gradient layout device dataType shape -&gt; SLayout layout
tsGradient :: forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
TensorSpec gradient layout device dataType shape
-&gt; SGradient gradient
tsShape :: SShape shape
tsDataType :: SDataType dataType
tsDevice :: SDevice device
tsLayout :: SLayout layout
tsGradient :: SGradient gradient
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#tsShape"><span class="hs-glyph hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">..</span></a></span></span></span></span></span></span><span class="hs-special">}</span><span> </span><span id="local-6989586621679800131"><span class="annot"><span class="annottext">gain
</span><a href="#local-6989586621679800131"><span class="hs-identifier hs-var">gain</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-84"></span><span>  </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679800130"><span class="annot"><span class="annottext">dims :: [Dim String Integer]
</span><a href="#local-6989586621679800130"><span class="hs-identifier hs-var hs-var">dims</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SShape shape -&gt; [Dim String Integer]
forall (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SShape shape -&gt; [Dim String Integer]
</span><a href="Torch.GraduallyTyped.Internal.TensorOptions.html#tensorDims"><span class="hs-identifier hs-var">tensorDims</span></a></span><span> </span><span class="annot"><span class="annottext">SShape shape
</span><a href="#local-6989586621679800137"><span class="hs-identifier hs-var">tsShape</span></a></span><span>
</span><span id="line-85"></span><span>      </span><span class="hs-special">(</span><span id="local-6989586621679800129"><span class="annot"><span class="annottext">Integer
</span><a href="#local-6989586621679800129"><span class="hs-identifier hs-var">fanIn</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679800128"><span class="annot"><span class="annottext">Integer
</span><a href="#local-6989586621679800128"><span class="hs-identifier hs-var">fanOut</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">[Dim String Integer] -&gt; (Integer, Integer)
</span><a href="Torch.GraduallyTyped.NN.Initialization.html#calculateFan"><span class="hs-identifier hs-var">calculateFan</span></a></span><span> </span><span class="annot"><span class="annottext">[Dim String Integer]
</span><a href="#local-6989586621679800130"><span class="hs-identifier hs-var">dims</span></a></span><span>
</span><span id="line-86"></span><span>      </span><span id="local-6989586621679800127"><span class="annot"><span class="annottext">std :: gain
</span><a href="#local-6989586621679800127"><span class="hs-identifier hs-var hs-var">std</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">gain
</span><a href="#local-6989586621679800131"><span class="hs-identifier hs-var">gain</span></a></span><span> </span><span class="annot"><span class="annottext">gain -&gt; gain -&gt; gain
forall a. Num a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">*</span></span><span> </span><span class="annot"><span class="annottext">gain -&gt; gain
forall a. Floating a =&gt; a -&gt; a
</span><span class="hs-identifier hs-var">sqrt</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">gain
</span><span class="hs-number">2</span></span><span> </span><span class="annot"><span class="annottext">gain -&gt; gain -&gt; gain
forall a. Fractional a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">/</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Integer -&gt; gain
forall a b. (Integral a, Num b) =&gt; a -&gt; b
</span><span class="hs-identifier hs-var">fromIntegral</span></span><span> </span><span class="annot"><span class="annottext">Integer
</span><a href="#local-6989586621679800129"><span class="hs-identifier hs-var">fanIn</span></a></span><span> </span><span class="annot"><span class="annottext">gain -&gt; gain -&gt; gain
forall a. Num a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">+</span></span><span> </span><span class="annot"><span class="annottext">Integer -&gt; gain
forall a b. (Integral a, Num b) =&gt; a -&gt; b
</span><span class="hs-identifier hs-var">fromIntegral</span></span><span> </span><span class="annot"><span class="annottext">Integer
</span><a href="#local-6989586621679800128"><span class="hs-identifier hs-var">fanOut</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-87"></span><span>      </span><span id="local-6989586621679800126"><span class="annot"><span class="annottext">bound :: gain
</span><a href="#local-6989586621679800126"><span class="hs-identifier hs-var hs-var">bound</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">gain -&gt; gain
forall a. Floating a =&gt; a -&gt; a
</span><span class="hs-identifier hs-var">sqrt</span></span><span> </span><span class="annot"><span class="annottext">gain
</span><span class="hs-number">3</span></span><span> </span><span class="annot"><span class="annottext">gain -&gt; gain -&gt; gain
forall a. Num a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">*</span></span><span> </span><span class="annot"><span class="annottext">gain
</span><a href="#local-6989586621679800127"><span class="hs-identifier hs-var">std</span></a></span><span>
</span><span id="line-88"></span><span>   </span><span class="hs-keyword">in</span><span> </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator
     (Unify (Device (DeviceType Nat)) device generatorDevice))
  (Tensor
     gradient
     layout
     (Unify (Device (DeviceType Nat)) device generatorDevice)
     dataType
     shape)
-&gt; Generator generatorDevice
-&gt; m (Tensor
        gradient
        layout
        (Unify (Device (DeviceType Nat)) device generatorDevice)
        dataType
        shape,
      Generator (Unify (Device (DeviceType Nat)) device generatorDevice))
forall (m :: * -&gt; *) i j a. IxStateT m i j a -&gt; i -&gt; m (a, j)
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var hs-var">runIxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">(IxStateT
   m
   (Generator generatorDevice)
   (Generator
      (Unify (Device (DeviceType Nat)) device generatorDevice))
   (Tensor
      gradient
      layout
      (Unify (Device (DeviceType Nat)) device generatorDevice)
      dataType
      shape)
 -&gt; Generator generatorDevice
 -&gt; m (Tensor
         gradient
         layout
         (Unify (Device (DeviceType Nat)) device generatorDevice)
         dataType
         shape,
       Generator
         (Unify (Device (DeviceType Nat)) device generatorDevice)))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator
        (Unify (Device (DeviceType Nat)) device generatorDevice))
     (Tensor
        gradient
        layout
        (Unify (Device (DeviceType Nat)) device generatorDevice)
        dataType
        shape)
-&gt; Generator generatorDevice
-&gt; m (Tensor
        gradient
        layout
        (Unify (Device (DeviceType Nat)) device generatorDevice)
        dataType
        shape,
      Generator (Unify (Device (DeviceType Nat)) device generatorDevice))
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-89"></span><span>        </span><span class="annot"><span class="annottext">(Generator generatorDevice
 -&gt; m (Tensor
         gradient
         layout
         (Unify (Device (DeviceType Nat)) device generatorDevice)
         dataType
         shape,
       Generator
         (Unify (Device (DeviceType Nat)) device generatorDevice)))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator
        (Unify (Device (DeviceType Nat)) device generatorDevice))
     (Tensor
        gradient
        layout
        (Unify (Device (DeviceType Nat)) device generatorDevice)
        dataType
        shape)
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">TensorSpec gradient layout device dataType shape
-&gt; Generator generatorDevice
-&gt; m (Tensor
        gradient layout (device &lt;+&gt; generatorDevice) dataType shape,
      Generator (device &lt;+&gt; generatorDevice))
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (generatorDevice :: Device (DeviceType Nat)) (m :: * -&gt; *).
MonadThrow m =&gt;
TensorSpec gradient layout device dataType shape
-&gt; Generator generatorDevice
-&gt; m (Tensor
        gradient layout (device &lt;+&gt; generatorDevice) dataType shape,
      Generator (device &lt;+&gt; generatorDevice))
</span><a href="Torch.GraduallyTyped.Tensor.Creation.html#sRandn"><span class="hs-identifier hs-var">sRandn</span></a></span><span> </span><span class="annot"><span class="annottext">TensorSpec gradient layout device dataType shape
</span><a href="#local-6989586621679800143"><span class="hs-identifier hs-var">tensorSpec</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-90"></span><span>          </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator
     (Unify (Device (DeviceType Nat)) device generatorDevice))
  (Tensor
     gradient
     layout
     (Unify (Device (DeviceType Nat)) device generatorDevice)
     dataType
     shape)
-&gt; (Tensor
      gradient
      layout
      (Unify (Device (DeviceType Nat)) device generatorDevice)
      dataType
      shape
    -&gt; IxStateT
         m
         (Generator
            (Unify (Device (DeviceType Nat)) device generatorDevice))
         (Generator
            (Unify (Device (DeviceType Nat)) device generatorDevice))
         (Tensor
            gradient
            layout
            (Unify (Device (DeviceType Nat)) device generatorDevice)
            dataType
            shape))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator
        (Unify (Device (DeviceType Nat)) device generatorDevice))
     (Tensor
        gradient
        layout
        (Unify (Device (DeviceType Nat)) device generatorDevice)
        dataType
        shape)
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="hs-glyph">\</span><span id="local-6989586621679800123"><span class="annot"><span class="annottext">Tensor
  gradient
  layout
  (Unify (Device (DeviceType Nat)) device generatorDevice)
  dataType
  shape
</span><a href="#local-6989586621679800123"><span class="hs-identifier hs-var">initTensor</span></a></span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">Tensor
  gradient
  layout
  (Unify (Device (DeviceType Nat)) device generatorDevice)
  dataType
  shape
-&gt; IxStateT
     m
     (Generator
        (Unify (Device (DeviceType Nat)) device generatorDevice))
     (Generator
        (Unify (Device (DeviceType Nat)) device generatorDevice))
     (Tensor
        gradient
        layout
        (Unify (Device (DeviceType Nat)) device generatorDevice)
        dataType
        shape)
forall k (m :: k -&gt; k -&gt; * -&gt; *) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">(Tensor
   gradient
   layout
   (Unify (Device (DeviceType Nat)) device generatorDevice)
   dataType
   shape
 -&gt; IxStateT
      m
      (Generator
         (Unify (Device (DeviceType Nat)) device generatorDevice))
      (Generator
         (Unify (Device (DeviceType Nat)) device generatorDevice))
      (Tensor
         gradient
         layout
         (Unify (Device (DeviceType Nat)) device generatorDevice)
         dataType
         shape))
-&gt; Tensor
     gradient
     layout
     (Unify (Device (DeviceType Nat)) device generatorDevice)
     dataType
     shape
-&gt; IxStateT
     m
     (Generator
        (Unify (Device (DeviceType Nat)) device generatorDevice))
     (Generator
        (Unify (Device (DeviceType Nat)) device generatorDevice))
     (Tensor
        gradient
        layout
        (Unify (Device (DeviceType Nat)) device generatorDevice)
        dataType
        shape)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Tensor
  gradient
  layout
  (Unify (Device (DeviceType Nat)) device generatorDevice)
  dataType
  shape
</span><a href="#local-6989586621679800123"><span class="hs-identifier hs-var">initTensor</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  gradient
  layout
  (Unify (Device (DeviceType Nat)) device generatorDevice)
  dataType
  shape
-&gt; gain
-&gt; Tensor
     gradient
     layout
     (Unify (Device (DeviceType Nat)) device generatorDevice)
     dataType
     shape
forall other (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
Scalar other =&gt;
Tensor gradient layout device dataType shape
-&gt; other -&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#mulScalar"><span class="hs-operator hs-var">`mulScalar`</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">gain
</span><a href="#local-6989586621679800126"><span class="hs-identifier hs-var">bound</span></a></span><span> </span><span class="annot"><span class="annottext">gain -&gt; gain -&gt; gain
forall a. Num a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">*</span></span><span> </span><span class="annot"><span class="annottext">gain
</span><span class="hs-number">2</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
  gradient
  layout
  (Unify (Device (DeviceType Nat)) device generatorDevice)
  dataType
  shape
-&gt; gain
-&gt; Tensor
     gradient
     layout
     (Unify (Device (DeviceType Nat)) device generatorDevice)
     dataType
     shape
forall other (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
Scalar other =&gt;
Tensor gradient layout device dataType shape
-&gt; other -&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#subScalar"><span class="hs-operator hs-var">`subScalar`</span></a></span><span> </span><span class="annot"><span class="annottext">gain
</span><a href="#local-6989586621679800126"><span class="hs-identifier hs-var">bound</span></a></span><span>
</span><span id="line-91"></span><span>
</span><span id="line-92"></span><span class="hs-comment">-- | Xavier normal initialization</span><span>
</span><span id="line-93"></span><span class="annot"><a href="Torch.GraduallyTyped.NN.Initialization.html#sXavierNormal"><span class="hs-identifier hs-type">sXavierNormal</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-94"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679800121"><span class="annot"><a href="#local-6989586621679800121"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679800120"><span class="annot"><a href="#local-6989586621679800120"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679800119"><span class="annot"><a href="#local-6989586621679800119"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679800118"><span class="annot"><a href="#local-6989586621679800118"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679800117"><span class="annot"><a href="#local-6989586621679800117"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679800116"><span class="annot"><a href="#local-6989586621679800116"><span class="hs-identifier hs-type">gain</span></a></span></span><span> </span><span id="local-6989586621679800115"><span class="annot"><a href="#local-6989586621679800115"><span class="hs-identifier hs-type">generatorDevice</span></a></span></span><span> </span><span id="local-6989586621679800114"><span class="annot"><a href="#local-6989586621679800114"><span class="hs-identifier hs-type">m</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-95"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Num</span></span><span> </span><span class="annot"><a href="#local-6989586621679800116"><span class="hs-identifier hs-type">gain</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-96"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Floating</span></span><span> </span><span class="annot"><a href="#local-6989586621679800116"><span class="hs-identifier hs-type">gain</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-97"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Scalar.html#Scalar"><span class="hs-identifier hs-type">Scalar</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679800116"><span class="hs-identifier hs-type">gain</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-98"></span><span>    </span><span class="annot"><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier hs-type">MonadThrow</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679800114"><span class="hs-identifier hs-type">m</span></a></span><span>
</span><span id="line-99"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-100"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorSpec"><span class="hs-identifier hs-type">TensorSpec</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679800121"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679800120"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679800119"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679800118"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679800117"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-101"></span><span>  </span><span class="annot"><a href="#local-6989586621679800116"><span class="hs-identifier hs-type">gain</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-102"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Random.html#Generator"><span class="hs-identifier hs-type">Generator</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679800115"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-103"></span><span>  </span><span class="annot"><a href="#local-6989586621679800114"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679800121"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679800120"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679800119"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679800115"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679800118"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679800117"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Random.html#Generator"><span class="hs-identifier hs-type">Generator</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679800119"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679800115"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-104"></span><span id="sXavierNormal"><span class="annot"><span class="annottext">sXavierNormal :: TensorSpec gradient layout device dataType shape
-&gt; gain
-&gt; Generator generatorDevice
-&gt; m (Tensor
        gradient layout (device &lt;+&gt; generatorDevice) dataType shape,
      Generator (device &lt;+&gt; generatorDevice))
</span><a href="Torch.GraduallyTyped.NN.Initialization.html#sXavierNormal"><span class="hs-identifier hs-var hs-var">sXavierNormal</span></a></span></span><span> </span><span id="local-6989586621679800113"><span class="annot"><span class="annottext">tensorSpec :: TensorSpec gradient layout device dataType shape
</span><a href="#local-6989586621679800113"><span class="hs-identifier hs-var">tensorSpec</span></a></span></span><span class="hs-glyph">@</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorSpec"><span class="hs-identifier hs-type">TensorSpec</span></a></span><span> </span><span class="hs-special">{</span><span id="local-6989586621679800108"><span id="local-6989586621679800109"><span id="local-6989586621679800110"><span id="local-6989586621679800111"><span id="local-6989586621679800112"><span class="annot"><span class="annottext">SLayout layout
SDevice device
SDataType dataType
SGradient gradient
SShape shape
tsShape :: SShape shape
tsDataType :: SDataType dataType
tsDevice :: SDevice device
tsLayout :: SLayout layout
tsGradient :: SGradient gradient
tsShape :: forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
TensorSpec gradient layout device dataType shape -&gt; SShape shape
tsDataType :: forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
TensorSpec gradient layout device dataType shape
-&gt; SDataType dataType
tsDevice :: forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
TensorSpec gradient layout device dataType shape -&gt; SDevice device
tsLayout :: forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
TensorSpec gradient layout device dataType shape -&gt; SLayout layout
tsGradient :: forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
TensorSpec gradient layout device dataType shape
-&gt; SGradient gradient
</span><a href="#local-6989586621679800108"><span class="hs-glyph hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">..</span></a></span></span></span></span></span></span><span class="hs-special">}</span><span> </span><span id="local-6989586621679800107"><span class="annot"><span class="annottext">gain
</span><a href="#local-6989586621679800107"><span class="hs-identifier hs-var">gain</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-105"></span><span>  </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679800106"><span class="annot"><span class="annottext">dims :: [Dim String Integer]
</span><a href="#local-6989586621679800106"><span class="hs-identifier hs-var hs-var">dims</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SShape shape -&gt; [Dim String Integer]
forall (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SShape shape -&gt; [Dim String Integer]
</span><a href="Torch.GraduallyTyped.Internal.TensorOptions.html#tensorDims"><span class="hs-identifier hs-var">tensorDims</span></a></span><span> </span><span class="annot"><span class="annottext">SShape shape
</span><a href="#local-6989586621679800108"><span class="hs-identifier hs-var">tsShape</span></a></span><span>
</span><span id="line-106"></span><span>      </span><span class="hs-special">(</span><span id="local-6989586621679800105"><span class="annot"><span class="annottext">Integer
</span><a href="#local-6989586621679800105"><span class="hs-identifier hs-var">fanIn</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679800104"><span class="annot"><span class="annottext">Integer
</span><a href="#local-6989586621679800104"><span class="hs-identifier hs-var">fanOut</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">[Dim String Integer] -&gt; (Integer, Integer)
</span><a href="Torch.GraduallyTyped.NN.Initialization.html#calculateFan"><span class="hs-identifier hs-var">calculateFan</span></a></span><span> </span><span class="annot"><span class="annottext">[Dim String Integer]
</span><a href="#local-6989586621679800106"><span class="hs-identifier hs-var">dims</span></a></span><span>
</span><span id="line-107"></span><span>      </span><span id="local-6989586621679800103"><span class="annot"><span class="annottext">std :: gain
</span><a href="#local-6989586621679800103"><span class="hs-identifier hs-var hs-var">std</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">gain
</span><a href="#local-6989586621679800107"><span class="hs-identifier hs-var">gain</span></a></span><span> </span><span class="annot"><span class="annottext">gain -&gt; gain -&gt; gain
forall a. Num a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">*</span></span><span> </span><span class="annot"><span class="annottext">gain -&gt; gain
forall a. Floating a =&gt; a -&gt; a
</span><span class="hs-identifier hs-var">sqrt</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">gain
</span><span class="hs-number">2</span></span><span> </span><span class="annot"><span class="annottext">gain -&gt; gain -&gt; gain
forall a. Fractional a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">/</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Integer -&gt; gain
forall a b. (Integral a, Num b) =&gt; a -&gt; b
</span><span class="hs-identifier hs-var">fromIntegral</span></span><span> </span><span class="annot"><span class="annottext">Integer
</span><a href="#local-6989586621679800105"><span class="hs-identifier hs-var">fanIn</span></a></span><span> </span><span class="annot"><span class="annottext">gain -&gt; gain -&gt; gain
forall a. Num a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">+</span></span><span> </span><span class="annot"><span class="annottext">Integer -&gt; gain
forall a b. (Integral a, Num b) =&gt; a -&gt; b
</span><span class="hs-identifier hs-var">fromIntegral</span></span><span> </span><span class="annot"><span class="annottext">Integer
</span><a href="#local-6989586621679800104"><span class="hs-identifier hs-var">fanOut</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-108"></span><span>   </span><span class="hs-keyword">in</span><span> </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator
     (Unify (Device (DeviceType Nat)) device generatorDevice))
  (Tensor
     gradient
     layout
     (Unify (Device (DeviceType Nat)) device generatorDevice)
     dataType
     shape)
-&gt; Generator generatorDevice
-&gt; m (Tensor
        gradient
        layout
        (Unify (Device (DeviceType Nat)) device generatorDevice)
        dataType
        shape,
      Generator (Unify (Device (DeviceType Nat)) device generatorDevice))
forall (m :: * -&gt; *) i j a. IxStateT m i j a -&gt; i -&gt; m (a, j)
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var hs-var">runIxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">(IxStateT
   m
   (Generator generatorDevice)
   (Generator
      (Unify (Device (DeviceType Nat)) device generatorDevice))
   (Tensor
      gradient
      layout
      (Unify (Device (DeviceType Nat)) device generatorDevice)
      dataType
      shape)
 -&gt; Generator generatorDevice
 -&gt; m (Tensor
         gradient
         layout
         (Unify (Device (DeviceType Nat)) device generatorDevice)
         dataType
         shape,
       Generator
         (Unify (Device (DeviceType Nat)) device generatorDevice)))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator
        (Unify (Device (DeviceType Nat)) device generatorDevice))
     (Tensor
        gradient
        layout
        (Unify (Device (DeviceType Nat)) device generatorDevice)
        dataType
        shape)
-&gt; Generator generatorDevice
-&gt; m (Tensor
        gradient
        layout
        (Unify (Device (DeviceType Nat)) device generatorDevice)
        dataType
        shape,
      Generator (Unify (Device (DeviceType Nat)) device generatorDevice))
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-109"></span><span>        </span><span class="annot"><span class="annottext">(Generator generatorDevice
 -&gt; m (Tensor
         gradient
         layout
         (Unify (Device (DeviceType Nat)) device generatorDevice)
         dataType
         shape,
       Generator
         (Unify (Device (DeviceType Nat)) device generatorDevice)))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator
        (Unify (Device (DeviceType Nat)) device generatorDevice))
     (Tensor
        gradient
        layout
        (Unify (Device (DeviceType Nat)) device generatorDevice)
        dataType
        shape)
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">TensorSpec gradient layout device dataType shape
-&gt; Generator generatorDevice
-&gt; m (Tensor
        gradient layout (device &lt;+&gt; generatorDevice) dataType shape,
      Generator (device &lt;+&gt; generatorDevice))
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (generatorDevice :: Device (DeviceType Nat)) (m :: * -&gt; *).
MonadThrow m =&gt;
TensorSpec gradient layout device dataType shape
-&gt; Generator generatorDevice
-&gt; m (Tensor
        gradient layout (device &lt;+&gt; generatorDevice) dataType shape,
      Generator (device &lt;+&gt; generatorDevice))
</span><a href="Torch.GraduallyTyped.Tensor.Creation.html#sRandn"><span class="hs-identifier hs-var">sRandn</span></a></span><span> </span><span class="annot"><span class="annottext">TensorSpec gradient layout device dataType shape
</span><a href="#local-6989586621679800113"><span class="hs-identifier hs-var">tensorSpec</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-110"></span><span>          </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator
     (Unify (Device (DeviceType Nat)) device generatorDevice))
  (Tensor
     gradient
     layout
     (Unify (Device (DeviceType Nat)) device generatorDevice)
     dataType
     shape)
-&gt; (Tensor
      gradient
      layout
      (Unify (Device (DeviceType Nat)) device generatorDevice)
      dataType
      shape
    -&gt; IxStateT
         m
         (Generator
            (Unify (Device (DeviceType Nat)) device generatorDevice))
         (Generator
            (Unify (Device (DeviceType Nat)) device generatorDevice))
         (Tensor
            gradient
            layout
            (Unify (Device (DeviceType Nat)) device generatorDevice)
            dataType
            shape))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator
        (Unify (Device (DeviceType Nat)) device generatorDevice))
     (Tensor
        gradient
        layout
        (Unify (Device (DeviceType Nat)) device generatorDevice)
        dataType
        shape)
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="hs-glyph">\</span><span id="local-6989586621679800102"><span class="annot"><span class="annottext">Tensor
  gradient
  layout
  (Unify (Device (DeviceType Nat)) device generatorDevice)
  dataType
  shape
</span><a href="#local-6989586621679800102"><span class="hs-identifier hs-var">initTensor</span></a></span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">Tensor
  gradient
  layout
  (Unify (Device (DeviceType Nat)) device generatorDevice)
  dataType
  shape
-&gt; IxStateT
     m
     (Generator
        (Unify (Device (DeviceType Nat)) device generatorDevice))
     (Generator
        (Unify (Device (DeviceType Nat)) device generatorDevice))
     (Tensor
        gradient
        layout
        (Unify (Device (DeviceType Nat)) device generatorDevice)
        dataType
        shape)
forall k (m :: k -&gt; k -&gt; * -&gt; *) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">(Tensor
   gradient
   layout
   (Unify (Device (DeviceType Nat)) device generatorDevice)
   dataType
   shape
 -&gt; IxStateT
      m
      (Generator
         (Unify (Device (DeviceType Nat)) device generatorDevice))
      (Generator
         (Unify (Device (DeviceType Nat)) device generatorDevice))
      (Tensor
         gradient
         layout
         (Unify (Device (DeviceType Nat)) device generatorDevice)
         dataType
         shape))
-&gt; Tensor
     gradient
     layout
     (Unify (Device (DeviceType Nat)) device generatorDevice)
     dataType
     shape
-&gt; IxStateT
     m
     (Generator
        (Unify (Device (DeviceType Nat)) device generatorDevice))
     (Generator
        (Unify (Device (DeviceType Nat)) device generatorDevice))
     (Tensor
        gradient
        layout
        (Unify (Device (DeviceType Nat)) device generatorDevice)
        dataType
        shape)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">Tensor
  gradient
  layout
  (Unify (Device (DeviceType Nat)) device generatorDevice)
  dataType
  shape
</span><a href="#local-6989586621679800102"><span class="hs-identifier hs-var">initTensor</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  gradient
  layout
  (Unify (Device (DeviceType Nat)) device generatorDevice)
  dataType
  shape
-&gt; gain
-&gt; Tensor
     gradient
     layout
     (Unify (Device (DeviceType Nat)) device generatorDevice)
     dataType
     shape
forall other (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
Scalar other =&gt;
Tensor gradient layout device dataType shape
-&gt; other -&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#mulScalar"><span class="hs-operator hs-var">`mulScalar`</span></a></span><span> </span><span class="annot"><span class="annottext">gain
</span><a href="#local-6989586621679800103"><span class="hs-identifier hs-var">std</span></a></span><span>
</span><span id="line-111"></span><span>
</span><span id="line-112"></span><span class="hs-comment">-- | Get fan in or fan out value depending on selected fan mode, used by Kaiming</span><span>
</span><span id="line-113"></span><span class="annot"><a href="Torch.GraduallyTyped.NN.Initialization.html#getter"><span class="hs-identifier hs-type">getter</span></a></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679800258"><span class="annot"><a href="#local-6989586621679800258"><span class="hs-identifier hs-type">a</span></a></span></span><span class="hs-operator">.</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Initialization.html#FanMode"><span class="hs-identifier hs-type">FanMode</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">(</span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679800258"><span class="hs-identifier hs-type">a</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679800258"><span class="hs-identifier hs-type">a</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="#local-6989586621679800258"><span class="hs-identifier hs-type">a</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-114"></span><span id="getter"><span class="annot"><span class="annottext">getter :: FanMode -&gt; (a, a) -&gt; a
</span><a href="Torch.GraduallyTyped.NN.Initialization.html#getter"><span class="hs-identifier hs-var hs-var">getter</span></a></span></span><span> </span><span class="annot"><span class="annottext">FanMode
</span><a href="Torch.GraduallyTyped.NN.Initialization.html#FanIn"><span class="hs-identifier hs-var">FanIn</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(a, a) -&gt; a
forall a b. (a, b) -&gt; a
</span><span class="hs-identifier hs-var">fst</span></span><span>
</span><span id="line-115"></span><span class="annot"><a href="Torch.GraduallyTyped.NN.Initialization.html#getter"><span class="hs-identifier hs-var">getter</span></a></span><span> </span><span class="annot"><span class="annottext">FanMode
</span><a href="Torch.GraduallyTyped.NN.Initialization.html#FanOut"><span class="hs-identifier hs-var">FanOut</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(a, a) -&gt; a
forall a b. (a, b) -&gt; b
</span><span class="hs-identifier hs-var">snd</span></span><span>
</span><span id="line-116"></span><span>
</span><span id="line-117"></span><span class="hs-comment">-- | Kaiming uniform initialization</span><span>
</span><span id="line-118"></span><span class="annot"><a href="Torch.GraduallyTyped.NN.Initialization.html#sKaimingUniform"><span class="hs-identifier hs-type">sKaimingUniform</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-119"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679800099"><span class="annot"><a href="#local-6989586621679800099"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679800098"><span class="annot"><a href="#local-6989586621679800098"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679800097"><span class="annot"><a href="#local-6989586621679800097"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679800096"><span class="annot"><a href="#local-6989586621679800096"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679800095"><span class="annot"><a href="#local-6989586621679800095"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679800094"><span class="annot"><a href="#local-6989586621679800094"><span class="hs-identifier hs-type">generatorDevice</span></a></span></span><span> </span><span id="local-6989586621679800093"><span class="annot"><a href="#local-6989586621679800093"><span class="hs-identifier hs-type">m</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-120"></span><span>  </span><span class="annot"><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier hs-type">MonadThrow</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679800093"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-121"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorSpec"><span class="hs-identifier hs-type">TensorSpec</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679800099"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679800098"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679800097"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679800096"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679800095"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-122"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Initialization.html#FanMode"><span class="hs-identifier hs-type">FanMode</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-123"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Initialization.html#ForNonLinearity"><span class="hs-identifier hs-type">ForNonLinearity</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-124"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Random.html#Generator"><span class="hs-identifier hs-type">Generator</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679800094"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-125"></span><span>  </span><span class="annot"><a href="#local-6989586621679800093"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679800099"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679800098"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679800097"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679800094"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679800096"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679800095"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Random.html#Generator"><span class="hs-identifier hs-type">Generator</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679800097"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679800094"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-126"></span><span id="sKaimingUniform"><span class="annot"><span class="annottext">sKaimingUniform :: TensorSpec gradient layout device dataType shape
-&gt; FanMode
-&gt; ForNonLinearity
-&gt; Generator generatorDevice
-&gt; m (Tensor
        gradient layout (device &lt;+&gt; generatorDevice) dataType shape,
      Generator (device &lt;+&gt; generatorDevice))
</span><a href="Torch.GraduallyTyped.NN.Initialization.html#sKaimingUniform"><span class="hs-identifier hs-var hs-var">sKaimingUniform</span></a></span></span><span> </span><span id="local-6989586621679800092"><span class="annot"><span class="annottext">tensorSpec :: TensorSpec gradient layout device dataType shape
</span><a href="#local-6989586621679800092"><span class="hs-identifier hs-var">tensorSpec</span></a></span></span><span class="hs-glyph">@</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorSpec"><span class="hs-identifier hs-type">TensorSpec</span></a></span><span> </span><span class="hs-special">{</span><span id="local-6989586621679800087"><span id="local-6989586621679800088"><span id="local-6989586621679800089"><span id="local-6989586621679800090"><span id="local-6989586621679800091"><span class="annot"><span class="annottext">SLayout layout
SDevice device
SDataType dataType
SGradient gradient
SShape shape
tsShape :: SShape shape
tsDataType :: SDataType dataType
tsDevice :: SDevice device
tsLayout :: SLayout layout
tsGradient :: SGradient gradient
tsShape :: forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
TensorSpec gradient layout device dataType shape -&gt; SShape shape
tsDataType :: forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
TensorSpec gradient layout device dataType shape
-&gt; SDataType dataType
tsDevice :: forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
TensorSpec gradient layout device dataType shape -&gt; SDevice device
tsLayout :: forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
TensorSpec gradient layout device dataType shape -&gt; SLayout layout
tsGradient :: forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
TensorSpec gradient layout device dataType shape
-&gt; SGradient gradient
</span><a href="#local-6989586621679800087"><span class="hs-glyph hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">..</span></a></span></span></span></span></span></span><span class="hs-special">}</span><span> </span><span id="local-6989586621679800086"><span class="annot"><span class="annottext">FanMode
</span><a href="#local-6989586621679800086"><span class="hs-identifier hs-var">fanMode</span></a></span></span><span> </span><span id="local-6989586621679800085"><span class="annot"><span class="annottext">ForNonLinearity
</span><a href="#local-6989586621679800085"><span class="hs-identifier hs-var">nonLinearity</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-127"></span><span>  </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679800084"><span class="annot"><span class="annottext">dims :: [Dim String Integer]
</span><a href="#local-6989586621679800084"><span class="hs-identifier hs-var hs-var">dims</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SShape shape -&gt; [Dim String Integer]
forall (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SShape shape -&gt; [Dim String Integer]
</span><a href="Torch.GraduallyTyped.Internal.TensorOptions.html#tensorDims"><span class="hs-identifier hs-var">tensorDims</span></a></span><span> </span><span class="annot"><span class="annottext">SShape shape
</span><a href="#local-6989586621679800087"><span class="hs-identifier hs-var">tsShape</span></a></span><span>
</span><span id="line-128"></span><span>      </span><span id="local-6989586621679800083"><span class="annot"><span class="annottext">gain :: Float
</span><a href="#local-6989586621679800083"><span class="hs-identifier hs-var hs-var">gain</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ForNonLinearity -&gt; Float
</span><a href="Torch.GraduallyTyped.NN.Initialization.html#calculateGain"><span class="hs-identifier hs-var">calculateGain</span></a></span><span> </span><span class="annot"><span class="annottext">ForNonLinearity
</span><a href="#local-6989586621679800085"><span class="hs-identifier hs-var">nonLinearity</span></a></span><span>
</span><span id="line-129"></span><span>      </span><span id="local-6989586621679800082"><span class="annot"><span class="annottext">fanValue :: Float
</span><a href="#local-6989586621679800082"><span class="hs-identifier hs-var hs-var">fanValue</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Integer -&gt; Float
forall a b. (Integral a, Num b) =&gt; a -&gt; b
</span><span class="hs-identifier hs-var">fromIntegral</span></span><span> </span><span class="annot"><span class="annottext">(Integer -&gt; Float) -&gt; Integer -&gt; Float
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">FanMode -&gt; (Integer, Integer) -&gt; Integer
forall a. FanMode -&gt; (a, a) -&gt; a
</span><a href="Torch.GraduallyTyped.NN.Initialization.html#getter"><span class="hs-identifier hs-var">getter</span></a></span><span> </span><span class="annot"><span class="annottext">FanMode
</span><a href="#local-6989586621679800086"><span class="hs-identifier hs-var">fanMode</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">[Dim String Integer] -&gt; (Integer, Integer)
</span><a href="Torch.GraduallyTyped.NN.Initialization.html#calculateFan"><span class="hs-identifier hs-var">calculateFan</span></a></span><span> </span><span class="annot"><span class="annottext">[Dim String Integer]
</span><a href="#local-6989586621679800084"><span class="hs-identifier hs-var">dims</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-130"></span><span>      </span><span id="local-6989586621679800081"><span class="annot"><span class="annottext">std :: Float
</span><a href="#local-6989586621679800081"><span class="hs-identifier hs-var hs-var">std</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Float
</span><a href="#local-6989586621679800083"><span class="hs-identifier hs-var">gain</span></a></span><span> </span><span class="annot"><span class="annottext">Float -&gt; Float -&gt; Float
forall a. Fractional a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">/</span></span><span> </span><span class="annot"><span class="annottext">Float -&gt; Float
forall a. Floating a =&gt; a -&gt; a
</span><span class="hs-identifier hs-var">sqrt</span></span><span> </span><span class="annot"><span class="annottext">Float
</span><a href="#local-6989586621679800082"><span class="hs-identifier hs-var">fanValue</span></a></span><span>
</span><span id="line-131"></span><span>      </span><span id="local-6989586621679800080"><span class="annot"><span class="annottext">bound :: Float
</span><a href="#local-6989586621679800080"><span class="hs-identifier hs-var hs-var">bound</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Float -&gt; Float
forall a. Floating a =&gt; a -&gt; a
</span><span class="hs-identifier hs-var">sqrt</span></span><span> </span><span class="annot"><span class="annottext">Float
</span><span class="hs-number">3</span></span><span> </span><span class="annot"><span class="annottext">Float -&gt; Float -&gt; Float
forall a. Num a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">*</span></span><span> </span><span class="annot"><span class="annottext">Float
</span><a href="#local-6989586621679800081"><span class="hs-identifier hs-var">std</span></a></span><span>
</span><span id="line-132"></span><span>   </span><span class="hs-keyword">in</span><span> </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator
     (Unify (Device (DeviceType Nat)) device generatorDevice))
  (Tensor
     gradient
     layout
     (Unify (Device (DeviceType Nat)) device generatorDevice)
     dataType
     shape)
-&gt; Generator generatorDevice
-&gt; m (Tensor
        gradient
        layout
        (Unify (Device (DeviceType Nat)) device generatorDevice)
        dataType
        shape,
      Generator (Unify (Device (DeviceType Nat)) device generatorDevice))
forall (m :: * -&gt; *) i j a. IxStateT m i j a -&gt; i -&gt; m (a, j)
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var hs-var">runIxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">(IxStateT
   m
   (Generator generatorDevice)
   (Generator
      (Unify (Device (DeviceType Nat)) device generatorDevice))
   (Tensor
      gradient
      layout
      (Unify (Device (DeviceType Nat)) device generatorDevice)
      dataType
      shape)
 -&gt; Generator generatorDevice
 -&gt; m (Tensor
         gradient
         layout
         (Unify (Device (DeviceType Nat)) device generatorDevice)
         dataType
         shape,
       Generator
         (Unify (Device (DeviceType Nat)) device generatorDevice)))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator
        (Unify (Device (DeviceType Nat)) device generatorDevice))
     (Tensor
        gradient
        layout
        (Unify (Device (DeviceType Nat)) device generatorDevice)
        dataType
        shape)
-&gt; Generator generatorDevice
-&gt; m (Tensor
        gradient
        layout
        (Unify (Device (DeviceType Nat)) device generatorDevice)
        dataType
        shape,
      Generator (Unify (Device (DeviceType Nat)) device generatorDevice))
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-133"></span><span>        </span><span class="annot"><span class="annottext">(Generator generatorDevice
 -&gt; m (Tensor
         gradient
         layout
         (Unify (Device (DeviceType Nat)) device generatorDevice)
         dataType
         shape,
       Generator
         (Unify (Device (DeviceType Nat)) device generatorDevice)))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator
        (Unify (Device (DeviceType Nat)) device generatorDevice))
     (Tensor
        gradient
        layout
        (Unify (Device (DeviceType Nat)) device generatorDevice)
        dataType
        shape)
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">TensorSpec gradient layout device dataType shape
-&gt; Generator generatorDevice
-&gt; m (Tensor
        gradient layout (device &lt;+&gt; generatorDevice) dataType shape,
      Generator (device &lt;+&gt; generatorDevice))
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (generatorDevice :: Device (DeviceType Nat)) (m :: * -&gt; *).
MonadThrow m =&gt;
TensorSpec gradient layout device dataType shape
-&gt; Generator generatorDevice
-&gt; m (Tensor
        gradient layout (device &lt;+&gt; generatorDevice) dataType shape,
      Generator (device &lt;+&gt; generatorDevice))
</span><a href="Torch.GraduallyTyped.Tensor.Creation.html#sRandn"><span class="hs-identifier hs-var">sRandn</span></a></span><span> </span><span class="annot"><span class="annottext">TensorSpec gradient layout device dataType shape
</span><a href="#local-6989586621679800092"><span class="hs-identifier hs-var">tensorSpec</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-134"></span><span>          </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator
     (Unify (Device (DeviceType Nat)) device generatorDevice))
  (Tensor
     gradient
     layout
     (Unify (Device (DeviceType Nat)) device generatorDevice)
     dataType
     shape)
-&gt; (Tensor
      gradient
      layout
      (Unify (Device (DeviceType Nat)) device generatorDevice)
      dataType
      shape
    -&gt; IxStateT
         m
         (Generator
            (Unify (Device (DeviceType Nat)) device generatorDevice))
         (Generator
            (Unify (Device (DeviceType Nat)) device generatorDevice))
         (Tensor
            gradient
            layout
            (Unify (Device (DeviceType Nat)) device generatorDevice)
            dataType
            shape))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator
        (Unify (Device (DeviceType Nat)) device generatorDevice))
     (Tensor
        gradient
        layout
        (Unify (Device (DeviceType Nat)) device generatorDevice)
        dataType
        shape)
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="hs-glyph">\</span><span id="local-6989586621679800079"><span class="annot"><span class="annottext">Tensor
  gradient
  layout
  (Unify (Device (DeviceType Nat)) device generatorDevice)
  dataType
  shape
</span><a href="#local-6989586621679800079"><span class="hs-identifier hs-var">initTensor</span></a></span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">Tensor
  gradient
  layout
  (Unify (Device (DeviceType Nat)) device generatorDevice)
  dataType
  shape
-&gt; IxStateT
     m
     (Generator
        (Unify (Device (DeviceType Nat)) device generatorDevice))
     (Generator
        (Unify (Device (DeviceType Nat)) device generatorDevice))
     (Tensor
        gradient
        layout
        (Unify (Device (DeviceType Nat)) device generatorDevice)
        dataType
        shape)
forall k (m :: k -&gt; k -&gt; * -&gt; *) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">(Tensor
   gradient
   layout
   (Unify (Device (DeviceType Nat)) device generatorDevice)
   dataType
   shape
 -&gt; IxStateT
      m
      (Generator
         (Unify (Device (DeviceType Nat)) device generatorDevice))
      (Generator
         (Unify (Device (DeviceType Nat)) device generatorDevice))
      (Tensor
         gradient
         layout
         (Unify (Device (DeviceType Nat)) device generatorDevice)
         dataType
         shape))
-&gt; Tensor
     gradient
     layout
     (Unify (Device (DeviceType Nat)) device generatorDevice)
     dataType
     shape
-&gt; IxStateT
     m
     (Generator
        (Unify (Device (DeviceType Nat)) device generatorDevice))
     (Generator
        (Unify (Device (DeviceType Nat)) device generatorDevice))
     (Tensor
        gradient
        layout
        (Unify (Device (DeviceType Nat)) device generatorDevice)
        dataType
        shape)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Tensor
  gradient
  layout
  (Unify (Device (DeviceType Nat)) device generatorDevice)
  dataType
  shape
</span><a href="#local-6989586621679800079"><span class="hs-identifier hs-var">initTensor</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  gradient
  layout
  (Unify (Device (DeviceType Nat)) device generatorDevice)
  dataType
  shape
-&gt; Float
-&gt; Tensor
     gradient
     layout
     (Unify (Device (DeviceType Nat)) device generatorDevice)
     dataType
     shape
forall other (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
Scalar other =&gt;
Tensor gradient layout device dataType shape
-&gt; other -&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#mulScalar"><span class="hs-operator hs-var">`mulScalar`</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Float
</span><a href="#local-6989586621679800080"><span class="hs-identifier hs-var">bound</span></a></span><span> </span><span class="annot"><span class="annottext">Float -&gt; Float -&gt; Float
forall a. Num a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">*</span></span><span> </span><span class="annot"><span class="annottext">Float
</span><span class="hs-number">2</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
  gradient
  layout
  (Unify (Device (DeviceType Nat)) device generatorDevice)
  dataType
  shape
-&gt; Float
-&gt; Tensor
     gradient
     layout
     (Unify (Device (DeviceType Nat)) device generatorDevice)
     dataType
     shape
forall other (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
Scalar other =&gt;
Tensor gradient layout device dataType shape
-&gt; other -&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#subScalar"><span class="hs-operator hs-var">`subScalar`</span></a></span><span> </span><span class="annot"><span class="annottext">Float
</span><a href="#local-6989586621679800080"><span class="hs-identifier hs-var">bound</span></a></span><span>
</span><span id="line-135"></span><span>
</span><span id="line-136"></span><span class="hs-comment">-- | Kaiming normal initialization</span><span>
</span><span id="line-137"></span><span class="annot"><a href="Torch.GraduallyTyped.NN.Initialization.html#sKaimingNormal"><span class="hs-identifier hs-type">sKaimingNormal</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-138"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679800077"><span class="annot"><a href="#local-6989586621679800077"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679800076"><span class="annot"><a href="#local-6989586621679800076"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679800075"><span class="annot"><a href="#local-6989586621679800075"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679800074"><span class="annot"><a href="#local-6989586621679800074"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679800073"><span class="annot"><a href="#local-6989586621679800073"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679800072"><span class="annot"><a href="#local-6989586621679800072"><span class="hs-identifier hs-type">generatorDevice</span></a></span></span><span> </span><span id="local-6989586621679800071"><span class="annot"><a href="#local-6989586621679800071"><span class="hs-identifier hs-type">m</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-139"></span><span>  </span><span class="annot"><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier hs-type">MonadThrow</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679800071"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-140"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorSpec"><span class="hs-identifier hs-type">TensorSpec</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679800077"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679800076"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679800075"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679800074"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679800073"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-141"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Initialization.html#FanMode"><span class="hs-identifier hs-type">FanMode</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-142"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Initialization.html#ForNonLinearity"><span class="hs-identifier hs-type">ForNonLinearity</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-143"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Random.html#Generator"><span class="hs-identifier hs-type">Generator</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679800072"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-144"></span><span>  </span><span class="annot"><a href="#local-6989586621679800071"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679800077"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679800076"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679800075"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679800072"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679800074"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679800073"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Random.html#Generator"><span class="hs-identifier hs-type">Generator</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679800075"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679800072"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-145"></span><span id="sKaimingNormal"><span class="annot"><span class="annottext">sKaimingNormal :: TensorSpec gradient layout device dataType shape
-&gt; FanMode
-&gt; ForNonLinearity
-&gt; Generator generatorDevice
-&gt; m (Tensor
        gradient layout (device &lt;+&gt; generatorDevice) dataType shape,
      Generator (device &lt;+&gt; generatorDevice))
</span><a href="Torch.GraduallyTyped.NN.Initialization.html#sKaimingNormal"><span class="hs-identifier hs-var hs-var">sKaimingNormal</span></a></span></span><span> </span><span id="local-6989586621679800070"><span class="annot"><span class="annottext">tensorSpec :: TensorSpec gradient layout device dataType shape
</span><a href="#local-6989586621679800070"><span class="hs-identifier hs-var">tensorSpec</span></a></span></span><span class="hs-glyph">@</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorSpec"><span class="hs-identifier hs-type">TensorSpec</span></a></span><span> </span><span class="hs-special">{</span><span id="local-6989586621679800065"><span id="local-6989586621679800066"><span id="local-6989586621679800067"><span id="local-6989586621679800068"><span id="local-6989586621679800069"><span class="annot"><span class="annottext">SLayout layout
SDevice device
SDataType dataType
SGradient gradient
SShape shape
tsShape :: SShape shape
tsDataType :: SDataType dataType
tsDevice :: SDevice device
tsLayout :: SLayout layout
tsGradient :: SGradient gradient
tsShape :: forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
TensorSpec gradient layout device dataType shape -&gt; SShape shape
tsDataType :: forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
TensorSpec gradient layout device dataType shape
-&gt; SDataType dataType
tsDevice :: forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
TensorSpec gradient layout device dataType shape -&gt; SDevice device
tsLayout :: forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
TensorSpec gradient layout device dataType shape -&gt; SLayout layout
tsGradient :: forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
TensorSpec gradient layout device dataType shape
-&gt; SGradient gradient
</span><a href="#local-6989586621679800065"><span class="hs-glyph hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">..</span></a></span></span></span></span></span></span><span class="hs-special">}</span><span> </span><span id="local-6989586621679800064"><span class="annot"><span class="annottext">FanMode
</span><a href="#local-6989586621679800064"><span class="hs-identifier hs-var">fanMode</span></a></span></span><span> </span><span id="local-6989586621679800063"><span class="annot"><span class="annottext">ForNonLinearity
</span><a href="#local-6989586621679800063"><span class="hs-identifier hs-var">nonLinearity</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-146"></span><span>  </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679800062"><span class="annot"><span class="annottext">dims :: [Dim String Integer]
</span><a href="#local-6989586621679800062"><span class="hs-identifier hs-var hs-var">dims</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SShape shape -&gt; [Dim String Integer]
forall (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SShape shape -&gt; [Dim String Integer]
</span><a href="Torch.GraduallyTyped.Internal.TensorOptions.html#tensorDims"><span class="hs-identifier hs-var">tensorDims</span></a></span><span> </span><span class="annot"><span class="annottext">SShape shape
</span><a href="#local-6989586621679800065"><span class="hs-identifier hs-var">tsShape</span></a></span><span>
</span><span id="line-147"></span><span>      </span><span id="local-6989586621679800061"><span class="annot"><span class="annottext">gain :: Float
</span><a href="#local-6989586621679800061"><span class="hs-identifier hs-var hs-var">gain</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ForNonLinearity -&gt; Float
</span><a href="Torch.GraduallyTyped.NN.Initialization.html#calculateGain"><span class="hs-identifier hs-var">calculateGain</span></a></span><span> </span><span class="annot"><span class="annottext">ForNonLinearity
</span><a href="#local-6989586621679800063"><span class="hs-identifier hs-var">nonLinearity</span></a></span><span>
</span><span id="line-148"></span><span>      </span><span id="local-6989586621679800060"><span class="annot"><span class="annottext">fanValue :: Float
</span><a href="#local-6989586621679800060"><span class="hs-identifier hs-var hs-var">fanValue</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Integer -&gt; Float
forall a b. (Integral a, Num b) =&gt; a -&gt; b
</span><span class="hs-identifier hs-var">fromIntegral</span></span><span> </span><span class="annot"><span class="annottext">(Integer -&gt; Float) -&gt; Integer -&gt; Float
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">FanMode -&gt; (Integer, Integer) -&gt; Integer
forall a. FanMode -&gt; (a, a) -&gt; a
</span><a href="Torch.GraduallyTyped.NN.Initialization.html#getter"><span class="hs-identifier hs-var">getter</span></a></span><span> </span><span class="annot"><span class="annottext">FanMode
</span><a href="#local-6989586621679800064"><span class="hs-identifier hs-var">fanMode</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">[Dim String Integer] -&gt; (Integer, Integer)
</span><a href="Torch.GraduallyTyped.NN.Initialization.html#calculateFan"><span class="hs-identifier hs-var">calculateFan</span></a></span><span> </span><span class="annot"><span class="annottext">[Dim String Integer]
</span><a href="#local-6989586621679800062"><span class="hs-identifier hs-var">dims</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-149"></span><span>      </span><span id="local-6989586621679800059"><span class="annot"><span class="annottext">std :: Float
</span><a href="#local-6989586621679800059"><span class="hs-identifier hs-var hs-var">std</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Float
</span><a href="#local-6989586621679800061"><span class="hs-identifier hs-var">gain</span></a></span><span> </span><span class="annot"><span class="annottext">Float -&gt; Float -&gt; Float
forall a. Fractional a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">/</span></span><span> </span><span class="annot"><span class="annottext">Float -&gt; Float
forall a. Floating a =&gt; a -&gt; a
</span><span class="hs-identifier hs-var">sqrt</span></span><span> </span><span class="annot"><span class="annottext">Float
</span><a href="#local-6989586621679800060"><span class="hs-identifier hs-var">fanValue</span></a></span><span>
</span><span id="line-150"></span><span>   </span><span class="hs-keyword">in</span><span> </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator
     (Unify (Device (DeviceType Nat)) device generatorDevice))
  (Tensor
     gradient
     layout
     (Unify (Device (DeviceType Nat)) device generatorDevice)
     dataType
     shape)
-&gt; Generator generatorDevice
-&gt; m (Tensor
        gradient
        layout
        (Unify (Device (DeviceType Nat)) device generatorDevice)
        dataType
        shape,
      Generator (Unify (Device (DeviceType Nat)) device generatorDevice))
forall (m :: * -&gt; *) i j a. IxStateT m i j a -&gt; i -&gt; m (a, j)
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var hs-var">runIxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">(IxStateT
   m
   (Generator generatorDevice)
   (Generator
      (Unify (Device (DeviceType Nat)) device generatorDevice))
   (Tensor
      gradient
      layout
      (Unify (Device (DeviceType Nat)) device generatorDevice)
      dataType
      shape)
 -&gt; Generator generatorDevice
 -&gt; m (Tensor
         gradient
         layout
         (Unify (Device (DeviceType Nat)) device generatorDevice)
         dataType
         shape,
       Generator
         (Unify (Device (DeviceType Nat)) device generatorDevice)))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator
        (Unify (Device (DeviceType Nat)) device generatorDevice))
     (Tensor
        gradient
        layout
        (Unify (Device (DeviceType Nat)) device generatorDevice)
        dataType
        shape)
-&gt; Generator generatorDevice
-&gt; m (Tensor
        gradient
        layout
        (Unify (Device (DeviceType Nat)) device generatorDevice)
        dataType
        shape,
      Generator (Unify (Device (DeviceType Nat)) device generatorDevice))
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-151"></span><span>        </span><span class="annot"><span class="annottext">(Generator generatorDevice
 -&gt; m (Tensor
         gradient
         layout
         (Unify (Device (DeviceType Nat)) device generatorDevice)
         dataType
         shape,
       Generator
         (Unify (Device (DeviceType Nat)) device generatorDevice)))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator
        (Unify (Device (DeviceType Nat)) device generatorDevice))
     (Tensor
        gradient
        layout
        (Unify (Device (DeviceType Nat)) device generatorDevice)
        dataType
        shape)
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">TensorSpec gradient layout device dataType shape
-&gt; Generator generatorDevice
-&gt; m (Tensor
        gradient layout (device &lt;+&gt; generatorDevice) dataType shape,
      Generator (device &lt;+&gt; generatorDevice))
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (generatorDevice :: Device (DeviceType Nat)) (m :: * -&gt; *).
MonadThrow m =&gt;
TensorSpec gradient layout device dataType shape
-&gt; Generator generatorDevice
-&gt; m (Tensor
        gradient layout (device &lt;+&gt; generatorDevice) dataType shape,
      Generator (device &lt;+&gt; generatorDevice))
</span><a href="Torch.GraduallyTyped.Tensor.Creation.html#sRandn"><span class="hs-identifier hs-var">sRandn</span></a></span><span> </span><span class="annot"><span class="annottext">TensorSpec gradient layout device dataType shape
</span><a href="#local-6989586621679800070"><span class="hs-identifier hs-var">tensorSpec</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-152"></span><span>          </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator
     (Unify (Device (DeviceType Nat)) device generatorDevice))
  (Tensor
     gradient
     layout
     (Unify (Device (DeviceType Nat)) device generatorDevice)
     dataType
     shape)
-&gt; (Tensor
      gradient
      layout
      (Unify (Device (DeviceType Nat)) device generatorDevice)
      dataType
      shape
    -&gt; IxStateT
         m
         (Generator
            (Unify (Device (DeviceType Nat)) device generatorDevice))
         (Generator
            (Unify (Device (DeviceType Nat)) device generatorDevice))
         (Tensor
            gradient
            layout
            (Unify (Device (DeviceType Nat)) device generatorDevice)
            dataType
            shape))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator
        (Unify (Device (DeviceType Nat)) device generatorDevice))
     (Tensor
        gradient
        layout
        (Unify (Device (DeviceType Nat)) device generatorDevice)
        dataType
        shape)
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="hs-glyph">\</span><span id="local-6989586621679800058"><span class="annot"><span class="annottext">Tensor
  gradient
  layout
  (Unify (Device (DeviceType Nat)) device generatorDevice)
  dataType
  shape
</span><a href="#local-6989586621679800058"><span class="hs-identifier hs-var">initTensor</span></a></span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">Tensor
  gradient
  layout
  (Unify (Device (DeviceType Nat)) device generatorDevice)
  dataType
  shape
-&gt; IxStateT
     m
     (Generator
        (Unify (Device (DeviceType Nat)) device generatorDevice))
     (Generator
        (Unify (Device (DeviceType Nat)) device generatorDevice))
     (Tensor
        gradient
        layout
        (Unify (Device (DeviceType Nat)) device generatorDevice)
        dataType
        shape)
forall k (m :: k -&gt; k -&gt; * -&gt; *) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">(Tensor
   gradient
   layout
   (Unify (Device (DeviceType Nat)) device generatorDevice)
   dataType
   shape
 -&gt; IxStateT
      m
      (Generator
         (Unify (Device (DeviceType Nat)) device generatorDevice))
      (Generator
         (Unify (Device (DeviceType Nat)) device generatorDevice))
      (Tensor
         gradient
         layout
         (Unify (Device (DeviceType Nat)) device generatorDevice)
         dataType
         shape))
-&gt; Tensor
     gradient
     layout
     (Unify (Device (DeviceType Nat)) device generatorDevice)
     dataType
     shape
-&gt; IxStateT
     m
     (Generator
        (Unify (Device (DeviceType Nat)) device generatorDevice))
     (Generator
        (Unify (Device (DeviceType Nat)) device generatorDevice))
     (Tensor
        gradient
        layout
        (Unify (Device (DeviceType Nat)) device generatorDevice)
        dataType
        shape)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">Tensor
  gradient
  layout
  (Unify (Device (DeviceType Nat)) device generatorDevice)
  dataType
  shape
</span><a href="#local-6989586621679800058"><span class="hs-identifier hs-var">initTensor</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  gradient
  layout
  (Unify (Device (DeviceType Nat)) device generatorDevice)
  dataType
  shape
-&gt; Float
-&gt; Tensor
     gradient
     layout
     (Unify (Device (DeviceType Nat)) device generatorDevice)
     dataType
     shape
forall other (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
Scalar other =&gt;
Tensor gradient layout device dataType shape
-&gt; other -&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#mulScalar"><span class="hs-operator hs-var">`mulScalar`</span></a></span><span> </span><span class="annot"><span class="annottext">Float
</span><a href="#local-6989586621679800059"><span class="hs-identifier hs-var">std</span></a></span></pre></body></html>