<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><link rel="stylesheet" type="text/css" href="style.css" /><script type="text/javascript" src="highlight.js"></script></head><body><pre><span class="hs-pragma">{-# LANGUAGE DataKinds #-}</span><span>
</span><span id="line-2"></span><span class="hs-pragma">{-# LANGUAGE ScopedTypeVariables #-}</span><span>
</span><span id="line-3"></span><span class="hs-pragma">{-# LANGUAGE TypeFamilies #-}</span><span>
</span><span id="line-4"></span><span class="hs-pragma">{-# LANGUAGE TypeOperators #-}</span><span>
</span><span id="line-5"></span><span class="hs-pragma">{-# LANGUAGE UndecidableInstances #-}</span><span>
</span><span id="line-6"></span><span>
</span><span id="line-7"></span><span class="hs-keyword">module</span><span> </span><span class="hs-identifier">Torch.GraduallyTyped.NN.Functional.Normalization</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-8"></span><span>
</span><span id="line-9"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">GHC.TypeLits</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier">Nat</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier">Symbol</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier">TypeError</span></span><span class="hs-special">,</span><span> </span><span class="hs-keyword">type</span><span> </span><span class="annot"><span class="hs-operator">(+)</span></span><span class="hs-special">,</span><span> </span><span class="hs-keyword">type</span><span> </span><span class="hs-special">(</span><span class="hs-glyph">-</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-10"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">System.IO.Unsafe</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier">unsafePerformIO</span></span><span class="hs-special">)</span><span>
</span><span id="line-11"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html"><span class="hs-identifier">Torch.GraduallyTyped.Prelude</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Length"><span class="hs-identifier">Length</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Reverse"><span class="hs-identifier">Reverse</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-12"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html"><span class="hs-identifier">Torch.GraduallyTyped.Shape.Type</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#By"><span class="hs-identifier">By</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier">Name</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDims"><span class="hs-identifier">SelectDims</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier">Shape</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier">Size</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#dimSize"><span class="hs-identifier">dimSize</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-13"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Creation.html"><span class="hs-identifier">Torch.GraduallyTyped.Tensor.Creation</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-14"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html"><span class="hs-identifier">Torch.GraduallyTyped.Tensor.Type</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetShape"><span class="hs-identifier">SGetShape</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#getDims"><span class="hs-identifier">getDims</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier">Tensor</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-15"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html"><span class="hs-identifier">Torch.GraduallyTyped.Unify</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-keyword">type</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator">(&lt;+&gt;)</span></a></span><span class="hs-special">,</span><span> </span><span class="hs-keyword">type</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator">(&lt;|&gt;)</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-16"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier">Torch.Internal.Cast</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier">cast5</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier">cast6</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-17"></span><span class="hs-keyword">import</span><span> </span><span class="hs-keyword">qualified</span><span> </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier">Torch.Internal.Managed.Native</span></a></span><span> </span><span class="hs-keyword">as</span><span> </span><span class="annot"><span class="hs-identifier">ATen</span></span><span>
</span><span id="line-18"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/a8ll3m7yfhm0g8j77q9rvjhgdb07zpwk-type-errors-pretty-lib-type-errors-pretty-0.0.1.1-haddock-doc/share/doc/type-errors-pretty/html/src"><span class="hs-identifier">Type.Errors.Pretty</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-keyword">type</span><span> </span><span class="annot"><a href="../file:///nix/store/a8ll3m7yfhm0g8j77q9rvjhgdb07zpwk-type-errors-pretty-lib-type-errors-pretty-0.0.1.1-haddock-doc/share/doc/type-errors-pretty/html/src"><span class="hs-operator">(%)</span></a></span><span class="hs-special">,</span><span> </span><span class="hs-keyword">type</span><span> </span><span class="annot"><a href="../file:///nix/store/a8ll3m7yfhm0g8j77q9rvjhgdb07zpwk-type-errors-pretty-lib-type-errors-pretty-0.0.1.1-haddock-doc/share/doc/type-errors-pretty/html/src"><span class="hs-operator">(&lt;&gt;)</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-19"></span><span>
</span><span id="line-20"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span> </span><span id="LayerNormImplF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Functional.Normalization.html#LayerNormImplF"><span class="hs-identifier hs-var">LayerNormImplF</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679524605"><span class="annot"><a href="#local-6989586621679524605"><span class="hs-identifier hs-type">reverseNormalizedDims</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679524604"><span class="annot"><a href="#local-6989586621679524604"><span class="hs-identifier hs-type">reverseInputDims</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">]</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-21"></span><span>  </span><span id="LayerNormImplF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Functional.Normalization.html#LayerNormImplF"><span class="hs-identifier hs-var">LayerNormImplF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="hs-special">]</span><span> </span><span id="local-6989586621679524603"><span class="annot"><a href="#local-6989586621679524603"><span class="hs-identifier hs-type hs-type">reverseInputDims</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="#local-6989586621679524603"><span class="hs-identifier hs-type">reverseInputDims</span></a></span><span>
</span><span id="line-22"></span><span>  </span><span id="LayerNormImplF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Functional.Normalization.html#LayerNormImplF"><span class="hs-identifier hs-var">LayerNormImplF</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679524602"><span class="annot"><a href="#local-6989586621679524602"><span class="hs-identifier hs-type hs-type">normalizedDim</span></a></span></span><span> </span><span class="hs-special">'</span><span class="hs-glyph">:</span><span> </span><span id="local-6989586621679524601"><span class="annot"><a href="#local-6989586621679524601"><span class="hs-identifier hs-type hs-type">reverseNormalizedDims</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679524600"><span class="annot"><a href="#local-6989586621679524600"><span class="hs-identifier hs-type hs-type">inputDim</span></a></span></span><span> </span><span class="hs-special">'</span><span class="hs-glyph">:</span><span> </span><span id="local-6989586621679524599"><span class="annot"><a href="#local-6989586621679524599"><span class="hs-identifier hs-type hs-type">reverseInputDims</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="#local-6989586621679524602"><span class="hs-identifier hs-type">normalizedDim</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679524600"><span class="hs-identifier hs-type">inputDim</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-glyph">:</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Functional.Normalization.html#LayerNormImplF"><span class="hs-identifier hs-type">LayerNormImplF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679524601"><span class="hs-identifier hs-type">reverseNormalizedDims</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679524599"><span class="hs-identifier hs-type">reverseInputDims</span></a></span><span>
</span><span id="line-23"></span><span>  </span><span id="LayerNormImplF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Functional.Normalization.html#LayerNormImplF"><span class="hs-identifier hs-var">LayerNormImplF</span></a></span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="hs-special">]</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="hs-identifier hs-type">TypeError</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Functional.Normalization.html#LayerNormShapeErrorMessage"><span class="hs-identifier hs-type">LayerNormShapeErrorMessage</span></a></span><span>
</span><span id="line-24"></span><span>
</span><span id="line-25"></span><span class="hs-keyword">type</span><span> </span><span id="LayerNormShapeErrorMessage"><span class="annot"><a href="Torch.GraduallyTyped.NN.Functional.Normalization.html#LayerNormShapeErrorMessage"><span class="hs-identifier hs-var">LayerNormShapeErrorMessage</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-26"></span><span>  </span><span class="annot"><span class="hs-string">&quot;Cannot apply the layer norm. &quot;</span></span><span>
</span><span id="line-27"></span><span>    </span><span class="annot"><a href="../file:///nix/store/a8ll3m7yfhm0g8j77q9rvjhgdb07zpwk-type-errors-pretty-lib-type-errors-pretty-0.0.1.1-haddock-doc/share/doc/type-errors-pretty/html/src"><span class="hs-operator hs-type">%</span></a></span><span> </span><span class="annot"><span class="hs-string">&quot;The normalized shape exceeds the input shape.&quot;</span></span><span>
</span><span id="line-28"></span><span>
</span><span id="line-29"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span> </span><span id="LayerNormWithBiasF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Functional.Normalization.html#LayerNormWithBiasF"><span class="hs-identifier hs-var">LayerNormWithBiasF</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679524597"><span class="annot"><a href="#local-6989586621679524597"><span class="hs-identifier hs-type">weightShape</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">[</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679524596"><span class="annot"><a href="#local-6989586621679524596"><span class="hs-identifier hs-type">biasShape</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">[</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679524595"><span class="annot"><a href="#local-6989586621679524595"><span class="hs-identifier hs-type">inputShape</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">[</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">[</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">]</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-30"></span><span>  </span><span id="LayerNormWithBiasF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Functional.Normalization.html#LayerNormWithBiasF"><span class="hs-identifier hs-var">LayerNormWithBiasF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#UncheckedShape"><span class="hs-identifier hs-type">UncheckedShape</span></a></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#UncheckedShape"><span class="hs-identifier hs-type">UncheckedShape</span></a></span><span>
</span><span id="line-31"></span><span>  </span><span id="LayerNormWithBiasF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Functional.Normalization.html#LayerNormWithBiasF"><span class="hs-identifier hs-var">LayerNormWithBiasF</span></a></span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#UncheckedShape"><span class="hs-identifier hs-type">UncheckedShape</span></a></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#UncheckedShape"><span class="hs-identifier hs-type">UncheckedShape</span></a></span><span>
</span><span id="line-32"></span><span>  </span><span id="LayerNormWithBiasF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Functional.Normalization.html#LayerNormWithBiasF"><span class="hs-identifier hs-var">LayerNormWithBiasF</span></a></span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#UncheckedShape"><span class="hs-identifier hs-type">UncheckedShape</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#UncheckedShape"><span class="hs-identifier hs-type">UncheckedShape</span></a></span><span>
</span><span id="line-33"></span><span>  </span><span id="LayerNormWithBiasF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Functional.Normalization.html#LayerNormWithBiasF"><span class="hs-identifier hs-var">LayerNormWithBiasF</span></a></span></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span id="local-6989586621679524592"><span class="annot"><a href="#local-6989586621679524592"><span class="hs-identifier hs-type hs-type">weightDims</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span id="local-6989586621679524591"><span class="annot"><a href="#local-6989586621679524591"><span class="hs-identifier hs-type hs-type">biasDims</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span id="local-6989586621679524590"><span class="annot"><a href="#local-6989586621679524590"><span class="hs-identifier hs-type hs-type">inputDims</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Reverse"><span class="hs-identifier hs-type">Reverse</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Functional.Normalization.html#LayerNormImplF"><span class="hs-identifier hs-type">LayerNormImplF</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Reverse"><span class="hs-identifier hs-type">Reverse</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679524592"><span class="hs-identifier hs-type">weightDims</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679524591"><span class="hs-identifier hs-type">biasDims</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Reverse"><span class="hs-identifier hs-type">Reverse</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679524590"><span class="hs-identifier hs-type">inputDims</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-34"></span><span>
</span><span id="line-35"></span><span class="annot"><a href="Torch.GraduallyTyped.NN.Functional.Normalization.html#layerNormWithBias"><span class="hs-identifier hs-type">layerNormWithBias</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-36"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679524588"><span class="annot"><a href="#local-6989586621679524588"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679524587"><span class="annot"><a href="#local-6989586621679524587"><span class="hs-identifier hs-type">gradient'</span></a></span></span><span> </span><span id="local-6989586621679524586"><span class="annot"><a href="#local-6989586621679524586"><span class="hs-identifier hs-type">gradient''</span></a></span></span><span> </span><span id="local-6989586621679524585"><span class="annot"><a href="#local-6989586621679524585"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679524584"><span class="annot"><a href="#local-6989586621679524584"><span class="hs-identifier hs-type">layout'</span></a></span></span><span> </span><span id="local-6989586621679524583"><span class="annot"><a href="#local-6989586621679524583"><span class="hs-identifier hs-type">layout''</span></a></span></span><span> </span><span id="local-6989586621679524582"><span class="annot"><a href="#local-6989586621679524582"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679524581"><span class="annot"><a href="#local-6989586621679524581"><span class="hs-identifier hs-type">device'</span></a></span></span><span> </span><span id="local-6989586621679524580"><span class="annot"><a href="#local-6989586621679524580"><span class="hs-identifier hs-type">device''</span></a></span></span><span> </span><span id="local-6989586621679524579"><span class="annot"><a href="#local-6989586621679524579"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679524578"><span class="annot"><a href="#local-6989586621679524578"><span class="hs-identifier hs-type">dataType'</span></a></span></span><span> </span><span id="local-6989586621679524577"><span class="annot"><a href="#local-6989586621679524577"><span class="hs-identifier hs-type">dataType''</span></a></span></span><span> </span><span id="local-6989586621679524576"><span class="annot"><a href="#local-6989586621679524576"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679524575"><span class="annot"><a href="#local-6989586621679524575"><span class="hs-identifier hs-type">shape'</span></a></span></span><span> </span><span id="local-6989586621679524574"><span class="annot"><a href="#local-6989586621679524574"><span class="hs-identifier hs-type">shape''</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-37"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetShape"><span class="hs-identifier hs-type">SGetShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679524576"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-38"></span><span>  </span><span class="hs-comment">-- | weight</span><span>
</span><span id="line-39"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679524588"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679524585"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679524582"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679524579"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679524576"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-40"></span><span>  </span><span class="hs-comment">-- | bias</span><span>
</span><span id="line-41"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679524587"><span class="hs-identifier hs-type">gradient'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679524584"><span class="hs-identifier hs-type">layout'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679524581"><span class="hs-identifier hs-type">device'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679524578"><span class="hs-identifier hs-type">dataType'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679524575"><span class="hs-identifier hs-type">shape'</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-42"></span><span>  </span><span class="hs-comment">-- | eps</span><span>
</span><span id="line-43"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-44"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-45"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679524586"><span class="hs-identifier hs-type">gradient''</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679524583"><span class="hs-identifier hs-type">layout''</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679524580"><span class="hs-identifier hs-type">device''</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679524577"><span class="hs-identifier hs-type">dataType''</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679524574"><span class="hs-identifier hs-type">shape''</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-46"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-47"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-48"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679524587"><span class="hs-identifier hs-type">gradient'</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679524587"><span class="hs-identifier hs-type">gradient'</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679524586"><span class="hs-identifier hs-type">gradient''</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-49"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679524585"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679524584"><span class="hs-identifier hs-type">layout'</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679524583"><span class="hs-identifier hs-type">layout''</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-50"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679524582"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679524581"><span class="hs-identifier hs-type">device'</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679524580"><span class="hs-identifier hs-type">device''</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-51"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679524579"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679524578"><span class="hs-identifier hs-type">dataType'</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679524577"><span class="hs-identifier hs-type">dataType''</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-52"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Functional.Normalization.html#LayerNormWithBiasF"><span class="hs-identifier hs-type">LayerNormWithBiasF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679524576"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679524575"><span class="hs-identifier hs-type">shape'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679524574"><span class="hs-identifier hs-type">shape''</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-53"></span><span id="layerNormWithBias"><span class="annot"><span class="annottext">layerNormWithBias :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; Double
-&gt; Tensor gradient'' layout'' device'' dataType'' shape''
-&gt; Tensor
     (gradient' &lt;|&gt; (gradient' &lt;|&gt; gradient''))
     (layout &lt;+&gt; (layout' &lt;+&gt; layout''))
     (device &lt;+&gt; (device' &lt;+&gt; device''))
     (dataType &lt;+&gt; (dataType' &lt;+&gt; dataType''))
     (LayerNormWithBiasF shape shape' shape'')
</span><a href="Torch.GraduallyTyped.NN.Functional.Normalization.html#layerNormWithBias"><span class="hs-identifier hs-var hs-var">layerNormWithBias</span></a></span></span><span> </span><span id="local-6989586621679524573"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679524573"><span class="hs-identifier hs-var">weight</span></a></span></span><span> </span><span id="local-6989586621679524572"><span class="annot"><span class="annottext">Tensor gradient' layout' device' dataType' shape'
</span><a href="#local-6989586621679524572"><span class="hs-identifier hs-var">bias</span></a></span></span><span> </span><span id="local-6989586621679524571"><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679524571"><span class="hs-identifier hs-var">eps</span></a></span></span><span> </span><span id="local-6989586621679524570"><span class="annot"><span class="annottext">Tensor gradient'' layout'' device'' dataType'' shape''
</span><a href="#local-6989586621679524570"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO
  (Tensor
     (Or
        (Gradient RequiresGradient)
        gradient'
        (Or (Gradient RequiresGradient) gradient' gradient''))
     (Unify
        (Layout LayoutType)
        layout
        (Unify (Layout LayoutType) layout' layout''))
     (Unify
        (Device (DeviceType Nat))
        device
        (Unify (Device (DeviceType Nat)) device' device''))
     (Unify
        (DataType DType)
        dataType
        (Unify (DataType DType) dataType' dataType''))
     (LayerNormWithBiasF shape shape' shape''))
-&gt; Tensor
     (Or
        (Gradient RequiresGradient)
        gradient'
        (Or (Gradient RequiresGradient) gradient' gradient''))
     (Unify
        (Layout LayoutType)
        layout
        (Unify (Layout LayoutType) layout' layout''))
     (Unify
        (Device (DeviceType Nat))
        device
        (Unify (Device (DeviceType Nat)) device' device''))
     (Unify
        (DataType DType)
        dataType
        (Unify (DataType DType) dataType' dataType''))
     (LayerNormWithBiasF shape shape' shape'')
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO
   (Tensor
      (Or
         (Gradient RequiresGradient)
         gradient'
         (Or (Gradient RequiresGradient) gradient' gradient''))
      (Unify
         (Layout LayoutType)
         layout
         (Unify (Layout LayoutType) layout' layout''))
      (Unify
         (Device (DeviceType Nat))
         device
         (Unify (Device (DeviceType Nat)) device' device''))
      (Unify
         (DataType DType)
         dataType
         (Unify (DataType DType) dataType' dataType''))
      (LayerNormWithBiasF shape shape' shape''))
 -&gt; Tensor
      (Or
         (Gradient RequiresGradient)
         gradient'
         (Or (Gradient RequiresGradient) gradient' gradient''))
      (Unify
         (Layout LayoutType)
         layout
         (Unify (Layout LayoutType) layout' layout''))
      (Unify
         (Device (DeviceType Nat))
         device
         (Unify (Device (DeviceType Nat)) device' device''))
      (Unify
         (DataType DType)
         dataType
         (Unify (DataType DType) dataType' dataType''))
      (LayerNormWithBiasF shape shape' shape''))
-&gt; IO
     (Tensor
        (Or
           (Gradient RequiresGradient)
           gradient'
           (Or (Gradient RequiresGradient) gradient' gradient''))
        (Unify
           (Layout LayoutType)
           layout
           (Unify (Layout LayoutType) layout' layout''))
        (Unify
           (Device (DeviceType Nat))
           device
           (Unify (Device (DeviceType Nat)) device' device''))
        (Unify
           (DataType DType)
           dataType
           (Unify (DataType DType) dataType' dataType''))
        (LayerNormWithBiasF shape shape' shape''))
-&gt; Tensor
     (Or
        (Gradient RequiresGradient)
        gradient'
        (Or (Gradient RequiresGradient) gradient' gradient''))
     (Unify
        (Layout LayoutType)
        layout
        (Unify (Layout LayoutType) layout' layout''))
     (Unify
        (Device (DeviceType Nat))
        device
        (Unify (Device (DeviceType Nat)) device' device''))
     (Unify
        (DataType DType)
        dataType
        (Unify (DataType DType) dataType' dataType''))
     (LayerNormWithBiasF shape shape' shape'')
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-54"></span><span>  </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679524569"><span class="annot"><span class="annottext">weightDims :: [Dim String Integer]
</span><a href="#local-6989586621679524569"><span class="hs-identifier hs-var hs-var">weightDims</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
-&gt; [Dim String Integer]
forall (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType).
SGetShape shape =&gt;
Tensor gradient layout device dataType shape
-&gt; [Dim String Integer]
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#getDims"><span class="hs-identifier hs-var">getDims</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679524573"><span class="hs-identifier hs-var">weight</span></a></span><span>
</span><span id="line-55"></span><span>  </span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr IntArray
 -&gt; ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; CDouble
 -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient'' layout'' device'' dataType'' shape''
-&gt; [Integer]
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; Double
-&gt; IO
     (Tensor
        (Or
           (Gradient RequiresGradient)
           gradient'
           (Or (Gradient RequiresGradient) gradient' gradient''))
        (Unify
           (Layout LayoutType)
           layout
           (Unify (Layout LayoutType) layout' layout''))
        (Unify
           (Device (DeviceType Nat))
           device
           (Unify (Device (DeviceType Nat)) device' device''))
        (Unify
           (DataType DType)
           dataType
           (Unify (DataType DType) dataType' dataType''))
        (LayerNormWithBiasF shape shape' shape''))
forall a ca x1 cx1 x2 cx2 x3 cx3 x4 cx4 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable x3 cx3,
 Castable x4 cx4, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; cx3 -&gt; cx4 -&gt; IO cy)
-&gt; a -&gt; x1 -&gt; x2 -&gt; x3 -&gt; x4 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast5</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; ForeignPtr IntArray
-&gt; ForeignPtr Tensor
-&gt; ForeignPtr Tensor
-&gt; CDouble
-&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.layer_norm_tlttd</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient'' layout'' device'' dataType'' shape''
</span><a href="#local-6989586621679524570"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Dim String Integer -&gt; Integer
forall name size. Dim name size -&gt; size
</span><a href="Torch.GraduallyTyped.Shape.Type.html#dimSize"><span class="hs-identifier hs-var hs-var">dimSize</span></a></span><span> </span><span class="annot"><span class="annottext">(Dim String Integer -&gt; Integer)
-&gt; [Dim String Integer] -&gt; [Integer]
forall (f :: * -&gt; *) a b. Functor f =&gt; (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;$&gt;</span></span><span> </span><span class="annot"><span class="annottext">[Dim String Integer]
</span><a href="#local-6989586621679524569"><span class="hs-identifier hs-var">weightDims</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679524573"><span class="hs-identifier hs-var">weight</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient' layout' device' dataType' shape'
</span><a href="#local-6989586621679524572"><span class="hs-identifier hs-var">bias</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679524571"><span class="hs-identifier hs-var">eps</span></a></span><span>
</span><span id="line-56"></span><span>
</span><span id="line-57"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span> </span><span id="LayerNormWithoutBiasF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Functional.Normalization.html#LayerNormWithoutBiasF"><span class="hs-identifier hs-var">LayerNormWithoutBiasF</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679524566"><span class="annot"><a href="#local-6989586621679524566"><span class="hs-identifier hs-type">weightShape</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">[</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679524565"><span class="annot"><a href="#local-6989586621679524565"><span class="hs-identifier hs-type">inputShape</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">[</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">[</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">]</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-58"></span><span>  </span><span id="LayerNormWithoutBiasF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Functional.Normalization.html#LayerNormWithoutBiasF"><span class="hs-identifier hs-var">LayerNormWithoutBiasF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#UncheckedShape"><span class="hs-identifier hs-type">UncheckedShape</span></a></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#UncheckedShape"><span class="hs-identifier hs-type">UncheckedShape</span></a></span><span>
</span><span id="line-59"></span><span>  </span><span id="LayerNormWithoutBiasF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Functional.Normalization.html#LayerNormWithoutBiasF"><span class="hs-identifier hs-var">LayerNormWithoutBiasF</span></a></span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#UncheckedShape"><span class="hs-identifier hs-type">UncheckedShape</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#UncheckedShape"><span class="hs-identifier hs-type">UncheckedShape</span></a></span><span>
</span><span id="line-60"></span><span>  </span><span id="LayerNormWithoutBiasF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Functional.Normalization.html#LayerNormWithoutBiasF"><span class="hs-identifier hs-var">LayerNormWithoutBiasF</span></a></span></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span id="local-6989586621679524564"><span class="annot"><a href="#local-6989586621679524564"><span class="hs-identifier hs-type hs-type">weightDims</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span id="local-6989586621679524563"><span class="annot"><a href="#local-6989586621679524563"><span class="hs-identifier hs-type hs-type">inputDims</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Reverse"><span class="hs-identifier hs-type">Reverse</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Functional.Normalization.html#LayerNormImplF"><span class="hs-identifier hs-type">LayerNormImplF</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Reverse"><span class="hs-identifier hs-type">Reverse</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679524564"><span class="hs-identifier hs-type">weightDims</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Reverse"><span class="hs-identifier hs-type">Reverse</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679524563"><span class="hs-identifier hs-type">inputDims</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-61"></span><span>
</span><span id="line-62"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span> </span><span id="LayerNormWithoutBiasSelectDimsF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Functional.Normalization.html#LayerNormWithoutBiasSelectDimsF"><span class="hs-identifier hs-var">LayerNormWithoutBiasSelectDimsF</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679524561"><span class="annot"><a href="#local-6989586621679524561"><span class="hs-identifier hs-type">weightShape</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">[</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679524560"><span class="annot"><a href="#local-6989586621679524560"><span class="hs-identifier hs-type">inputShape</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">[</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDims"><span class="hs-identifier hs-type">SelectDims</span></a></span><span> </span><span class="hs-special">[</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#By"><span class="hs-identifier hs-type">By</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">]</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-63"></span><span>  </span><span id="LayerNormWithoutBiasSelectDimsF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Functional.Normalization.html#LayerNormWithoutBiasSelectDimsF"><span class="hs-identifier hs-var">LayerNormWithoutBiasSelectDimsF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#UncheckedShape"><span class="hs-identifier hs-type">UncheckedShape</span></a></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#UncheckedSelectDims"><span class="hs-identifier hs-type">UncheckedSelectDims</span></a></span><span>
</span><span id="line-64"></span><span>  </span><span id="LayerNormWithoutBiasSelectDimsF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Functional.Normalization.html#LayerNormWithoutBiasSelectDimsF"><span class="hs-identifier hs-var">LayerNormWithoutBiasSelectDimsF</span></a></span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#UncheckedShape"><span class="hs-identifier hs-type">UncheckedShape</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#UncheckedSelectDims"><span class="hs-identifier hs-type">UncheckedSelectDims</span></a></span><span>
</span><span id="line-65"></span><span>  </span><span id="LayerNormWithoutBiasSelectDimsF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Functional.Normalization.html#LayerNormWithoutBiasSelectDimsF"><span class="hs-identifier hs-var">LayerNormWithoutBiasSelectDimsF</span></a></span></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span id="local-6989586621679524558"><span class="annot"><a href="#local-6989586621679524558"><span class="hs-identifier hs-type hs-type">weightDims</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span id="local-6989586621679524557"><span class="annot"><a href="#local-6989586621679524557"><span class="hs-identifier hs-type hs-type">inputDims</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDims"><span class="hs-identifier hs-type">SelectDims</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Functional.Normalization.html#LayerNormWithoutBiasBysF"><span class="hs-identifier hs-type">LayerNormWithoutBiasBysF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679524558"><span class="hs-identifier hs-type">weightDims</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679524557"><span class="hs-identifier hs-type">inputDims</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Length"><span class="hs-identifier hs-type">Length</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679524557"><span class="hs-identifier hs-type">inputDims</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span>
</span><span id="line-66"></span><span>
</span><span id="line-67"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span> </span><span id="LayerNormWithoutBiasBysF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Functional.Normalization.html#LayerNormWithoutBiasBysF"><span class="hs-identifier hs-var">LayerNormWithoutBiasBysF</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679524554"><span class="annot"><a href="#local-6989586621679524554"><span class="hs-identifier hs-type">weightDims</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679524553"><span class="annot"><a href="#local-6989586621679524553"><span class="hs-identifier hs-type">inputDims</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679524552"><span class="annot"><a href="#local-6989586621679524552"><span class="hs-identifier hs-type">inputDimsLength</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679524551"><span class="annot"><a href="#local-6989586621679524551"><span class="hs-identifier hs-type">counter</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#By"><span class="hs-identifier hs-type">By</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">]</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-68"></span><span>  </span><span id="LayerNormWithoutBiasBysF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Functional.Normalization.html#LayerNormWithoutBiasBysF"><span class="hs-identifier hs-var">LayerNormWithoutBiasBysF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="hs-special">]</span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="hs-special">]</span><span>
</span><span id="line-69"></span><span>  </span><span id="LayerNormWithoutBiasBysF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Functional.Normalization.html#LayerNormWithoutBiasBysF"><span class="hs-identifier hs-var">LayerNormWithoutBiasBysF</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-special">'</span><span class="hs-glyph">:</span><span> </span><span id="local-6989586621679524550"><span class="annot"><a href="#local-6989586621679524550"><span class="hs-identifier hs-type hs-type">weightDims</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-special">'</span><span class="hs-glyph">:</span><span> </span><span id="local-6989586621679524549"><span class="annot"><a href="#local-6989586621679524549"><span class="hs-identifier hs-type hs-type">inputDims</span></a></span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679524548"><span class="annot"><a href="#local-6989586621679524548"><span class="hs-identifier hs-type hs-type">inputDimsLength</span></a></span></span><span> </span><span id="local-6989586621679524547"><span class="annot"><a href="#local-6989586621679524547"><span class="hs-identifier hs-type hs-type">counter</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679524548"><span class="hs-identifier hs-type">inputDimsLength</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">-</span></span><span> </span><span class="annot"><a href="#local-6989586621679524547"><span class="hs-identifier hs-type">counter</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">'</span><span class="hs-glyph">:</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Functional.Normalization.html#LayerNormWithoutBiasBysF"><span class="hs-identifier hs-type">LayerNormWithoutBiasBysF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679524550"><span class="hs-identifier hs-type">weightDims</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679524549"><span class="hs-identifier hs-type">inputDims</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679524548"><span class="hs-identifier hs-type">inputDimsLength</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679524547"><span class="hs-identifier hs-type">counter</span></a></span><span> </span><span class="annot"><span class="hs-operator hs-type">+</span></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span>
</span><span id="line-70"></span><span>  </span><span id="LayerNormWithoutBiasBysF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Functional.Normalization.html#LayerNormWithoutBiasBysF"><span class="hs-identifier hs-var">LayerNormWithoutBiasBysF</span></a></span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="hs-special">]</span><span> </span><span id="local-6989586621679524545"><span class="annot"><a href="#local-6989586621679524545"><span class="hs-identifier hs-type hs-type">inputDimsLength</span></a></span></span><span> </span><span id="local-6989586621679524544"><span class="annot"><a href="#local-6989586621679524544"><span class="hs-identifier hs-type hs-type">counter</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-71"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">TypeError</span></span><span>
</span><span id="line-72"></span><span>      </span><span class="hs-special">(</span><span> </span><span class="annot"><span class="hs-string">&quot;Cannot apply the layer norm.&quot;</span></span><span>
</span><span id="line-73"></span><span>          </span><span class="annot"><a href="../file:///nix/store/a8ll3m7yfhm0g8j77q9rvjhgdb07zpwk-type-errors-pretty-lib-type-errors-pretty-0.0.1.1-haddock-doc/share/doc/type-errors-pretty/html/src"><span class="hs-operator hs-type">%</span></a></span><span> </span><span class="annot"><span class="hs-string">&quot;The provided weight tensor has more dimensions than the input tensor,&quot;</span></span><span>
</span><span id="line-74"></span><span>          </span><span class="annot"><a href="../file:///nix/store/a8ll3m7yfhm0g8j77q9rvjhgdb07zpwk-type-errors-pretty-lib-type-errors-pretty-0.0.1.1-haddock-doc/share/doc/type-errors-pretty/html/src"><span class="hs-operator hs-type">%</span></a></span><span> </span><span class="annot"><span class="hs-string">&quot;&quot;</span></span><span>
</span><span id="line-75"></span><span>          </span><span class="annot"><a href="../file:///nix/store/a8ll3m7yfhm0g8j77q9rvjhgdb07zpwk-type-errors-pretty-lib-type-errors-pretty-0.0.1.1-haddock-doc/share/doc/type-errors-pretty/html/src"><span class="hs-operator hs-type">%</span></a></span><span> </span><span class="annot"><span class="hs-string">&quot;    '&quot;</span></span><span> </span><span class="annot"><a href="../file:///nix/store/a8ll3m7yfhm0g8j77q9rvjhgdb07zpwk-type-errors-pretty-lib-type-errors-pretty-0.0.1.1-haddock-doc/share/doc/type-errors-pretty/html/src"><span class="hs-operator hs-type">&lt;&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679524544"><span class="hs-identifier hs-type">counter</span></a></span><span> </span><span class="annot"><a href="../file:///nix/store/a8ll3m7yfhm0g8j77q9rvjhgdb07zpwk-type-errors-pretty-lib-type-errors-pretty-0.0.1.1-haddock-doc/share/doc/type-errors-pretty/html/src"><span class="hs-operator hs-type">&lt;&gt;</span></a></span><span> </span><span class="annot"><span class="hs-string">&quot;'&quot;</span></span><span>
</span><span id="line-76"></span><span>          </span><span class="annot"><a href="../file:///nix/store/a8ll3m7yfhm0g8j77q9rvjhgdb07zpwk-type-errors-pretty-lib-type-errors-pretty-0.0.1.1-haddock-doc/share/doc/type-errors-pretty/html/src"><span class="hs-operator hs-type">%</span></a></span><span> </span><span class="annot"><span class="hs-string">&quot;&quot;</span></span><span>
</span><span id="line-77"></span><span>          </span><span class="annot"><a href="../file:///nix/store/a8ll3m7yfhm0g8j77q9rvjhgdb07zpwk-type-errors-pretty-lib-type-errors-pretty-0.0.1.1-haddock-doc/share/doc/type-errors-pretty/html/src"><span class="hs-operator hs-type">%</span></a></span><span> </span><span class="annot"><span class="hs-string">&quot;and&quot;</span></span><span>
</span><span id="line-78"></span><span>          </span><span class="annot"><a href="../file:///nix/store/a8ll3m7yfhm0g8j77q9rvjhgdb07zpwk-type-errors-pretty-lib-type-errors-pretty-0.0.1.1-haddock-doc/share/doc/type-errors-pretty/html/src"><span class="hs-operator hs-type">%</span></a></span><span> </span><span class="annot"><span class="hs-string">&quot;&quot;</span></span><span>
</span><span id="line-79"></span><span>          </span><span class="annot"><a href="../file:///nix/store/a8ll3m7yfhm0g8j77q9rvjhgdb07zpwk-type-errors-pretty-lib-type-errors-pretty-0.0.1.1-haddock-doc/share/doc/type-errors-pretty/html/src"><span class="hs-operator hs-type">%</span></a></span><span> </span><span class="annot"><span class="hs-string">&quot;    '&quot;</span></span><span> </span><span class="annot"><a href="../file:///nix/store/a8ll3m7yfhm0g8j77q9rvjhgdb07zpwk-type-errors-pretty-lib-type-errors-pretty-0.0.1.1-haddock-doc/share/doc/type-errors-pretty/html/src"><span class="hs-operator hs-type">&lt;&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679524545"><span class="hs-identifier hs-type">inputDimsLength</span></a></span><span> </span><span class="annot"><a href="../file:///nix/store/a8ll3m7yfhm0g8j77q9rvjhgdb07zpwk-type-errors-pretty-lib-type-errors-pretty-0.0.1.1-haddock-doc/share/doc/type-errors-pretty/html/src"><span class="hs-operator hs-type">&lt;&gt;</span></a></span><span> </span><span class="annot"><span class="hs-string">&quot;',&quot;</span></span><span>
</span><span id="line-80"></span><span>          </span><span class="annot"><a href="../file:///nix/store/a8ll3m7yfhm0g8j77q9rvjhgdb07zpwk-type-errors-pretty-lib-type-errors-pretty-0.0.1.1-haddock-doc/share/doc/type-errors-pretty/html/src"><span class="hs-operator hs-type">%</span></a></span><span> </span><span class="annot"><span class="hs-string">&quot;&quot;</span></span><span>
</span><span id="line-81"></span><span>          </span><span class="annot"><a href="../file:///nix/store/a8ll3m7yfhm0g8j77q9rvjhgdb07zpwk-type-errors-pretty-lib-type-errors-pretty-0.0.1.1-haddock-doc/share/doc/type-errors-pretty/html/src"><span class="hs-operator hs-type">%</span></a></span><span> </span><span class="annot"><span class="hs-string">&quot;respectively.&quot;</span></span><span>
</span><span id="line-82"></span><span>      </span><span class="hs-special">)</span><span>
</span><span id="line-83"></span><span>
</span><span id="line-84"></span><span class="hs-comment">-- | T5-style layer norm</span><span>
</span><span id="line-85"></span><span class="annot"><a href="Torch.GraduallyTyped.NN.Functional.Normalization.html#layerNormWithoutBias"><span class="hs-identifier hs-type">layerNormWithoutBias</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-86"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679524542"><span class="annot"><a href="#local-6989586621679524542"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679524541"><span class="annot"><a href="#local-6989586621679524541"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679524540"><span class="annot"><a href="#local-6989586621679524540"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679524539"><span class="annot"><a href="#local-6989586621679524539"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679524538"><span class="annot"><a href="#local-6989586621679524538"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679524537"><span class="annot"><a href="#local-6989586621679524537"><span class="hs-identifier hs-type">gradient'</span></a></span></span><span> </span><span id="local-6989586621679524536"><span class="annot"><a href="#local-6989586621679524536"><span class="hs-identifier hs-type">layout'</span></a></span></span><span> </span><span id="local-6989586621679524535"><span class="annot"><a href="#local-6989586621679524535"><span class="hs-identifier hs-type">device'</span></a></span></span><span> </span><span id="local-6989586621679524534"><span class="annot"><a href="#local-6989586621679524534"><span class="hs-identifier hs-type">dataType'</span></a></span></span><span> </span><span id="local-6989586621679524533"><span class="annot"><a href="#local-6989586621679524533"><span class="hs-identifier hs-type">shape'</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-87"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetShape"><span class="hs-identifier hs-type">SGetShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679524538"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetShape"><span class="hs-identifier hs-type">SGetShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679524533"><span class="hs-identifier hs-type">shape'</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-88"></span><span>  </span><span class="hs-comment">-- | weight</span><span>
</span><span id="line-89"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679524542"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679524541"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679524540"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679524539"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679524538"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-90"></span><span>  </span><span class="hs-comment">-- | eps</span><span>
</span><span id="line-91"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-92"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-93"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679524537"><span class="hs-identifier hs-type">gradient'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679524536"><span class="hs-identifier hs-type">layout'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679524535"><span class="hs-identifier hs-type">device'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679524534"><span class="hs-identifier hs-type">dataType'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679524533"><span class="hs-identifier hs-type">shape'</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-94"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-95"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-96"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679524542"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679524537"><span class="hs-identifier hs-type">gradient'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-97"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679524541"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679524536"><span class="hs-identifier hs-type">layout'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-98"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679524540"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679524535"><span class="hs-identifier hs-type">device'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-99"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679524539"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679524534"><span class="hs-identifier hs-type">dataType'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-100"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Functional.Normalization.html#LayerNormWithoutBiasF"><span class="hs-identifier hs-type">LayerNormWithoutBiasF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679524538"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679524533"><span class="hs-identifier hs-type">shape'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-101"></span><span id="layerNormWithoutBias"><span class="annot"><span class="annottext">layerNormWithoutBias :: Tensor gradient layout device dataType shape
-&gt; Double
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; Tensor
     (gradient &lt;|&gt; gradient')
     (layout &lt;+&gt; layout')
     (device &lt;+&gt; device')
     (dataType &lt;+&gt; dataType')
     (LayerNormWithoutBiasF shape shape')
</span><a href="Torch.GraduallyTyped.NN.Functional.Normalization.html#layerNormWithoutBias"><span class="hs-identifier hs-var hs-var">layerNormWithoutBias</span></a></span></span><span> </span><span id="local-6989586621679524532"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679524532"><span class="hs-identifier hs-var">weight</span></a></span></span><span> </span><span id="local-6989586621679524531"><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679524531"><span class="hs-identifier hs-var">eps</span></a></span></span><span> </span><span id="local-6989586621679524530"><span class="annot"><span class="annottext">Tensor gradient' layout' device' dataType' shape'
</span><a href="#local-6989586621679524530"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO
  (Tensor
     (Or (Gradient RequiresGradient) gradient gradient')
     (Unify (Layout LayoutType) layout layout')
     (Unify (Device (DeviceType Nat)) device device')
     (Unify (DataType DType) dataType dataType')
     (LayerNormWithoutBiasF shape shape'))
-&gt; Tensor
     (Or (Gradient RequiresGradient) gradient gradient')
     (Unify (Layout LayoutType) layout layout')
     (Unify (Device (DeviceType Nat)) device device')
     (Unify (DataType DType) dataType dataType')
     (LayerNormWithoutBiasF shape shape')
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO
   (Tensor
      (Or (Gradient RequiresGradient) gradient gradient')
      (Unify (Layout LayoutType) layout layout')
      (Unify (Device (DeviceType Nat)) device device')
      (Unify (DataType DType) dataType dataType')
      (LayerNormWithoutBiasF shape shape'))
 -&gt; Tensor
      (Or (Gradient RequiresGradient) gradient gradient')
      (Unify (Layout LayoutType) layout layout')
      (Unify (Device (DeviceType Nat)) device device')
      (Unify (DataType DType) dataType dataType')
      (LayerNormWithoutBiasF shape shape'))
-&gt; IO
     (Tensor
        (Or (Gradient RequiresGradient) gradient gradient')
        (Unify (Layout LayoutType) layout layout')
        (Unify (Device (DeviceType Nat)) device device')
        (Unify (DataType DType) dataType dataType')
        (LayerNormWithoutBiasF shape shape'))
-&gt; Tensor
     (Or (Gradient RequiresGradient) gradient gradient')
     (Unify (Layout LayoutType) layout layout')
     (Unify (Device (DeviceType Nat)) device device')
     (Unify (DataType DType) dataType dataType')
     (LayerNormWithoutBiasF shape shape')
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-102"></span><span>  </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679524529"><span class="annot"><span class="annottext">weightDims :: [Dim String Integer]
</span><a href="#local-6989586621679524529"><span class="hs-identifier hs-var hs-var">weightDims</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
-&gt; [Dim String Integer]
forall (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType).
SGetShape shape =&gt;
Tensor gradient layout device dataType shape
-&gt; [Dim String Integer]
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#getDims"><span class="hs-identifier hs-var">getDims</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679524532"><span class="hs-identifier hs-var">weight</span></a></span><span>
</span><span id="line-103"></span><span>      </span><span id="local-6989586621679524528"><span class="annot"><span class="annottext">inputDims :: [Dim String Integer]
</span><a href="#local-6989586621679524528"><span class="hs-identifier hs-var hs-var">inputDims</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor gradient' layout' device' dataType' shape'
-&gt; [Dim String Integer]
forall (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType).
SGetShape shape =&gt;
Tensor gradient layout device dataType shape
-&gt; [Dim String Integer]
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#getDims"><span class="hs-identifier hs-var">getDims</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient' layout' device' dataType' shape'
</span><a href="#local-6989586621679524530"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-104"></span><span>  </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679524527"><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679524527"><span class="hs-identifier hs-var">indexes</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">]</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int
forall a b. (Integral a, Num b) =&gt; a -&gt; b
</span><span class="hs-identifier hs-var">fromIntegral</span></span><span> </span><span class="annot"><span class="annottext">(Int -&gt; Int) -&gt; (Int -&gt; Int) -&gt; Int -&gt; Int
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">[Dim String Integer] -&gt; Int
forall (t :: * -&gt; *) a. Foldable t =&gt; t a -&gt; Int
</span><span class="hs-identifier hs-var">length</span></span><span> </span><span class="annot"><span class="annottext">[Dim String Integer]
</span><a href="#local-6989586621679524528"><span class="hs-identifier hs-var">inputDims</span></a></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Int
forall a. Num a =&gt; a -&gt; a -&gt; a
</span><span class="hs-glyph hs-var">-</span></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">(Int -&gt; Int) -&gt; [Int] -&gt; [Int]
forall (f :: * -&gt; *) a b. Functor f =&gt; (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;$&gt;</span></span><span> </span><span class="hs-special">[</span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">1</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">2</span></span><span> </span><span class="hs-glyph">..</span><span> </span><span class="annot"><span class="annottext">[Dim String Integer] -&gt; Int
forall (t :: * -&gt; *) a. Foldable t =&gt; t a -&gt; Int
</span><span class="hs-identifier hs-var">length</span></span><span> </span><span class="annot"><span class="annottext">[Dim String Integer]
</span><a href="#local-6989586621679524529"><span class="hs-identifier hs-var">weightDims</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-105"></span><span>  </span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; ForeignPtr IntArray
 -&gt; ForeignPtr Scalar
 -&gt; ForeignPtr Scalar
 -&gt; CBool
 -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; Tensor gradient layout device dataType shape
-&gt; [Int]
-&gt; Double
-&gt; Double
-&gt; Bool
-&gt; IO
     (Tensor
        (Or (Gradient RequiresGradient) gradient gradient')
        (Unify (Layout LayoutType) layout layout')
        (Unify (Device (DeviceType Nat)) device device')
        (Unify (DataType DType) dataType dataType')
        (LayerNormWithoutBiasF shape shape'))
forall a ca x1 cx1 x2 cx2 x3 cx3 x4 cx4 x5 cx5 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable x3 cx3,
 Castable x4 cx4, Castable x5 cx5, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; cx3 -&gt; cx4 -&gt; cx5 -&gt; IO cy)
-&gt; a -&gt; x1 -&gt; x2 -&gt; x3 -&gt; x4 -&gt; x5 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast6</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Bool
-&gt; ForeignPtr Tensor
-&gt; ForeignPtr Tensor
-&gt; ForeignPtr IntArray
-&gt; ForeignPtr Scalar
-&gt; ForeignPtr Scalar
-&gt; CBool
-&gt; IO (ForeignPtr Tensor)
</span><a href="#local-6989586621679524524"><span class="hs-identifier hs-var">go</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">[Int] -&gt; Bool
forall (t :: * -&gt; *) a. Foldable t =&gt; t a -&gt; Bool
</span><span class="hs-identifier hs-var">null</span></span><span> </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679524527"><span class="hs-identifier hs-var">indexes</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor gradient' layout' device' dataType' shape'
</span><a href="#local-6989586621679524530"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679524532"><span class="hs-identifier hs-var">weight</span></a></span><span> </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679524527"><span class="hs-identifier hs-var">indexes</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679524531"><span class="hs-identifier hs-var">eps</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Double
</span><span class="hs-number">2</span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Bool
</span><span class="hs-identifier hs-var">True</span></span><span>
</span><span id="line-106"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-107"></span><span>    </span><span id="local-6989586621679524524"><span class="annot"><span class="annottext">go :: Bool
-&gt; ForeignPtr Tensor
-&gt; ForeignPtr Tensor
-&gt; ForeignPtr IntArray
-&gt; ForeignPtr Scalar
-&gt; ForeignPtr Scalar
-&gt; CBool
-&gt; IO (ForeignPtr Tensor)
</span><a href="#local-6989586621679524524"><span class="hs-identifier hs-var hs-var">go</span></a></span></span><span> </span><span id="local-6989586621679524522"><span class="annot"><span class="annottext">Bool
</span><a href="#local-6989586621679524522"><span class="hs-identifier hs-var">nullIndexes</span></a></span></span><span> </span><span id="local-6989586621679524521"><span class="annot"><span class="annottext">ForeignPtr Tensor
</span><a href="#local-6989586621679524521"><span class="hs-identifier hs-var">input'</span></a></span></span><span> </span><span id="local-6989586621679524520"><span class="annot"><span class="annottext">ForeignPtr Tensor
</span><a href="#local-6989586621679524520"><span class="hs-identifier hs-var">weight'</span></a></span></span><span> </span><span id="local-6989586621679524519"><span class="annot"><span class="annottext">ForeignPtr IntArray
</span><a href="#local-6989586621679524519"><span class="hs-identifier hs-var">indexes</span></a></span></span><span> </span><span id="local-6989586621679524518"><span class="annot"><span class="annottext">ForeignPtr Scalar
</span><a href="#local-6989586621679524518"><span class="hs-identifier hs-var">eps'</span></a></span></span><span> </span><span id="local-6989586621679524517"><span class="annot"><span class="annottext">ForeignPtr Scalar
</span><a href="#local-6989586621679524517"><span class="hs-identifier hs-var">exponent'</span></a></span></span><span> </span><span id="local-6989586621679524516"><span class="annot"><span class="annottext">CBool
</span><a href="#local-6989586621679524516"><span class="hs-identifier hs-var">keepDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-108"></span><span>      </span><span id="local-6989586621679524515"><span class="annot"><span class="annottext">ForeignPtr Tensor
</span><a href="#local-6989586621679524515"><span class="hs-identifier hs-var">squaredInput</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr Scalar -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.pow_ts</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
</span><a href="#local-6989586621679524521"><span class="hs-identifier hs-var">input'</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Scalar
</span><a href="#local-6989586621679524517"><span class="hs-identifier hs-var">exponent'</span></a></span><span>
</span><span id="line-109"></span><span>      </span><span id="local-6989586621679524513"><span class="annot"><span class="annottext">ForeignPtr Tensor
</span><a href="#local-6989586621679524513"><span class="hs-identifier hs-var">variance</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span>
</span><span id="line-110"></span><span>        </span><span class="hs-keyword">if</span><span> </span><span class="annot"><span class="annottext">Bool
</span><a href="#local-6989586621679524522"><span class="hs-identifier hs-var">nullIndexes</span></a></span><span>
</span><span id="line-111"></span><span>          </span><span class="hs-keyword">then</span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
</span><a href="#local-6989586621679524515"><span class="hs-identifier hs-var">squaredInput</span></a></span><span>
</span><span id="line-112"></span><span>          </span><span class="hs-keyword">else</span><span>
</span><span id="line-113"></span><span>            </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; ForeignPtr IntArray -&gt; CBool -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.mean_tlb</span></a></span><span>
</span><span id="line-114"></span><span>              </span><span class="annot"><span class="annottext">ForeignPtr Tensor
</span><a href="#local-6989586621679524515"><span class="hs-identifier hs-var">squaredInput</span></a></span><span>
</span><span id="line-115"></span><span>              </span><span class="annot"><span class="annottext">ForeignPtr IntArray
</span><a href="#local-6989586621679524519"><span class="hs-identifier hs-var">indexes</span></a></span><span>
</span><span id="line-116"></span><span>              </span><span class="annot"><span class="annottext">CBool
</span><a href="#local-6989586621679524516"><span class="hs-identifier hs-var">keepDim</span></a></span><span>
</span><span id="line-117"></span><span>      </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr Scalar -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.add_ts</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
</span><a href="#local-6989586621679524513"><span class="hs-identifier hs-var">variance</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Scalar
</span><a href="#local-6989586621679524518"><span class="hs-identifier hs-var">eps'</span></a></span><span>
</span><span id="line-118"></span><span>        </span><span class="annot"><span class="annottext">IO (ForeignPtr Tensor)
-&gt; (ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; IO (ForeignPtr Tensor)
forall (m :: * -&gt; *) a b. Monad m =&gt; m a -&gt; (a -&gt; m b) -&gt; m b
</span><span class="hs-operator hs-var">&gt;&gt;=</span></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.rsqrt_t</span></a></span><span>
</span><span id="line-119"></span><span>        </span><span class="annot"><span class="annottext">IO (ForeignPtr Tensor)
-&gt; (ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; IO (ForeignPtr Tensor)
forall (m :: * -&gt; *) a b. Monad m =&gt; m a -&gt; (a -&gt; m b) -&gt; m b
</span><span class="hs-operator hs-var">&gt;&gt;=</span></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.mul_tt</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
</span><a href="#local-6989586621679524521"><span class="hs-identifier hs-var">input'</span></a></span><span>
</span><span id="line-120"></span><span>        </span><span class="annot"><span class="annottext">IO (ForeignPtr Tensor)
-&gt; (ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; IO (ForeignPtr Tensor)
forall (m :: * -&gt; *) a b. Monad m =&gt; m a -&gt; (a -&gt; m b) -&gt; m b
</span><span class="hs-operator hs-var">&gt;&gt;=</span></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.mul_tt</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
</span><a href="#local-6989586621679524520"><span class="hs-identifier hs-var">weight'</span></a></span><span>
</span><span id="line-121"></span></pre></body></html>