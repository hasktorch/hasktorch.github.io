<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><link rel="stylesheet" type="text/css" href="style.css" /><script type="text/javascript" src="highlight.js"></script></head><body><pre><span class="hs-pragma">{-# LANGUAGE DataKinds #-}</span><span>
</span><span id="line-2"></span><span class="hs-pragma">{-# LANGUAGE FlexibleInstances #-}</span><span>
</span><span id="line-3"></span><span class="hs-pragma">{-# LANGUAGE GADTs #-}</span><span>
</span><span id="line-4"></span><span class="hs-pragma">{-# LANGUAGE LambdaCase #-}</span><span>
</span><span id="line-5"></span><span class="hs-pragma">{-# LANGUAGE MultiParamTypeClasses #-}</span><span>
</span><span id="line-6"></span><span class="hs-pragma">{-# LANGUAGE OverloadedStrings #-}</span><span>
</span><span id="line-7"></span><span class="hs-pragma">{-# LANGUAGE PatternSynonyms #-}</span><span>
</span><span id="line-8"></span><span class="hs-pragma">{-# LANGUAGE RecordWildCards #-}</span><span>
</span><span id="line-9"></span><span class="hs-pragma">{-# LANGUAGE ScopedTypeVariables #-}</span><span>
</span><span id="line-10"></span><span class="hs-pragma">{-# LANGUAGE TypeApplications #-}</span><span>
</span><span id="line-11"></span><span class="hs-pragma">{-# LANGUAGE TypeFamilies #-}</span><span>
</span><span id="line-12"></span><span class="hs-pragma">{-# LANGUAGE TypeOperators #-}</span><span>
</span><span id="line-13"></span><span class="hs-pragma">{-# LANGUAGE UndecidableInstances #-}</span><span>
</span><span id="line-14"></span><span>
</span><span id="line-15"></span><span class="hs-keyword">module</span><span> </span><span class="hs-identifier">Torch.GraduallyTyped.NN.Transformer.GLMHead</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-16"></span><span>
</span><span id="line-17"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier">Control.Monad.Indexed</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier">IxPointed</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator">(&gt;&gt;&gt;=)</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-18"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier">Control.Monad.Indexed.State</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier">IxStateT</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-19"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier">Control.Monad.Indexed.Trans</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier">IxMonadTrans</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier">ilift</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-20"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier">Data.Functor.Indexed</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator">(&lt;&lt;$&gt;&gt;)</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator">(&lt;&lt;*&gt;&gt;)</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-21"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">Data.Kind</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier">Type</span></span><span class="hs-special">)</span><span>
</span><span id="line-22"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">Data.Singletons</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">SingKind</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">fromSing</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-23"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">Data.Singletons.Prelude.List</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">SList</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">SNil</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-24"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">GHC.TypeLits</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier">Nat</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier">Symbol</span></span><span class="hs-special">)</span><span>
</span><span id="line-25"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html"><span class="hs-identifier">Torch.GraduallyTyped.DType</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier">DType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier">DataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier">SDataType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-26"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html"><span class="hs-identifier">Torch.GraduallyTyped.Device</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier">Device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#DeviceType"><span class="hs-identifier">DeviceType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#SDevice"><span class="hs-identifier">SDevice</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-27"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html"><span class="hs-identifier">Torch.GraduallyTyped.Layout</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier">Layout</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#LayoutType"><span class="hs-identifier">LayoutType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#SLayout"><span class="hs-identifier">SLayout</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#SLayoutType"><span class="hs-identifier">SLayoutType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-28"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Activation.html"><span class="hs-identifier">Torch.GraduallyTyped.NN.Activation</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Activation.html#Gelu"><span class="hs-identifier">Gelu</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-29"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html"><span class="hs-identifier">Torch.GraduallyTyped.NN.Class</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier">HasForward</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier">HasInitialize</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasStateDict"><span class="hs-identifier">HasStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier">ModelSpec</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier">NamedModel</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-30"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Linear.html"><span class="hs-identifier">Torch.GraduallyTyped.NN.Linear</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Linear.html#GLinearF"><span class="hs-identifier">GLinearF</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Linear.html#linearSpec"><span class="hs-identifier">linearSpec</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-31"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Normalization.html"><span class="hs-identifier">Torch.GraduallyTyped.NN.Normalization</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Normalization.html#LayerNorm"><span class="hs-identifier">LayerNorm</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Normalization.html#LayerNormSpec"><span class="hs-identifier">LayerNormSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-32"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html"><span class="hs-identifier">Torch.GraduallyTyped.NN.Transformer.Type</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#STransformerStyle"><span class="hs-identifier">STransformerStyle</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerStyle"><span class="hs-identifier">TransformerStyle</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-33"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Type.html"><span class="hs-identifier">Torch.GraduallyTyped.NN.Type</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Type.html#HasBias"><span class="hs-identifier">HasBias</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Type.html#SHasBias"><span class="hs-identifier">SHasBias</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-34"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html"><span class="hs-identifier">Torch.GraduallyTyped.Prelude</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#forgetIsChecked"><span class="hs-identifier">forgetIsChecked</span></a></span><span class="hs-special">,</span><span> </span><span class="hs-keyword">pattern</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#%3A%7C%3A"><span class="hs-operator">(:|:)</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-35"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html"><span class="hs-identifier">Torch.GraduallyTyped.RequiresGradient</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier">Gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#RequiresGradient"><span class="hs-identifier">RequiresGradient</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier">SGradient</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-36"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html"><span class="hs-identifier">Torch.GraduallyTyped.Shape.Class</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#BroadcastShapesF"><span class="hs-identifier">BroadcastShapesF</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-37"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html"><span class="hs-identifier">Torch.GraduallyTyped.Shape.Type</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier">Name</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier">SDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier">SName</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier">SShape</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier">SSize</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier">Shape</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier">Size</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="hs-keyword">pattern</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator">(:&amp;:)</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-38"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Creation.html"><span class="hs-identifier">Torch.GraduallyTyped.Tensor.Creation</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Creation.html#sZeros"><span class="hs-identifier">sZeros</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-39"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html"><span class="hs-identifier">Torch.GraduallyTyped.Tensor.MathOperations.Pointwise</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#add"><span class="hs-identifier">add</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#mulScalar"><span class="hs-identifier">mulScalar</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-40"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html"><span class="hs-identifier">Torch.GraduallyTyped.Tensor.Type</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier">Tensor</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorSpec"><span class="hs-identifier">TensorSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-41"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html"><span class="hs-identifier">Torch.GraduallyTyped.Unify</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-keyword">type</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator">(&lt;+&gt;)</span></a></span><span class="hs-special">,</span><span> </span><span class="hs-keyword">type</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator">(&lt;|&gt;)</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-42"></span><span>
</span><span id="line-43"></span><span class="hs-comment">-- | A data type that represents whether or not the language modelling head</span><span>
</span><span id="line-44"></span><span class="hs-comment">-- has a scaled decoder output.</span><span>
</span><span id="line-45"></span><span class="hs-keyword">data</span><span> </span><span id="LMHeadHasScaling"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadHasScaling"><span class="hs-identifier hs-var">LMHeadHasScaling</span></a></span></span><span>
</span><span id="line-46"></span><span>  </span><span class="hs-glyph">=</span><span> </span><span id="LMHeadWithScaling"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadWithScaling"><span class="hs-identifier hs-var">LMHeadWithScaling</span></a></span></span><span>
</span><span id="line-47"></span><span>  </span><span class="hs-glyph">|</span><span> </span><span id="LMHeadWithoutScaling"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadWithoutScaling"><span class="hs-identifier hs-var">LMHeadWithoutScaling</span></a></span></span><span>
</span><span id="line-48"></span><span>
</span><span id="line-49"></span><span class="hs-comment">-- | Generic language modelling head for transformer encoders and decoders.</span><span>
</span><span id="line-50"></span><span class="hs-comment">--</span><span>
</span><span id="line-51"></span><span class="hs-comment">-- - @inputEmbedDim@ is the dimension of the input embedding.</span><span>
</span><span id="line-52"></span><span class="hs-comment">-- - @dense@ is a dense layer.</span><span>
</span><span id="line-53"></span><span class="hs-comment">-- - @activation@ is an activation function.</span><span>
</span><span id="line-54"></span><span class="hs-comment">-- - @layerNorm@ is a layer normalization layer.</span><span>
</span><span id="line-55"></span><span class="hs-comment">-- - @decoder@ is a decoder layer.</span><span>
</span><span id="line-56"></span><span class="hs-comment">-- - @bias@ is a bias layer.</span><span>
</span><span id="line-57"></span><span class="hs-keyword">data</span><span>
</span><span id="line-58"></span><span>  </span><span id="GLMHead"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#GLMHead"><span class="hs-identifier hs-var">GLMHead</span></a></span></span><span>
</span><span id="line-59"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679652062"><span class="annot"><a href="#local-6989586621679652062"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-60"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679652061"><span class="annot"><a href="#local-6989586621679652061"><span class="hs-identifier hs-type">dense</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span class="hs-special">)</span><span>
</span><span id="line-61"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679652060"><span class="annot"><a href="#local-6989586621679652060"><span class="hs-identifier hs-type">activation</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span class="hs-special">)</span><span>
</span><span id="line-62"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679652059"><span class="annot"><a href="#local-6989586621679652059"><span class="hs-identifier hs-type">layerNorm</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span class="hs-special">)</span><span>
</span><span id="line-63"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679652058"><span class="annot"><a href="#local-6989586621679652058"><span class="hs-identifier hs-type">decoder</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span class="hs-special">)</span><span>
</span><span id="line-64"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679652057"><span class="annot"><a href="#local-6989586621679652057"><span class="hs-identifier hs-type">bias</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span class="hs-special">)</span><span>
</span><span id="line-65"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-66"></span><span>  </span><span id="GLMHead"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#GLMHead"><span class="hs-identifier hs-var">GLMHead</span></a></span></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-67"></span><span>    </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679652346"><span class="annot"><a href="#local-6989586621679652346"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679652345"><span class="annot"><a href="#local-6989586621679652345"><span class="hs-identifier hs-type">dense</span></a></span></span><span> </span><span id="local-6989586621679652344"><span class="annot"><a href="#local-6989586621679652344"><span class="hs-identifier hs-type">activation</span></a></span></span><span> </span><span id="local-6989586621679652343"><span class="annot"><a href="#local-6989586621679652343"><span class="hs-identifier hs-type">layerNorm</span></a></span></span><span> </span><span id="local-6989586621679652342"><span class="annot"><a href="#local-6989586621679652342"><span class="hs-identifier hs-type">decoder</span></a></span></span><span> </span><span id="local-6989586621679652341"><span class="annot"><a href="#local-6989586621679652341"><span class="hs-identifier hs-type">bias</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-68"></span><span>    </span><span class="hs-special">{</span><span> </span><span class="hs-comment">-- | the dimension of the input embedding.</span><span>
</span><span id="line-69"></span><span>      </span><span id="lmHeadInputEmbedDim"><span class="annot"><span class="annottext">GLMHead inputEmbedDim dense activation layerNorm decoder bias
-&gt; SDim inputEmbedDim
</span><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#lmHeadInputEmbedDim"><span class="hs-identifier hs-var hs-var">lmHeadInputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679652346"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-70"></span><span>      </span><span class="hs-comment">-- | the dense layer.</span><span>
</span><span id="line-71"></span><span>      </span><span id="lmHeadDense"><span class="annot"><span class="annottext">GLMHead inputEmbedDim dense activation layerNorm decoder bias
-&gt; dense
</span><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#lmHeadDense"><span class="hs-identifier hs-var hs-var">lmHeadDense</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679652345"><span class="hs-identifier hs-type">dense</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-72"></span><span>      </span><span class="hs-comment">-- | the activation function.</span><span>
</span><span id="line-73"></span><span>      </span><span id="lmHeadActivation"><span class="annot"><span class="annottext">GLMHead inputEmbedDim dense activation layerNorm decoder bias
-&gt; activation
</span><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#lmHeadActivation"><span class="hs-identifier hs-var hs-var">lmHeadActivation</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679652344"><span class="hs-identifier hs-type">activation</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-74"></span><span>      </span><span class="hs-comment">-- | the layer normalization layer.</span><span>
</span><span id="line-75"></span><span>      </span><span id="lmHeadLayerNorm"><span class="annot"><span class="annottext">GLMHead inputEmbedDim dense activation layerNorm decoder bias
-&gt; layerNorm
</span><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#lmHeadLayerNorm"><span class="hs-identifier hs-var hs-var">lmHeadLayerNorm</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679652343"><span class="hs-identifier hs-type">layerNorm</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-76"></span><span>      </span><span class="hs-comment">-- | the decoder layer.</span><span>
</span><span id="line-77"></span><span>      </span><span id="lmHeadDecoder"><span class="annot"><span class="annottext">GLMHead inputEmbedDim dense activation layerNorm decoder bias
-&gt; decoder
</span><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#lmHeadDecoder"><span class="hs-identifier hs-var hs-var">lmHeadDecoder</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679652342"><span class="hs-identifier hs-type">decoder</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-78"></span><span>      </span><span class="hs-comment">-- | the bias layer.</span><span>
</span><span id="line-79"></span><span>      </span><span id="lmHeadBias"><span class="annot"><span class="annottext">GLMHead inputEmbedDim dense activation layerNorm decoder bias
-&gt; bias
</span><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#lmHeadBias"><span class="hs-identifier hs-var hs-var">lmHeadBias</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679652341"><span class="hs-identifier hs-type">bias</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-80"></span><span>      </span><span class="hs-comment">-- | whether or not the head has a scaled decoder output.</span><span>
</span><span id="line-81"></span><span>      </span><span id="lmHeadHasScaling"><span class="annot"><span class="annottext">GLMHead inputEmbedDim dense activation layerNorm decoder bias
-&gt; LMHeadHasScaling
</span><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#lmHeadHasScaling"><span class="hs-identifier hs-var hs-var">lmHeadHasScaling</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadHasScaling"><span class="hs-identifier hs-type">LMHeadHasScaling</span></a></span><span>
</span><span id="line-82"></span><span>    </span><span class="hs-special">}</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-83"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#GLMHead"><span class="hs-identifier hs-type">GLMHead</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679652346"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679652345"><span class="hs-identifier hs-type">dense</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679652344"><span class="hs-identifier hs-type">activation</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679652343"><span class="hs-identifier hs-type">layerNorm</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679652342"><span class="hs-identifier hs-type">decoder</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679652341"><span class="hs-identifier hs-type">bias</span></a></span><span>
</span><span id="line-84"></span><span>
</span><span id="line-85"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">instance</span><span>
</span><span id="line-86"></span><span>  </span><span id="ModelSpec"><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier hs-var">ModelSpec</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#GLMHead"><span class="hs-identifier hs-type">GLMHead</span></a></span><span> </span><span id="local-6989586621679652048"><span class="annot"><a href="#local-6989586621679652048"><span class="hs-identifier hs-type hs-type">inputEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679652047"><span class="annot"><a href="#local-6989586621679652047"><span class="hs-identifier hs-type hs-type">dense</span></a></span></span><span> </span><span id="local-6989586621679652046"><span class="annot"><a href="#local-6989586621679652046"><span class="hs-identifier hs-type hs-type">activation</span></a></span></span><span> </span><span id="local-6989586621679652045"><span class="annot"><a href="#local-6989586621679652045"><span class="hs-identifier hs-type hs-type">layerNorm</span></a></span></span><span> </span><span id="local-6989586621679652044"><span class="annot"><a href="#local-6989586621679652044"><span class="hs-identifier hs-type hs-type">decoder</span></a></span></span><span> </span><span id="local-6989586621679652043"><span class="annot"><a href="#local-6989586621679652043"><span class="hs-identifier hs-type hs-type">bias</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-87"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#GLMHead"><span class="hs-identifier hs-type">GLMHead</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679652048"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier hs-type">ModelSpec</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679652047"><span class="hs-identifier hs-type">dense</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier hs-type">ModelSpec</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679652046"><span class="hs-identifier hs-type">activation</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier hs-type">ModelSpec</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679652045"><span class="hs-identifier hs-type">layerNorm</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier hs-type">ModelSpec</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679652044"><span class="hs-identifier hs-type">decoder</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier hs-type">ModelSpec</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679652043"><span class="hs-identifier hs-type">bias</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-88"></span><span>
</span><span id="line-89"></span><span class="hs-comment">-- | Generic data type for biasing the language model head.</span><span>
</span><span id="line-90"></span><span class="hs-keyword">data</span><span> </span><span id="GBias"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#GBias"><span class="hs-identifier hs-var">GBias</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679652042"><span class="annot"><a href="#local-6989586621679652042"><span class="hs-identifier hs-type">bias</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span class="hs-special">)</span><span> </span><span class="hs-keyword">where</span><span> </span><span id="GBias"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#GBias"><span class="hs-identifier hs-var">GBias</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679652350"><span class="annot"><a href="#local-6989586621679652350"><span class="hs-identifier hs-type">bias</span></a></span></span><span class="hs-operator">.</span><span> </span><span class="annot"><a href="#local-6989586621679652350"><span class="hs-identifier hs-type">bias</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#GBias"><span class="hs-identifier hs-type">GBias</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679652350"><span class="hs-identifier hs-type">bias</span></a></span><span>
</span><span id="line-91"></span><span>
</span><span id="line-92"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">instance</span><span> </span><span id="ModelSpec"><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier hs-var">ModelSpec</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#GBias"><span class="hs-identifier hs-type">GBias</span></a></span><span> </span><span id="local-6989586621679652040"><span class="annot"><a href="#local-6989586621679652040"><span class="hs-identifier hs-type hs-type">bias</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#GBias"><span class="hs-identifier hs-type">GBias</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier hs-type">ModelSpec</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679652040"><span class="hs-identifier hs-type">bias</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-93"></span><span>
</span><span id="line-94"></span><span class="hs-comment">-- | Specifies the dense layer of the language model head.</span><span>
</span><span id="line-95"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span>
</span><span id="line-96"></span><span>  </span><span id="LMHeadDenseF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadDenseF"><span class="hs-identifier hs-var">LMHeadDenseF</span></a></span></span><span>
</span><span id="line-97"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679652039"><span class="annot"><a href="#local-6989586621679652039"><span class="hs-identifier hs-type">style</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerStyle"><span class="hs-identifier hs-type">TransformerStyle</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-98"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679652038"><span class="annot"><a href="#local-6989586621679652038"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#RequiresGradient"><span class="hs-identifier hs-type">RequiresGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-99"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679652037"><span class="annot"><a href="#local-6989586621679652037"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier hs-type">Device</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#DeviceType"><span class="hs-identifier hs-type">DeviceType</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-100"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679652036"><span class="annot"><a href="#local-6989586621679652036"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier hs-type">DType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-101"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679652035"><span class="annot"><a href="#local-6989586621679652035"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-102"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span>
</span><span id="line-103"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-104"></span><span>  </span><span id="LMHeadDenseF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadDenseF"><span class="hs-identifier hs-var">LMHeadDenseF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#T5"><span class="hs-identifier hs-type">T5</span></a></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-105"></span><span>    </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-106"></span><span>  </span><span id="LMHeadDenseF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadDenseF"><span class="hs-identifier hs-var">LMHeadDenseF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ByT5"><span class="hs-identifier hs-type">ByT5</span></a></span><span> </span><span id="local-6989586621679652032"><span class="annot"><a href="#local-6989586621679652032"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679652031"><span class="annot"><a href="#local-6989586621679652031"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679652030"><span class="annot"><a href="#local-6989586621679652030"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679652029"><span class="annot"><a href="#local-6989586621679652029"><span class="hs-identifier hs-type hs-type">inputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-107"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadDenseF"><span class="hs-identifier hs-type">LMHeadDenseF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#T5"><span class="hs-identifier hs-type">T5</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679652032"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679652031"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679652030"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679652029"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span>
</span><span id="line-108"></span><span>  </span><span id="LMHeadDenseF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadDenseF"><span class="hs-identifier hs-var">LMHeadDenseF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-109"></span><span>    </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-110"></span><span>  </span><span id="LMHeadDenseF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadDenseF"><span class="hs-identifier hs-var">LMHeadDenseF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MBART"><span class="hs-identifier hs-type">MBART</span></a></span><span> </span><span id="local-6989586621679652026"><span class="annot"><a href="#local-6989586621679652026"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679652025"><span class="annot"><a href="#local-6989586621679652025"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679652024"><span class="annot"><a href="#local-6989586621679652024"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679652023"><span class="annot"><a href="#local-6989586621679652023"><span class="hs-identifier hs-type hs-type">inputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-111"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadDenseF"><span class="hs-identifier hs-type">LMHeadDenseF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679652026"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679652025"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679652024"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679652023"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span>
</span><span id="line-112"></span><span>  </span><span id="LMHeadDenseF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadDenseF"><span class="hs-identifier hs-var">LMHeadDenseF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#Pegasus"><span class="hs-identifier hs-type">Pegasus</span></a></span><span> </span><span id="local-6989586621679652021"><span class="annot"><a href="#local-6989586621679652021"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679652020"><span class="annot"><a href="#local-6989586621679652020"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679652019"><span class="annot"><a href="#local-6989586621679652019"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679652018"><span class="annot"><a href="#local-6989586621679652018"><span class="hs-identifier hs-type hs-type">inputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-113"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadDenseF"><span class="hs-identifier hs-type">LMHeadDenseF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679652021"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679652020"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679652019"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679652018"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span>
</span><span id="line-114"></span><span>  </span><span id="LMHeadDenseF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadDenseF"><span class="hs-identifier hs-var">LMHeadDenseF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BERT"><span class="hs-identifier hs-type">BERT</span></a></span><span> </span><span id="local-6989586621679652016"><span class="annot"><a href="#local-6989586621679652016"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679652015"><span class="annot"><a href="#local-6989586621679652015"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679652014"><span class="annot"><a href="#local-6989586621679652014"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679652013"><span class="annot"><a href="#local-6989586621679652013"><span class="hs-identifier hs-type hs-type">inputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-115"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-type">NamedModel</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Linear.html#GLinearF"><span class="hs-identifier hs-type">GLinearF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Type.html#WithBias"><span class="hs-identifier hs-type">WithBias</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679652016"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679652015"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679652014"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679652013"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679652013"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-116"></span><span>  </span><span id="LMHeadDenseF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadDenseF"><span class="hs-identifier hs-var">LMHeadDenseF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#RoBERTa"><span class="hs-identifier hs-type">RoBERTa</span></a></span><span> </span><span id="local-6989586621679652011"><span class="annot"><a href="#local-6989586621679652011"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679652010"><span class="annot"><a href="#local-6989586621679652010"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679652009"><span class="annot"><a href="#local-6989586621679652009"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679652008"><span class="annot"><a href="#local-6989586621679652008"><span class="hs-identifier hs-type hs-type">inputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-117"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadDenseF"><span class="hs-identifier hs-type">LMHeadDenseF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BERT"><span class="hs-identifier hs-type">BERT</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679652011"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679652010"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679652009"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679652008"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span>
</span><span id="line-118"></span><span>
</span><span id="line-119"></span><span class="hs-comment">-- | Specifies the activation function of the language model head.</span><span>
</span><span id="line-120"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span>
</span><span id="line-121"></span><span>  </span><span id="LMHeadActivationF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadActivationF"><span class="hs-identifier hs-var">LMHeadActivationF</span></a></span></span><span>
</span><span id="line-122"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679652007"><span class="annot"><a href="#local-6989586621679652007"><span class="hs-identifier hs-type">style</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerStyle"><span class="hs-identifier hs-type">TransformerStyle</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-123"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span>
</span><span id="line-124"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-125"></span><span>  </span><span id="LMHeadActivationF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadActivationF"><span class="hs-identifier hs-var">LMHeadActivationF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#T5"><span class="hs-identifier hs-type">T5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-126"></span><span>  </span><span id="LMHeadActivationF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadActivationF"><span class="hs-identifier hs-var">LMHeadActivationF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ByT5"><span class="hs-identifier hs-type">ByT5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadActivationF"><span class="hs-identifier hs-type">LMHeadActivationF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#T5"><span class="hs-identifier hs-type">T5</span></a></span><span>
</span><span id="line-127"></span><span>  </span><span id="LMHeadActivationF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadActivationF"><span class="hs-identifier hs-var">LMHeadActivationF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-128"></span><span>  </span><span id="LMHeadActivationF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadActivationF"><span class="hs-identifier hs-var">LMHeadActivationF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MBART"><span class="hs-identifier hs-type">MBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadActivationF"><span class="hs-identifier hs-type">LMHeadActivationF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span>
</span><span id="line-129"></span><span>  </span><span id="LMHeadActivationF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadActivationF"><span class="hs-identifier hs-var">LMHeadActivationF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#Pegasus"><span class="hs-identifier hs-type">Pegasus</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadActivationF"><span class="hs-identifier hs-type">LMHeadActivationF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span>
</span><span id="line-130"></span><span>  </span><span id="LMHeadActivationF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadActivationF"><span class="hs-identifier hs-var">LMHeadActivationF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BERT"><span class="hs-identifier hs-type">BERT</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Activation.html#Gelu"><span class="hs-identifier hs-type">Gelu</span></a></span><span>
</span><span id="line-131"></span><span>  </span><span id="LMHeadActivationF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadActivationF"><span class="hs-identifier hs-var">LMHeadActivationF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#RoBERTa"><span class="hs-identifier hs-type">RoBERTa</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadActivationF"><span class="hs-identifier hs-type">LMHeadActivationF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BERT"><span class="hs-identifier hs-type">BERT</span></a></span><span>
</span><span id="line-132"></span><span>
</span><span id="line-133"></span><span class="hs-comment">-- | Specifies the layer normalization layer of the language model head.</span><span>
</span><span id="line-134"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span>
</span><span id="line-135"></span><span>  </span><span id="LMHeadLayerNormF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadLayerNormF"><span class="hs-identifier hs-var">LMHeadLayerNormF</span></a></span></span><span>
</span><span id="line-136"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679652006"><span class="annot"><a href="#local-6989586621679652006"><span class="hs-identifier hs-type">style</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerStyle"><span class="hs-identifier hs-type">TransformerStyle</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-137"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679652005"><span class="annot"><a href="#local-6989586621679652005"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#RequiresGradient"><span class="hs-identifier hs-type">RequiresGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-138"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679652004"><span class="annot"><a href="#local-6989586621679652004"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier hs-type">Device</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#DeviceType"><span class="hs-identifier hs-type">DeviceType</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-139"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679652003"><span class="annot"><a href="#local-6989586621679652003"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier hs-type">DType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-140"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679652002"><span class="annot"><a href="#local-6989586621679652002"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-141"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span>
</span><span id="line-142"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-143"></span><span>  </span><span id="LMHeadLayerNormF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadLayerNormF"><span class="hs-identifier hs-var">LMHeadLayerNormF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#T5"><span class="hs-identifier hs-type">T5</span></a></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-144"></span><span>  </span><span id="LMHeadLayerNormF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadLayerNormF"><span class="hs-identifier hs-var">LMHeadLayerNormF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ByT5"><span class="hs-identifier hs-type">ByT5</span></a></span><span> </span><span id="local-6989586621679652001"><span class="annot"><a href="#local-6989586621679652001"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679652000"><span class="annot"><a href="#local-6989586621679652000"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679651999"><span class="annot"><a href="#local-6989586621679651999"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679651998"><span class="annot"><a href="#local-6989586621679651998"><span class="hs-identifier hs-type hs-type">inputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-145"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadLayerNormF"><span class="hs-identifier hs-type">LMHeadLayerNormF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#T5"><span class="hs-identifier hs-type">T5</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679652001"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679652000"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651999"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651998"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span>
</span><span id="line-146"></span><span>  </span><span id="LMHeadLayerNormF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadLayerNormF"><span class="hs-identifier hs-var">LMHeadLayerNormF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-147"></span><span>  </span><span id="LMHeadLayerNormF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadLayerNormF"><span class="hs-identifier hs-var">LMHeadLayerNormF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MBART"><span class="hs-identifier hs-type">MBART</span></a></span><span> </span><span id="local-6989586621679651997"><span class="annot"><a href="#local-6989586621679651997"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679651996"><span class="annot"><a href="#local-6989586621679651996"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679651995"><span class="annot"><a href="#local-6989586621679651995"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679651994"><span class="annot"><a href="#local-6989586621679651994"><span class="hs-identifier hs-type hs-type">inputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-148"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadLayerNormF"><span class="hs-identifier hs-type">LMHeadLayerNormF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651997"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651996"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651995"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651994"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span>
</span><span id="line-149"></span><span>  </span><span id="LMHeadLayerNormF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadLayerNormF"><span class="hs-identifier hs-var">LMHeadLayerNormF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#Pegasus"><span class="hs-identifier hs-type">Pegasus</span></a></span><span> </span><span id="local-6989586621679651993"><span class="annot"><a href="#local-6989586621679651993"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679651992"><span class="annot"><a href="#local-6989586621679651992"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679651991"><span class="annot"><a href="#local-6989586621679651991"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679651990"><span class="annot"><a href="#local-6989586621679651990"><span class="hs-identifier hs-type hs-type">inputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-150"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadLayerNormF"><span class="hs-identifier hs-type">LMHeadLayerNormF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651993"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651992"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651991"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651990"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span>
</span><span id="line-151"></span><span>  </span><span id="LMHeadLayerNormF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadLayerNormF"><span class="hs-identifier hs-var">LMHeadLayerNormF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BERT"><span class="hs-identifier hs-type">BERT</span></a></span><span> </span><span id="local-6989586621679651989"><span class="annot"><a href="#local-6989586621679651989"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679651988"><span class="annot"><a href="#local-6989586621679651988"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679651987"><span class="annot"><a href="#local-6989586621679651987"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679651986"><span class="annot"><a href="#local-6989586621679651986"><span class="hs-identifier hs-type hs-type">inputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-152"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-type">NamedModel</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Normalization.html#LayerNorm"><span class="hs-identifier hs-type">LayerNorm</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Type.html#WithBias"><span class="hs-identifier hs-type">WithBias</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651989"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651988"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651987"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679651986"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-153"></span><span>  </span><span id="LMHeadLayerNormF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadLayerNormF"><span class="hs-identifier hs-var">LMHeadLayerNormF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#RoBERTa"><span class="hs-identifier hs-type">RoBERTa</span></a></span><span> </span><span id="local-6989586621679651985"><span class="annot"><a href="#local-6989586621679651985"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679651984"><span class="annot"><a href="#local-6989586621679651984"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679651983"><span class="annot"><a href="#local-6989586621679651983"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679651982"><span class="annot"><a href="#local-6989586621679651982"><span class="hs-identifier hs-type hs-type">inputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-154"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadLayerNormF"><span class="hs-identifier hs-type">LMHeadLayerNormF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BERT"><span class="hs-identifier hs-type">BERT</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651985"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651984"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651983"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651982"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span>
</span><span id="line-155"></span><span>
</span><span id="line-156"></span><span class="hs-comment">-- | Specifies the decoder layer of the language model head.</span><span>
</span><span id="line-157"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span>
</span><span id="line-158"></span><span>  </span><span id="LMHeadDecoderF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadDecoderF"><span class="hs-identifier hs-var">LMHeadDecoderF</span></a></span></span><span>
</span><span id="line-159"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679651981"><span class="annot"><a href="#local-6989586621679651981"><span class="hs-identifier hs-type">style</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerStyle"><span class="hs-identifier hs-type">TransformerStyle</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-160"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679651980"><span class="annot"><a href="#local-6989586621679651980"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#RequiresGradient"><span class="hs-identifier hs-type">RequiresGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-161"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679651979"><span class="annot"><a href="#local-6989586621679651979"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier hs-type">Device</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#DeviceType"><span class="hs-identifier hs-type">DeviceType</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-162"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679651978"><span class="annot"><a href="#local-6989586621679651978"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier hs-type">DType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-163"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679651977"><span class="annot"><a href="#local-6989586621679651977"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-164"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679651976"><span class="annot"><a href="#local-6989586621679651976"><span class="hs-identifier hs-type">vocabDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-165"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span>
</span><span id="line-166"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-167"></span><span>  </span><span id="LMHeadDecoderF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadDecoderF"><span class="hs-identifier hs-var">LMHeadDecoderF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#T5"><span class="hs-identifier hs-type">T5</span></a></span><span> </span><span id="local-6989586621679651975"><span class="annot"><a href="#local-6989586621679651975"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679651974"><span class="annot"><a href="#local-6989586621679651974"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679651973"><span class="annot"><a href="#local-6989586621679651973"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679651972"><span class="annot"><a href="#local-6989586621679651972"><span class="hs-identifier hs-type hs-type">inputEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679651971"><span class="annot"><a href="#local-6989586621679651971"><span class="hs-identifier hs-type hs-type">vocabDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-168"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-type">NamedModel</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Linear.html#GLinearF"><span class="hs-identifier hs-type">GLinearF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Type.html#WithoutBias"><span class="hs-identifier hs-type">WithoutBias</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651975"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651974"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651973"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651972"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651971"><span class="hs-identifier hs-type">vocabDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-169"></span><span>  </span><span id="LMHeadDecoderF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadDecoderF"><span class="hs-identifier hs-var">LMHeadDecoderF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ByT5"><span class="hs-identifier hs-type">ByT5</span></a></span><span> </span><span id="local-6989586621679651970"><span class="annot"><a href="#local-6989586621679651970"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679651969"><span class="annot"><a href="#local-6989586621679651969"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679651968"><span class="annot"><a href="#local-6989586621679651968"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679651967"><span class="annot"><a href="#local-6989586621679651967"><span class="hs-identifier hs-type hs-type">inputEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679651966"><span class="annot"><a href="#local-6989586621679651966"><span class="hs-identifier hs-type hs-type">vocabDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-170"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadDecoderF"><span class="hs-identifier hs-type">LMHeadDecoderF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#T5"><span class="hs-identifier hs-type">T5</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651970"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651969"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651968"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651967"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651966"><span class="hs-identifier hs-type">vocabDim</span></a></span><span>
</span><span id="line-171"></span><span>  </span><span id="LMHeadDecoderF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadDecoderF"><span class="hs-identifier hs-var">LMHeadDecoderF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span> </span><span id="local-6989586621679651965"><span class="annot"><a href="#local-6989586621679651965"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679651964"><span class="annot"><a href="#local-6989586621679651964"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679651963"><span class="annot"><a href="#local-6989586621679651963"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679651962"><span class="annot"><a href="#local-6989586621679651962"><span class="hs-identifier hs-type hs-type">inputEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679651961"><span class="annot"><a href="#local-6989586621679651961"><span class="hs-identifier hs-type hs-type">vocabDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-172"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-type">NamedModel</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Linear.html#GLinearF"><span class="hs-identifier hs-type">GLinearF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Type.html#WithoutBias"><span class="hs-identifier hs-type">WithoutBias</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651965"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651964"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651963"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651962"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651961"><span class="hs-identifier hs-type">vocabDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-173"></span><span>  </span><span id="LMHeadDecoderF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadDecoderF"><span class="hs-identifier hs-var">LMHeadDecoderF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MBART"><span class="hs-identifier hs-type">MBART</span></a></span><span> </span><span id="local-6989586621679651960"><span class="annot"><a href="#local-6989586621679651960"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679651959"><span class="annot"><a href="#local-6989586621679651959"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679651958"><span class="annot"><a href="#local-6989586621679651958"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679651957"><span class="annot"><a href="#local-6989586621679651957"><span class="hs-identifier hs-type hs-type">inputEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679651956"><span class="annot"><a href="#local-6989586621679651956"><span class="hs-identifier hs-type hs-type">vocabDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-174"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadDecoderF"><span class="hs-identifier hs-type">LMHeadDecoderF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651960"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651959"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651958"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651957"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651956"><span class="hs-identifier hs-type">vocabDim</span></a></span><span>
</span><span id="line-175"></span><span>  </span><span id="LMHeadDecoderF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadDecoderF"><span class="hs-identifier hs-var">LMHeadDecoderF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#Pegasus"><span class="hs-identifier hs-type">Pegasus</span></a></span><span> </span><span id="local-6989586621679651955"><span class="annot"><a href="#local-6989586621679651955"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679651954"><span class="annot"><a href="#local-6989586621679651954"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679651953"><span class="annot"><a href="#local-6989586621679651953"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679651952"><span class="annot"><a href="#local-6989586621679651952"><span class="hs-identifier hs-type hs-type">inputEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679651951"><span class="annot"><a href="#local-6989586621679651951"><span class="hs-identifier hs-type hs-type">vocabDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-176"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadDecoderF"><span class="hs-identifier hs-type">LMHeadDecoderF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651955"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651954"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651953"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651952"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651951"><span class="hs-identifier hs-type">vocabDim</span></a></span><span>
</span><span id="line-177"></span><span>  </span><span id="LMHeadDecoderF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadDecoderF"><span class="hs-identifier hs-var">LMHeadDecoderF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BERT"><span class="hs-identifier hs-type">BERT</span></a></span><span> </span><span id="local-6989586621679651950"><span class="annot"><a href="#local-6989586621679651950"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679651949"><span class="annot"><a href="#local-6989586621679651949"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679651948"><span class="annot"><a href="#local-6989586621679651948"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679651947"><span class="annot"><a href="#local-6989586621679651947"><span class="hs-identifier hs-type hs-type">inputEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679651946"><span class="annot"><a href="#local-6989586621679651946"><span class="hs-identifier hs-type hs-type">vocabDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-178"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-type">NamedModel</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Linear.html#GLinearF"><span class="hs-identifier hs-type">GLinearF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Type.html#WithBias"><span class="hs-identifier hs-type">WithBias</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651950"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651949"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651948"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651947"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651946"><span class="hs-identifier hs-type">vocabDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-179"></span><span>  </span><span id="LMHeadDecoderF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadDecoderF"><span class="hs-identifier hs-var">LMHeadDecoderF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#RoBERTa"><span class="hs-identifier hs-type">RoBERTa</span></a></span><span> </span><span id="local-6989586621679651945"><span class="annot"><a href="#local-6989586621679651945"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679651944"><span class="annot"><a href="#local-6989586621679651944"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679651943"><span class="annot"><a href="#local-6989586621679651943"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679651942"><span class="annot"><a href="#local-6989586621679651942"><span class="hs-identifier hs-type hs-type">inputEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679651941"><span class="annot"><a href="#local-6989586621679651941"><span class="hs-identifier hs-type hs-type">vocabDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-180"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadDecoderF"><span class="hs-identifier hs-type">LMHeadDecoderF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BERT"><span class="hs-identifier hs-type">BERT</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651945"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651944"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651943"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651942"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651941"><span class="hs-identifier hs-type">vocabDim</span></a></span><span>
</span><span id="line-181"></span><span>
</span><span id="line-182"></span><span class="hs-comment">-- | Specifies the bias layer of the language model head.</span><span>
</span><span id="line-183"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span>
</span><span id="line-184"></span><span>  </span><span id="LMHeadBiasF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadBiasF"><span class="hs-identifier hs-var">LMHeadBiasF</span></a></span></span><span>
</span><span id="line-185"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679651940"><span class="annot"><a href="#local-6989586621679651940"><span class="hs-identifier hs-type">style</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerStyle"><span class="hs-identifier hs-type">TransformerStyle</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-186"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679651939"><span class="annot"><a href="#local-6989586621679651939"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#RequiresGradient"><span class="hs-identifier hs-type">RequiresGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-187"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679651938"><span class="annot"><a href="#local-6989586621679651938"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier hs-type">Device</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#DeviceType"><span class="hs-identifier hs-type">DeviceType</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-188"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679651937"><span class="annot"><a href="#local-6989586621679651937"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier hs-type">DType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-189"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679651936"><span class="annot"><a href="#local-6989586621679651936"><span class="hs-identifier hs-type">vocabDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-190"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span>
</span><span id="line-191"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-192"></span><span>  </span><span id="LMHeadBiasF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadBiasF"><span class="hs-identifier hs-var">LMHeadBiasF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#T5"><span class="hs-identifier hs-type">T5</span></a></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-193"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#GBias"><span class="hs-identifier hs-type">GBias</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-194"></span><span>  </span><span id="LMHeadBiasF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadBiasF"><span class="hs-identifier hs-var">LMHeadBiasF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ByT5"><span class="hs-identifier hs-type">ByT5</span></a></span><span> </span><span id="local-6989586621679651935"><span class="annot"><a href="#local-6989586621679651935"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679651934"><span class="annot"><a href="#local-6989586621679651934"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679651933"><span class="annot"><a href="#local-6989586621679651933"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679651932"><span class="annot"><a href="#local-6989586621679651932"><span class="hs-identifier hs-type hs-type">vocabDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-195"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadBiasF"><span class="hs-identifier hs-type">LMHeadBiasF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#T5"><span class="hs-identifier hs-type">T5</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651935"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651934"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651933"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651932"><span class="hs-identifier hs-type">vocabDim</span></a></span><span>
</span><span id="line-196"></span><span>  </span><span id="LMHeadBiasF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadBiasF"><span class="hs-identifier hs-var">LMHeadBiasF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span> </span><span id="local-6989586621679651931"><span class="annot"><a href="#local-6989586621679651931"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679651930"><span class="annot"><a href="#local-6989586621679651930"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679651929"><span class="annot"><a href="#local-6989586621679651929"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679651928"><span class="annot"><a href="#local-6989586621679651928"><span class="hs-identifier hs-type hs-type">vocabDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-197"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#GBias"><span class="hs-identifier hs-type">GBias</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-type">NamedModel</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651931"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Dense"><span class="hs-identifier hs-type">Dense</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679651930"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651929"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679651928"><span class="hs-identifier hs-type">vocabDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-198"></span><span>  </span><span id="LMHeadBiasF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadBiasF"><span class="hs-identifier hs-var">LMHeadBiasF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MBART"><span class="hs-identifier hs-type">MBART</span></a></span><span> </span><span id="local-6989586621679651927"><span class="annot"><a href="#local-6989586621679651927"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679651926"><span class="annot"><a href="#local-6989586621679651926"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679651925"><span class="annot"><a href="#local-6989586621679651925"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679651924"><span class="annot"><a href="#local-6989586621679651924"><span class="hs-identifier hs-type hs-type">vocabDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-199"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadBiasF"><span class="hs-identifier hs-type">LMHeadBiasF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651927"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651926"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651925"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651924"><span class="hs-identifier hs-type">vocabDim</span></a></span><span>
</span><span id="line-200"></span><span>  </span><span id="LMHeadBiasF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadBiasF"><span class="hs-identifier hs-var">LMHeadBiasF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#Pegasus"><span class="hs-identifier hs-type">Pegasus</span></a></span><span> </span><span id="local-6989586621679651923"><span class="annot"><a href="#local-6989586621679651923"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679651922"><span class="annot"><a href="#local-6989586621679651922"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679651921"><span class="annot"><a href="#local-6989586621679651921"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679651920"><span class="annot"><a href="#local-6989586621679651920"><span class="hs-identifier hs-type hs-type">vocabDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-201"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadBiasF"><span class="hs-identifier hs-type">LMHeadBiasF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651923"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651922"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651921"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651920"><span class="hs-identifier hs-type">vocabDim</span></a></span><span>
</span><span id="line-202"></span><span>  </span><span id="LMHeadBiasF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadBiasF"><span class="hs-identifier hs-var">LMHeadBiasF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BERT"><span class="hs-identifier hs-type">BERT</span></a></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-203"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#GBias"><span class="hs-identifier hs-type">GBias</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-204"></span><span>  </span><span id="LMHeadBiasF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadBiasF"><span class="hs-identifier hs-var">LMHeadBiasF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#RoBERTa"><span class="hs-identifier hs-type">RoBERTa</span></a></span><span> </span><span id="local-6989586621679651919"><span class="annot"><a href="#local-6989586621679651919"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679651918"><span class="annot"><a href="#local-6989586621679651918"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679651917"><span class="annot"><a href="#local-6989586621679651917"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679651916"><span class="annot"><a href="#local-6989586621679651916"><span class="hs-identifier hs-type hs-type">vocabDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-205"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadBiasF"><span class="hs-identifier hs-type">LMHeadBiasF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BERT"><span class="hs-identifier hs-type">BERT</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651919"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651918"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651917"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651916"><span class="hs-identifier hs-type">vocabDim</span></a></span><span>
</span><span id="line-206"></span><span>
</span><span id="line-207"></span><span class="hs-comment">-- |</span><span>
</span><span id="line-208"></span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#lmHeadSpec"><span class="hs-identifier hs-type">lmHeadSpec</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-209"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679651914"><span class="annot"><a href="#local-6989586621679651914"><span class="hs-identifier hs-type">style</span></a></span></span><span> </span><span id="local-6989586621679651913"><span class="annot"><a href="#local-6989586621679651913"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679651912"><span class="annot"><a href="#local-6989586621679651912"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679651911"><span class="annot"><a href="#local-6989586621679651911"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679651910"><span class="annot"><a href="#local-6989586621679651910"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679651909"><span class="annot"><a href="#local-6989586621679651909"><span class="hs-identifier hs-type">vocabDim</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-210"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#STransformerStyle"><span class="hs-identifier hs-type">STransformerStyle</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651914"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-211"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier hs-type">SGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651913"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-212"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#SDevice"><span class="hs-identifier hs-type">SDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651912"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-213"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier hs-type">SDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651911"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-214"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651910"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-215"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651909"><span class="hs-identifier hs-type">vocabDim</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-216"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-217"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier hs-type">ModelSpec</span></a></span><span>
</span><span id="line-218"></span><span>    </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#GLMHead"><span class="hs-identifier hs-type">GLMHead</span></a></span><span>
</span><span id="line-219"></span><span>        </span><span class="annot"><a href="#local-6989586621679651910"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span>
</span><span id="line-220"></span><span>        </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadDenseF"><span class="hs-identifier hs-type">LMHeadDenseF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651914"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651913"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651912"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651911"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651910"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-221"></span><span>        </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadActivationF"><span class="hs-identifier hs-type">LMHeadActivationF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651914"><span class="hs-identifier hs-type">style</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-222"></span><span>        </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadLayerNormF"><span class="hs-identifier hs-type">LMHeadLayerNormF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651914"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651913"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651912"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651911"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651910"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-223"></span><span>        </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadDecoderF"><span class="hs-identifier hs-type">LMHeadDecoderF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651914"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651913"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651912"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651911"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651910"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651909"><span class="hs-identifier hs-type">vocabDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-224"></span><span>        </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadBiasF"><span class="hs-identifier hs-type">LMHeadBiasF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651914"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651913"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651912"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651911"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651909"><span class="hs-identifier hs-type">vocabDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-225"></span><span>    </span><span class="hs-special">)</span><span>
</span><span id="line-226"></span><span id="lmHeadSpec"><span class="annot"><span class="annottext">lmHeadSpec :: STransformerStyle style
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim inputEmbedDim
-&gt; SDim vocabDim
-&gt; Double
-&gt; ModelSpec
     (GLMHead
        inputEmbedDim
        (LMHeadDenseF style gradient device dataType inputEmbedDim)
        (LMHeadActivationF style)
        (LMHeadLayerNormF style gradient device dataType inputEmbedDim)
        (LMHeadDecoderF
           style gradient device dataType inputEmbedDim vocabDim)
        (LMHeadBiasF style gradient device dataType vocabDim))
</span><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#lmHeadSpec"><span class="hs-identifier hs-var hs-var">lmHeadSpec</span></a></span></span><span> </span><span id="local-6989586621679651908"><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="#local-6989586621679651908"><span class="hs-identifier hs-var">style</span></a></span></span><span> </span><span id="local-6989586621679651907"><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679651907"><span class="hs-identifier hs-var">gradient</span></a></span></span><span> </span><span id="local-6989586621679651906"><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679651906"><span class="hs-identifier hs-var">device</span></a></span></span><span> </span><span id="local-6989586621679651905"><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679651905"><span class="hs-identifier hs-var">dataType</span></a></span></span><span> </span><span id="local-6989586621679651904"><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679651904"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679651903"><span class="annot"><span class="annottext">SDim vocabDim
</span><a href="#local-6989586621679651903"><span class="hs-identifier hs-var">vocabDim</span></a></span></span><span> </span><span id="local-6989586621679651902"><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679651902"><span class="hs-identifier hs-var">eps</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-227"></span><span>  </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679651901"><span class="annot"><span class="annottext">denseSpec :: STransformerStyle style
-&gt; ModelSpec
     (LMHeadDenseF style gradient device dataType inputEmbedDim)
</span><a href="#local-6989586621679651901"><span class="hs-identifier hs-var hs-var">denseSpec</span></a></span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-228"></span><span>      </span><span class="annot"><a href="#local-6989586621679651901"><span class="hs-identifier hs-var">denseSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-229"></span><span>      </span><span class="annot"><a href="#local-6989586621679651901"><span class="hs-identifier hs-var">denseSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-230"></span><span>      </span><span class="annot"><a href="#local-6989586621679651901"><span class="hs-identifier hs-var">denseSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-231"></span><span>      </span><span class="annot"><a href="#local-6989586621679651901"><span class="hs-identifier hs-var">denseSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-232"></span><span>      </span><span class="annot"><a href="#local-6989586621679651901"><span class="hs-identifier hs-var">denseSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Text
-&gt; GLinear
     (NamedModel
        (TensorSpec
           gradient
           ('Layout 'Dense)
           device
           dataType
           ('Shape '[inputEmbedDim, inputEmbedDim])))
     (NamedModel
        (TensorSpec
           gradient
           ('Layout 'Dense)
           device
           dataType
           ('Shape '[inputEmbedDim])))
-&gt; NamedModel
     (GLinear
        (NamedModel
           (TensorSpec
              gradient
              ('Layout 'Dense)
              device
              dataType
              ('Shape '[inputEmbedDim, inputEmbedDim])))
        (NamedModel
           (TensorSpec
              gradient
              ('Layout 'Dense)
              device
              dataType
              ('Shape '[inputEmbedDim]))))
forall model. Text -&gt; model -&gt; NamedModel model
</span><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-var">NamedModel</span></a></span><span> </span><span class="annot"><span class="annottext">Text
</span><span class="hs-string">&quot;transform.dense.&quot;</span></span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (GLinearF
     'WithBias gradient device dataType inputEmbedDim inputEmbedDim)
GLinear
  (NamedModel
     (TensorSpec
        gradient
        ('Layout 'Dense)
        device
        dataType
        ('Shape '[inputEmbedDim, inputEmbedDim])))
  (NamedModel
     (TensorSpec
        gradient
        ('Layout 'Dense)
        device
        dataType
        ('Shape '[inputEmbedDim])))
</span><a href="#local-6989586621679651893"><span class="hs-identifier hs-var">linearSpec'</span></a></span><span>
</span><span id="line-233"></span><span>      </span><span class="annot"><a href="#local-6989586621679651901"><span class="hs-identifier hs-var">denseSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Text
-&gt; GLinear
     (NamedModel
        (TensorSpec
           gradient
           ('Layout 'Dense)
           device
           dataType
           ('Shape '[inputEmbedDim, inputEmbedDim])))
     (NamedModel
        (TensorSpec
           gradient
           ('Layout 'Dense)
           device
           dataType
           ('Shape '[inputEmbedDim])))
-&gt; NamedModel
     (GLinear
        (NamedModel
           (TensorSpec
              gradient
              ('Layout 'Dense)
              device
              dataType
              ('Shape '[inputEmbedDim, inputEmbedDim])))
        (NamedModel
           (TensorSpec
              gradient
              ('Layout 'Dense)
              device
              dataType
              ('Shape '[inputEmbedDim]))))
forall model. Text -&gt; model -&gt; NamedModel model
</span><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-var">NamedModel</span></a></span><span> </span><span class="annot"><span class="annottext">Text
</span><span class="hs-string">&quot;dense.&quot;</span></span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (GLinearF
     'WithBias gradient device dataType inputEmbedDim inputEmbedDim)
GLinear
  (NamedModel
     (TensorSpec
        gradient
        ('Layout 'Dense)
        device
        dataType
        ('Shape '[inputEmbedDim, inputEmbedDim])))
  (NamedModel
     (TensorSpec
        gradient
        ('Layout 'Dense)
        device
        dataType
        ('Shape '[inputEmbedDim])))
</span><a href="#local-6989586621679651893"><span class="hs-identifier hs-var">linearSpec'</span></a></span><span>
</span><span id="line-234"></span><span>      </span><span class="annot"><a href="#local-6989586621679651901"><span class="hs-identifier hs-var">denseSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SGPT2"><span class="hs-identifier hs-var">SGPT2</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (LMHeadDenseF style gradient device dataType inputEmbedDim)
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-235"></span><span>      </span><span class="annot"><a href="#local-6989586621679651889"><span class="hs-identifier hs-type">activationSpec</span></a></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#STransformerStyle"><span class="hs-identifier hs-type">STransformerStyle</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651914"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier hs-type">ModelSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadActivationF"><span class="hs-identifier hs-type">LMHeadActivationF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651914"><span class="hs-identifier hs-type">style</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-236"></span><span>      </span><span id="local-6989586621679651889"><span class="annot"><span class="annottext">activationSpec :: STransformerStyle style -&gt; ModelSpec (LMHeadActivationF style)
</span><a href="#local-6989586621679651889"><span class="hs-identifier hs-var hs-var">activationSpec</span></a></span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-237"></span><span>      </span><span class="annot"><a href="#local-6989586621679651889"><span class="hs-identifier hs-var">activationSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-238"></span><span>      </span><span class="annot"><a href="#local-6989586621679651889"><span class="hs-identifier hs-var">activationSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-239"></span><span>      </span><span class="annot"><a href="#local-6989586621679651889"><span class="hs-identifier hs-var">activationSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-240"></span><span>      </span><span class="annot"><a href="#local-6989586621679651889"><span class="hs-identifier hs-var">activationSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-241"></span><span>      </span><span class="annot"><a href="#local-6989586621679651889"><span class="hs-identifier hs-var">activationSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec (LMHeadActivationF style)
Gelu
</span><a href="Torch.GraduallyTyped.NN.Activation.html#Gelu"><span class="hs-identifier hs-var">Gelu</span></a></span><span>
</span><span id="line-242"></span><span>      </span><span class="annot"><a href="#local-6989586621679651889"><span class="hs-identifier hs-var">activationSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec (LMHeadActivationF style)
Gelu
</span><a href="Torch.GraduallyTyped.NN.Activation.html#Gelu"><span class="hs-identifier hs-var">Gelu</span></a></span><span>
</span><span id="line-243"></span><span>      </span><span class="annot"><a href="#local-6989586621679651889"><span class="hs-identifier hs-var">activationSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SGPT2"><span class="hs-identifier hs-var">SGPT2</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec (LMHeadActivationF style)
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-244"></span><span>      </span><span id="local-6989586621679651887"><span class="annot"><span class="annottext">layerNormSpec :: STransformerStyle style
-&gt; ModelSpec
     (LMHeadLayerNormF style gradient device dataType inputEmbedDim)
</span><a href="#local-6989586621679651887"><span class="hs-identifier hs-var hs-var">layerNormSpec</span></a></span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-245"></span><span>      </span><span class="annot"><a href="#local-6989586621679651887"><span class="hs-identifier hs-var">layerNormSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-246"></span><span>      </span><span class="annot"><a href="#local-6989586621679651887"><span class="hs-identifier hs-var">layerNormSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-247"></span><span>      </span><span class="annot"><a href="#local-6989586621679651887"><span class="hs-identifier hs-var">layerNormSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-248"></span><span>      </span><span class="annot"><a href="#local-6989586621679651887"><span class="hs-identifier hs-var">layerNormSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-249"></span><span>      </span><span class="annot"><a href="#local-6989586621679651887"><span class="hs-identifier hs-var">layerNormSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Text
-&gt; LayerNormSpec
     'WithBias gradient device dataType ('Shape '[inputEmbedDim])
-&gt; NamedModel
     (LayerNormSpec
        'WithBias gradient device dataType ('Shape '[inputEmbedDim]))
forall model. Text -&gt; model -&gt; NamedModel model
</span><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-var">NamedModel</span></a></span><span> </span><span class="annot"><span class="annottext">Text
</span><span class="hs-string">&quot;transform.LayerNorm.&quot;</span></span><span> </span><span class="annot"><span class="annottext">LayerNormSpec
  'WithBias gradient device dataType ('Shape '[inputEmbedDim])
</span><a href="#local-6989586621679651886"><span class="hs-identifier hs-var">layerNormSpec'</span></a></span><span>
</span><span id="line-250"></span><span>      </span><span class="annot"><a href="#local-6989586621679651887"><span class="hs-identifier hs-var">layerNormSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Text
-&gt; LayerNormSpec
     'WithBias gradient device dataType ('Shape '[inputEmbedDim])
-&gt; NamedModel
     (LayerNormSpec
        'WithBias gradient device dataType ('Shape '[inputEmbedDim]))
forall model. Text -&gt; model -&gt; NamedModel model
</span><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-var">NamedModel</span></a></span><span> </span><span class="annot"><span class="annottext">Text
</span><span class="hs-string">&quot;layer_norm.&quot;</span></span><span> </span><span class="annot"><span class="annottext">LayerNormSpec
  'WithBias gradient device dataType ('Shape '[inputEmbedDim])
</span><a href="#local-6989586621679651886"><span class="hs-identifier hs-var">layerNormSpec'</span></a></span><span>
</span><span id="line-251"></span><span>      </span><span class="annot"><a href="#local-6989586621679651887"><span class="hs-identifier hs-var">layerNormSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SGPT2"><span class="hs-identifier hs-var">SGPT2</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (LMHeadLayerNormF style gradient device dataType inputEmbedDim)
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-252"></span><span>      </span><span id="local-6989586621679651885"><span class="annot"><span class="annottext">decoderSpec :: STransformerStyle style
-&gt; ModelSpec
     (LMHeadDecoderF
        style gradient device dataType inputEmbedDim vocabDim)
</span><a href="#local-6989586621679651885"><span class="hs-identifier hs-var hs-var">decoderSpec</span></a></span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Text
-&gt; GLinear
     (NamedModel
        (TensorSpec
           gradient
           ('Layout 'Dense)
           device
           dataType
           ('Shape '[vocabDim, inputEmbedDim])))
     (NamedModel ())
-&gt; NamedModel
     (GLinear
        (NamedModel
           (TensorSpec
              gradient
              ('Layout 'Dense)
              device
              dataType
              ('Shape '[vocabDim, inputEmbedDim])))
        (NamedModel ()))
forall model. Text -&gt; model -&gt; NamedModel model
</span><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-var">NamedModel</span></a></span><span> </span><span class="annot"><span class="annottext">Text
forall a. Monoid a =&gt; a
</span><span class="hs-identifier hs-var">mempty</span></span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (GLinearF
     'WithoutBias gradient device dataType inputEmbedDim vocabDim)
GLinear
  (NamedModel
     (TensorSpec
        gradient
        ('Layout 'Dense)
        device
        dataType
        ('Shape '[vocabDim, inputEmbedDim])))
  (NamedModel ())
</span><a href="#local-6989586621679651884"><span class="hs-identifier hs-var">linearWithoutBiasSpec'</span></a></span><span>
</span><span id="line-253"></span><span>      </span><span class="annot"><a href="#local-6989586621679651885"><span class="hs-identifier hs-var">decoderSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Text
-&gt; GLinear
     (NamedModel
        (TensorSpec
           gradient
           ('Layout 'Dense)
           device
           dataType
           ('Shape '[vocabDim, inputEmbedDim])))
     (NamedModel ())
-&gt; NamedModel
     (GLinear
        (NamedModel
           (TensorSpec
              gradient
              ('Layout 'Dense)
              device
              dataType
              ('Shape '[vocabDim, inputEmbedDim])))
        (NamedModel ()))
forall model. Text -&gt; model -&gt; NamedModel model
</span><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-var">NamedModel</span></a></span><span> </span><span class="annot"><span class="annottext">Text
forall a. Monoid a =&gt; a
</span><span class="hs-identifier hs-var">mempty</span></span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (GLinearF
     'WithoutBias gradient device dataType inputEmbedDim vocabDim)
GLinear
  (NamedModel
     (TensorSpec
        gradient
        ('Layout 'Dense)
        device
        dataType
        ('Shape '[vocabDim, inputEmbedDim])))
  (NamedModel ())
</span><a href="#local-6989586621679651884"><span class="hs-identifier hs-var">linearWithoutBiasSpec'</span></a></span><span>
</span><span id="line-254"></span><span>      </span><span class="annot"><a href="#local-6989586621679651885"><span class="hs-identifier hs-var">decoderSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Text
-&gt; GLinear
     (NamedModel
        (TensorSpec
           gradient
           ('Layout 'Dense)
           device
           dataType
           ('Shape '[vocabDim, inputEmbedDim])))
     (NamedModel ())
-&gt; NamedModel
     (GLinear
        (NamedModel
           (TensorSpec
              gradient
              ('Layout 'Dense)
              device
              dataType
              ('Shape '[vocabDim, inputEmbedDim])))
        (NamedModel ()))
forall model. Text -&gt; model -&gt; NamedModel model
</span><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-var">NamedModel</span></a></span><span> </span><span class="annot"><span class="annottext">Text
</span><span class="hs-string">&quot;lm_head.&quot;</span></span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (GLinearF
     'WithoutBias gradient device dataType inputEmbedDim vocabDim)
GLinear
  (NamedModel
     (TensorSpec
        gradient
        ('Layout 'Dense)
        device
        dataType
        ('Shape '[vocabDim, inputEmbedDim])))
  (NamedModel ())
</span><a href="#local-6989586621679651884"><span class="hs-identifier hs-var">linearWithoutBiasSpec'</span></a></span><span>
</span><span id="line-255"></span><span>      </span><span class="annot"><a href="#local-6989586621679651885"><span class="hs-identifier hs-var">decoderSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Text
-&gt; GLinear
     (NamedModel
        (TensorSpec
           gradient
           ('Layout 'Dense)
           device
           dataType
           ('Shape '[vocabDim, inputEmbedDim])))
     (NamedModel ())
-&gt; NamedModel
     (GLinear
        (NamedModel
           (TensorSpec
              gradient
              ('Layout 'Dense)
              device
              dataType
              ('Shape '[vocabDim, inputEmbedDim])))
        (NamedModel ()))
forall model. Text -&gt; model -&gt; NamedModel model
</span><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-var">NamedModel</span></a></span><span> </span><span class="annot"><span class="annottext">Text
</span><span class="hs-string">&quot;lm_head.&quot;</span></span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (GLinearF
     'WithoutBias gradient device dataType inputEmbedDim vocabDim)
GLinear
  (NamedModel
     (TensorSpec
        gradient
        ('Layout 'Dense)
        device
        dataType
        ('Shape '[vocabDim, inputEmbedDim])))
  (NamedModel ())
</span><a href="#local-6989586621679651884"><span class="hs-identifier hs-var">linearWithoutBiasSpec'</span></a></span><span>
</span><span id="line-256"></span><span>      </span><span class="annot"><a href="#local-6989586621679651885"><span class="hs-identifier hs-var">decoderSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Text
-&gt; GLinear
     (NamedModel
        (TensorSpec
           gradient
           ('Layout 'Dense)
           device
           dataType
           ('Shape '[vocabDim, inputEmbedDim])))
     (NamedModel ())
-&gt; NamedModel
     (GLinear
        (NamedModel
           (TensorSpec
              gradient
              ('Layout 'Dense)
              device
              dataType
              ('Shape '[vocabDim, inputEmbedDim])))
        (NamedModel ()))
forall model. Text -&gt; model -&gt; NamedModel model
</span><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-var">NamedModel</span></a></span><span> </span><span class="annot"><span class="annottext">Text
</span><span class="hs-string">&quot;lm_head.&quot;</span></span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (GLinearF
     'WithoutBias gradient device dataType inputEmbedDim vocabDim)
GLinear
  (NamedModel
     (TensorSpec
        gradient
        ('Layout 'Dense)
        device
        dataType
        ('Shape '[vocabDim, inputEmbedDim])))
  (NamedModel ())
</span><a href="#local-6989586621679651884"><span class="hs-identifier hs-var">linearWithoutBiasSpec'</span></a></span><span>
</span><span id="line-257"></span><span>      </span><span class="annot"><a href="#local-6989586621679651885"><span class="hs-identifier hs-var">decoderSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Text
-&gt; GLinear
     (NamedModel
        (TensorSpec
           gradient
           ('Layout 'Dense)
           device
           dataType
           ('Shape '[vocabDim, inputEmbedDim])))
     (NamedModel
        (TensorSpec
           gradient ('Layout 'Dense) device dataType ('Shape '[vocabDim])))
-&gt; NamedModel
     (GLinear
        (NamedModel
           (TensorSpec
              gradient
              ('Layout 'Dense)
              device
              dataType
              ('Shape '[vocabDim, inputEmbedDim])))
        (NamedModel
           (TensorSpec
              gradient ('Layout 'Dense) device dataType ('Shape '[vocabDim]))))
forall model. Text -&gt; model -&gt; NamedModel model
</span><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-var">NamedModel</span></a></span><span> </span><span class="annot"><span class="annottext">Text
</span><span class="hs-string">&quot;decoder.&quot;</span></span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (GLinearF
     'WithBias gradient device dataType inputEmbedDim vocabDim)
GLinear
  (NamedModel
     (TensorSpec
        gradient
        ('Layout 'Dense)
        device
        dataType
        ('Shape '[vocabDim, inputEmbedDim])))
  (NamedModel
     (TensorSpec
        gradient ('Layout 'Dense) device dataType ('Shape '[vocabDim])))
</span><a href="#local-6989586621679651883"><span class="hs-identifier hs-var">linearWithBiasSpec'</span></a></span><span>
</span><span id="line-258"></span><span>      </span><span class="annot"><a href="#local-6989586621679651885"><span class="hs-identifier hs-var">decoderSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Text
-&gt; GLinear
     (NamedModel
        (TensorSpec
           gradient
           ('Layout 'Dense)
           device
           dataType
           ('Shape '[vocabDim, inputEmbedDim])))
     (NamedModel
        (TensorSpec
           gradient ('Layout 'Dense) device dataType ('Shape '[vocabDim])))
-&gt; NamedModel
     (GLinear
        (NamedModel
           (TensorSpec
              gradient
              ('Layout 'Dense)
              device
              dataType
              ('Shape '[vocabDim, inputEmbedDim])))
        (NamedModel
           (TensorSpec
              gradient ('Layout 'Dense) device dataType ('Shape '[vocabDim]))))
forall model. Text -&gt; model -&gt; NamedModel model
</span><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-var">NamedModel</span></a></span><span> </span><span class="annot"><span class="annottext">Text
</span><span class="hs-string">&quot;decoder.&quot;</span></span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (GLinearF
     'WithBias gradient device dataType inputEmbedDim vocabDim)
GLinear
  (NamedModel
     (TensorSpec
        gradient
        ('Layout 'Dense)
        device
        dataType
        ('Shape '[vocabDim, inputEmbedDim])))
  (NamedModel
     (TensorSpec
        gradient ('Layout 'Dense) device dataType ('Shape '[vocabDim])))
</span><a href="#local-6989586621679651883"><span class="hs-identifier hs-var">linearWithBiasSpec'</span></a></span><span>
</span><span id="line-259"></span><span>      </span><span class="annot"><a href="#local-6989586621679651885"><span class="hs-identifier hs-var">decoderSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SGPT2"><span class="hs-identifier hs-var">SGPT2</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (LMHeadDecoderF
     style gradient device dataType inputEmbedDim vocabDim)
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-260"></span><span>      </span><span id="local-6989586621679651882"><span class="annot"><span class="annottext">biasSpec :: STransformerStyle style
-&gt; ModelSpec (LMHeadBiasF style gradient device dataType vocabDim)
</span><a href="#local-6989586621679651882"><span class="hs-identifier hs-var hs-var">biasSpec</span></a></span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">() -&gt; GBias ()
forall bias. bias -&gt; GBias bias
</span><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#GBias"><span class="hs-identifier hs-var">GBias</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-261"></span><span>      </span><span class="annot"><a href="#local-6989586621679651882"><span class="hs-identifier hs-var">biasSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">() -&gt; GBias ()
forall bias. bias -&gt; GBias bias
</span><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#GBias"><span class="hs-identifier hs-var">GBias</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-262"></span><span>      </span><span class="annot"><a href="#local-6989586621679651882"><span class="hs-identifier hs-var">biasSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">NamedModel
  (TensorSpec
     gradient
     ('Layout 'Dense)
     device
     dataType
     ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), vocabDim]))
-&gt; GBias
     (NamedModel
        (TensorSpec
           gradient
           ('Layout 'Dense)
           device
           dataType
           ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), vocabDim])))
forall bias. bias -&gt; GBias bias
</span><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#GBias"><span class="hs-identifier hs-var">GBias</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Text
-&gt; TensorSpec
     gradient
     ('Layout 'Dense)
     device
     dataType
     ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), vocabDim])
-&gt; NamedModel
     (TensorSpec
        gradient
        ('Layout 'Dense)
        device
        dataType
        ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), vocabDim]))
forall model. Text -&gt; model -&gt; NamedModel model
</span><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-var">NamedModel</span></a></span><span> </span><span class="annot"><span class="annottext">Text
</span><span class="hs-string">&quot;final_logits_bias&quot;</span></span><span> </span><span class="annot"><span class="annottext">TensorSpec
  gradient
  ('Layout 'Dense)
  device
  dataType
  ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), vocabDim])
</span><a href="#local-6989586621679651881"><span class="hs-identifier hs-var">biasSpec'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-263"></span><span>      </span><span class="annot"><a href="#local-6989586621679651882"><span class="hs-identifier hs-var">biasSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">NamedModel
  (TensorSpec
     gradient
     ('Layout 'Dense)
     device
     dataType
     ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), vocabDim]))
-&gt; GBias
     (NamedModel
        (TensorSpec
           gradient
           ('Layout 'Dense)
           device
           dataType
           ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), vocabDim])))
forall bias. bias -&gt; GBias bias
</span><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#GBias"><span class="hs-identifier hs-var">GBias</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Text
-&gt; TensorSpec
     gradient
     ('Layout 'Dense)
     device
     dataType
     ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), vocabDim])
-&gt; NamedModel
     (TensorSpec
        gradient
        ('Layout 'Dense)
        device
        dataType
        ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), vocabDim]))
forall model. Text -&gt; model -&gt; NamedModel model
</span><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-var">NamedModel</span></a></span><span> </span><span class="annot"><span class="annottext">Text
</span><span class="hs-string">&quot;final_logits_bias&quot;</span></span><span> </span><span class="annot"><span class="annottext">TensorSpec
  gradient
  ('Layout 'Dense)
  device
  dataType
  ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), vocabDim])
</span><a href="#local-6989586621679651881"><span class="hs-identifier hs-var">biasSpec'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-264"></span><span>      </span><span class="annot"><a href="#local-6989586621679651882"><span class="hs-identifier hs-var">biasSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">NamedModel
  (TensorSpec
     gradient
     ('Layout 'Dense)
     device
     dataType
     ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), vocabDim]))
-&gt; GBias
     (NamedModel
        (TensorSpec
           gradient
           ('Layout 'Dense)
           device
           dataType
           ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), vocabDim])))
forall bias. bias -&gt; GBias bias
</span><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#GBias"><span class="hs-identifier hs-var">GBias</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Text
-&gt; TensorSpec
     gradient
     ('Layout 'Dense)
     device
     dataType
     ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), vocabDim])
-&gt; NamedModel
     (TensorSpec
        gradient
        ('Layout 'Dense)
        device
        dataType
        ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), vocabDim]))
forall model. Text -&gt; model -&gt; NamedModel model
</span><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-var">NamedModel</span></a></span><span> </span><span class="annot"><span class="annottext">Text
</span><span class="hs-string">&quot;final_logits_bias&quot;</span></span><span> </span><span class="annot"><span class="annottext">TensorSpec
  gradient
  ('Layout 'Dense)
  device
  dataType
  ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), vocabDim])
</span><a href="#local-6989586621679651881"><span class="hs-identifier hs-var">biasSpec'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-265"></span><span>      </span><span class="annot"><a href="#local-6989586621679651882"><span class="hs-identifier hs-var">biasSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">() -&gt; GBias ()
forall bias. bias -&gt; GBias bias
</span><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#GBias"><span class="hs-identifier hs-var">GBias</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-266"></span><span>      </span><span class="annot"><a href="#local-6989586621679651882"><span class="hs-identifier hs-var">biasSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">() -&gt; GBias ()
forall bias. bias -&gt; GBias bias
</span><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#GBias"><span class="hs-identifier hs-var">GBias</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-267"></span><span>      </span><span class="annot"><a href="#local-6989586621679651882"><span class="hs-identifier hs-var">biasSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SGPT2"><span class="hs-identifier hs-var">SGPT2</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec (LMHeadBiasF style gradient device dataType vocabDim)
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-268"></span><span>      </span><span class="annot"><a href="#local-6989586621679651880"><span class="hs-identifier hs-type">scalingSpec</span></a></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#STransformerStyle"><span class="hs-identifier hs-type">STransformerStyle</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651914"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadHasScaling"><span class="hs-identifier hs-type">LMHeadHasScaling</span></a></span><span>
</span><span id="line-269"></span><span>      </span><span id="local-6989586621679651880"><span class="annot"><span class="annottext">scalingSpec :: STransformerStyle style -&gt; LMHeadHasScaling
</span><a href="#local-6989586621679651880"><span class="hs-identifier hs-var hs-var">scalingSpec</span></a></span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">LMHeadHasScaling
</span><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadWithScaling"><span class="hs-identifier hs-var">LMHeadWithScaling</span></a></span><span>
</span><span id="line-270"></span><span>      </span><span class="annot"><a href="#local-6989586621679651880"><span class="hs-identifier hs-var">scalingSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">LMHeadHasScaling
</span><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadWithScaling"><span class="hs-identifier hs-var">LMHeadWithScaling</span></a></span><span>
</span><span id="line-271"></span><span>      </span><span class="annot"><a href="#local-6989586621679651880"><span class="hs-identifier hs-var">scalingSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">LMHeadHasScaling
</span><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadWithoutScaling"><span class="hs-identifier hs-var">LMHeadWithoutScaling</span></a></span><span>
</span><span id="line-272"></span><span>      </span><span class="annot"><a href="#local-6989586621679651880"><span class="hs-identifier hs-var">scalingSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">LMHeadHasScaling
</span><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadWithoutScaling"><span class="hs-identifier hs-var">LMHeadWithoutScaling</span></a></span><span>
</span><span id="line-273"></span><span>      </span><span class="annot"><a href="#local-6989586621679651880"><span class="hs-identifier hs-var">scalingSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">LMHeadHasScaling
</span><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadWithoutScaling"><span class="hs-identifier hs-var">LMHeadWithoutScaling</span></a></span><span>
</span><span id="line-274"></span><span>      </span><span class="annot"><a href="#local-6989586621679651880"><span class="hs-identifier hs-var">scalingSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">LMHeadHasScaling
</span><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadWithoutScaling"><span class="hs-identifier hs-var">LMHeadWithoutScaling</span></a></span><span>
</span><span id="line-275"></span><span>      </span><span class="annot"><a href="#local-6989586621679651880"><span class="hs-identifier hs-var">scalingSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">LMHeadHasScaling
</span><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadWithoutScaling"><span class="hs-identifier hs-var">LMHeadWithoutScaling</span></a></span><span>
</span><span id="line-276"></span><span>      </span><span class="annot"><a href="#local-6989586621679651880"><span class="hs-identifier hs-var">scalingSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SGPT2"><span class="hs-identifier hs-var">SGPT2</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">LMHeadHasScaling
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-277"></span><span>   </span><span class="hs-keyword">in</span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
-&gt; ModelSpec
     (LMHeadDenseF style gradient device dataType inputEmbedDim)
-&gt; ModelSpec (LMHeadActivationF style)
-&gt; ModelSpec
     (LMHeadLayerNormF style gradient device dataType inputEmbedDim)
-&gt; ModelSpec
     (LMHeadDecoderF
        style gradient device dataType inputEmbedDim vocabDim)
-&gt; ModelSpec (LMHeadBiasF style gradient device dataType vocabDim)
-&gt; LMHeadHasScaling
-&gt; GLMHead
     inputEmbedDim
     (ModelSpec
        (LMHeadDenseF style gradient device dataType inputEmbedDim))
     (ModelSpec (LMHeadActivationF style))
     (ModelSpec
        (LMHeadLayerNormF style gradient device dataType inputEmbedDim))
     (ModelSpec
        (LMHeadDecoderF
           style gradient device dataType inputEmbedDim vocabDim))
     (ModelSpec (LMHeadBiasF style gradient device dataType vocabDim))
forall (inputEmbedDim :: Dim (Name Symbol) (Size Nat)) dense
       activation layerNorm decoder bias.
SDim inputEmbedDim
-&gt; dense
-&gt; activation
-&gt; layerNorm
-&gt; decoder
-&gt; bias
-&gt; LMHeadHasScaling
-&gt; GLMHead inputEmbedDim dense activation layerNorm decoder bias
</span><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#GLMHead"><span class="hs-identifier hs-var">GLMHead</span></a></span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679651904"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; ModelSpec
     (LMHeadDenseF style gradient device dataType inputEmbedDim)
</span><a href="#local-6989586621679651901"><span class="hs-identifier hs-var">denseSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="#local-6989586621679651908"><span class="hs-identifier hs-var">style</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">STransformerStyle style -&gt; ModelSpec (LMHeadActivationF style)
</span><a href="#local-6989586621679651889"><span class="hs-identifier hs-var">activationSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="#local-6989586621679651908"><span class="hs-identifier hs-var">style</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; ModelSpec
     (LMHeadLayerNormF style gradient device dataType inputEmbedDim)
</span><a href="#local-6989586621679651887"><span class="hs-identifier hs-var">layerNormSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="#local-6989586621679651908"><span class="hs-identifier hs-var">style</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; ModelSpec
     (LMHeadDecoderF
        style gradient device dataType inputEmbedDim vocabDim)
</span><a href="#local-6989586621679651885"><span class="hs-identifier hs-var">decoderSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="#local-6989586621679651908"><span class="hs-identifier hs-var">style</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; ModelSpec (LMHeadBiasF style gradient device dataType vocabDim)
</span><a href="#local-6989586621679651882"><span class="hs-identifier hs-var">biasSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="#local-6989586621679651908"><span class="hs-identifier hs-var">style</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">STransformerStyle style -&gt; LMHeadHasScaling
</span><a href="#local-6989586621679651880"><span class="hs-identifier hs-var">scalingSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="#local-6989586621679651908"><span class="hs-identifier hs-var">style</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-278"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-279"></span><span>    </span><span id="local-6989586621679651893"><span class="annot"><span class="annottext">linearSpec' :: ModelSpec
  (GLinearF
     'WithBias gradient device dataType inputEmbedDim inputEmbedDim)
</span><a href="#local-6989586621679651893"><span class="hs-identifier hs-var hs-var">linearSpec'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SHasBias 'WithBias
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim inputEmbedDim
-&gt; SDim inputEmbedDim
-&gt; ModelSpec
     (GLinearF
        'WithBias gradient device dataType inputEmbedDim inputEmbedDim)
forall (hasBias :: HasBias) (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (inputDim :: Dim (Name Symbol) (Size Nat))
       (outputDim :: Dim (Name Symbol) (Size Nat)).
SHasBias hasBias
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim inputDim
-&gt; SDim outputDim
-&gt; ModelSpec
     (GLinearF hasBias gradient device dataType inputDim outputDim)
</span><a href="Torch.GraduallyTyped.NN.Linear.html#linearSpec"><span class="hs-identifier hs-var">linearSpec</span></a></span><span> </span><span class="annot"><span class="annottext">SHasBias 'WithBias
</span><a href="Torch.GraduallyTyped.NN.Type.html#SWithBias"><span class="hs-identifier hs-var">SWithBias</span></a></span><span> </span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679651907"><span class="hs-identifier hs-var">gradient</span></a></span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679651906"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679651905"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679651904"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679651904"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span>
</span><span id="line-280"></span><span>    </span><span id="local-6989586621679651881"><span class="annot"><span class="annottext">biasSpec' :: TensorSpec
  gradient
  ('Layout 'Dense)
  device
  dataType
  ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), vocabDim])
</span><a href="#local-6989586621679651881"><span class="hs-identifier hs-var hs-var">biasSpec'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SGradient gradient
-&gt; SLayout ('Layout 'Dense)
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SShape ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), vocabDim])
-&gt; TensorSpec
     gradient
     ('Layout 'Dense)
     device
     dataType
     ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), vocabDim])
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SShape shape
-&gt; TensorSpec gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorSpec"><span class="hs-identifier hs-var">TensorSpec</span></a></span><span> </span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679651907"><span class="hs-identifier hs-var">gradient</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SLayoutType 'Dense -&gt; SLayout ('Layout 'Dense)
forall (layoutType :: LayoutType).
SLayoutType layoutType -&gt; SLayout ('Layout layoutType)
</span><a href="Torch.GraduallyTyped.Layout.html#SLayout"><span class="hs-identifier hs-var">SLayout</span></a></span><span> </span><span class="annot"><span class="annottext">SLayoutType 'Dense
</span><a href="Torch.GraduallyTyped.Layout.html#SDense"><span class="hs-identifier hs-var">SDense</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679651906"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679651905"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SList '[ 'Dim ('Name &quot;*&quot;) ('Size 1), vocabDim]
-&gt; SShape ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), vocabDim])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList '[ 'Dim ('Name &quot;*&quot;) ('Size 1), vocabDim]
 -&gt; SShape ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), vocabDim]))
-&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 1), vocabDim]
-&gt; SShape ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), vocabDim])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize ('Size 1) -&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 1))
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownNat 1 =&gt; SSize ('Size 1)
forall (size :: Nat). KnownNat size =&gt; SSize ('Size size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier hs-var">SSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">1</span></span><span> </span><span class="annot"><span class="annottext">Sing ('Dim ('Name &quot;*&quot;) ('Size 1))
-&gt; SList '[vocabDim]
-&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 1), vocabDim]
forall a1 (a2 :: a1) (as :: [a1]).
Sing a2 -&gt; SList as -&gt; SList (a2 : as)
</span><a href="Torch.GraduallyTyped.Prelude.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">Sing vocabDim
SDim vocabDim
</span><a href="#local-6989586621679651903"><span class="hs-identifier hs-var">vocabDim</span></a></span><span> </span><span class="annot"><span class="annottext">Sing vocabDim -&gt; SList '[] -&gt; SList '[vocabDim]
forall a1 (a2 :: a1) (as :: [a1]).
Sing a2 -&gt; SList as -&gt; SList (a2 : as)
</span><a href="Torch.GraduallyTyped.Prelude.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-281"></span><span>    </span><span id="local-6989586621679651886"><span class="annot"><span class="annottext">layerNormSpec' :: LayerNormSpec
  'WithBias gradient device dataType ('Shape '[inputEmbedDim])
</span><a href="#local-6989586621679651886"><span class="hs-identifier hs-var hs-var">layerNormSpec'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SHasBias 'WithBias
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SShape ('Shape '[inputEmbedDim])
-&gt; Double
-&gt; LayerNormSpec
     'WithBias gradient device dataType ('Shape '[inputEmbedDim])
forall (hasBias :: HasBias) (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (normalizedShape :: Shape [Dim (Name Symbol) (Size Nat)]).
SHasBias hasBias
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SShape normalizedShape
-&gt; Double
-&gt; LayerNormSpec hasBias gradient device dataType normalizedShape
</span><a href="Torch.GraduallyTyped.NN.Normalization.html#LayerNormSpec"><span class="hs-identifier hs-var">LayerNormSpec</span></a></span><span> </span><span class="annot"><span class="annottext">SHasBias 'WithBias
</span><a href="Torch.GraduallyTyped.NN.Type.html#SWithBias"><span class="hs-identifier hs-var">SWithBias</span></a></span><span> </span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679651907"><span class="hs-identifier hs-var">gradient</span></a></span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679651906"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679651905"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SList '[inputEmbedDim] -&gt; SShape ('Shape '[inputEmbedDim])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList '[inputEmbedDim] -&gt; SShape ('Shape '[inputEmbedDim]))
-&gt; SList '[inputEmbedDim] -&gt; SShape ('Shape '[inputEmbedDim])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">Sing inputEmbedDim
SDim inputEmbedDim
</span><a href="#local-6989586621679651904"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">Sing inputEmbedDim -&gt; SList '[] -&gt; SList '[inputEmbedDim]
forall a1 (a2 :: a1) (as :: [a1]).
Sing a2 -&gt; SList as -&gt; SList (a2 : as)
</span><a href="Torch.GraduallyTyped.Prelude.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679651902"><span class="hs-identifier hs-var">eps</span></a></span><span>
</span><span id="line-282"></span><span>    </span><span id="local-6989586621679651884"><span class="annot"><span class="annottext">linearWithoutBiasSpec' :: ModelSpec
  (GLinearF
     'WithoutBias gradient device dataType inputEmbedDim vocabDim)
</span><a href="#local-6989586621679651884"><span class="hs-identifier hs-var hs-var">linearWithoutBiasSpec'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SHasBias 'WithoutBias
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim inputEmbedDim
-&gt; SDim vocabDim
-&gt; ModelSpec
     (GLinearF
        'WithoutBias gradient device dataType inputEmbedDim vocabDim)
forall (hasBias :: HasBias) (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (inputDim :: Dim (Name Symbol) (Size Nat))
       (outputDim :: Dim (Name Symbol) (Size Nat)).
SHasBias hasBias
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim inputDim
-&gt; SDim outputDim
-&gt; ModelSpec
     (GLinearF hasBias gradient device dataType inputDim outputDim)
</span><a href="Torch.GraduallyTyped.NN.Linear.html#linearSpec"><span class="hs-identifier hs-var">linearSpec</span></a></span><span> </span><span class="annot"><span class="annottext">SHasBias 'WithoutBias
</span><a href="Torch.GraduallyTyped.NN.Type.html#SWithoutBias"><span class="hs-identifier hs-var">SWithoutBias</span></a></span><span> </span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679651907"><span class="hs-identifier hs-var">gradient</span></a></span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679651906"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679651905"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679651904"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim vocabDim
</span><a href="#local-6989586621679651903"><span class="hs-identifier hs-var">vocabDim</span></a></span><span>
</span><span id="line-283"></span><span>    </span><span id="local-6989586621679651883"><span class="annot"><span class="annottext">linearWithBiasSpec' :: ModelSpec
  (GLinearF
     'WithBias gradient device dataType inputEmbedDim vocabDim)
</span><a href="#local-6989586621679651883"><span class="hs-identifier hs-var hs-var">linearWithBiasSpec'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SHasBias 'WithBias
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim inputEmbedDim
-&gt; SDim vocabDim
-&gt; ModelSpec
     (GLinearF
        'WithBias gradient device dataType inputEmbedDim vocabDim)
forall (hasBias :: HasBias) (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (inputDim :: Dim (Name Symbol) (Size Nat))
       (outputDim :: Dim (Name Symbol) (Size Nat)).
SHasBias hasBias
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim inputDim
-&gt; SDim outputDim
-&gt; ModelSpec
     (GLinearF hasBias gradient device dataType inputDim outputDim)
</span><a href="Torch.GraduallyTyped.NN.Linear.html#linearSpec"><span class="hs-identifier hs-var">linearSpec</span></a></span><span> </span><span class="annot"><span class="annottext">SHasBias 'WithBias
</span><a href="Torch.GraduallyTyped.NN.Type.html#SWithBias"><span class="hs-identifier hs-var">SWithBias</span></a></span><span> </span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679651907"><span class="hs-identifier hs-var">gradient</span></a></span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679651906"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679651905"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679651904"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim vocabDim
</span><a href="#local-6989586621679651903"><span class="hs-identifier hs-var">vocabDim</span></a></span><span>
</span><span id="line-284"></span><span>
</span><span id="line-285"></span><span id="local-6989586621679651864"><span id="local-6989586621679651865"><span id="local-6989586621679651866"><span id="local-6989586621679651867"><span id="local-6989586621679651868"><span id="local-6989586621679651869"><span id="local-6989586621679651870"><span class="hs-keyword">instance</span><span>
</span><span id="line-286"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651870"><span class="hs-identifier hs-type">dense</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651869"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651870"><span class="hs-identifier hs-type">dense</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651869"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-287"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651868"><span class="hs-identifier hs-type">activation</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651869"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651868"><span class="hs-identifier hs-type">activation</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651869"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-288"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651867"><span class="hs-identifier hs-type">layerNorm</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651869"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651867"><span class="hs-identifier hs-type">layerNorm</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651869"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-289"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651866"><span class="hs-identifier hs-type">decoder</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651869"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651866"><span class="hs-identifier hs-type">decoder</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651869"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-290"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651865"><span class="hs-identifier hs-type">bias</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651869"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651865"><span class="hs-identifier hs-type">bias</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651869"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-291"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-292"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span>
</span><span id="line-293"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#GLMHead"><span class="hs-identifier hs-type">GLMHead</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651864"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651870"><span class="hs-identifier hs-type">dense</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651868"><span class="hs-identifier hs-type">activation</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651867"><span class="hs-identifier hs-type">layerNorm</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651866"><span class="hs-identifier hs-type">decoder</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651865"><span class="hs-identifier hs-type">bias</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-294"></span><span>    </span><span class="annot"><a href="#local-6989586621679651869"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-295"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#GLMHead"><span class="hs-identifier hs-type">GLMHead</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651864"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651870"><span class="hs-identifier hs-type">dense</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651868"><span class="hs-identifier hs-type">activation</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651867"><span class="hs-identifier hs-type">layerNorm</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651866"><span class="hs-identifier hs-type">decoder</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651865"><span class="hs-identifier hs-type">bias</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-296"></span><span>    </span><span class="annot"><a href="#local-6989586621679651869"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-297"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-298"></span><span>  </span><span id="local-6989586621679651861"><span class="annot"><span class="annottext">initialize :: ModelSpec
  (GLMHead inputEmbedDim dense activation layerNorm decoder bias)
-&gt; Generator generatorDevice
-&gt; m (GLMHead
        inputEmbedDim dense activation layerNorm decoder bias,
      Generator generatorDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#initialize"><span class="hs-identifier hs-var hs-var hs-var hs-var">initialize</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#GLMHead"><span class="hs-identifier hs-type">GLMHead</span></a></span><span> </span><span id="local-6989586621679651859"><span class="annot"><a href="#local-6989586621679651859"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679651858"><span class="annot"><a href="#local-6989586621679651858"><span class="hs-identifier hs-var">denseSpec</span></a></span></span><span> </span><span id="local-6989586621679651857"><span class="annot"><a href="#local-6989586621679651857"><span class="hs-identifier hs-var">activationSpec</span></a></span></span><span> </span><span id="local-6989586621679651856"><span class="annot"><a href="#local-6989586621679651856"><span class="hs-identifier hs-var">layerNormSpec</span></a></span></span><span> </span><span id="local-6989586621679651855"><span class="annot"><a href="#local-6989586621679651855"><span class="hs-identifier hs-var">decoderSpec</span></a></span></span><span> </span><span id="local-6989586621679651854"><span class="annot"><a href="#local-6989586621679651854"><span class="hs-identifier hs-var">biasSpec</span></a></span></span><span> </span><span id="local-6989586621679651853"><span class="annot"><a href="#local-6989586621679651853"><span class="hs-identifier hs-var">hasScaling</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-299"></span><span>    </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679651852"><span class="annot"><span class="annottext">dense :: IxStateT
  m (Generator generatorDevice) (Generator generatorDevice) dense
</span><a href="#local-6989586621679651852"><span class="hs-identifier hs-var hs-var">dense</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(Generator generatorDevice -&gt; m (dense, Generator generatorDevice))
-&gt; IxStateT
     m (Generator generatorDevice) (Generator generatorDevice) dense
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator generatorDevice
  -&gt; m (dense, Generator generatorDevice))
 -&gt; IxStateT
      m (Generator generatorDevice) (Generator generatorDevice) dense)
-&gt; (ModelSpec dense
    -&gt; Generator generatorDevice
    -&gt; m (dense, Generator generatorDevice))
-&gt; ModelSpec dense
-&gt; IxStateT
     m (Generator generatorDevice) (Generator generatorDevice) dense
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">ModelSpec dense
-&gt; Generator generatorDevice
-&gt; m (dense, Generator generatorDevice)
forall model (generatorDevice :: Device (DeviceType Nat)) output
       (generatorOutputDevice :: Device (DeviceType Nat)) (m :: * -&gt; *).
(HasInitialize model generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
ModelSpec model
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#initialize"><span class="hs-identifier hs-var">initialize</span></a></span><span> </span><span class="annot"><span class="annottext">(ModelSpec dense
 -&gt; IxStateT
      m (Generator generatorDevice) (Generator generatorDevice) dense)
-&gt; ModelSpec dense
-&gt; IxStateT
     m (Generator generatorDevice) (Generator generatorDevice) dense
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">ModelSpec dense
</span><a href="#local-6989586621679651858"><span class="hs-identifier hs-var">denseSpec</span></a></span><span>
</span><span id="line-300"></span><span>        </span><span id="local-6989586621679651849"><span class="annot"><span class="annottext">activation :: IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorDevice)
  activation
</span><a href="#local-6989586621679651849"><span class="hs-identifier hs-var hs-var">activation</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(Generator generatorDevice
 -&gt; m (activation, Generator generatorDevice))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     activation
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator generatorDevice
  -&gt; m (activation, Generator generatorDevice))
 -&gt; IxStateT
      m
      (Generator generatorDevice)
      (Generator generatorDevice)
      activation)
-&gt; (ModelSpec activation
    -&gt; Generator generatorDevice
    -&gt; m (activation, Generator generatorDevice))
-&gt; ModelSpec activation
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     activation
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">ModelSpec activation
-&gt; Generator generatorDevice
-&gt; m (activation, Generator generatorDevice)
forall model (generatorDevice :: Device (DeviceType Nat)) output
       (generatorOutputDevice :: Device (DeviceType Nat)) (m :: * -&gt; *).
(HasInitialize model generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
ModelSpec model
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#initialize"><span class="hs-identifier hs-var">initialize</span></a></span><span> </span><span class="annot"><span class="annottext">(ModelSpec activation
 -&gt; IxStateT
      m
      (Generator generatorDevice)
      (Generator generatorDevice)
      activation)
-&gt; ModelSpec activation
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     activation
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">ModelSpec activation
</span><a href="#local-6989586621679651857"><span class="hs-identifier hs-var">activationSpec</span></a></span><span>
</span><span id="line-301"></span><span>        </span><span id="local-6989586621679651848"><span class="annot"><span class="annottext">layerNorm :: IxStateT
  m (Generator generatorDevice) (Generator generatorDevice) layerNorm
</span><a href="#local-6989586621679651848"><span class="hs-identifier hs-var hs-var">layerNorm</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(Generator generatorDevice
 -&gt; m (layerNorm, Generator generatorDevice))
-&gt; IxStateT
     m (Generator generatorDevice) (Generator generatorDevice) layerNorm
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator generatorDevice
  -&gt; m (layerNorm, Generator generatorDevice))
 -&gt; IxStateT
      m
      (Generator generatorDevice)
      (Generator generatorDevice)
      layerNorm)
-&gt; (ModelSpec layerNorm
    -&gt; Generator generatorDevice
    -&gt; m (layerNorm, Generator generatorDevice))
-&gt; ModelSpec layerNorm
-&gt; IxStateT
     m (Generator generatorDevice) (Generator generatorDevice) layerNorm
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">ModelSpec layerNorm
-&gt; Generator generatorDevice
-&gt; m (layerNorm, Generator generatorDevice)
forall model (generatorDevice :: Device (DeviceType Nat)) output
       (generatorOutputDevice :: Device (DeviceType Nat)) (m :: * -&gt; *).
(HasInitialize model generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
ModelSpec model
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#initialize"><span class="hs-identifier hs-var">initialize</span></a></span><span> </span><span class="annot"><span class="annottext">(ModelSpec layerNorm
 -&gt; IxStateT
      m
      (Generator generatorDevice)
      (Generator generatorDevice)
      layerNorm)
-&gt; ModelSpec layerNorm
-&gt; IxStateT
     m (Generator generatorDevice) (Generator generatorDevice) layerNorm
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">ModelSpec layerNorm
</span><a href="#local-6989586621679651856"><span class="hs-identifier hs-var">layerNormSpec</span></a></span><span>
</span><span id="line-302"></span><span>        </span><span id="local-6989586621679651847"><span class="annot"><span class="annottext">decoder :: IxStateT
  m (Generator generatorDevice) (Generator generatorDevice) decoder
</span><a href="#local-6989586621679651847"><span class="hs-identifier hs-var hs-var">decoder</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(Generator generatorDevice
 -&gt; m (decoder, Generator generatorDevice))
-&gt; IxStateT
     m (Generator generatorDevice) (Generator generatorDevice) decoder
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator generatorDevice
  -&gt; m (decoder, Generator generatorDevice))
 -&gt; IxStateT
      m (Generator generatorDevice) (Generator generatorDevice) decoder)
-&gt; (ModelSpec decoder
    -&gt; Generator generatorDevice
    -&gt; m (decoder, Generator generatorDevice))
-&gt; ModelSpec decoder
-&gt; IxStateT
     m (Generator generatorDevice) (Generator generatorDevice) decoder
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">ModelSpec decoder
-&gt; Generator generatorDevice
-&gt; m (decoder, Generator generatorDevice)
forall model (generatorDevice :: Device (DeviceType Nat)) output
       (generatorOutputDevice :: Device (DeviceType Nat)) (m :: * -&gt; *).
(HasInitialize model generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
ModelSpec model
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#initialize"><span class="hs-identifier hs-var">initialize</span></a></span><span> </span><span class="annot"><span class="annottext">(ModelSpec decoder
 -&gt; IxStateT
      m (Generator generatorDevice) (Generator generatorDevice) decoder)
-&gt; ModelSpec decoder
-&gt; IxStateT
     m (Generator generatorDevice) (Generator generatorDevice) decoder
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">ModelSpec decoder
</span><a href="#local-6989586621679651855"><span class="hs-identifier hs-var">decoderSpec</span></a></span><span>
</span><span id="line-303"></span><span>        </span><span id="local-6989586621679651846"><span class="annot"><span class="annottext">bias :: IxStateT
  m (Generator generatorDevice) (Generator generatorDevice) bias
</span><a href="#local-6989586621679651846"><span class="hs-identifier hs-var hs-var">bias</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(Generator generatorDevice -&gt; m (bias, Generator generatorDevice))
-&gt; IxStateT
     m (Generator generatorDevice) (Generator generatorDevice) bias
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator generatorDevice -&gt; m (bias, Generator generatorDevice))
 -&gt; IxStateT
      m (Generator generatorDevice) (Generator generatorDevice) bias)
-&gt; (ModelSpec bias
    -&gt; Generator generatorDevice
    -&gt; m (bias, Generator generatorDevice))
-&gt; ModelSpec bias
-&gt; IxStateT
     m (Generator generatorDevice) (Generator generatorDevice) bias
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">ModelSpec bias
-&gt; Generator generatorDevice -&gt; m (bias, Generator generatorDevice)
forall model (generatorDevice :: Device (DeviceType Nat)) output
       (generatorOutputDevice :: Device (DeviceType Nat)) (m :: * -&gt; *).
(HasInitialize model generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
ModelSpec model
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#initialize"><span class="hs-identifier hs-var">initialize</span></a></span><span> </span><span class="annot"><span class="annottext">(ModelSpec bias
 -&gt; IxStateT
      m (Generator generatorDevice) (Generator generatorDevice) bias)
-&gt; ModelSpec bias
-&gt; IxStateT
     m (Generator generatorDevice) (Generator generatorDevice) bias
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">ModelSpec bias
</span><a href="#local-6989586621679651854"><span class="hs-identifier hs-var">biasSpec</span></a></span><span>
</span><span id="line-304"></span><span>     </span><span class="hs-keyword">in</span><span> </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorDevice)
  (GLMHead inputEmbedDim dense activation layerNorm decoder bias)
-&gt; Generator generatorDevice
-&gt; m (GLMHead
        inputEmbedDim dense activation layerNorm decoder bias,
      Generator generatorDevice)
forall (m :: * -&gt; *) i j a. IxStateT m i j a -&gt; i -&gt; m (a, j)
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var hs-var">runIxStateT</span></a></span><span>
</span><span id="line-305"></span><span>          </span><span class="hs-special">(</span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
-&gt; dense
-&gt; activation
-&gt; layerNorm
-&gt; decoder
-&gt; bias
-&gt; LMHeadHasScaling
-&gt; GLMHead inputEmbedDim dense activation layerNorm decoder bias
forall (inputEmbedDim :: Dim (Name Symbol) (Size Nat)) dense
       activation layerNorm decoder bias.
SDim inputEmbedDim
-&gt; dense
-&gt; activation
-&gt; layerNorm
-&gt; decoder
-&gt; bias
-&gt; LMHeadHasScaling
-&gt; GLMHead inputEmbedDim dense activation layerNorm decoder bias
</span><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#GLMHead"><span class="hs-identifier hs-var">GLMHead</span></a></span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679651859"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span>
</span><span id="line-306"></span><span>              </span><span class="annot"><span class="annottext">(dense
 -&gt; activation
 -&gt; layerNorm
 -&gt; decoder
 -&gt; bias
 -&gt; LMHeadHasScaling
 -&gt; GLMHead inputEmbedDim dense activation layerNorm decoder bias)
-&gt; IxStateT
     m (Generator generatorDevice) (Generator generatorDevice) dense
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     (activation
      -&gt; layerNorm
      -&gt; decoder
      -&gt; bias
      -&gt; LMHeadHasScaling
      -&gt; GLMHead inputEmbedDim dense activation layerNorm decoder bias)
forall k1 k2 (f :: k1 -&gt; k2 -&gt; * -&gt; *) a b (j :: k1) (k3 :: k2).
IxFunctor f =&gt;
(a -&gt; b) -&gt; f j k3 a -&gt; f j k3 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&lt;&lt;$&gt;&gt;</span></a></span><span> </span><span class="annot"><span class="annottext">IxStateT
  m (Generator generatorDevice) (Generator generatorDevice) dense
</span><a href="#local-6989586621679651852"><span class="hs-identifier hs-var">dense</span></a></span><span>
</span><span id="line-307"></span><span>              </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorDevice)
  (activation
   -&gt; layerNorm
   -&gt; decoder
   -&gt; bias
   -&gt; LMHeadHasScaling
   -&gt; GLMHead inputEmbedDim dense activation layerNorm decoder bias)
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     activation
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     (layerNorm
      -&gt; decoder
      -&gt; bias
      -&gt; LMHeadHasScaling
      -&gt; GLMHead inputEmbedDim dense activation layerNorm decoder bias)
forall k1 (f :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a b
       (k2 :: k1).
IxApplicative f =&gt;
f i j (a -&gt; b) -&gt; f j k2 a -&gt; f i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&lt;&lt;*&gt;&gt;</span></a></span><span> </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorDevice)
  activation
</span><a href="#local-6989586621679651849"><span class="hs-identifier hs-var">activation</span></a></span><span>
</span><span id="line-308"></span><span>              </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorDevice)
  (layerNorm
   -&gt; decoder
   -&gt; bias
   -&gt; LMHeadHasScaling
   -&gt; GLMHead inputEmbedDim dense activation layerNorm decoder bias)
-&gt; IxStateT
     m (Generator generatorDevice) (Generator generatorDevice) layerNorm
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     (decoder
      -&gt; bias
      -&gt; LMHeadHasScaling
      -&gt; GLMHead inputEmbedDim dense activation layerNorm decoder bias)
forall k1 (f :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a b
       (k2 :: k1).
IxApplicative f =&gt;
f i j (a -&gt; b) -&gt; f j k2 a -&gt; f i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&lt;&lt;*&gt;&gt;</span></a></span><span> </span><span class="annot"><span class="annottext">IxStateT
  m (Generator generatorDevice) (Generator generatorDevice) layerNorm
</span><a href="#local-6989586621679651848"><span class="hs-identifier hs-var">layerNorm</span></a></span><span>
</span><span id="line-309"></span><span>              </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorDevice)
  (decoder
   -&gt; bias
   -&gt; LMHeadHasScaling
   -&gt; GLMHead inputEmbedDim dense activation layerNorm decoder bias)
-&gt; IxStateT
     m (Generator generatorDevice) (Generator generatorDevice) decoder
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     (bias
      -&gt; LMHeadHasScaling
      -&gt; GLMHead inputEmbedDim dense activation layerNorm decoder bias)
forall k1 (f :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a b
       (k2 :: k1).
IxApplicative f =&gt;
f i j (a -&gt; b) -&gt; f j k2 a -&gt; f i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&lt;&lt;*&gt;&gt;</span></a></span><span> </span><span class="annot"><span class="annottext">IxStateT
  m (Generator generatorDevice) (Generator generatorDevice) decoder
</span><a href="#local-6989586621679651847"><span class="hs-identifier hs-var">decoder</span></a></span><span>
</span><span id="line-310"></span><span>              </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorDevice)
  (bias
   -&gt; LMHeadHasScaling
   -&gt; GLMHead inputEmbedDim dense activation layerNorm decoder bias)
-&gt; IxStateT
     m (Generator generatorDevice) (Generator generatorDevice) bias
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     (LMHeadHasScaling
      -&gt; GLMHead inputEmbedDim dense activation layerNorm decoder bias)
forall k1 (f :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a b
       (k2 :: k1).
IxApplicative f =&gt;
f i j (a -&gt; b) -&gt; f j k2 a -&gt; f i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&lt;&lt;*&gt;&gt;</span></a></span><span> </span><span class="annot"><span class="annottext">IxStateT
  m (Generator generatorDevice) (Generator generatorDevice) bias
</span><a href="#local-6989586621679651846"><span class="hs-identifier hs-var">bias</span></a></span><span>
</span><span id="line-311"></span><span>              </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorDevice)
  (LMHeadHasScaling
   -&gt; GLMHead inputEmbedDim dense activation layerNorm decoder bias)
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     LMHeadHasScaling
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     (GLMHead inputEmbedDim dense activation layerNorm decoder bias)
forall k1 (f :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a b
       (k2 :: k1).
IxApplicative f =&gt;
f i j (a -&gt; b) -&gt; f j k2 a -&gt; f i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&lt;&lt;*&gt;&gt;</span></a></span><span> </span><span class="annot"><span class="annottext">LMHeadHasScaling
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     LMHeadHasScaling
forall k (m :: k -&gt; k -&gt; * -&gt; *) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">LMHeadHasScaling
</span><a href="#local-6989586621679651853"><span class="hs-identifier hs-var">hasScaling</span></a></span><span>
</span><span id="line-312"></span><span>          </span><span class="hs-special">)</span></span></span></span></span></span></span></span><span>
</span><span id="line-313"></span><span>
</span><span id="line-314"></span><span id="local-6989586621679651843"><span class="hs-keyword">instance</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#GBias"><span class="hs-identifier hs-type">GBias</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679651843"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#GBias"><span class="hs-identifier hs-type">GBias</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679651843"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-315"></span><span>  </span><span id="local-6989586621679651841"><span class="annot"><span class="annottext">initialize :: ModelSpec (GBias ())
-&gt; Generator generatorDevice
-&gt; m (GBias (), Generator generatorDevice)
</span><a href="#local-6989586621679651841"><span class="hs-identifier hs-var hs-var hs-var hs-var">initialize</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#GBias"><span class="hs-identifier hs-type">GBias</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span id="local-6989586621679651840"><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679651840"><span class="hs-identifier hs-var">g</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(GBias (), Generator generatorDevice)
-&gt; m (GBias (), Generator generatorDevice)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">() -&gt; GBias ()
forall bias. bias -&gt; GBias bias
</span><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#GBias"><span class="hs-identifier hs-var">GBias</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679651840"><span class="hs-identifier hs-var">g</span></a></span><span class="hs-special">)</span></span><span>
</span><span id="line-316"></span><span>
</span><span id="line-317"></span><span id="local-6989586621679651834"><span id="local-6989586621679651835"><span id="local-6989586621679651836"><span id="local-6989586621679651837"><span id="local-6989586621679651838"><span id="local-6989586621679651839"><span class="hs-keyword">instance</span><span>
</span><span id="line-318"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span>
</span><span id="line-319"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#GBias"><span class="hs-identifier hs-type">GBias</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651839"><span class="hs-identifier hs-type">biasGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651838"><span class="hs-identifier hs-type">biasLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651837"><span class="hs-identifier hs-type">biasDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651836"><span class="hs-identifier hs-type">biasDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651835"><span class="hs-identifier hs-type">biasShape</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-320"></span><span>    </span><span class="annot"><a href="#local-6989586621679651834"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-321"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#GBias"><span class="hs-identifier hs-type">GBias</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651839"><span class="hs-identifier hs-type">biasGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651838"><span class="hs-identifier hs-type">biasLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651837"><span class="hs-identifier hs-type">biasDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651836"><span class="hs-identifier hs-type">biasDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651835"><span class="hs-identifier hs-type">biasShape</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-322"></span><span>    </span><span class="annot"><a href="#local-6989586621679651834"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-323"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-324"></span><span>  </span><span id="local-6989586621679651832"><span class="annot"><span class="annottext">initialize :: ModelSpec
  (GBias
     (Tensor biasGradient biasLayout biasDevice biasDataType biasShape))
-&gt; Generator generatorDevice
-&gt; m (GBias
        (Tensor biasGradient biasLayout biasDevice biasDataType biasShape),
      Generator generatorDevice)
</span><a href="#local-6989586621679651832"><span class="hs-identifier hs-var hs-var hs-var hs-var">initialize</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#GBias"><span class="hs-identifier hs-type">GBias</span></a></span><span> </span><span id="local-6989586621679651831"><span class="annot"><a href="#local-6989586621679651831"><span class="hs-identifier hs-var">biasSpec</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-325"></span><span>    </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorDevice)
  (GBias
     (Tensor biasGradient biasLayout biasDevice biasDataType biasShape))
-&gt; Generator generatorDevice
-&gt; m (GBias
        (Tensor biasGradient biasLayout biasDevice biasDataType biasShape),
      Generator generatorDevice)
forall (m :: * -&gt; *) i j a. IxStateT m i j a -&gt; i -&gt; m (a, j)
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var hs-var">runIxStateT</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Tensor biasGradient biasLayout biasDevice biasDataType biasShape
-&gt; GBias
     (Tensor biasGradient biasLayout biasDevice biasDataType biasShape)
forall bias. bias -&gt; GBias bias
</span><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#GBias"><span class="hs-identifier hs-var">GBias</span></a></span><span> </span><span class="annot"><span class="annottext">(Tensor biasGradient biasLayout biasDevice biasDataType biasShape
 -&gt; GBias
      (Tensor biasGradient biasLayout biasDevice biasDataType biasShape))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     (Tensor biasGradient biasLayout biasDevice biasDataType biasShape)
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     (GBias
        (Tensor biasGradient biasLayout biasDevice biasDataType biasShape))
forall k1 k2 (f :: k1 -&gt; k2 -&gt; * -&gt; *) a b (j :: k1) (k3 :: k2).
IxFunctor f =&gt;
(a -&gt; b) -&gt; f j k3 a -&gt; f j k3 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&lt;&lt;$&gt;&gt;</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">m (Tensor
     biasGradient biasLayout biasDevice biasDataType biasShape)
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     (Tensor biasGradient biasLayout biasDevice biasDataType biasShape)
forall k (t :: (* -&gt; *) -&gt; k -&gt; k -&gt; * -&gt; *) (m :: * -&gt; *) a
       (i :: k).
(IxMonadTrans t, Monad m) =&gt;
m a -&gt; t m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ilift</span></a></span><span> </span><span class="annot"><span class="annottext">(m (Tensor
      biasGradient biasLayout biasDevice biasDataType biasShape)
 -&gt; IxStateT
      m
      (Generator generatorDevice)
      (Generator generatorDevice)
      (Tensor biasGradient biasLayout biasDevice biasDataType biasShape))
-&gt; (TensorSpec
      biasGradient biasLayout biasDevice biasDataType biasShape
    -&gt; m (Tensor
            biasGradient biasLayout biasDevice biasDataType biasShape))
-&gt; TensorSpec
     biasGradient biasLayout biasDevice biasDataType biasShape
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     (Tensor biasGradient biasLayout biasDevice biasDataType biasShape)
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">TensorSpec
  biasGradient biasLayout biasDevice biasDataType biasShape
-&gt; m (Tensor
        biasGradient biasLayout biasDevice biasDataType biasShape)
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]) (m :: * -&gt; *).
MonadThrow m =&gt;
TensorSpec gradient layout device dataType shape
-&gt; m (Tensor gradient layout device dataType shape)
</span><a href="Torch.GraduallyTyped.Tensor.Creation.html#sZeros"><span class="hs-identifier hs-var">sZeros</span></a></span><span> </span><span class="annot"><span class="annottext">(TensorSpec
   biasGradient biasLayout biasDevice biasDataType biasShape
 -&gt; IxStateT
      m
      (Generator generatorDevice)
      (Generator generatorDevice)
      (Tensor biasGradient biasLayout biasDevice biasDataType biasShape))
-&gt; TensorSpec
     biasGradient biasLayout biasDevice biasDataType biasShape
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     (Tensor biasGradient biasLayout biasDevice biasDataType biasShape)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">TensorSpec
  biasGradient biasLayout biasDevice biasDataType biasShape
</span><a href="#local-6989586621679651831"><span class="hs-identifier hs-var">biasSpec</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span></span></span></span></span></span></span><span>
</span><span id="line-326"></span><span>
</span><span id="line-327"></span><span id="local-6989586621679651825"><span id="local-6989586621679651826"><span id="local-6989586621679651827"><span id="local-6989586621679651828"><span id="local-6989586621679651829"><span id="local-6989586621679651830"><span class="hs-keyword">instance</span><span>
</span><span id="line-328"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span>
</span><span id="line-329"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#GBias"><span class="hs-identifier hs-type">GBias</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-type">NamedModel</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651830"><span class="hs-identifier hs-type">biasGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651829"><span class="hs-identifier hs-type">biasLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651828"><span class="hs-identifier hs-type">biasDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651827"><span class="hs-identifier hs-type">biasDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651826"><span class="hs-identifier hs-type">biasShape</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-330"></span><span>    </span><span class="annot"><a href="#local-6989586621679651825"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-331"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#GBias"><span class="hs-identifier hs-type">GBias</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-type">NamedModel</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651830"><span class="hs-identifier hs-type">biasGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651829"><span class="hs-identifier hs-type">biasLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651828"><span class="hs-identifier hs-type">biasDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651827"><span class="hs-identifier hs-type">biasDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651826"><span class="hs-identifier hs-type">biasShape</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-332"></span><span>    </span><span class="annot"><a href="#local-6989586621679651825"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-333"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-334"></span><span>  </span><span id="local-6989586621679651823"><span class="annot"><span class="annottext">initialize :: ModelSpec
  (GBias
     (NamedModel
        (Tensor
           biasGradient biasLayout biasDevice biasDataType biasShape)))
-&gt; Generator generatorDevice
-&gt; m (GBias
        (NamedModel
           (Tensor
              biasGradient biasLayout biasDevice biasDataType biasShape)),
      Generator generatorDevice)
</span><a href="#local-6989586621679651823"><span class="hs-identifier hs-var hs-var hs-var hs-var">initialize</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#GBias"><span class="hs-identifier hs-type">GBias</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-type">NamedModel</span></a></span><span> </span><span id="local-6989586621679651822"><span class="annot"><a href="#local-6989586621679651822"><span class="hs-identifier hs-var">biasName</span></a></span></span><span> </span><span id="local-6989586621679651821"><span class="annot"><a href="#local-6989586621679651821"><span class="hs-identifier hs-var">biasSpec</span></a></span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-335"></span><span>    </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorDevice)
  (GBias
     (NamedModel
        (Tensor
           biasGradient biasLayout biasDevice biasDataType biasShape)))
-&gt; Generator generatorDevice
-&gt; m (GBias
        (NamedModel
           (Tensor
              biasGradient biasLayout biasDevice biasDataType biasShape)),
      Generator generatorDevice)
forall (m :: * -&gt; *) i j a. IxStateT m i j a -&gt; i -&gt; m (a, j)
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var hs-var">runIxStateT</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">NamedModel
  (Tensor biasGradient biasLayout biasDevice biasDataType biasShape)
-&gt; GBias
     (NamedModel
        (Tensor biasGradient biasLayout biasDevice biasDataType biasShape))
forall bias. bias -&gt; GBias bias
</span><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#GBias"><span class="hs-identifier hs-var">GBias</span></a></span><span> </span><span class="annot"><span class="annottext">(NamedModel
   (Tensor biasGradient biasLayout biasDevice biasDataType biasShape)
 -&gt; GBias
      (NamedModel
         (Tensor
            biasGradient biasLayout biasDevice biasDataType biasShape)))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     (NamedModel
        (Tensor biasGradient biasLayout biasDevice biasDataType biasShape))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     (GBias
        (NamedModel
           (Tensor
              biasGradient biasLayout biasDevice biasDataType biasShape)))
forall k1 k2 (f :: k1 -&gt; k2 -&gt; * -&gt; *) a b (j :: k1) (k3 :: k2).
IxFunctor f =&gt;
(a -&gt; b) -&gt; f j k3 a -&gt; f j k3 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&lt;&lt;$&gt;&gt;</span></a></span><span> </span><span class="annot"><span class="annottext">m (NamedModel
     (Tensor biasGradient biasLayout biasDevice biasDataType biasShape))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     (NamedModel
        (Tensor biasGradient biasLayout biasDevice biasDataType biasShape))
forall k (t :: (* -&gt; *) -&gt; k -&gt; k -&gt; * -&gt; *) (m :: * -&gt; *) a
       (i :: k).
(IxMonadTrans t, Monad m) =&gt;
m a -&gt; t m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ilift</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Text
-&gt; Tensor biasGradient biasLayout biasDevice biasDataType biasShape
-&gt; NamedModel
     (Tensor biasGradient biasLayout biasDevice biasDataType biasShape)
forall model. Text -&gt; model -&gt; NamedModel model
</span><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-var">NamedModel</span></a></span><span> </span><span class="annot"><span class="annottext">Text
</span><a href="#local-6989586621679651822"><span class="hs-identifier hs-var">biasName</span></a></span><span> </span><span class="annot"><span class="annottext">(Tensor biasGradient biasLayout biasDevice biasDataType biasShape
 -&gt; NamedModel
      (Tensor biasGradient biasLayout biasDevice biasDataType biasShape))
-&gt; m (Tensor
        biasGradient biasLayout biasDevice biasDataType biasShape)
-&gt; m (NamedModel
        (Tensor biasGradient biasLayout biasDevice biasDataType biasShape))
forall (f :: * -&gt; *) a b. Functor f =&gt; (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;$&gt;</span></span><span> </span><span class="annot"><span class="annottext">TensorSpec
  biasGradient biasLayout biasDevice biasDataType biasShape
-&gt; m (Tensor
        biasGradient biasLayout biasDevice biasDataType biasShape)
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]) (m :: * -&gt; *).
MonadThrow m =&gt;
TensorSpec gradient layout device dataType shape
-&gt; m (Tensor gradient layout device dataType shape)
</span><a href="Torch.GraduallyTyped.Tensor.Creation.html#sZeros"><span class="hs-identifier hs-var">sZeros</span></a></span><span> </span><span class="annot"><span class="annottext">TensorSpec
  biasGradient biasLayout biasDevice biasDataType biasShape
</span><a href="#local-6989586621679651821"><span class="hs-identifier hs-var">biasSpec</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span></span></span></span></span></span></span><span>
</span><span id="line-336"></span><span>
</span><span id="line-337"></span><span id="local-6989586621679651814"><span id="local-6989586621679651815"><span id="local-6989586621679651816"><span id="local-6989586621679651817"><span id="local-6989586621679651818"><span id="local-6989586621679651819"><span class="hs-keyword">instance</span><span>
</span><span id="line-338"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasStateDict"><span class="hs-identifier hs-type">HasStateDict</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651819"><span class="hs-identifier hs-type">dense</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-339"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasStateDict"><span class="hs-identifier hs-type">HasStateDict</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651818"><span class="hs-identifier hs-type">activation</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-340"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasStateDict"><span class="hs-identifier hs-type">HasStateDict</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651817"><span class="hs-identifier hs-type">layerNorm</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-341"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasStateDict"><span class="hs-identifier hs-type">HasStateDict</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651816"><span class="hs-identifier hs-type">decoder</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-342"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasStateDict"><span class="hs-identifier hs-type">HasStateDict</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651815"><span class="hs-identifier hs-type">bias</span></a></span><span>
</span><span id="line-343"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-344"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasStateDict"><span class="hs-identifier hs-type">HasStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#GLMHead"><span class="hs-identifier hs-type">GLMHead</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651814"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651819"><span class="hs-identifier hs-type">dense</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651818"><span class="hs-identifier hs-type">activation</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651817"><span class="hs-identifier hs-type">layerNorm</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651816"><span class="hs-identifier hs-type">decoder</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651815"><span class="hs-identifier hs-type">bias</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-345"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-346"></span><span>  </span><span id="local-6989586621679651810"><span class="annot"><span class="annottext">fromStateDict :: ModelSpec
  (GLMHead inputEmbedDim dense activation layerNorm decoder bias)
-&gt; Text
-&gt; m (GLMHead
        inputEmbedDim dense activation layerNorm decoder bias)
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var hs-var hs-var hs-var">fromStateDict</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#GLMHead"><span class="hs-identifier hs-type">GLMHead</span></a></span><span> </span><span id="local-6989586621679651808"><span class="annot"><a href="#local-6989586621679651808"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679651807"><span class="annot"><a href="#local-6989586621679651807"><span class="hs-identifier hs-var">denseSpec</span></a></span></span><span> </span><span id="local-6989586621679651806"><span class="annot"><a href="#local-6989586621679651806"><span class="hs-identifier hs-var">activationSpec</span></a></span></span><span> </span><span id="local-6989586621679651805"><span class="annot"><a href="#local-6989586621679651805"><span class="hs-identifier hs-var">layerNormSpec</span></a></span></span><span> </span><span id="local-6989586621679651804"><span class="annot"><a href="#local-6989586621679651804"><span class="hs-identifier hs-var">decoderSpec</span></a></span></span><span> </span><span id="local-6989586621679651803"><span class="annot"><a href="#local-6989586621679651803"><span class="hs-identifier hs-var">biasSpec</span></a></span></span><span> </span><span id="local-6989586621679651802"><span class="annot"><a href="#local-6989586621679651802"><span class="hs-identifier hs-var">hasScaling</span></a></span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679651801"><span class="annot"><span class="annottext">Text
</span><a href="#local-6989586621679651801"><span class="hs-identifier hs-var">k</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-347"></span><span>    </span><span class="annot"><span class="annottext">SDim inputEmbedDim
-&gt; dense
-&gt; activation
-&gt; layerNorm
-&gt; decoder
-&gt; bias
-&gt; LMHeadHasScaling
-&gt; GLMHead inputEmbedDim dense activation layerNorm decoder bias
forall (inputEmbedDim :: Dim (Name Symbol) (Size Nat)) dense
       activation layerNorm decoder bias.
SDim inputEmbedDim
-&gt; dense
-&gt; activation
-&gt; layerNorm
-&gt; decoder
-&gt; bias
-&gt; LMHeadHasScaling
-&gt; GLMHead inputEmbedDim dense activation layerNorm decoder bias
</span><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#GLMHead"><span class="hs-identifier hs-var">GLMHead</span></a></span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679651808"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span>
</span><span id="line-348"></span><span>      </span><span class="annot"><span class="annottext">(dense
 -&gt; activation
 -&gt; layerNorm
 -&gt; decoder
 -&gt; bias
 -&gt; LMHeadHasScaling
 -&gt; GLMHead inputEmbedDim dense activation layerNorm decoder bias)
-&gt; m dense
-&gt; m (activation
      -&gt; layerNorm
      -&gt; decoder
      -&gt; bias
      -&gt; LMHeadHasScaling
      -&gt; GLMHead inputEmbedDim dense activation layerNorm decoder bias)
forall (f :: * -&gt; *) a b. Functor f =&gt; (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;$&gt;</span></span><span> </span><span class="annot"><span class="annottext">ModelSpec dense -&gt; Text -&gt; m dense
forall model (m :: * -&gt; *).
(HasStateDict model, MonadIO m, MonadThrow m,
 MonadState StateDict m) =&gt;
ModelSpec model -&gt; Text -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">ModelSpec dense
</span><a href="#local-6989586621679651807"><span class="hs-identifier hs-var">denseSpec</span></a></span><span> </span><span class="annot"><span class="annottext">Text
</span><a href="#local-6989586621679651801"><span class="hs-identifier hs-var">k</span></a></span><span>
</span><span id="line-349"></span><span>      </span><span class="annot"><span class="annottext">m (activation
   -&gt; layerNorm
   -&gt; decoder
   -&gt; bias
   -&gt; LMHeadHasScaling
   -&gt; GLMHead inputEmbedDim dense activation layerNorm decoder bias)
-&gt; m activation
-&gt; m (layerNorm
      -&gt; decoder
      -&gt; bias
      -&gt; LMHeadHasScaling
      -&gt; GLMHead inputEmbedDim dense activation layerNorm decoder bias)
forall (f :: * -&gt; *) a b. Applicative f =&gt; f (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;*&gt;</span></span><span> </span><span class="annot"><span class="annottext">ModelSpec activation -&gt; Text -&gt; m activation
forall model (m :: * -&gt; *).
(HasStateDict model, MonadIO m, MonadThrow m,
 MonadState StateDict m) =&gt;
ModelSpec model -&gt; Text -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">ModelSpec activation
</span><a href="#local-6989586621679651806"><span class="hs-identifier hs-var">activationSpec</span></a></span><span> </span><span class="annot"><span class="annottext">Text
</span><a href="#local-6989586621679651801"><span class="hs-identifier hs-var">k</span></a></span><span>
</span><span id="line-350"></span><span>      </span><span class="annot"><span class="annottext">m (layerNorm
   -&gt; decoder
   -&gt; bias
   -&gt; LMHeadHasScaling
   -&gt; GLMHead inputEmbedDim dense activation layerNorm decoder bias)
-&gt; m layerNorm
-&gt; m (decoder
      -&gt; bias
      -&gt; LMHeadHasScaling
      -&gt; GLMHead inputEmbedDim dense activation layerNorm decoder bias)
forall (f :: * -&gt; *) a b. Applicative f =&gt; f (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;*&gt;</span></span><span> </span><span class="annot"><span class="annottext">ModelSpec layerNorm -&gt; Text -&gt; m layerNorm
forall model (m :: * -&gt; *).
(HasStateDict model, MonadIO m, MonadThrow m,
 MonadState StateDict m) =&gt;
ModelSpec model -&gt; Text -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">ModelSpec layerNorm
</span><a href="#local-6989586621679651805"><span class="hs-identifier hs-var">layerNormSpec</span></a></span><span> </span><span class="annot"><span class="annottext">Text
</span><a href="#local-6989586621679651801"><span class="hs-identifier hs-var">k</span></a></span><span>
</span><span id="line-351"></span><span>      </span><span class="annot"><span class="annottext">m (decoder
   -&gt; bias
   -&gt; LMHeadHasScaling
   -&gt; GLMHead inputEmbedDim dense activation layerNorm decoder bias)
-&gt; m decoder
-&gt; m (bias
      -&gt; LMHeadHasScaling
      -&gt; GLMHead inputEmbedDim dense activation layerNorm decoder bias)
forall (f :: * -&gt; *) a b. Applicative f =&gt; f (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;*&gt;</span></span><span> </span><span class="annot"><span class="annottext">ModelSpec decoder -&gt; Text -&gt; m decoder
forall model (m :: * -&gt; *).
(HasStateDict model, MonadIO m, MonadThrow m,
 MonadState StateDict m) =&gt;
ModelSpec model -&gt; Text -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">ModelSpec decoder
</span><a href="#local-6989586621679651804"><span class="hs-identifier hs-var">decoderSpec</span></a></span><span> </span><span class="annot"><span class="annottext">Text
</span><a href="#local-6989586621679651801"><span class="hs-identifier hs-var">k</span></a></span><span>
</span><span id="line-352"></span><span>      </span><span class="annot"><span class="annottext">m (bias
   -&gt; LMHeadHasScaling
   -&gt; GLMHead inputEmbedDim dense activation layerNorm decoder bias)
-&gt; m bias
-&gt; m (LMHeadHasScaling
      -&gt; GLMHead inputEmbedDim dense activation layerNorm decoder bias)
forall (f :: * -&gt; *) a b. Applicative f =&gt; f (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;*&gt;</span></span><span> </span><span class="annot"><span class="annottext">ModelSpec bias -&gt; Text -&gt; m bias
forall model (m :: * -&gt; *).
(HasStateDict model, MonadIO m, MonadThrow m,
 MonadState StateDict m) =&gt;
ModelSpec model -&gt; Text -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">ModelSpec bias
</span><a href="#local-6989586621679651803"><span class="hs-identifier hs-var">biasSpec</span></a></span><span> </span><span class="annot"><span class="annottext">Text
</span><a href="#local-6989586621679651801"><span class="hs-identifier hs-var">k</span></a></span><span>
</span><span id="line-353"></span><span>      </span><span class="annot"><span class="annottext">m (LMHeadHasScaling
   -&gt; GLMHead inputEmbedDim dense activation layerNorm decoder bias)
-&gt; m LMHeadHasScaling
-&gt; m (GLMHead
        inputEmbedDim dense activation layerNorm decoder bias)
forall (f :: * -&gt; *) a b. Applicative f =&gt; f (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;*&gt;</span></span><span> </span><span class="annot"><span class="annottext">LMHeadHasScaling -&gt; m LMHeadHasScaling
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">LMHeadHasScaling
</span><a href="#local-6989586621679651802"><span class="hs-identifier hs-var">hasScaling</span></a></span><span>
</span><span id="line-354"></span><span>  </span><span id="local-6989586621679651800"><span class="annot"><span class="annottext">toStateDict :: Text
-&gt; GLMHead inputEmbedDim dense activation layerNorm decoder bias
-&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var hs-var hs-var hs-var">toStateDict</span></a></span></span><span> </span><span id="local-6989586621679651798"><span class="annot"><span class="annottext">Text
</span><a href="#local-6989586621679651798"><span class="hs-identifier hs-var">k</span></a></span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#GLMHead"><span class="hs-identifier hs-type">GLMHead</span></a></span><span> </span><span class="hs-special">{</span><span id="local-6989586621679651791"><span id="local-6989586621679651792"><span id="local-6989586621679651793"><span id="local-6989586621679651794"><span id="local-6989586621679651795"><span id="local-6989586621679651796"><span id="local-6989586621679651797"><span class="annot"><span class="annottext">dense
activation
layerNorm
decoder
bias
SDim inputEmbedDim
LMHeadHasScaling
lmHeadHasScaling :: LMHeadHasScaling
lmHeadBias :: bias
lmHeadDecoder :: decoder
lmHeadLayerNorm :: layerNorm
lmHeadActivation :: activation
lmHeadDense :: dense
lmHeadInputEmbedDim :: SDim inputEmbedDim
lmHeadHasScaling :: forall (inputEmbedDim :: Dim (Name Symbol) (Size Nat)) dense
       activation layerNorm decoder bias.
GLMHead inputEmbedDim dense activation layerNorm decoder bias
-&gt; LMHeadHasScaling
lmHeadBias :: forall (inputEmbedDim :: Dim (Name Symbol) (Size Nat)) dense
       activation layerNorm decoder bias.
GLMHead inputEmbedDim dense activation layerNorm decoder bias
-&gt; bias
lmHeadDecoder :: forall (inputEmbedDim :: Dim (Name Symbol) (Size Nat)) dense
       activation layerNorm decoder bias.
GLMHead inputEmbedDim dense activation layerNorm decoder bias
-&gt; decoder
lmHeadLayerNorm :: forall (inputEmbedDim :: Dim (Name Symbol) (Size Nat)) dense
       activation layerNorm decoder bias.
GLMHead inputEmbedDim dense activation layerNorm decoder bias
-&gt; layerNorm
lmHeadActivation :: forall (inputEmbedDim :: Dim (Name Symbol) (Size Nat)) dense
       activation layerNorm decoder bias.
GLMHead inputEmbedDim dense activation layerNorm decoder bias
-&gt; activation
lmHeadDense :: forall (inputEmbedDim :: Dim (Name Symbol) (Size Nat)) dense
       activation layerNorm decoder bias.
GLMHead inputEmbedDim dense activation layerNorm decoder bias
-&gt; dense
lmHeadInputEmbedDim :: forall (inputEmbedDim :: Dim (Name Symbol) (Size Nat)) dense
       activation layerNorm decoder bias.
GLMHead inputEmbedDim dense activation layerNorm decoder bias
-&gt; SDim inputEmbedDim
</span><a href="#local-6989586621679651791"><span class="hs-glyph hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">..</span></a></span></span></span></span></span></span></span></span><span class="hs-special">}</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-355"></span><span>    </span><span class="hs-special">(</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">Text -&gt; dense -&gt; m ()
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
Text -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">Text
</span><a href="#local-6989586621679651798"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">dense
</span><a href="#local-6989586621679651796"><span class="hs-identifier hs-var">lmHeadDense</span></a></span><span>
</span><span id="line-356"></span><span>    </span><span class="hs-special">(</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">Text -&gt; activation -&gt; m ()
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
Text -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">Text
</span><a href="#local-6989586621679651798"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">activation
</span><a href="#local-6989586621679651795"><span class="hs-identifier hs-var">lmHeadActivation</span></a></span><span>
</span><span id="line-357"></span><span>    </span><span class="hs-special">(</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">Text -&gt; layerNorm -&gt; m ()
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
Text -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">Text
</span><a href="#local-6989586621679651798"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">layerNorm
</span><a href="#local-6989586621679651794"><span class="hs-identifier hs-var">lmHeadLayerNorm</span></a></span><span>
</span><span id="line-358"></span><span>    </span><span class="hs-special">(</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">Text -&gt; decoder -&gt; m ()
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
Text -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">Text
</span><a href="#local-6989586621679651798"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">decoder
</span><a href="#local-6989586621679651793"><span class="hs-identifier hs-var">lmHeadDecoder</span></a></span><span>
</span><span id="line-359"></span><span>    </span><span class="hs-special">(</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">Text -&gt; bias -&gt; m ()
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
Text -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">Text
</span><a href="#local-6989586621679651798"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">bias
</span><a href="#local-6989586621679651792"><span class="hs-identifier hs-var">lmHeadBias</span></a></span><span>
</span><span id="line-360"></span><span>    </span><span class="annot"><span class="annottext">() -&gt; m ()
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span></span></span></span></span></span></span><span>
</span><span id="line-361"></span><span>
</span><span id="line-362"></span><span id="local-6989586621679651790"><span class="hs-keyword">instance</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasStateDict"><span class="hs-identifier hs-type">HasStateDict</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651790"><span class="hs-identifier hs-type">model</span></a></span><span> </span><span class="hs-glyph">=&gt;</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasStateDict"><span class="hs-identifier hs-type">HasStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#GBias"><span class="hs-identifier hs-type">GBias</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651790"><span class="hs-identifier hs-type">model</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-363"></span><span>  </span><span id="local-6989586621679651787"><span class="annot"><span class="annottext">fromStateDict :: ModelSpec (GBias model) -&gt; Text -&gt; m (GBias model)
</span><a href="#local-6989586621679651787"><span class="hs-identifier hs-var hs-var hs-var hs-var">fromStateDict</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#GBias"><span class="hs-identifier hs-type">GBias</span></a></span><span> </span><span id="local-6989586621679651786"><span class="annot"><a href="#local-6989586621679651786"><span class="hs-identifier hs-var">biasSpec</span></a></span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679651785"><span class="annot"><span class="annottext">Text
</span><a href="#local-6989586621679651785"><span class="hs-identifier hs-var">k</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">model -&gt; GBias model
forall bias. bias -&gt; GBias bias
</span><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#GBias"><span class="hs-identifier hs-var">GBias</span></a></span><span> </span><span class="annot"><span class="annottext">(model -&gt; GBias model) -&gt; m model -&gt; m (GBias model)
forall (f :: * -&gt; *) a b. Functor f =&gt; (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;$&gt;</span></span><span> </span><span class="annot"><span class="annottext">ModelSpec model -&gt; Text -&gt; m model
forall model (m :: * -&gt; *).
(HasStateDict model, MonadIO m, MonadThrow m,
 MonadState StateDict m) =&gt;
ModelSpec model -&gt; Text -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">ModelSpec model
</span><a href="#local-6989586621679651786"><span class="hs-identifier hs-var">biasSpec</span></a></span><span> </span><span class="annot"><span class="annottext">Text
</span><a href="#local-6989586621679651785"><span class="hs-identifier hs-var">k</span></a></span><span>
</span><span id="line-364"></span><span>  </span><span id="local-6989586621679651784"><span class="annot"><span class="annottext">toStateDict :: Text -&gt; GBias model -&gt; m ()
</span><a href="#local-6989586621679651784"><span class="hs-identifier hs-var hs-var hs-var hs-var">toStateDict</span></a></span></span><span> </span><span id="local-6989586621679651783"><span class="annot"><span class="annottext">Text
</span><a href="#local-6989586621679651783"><span class="hs-identifier hs-var">k</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#GBias"><span class="hs-identifier hs-type">GBias</span></a></span><span> </span><span id="local-6989586621679651782"><span class="annot"><span class="annottext">model
</span><a href="#local-6989586621679651782"><span class="hs-identifier hs-var">bias</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Text -&gt; model -&gt; m ()
forall model (m :: * -&gt; *).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
Text -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">Text
</span><a href="#local-6989586621679651783"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">model
</span><a href="#local-6989586621679651782"><span class="hs-identifier hs-var">bias</span></a></span></span><span>
</span><span id="line-365"></span><span>
</span><span id="line-366"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span>
</span><span id="line-367"></span><span>  </span><span id="LMHeadOutputF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadOutputF"><span class="hs-identifier hs-var">LMHeadOutputF</span></a></span></span><span>
</span><span id="line-368"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679651780"><span class="annot"><a href="#local-6989586621679651780"><span class="hs-identifier hs-type">style</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerStyle"><span class="hs-identifier hs-type">TransformerStyle</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-369"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679651779"><span class="annot"><a href="#local-6989586621679651779"><span class="hs-identifier hs-type">decoderOutput</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span class="hs-special">)</span><span>
</span><span id="line-370"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679651778"><span class="annot"><a href="#local-6989586621679651778"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#RequiresGradient"><span class="hs-identifier hs-type">RequiresGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-371"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679651777"><span class="annot"><a href="#local-6989586621679651777"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier hs-type">Device</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#DeviceType"><span class="hs-identifier hs-type">DeviceType</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-372"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679651776"><span class="annot"><a href="#local-6989586621679651776"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier hs-type">DType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-373"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679651775"><span class="annot"><a href="#local-6989586621679651775"><span class="hs-identifier hs-type">vocabDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-374"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span>
</span><span id="line-375"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-376"></span><span>  </span><span id="LMHeadOutputF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadOutputF"><span class="hs-identifier hs-var">LMHeadOutputF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#T5"><span class="hs-identifier hs-type">T5</span></a></span><span> </span><span id="local-6989586621679651774"><span class="annot"><a href="#local-6989586621679651774"><span class="hs-identifier hs-type hs-type">decoderOutput</span></a></span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="#local-6989586621679651774"><span class="hs-identifier hs-type">decoderOutput</span></a></span><span>
</span><span id="line-377"></span><span>  </span><span id="LMHeadOutputF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadOutputF"><span class="hs-identifier hs-var">LMHeadOutputF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ByT5"><span class="hs-identifier hs-type">ByT5</span></a></span><span> </span><span id="local-6989586621679651773"><span class="annot"><a href="#local-6989586621679651773"><span class="hs-identifier hs-type hs-type">decoderOutput</span></a></span></span><span> </span><span id="local-6989586621679651772"><span class="annot"><a href="#local-6989586621679651772"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679651771"><span class="annot"><a href="#local-6989586621679651771"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679651770"><span class="annot"><a href="#local-6989586621679651770"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679651769"><span class="annot"><a href="#local-6989586621679651769"><span class="hs-identifier hs-type hs-type">vocabDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadOutputF"><span class="hs-identifier hs-type">LMHeadOutputF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#T5"><span class="hs-identifier hs-type">T5</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651773"><span class="hs-identifier hs-type">decoderOutput</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651772"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651771"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651770"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651769"><span class="hs-identifier hs-type">vocabDim</span></a></span><span>
</span><span id="line-378"></span><span>  </span><span id="LMHeadOutputF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadOutputF"><span class="hs-identifier hs-var">LMHeadOutputF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span id="local-6989586621679651768"><span class="annot"><a href="#local-6989586621679651768"><span class="hs-identifier hs-type hs-type">gradient'</span></a></span></span><span> </span><span id="local-6989586621679651767"><span class="annot"><a href="#local-6989586621679651767"><span class="hs-identifier hs-type hs-type">layout'</span></a></span></span><span> </span><span id="local-6989586621679651766"><span class="annot"><a href="#local-6989586621679651766"><span class="hs-identifier hs-type hs-type">device'</span></a></span></span><span> </span><span id="local-6989586621679651765"><span class="annot"><a href="#local-6989586621679651765"><span class="hs-identifier hs-type hs-type">dataType'</span></a></span></span><span> </span><span id="local-6989586621679651764"><span class="annot"><a href="#local-6989586621679651764"><span class="hs-identifier hs-type hs-type">shape'</span></a></span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679651763"><span class="annot"><a href="#local-6989586621679651763"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679651762"><span class="annot"><a href="#local-6989586621679651762"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679651761"><span class="annot"><a href="#local-6989586621679651761"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679651760"><span class="annot"><a href="#local-6989586621679651760"><span class="hs-identifier hs-type hs-type">vocabDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-379"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-380"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679651768"><span class="hs-identifier hs-type">gradient'</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651763"><span class="hs-identifier hs-type">gradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-381"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679651767"><span class="hs-identifier hs-type">layout'</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Dense"><span class="hs-identifier hs-type">Dense</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-382"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679651766"><span class="hs-identifier hs-type">device'</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651762"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-383"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679651765"><span class="hs-identifier hs-type">dataType'</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651761"><span class="hs-identifier hs-type">dataType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-384"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#BroadcastShapesF"><span class="hs-identifier hs-type">BroadcastShapesF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651764"><span class="hs-identifier hs-type">shape'</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679651760"><span class="hs-identifier hs-type">vocabDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-385"></span><span>  </span><span id="LMHeadOutputF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadOutputF"><span class="hs-identifier hs-var">LMHeadOutputF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MBART"><span class="hs-identifier hs-type">MBART</span></a></span><span> </span><span id="local-6989586621679651759"><span class="annot"><a href="#local-6989586621679651759"><span class="hs-identifier hs-type hs-type">decoderOutput</span></a></span></span><span> </span><span id="local-6989586621679651758"><span class="annot"><a href="#local-6989586621679651758"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679651757"><span class="annot"><a href="#local-6989586621679651757"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679651756"><span class="annot"><a href="#local-6989586621679651756"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679651755"><span class="annot"><a href="#local-6989586621679651755"><span class="hs-identifier hs-type hs-type">vocabDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadOutputF"><span class="hs-identifier hs-type">LMHeadOutputF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651759"><span class="hs-identifier hs-type">decoderOutput</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651758"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651757"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651756"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651755"><span class="hs-identifier hs-type">vocabDim</span></a></span><span>
</span><span id="line-386"></span><span>  </span><span id="LMHeadOutputF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadOutputF"><span class="hs-identifier hs-var">LMHeadOutputF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#Pegasus"><span class="hs-identifier hs-type">Pegasus</span></a></span><span> </span><span id="local-6989586621679651754"><span class="annot"><a href="#local-6989586621679651754"><span class="hs-identifier hs-type hs-type">decoderOutput</span></a></span></span><span> </span><span id="local-6989586621679651753"><span class="annot"><a href="#local-6989586621679651753"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679651752"><span class="annot"><a href="#local-6989586621679651752"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679651751"><span class="annot"><a href="#local-6989586621679651751"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679651750"><span class="annot"><a href="#local-6989586621679651750"><span class="hs-identifier hs-type hs-type">vocabDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadOutputF"><span class="hs-identifier hs-type">LMHeadOutputF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651754"><span class="hs-identifier hs-type">decoderOutput</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651753"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651752"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651751"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651750"><span class="hs-identifier hs-type">vocabDim</span></a></span><span>
</span><span id="line-387"></span><span>  </span><span id="LMHeadOutputF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadOutputF"><span class="hs-identifier hs-var">LMHeadOutputF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#RoBERTa"><span class="hs-identifier hs-type">RoBERTa</span></a></span><span> </span><span id="local-6989586621679651749"><span class="annot"><a href="#local-6989586621679651749"><span class="hs-identifier hs-type hs-type">decoderOutput</span></a></span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="#local-6989586621679651749"><span class="hs-identifier hs-type">decoderOutput</span></a></span><span>
</span><span id="line-388"></span><span>  </span><span id="LMHeadOutputF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadOutputF"><span class="hs-identifier hs-var">LMHeadOutputF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BERT"><span class="hs-identifier hs-type">BERT</span></a></span><span> </span><span id="local-6989586621679651748"><span class="annot"><a href="#local-6989586621679651748"><span class="hs-identifier hs-type hs-type">decoderOutput</span></a></span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="#local-6989586621679651748"><span class="hs-identifier hs-type">decoderOutput</span></a></span><span>
</span><span id="line-389"></span><span>
</span><span id="line-390"></span><span class="hs-comment">-- | 'HasForward' instance for 'LMHead'.</span><span>
</span><span id="line-391"></span><span class="hs-comment">--</span><span>
</span><span id="line-392"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-393"></span><span class="hs-comment">--     &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;</span><span>
</span><span id="line-394"></span><span class="hs-comment">--     &#9474; input &#9474;</span><span>
</span><span id="line-395"></span><span class="hs-comment">--     &#9492;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-396"></span><span class="hs-comment">--         &#9474;</span><span>
</span><span id="line-397"></span><span class="hs-comment">--         &#9660;</span><span>
</span><span id="line-398"></span><span class="hs-comment">--   (lmHeadDense)</span><span>
</span><span id="line-399"></span><span class="hs-comment">--         &#9660;</span><span>
</span><span id="line-400"></span><span class="hs-comment">-- (lmHeadActivation)</span><span>
</span><span id="line-401"></span><span class="hs-comment">--         &#9660;</span><span>
</span><span id="line-402"></span><span class="hs-comment">-- (lmHeadLayerNorm)</span><span>
</span><span id="line-403"></span><span class="hs-comment">--         &#9660;</span><span>
</span><span id="line-404"></span><span class="hs-comment">--   lmHeadDecoder</span><span>
</span><span id="line-405"></span><span class="hs-comment">--         &#9660;</span><span>
</span><span id="line-406"></span><span class="hs-comment">--     (scaling)</span><span>
</span><span id="line-407"></span><span class="hs-comment">--         &#9660;</span><span>
</span><span id="line-408"></span><span class="hs-comment">--    (lmHeadBias)</span><span>
</span><span id="line-409"></span><span class="hs-comment">--         &#9474;</span><span>
</span><span id="line-410"></span><span class="hs-comment">--         &#9660;</span><span>
</span><span id="line-411"></span><span class="hs-comment">-- &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;</span><span>
</span><span id="line-412"></span><span class="hs-comment">-- &#9474; decoderOutput &#9474;</span><span>
</span><span id="line-413"></span><span class="hs-comment">-- &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-414"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-415"></span><span id="local-6989586621679651722"><span id="local-6989586621679651723"><span id="local-6989586621679651724"><span id="local-6989586621679651725"><span id="local-6989586621679651726"><span id="local-6989586621679651727"><span id="local-6989586621679651728"><span id="local-6989586621679651729"><span id="local-6989586621679651730"><span id="local-6989586621679651731"><span id="local-6989586621679651732"><span id="local-6989586621679651733"><span id="local-6989586621679651734"><span id="local-6989586621679651735"><span id="local-6989586621679651736"><span id="local-6989586621679651737"><span id="local-6989586621679651738"><span id="local-6989586621679651739"><span id="local-6989586621679651740"><span id="local-6989586621679651741"><span id="local-6989586621679651742"><span id="local-6989586621679651743"><span id="local-6989586621679651744"><span id="local-6989586621679651745"><span id="local-6989586621679651746"><span id="local-6989586621679651747"><span class="hs-keyword">instance</span><span>
</span><span id="line-416"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-417"></span><span>      </span><span class="annot"><a href="#local-6989586621679651747"><span class="hs-identifier hs-type">dense</span></a></span><span>
</span><span id="line-418"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651746"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651745"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651744"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651743"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651742"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-419"></span><span>      </span><span class="annot"><a href="#local-6989586621679651741"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-420"></span><span>      </span><span class="annot"><a href="#local-6989586621679651740"><span class="hs-identifier hs-type">tensor0</span></a></span><span>
</span><span id="line-421"></span><span>      </span><span class="annot"><a href="#local-6989586621679651739"><span class="hs-identifier hs-type">generatorDevice0</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-422"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-423"></span><span>      </span><span class="annot"><a href="#local-6989586621679651738"><span class="hs-identifier hs-type">activation</span></a></span><span>
</span><span id="line-424"></span><span>      </span><span class="annot"><a href="#local-6989586621679651740"><span class="hs-identifier hs-type">tensor0</span></a></span><span>
</span><span id="line-425"></span><span>      </span><span class="annot"><a href="#local-6989586621679651739"><span class="hs-identifier hs-type">generatorDevice0</span></a></span><span>
</span><span id="line-426"></span><span>      </span><span class="annot"><a href="#local-6989586621679651737"><span class="hs-identifier hs-type">tensor1</span></a></span><span>
</span><span id="line-427"></span><span>      </span><span class="annot"><a href="#local-6989586621679651736"><span class="hs-identifier hs-type">generatorDevice1</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-428"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-429"></span><span>      </span><span class="annot"><a href="#local-6989586621679651735"><span class="hs-identifier hs-type">layerNorm</span></a></span><span>
</span><span id="line-430"></span><span>      </span><span class="annot"><a href="#local-6989586621679651737"><span class="hs-identifier hs-type">tensor1</span></a></span><span>
</span><span id="line-431"></span><span>      </span><span class="annot"><a href="#local-6989586621679651736"><span class="hs-identifier hs-type">generatorDevice1</span></a></span><span>
</span><span id="line-432"></span><span>      </span><span class="annot"><a href="#local-6989586621679651734"><span class="hs-identifier hs-type">tensor2</span></a></span><span>
</span><span id="line-433"></span><span>      </span><span class="annot"><a href="#local-6989586621679651733"><span class="hs-identifier hs-type">generatorDevice2</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-434"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-435"></span><span>      </span><span class="annot"><a href="#local-6989586621679651732"><span class="hs-identifier hs-type">decoder</span></a></span><span>
</span><span id="line-436"></span><span>      </span><span class="annot"><a href="#local-6989586621679651734"><span class="hs-identifier hs-type">tensor2</span></a></span><span>
</span><span id="line-437"></span><span>      </span><span class="annot"><a href="#local-6989586621679651733"><span class="hs-identifier hs-type">generatorDevice2</span></a></span><span>
</span><span id="line-438"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651731"><span class="hs-identifier hs-type">gradient3</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651730"><span class="hs-identifier hs-type">layout3</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651729"><span class="hs-identifier hs-type">device3</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651728"><span class="hs-identifier hs-type">dataType3</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651727"><span class="hs-identifier hs-type">shape3</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-439"></span><span>      </span><span class="annot"><a href="#local-6989586621679651726"><span class="hs-identifier hs-type">generatorDevice3</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-440"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-441"></span><span>      </span><span class="annot"><a href="#local-6989586621679651725"><span class="hs-identifier hs-type">bias</span></a></span><span>
</span><span id="line-442"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651731"><span class="hs-identifier hs-type">gradient3</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651730"><span class="hs-identifier hs-type">layout3</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651729"><span class="hs-identifier hs-type">device3</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651728"><span class="hs-identifier hs-type">dataType3</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651727"><span class="hs-identifier hs-type">shape3</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-443"></span><span>      </span><span class="annot"><a href="#local-6989586621679651726"><span class="hs-identifier hs-type">generatorDevice3</span></a></span><span>
</span><span id="line-444"></span><span>      </span><span class="annot"><a href="#local-6989586621679651724"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-445"></span><span>      </span><span class="annot"><a href="#local-6989586621679651723"><span class="hs-identifier hs-type">generatorOutputDevice</span></a></span><span>
</span><span id="line-446"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-447"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-448"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#GLMHead"><span class="hs-identifier hs-type">GLMHead</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651722"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651747"><span class="hs-identifier hs-type">dense</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651738"><span class="hs-identifier hs-type">activation</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651735"><span class="hs-identifier hs-type">layerNorm</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651732"><span class="hs-identifier hs-type">decoder</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651725"><span class="hs-identifier hs-type">bias</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-449"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651746"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651745"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651744"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651743"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651742"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-450"></span><span>    </span><span class="annot"><a href="#local-6989586621679651741"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-451"></span><span>    </span><span class="annot"><a href="#local-6989586621679651724"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-452"></span><span>    </span><span class="annot"><a href="#local-6989586621679651723"><span class="hs-identifier hs-type">generatorOutputDevice</span></a></span><span>
</span><span id="line-453"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-454"></span><span>  </span><span id="local-6989586621679651719"><span class="annot"><span class="annottext">forward :: GLMHead inputEmbedDim dense activation layerNorm decoder bias
-&gt; Tensor gradient layout device dataType shape
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var hs-var hs-var hs-var">forward</span></a></span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#GLMHead"><span class="hs-identifier hs-type">GLMHead</span></a></span><span> </span><span class="hs-special">{</span><span id="local-6989586621679651711"><span id="local-6989586621679651712"><span id="local-6989586621679651713"><span id="local-6989586621679651714"><span id="local-6989586621679651715"><span id="local-6989586621679651716"><span id="local-6989586621679651717"><span class="annot"><span class="annottext">dense
activation
layerNorm
decoder
bias
SDim inputEmbedDim
LMHeadHasScaling
lmHeadHasScaling :: LMHeadHasScaling
lmHeadBias :: bias
lmHeadDecoder :: decoder
lmHeadLayerNorm :: layerNorm
lmHeadActivation :: activation
lmHeadDense :: dense
lmHeadInputEmbedDim :: SDim inputEmbedDim
lmHeadHasScaling :: forall (inputEmbedDim :: Dim (Name Symbol) (Size Nat)) dense
       activation layerNorm decoder bias.
GLMHead inputEmbedDim dense activation layerNorm decoder bias
-&gt; LMHeadHasScaling
lmHeadBias :: forall (inputEmbedDim :: Dim (Name Symbol) (Size Nat)) dense
       activation layerNorm decoder bias.
GLMHead inputEmbedDim dense activation layerNorm decoder bias
-&gt; bias
lmHeadDecoder :: forall (inputEmbedDim :: Dim (Name Symbol) (Size Nat)) dense
       activation layerNorm decoder bias.
GLMHead inputEmbedDim dense activation layerNorm decoder bias
-&gt; decoder
lmHeadLayerNorm :: forall (inputEmbedDim :: Dim (Name Symbol) (Size Nat)) dense
       activation layerNorm decoder bias.
GLMHead inputEmbedDim dense activation layerNorm decoder bias
-&gt; layerNorm
lmHeadActivation :: forall (inputEmbedDim :: Dim (Name Symbol) (Size Nat)) dense
       activation layerNorm decoder bias.
GLMHead inputEmbedDim dense activation layerNorm decoder bias
-&gt; activation
lmHeadDense :: forall (inputEmbedDim :: Dim (Name Symbol) (Size Nat)) dense
       activation layerNorm decoder bias.
GLMHead inputEmbedDim dense activation layerNorm decoder bias
-&gt; dense
lmHeadInputEmbedDim :: forall (inputEmbedDim :: Dim (Name Symbol) (Size Nat)) dense
       activation layerNorm decoder bias.
GLMHead inputEmbedDim dense activation layerNorm decoder bias
-&gt; SDim inputEmbedDim
</span><a href="#local-6989586621679651711"><span class="hs-glyph hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">..</span></a></span></span></span></span></span></span></span></span><span class="hs-special">}</span><span> </span><span id="local-6989586621679651710"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679651710"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-455"></span><span>    </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679651709"><span class="annot"><span class="annottext">scaling :: Double
</span><a href="#local-6989586621679651709"><span class="hs-identifier hs-var hs-var">scaling</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Double
</span><span class="hs-number">1</span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Double -&gt; Double -&gt; Double
forall a. Fractional a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">/</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Double -&gt; Double
forall a. Floating a =&gt; a -&gt; a
</span><span class="hs-identifier hs-var">sqrt</span></span><span> </span><span class="annot"><span class="annottext">(Double -&gt; Double)
-&gt; (SDim inputEmbedDim -&gt; Double) -&gt; SDim inputEmbedDim -&gt; Double
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Integer -&gt; Double
forall a b. (Integral a, Num b) =&gt; a -&gt; b
</span><span class="hs-identifier hs-var">fromIntegral</span></span><span> </span><span class="annot"><span class="annottext">(Integer -&gt; Double)
-&gt; (SDim inputEmbedDim -&gt; Integer) -&gt; SDim inputEmbedDim -&gt; Double
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">IsChecked Integer -&gt; Integer
forall a. IsChecked a -&gt; a
</span><a href="Torch.GraduallyTyped.Prelude.html#forgetIsChecked"><span class="hs-identifier hs-var">forgetIsChecked</span></a></span><span> </span><span class="annot"><span class="annottext">(IsChecked Integer -&gt; Integer)
-&gt; (SDim inputEmbedDim -&gt; IsChecked Integer)
-&gt; SDim inputEmbedDim
-&gt; Integer
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Dim (IsChecked String) (IsChecked Integer) -&gt; IsChecked Integer
forall name size. Dim name size -&gt; size
</span><a href="Torch.GraduallyTyped.Shape.Type.html#dimSize"><span class="hs-identifier hs-var hs-var">dimSize</span></a></span><span> </span><span class="annot"><span class="annottext">(Dim (IsChecked String) (IsChecked Integer) -&gt; IsChecked Integer)
-&gt; (SDim inputEmbedDim
    -&gt; Dim (IsChecked String) (IsChecked Integer))
-&gt; SDim inputEmbedDim
-&gt; IsChecked Integer
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim -&gt; Dim (IsChecked String) (IsChecked Integer)
forall k (a :: k). SingKind k =&gt; Sing a -&gt; Demote k
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">fromSing</span></a></span><span> </span><span class="annot"><span class="annottext">(SDim inputEmbedDim -&gt; Double) -&gt; SDim inputEmbedDim -&gt; Double
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679651717"><span class="hs-identifier hs-var">lmHeadInputEmbedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-456"></span><span>     </span><span class="hs-keyword">in</span><span> </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorOutputDevice)
  output
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
forall (m :: * -&gt; *) i j a. IxStateT m i j a -&gt; i -&gt; m (a, j)
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var hs-var">runIxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">(IxStateT
   m
   (Generator generatorDevice)
   (Generator generatorOutputDevice)
   output
 -&gt; Generator generatorDevice
 -&gt; m (output, Generator generatorOutputDevice))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorOutputDevice)
     output
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-457"></span><span>          </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     (Tensor gradient layout device dataType shape)
forall k (m :: k -&gt; k -&gt; * -&gt; *) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679651710"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-458"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorDevice)
  (Tensor gradient layout device dataType shape)
-&gt; (Tensor gradient layout device dataType shape
    -&gt; IxStateT
         m (Generator generatorDevice) (Generator generatorDevice0) tensor0)
-&gt; IxStateT
     m (Generator generatorDevice) (Generator generatorDevice0) tensor0
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(Generator generatorDevice
 -&gt; m (tensor0, Generator generatorDevice0))
-&gt; IxStateT
     m (Generator generatorDevice) (Generator generatorDevice0) tensor0
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator generatorDevice
  -&gt; m (tensor0, Generator generatorDevice0))
 -&gt; IxStateT
      m (Generator generatorDevice) (Generator generatorDevice0) tensor0)
-&gt; (Tensor gradient layout device dataType shape
    -&gt; Generator generatorDevice
    -&gt; m (tensor0, Generator generatorDevice0))
-&gt; Tensor gradient layout device dataType shape
-&gt; IxStateT
     m (Generator generatorDevice) (Generator generatorDevice0) tensor0
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">dense
-&gt; Tensor gradient layout device dataType shape
-&gt; Generator generatorDevice
-&gt; m (tensor0, Generator generatorDevice0)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: * -&gt; *).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">dense
</span><a href="#local-6989586621679651716"><span class="hs-identifier hs-var">lmHeadDense</span></a></span><span>
</span><span id="line-459"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m (Generator generatorDevice) (Generator generatorDevice0) tensor0
-&gt; (tensor0
    -&gt; IxStateT
         m
         (Generator generatorDevice0)
         (Generator generatorDevice1)
         tensor1)
-&gt; IxStateT
     m (Generator generatorDevice) (Generator generatorDevice1) tensor1
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(Generator generatorDevice0
 -&gt; m (tensor1, Generator generatorDevice1))
-&gt; IxStateT
     m (Generator generatorDevice0) (Generator generatorDevice1) tensor1
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator generatorDevice0
  -&gt; m (tensor1, Generator generatorDevice1))
 -&gt; IxStateT
      m
      (Generator generatorDevice0)
      (Generator generatorDevice1)
      tensor1)
-&gt; (tensor0
    -&gt; Generator generatorDevice0
    -&gt; m (tensor1, Generator generatorDevice1))
-&gt; tensor0
-&gt; IxStateT
     m (Generator generatorDevice0) (Generator generatorDevice1) tensor1
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">activation
-&gt; tensor0
-&gt; Generator generatorDevice0
-&gt; m (tensor1, Generator generatorDevice1)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: * -&gt; *).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">activation
</span><a href="#local-6989586621679651715"><span class="hs-identifier hs-var">lmHeadActivation</span></a></span><span>
</span><span id="line-460"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m (Generator generatorDevice) (Generator generatorDevice1) tensor1
-&gt; (tensor1
    -&gt; IxStateT
         m
         (Generator generatorDevice1)
         (Generator generatorDevice2)
         tensor2)
-&gt; IxStateT
     m (Generator generatorDevice) (Generator generatorDevice2) tensor2
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(Generator generatorDevice1
 -&gt; m (tensor2, Generator generatorDevice2))
-&gt; IxStateT
     m (Generator generatorDevice1) (Generator generatorDevice2) tensor2
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator generatorDevice1
  -&gt; m (tensor2, Generator generatorDevice2))
 -&gt; IxStateT
      m
      (Generator generatorDevice1)
      (Generator generatorDevice2)
      tensor2)
-&gt; (tensor1
    -&gt; Generator generatorDevice1
    -&gt; m (tensor2, Generator generatorDevice2))
-&gt; tensor1
-&gt; IxStateT
     m (Generator generatorDevice1) (Generator generatorDevice2) tensor2
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">layerNorm
-&gt; tensor1
-&gt; Generator generatorDevice1
-&gt; m (tensor2, Generator generatorDevice2)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: * -&gt; *).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">layerNorm
</span><a href="#local-6989586621679651714"><span class="hs-identifier hs-var">lmHeadLayerNorm</span></a></span><span>
</span><span id="line-461"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m (Generator generatorDevice) (Generator generatorDevice2) tensor2
-&gt; (tensor2
    -&gt; IxStateT
         m
         (Generator generatorDevice2)
         (Generator generatorDevice3)
         (Tensor gradient3 layout3 device3 dataType3 shape3))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice3)
     (Tensor gradient3 layout3 device3 dataType3 shape3)
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(Generator generatorDevice2
 -&gt; m (Tensor gradient3 layout3 device3 dataType3 shape3,
       Generator generatorDevice3))
-&gt; IxStateT
     m
     (Generator generatorDevice2)
     (Generator generatorDevice3)
     (Tensor gradient3 layout3 device3 dataType3 shape3)
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator generatorDevice2
  -&gt; m (Tensor gradient3 layout3 device3 dataType3 shape3,
        Generator generatorDevice3))
 -&gt; IxStateT
      m
      (Generator generatorDevice2)
      (Generator generatorDevice3)
      (Tensor gradient3 layout3 device3 dataType3 shape3))
-&gt; (tensor2
    -&gt; Generator generatorDevice2
    -&gt; m (Tensor gradient3 layout3 device3 dataType3 shape3,
          Generator generatorDevice3))
-&gt; tensor2
-&gt; IxStateT
     m
     (Generator generatorDevice2)
     (Generator generatorDevice3)
     (Tensor gradient3 layout3 device3 dataType3 shape3)
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">decoder
-&gt; tensor2
-&gt; Generator generatorDevice2
-&gt; m (Tensor gradient3 layout3 device3 dataType3 shape3,
      Generator generatorDevice3)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: * -&gt; *).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">decoder
</span><a href="#local-6989586621679651713"><span class="hs-identifier hs-var">lmHeadDecoder</span></a></span><span>
</span><span id="line-462"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorDevice3)
  (Tensor gradient3 layout3 device3 dataType3 shape3)
-&gt; (Tensor gradient3 layout3 device3 dataType3 shape3
    -&gt; IxStateT
         m
         (Generator generatorDevice3)
         (Generator generatorDevice3)
         (Tensor gradient3 layout3 device3 dataType3 shape3))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice3)
     (Tensor gradient3 layout3 device3 dataType3 shape3)
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient3 layout3 device3 dataType3 shape3
-&gt; IxStateT
     m
     (Generator generatorDevice3)
     (Generator generatorDevice3)
     (Tensor gradient3 layout3 device3 dataType3 shape3)
forall k (m :: k -&gt; k -&gt; * -&gt; *) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span>
</span><span id="line-463"></span><span>              </span><span class="annot"><span class="annottext">(Tensor gradient3 layout3 device3 dataType3 shape3
 -&gt; IxStateT
      m
      (Generator generatorDevice3)
      (Generator generatorDevice3)
      (Tensor gradient3 layout3 device3 dataType3 shape3))
-&gt; (Tensor gradient3 layout3 device3 dataType3 shape3
    -&gt; Tensor gradient3 layout3 device3 dataType3 shape3)
-&gt; Tensor gradient3 layout3 device3 dataType3 shape3
-&gt; IxStateT
     m
     (Generator generatorDevice3)
     (Generator generatorDevice3)
     (Tensor gradient3 layout3 device3 dataType3 shape3)
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="hs-special">(</span><span> </span><span class="hs-glyph">\</span><span class="hs-glyph">case</span><span>
</span><span id="line-464"></span><span>                    </span><span class="annot"><span class="annottext">LMHeadHasScaling
</span><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadWithoutScaling"><span class="hs-identifier hs-var">LMHeadWithoutScaling</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">Tensor gradient3 layout3 device3 dataType3 shape3
-&gt; Tensor gradient3 layout3 device3 dataType3 shape3
forall a. a -&gt; a
</span><span class="hs-identifier hs-var">id</span></span><span>
</span><span id="line-465"></span><span>                    </span><span class="annot"><span class="annottext">LMHeadHasScaling
</span><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadWithScaling"><span class="hs-identifier hs-var">LMHeadWithScaling</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">(Tensor gradient3 layout3 device3 dataType3 shape3
 -&gt; Double -&gt; Tensor gradient3 layout3 device3 dataType3 shape3)
-&gt; Double
-&gt; Tensor gradient3 layout3 device3 dataType3 shape3
-&gt; Tensor gradient3 layout3 device3 dataType3 shape3
forall a b c. (a -&gt; b -&gt; c) -&gt; b -&gt; a -&gt; c
</span><span class="hs-identifier hs-var">flip</span></span><span> </span><span class="annot"><span class="annottext">Tensor gradient3 layout3 device3 dataType3 shape3
-&gt; Double -&gt; Tensor gradient3 layout3 device3 dataType3 shape3
forall other (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
Scalar other =&gt;
Tensor gradient layout device dataType shape
-&gt; other -&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#mulScalar"><span class="hs-identifier hs-var">mulScalar</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679651709"><span class="hs-identifier hs-var">scaling</span></a></span><span>
</span><span id="line-466"></span><span>                </span><span class="hs-special">)</span><span>
</span><span id="line-467"></span><span>                </span><span class="annot"><span class="annottext">LMHeadHasScaling
</span><a href="#local-6989586621679651711"><span class="hs-identifier hs-var">lmHeadHasScaling</span></a></span><span>
</span><span id="line-468"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorDevice3)
  (Tensor gradient3 layout3 device3 dataType3 shape3)
-&gt; (Tensor gradient3 layout3 device3 dataType3 shape3
    -&gt; IxStateT
         m
         (Generator generatorDevice3)
         (Generator generatorOutputDevice)
         output)
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorOutputDevice)
     output
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(Generator generatorDevice3
 -&gt; m (output, Generator generatorOutputDevice))
-&gt; IxStateT
     m
     (Generator generatorDevice3)
     (Generator generatorOutputDevice)
     output
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator generatorDevice3
  -&gt; m (output, Generator generatorOutputDevice))
 -&gt; IxStateT
      m
      (Generator generatorDevice3)
      (Generator generatorOutputDevice)
      output)
-&gt; (Tensor gradient3 layout3 device3 dataType3 shape3
    -&gt; Generator generatorDevice3
    -&gt; m (output, Generator generatorOutputDevice))
-&gt; Tensor gradient3 layout3 device3 dataType3 shape3
-&gt; IxStateT
     m
     (Generator generatorDevice3)
     (Generator generatorOutputDevice)
     output
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">bias
-&gt; Tensor gradient3 layout3 device3 dataType3 shape3
-&gt; Generator generatorDevice3
-&gt; m (output, Generator generatorOutputDevice)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: * -&gt; *).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">bias
</span><a href="#local-6989586621679651712"><span class="hs-identifier hs-var">lmHeadBias</span></a></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span>
</span><span id="line-469"></span><span>
</span><span id="line-470"></span><span id="local-6989586621679651698"><span id="local-6989586621679651699"><span id="local-6989586621679651700"><span id="local-6989586621679651701"><span id="local-6989586621679651702"><span id="local-6989586621679651703"><span class="hs-keyword">instance</span><span>
</span><span id="line-471"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-472"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#GBias"><span class="hs-identifier hs-type">GBias</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-473"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651703"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651702"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651701"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651700"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651699"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-474"></span><span>    </span><span class="annot"><a href="#local-6989586621679651698"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-475"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651703"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651702"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651701"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651700"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651699"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-476"></span><span>    </span><span class="annot"><a href="#local-6989586621679651698"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-477"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-478"></span><span>  </span><span id="local-6989586621679651696"><span class="annot"><span class="annottext">forward :: GBias ()
-&gt; Tensor gradient layout device dataType shape
-&gt; Generator generatorDevice
-&gt; m (Tensor gradient layout device dataType shape,
      Generator generatorDevice)
</span><a href="#local-6989586621679651696"><span class="hs-identifier hs-var hs-var hs-var hs-var">forward</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#GBias"><span class="hs-identifier hs-type">GBias</span></a></span><span> </span><span id="local-6989586621679651695"><span class="annot"><span class="annottext">()
</span><a href="#local-6989586621679651695"><span class="hs-identifier hs-var">bias</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">()
-&gt; Tensor gradient layout device dataType shape
-&gt; Generator generatorDevice
-&gt; m (Tensor gradient layout device dataType shape,
      Generator generatorDevice)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: * -&gt; *).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">()
</span><a href="#local-6989586621679651695"><span class="hs-identifier hs-var">bias</span></a></span></span></span></span></span></span></span><span>
</span><span id="line-479"></span><span>
</span><span id="line-480"></span><span id="local-6989586621679651683"><span id="local-6989586621679651684"><span id="local-6989586621679651685"><span id="local-6989586621679651686"><span id="local-6989586621679651687"><span id="local-6989586621679651688"><span id="local-6989586621679651689"><span id="local-6989586621679651690"><span id="local-6989586621679651691"><span id="local-6989586621679651692"><span id="local-6989586621679651693"><span id="local-6989586621679651694"><span class="hs-keyword">instance</span><span>
</span><span id="line-481"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="#local-6989586621679651694"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-482"></span><span>      </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-483"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679651693"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651692"><span class="hs-identifier hs-type">biasGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-484"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679651691"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651690"><span class="hs-identifier hs-type">biasLayout</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-485"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679651689"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651688"><span class="hs-identifier hs-type">biasDevice</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-486"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679651687"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651686"><span class="hs-identifier hs-type">biasDataType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-487"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#BroadcastShapesF"><span class="hs-identifier hs-type">BroadcastShapesF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651685"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651684"><span class="hs-identifier hs-type">biasShape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-488"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-489"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-490"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#GBias"><span class="hs-identifier hs-type">GBias</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651692"><span class="hs-identifier hs-type">biasGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651690"><span class="hs-identifier hs-type">biasLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651688"><span class="hs-identifier hs-type">biasDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651686"><span class="hs-identifier hs-type">biasDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651684"><span class="hs-identifier hs-type">biasShape</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-491"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651693"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651691"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651689"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651687"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651685"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-492"></span><span>    </span><span class="annot"><a href="#local-6989586621679651683"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-493"></span><span>    </span><span class="annot"><a href="#local-6989586621679651694"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-494"></span><span>    </span><span class="annot"><a href="#local-6989586621679651683"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-495"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-496"></span><span>  </span><span id="local-6989586621679651681"><span class="annot"><span class="annottext">forward :: GBias
  (Tensor biasGradient biasLayout biasDevice biasDataType biasShape)
-&gt; Tensor gradient layout device dataType shape
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorDevice)
</span><a href="#local-6989586621679651681"><span class="hs-identifier hs-var hs-var hs-var hs-var">forward</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#GBias"><span class="hs-identifier hs-type">GBias</span></a></span><span> </span><span id="local-6989586621679651680"><span class="annot"><span class="annottext">Tensor biasGradient biasLayout biasDevice biasDataType biasShape
</span><a href="#local-6989586621679651680"><span class="hs-identifier hs-var">bias</span></a></span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679651679"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679651679"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span id="local-6989586621679651678"><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679651678"><span class="hs-identifier hs-var">g</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(output, Generator generatorDevice)
-&gt; m (output, Generator generatorDevice)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679651679"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
-&gt; Tensor biasGradient biasLayout biasDevice biasDataType biasShape
-&gt; Tensor
     (gradient &lt;|&gt; biasGradient)
     (layout &lt;+&gt; biasLayout)
     (device &lt;+&gt; biasDevice)
     (dataType &lt;+&gt; biasDataType)
     (BroadcastShapesF shape biasShape)
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (gradient' :: Gradient RequiresGradient)
       (layout' :: Layout LayoutType) (device' :: Device (DeviceType Nat))
       (dataType' :: DataType DType)
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]).
Tensor gradient layout device dataType shape
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; Tensor
     (gradient &lt;|&gt; gradient')
     (layout &lt;+&gt; layout')
     (device &lt;+&gt; device')
     (dataType &lt;+&gt; dataType')
     (BroadcastShapesF shape shape')
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#add"><span class="hs-operator hs-var">`add`</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor biasGradient biasLayout biasDevice biasDataType biasShape
</span><a href="#local-6989586621679651680"><span class="hs-identifier hs-var">bias</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679651678"><span class="hs-identifier hs-var">g</span></a></span><span class="hs-special">)</span></span></span></span></span></span></span></span></span></span></span></span></span><span>
</span><span id="line-497"></span><span>
</span><span id="line-498"></span><span id="local-6989586621679651666"><span id="local-6989586621679651667"><span id="local-6989586621679651668"><span id="local-6989586621679651669"><span id="local-6989586621679651670"><span id="local-6989586621679651671"><span id="local-6989586621679651672"><span id="local-6989586621679651673"><span id="local-6989586621679651674"><span id="local-6989586621679651675"><span id="local-6989586621679651676"><span id="local-6989586621679651677"><span class="hs-keyword">instance</span><span>
</span><span id="line-499"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="#local-6989586621679651677"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-500"></span><span>      </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-501"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679651676"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651675"><span class="hs-identifier hs-type">biasGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-502"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679651674"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651673"><span class="hs-identifier hs-type">biasLayout</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-503"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679651672"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651671"><span class="hs-identifier hs-type">biasDevice</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-504"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679651670"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651669"><span class="hs-identifier hs-type">biasDataType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-505"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#BroadcastShapesF"><span class="hs-identifier hs-type">BroadcastShapesF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651668"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651667"><span class="hs-identifier hs-type">biasShape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-506"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-507"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-508"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#GBias"><span class="hs-identifier hs-type">GBias</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-type">NamedModel</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651675"><span class="hs-identifier hs-type">biasGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651673"><span class="hs-identifier hs-type">biasLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651671"><span class="hs-identifier hs-type">biasDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651669"><span class="hs-identifier hs-type">biasDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651667"><span class="hs-identifier hs-type">biasShape</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-509"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651676"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651674"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651672"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651670"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679651668"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-510"></span><span>    </span><span class="annot"><a href="#local-6989586621679651666"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-511"></span><span>    </span><span class="annot"><a href="#local-6989586621679651677"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-512"></span><span>    </span><span class="annot"><a href="#local-6989586621679651666"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-513"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-514"></span><span>  </span><span id="local-6989586621679651664"><span class="annot"><span class="annottext">forward :: GBias
  (NamedModel
     (Tensor biasGradient biasLayout biasDevice biasDataType biasShape))
-&gt; Tensor gradient layout device dataType shape
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorDevice)
</span><a href="#local-6989586621679651664"><span class="hs-identifier hs-var hs-var hs-var hs-var">forward</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#GBias"><span class="hs-identifier hs-type">GBias</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-type">NamedModel</span></a></span><span> </span><span class="annot"><span class="annottext">Text
</span><span class="hs-identifier">_</span></span><span> </span><span id="local-6989586621679651663"><span class="annot"><span class="annottext">Tensor biasGradient biasLayout biasDevice biasDataType biasShape
</span><a href="#local-6989586621679651663"><span class="hs-identifier hs-var">bias</span></a></span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span id="local-6989586621679651662"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679651662"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span id="local-6989586621679651661"><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679651661"><span class="hs-identifier hs-var">g</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(output, Generator generatorDevice)
-&gt; m (output, Generator generatorDevice)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679651662"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
-&gt; Tensor biasGradient biasLayout biasDevice biasDataType biasShape
-&gt; Tensor
     (gradient &lt;|&gt; biasGradient)
     (layout &lt;+&gt; biasLayout)
     (device &lt;+&gt; biasDevice)
     (dataType &lt;+&gt; biasDataType)
     (BroadcastShapesF shape biasShape)
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (gradient' :: Gradient RequiresGradient)
       (layout' :: Layout LayoutType) (device' :: Device (DeviceType Nat))
       (dataType' :: DataType DType)
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]).
Tensor gradient layout device dataType shape
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; Tensor
     (gradient &lt;|&gt; gradient')
     (layout &lt;+&gt; layout')
     (device &lt;+&gt; device')
     (dataType &lt;+&gt; dataType')
     (BroadcastShapesF shape shape')
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#add"><span class="hs-operator hs-var">`add`</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor biasGradient biasLayout biasDevice biasDataType biasShape
</span><a href="#local-6989586621679651663"><span class="hs-identifier hs-var">bias</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679651661"><span class="hs-identifier hs-var">g</span></a></span><span class="hs-special">)</span></span></span></span></span></span></span></span></span></span></span></span></span><span>
</span><span id="line-515"></span></pre></body></html>