<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><link rel="stylesheet" type="text/css" href="style.css" /><script type="text/javascript" src="highlight.js"></script></head><body><pre><span id="%24con2tag_ABiU54IEe2w9F86opvuSYM"></span><span class="hs-pragma">{-# LANGUAGE DataKinds #-}</span><span>
</span><span id="line-2"></span><span class="hs-pragma">{-# LANGUAGE DeriveGeneric #-}</span><span>
</span><span id="line-3"></span><span class="hs-pragma">{-# LANGUAGE DerivingStrategies #-}</span><span>
</span><span id="line-4"></span><span class="hs-pragma">{-# LANGUAGE FlexibleInstances #-}</span><span>
</span><span id="line-5"></span><span class="hs-pragma">{-# LANGUAGE GADTs #-}</span><span>
</span><span id="line-6"></span><span class="hs-pragma">{-# LANGUAGE LambdaCase #-}</span><span>
</span><span id="line-7"></span><span class="hs-pragma">{-# LANGUAGE MultiParamTypeClasses #-}</span><span>
</span><span id="line-8"></span><span class="hs-pragma">{-# LANGUAGE OverloadedStrings #-}</span><span>
</span><span id="line-9"></span><span class="hs-pragma">{-# LANGUAGE PatternSynonyms #-}</span><span>
</span><span id="line-10"></span><span class="hs-pragma">{-# LANGUAGE RecordWildCards #-}</span><span>
</span><span id="line-11"></span><span class="hs-pragma">{-# LANGUAGE ScopedTypeVariables #-}</span><span>
</span><span id="line-12"></span><span class="hs-pragma">{-# LANGUAGE TypeApplications #-}</span><span>
</span><span id="line-13"></span><span class="hs-pragma">{-# LANGUAGE TypeFamilies #-}</span><span>
</span><span id="line-14"></span><span class="hs-pragma">{-# LANGUAGE TypeOperators #-}</span><span>
</span><span id="line-15"></span><span class="hs-pragma">{-# LANGUAGE UndecidableInstances #-}</span><span>
</span><span id="line-16"></span><span>
</span><span id="line-17"></span><span class="hs-keyword">module</span><span> </span><span class="hs-identifier">Torch.GraduallyTyped.NN.Transformer.GLMHead</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-18"></span><span>
</span><span id="line-19"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/wpb5hggv8az7m3hh6dk4vnmz1z9va197-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier">Control.Monad.Indexed</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/wpb5hggv8az7m3hh6dk4vnmz1z9va197-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier">IxPointed</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../file:///nix/store/wpb5hggv8az7m3hh6dk4vnmz1z9va197-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator">(&gt;&gt;&gt;=)</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-20"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/izdh8cwvq0acwzr2lk5vjhjfywaq1s9y-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier">Control.Monad.Indexed.State</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/izdh8cwvq0acwzr2lk5vjhjfywaq1s9y-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier">IxStateT</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-21"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/wpb5hggv8az7m3hh6dk4vnmz1z9va197-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier">Control.Monad.Indexed.Trans</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/wpb5hggv8az7m3hh6dk4vnmz1z9va197-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier">IxMonadTrans</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/wpb5hggv8az7m3hh6dk4vnmz1z9va197-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier">ilift</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-22"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/wpb5hggv8az7m3hh6dk4vnmz1z9va197-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier">Data.Functor.Indexed</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/wpb5hggv8az7m3hh6dk4vnmz1z9va197-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator">(&lt;&lt;$&gt;&gt;)</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-23"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">Data.Kind</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier">Type</span></span><span class="hs-special">)</span><span>
</span><span id="line-24"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/44d7539k7gqlplsaxjj66fck1zc772zc-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">Data.Singletons</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/44d7539k7gqlplsaxjj66fck1zc772zc-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">SingKind</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/44d7539k7gqlplsaxjj66fck1zc772zc-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">fromSing</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-25"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">GHC.Generics</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier">Generic</span></span><span class="hs-special">)</span><span>
</span><span id="line-26"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">GHC.TypeLits</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier">Nat</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier">Symbol</span></span><span class="hs-special">)</span><span>
</span><span id="line-27"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html"><span class="hs-identifier">Torch.GraduallyTyped.DType</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier">DType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier">DataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier">SDataType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-28"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html"><span class="hs-identifier">Torch.GraduallyTyped.Device</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier">Device</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#DeviceType"><span class="hs-identifier">DeviceType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#SDevice"><span class="hs-identifier">SDevice</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-29"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html"><span class="hs-identifier">Torch.GraduallyTyped.Layout</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier">Layout</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#LayoutType"><span class="hs-identifier">LayoutType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#SLayout"><span class="hs-identifier">SLayout</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#SLayoutType"><span class="hs-identifier">SLayoutType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-30"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Activation.html"><span class="hs-identifier">Torch.GraduallyTyped.NN.Activation</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Activation.html#Gelu"><span class="hs-identifier">Gelu</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-31"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html"><span class="hs-identifier">Torch.GraduallyTyped.NN.Class</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier">HasForward</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier">HasInitialize</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasStateDict"><span class="hs-identifier">HasStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier">ModelSpec</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier">NamedModel</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-32"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Linear.html"><span class="hs-identifier">Torch.GraduallyTyped.NN.Linear</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Linear.html#GLinearF"><span class="hs-identifier">GLinearF</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Linear.html#linearSpec"><span class="hs-identifier">linearSpec</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-33"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Normalization.html"><span class="hs-identifier">Torch.GraduallyTyped.NN.Normalization</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Normalization.html#LayerNorm"><span class="hs-identifier">LayerNorm</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Normalization.html#LayerNormSpec"><span class="hs-identifier">LayerNormSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-34"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html"><span class="hs-identifier">Torch.GraduallyTyped.NN.Transformer.Type</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#STransformerStyle"><span class="hs-identifier">STransformerStyle</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerStyle"><span class="hs-identifier">TransformerStyle</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-35"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Type.html"><span class="hs-identifier">Torch.GraduallyTyped.NN.Type</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Type.html#HasBias"><span class="hs-identifier">HasBias</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Type.html#SHasBias"><span class="hs-identifier">SHasBias</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-36"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html"><span class="hs-identifier">Torch.GraduallyTyped.Prelude</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Catch"><span class="hs-identifier">Catch</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#forgetIsChecked"><span class="hs-identifier">forgetIsChecked</span></a></span><span class="hs-special">,</span><span> </span><span class="hs-keyword">pattern</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#%3A%7C%3A"><span class="hs-operator">(:|:)</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-37"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.List.html"><span class="hs-identifier">Torch.GraduallyTyped.Prelude.List</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/44d7539k7gqlplsaxjj66fck1zc772zc-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">SList</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/44d7539k7gqlplsaxjj66fck1zc772zc-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">SNil</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-38"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html"><span class="hs-identifier">Torch.GraduallyTyped.RequiresGradient</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier">Gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#RequiresGradient"><span class="hs-identifier">RequiresGradient</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier">SGradient</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-39"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html"><span class="hs-identifier">Torch.GraduallyTyped.Shape.Class</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#BroadcastShapesF"><span class="hs-identifier">BroadcastShapesF</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-40"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html"><span class="hs-identifier">Torch.GraduallyTyped.Shape.Type</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier">Name</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier">SDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier">SName</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier">SShape</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier">SSize</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier">Shape</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier">Size</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="hs-keyword">pattern</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator">(:&amp;:)</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-41"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Creation.html"><span class="hs-identifier">Torch.GraduallyTyped.Tensor.Creation</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Creation.html#sZeros"><span class="hs-identifier">sZeros</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-42"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html"><span class="hs-identifier">Torch.GraduallyTyped.Tensor.MathOperations.Pointwise</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#add"><span class="hs-identifier">add</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#mulScalar"><span class="hs-identifier">mulScalar</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-43"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html"><span class="hs-identifier">Torch.GraduallyTyped.Tensor.Type</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier">Tensor</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorSpec"><span class="hs-identifier">TensorSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-44"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html"><span class="hs-identifier">Torch.GraduallyTyped.Unify</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-keyword">type</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator">(&lt;+&gt;)</span></a></span><span class="hs-special">,</span><span> </span><span class="hs-keyword">type</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator">(&lt;|&gt;)</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-45"></span><span>
</span><span id="line-46"></span><span class="hs-comment">-- | A data type that represents whether or not the language modelling head</span><span>
</span><span id="line-47"></span><span class="hs-comment">-- has a scaled decoder output.</span><span>
</span><span id="line-48"></span><span id="local-6989586621679697013"><span id="local-6989586621679697014"></span></span><span class="hs-keyword">data</span><span> </span><span id="LMHeadHasScaling"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadHasScaling"><span class="hs-identifier hs-var">LMHeadHasScaling</span></a></span></span><span>
</span><span id="line-49"></span><span>  </span><span class="hs-glyph">=</span><span> </span><span id="LMHeadWithScaling"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadWithScaling"><span class="hs-identifier hs-var">LMHeadWithScaling</span></a></span></span><span>
</span><span id="line-50"></span><span>  </span><span class="hs-glyph">|</span><span> </span><span id="LMHeadWithoutScaling"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadWithoutScaling"><span class="hs-identifier hs-var">LMHeadWithoutScaling</span></a></span></span><span>
</span><span id="line-51"></span><span>  </span><span class="hs-keyword">deriving</span><span> </span><span class="annot"><span class="hs-keyword">stock</span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679697007"><span id="local-6989586621679697009"><span class="annot"><span class="annottext">LMHeadHasScaling -&gt; LMHeadHasScaling -&gt; Bool
(LMHeadHasScaling -&gt; LMHeadHasScaling -&gt; Bool)
-&gt; (LMHeadHasScaling -&gt; LMHeadHasScaling -&gt; Bool)
-&gt; Eq LMHeadHasScaling
forall a. (a -&gt; a -&gt; Bool) -&gt; (a -&gt; a -&gt; Bool) -&gt; Eq a
/= :: LMHeadHasScaling -&gt; LMHeadHasScaling -&gt; Bool
$c/= :: LMHeadHasScaling -&gt; LMHeadHasScaling -&gt; Bool
== :: LMHeadHasScaling -&gt; LMHeadHasScaling -&gt; Bool
$c== :: LMHeadHasScaling -&gt; LMHeadHasScaling -&gt; Bool
</span><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var">Eq</span></span></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679696991"><span id="local-6989586621679696993"><span id="local-6989586621679696995"><span id="local-6989586621679696997"><span id="local-6989586621679696999"><span id="local-6989586621679697001"><span id="local-6989586621679697003"><span class="annot"><span class="annottext">Eq LMHeadHasScaling
Eq LMHeadHasScaling
-&gt; (LMHeadHasScaling -&gt; LMHeadHasScaling -&gt; Ordering)
-&gt; (LMHeadHasScaling -&gt; LMHeadHasScaling -&gt; Bool)
-&gt; (LMHeadHasScaling -&gt; LMHeadHasScaling -&gt; Bool)
-&gt; (LMHeadHasScaling -&gt; LMHeadHasScaling -&gt; Bool)
-&gt; (LMHeadHasScaling -&gt; LMHeadHasScaling -&gt; Bool)
-&gt; (LMHeadHasScaling -&gt; LMHeadHasScaling -&gt; LMHeadHasScaling)
-&gt; (LMHeadHasScaling -&gt; LMHeadHasScaling -&gt; LMHeadHasScaling)
-&gt; Ord LMHeadHasScaling
LMHeadHasScaling -&gt; LMHeadHasScaling -&gt; Bool
LMHeadHasScaling -&gt; LMHeadHasScaling -&gt; Ordering
LMHeadHasScaling -&gt; LMHeadHasScaling -&gt; LMHeadHasScaling
forall a.
Eq a
-&gt; (a -&gt; a -&gt; Ordering)
-&gt; (a -&gt; a -&gt; Bool)
-&gt; (a -&gt; a -&gt; Bool)
-&gt; (a -&gt; a -&gt; Bool)
-&gt; (a -&gt; a -&gt; Bool)
-&gt; (a -&gt; a -&gt; a)
-&gt; (a -&gt; a -&gt; a)
-&gt; Ord a
min :: LMHeadHasScaling -&gt; LMHeadHasScaling -&gt; LMHeadHasScaling
$cmin :: LMHeadHasScaling -&gt; LMHeadHasScaling -&gt; LMHeadHasScaling
max :: LMHeadHasScaling -&gt; LMHeadHasScaling -&gt; LMHeadHasScaling
$cmax :: LMHeadHasScaling -&gt; LMHeadHasScaling -&gt; LMHeadHasScaling
&gt;= :: LMHeadHasScaling -&gt; LMHeadHasScaling -&gt; Bool
$c&gt;= :: LMHeadHasScaling -&gt; LMHeadHasScaling -&gt; Bool
&gt; :: LMHeadHasScaling -&gt; LMHeadHasScaling -&gt; Bool
$c&gt; :: LMHeadHasScaling -&gt; LMHeadHasScaling -&gt; Bool
&lt;= :: LMHeadHasScaling -&gt; LMHeadHasScaling -&gt; Bool
$c&lt;= :: LMHeadHasScaling -&gt; LMHeadHasScaling -&gt; Bool
&lt; :: LMHeadHasScaling -&gt; LMHeadHasScaling -&gt; Bool
$c&lt; :: LMHeadHasScaling -&gt; LMHeadHasScaling -&gt; Bool
compare :: LMHeadHasScaling -&gt; LMHeadHasScaling -&gt; Ordering
$ccompare :: LMHeadHasScaling -&gt; LMHeadHasScaling -&gt; Ordering
$cp1Ord :: Eq LMHeadHasScaling
</span><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">Ord</span></span></span></span></span></span></span></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679696984"><span id="local-6989586621679696986"><span id="local-6989586621679696988"><span class="annot"><span class="annottext">Int -&gt; LMHeadHasScaling -&gt; ShowS
[LMHeadHasScaling] -&gt; ShowS
LMHeadHasScaling -&gt; String
(Int -&gt; LMHeadHasScaling -&gt; ShowS)
-&gt; (LMHeadHasScaling -&gt; String)
-&gt; ([LMHeadHasScaling] -&gt; ShowS)
-&gt; Show LMHeadHasScaling
forall a.
(Int -&gt; a -&gt; ShowS) -&gt; (a -&gt; String) -&gt; ([a] -&gt; ShowS) -&gt; Show a
showList :: [LMHeadHasScaling] -&gt; ShowS
$cshowList :: [LMHeadHasScaling] -&gt; ShowS
show :: LMHeadHasScaling -&gt; String
$cshow :: LMHeadHasScaling -&gt; String
showsPrec :: Int -&gt; LMHeadHasScaling -&gt; ShowS
$cshowsPrec :: Int -&gt; LMHeadHasScaling -&gt; ShowS
</span><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">Show</span></span></span></span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">(forall x. LMHeadHasScaling -&gt; Rep LMHeadHasScaling x)
-&gt; (forall x. Rep LMHeadHasScaling x -&gt; LMHeadHasScaling)
-&gt; Generic LMHeadHasScaling
forall x. Rep LMHeadHasScaling x -&gt; LMHeadHasScaling
forall x. LMHeadHasScaling -&gt; Rep LMHeadHasScaling x
forall a.
(forall x. a -&gt; Rep a x) -&gt; (forall x. Rep a x -&gt; a) -&gt; Generic a
$cto :: forall x. Rep LMHeadHasScaling x -&gt; LMHeadHasScaling
$cfrom :: forall x. LMHeadHasScaling -&gt; Rep LMHeadHasScaling x
</span><span class="hs-identifier hs-var hs-var hs-var hs-var">Generic</span></span><span class="hs-special">)</span><span>
</span><span id="line-52"></span><span>
</span><span id="line-53"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">instance</span><span> </span><span id="ModelSpec"><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier hs-var">ModelSpec</span></a></span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadHasScaling"><span class="hs-identifier hs-type">LMHeadHasScaling</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadHasScaling"><span class="hs-identifier hs-type">LMHeadHasScaling</span></a></span><span>
</span><span id="line-54"></span><span>
</span><span id="line-55"></span><span id="local-6989586621679696979"><span class="hs-keyword">instance</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadHasScaling"><span class="hs-identifier hs-type">LMHeadHasScaling</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696979"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadHasScaling"><span class="hs-identifier hs-type">LMHeadHasScaling</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696979"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-56"></span><span>  </span><span id="local-6989586621679696976"><span class="annot"><span class="annottext">initialize :: ModelSpec LMHeadHasScaling
-&gt; Generator generatorDevice
-&gt; m (LMHeadHasScaling, Generator generatorDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#initialize"><span class="hs-identifier hs-var hs-var hs-var hs-var">initialize</span></a></span></span><span> </span><span id="local-6989586621679696974"><span class="annot"><span class="annottext">ModelSpec LMHeadHasScaling
</span><a href="#local-6989586621679696974"><span class="hs-identifier hs-var">hasScaling</span></a></span></span><span> </span><span id="local-6989586621679696973"><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679696973"><span class="hs-identifier hs-var">g</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(LMHeadHasScaling, Generator generatorDevice)
-&gt; m (LMHeadHasScaling, Generator generatorDevice)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">ModelSpec LMHeadHasScaling
LMHeadHasScaling
</span><a href="#local-6989586621679696974"><span class="hs-identifier hs-var">hasScaling</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679696973"><span class="hs-identifier hs-var">g</span></a></span><span class="hs-special">)</span></span><span>
</span><span id="line-57"></span><span>
</span><span id="line-58"></span><span class="hs-keyword">instance</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasStateDict"><span class="hs-identifier hs-type">HasStateDict</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadHasScaling"><span class="hs-identifier hs-type">LMHeadHasScaling</span></a></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-59"></span><span>  </span><span id="local-6989586621679696969"><span class="annot"><span class="annottext">fromStateDict :: ModelSpec LMHeadHasScaling -&gt; StateDictKey -&gt; m LMHeadHasScaling
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var hs-var hs-var hs-var">fromStateDict</span></a></span></span><span> </span><span id="local-6989586621679696967"><span class="annot"><span class="annottext">ModelSpec LMHeadHasScaling
</span><a href="#local-6989586621679696967"><span class="hs-identifier hs-var">hasScaling</span></a></span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">LMHeadHasScaling -&gt; m LMHeadHasScaling
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">ModelSpec LMHeadHasScaling
LMHeadHasScaling
</span><a href="#local-6989586621679696967"><span class="hs-identifier hs-var">hasScaling</span></a></span><span>
</span><span id="line-60"></span><span>  </span><span id="local-6989586621679696966"><span class="annot"><span class="annottext">toStateDict :: StateDictKey -&gt; LMHeadHasScaling -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var hs-var hs-var hs-var">toStateDict</span></a></span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="annottext">LMHeadHasScaling
</span><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">() -&gt; m ()
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-61"></span><span>
</span><span id="line-62"></span><span class="hs-comment">-- | Generic language modelling head for transformer encoders and decoders.</span><span>
</span><span id="line-63"></span><span class="hs-comment">--</span><span>
</span><span id="line-64"></span><span class="hs-comment">-- - @inputEmbedDim@ is the dimension of the input embedding.</span><span>
</span><span id="line-65"></span><span class="hs-comment">-- - @dense@ is a dense layer.</span><span>
</span><span id="line-66"></span><span class="hs-comment">-- - @activation@ is an activation function.</span><span>
</span><span id="line-67"></span><span class="hs-comment">-- - @layerNorm@ is a layer normalization layer.</span><span>
</span><span id="line-68"></span><span class="hs-comment">-- - @decoder@ is a decoder layer.</span><span>
</span><span id="line-69"></span><span class="hs-comment">-- - @bias@ is a bias layer.</span><span>
</span><span id="line-70"></span><span id="local-6989586621679696963"><span id="local-6989586621679696964"></span></span><span class="hs-keyword">data</span><span>
</span><span id="line-71"></span><span>  </span><span id="GLMHead"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#GLMHead"><span class="hs-identifier hs-var">GLMHead</span></a></span></span><span>
</span><span id="line-72"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679696962"><span class="annot"><a href="#local-6989586621679696962"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-73"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679696961"><span class="annot"><a href="#local-6989586621679696961"><span class="hs-identifier hs-type">dense</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span class="hs-special">)</span><span>
</span><span id="line-74"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679696960"><span class="annot"><a href="#local-6989586621679696960"><span class="hs-identifier hs-type">activation</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span class="hs-special">)</span><span>
</span><span id="line-75"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679696959"><span class="annot"><a href="#local-6989586621679696959"><span class="hs-identifier hs-type">layerNorm</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span class="hs-special">)</span><span>
</span><span id="line-76"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679696958"><span class="annot"><a href="#local-6989586621679696958"><span class="hs-identifier hs-type">decoder</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span class="hs-special">)</span><span>
</span><span id="line-77"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679696957"><span class="annot"><a href="#local-6989586621679696957"><span class="hs-identifier hs-type">bias</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span class="hs-special">)</span><span>
</span><span id="line-78"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-79"></span><span>  </span><span id="GLMHead"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#GLMHead"><span class="hs-identifier hs-var">GLMHead</span></a></span></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-80"></span><span>    </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679697281"><span class="annot"><a href="#local-6989586621679697281"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679697280"><span class="annot"><a href="#local-6989586621679697280"><span class="hs-identifier hs-type">dense</span></a></span></span><span> </span><span id="local-6989586621679697279"><span class="annot"><a href="#local-6989586621679697279"><span class="hs-identifier hs-type">activation</span></a></span></span><span> </span><span id="local-6989586621679697278"><span class="annot"><a href="#local-6989586621679697278"><span class="hs-identifier hs-type">layerNorm</span></a></span></span><span> </span><span id="local-6989586621679697277"><span class="annot"><a href="#local-6989586621679697277"><span class="hs-identifier hs-type">decoder</span></a></span></span><span> </span><span id="local-6989586621679697276"><span class="annot"><a href="#local-6989586621679697276"><span class="hs-identifier hs-type">bias</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-81"></span><span>    </span><span class="hs-special">{</span><span> </span><span class="hs-comment">-- | the dimension of the input embedding.</span><span>
</span><span id="line-82"></span><span>      </span><span id="lmHeadInputEmbedDim"><span class="annot"><span class="annottext">GLMHead inputEmbedDim dense activation layerNorm decoder bias
-&gt; SDim inputEmbedDim
</span><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#lmHeadInputEmbedDim"><span class="hs-identifier hs-var hs-var">lmHeadInputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697281"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-83"></span><span>      </span><span class="hs-comment">-- | the dense layer.</span><span>
</span><span id="line-84"></span><span>      </span><span id="lmHeadDense"><span class="annot"><span class="annottext">GLMHead inputEmbedDim dense activation layerNorm decoder bias
-&gt; dense
</span><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#lmHeadDense"><span class="hs-identifier hs-var hs-var">lmHeadDense</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679697280"><span class="hs-identifier hs-type">dense</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-85"></span><span>      </span><span class="hs-comment">-- | the activation function.</span><span>
</span><span id="line-86"></span><span>      </span><span id="lmHeadActivation"><span class="annot"><span class="annottext">GLMHead inputEmbedDim dense activation layerNorm decoder bias
-&gt; activation
</span><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#lmHeadActivation"><span class="hs-identifier hs-var hs-var">lmHeadActivation</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679697279"><span class="hs-identifier hs-type">activation</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-87"></span><span>      </span><span class="hs-comment">-- | the layer normalization layer.</span><span>
</span><span id="line-88"></span><span>      </span><span id="lmHeadLayerNorm"><span class="annot"><span class="annottext">GLMHead inputEmbedDim dense activation layerNorm decoder bias
-&gt; layerNorm
</span><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#lmHeadLayerNorm"><span class="hs-identifier hs-var hs-var">lmHeadLayerNorm</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679697278"><span class="hs-identifier hs-type">layerNorm</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-89"></span><span>      </span><span class="hs-comment">-- | the decoder layer.</span><span>
</span><span id="line-90"></span><span>      </span><span id="lmHeadDecoder"><span class="annot"><span class="annottext">GLMHead inputEmbedDim dense activation layerNorm decoder bias
-&gt; decoder
</span><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#lmHeadDecoder"><span class="hs-identifier hs-var hs-var">lmHeadDecoder</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679697277"><span class="hs-identifier hs-type">decoder</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-91"></span><span>      </span><span class="hs-comment">-- | the bias layer.</span><span>
</span><span id="line-92"></span><span>      </span><span id="lmHeadBias"><span class="annot"><span class="annottext">GLMHead inputEmbedDim dense activation layerNorm decoder bias
-&gt; bias
</span><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#lmHeadBias"><span class="hs-identifier hs-var hs-var">lmHeadBias</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679697276"><span class="hs-identifier hs-type">bias</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-93"></span><span>      </span><span class="hs-comment">-- | whether or not the head has a scaled decoder output.</span><span>
</span><span id="line-94"></span><span>      </span><span id="lmHeadHasScaling"><span class="annot"><span class="annottext">GLMHead inputEmbedDim dense activation layerNorm decoder bias
-&gt; LMHeadHasScaling
</span><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#lmHeadHasScaling"><span class="hs-identifier hs-var hs-var">lmHeadHasScaling</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadHasScaling"><span class="hs-identifier hs-type">LMHeadHasScaling</span></a></span><span>
</span><span id="line-95"></span><span>    </span><span class="hs-special">}</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-96"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#GLMHead"><span class="hs-identifier hs-type">GLMHead</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697281"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697280"><span class="hs-identifier hs-type">dense</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697279"><span class="hs-identifier hs-type">activation</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697278"><span class="hs-identifier hs-type">layerNorm</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697277"><span class="hs-identifier hs-type">decoder</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697276"><span class="hs-identifier hs-type">bias</span></a></span><span>
</span><span id="line-97"></span><span>  </span><span class="hs-keyword">deriving</span><span> </span><span class="annot"><span class="hs-keyword">stock</span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679696943"><span id="local-6989586621679696945"><span id="local-6989586621679696947"><span class="annot"><span class="annottext">Int
-&gt; GLMHead inputEmbedDim dense activation layerNorm decoder bias
-&gt; ShowS
[GLMHead inputEmbedDim dense activation layerNorm decoder bias]
-&gt; ShowS
GLMHead inputEmbedDim dense activation layerNorm decoder bias
-&gt; String
(Int
 -&gt; GLMHead inputEmbedDim dense activation layerNorm decoder bias
 -&gt; ShowS)
-&gt; (GLMHead inputEmbedDim dense activation layerNorm decoder bias
    -&gt; String)
-&gt; ([GLMHead inputEmbedDim dense activation layerNorm decoder bias]
    -&gt; ShowS)
-&gt; Show
     (GLMHead inputEmbedDim dense activation layerNorm decoder bias)
forall a.
(Int -&gt; a -&gt; ShowS) -&gt; (a -&gt; String) -&gt; ([a] -&gt; ShowS) -&gt; Show a
forall (inputEmbedDim :: Dim (Name Symbol) (Size Nat)) dense
       activation layerNorm decoder bias.
(Show dense, Show activation, Show layerNorm, Show decoder,
 Show bias) =&gt;
Int
-&gt; GLMHead inputEmbedDim dense activation layerNorm decoder bias
-&gt; ShowS
forall (inputEmbedDim :: Dim (Name Symbol) (Size Nat)) dense
       activation layerNorm decoder bias.
(Show dense, Show activation, Show layerNorm, Show decoder,
 Show bias) =&gt;
[GLMHead inputEmbedDim dense activation layerNorm decoder bias]
-&gt; ShowS
forall (inputEmbedDim :: Dim (Name Symbol) (Size Nat)) dense
       activation layerNorm decoder bias.
(Show dense, Show activation, Show layerNorm, Show decoder,
 Show bias) =&gt;
GLMHead inputEmbedDim dense activation layerNorm decoder bias
-&gt; String
showList :: [GLMHead inputEmbedDim dense activation layerNorm decoder bias]
-&gt; ShowS
$cshowList :: forall (inputEmbedDim :: Dim (Name Symbol) (Size Nat)) dense
       activation layerNorm decoder bias.
(Show dense, Show activation, Show layerNorm, Show decoder,
 Show bias) =&gt;
[GLMHead inputEmbedDim dense activation layerNorm decoder bias]
-&gt; ShowS
show :: GLMHead inputEmbedDim dense activation layerNorm decoder bias
-&gt; String
$cshow :: forall (inputEmbedDim :: Dim (Name Symbol) (Size Nat)) dense
       activation layerNorm decoder bias.
(Show dense, Show activation, Show layerNorm, Show decoder,
 Show bias) =&gt;
GLMHead inputEmbedDim dense activation layerNorm decoder bias
-&gt; String
showsPrec :: Int
-&gt; GLMHead inputEmbedDim dense activation layerNorm decoder bias
-&gt; ShowS
$cshowsPrec :: forall (inputEmbedDim :: Dim (Name Symbol) (Size Nat)) dense
       activation layerNorm decoder bias.
(Show dense, Show activation, Show layerNorm, Show decoder,
 Show bias) =&gt;
Int
-&gt; GLMHead inputEmbedDim dense activation layerNorm decoder bias
-&gt; ShowS
</span><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">Show</span></span></span></span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">(forall x.
 GLMHead inputEmbedDim dense activation layerNorm decoder bias
 -&gt; Rep
      (GLMHead inputEmbedDim dense activation layerNorm decoder bias) x)
-&gt; (forall x.
    Rep
      (GLMHead inputEmbedDim dense activation layerNorm decoder bias) x
    -&gt; GLMHead inputEmbedDim dense activation layerNorm decoder bias)
-&gt; Generic
     (GLMHead inputEmbedDim dense activation layerNorm decoder bias)
forall x.
Rep
  (GLMHead inputEmbedDim dense activation layerNorm decoder bias) x
-&gt; GLMHead inputEmbedDim dense activation layerNorm decoder bias
forall x.
GLMHead inputEmbedDim dense activation layerNorm decoder bias
-&gt; Rep
     (GLMHead inputEmbedDim dense activation layerNorm decoder bias) x
forall a.
(forall x. a -&gt; Rep a x) -&gt; (forall x. Rep a x -&gt; a) -&gt; Generic a
forall (inputEmbedDim :: Dim (Name Symbol) (Size Nat)) dense
       activation layerNorm decoder bias x.
Rep
  (GLMHead inputEmbedDim dense activation layerNorm decoder bias) x
-&gt; GLMHead inputEmbedDim dense activation layerNorm decoder bias
forall (inputEmbedDim :: Dim (Name Symbol) (Size Nat)) dense
       activation layerNorm decoder bias x.
GLMHead inputEmbedDim dense activation layerNorm decoder bias
-&gt; Rep
     (GLMHead inputEmbedDim dense activation layerNorm decoder bias) x
$cto :: forall (inputEmbedDim :: Dim (Name Symbol) (Size Nat)) dense
       activation layerNorm decoder bias x.
Rep
  (GLMHead inputEmbedDim dense activation layerNorm decoder bias) x
-&gt; GLMHead inputEmbedDim dense activation layerNorm decoder bias
$cfrom :: forall (inputEmbedDim :: Dim (Name Symbol) (Size Nat)) dense
       activation layerNorm decoder bias x.
GLMHead inputEmbedDim dense activation layerNorm decoder bias
-&gt; Rep
     (GLMHead inputEmbedDim dense activation layerNorm decoder bias) x
</span><span class="hs-identifier hs-var hs-var hs-var hs-var">Generic</span></span><span class="hs-special">)</span><span>
</span><span id="line-98"></span><span>
</span><span id="line-99"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">instance</span><span>
</span><span id="line-100"></span><span>  </span><span id="ModelSpec"><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier hs-var">ModelSpec</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#GLMHead"><span class="hs-identifier hs-type">GLMHead</span></a></span><span> </span><span id="local-6989586621679696940"><span class="annot"><a href="#local-6989586621679696940"><span class="hs-identifier hs-type hs-type">inputEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679696939"><span class="annot"><a href="#local-6989586621679696939"><span class="hs-identifier hs-type hs-type">dense</span></a></span></span><span> </span><span id="local-6989586621679696938"><span class="annot"><a href="#local-6989586621679696938"><span class="hs-identifier hs-type hs-type">activation</span></a></span></span><span> </span><span id="local-6989586621679696937"><span class="annot"><a href="#local-6989586621679696937"><span class="hs-identifier hs-type hs-type">layerNorm</span></a></span></span><span> </span><span id="local-6989586621679696936"><span class="annot"><a href="#local-6989586621679696936"><span class="hs-identifier hs-type hs-type">decoder</span></a></span></span><span> </span><span id="local-6989586621679696935"><span class="annot"><a href="#local-6989586621679696935"><span class="hs-identifier hs-type hs-type">bias</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-101"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#GLMHead"><span class="hs-identifier hs-type">GLMHead</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696940"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier hs-type">ModelSpec</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696939"><span class="hs-identifier hs-type">dense</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier hs-type">ModelSpec</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696938"><span class="hs-identifier hs-type">activation</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier hs-type">ModelSpec</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696937"><span class="hs-identifier hs-type">layerNorm</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier hs-type">ModelSpec</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696936"><span class="hs-identifier hs-type">decoder</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier hs-type">ModelSpec</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696935"><span class="hs-identifier hs-type">bias</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-102"></span><span>
</span><span id="line-103"></span><span class="hs-comment">-- | Generic data type for biasing the language model head.</span><span>
</span><span id="line-104"></span><span id="local-6989586621679696933"><span id="local-6989586621679696934"></span></span><span class="hs-keyword">data</span><span> </span><span id="GBias"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#GBias"><span class="hs-identifier hs-var">GBias</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679696932"><span class="annot"><a href="#local-6989586621679696932"><span class="hs-identifier hs-type">bias</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span class="hs-special">)</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-105"></span><span>  </span><span id="GBias"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#GBias"><span class="hs-identifier hs-var">GBias</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679697285"><span class="annot"><a href="#local-6989586621679697285"><span class="hs-identifier hs-type">bias</span></a></span></span><span class="hs-operator">.</span><span> </span><span class="annot"><a href="#local-6989586621679697285"><span class="hs-identifier hs-type">bias</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#GBias"><span class="hs-identifier hs-type">GBias</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679697285"><span class="hs-identifier hs-type">bias</span></a></span><span>
</span><span id="line-106"></span><span>  </span><span class="hs-keyword">deriving</span><span> </span><span class="annot"><span class="hs-keyword">stock</span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679696927"><span id="local-6989586621679696929"><span class="annot"><span class="annottext">GBias bias -&gt; GBias bias -&gt; Bool
(GBias bias -&gt; GBias bias -&gt; Bool)
-&gt; (GBias bias -&gt; GBias bias -&gt; Bool) -&gt; Eq (GBias bias)
forall bias. Eq bias =&gt; GBias bias -&gt; GBias bias -&gt; Bool
forall a. (a -&gt; a -&gt; Bool) -&gt; (a -&gt; a -&gt; Bool) -&gt; Eq a
/= :: GBias bias -&gt; GBias bias -&gt; Bool
$c/= :: forall bias. Eq bias =&gt; GBias bias -&gt; GBias bias -&gt; Bool
== :: GBias bias -&gt; GBias bias -&gt; Bool
$c== :: forall bias. Eq bias =&gt; GBias bias -&gt; GBias bias -&gt; Bool
</span><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var">Eq</span></span></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679696912"><span id="local-6989586621679696914"><span id="local-6989586621679696916"><span id="local-6989586621679696918"><span id="local-6989586621679696920"><span id="local-6989586621679696922"><span id="local-6989586621679696924"><span class="annot"><span class="annottext">Eq (GBias bias)
Eq (GBias bias)
-&gt; (GBias bias -&gt; GBias bias -&gt; Ordering)
-&gt; (GBias bias -&gt; GBias bias -&gt; Bool)
-&gt; (GBias bias -&gt; GBias bias -&gt; Bool)
-&gt; (GBias bias -&gt; GBias bias -&gt; Bool)
-&gt; (GBias bias -&gt; GBias bias -&gt; Bool)
-&gt; (GBias bias -&gt; GBias bias -&gt; GBias bias)
-&gt; (GBias bias -&gt; GBias bias -&gt; GBias bias)
-&gt; Ord (GBias bias)
GBias bias -&gt; GBias bias -&gt; Bool
GBias bias -&gt; GBias bias -&gt; Ordering
GBias bias -&gt; GBias bias -&gt; GBias bias
forall a.
Eq a
-&gt; (a -&gt; a -&gt; Ordering)
-&gt; (a -&gt; a -&gt; Bool)
-&gt; (a -&gt; a -&gt; Bool)
-&gt; (a -&gt; a -&gt; Bool)
-&gt; (a -&gt; a -&gt; Bool)
-&gt; (a -&gt; a -&gt; a)
-&gt; (a -&gt; a -&gt; a)
-&gt; Ord a
forall bias. Ord bias =&gt; Eq (GBias bias)
forall bias. Ord bias =&gt; GBias bias -&gt; GBias bias -&gt; Bool
forall bias. Ord bias =&gt; GBias bias -&gt; GBias bias -&gt; Ordering
forall bias. Ord bias =&gt; GBias bias -&gt; GBias bias -&gt; GBias bias
min :: GBias bias -&gt; GBias bias -&gt; GBias bias
$cmin :: forall bias. Ord bias =&gt; GBias bias -&gt; GBias bias -&gt; GBias bias
max :: GBias bias -&gt; GBias bias -&gt; GBias bias
$cmax :: forall bias. Ord bias =&gt; GBias bias -&gt; GBias bias -&gt; GBias bias
&gt;= :: GBias bias -&gt; GBias bias -&gt; Bool
$c&gt;= :: forall bias. Ord bias =&gt; GBias bias -&gt; GBias bias -&gt; Bool
&gt; :: GBias bias -&gt; GBias bias -&gt; Bool
$c&gt; :: forall bias. Ord bias =&gt; GBias bias -&gt; GBias bias -&gt; Bool
&lt;= :: GBias bias -&gt; GBias bias -&gt; Bool
$c&lt;= :: forall bias. Ord bias =&gt; GBias bias -&gt; GBias bias -&gt; Bool
&lt; :: GBias bias -&gt; GBias bias -&gt; Bool
$c&lt; :: forall bias. Ord bias =&gt; GBias bias -&gt; GBias bias -&gt; Bool
compare :: GBias bias -&gt; GBias bias -&gt; Ordering
$ccompare :: forall bias. Ord bias =&gt; GBias bias -&gt; GBias bias -&gt; Ordering
$cp1Ord :: forall bias. Ord bias =&gt; Eq (GBias bias)
</span><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">Ord</span></span></span></span></span></span></span></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679696906"><span id="local-6989586621679696908"><span id="local-6989586621679696910"><span class="annot"><span class="annottext">Int -&gt; GBias bias -&gt; ShowS
[GBias bias] -&gt; ShowS
GBias bias -&gt; String
(Int -&gt; GBias bias -&gt; ShowS)
-&gt; (GBias bias -&gt; String)
-&gt; ([GBias bias] -&gt; ShowS)
-&gt; Show (GBias bias)
forall bias. Show bias =&gt; Int -&gt; GBias bias -&gt; ShowS
forall bias. Show bias =&gt; [GBias bias] -&gt; ShowS
forall bias. Show bias =&gt; GBias bias -&gt; String
forall a.
(Int -&gt; a -&gt; ShowS) -&gt; (a -&gt; String) -&gt; ([a] -&gt; ShowS) -&gt; Show a
showList :: [GBias bias] -&gt; ShowS
$cshowList :: forall bias. Show bias =&gt; [GBias bias] -&gt; ShowS
show :: GBias bias -&gt; String
$cshow :: forall bias. Show bias =&gt; GBias bias -&gt; String
showsPrec :: Int -&gt; GBias bias -&gt; ShowS
$cshowsPrec :: forall bias. Show bias =&gt; Int -&gt; GBias bias -&gt; ShowS
</span><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">Show</span></span></span></span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">(forall x. GBias bias -&gt; Rep (GBias bias) x)
-&gt; (forall x. Rep (GBias bias) x -&gt; GBias bias)
-&gt; Generic (GBias bias)
forall x. Rep (GBias bias) x -&gt; GBias bias
forall x. GBias bias -&gt; Rep (GBias bias) x
forall a.
(forall x. a -&gt; Rep a x) -&gt; (forall x. Rep a x -&gt; a) -&gt; Generic a
forall bias x. Rep (GBias bias) x -&gt; GBias bias
forall bias x. GBias bias -&gt; Rep (GBias bias) x
$cto :: forall bias x. Rep (GBias bias) x -&gt; GBias bias
$cfrom :: forall bias x. GBias bias -&gt; Rep (GBias bias) x
</span><span class="hs-identifier hs-var hs-var hs-var hs-var">Generic</span></span><span class="hs-special">)</span><span>
</span><span id="line-107"></span><span>
</span><span id="line-108"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">instance</span><span> </span><span id="ModelSpec"><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier hs-var">ModelSpec</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#GBias"><span class="hs-identifier hs-type">GBias</span></a></span><span> </span><span id="local-6989586621679696903"><span class="annot"><a href="#local-6989586621679696903"><span class="hs-identifier hs-type hs-type">bias</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#GBias"><span class="hs-identifier hs-type">GBias</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier hs-type">ModelSpec</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696903"><span class="hs-identifier hs-type">bias</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-109"></span><span>
</span><span id="line-110"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span>
</span><span id="line-111"></span><span>  </span><span id="GLMHeadF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#GLMHeadF"><span class="hs-identifier hs-var">GLMHeadF</span></a></span></span><span>
</span><span id="line-112"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679696902"><span class="annot"><a href="#local-6989586621679696902"><span class="hs-identifier hs-type">style</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerStyle"><span class="hs-identifier hs-type">TransformerStyle</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-113"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679696901"><span class="annot"><a href="#local-6989586621679696901"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#RequiresGradient"><span class="hs-identifier hs-type">RequiresGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-114"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679696900"><span class="annot"><a href="#local-6989586621679696900"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier hs-type">Device</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#DeviceType"><span class="hs-identifier hs-type">DeviceType</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-115"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679696899"><span class="annot"><a href="#local-6989586621679696899"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier hs-type">DType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-116"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679696898"><span class="annot"><a href="#local-6989586621679696898"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-117"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679696897"><span class="annot"><a href="#local-6989586621679696897"><span class="hs-identifier hs-type">vocabDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-118"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span>
</span><span id="line-119"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-120"></span><span>  </span><span id="GLMHeadF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#GLMHeadF"><span class="hs-identifier hs-var">GLMHeadF</span></a></span></span><span> </span><span id="local-6989586621679696896"><span class="annot"><a href="#local-6989586621679696896"><span class="hs-identifier hs-type hs-type">style</span></a></span></span><span> </span><span id="local-6989586621679696895"><span class="annot"><a href="#local-6989586621679696895"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679696894"><span class="annot"><a href="#local-6989586621679696894"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679696893"><span class="annot"><a href="#local-6989586621679696893"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679696892"><span class="annot"><a href="#local-6989586621679696892"><span class="hs-identifier hs-type hs-type">inputEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679696891"><span class="annot"><a href="#local-6989586621679696891"><span class="hs-identifier hs-type hs-type">vocabDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-121"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#GLMHead"><span class="hs-identifier hs-type">GLMHead</span></a></span><span>
</span><span id="line-122"></span><span>      </span><span class="annot"><a href="#local-6989586621679696892"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span>
</span><span id="line-123"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadDenseF"><span class="hs-identifier hs-type">LMHeadDenseF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696896"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696895"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696894"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696893"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696892"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-124"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadActivationF"><span class="hs-identifier hs-type">LMHeadActivationF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696896"><span class="hs-identifier hs-type">style</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-125"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadLayerNormF"><span class="hs-identifier hs-type">LMHeadLayerNormF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696896"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696895"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696894"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696893"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696892"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-126"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadDecoderF"><span class="hs-identifier hs-type">LMHeadDecoderF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696896"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696895"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696894"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696893"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696892"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696891"><span class="hs-identifier hs-type">vocabDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-127"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadBiasF"><span class="hs-identifier hs-type">LMHeadBiasF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696896"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696895"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696894"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696893"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696891"><span class="hs-identifier hs-type">vocabDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-128"></span><span>
</span><span id="line-129"></span><span class="hs-comment">-- | Specifies the dense layer of the language model head.</span><span>
</span><span id="line-130"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span>
</span><span id="line-131"></span><span>  </span><span id="LMHeadDenseF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadDenseF"><span class="hs-identifier hs-var">LMHeadDenseF</span></a></span></span><span>
</span><span id="line-132"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679696890"><span class="annot"><a href="#local-6989586621679696890"><span class="hs-identifier hs-type">style</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerStyle"><span class="hs-identifier hs-type">TransformerStyle</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-133"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679696889"><span class="annot"><a href="#local-6989586621679696889"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#RequiresGradient"><span class="hs-identifier hs-type">RequiresGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-134"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679696888"><span class="annot"><a href="#local-6989586621679696888"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier hs-type">Device</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#DeviceType"><span class="hs-identifier hs-type">DeviceType</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-135"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679696887"><span class="annot"><a href="#local-6989586621679696887"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier hs-type">DType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-136"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679696886"><span class="annot"><a href="#local-6989586621679696886"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-137"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span>
</span><span id="line-138"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-139"></span><span>  </span><span id="LMHeadDenseF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadDenseF"><span class="hs-identifier hs-var">LMHeadDenseF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#T5"><span class="hs-identifier hs-type">T5</span></a></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-140"></span><span>    </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-141"></span><span>  </span><span id="LMHeadDenseF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadDenseF"><span class="hs-identifier hs-var">LMHeadDenseF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ByT5"><span class="hs-identifier hs-type">ByT5</span></a></span><span> </span><span id="local-6989586621679696883"><span class="annot"><a href="#local-6989586621679696883"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679696882"><span class="annot"><a href="#local-6989586621679696882"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679696881"><span class="annot"><a href="#local-6989586621679696881"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679696880"><span class="annot"><a href="#local-6989586621679696880"><span class="hs-identifier hs-type hs-type">inputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-142"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadDenseF"><span class="hs-identifier hs-type">LMHeadDenseF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#T5"><span class="hs-identifier hs-type">T5</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696883"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696882"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696881"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696880"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span>
</span><span id="line-143"></span><span>  </span><span id="LMHeadDenseF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadDenseF"><span class="hs-identifier hs-var">LMHeadDenseF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-144"></span><span>    </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-145"></span><span>  </span><span id="LMHeadDenseF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadDenseF"><span class="hs-identifier hs-var">LMHeadDenseF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MBART"><span class="hs-identifier hs-type">MBART</span></a></span><span> </span><span id="local-6989586621679696877"><span class="annot"><a href="#local-6989586621679696877"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679696876"><span class="annot"><a href="#local-6989586621679696876"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679696875"><span class="annot"><a href="#local-6989586621679696875"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679696874"><span class="annot"><a href="#local-6989586621679696874"><span class="hs-identifier hs-type hs-type">inputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-146"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadDenseF"><span class="hs-identifier hs-type">LMHeadDenseF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696877"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696876"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696875"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696874"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span>
</span><span id="line-147"></span><span>  </span><span id="LMHeadDenseF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadDenseF"><span class="hs-identifier hs-var">LMHeadDenseF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#Pegasus"><span class="hs-identifier hs-type">Pegasus</span></a></span><span> </span><span id="local-6989586621679696872"><span class="annot"><a href="#local-6989586621679696872"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679696871"><span class="annot"><a href="#local-6989586621679696871"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679696870"><span class="annot"><a href="#local-6989586621679696870"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679696869"><span class="annot"><a href="#local-6989586621679696869"><span class="hs-identifier hs-type hs-type">inputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-148"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadDenseF"><span class="hs-identifier hs-type">LMHeadDenseF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696872"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696871"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696870"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696869"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span>
</span><span id="line-149"></span><span>  </span><span id="LMHeadDenseF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadDenseF"><span class="hs-identifier hs-var">LMHeadDenseF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BERT"><span class="hs-identifier hs-type">BERT</span></a></span><span> </span><span id="local-6989586621679696867"><span class="annot"><a href="#local-6989586621679696867"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679696866"><span class="annot"><a href="#local-6989586621679696866"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679696865"><span class="annot"><a href="#local-6989586621679696865"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679696864"><span class="annot"><a href="#local-6989586621679696864"><span class="hs-identifier hs-type hs-type">inputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-150"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-type">NamedModel</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Linear.html#GLinearF"><span class="hs-identifier hs-type">GLinearF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Type.html#WithBias"><span class="hs-identifier hs-type">WithBias</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696867"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696866"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696865"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696864"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696864"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-151"></span><span>  </span><span id="LMHeadDenseF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadDenseF"><span class="hs-identifier hs-var">LMHeadDenseF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#RoBERTa"><span class="hs-identifier hs-type">RoBERTa</span></a></span><span> </span><span id="local-6989586621679696862"><span class="annot"><a href="#local-6989586621679696862"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679696861"><span class="annot"><a href="#local-6989586621679696861"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679696860"><span class="annot"><a href="#local-6989586621679696860"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679696859"><span class="annot"><a href="#local-6989586621679696859"><span class="hs-identifier hs-type hs-type">inputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-152"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadDenseF"><span class="hs-identifier hs-type">LMHeadDenseF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BERT"><span class="hs-identifier hs-type">BERT</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696862"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696861"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696860"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696859"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span>
</span><span id="line-153"></span><span>
</span><span id="line-154"></span><span class="hs-comment">-- | Specifies the activation function of the language model head.</span><span>
</span><span id="line-155"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span>
</span><span id="line-156"></span><span>  </span><span id="LMHeadActivationF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadActivationF"><span class="hs-identifier hs-var">LMHeadActivationF</span></a></span></span><span>
</span><span id="line-157"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679696858"><span class="annot"><a href="#local-6989586621679696858"><span class="hs-identifier hs-type">style</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerStyle"><span class="hs-identifier hs-type">TransformerStyle</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-158"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span>
</span><span id="line-159"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-160"></span><span>  </span><span id="LMHeadActivationF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadActivationF"><span class="hs-identifier hs-var">LMHeadActivationF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#T5"><span class="hs-identifier hs-type">T5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-161"></span><span>  </span><span id="LMHeadActivationF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadActivationF"><span class="hs-identifier hs-var">LMHeadActivationF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ByT5"><span class="hs-identifier hs-type">ByT5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadActivationF"><span class="hs-identifier hs-type">LMHeadActivationF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#T5"><span class="hs-identifier hs-type">T5</span></a></span><span>
</span><span id="line-162"></span><span>  </span><span id="LMHeadActivationF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadActivationF"><span class="hs-identifier hs-var">LMHeadActivationF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-163"></span><span>  </span><span id="LMHeadActivationF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadActivationF"><span class="hs-identifier hs-var">LMHeadActivationF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MBART"><span class="hs-identifier hs-type">MBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadActivationF"><span class="hs-identifier hs-type">LMHeadActivationF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span>
</span><span id="line-164"></span><span>  </span><span id="LMHeadActivationF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadActivationF"><span class="hs-identifier hs-var">LMHeadActivationF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#Pegasus"><span class="hs-identifier hs-type">Pegasus</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadActivationF"><span class="hs-identifier hs-type">LMHeadActivationF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span>
</span><span id="line-165"></span><span>  </span><span id="LMHeadActivationF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadActivationF"><span class="hs-identifier hs-var">LMHeadActivationF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BERT"><span class="hs-identifier hs-type">BERT</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Activation.html#Gelu"><span class="hs-identifier hs-type">Gelu</span></a></span><span>
</span><span id="line-166"></span><span>  </span><span id="LMHeadActivationF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadActivationF"><span class="hs-identifier hs-var">LMHeadActivationF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#RoBERTa"><span class="hs-identifier hs-type">RoBERTa</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadActivationF"><span class="hs-identifier hs-type">LMHeadActivationF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BERT"><span class="hs-identifier hs-type">BERT</span></a></span><span>
</span><span id="line-167"></span><span>
</span><span id="line-168"></span><span class="hs-comment">-- | Specifies the layer normalization layer of the language model head.</span><span>
</span><span id="line-169"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span>
</span><span id="line-170"></span><span>  </span><span id="LMHeadLayerNormF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadLayerNormF"><span class="hs-identifier hs-var">LMHeadLayerNormF</span></a></span></span><span>
</span><span id="line-171"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679696857"><span class="annot"><a href="#local-6989586621679696857"><span class="hs-identifier hs-type">style</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerStyle"><span class="hs-identifier hs-type">TransformerStyle</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-172"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679696856"><span class="annot"><a href="#local-6989586621679696856"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#RequiresGradient"><span class="hs-identifier hs-type">RequiresGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-173"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679696855"><span class="annot"><a href="#local-6989586621679696855"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier hs-type">Device</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#DeviceType"><span class="hs-identifier hs-type">DeviceType</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-174"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679696854"><span class="annot"><a href="#local-6989586621679696854"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier hs-type">DType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-175"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679696853"><span class="annot"><a href="#local-6989586621679696853"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-176"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span>
</span><span id="line-177"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-178"></span><span>  </span><span id="LMHeadLayerNormF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadLayerNormF"><span class="hs-identifier hs-var">LMHeadLayerNormF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#T5"><span class="hs-identifier hs-type">T5</span></a></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-179"></span><span>  </span><span id="LMHeadLayerNormF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadLayerNormF"><span class="hs-identifier hs-var">LMHeadLayerNormF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ByT5"><span class="hs-identifier hs-type">ByT5</span></a></span><span> </span><span id="local-6989586621679696852"><span class="annot"><a href="#local-6989586621679696852"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679696851"><span class="annot"><a href="#local-6989586621679696851"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679696850"><span class="annot"><a href="#local-6989586621679696850"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679696849"><span class="annot"><a href="#local-6989586621679696849"><span class="hs-identifier hs-type hs-type">inputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-180"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadLayerNormF"><span class="hs-identifier hs-type">LMHeadLayerNormF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#T5"><span class="hs-identifier hs-type">T5</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696852"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696851"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696850"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696849"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span>
</span><span id="line-181"></span><span>  </span><span id="LMHeadLayerNormF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadLayerNormF"><span class="hs-identifier hs-var">LMHeadLayerNormF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-182"></span><span>  </span><span id="LMHeadLayerNormF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadLayerNormF"><span class="hs-identifier hs-var">LMHeadLayerNormF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MBART"><span class="hs-identifier hs-type">MBART</span></a></span><span> </span><span id="local-6989586621679696848"><span class="annot"><a href="#local-6989586621679696848"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679696847"><span class="annot"><a href="#local-6989586621679696847"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679696846"><span class="annot"><a href="#local-6989586621679696846"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679696845"><span class="annot"><a href="#local-6989586621679696845"><span class="hs-identifier hs-type hs-type">inputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-183"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadLayerNormF"><span class="hs-identifier hs-type">LMHeadLayerNormF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696848"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696847"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696846"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696845"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span>
</span><span id="line-184"></span><span>  </span><span id="LMHeadLayerNormF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadLayerNormF"><span class="hs-identifier hs-var">LMHeadLayerNormF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#Pegasus"><span class="hs-identifier hs-type">Pegasus</span></a></span><span> </span><span id="local-6989586621679696844"><span class="annot"><a href="#local-6989586621679696844"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679696843"><span class="annot"><a href="#local-6989586621679696843"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679696842"><span class="annot"><a href="#local-6989586621679696842"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679696841"><span class="annot"><a href="#local-6989586621679696841"><span class="hs-identifier hs-type hs-type">inputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-185"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadLayerNormF"><span class="hs-identifier hs-type">LMHeadLayerNormF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696844"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696843"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696842"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696841"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span>
</span><span id="line-186"></span><span>  </span><span id="LMHeadLayerNormF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadLayerNormF"><span class="hs-identifier hs-var">LMHeadLayerNormF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BERT"><span class="hs-identifier hs-type">BERT</span></a></span><span> </span><span id="local-6989586621679696840"><span class="annot"><a href="#local-6989586621679696840"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679696839"><span class="annot"><a href="#local-6989586621679696839"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679696838"><span class="annot"><a href="#local-6989586621679696838"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679696837"><span class="annot"><a href="#local-6989586621679696837"><span class="hs-identifier hs-type hs-type">inputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-187"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-type">NamedModel</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Normalization.html#LayerNorm"><span class="hs-identifier hs-type">LayerNorm</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Type.html#WithBias"><span class="hs-identifier hs-type">WithBias</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696840"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696839"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696838"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679696837"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-188"></span><span>  </span><span id="LMHeadLayerNormF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadLayerNormF"><span class="hs-identifier hs-var">LMHeadLayerNormF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#RoBERTa"><span class="hs-identifier hs-type">RoBERTa</span></a></span><span> </span><span id="local-6989586621679696836"><span class="annot"><a href="#local-6989586621679696836"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679696835"><span class="annot"><a href="#local-6989586621679696835"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679696834"><span class="annot"><a href="#local-6989586621679696834"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679696833"><span class="annot"><a href="#local-6989586621679696833"><span class="hs-identifier hs-type hs-type">inputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-189"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadLayerNormF"><span class="hs-identifier hs-type">LMHeadLayerNormF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BERT"><span class="hs-identifier hs-type">BERT</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696836"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696835"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696834"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696833"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span>
</span><span id="line-190"></span><span>
</span><span id="line-191"></span><span class="hs-comment">-- | Specifies the decoder layer of the language model head.</span><span>
</span><span id="line-192"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span>
</span><span id="line-193"></span><span>  </span><span id="LMHeadDecoderF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadDecoderF"><span class="hs-identifier hs-var">LMHeadDecoderF</span></a></span></span><span>
</span><span id="line-194"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679696832"><span class="annot"><a href="#local-6989586621679696832"><span class="hs-identifier hs-type">style</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerStyle"><span class="hs-identifier hs-type">TransformerStyle</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-195"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679696831"><span class="annot"><a href="#local-6989586621679696831"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#RequiresGradient"><span class="hs-identifier hs-type">RequiresGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-196"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679696830"><span class="annot"><a href="#local-6989586621679696830"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier hs-type">Device</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#DeviceType"><span class="hs-identifier hs-type">DeviceType</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-197"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679696829"><span class="annot"><a href="#local-6989586621679696829"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier hs-type">DType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-198"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679696828"><span class="annot"><a href="#local-6989586621679696828"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-199"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679696827"><span class="annot"><a href="#local-6989586621679696827"><span class="hs-identifier hs-type">vocabDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-200"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span>
</span><span id="line-201"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-202"></span><span>  </span><span id="LMHeadDecoderF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadDecoderF"><span class="hs-identifier hs-var">LMHeadDecoderF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#T5"><span class="hs-identifier hs-type">T5</span></a></span><span> </span><span id="local-6989586621679696826"><span class="annot"><a href="#local-6989586621679696826"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679696825"><span class="annot"><a href="#local-6989586621679696825"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679696824"><span class="annot"><a href="#local-6989586621679696824"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679696823"><span class="annot"><a href="#local-6989586621679696823"><span class="hs-identifier hs-type hs-type">inputEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679696822"><span class="annot"><a href="#local-6989586621679696822"><span class="hs-identifier hs-type hs-type">vocabDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-203"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-type">NamedModel</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Linear.html#GLinearF"><span class="hs-identifier hs-type">GLinearF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Type.html#WithoutBias"><span class="hs-identifier hs-type">WithoutBias</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696826"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696825"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696824"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696823"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696822"><span class="hs-identifier hs-type">vocabDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-204"></span><span>  </span><span id="LMHeadDecoderF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadDecoderF"><span class="hs-identifier hs-var">LMHeadDecoderF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ByT5"><span class="hs-identifier hs-type">ByT5</span></a></span><span> </span><span id="local-6989586621679696821"><span class="annot"><a href="#local-6989586621679696821"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679696820"><span class="annot"><a href="#local-6989586621679696820"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679696819"><span class="annot"><a href="#local-6989586621679696819"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679696818"><span class="annot"><a href="#local-6989586621679696818"><span class="hs-identifier hs-type hs-type">inputEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679696817"><span class="annot"><a href="#local-6989586621679696817"><span class="hs-identifier hs-type hs-type">vocabDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-205"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadDecoderF"><span class="hs-identifier hs-type">LMHeadDecoderF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#T5"><span class="hs-identifier hs-type">T5</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696821"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696820"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696819"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696818"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696817"><span class="hs-identifier hs-type">vocabDim</span></a></span><span>
</span><span id="line-206"></span><span>  </span><span id="LMHeadDecoderF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadDecoderF"><span class="hs-identifier hs-var">LMHeadDecoderF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span> </span><span id="local-6989586621679696816"><span class="annot"><a href="#local-6989586621679696816"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679696815"><span class="annot"><a href="#local-6989586621679696815"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679696814"><span class="annot"><a href="#local-6989586621679696814"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679696813"><span class="annot"><a href="#local-6989586621679696813"><span class="hs-identifier hs-type hs-type">inputEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679696812"><span class="annot"><a href="#local-6989586621679696812"><span class="hs-identifier hs-type hs-type">vocabDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-207"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-type">NamedModel</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Linear.html#GLinearF"><span class="hs-identifier hs-type">GLinearF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Type.html#WithoutBias"><span class="hs-identifier hs-type">WithoutBias</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696816"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696815"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696814"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696813"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696812"><span class="hs-identifier hs-type">vocabDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-208"></span><span>  </span><span id="LMHeadDecoderF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadDecoderF"><span class="hs-identifier hs-var">LMHeadDecoderF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MBART"><span class="hs-identifier hs-type">MBART</span></a></span><span> </span><span id="local-6989586621679696811"><span class="annot"><a href="#local-6989586621679696811"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679696810"><span class="annot"><a href="#local-6989586621679696810"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679696809"><span class="annot"><a href="#local-6989586621679696809"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679696808"><span class="annot"><a href="#local-6989586621679696808"><span class="hs-identifier hs-type hs-type">inputEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679696807"><span class="annot"><a href="#local-6989586621679696807"><span class="hs-identifier hs-type hs-type">vocabDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-209"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadDecoderF"><span class="hs-identifier hs-type">LMHeadDecoderF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696811"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696810"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696809"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696808"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696807"><span class="hs-identifier hs-type">vocabDim</span></a></span><span>
</span><span id="line-210"></span><span>  </span><span id="LMHeadDecoderF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadDecoderF"><span class="hs-identifier hs-var">LMHeadDecoderF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#Pegasus"><span class="hs-identifier hs-type">Pegasus</span></a></span><span> </span><span id="local-6989586621679696806"><span class="annot"><a href="#local-6989586621679696806"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679696805"><span class="annot"><a href="#local-6989586621679696805"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679696804"><span class="annot"><a href="#local-6989586621679696804"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679696803"><span class="annot"><a href="#local-6989586621679696803"><span class="hs-identifier hs-type hs-type">inputEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679696802"><span class="annot"><a href="#local-6989586621679696802"><span class="hs-identifier hs-type hs-type">vocabDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-211"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadDecoderF"><span class="hs-identifier hs-type">LMHeadDecoderF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696806"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696805"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696804"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696803"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696802"><span class="hs-identifier hs-type">vocabDim</span></a></span><span>
</span><span id="line-212"></span><span>  </span><span id="LMHeadDecoderF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadDecoderF"><span class="hs-identifier hs-var">LMHeadDecoderF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BERT"><span class="hs-identifier hs-type">BERT</span></a></span><span> </span><span id="local-6989586621679696801"><span class="annot"><a href="#local-6989586621679696801"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679696800"><span class="annot"><a href="#local-6989586621679696800"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679696799"><span class="annot"><a href="#local-6989586621679696799"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679696798"><span class="annot"><a href="#local-6989586621679696798"><span class="hs-identifier hs-type hs-type">inputEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679696797"><span class="annot"><a href="#local-6989586621679696797"><span class="hs-identifier hs-type hs-type">vocabDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-213"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-type">NamedModel</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Linear.html#GLinearF"><span class="hs-identifier hs-type">GLinearF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Type.html#WithBias"><span class="hs-identifier hs-type">WithBias</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696801"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696800"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696799"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696798"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696797"><span class="hs-identifier hs-type">vocabDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-214"></span><span>  </span><span id="LMHeadDecoderF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadDecoderF"><span class="hs-identifier hs-var">LMHeadDecoderF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#RoBERTa"><span class="hs-identifier hs-type">RoBERTa</span></a></span><span> </span><span id="local-6989586621679696796"><span class="annot"><a href="#local-6989586621679696796"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679696795"><span class="annot"><a href="#local-6989586621679696795"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679696794"><span class="annot"><a href="#local-6989586621679696794"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679696793"><span class="annot"><a href="#local-6989586621679696793"><span class="hs-identifier hs-type hs-type">inputEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679696792"><span class="annot"><a href="#local-6989586621679696792"><span class="hs-identifier hs-type hs-type">vocabDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-215"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadDecoderF"><span class="hs-identifier hs-type">LMHeadDecoderF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BERT"><span class="hs-identifier hs-type">BERT</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696796"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696795"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696794"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696793"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696792"><span class="hs-identifier hs-type">vocabDim</span></a></span><span>
</span><span id="line-216"></span><span>
</span><span id="line-217"></span><span class="hs-comment">-- | Specifies the bias layer of the language model head.</span><span>
</span><span id="line-218"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span>
</span><span id="line-219"></span><span>  </span><span id="LMHeadBiasF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadBiasF"><span class="hs-identifier hs-var">LMHeadBiasF</span></a></span></span><span>
</span><span id="line-220"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679696791"><span class="annot"><a href="#local-6989586621679696791"><span class="hs-identifier hs-type">style</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerStyle"><span class="hs-identifier hs-type">TransformerStyle</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-221"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679696790"><span class="annot"><a href="#local-6989586621679696790"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#RequiresGradient"><span class="hs-identifier hs-type">RequiresGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-222"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679696789"><span class="annot"><a href="#local-6989586621679696789"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier hs-type">Device</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#DeviceType"><span class="hs-identifier hs-type">DeviceType</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-223"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679696788"><span class="annot"><a href="#local-6989586621679696788"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier hs-type">DType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-224"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679696787"><span class="annot"><a href="#local-6989586621679696787"><span class="hs-identifier hs-type">vocabDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-225"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span>
</span><span id="line-226"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-227"></span><span>  </span><span id="LMHeadBiasF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadBiasF"><span class="hs-identifier hs-var">LMHeadBiasF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#T5"><span class="hs-identifier hs-type">T5</span></a></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-228"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#GBias"><span class="hs-identifier hs-type">GBias</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-229"></span><span>  </span><span id="LMHeadBiasF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadBiasF"><span class="hs-identifier hs-var">LMHeadBiasF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ByT5"><span class="hs-identifier hs-type">ByT5</span></a></span><span> </span><span id="local-6989586621679696786"><span class="annot"><a href="#local-6989586621679696786"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679696785"><span class="annot"><a href="#local-6989586621679696785"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679696784"><span class="annot"><a href="#local-6989586621679696784"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679696783"><span class="annot"><a href="#local-6989586621679696783"><span class="hs-identifier hs-type hs-type">vocabDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-230"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadBiasF"><span class="hs-identifier hs-type">LMHeadBiasF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#T5"><span class="hs-identifier hs-type">T5</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696786"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696785"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696784"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696783"><span class="hs-identifier hs-type">vocabDim</span></a></span><span>
</span><span id="line-231"></span><span>  </span><span id="LMHeadBiasF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadBiasF"><span class="hs-identifier hs-var">LMHeadBiasF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span> </span><span id="local-6989586621679696782"><span class="annot"><a href="#local-6989586621679696782"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679696781"><span class="annot"><a href="#local-6989586621679696781"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679696780"><span class="annot"><a href="#local-6989586621679696780"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679696779"><span class="annot"><a href="#local-6989586621679696779"><span class="hs-identifier hs-type hs-type">vocabDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-232"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#GBias"><span class="hs-identifier hs-type">GBias</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-type">NamedModel</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696782"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Dense"><span class="hs-identifier hs-type">Dense</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679696781"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696780"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679696779"><span class="hs-identifier hs-type">vocabDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-233"></span><span>  </span><span id="LMHeadBiasF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadBiasF"><span class="hs-identifier hs-var">LMHeadBiasF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MBART"><span class="hs-identifier hs-type">MBART</span></a></span><span> </span><span id="local-6989586621679696778"><span class="annot"><a href="#local-6989586621679696778"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679696777"><span class="annot"><a href="#local-6989586621679696777"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679696776"><span class="annot"><a href="#local-6989586621679696776"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679696775"><span class="annot"><a href="#local-6989586621679696775"><span class="hs-identifier hs-type hs-type">vocabDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-234"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadBiasF"><span class="hs-identifier hs-type">LMHeadBiasF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696778"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696777"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696776"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696775"><span class="hs-identifier hs-type">vocabDim</span></a></span><span>
</span><span id="line-235"></span><span>  </span><span id="LMHeadBiasF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadBiasF"><span class="hs-identifier hs-var">LMHeadBiasF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#Pegasus"><span class="hs-identifier hs-type">Pegasus</span></a></span><span> </span><span id="local-6989586621679696774"><span class="annot"><a href="#local-6989586621679696774"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679696773"><span class="annot"><a href="#local-6989586621679696773"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679696772"><span class="annot"><a href="#local-6989586621679696772"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679696771"><span class="annot"><a href="#local-6989586621679696771"><span class="hs-identifier hs-type hs-type">vocabDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-236"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadBiasF"><span class="hs-identifier hs-type">LMHeadBiasF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696774"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696773"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696772"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696771"><span class="hs-identifier hs-type">vocabDim</span></a></span><span>
</span><span id="line-237"></span><span>  </span><span id="LMHeadBiasF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadBiasF"><span class="hs-identifier hs-var">LMHeadBiasF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BERT"><span class="hs-identifier hs-type">BERT</span></a></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-238"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#GBias"><span class="hs-identifier hs-type">GBias</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-239"></span><span>  </span><span id="LMHeadBiasF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadBiasF"><span class="hs-identifier hs-var">LMHeadBiasF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#RoBERTa"><span class="hs-identifier hs-type">RoBERTa</span></a></span><span> </span><span id="local-6989586621679696770"><span class="annot"><a href="#local-6989586621679696770"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679696769"><span class="annot"><a href="#local-6989586621679696769"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679696768"><span class="annot"><a href="#local-6989586621679696768"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679696767"><span class="annot"><a href="#local-6989586621679696767"><span class="hs-identifier hs-type hs-type">vocabDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-240"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadBiasF"><span class="hs-identifier hs-type">LMHeadBiasF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BERT"><span class="hs-identifier hs-type">BERT</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696770"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696769"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696768"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696767"><span class="hs-identifier hs-type">vocabDim</span></a></span><span>
</span><span id="line-241"></span><span>
</span><span id="line-242"></span><span class="hs-comment">-- | Specifies the parameters of the language model head.</span><span>
</span><span id="line-243"></span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#lmHeadSpec"><span class="hs-identifier hs-type">lmHeadSpec</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-244"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679696765"><span class="annot"><a href="#local-6989586621679696765"><span class="hs-identifier hs-type">style</span></a></span></span><span> </span><span id="local-6989586621679696764"><span class="annot"><a href="#local-6989586621679696764"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679696763"><span class="annot"><a href="#local-6989586621679696763"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679696762"><span class="annot"><a href="#local-6989586621679696762"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679696761"><span class="annot"><a href="#local-6989586621679696761"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679696760"><span class="annot"><a href="#local-6989586621679696760"><span class="hs-identifier hs-type">vocabDim</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-245"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#STransformerStyle"><span class="hs-identifier hs-type">STransformerStyle</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696765"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-246"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier hs-type">SGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696764"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-247"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#SDevice"><span class="hs-identifier hs-type">SDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696763"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-248"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier hs-type">SDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696762"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-249"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696761"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-250"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696760"><span class="hs-identifier hs-type">vocabDim</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-251"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-252"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier hs-type">ModelSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#GLMHeadF"><span class="hs-identifier hs-type">GLMHeadF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696765"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696764"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696763"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696762"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696761"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696760"><span class="hs-identifier hs-type">vocabDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-253"></span><span id="lmHeadSpec"><span class="annot"><span class="annottext">lmHeadSpec :: STransformerStyle style
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim inputEmbedDim
-&gt; SDim vocabDim
-&gt; Double
-&gt; ModelSpec
     (GLMHeadF style gradient device dataType inputEmbedDim vocabDim)
</span><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#lmHeadSpec"><span class="hs-identifier hs-var hs-var">lmHeadSpec</span></a></span></span><span> </span><span id="local-6989586621679696759"><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="#local-6989586621679696759"><span class="hs-identifier hs-var">style</span></a></span></span><span> </span><span id="local-6989586621679696758"><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679696758"><span class="hs-identifier hs-var">gradient</span></a></span></span><span> </span><span id="local-6989586621679696757"><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679696757"><span class="hs-identifier hs-var">device</span></a></span></span><span> </span><span id="local-6989586621679696756"><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679696756"><span class="hs-identifier hs-var">dataType</span></a></span></span><span> </span><span id="local-6989586621679696755"><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679696755"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679696754"><span class="annot"><span class="annottext">SDim vocabDim
</span><a href="#local-6989586621679696754"><span class="hs-identifier hs-var">vocabDim</span></a></span></span><span> </span><span id="local-6989586621679696753"><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679696753"><span class="hs-identifier hs-var">eps</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-254"></span><span>  </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679696752"><span class="annot"><span class="annottext">denseSpec :: STransformerStyle style
-&gt; ModelSpec
     (LMHeadDenseF style gradient device dataType inputEmbedDim)
</span><a href="#local-6989586621679696752"><span class="hs-identifier hs-var hs-var">denseSpec</span></a></span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-255"></span><span>      </span><span class="annot"><a href="#local-6989586621679696752"><span class="hs-identifier hs-var">denseSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-256"></span><span>      </span><span class="annot"><a href="#local-6989586621679696752"><span class="hs-identifier hs-var">denseSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-257"></span><span>      </span><span class="annot"><a href="#local-6989586621679696752"><span class="hs-identifier hs-var">denseSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-258"></span><span>      </span><span class="annot"><a href="#local-6989586621679696752"><span class="hs-identifier hs-var">denseSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-259"></span><span>      </span><span class="annot"><a href="#local-6989586621679696752"><span class="hs-identifier hs-var">denseSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; GLinear
     (NamedModel
        (TensorSpec
           gradient
           ('Layout 'Dense)
           device
           dataType
           ('Shape '[inputEmbedDim, inputEmbedDim])))
     (NamedModel
        (TensorSpec
           gradient
           ('Layout 'Dense)
           device
           dataType
           ('Shape '[inputEmbedDim])))
-&gt; NamedModel
     (GLinear
        (NamedModel
           (TensorSpec
              gradient
              ('Layout 'Dense)
              device
              dataType
              ('Shape '[inputEmbedDim, inputEmbedDim])))
        (NamedModel
           (TensorSpec
              gradient
              ('Layout 'Dense)
              device
              dataType
              ('Shape '[inputEmbedDim]))))
forall model. StateDictKey -&gt; model -&gt; NamedModel model
</span><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-var">NamedModel</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;transform.dense.&quot;</span></span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (GLinearF
     'WithBias gradient device dataType inputEmbedDim inputEmbedDim)
GLinear
  (NamedModel
     (TensorSpec
        gradient
        ('Layout 'Dense)
        device
        dataType
        ('Shape '[inputEmbedDim, inputEmbedDim])))
  (NamedModel
     (TensorSpec
        gradient
        ('Layout 'Dense)
        device
        dataType
        ('Shape '[inputEmbedDim])))
</span><a href="#local-6989586621679696744"><span class="hs-identifier hs-var">linearSpec'</span></a></span><span>
</span><span id="line-260"></span><span>      </span><span class="annot"><a href="#local-6989586621679696752"><span class="hs-identifier hs-var">denseSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; GLinear
     (NamedModel
        (TensorSpec
           gradient
           ('Layout 'Dense)
           device
           dataType
           ('Shape '[inputEmbedDim, inputEmbedDim])))
     (NamedModel
        (TensorSpec
           gradient
           ('Layout 'Dense)
           device
           dataType
           ('Shape '[inputEmbedDim])))
-&gt; NamedModel
     (GLinear
        (NamedModel
           (TensorSpec
              gradient
              ('Layout 'Dense)
              device
              dataType
              ('Shape '[inputEmbedDim, inputEmbedDim])))
        (NamedModel
           (TensorSpec
              gradient
              ('Layout 'Dense)
              device
              dataType
              ('Shape '[inputEmbedDim]))))
forall model. StateDictKey -&gt; model -&gt; NamedModel model
</span><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-var">NamedModel</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;dense.&quot;</span></span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (GLinearF
     'WithBias gradient device dataType inputEmbedDim inputEmbedDim)
GLinear
  (NamedModel
     (TensorSpec
        gradient
        ('Layout 'Dense)
        device
        dataType
        ('Shape '[inputEmbedDim, inputEmbedDim])))
  (NamedModel
     (TensorSpec
        gradient
        ('Layout 'Dense)
        device
        dataType
        ('Shape '[inputEmbedDim])))
</span><a href="#local-6989586621679696744"><span class="hs-identifier hs-var">linearSpec'</span></a></span><span>
</span><span id="line-261"></span><span>      </span><span class="annot"><a href="#local-6989586621679696752"><span class="hs-identifier hs-var">denseSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SGPT2"><span class="hs-identifier hs-var">SGPT2</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (LMHeadDenseF style gradient device dataType inputEmbedDim)
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-262"></span><span>      </span><span class="annot"><a href="#local-6989586621679696740"><span class="hs-identifier hs-type">activationSpec</span></a></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#STransformerStyle"><span class="hs-identifier hs-type">STransformerStyle</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696765"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier hs-type">ModelSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadActivationF"><span class="hs-identifier hs-type">LMHeadActivationF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696765"><span class="hs-identifier hs-type">style</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-263"></span><span>      </span><span id="local-6989586621679696740"><span class="annot"><span class="annottext">activationSpec :: STransformerStyle style -&gt; ModelSpec (LMHeadActivationF style)
</span><a href="#local-6989586621679696740"><span class="hs-identifier hs-var hs-var">activationSpec</span></a></span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-264"></span><span>      </span><span class="annot"><a href="#local-6989586621679696740"><span class="hs-identifier hs-var">activationSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-265"></span><span>      </span><span class="annot"><a href="#local-6989586621679696740"><span class="hs-identifier hs-var">activationSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-266"></span><span>      </span><span class="annot"><a href="#local-6989586621679696740"><span class="hs-identifier hs-var">activationSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-267"></span><span>      </span><span class="annot"><a href="#local-6989586621679696740"><span class="hs-identifier hs-var">activationSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-268"></span><span>      </span><span class="annot"><a href="#local-6989586621679696740"><span class="hs-identifier hs-var">activationSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec (LMHeadActivationF style)
Gelu
</span><a href="Torch.GraduallyTyped.NN.Activation.html#Gelu"><span class="hs-identifier hs-var">Gelu</span></a></span><span>
</span><span id="line-269"></span><span>      </span><span class="annot"><a href="#local-6989586621679696740"><span class="hs-identifier hs-var">activationSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec (LMHeadActivationF style)
Gelu
</span><a href="Torch.GraduallyTyped.NN.Activation.html#Gelu"><span class="hs-identifier hs-var">Gelu</span></a></span><span>
</span><span id="line-270"></span><span>      </span><span class="annot"><a href="#local-6989586621679696740"><span class="hs-identifier hs-var">activationSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SGPT2"><span class="hs-identifier hs-var">SGPT2</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec (LMHeadActivationF style)
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-271"></span><span>      </span><span id="local-6989586621679696738"><span class="annot"><span class="annottext">layerNormSpec :: STransformerStyle style
-&gt; ModelSpec
     (LMHeadLayerNormF style gradient device dataType inputEmbedDim)
</span><a href="#local-6989586621679696738"><span class="hs-identifier hs-var hs-var">layerNormSpec</span></a></span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-272"></span><span>      </span><span class="annot"><a href="#local-6989586621679696738"><span class="hs-identifier hs-var">layerNormSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-273"></span><span>      </span><span class="annot"><a href="#local-6989586621679696738"><span class="hs-identifier hs-var">layerNormSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-274"></span><span>      </span><span class="annot"><a href="#local-6989586621679696738"><span class="hs-identifier hs-var">layerNormSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-275"></span><span>      </span><span class="annot"><a href="#local-6989586621679696738"><span class="hs-identifier hs-var">layerNormSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-276"></span><span>      </span><span class="annot"><a href="#local-6989586621679696738"><span class="hs-identifier hs-var">layerNormSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; LayerNormSpec
     'WithBias gradient device dataType ('Shape '[inputEmbedDim])
-&gt; NamedModel
     (LayerNormSpec
        'WithBias gradient device dataType ('Shape '[inputEmbedDim]))
forall model. StateDictKey -&gt; model -&gt; NamedModel model
</span><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-var">NamedModel</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;transform.LayerNorm.&quot;</span></span><span> </span><span class="annot"><span class="annottext">LayerNormSpec
  'WithBias gradient device dataType ('Shape '[inputEmbedDim])
</span><a href="#local-6989586621679696737"><span class="hs-identifier hs-var">layerNormSpec'</span></a></span><span>
</span><span id="line-277"></span><span>      </span><span class="annot"><a href="#local-6989586621679696738"><span class="hs-identifier hs-var">layerNormSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; LayerNormSpec
     'WithBias gradient device dataType ('Shape '[inputEmbedDim])
-&gt; NamedModel
     (LayerNormSpec
        'WithBias gradient device dataType ('Shape '[inputEmbedDim]))
forall model. StateDictKey -&gt; model -&gt; NamedModel model
</span><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-var">NamedModel</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;layer_norm.&quot;</span></span><span> </span><span class="annot"><span class="annottext">LayerNormSpec
  'WithBias gradient device dataType ('Shape '[inputEmbedDim])
</span><a href="#local-6989586621679696737"><span class="hs-identifier hs-var">layerNormSpec'</span></a></span><span>
</span><span id="line-278"></span><span>      </span><span class="annot"><a href="#local-6989586621679696738"><span class="hs-identifier hs-var">layerNormSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SGPT2"><span class="hs-identifier hs-var">SGPT2</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (LMHeadLayerNormF style gradient device dataType inputEmbedDim)
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-279"></span><span>      </span><span id="local-6989586621679696736"><span class="annot"><span class="annottext">decoderSpec :: STransformerStyle style
-&gt; ModelSpec
     (LMHeadDecoderF
        style gradient device dataType inputEmbedDim vocabDim)
</span><a href="#local-6989586621679696736"><span class="hs-identifier hs-var hs-var">decoderSpec</span></a></span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; GLinear
     (NamedModel
        (TensorSpec
           gradient
           ('Layout 'Dense)
           device
           dataType
           ('Shape '[vocabDim, inputEmbedDim])))
     (NamedModel ())
-&gt; NamedModel
     (GLinear
        (NamedModel
           (TensorSpec
              gradient
              ('Layout 'Dense)
              device
              dataType
              ('Shape '[vocabDim, inputEmbedDim])))
        (NamedModel ()))
forall model. StateDictKey -&gt; model -&gt; NamedModel model
</span><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-var">NamedModel</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey
forall a. Monoid a =&gt; a
</span><span class="hs-identifier hs-var">mempty</span></span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (GLinearF
     'WithoutBias gradient device dataType inputEmbedDim vocabDim)
GLinear
  (NamedModel
     (TensorSpec
        gradient
        ('Layout 'Dense)
        device
        dataType
        ('Shape '[vocabDim, inputEmbedDim])))
  (NamedModel ())
</span><a href="#local-6989586621679696735"><span class="hs-identifier hs-var">linearWithoutBiasSpec'</span></a></span><span>
</span><span id="line-280"></span><span>      </span><span class="annot"><a href="#local-6989586621679696736"><span class="hs-identifier hs-var">decoderSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; GLinear
     (NamedModel
        (TensorSpec
           gradient
           ('Layout 'Dense)
           device
           dataType
           ('Shape '[vocabDim, inputEmbedDim])))
     (NamedModel ())
-&gt; NamedModel
     (GLinear
        (NamedModel
           (TensorSpec
              gradient
              ('Layout 'Dense)
              device
              dataType
              ('Shape '[vocabDim, inputEmbedDim])))
        (NamedModel ()))
forall model. StateDictKey -&gt; model -&gt; NamedModel model
</span><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-var">NamedModel</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey
forall a. Monoid a =&gt; a
</span><span class="hs-identifier hs-var">mempty</span></span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (GLinearF
     'WithoutBias gradient device dataType inputEmbedDim vocabDim)
GLinear
  (NamedModel
     (TensorSpec
        gradient
        ('Layout 'Dense)
        device
        dataType
        ('Shape '[vocabDim, inputEmbedDim])))
  (NamedModel ())
</span><a href="#local-6989586621679696735"><span class="hs-identifier hs-var">linearWithoutBiasSpec'</span></a></span><span>
</span><span id="line-281"></span><span>      </span><span class="annot"><a href="#local-6989586621679696736"><span class="hs-identifier hs-var">decoderSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; GLinear
     (NamedModel
        (TensorSpec
           gradient
           ('Layout 'Dense)
           device
           dataType
           ('Shape '[vocabDim, inputEmbedDim])))
     (NamedModel ())
-&gt; NamedModel
     (GLinear
        (NamedModel
           (TensorSpec
              gradient
              ('Layout 'Dense)
              device
              dataType
              ('Shape '[vocabDim, inputEmbedDim])))
        (NamedModel ()))
forall model. StateDictKey -&gt; model -&gt; NamedModel model
</span><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-var">NamedModel</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;lm_head.&quot;</span></span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (GLinearF
     'WithoutBias gradient device dataType inputEmbedDim vocabDim)
GLinear
  (NamedModel
     (TensorSpec
        gradient
        ('Layout 'Dense)
        device
        dataType
        ('Shape '[vocabDim, inputEmbedDim])))
  (NamedModel ())
</span><a href="#local-6989586621679696735"><span class="hs-identifier hs-var">linearWithoutBiasSpec'</span></a></span><span>
</span><span id="line-282"></span><span>      </span><span class="annot"><a href="#local-6989586621679696736"><span class="hs-identifier hs-var">decoderSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; GLinear
     (NamedModel
        (TensorSpec
           gradient
           ('Layout 'Dense)
           device
           dataType
           ('Shape '[vocabDim, inputEmbedDim])))
     (NamedModel ())
-&gt; NamedModel
     (GLinear
        (NamedModel
           (TensorSpec
              gradient
              ('Layout 'Dense)
              device
              dataType
              ('Shape '[vocabDim, inputEmbedDim])))
        (NamedModel ()))
forall model. StateDictKey -&gt; model -&gt; NamedModel model
</span><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-var">NamedModel</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;lm_head.&quot;</span></span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (GLinearF
     'WithoutBias gradient device dataType inputEmbedDim vocabDim)
GLinear
  (NamedModel
     (TensorSpec
        gradient
        ('Layout 'Dense)
        device
        dataType
        ('Shape '[vocabDim, inputEmbedDim])))
  (NamedModel ())
</span><a href="#local-6989586621679696735"><span class="hs-identifier hs-var">linearWithoutBiasSpec'</span></a></span><span>
</span><span id="line-283"></span><span>      </span><span class="annot"><a href="#local-6989586621679696736"><span class="hs-identifier hs-var">decoderSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; GLinear
     (NamedModel
        (TensorSpec
           gradient
           ('Layout 'Dense)
           device
           dataType
           ('Shape '[vocabDim, inputEmbedDim])))
     (NamedModel ())
-&gt; NamedModel
     (GLinear
        (NamedModel
           (TensorSpec
              gradient
              ('Layout 'Dense)
              device
              dataType
              ('Shape '[vocabDim, inputEmbedDim])))
        (NamedModel ()))
forall model. StateDictKey -&gt; model -&gt; NamedModel model
</span><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-var">NamedModel</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;lm_head.&quot;</span></span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (GLinearF
     'WithoutBias gradient device dataType inputEmbedDim vocabDim)
GLinear
  (NamedModel
     (TensorSpec
        gradient
        ('Layout 'Dense)
        device
        dataType
        ('Shape '[vocabDim, inputEmbedDim])))
  (NamedModel ())
</span><a href="#local-6989586621679696735"><span class="hs-identifier hs-var">linearWithoutBiasSpec'</span></a></span><span>
</span><span id="line-284"></span><span>      </span><span class="annot"><a href="#local-6989586621679696736"><span class="hs-identifier hs-var">decoderSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; GLinear
     (NamedModel
        (TensorSpec
           gradient
           ('Layout 'Dense)
           device
           dataType
           ('Shape '[vocabDim, inputEmbedDim])))
     (NamedModel
        (TensorSpec
           gradient ('Layout 'Dense) device dataType ('Shape '[vocabDim])))
-&gt; NamedModel
     (GLinear
        (NamedModel
           (TensorSpec
              gradient
              ('Layout 'Dense)
              device
              dataType
              ('Shape '[vocabDim, inputEmbedDim])))
        (NamedModel
           (TensorSpec
              gradient ('Layout 'Dense) device dataType ('Shape '[vocabDim]))))
forall model. StateDictKey -&gt; model -&gt; NamedModel model
</span><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-var">NamedModel</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;decoder.&quot;</span></span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (GLinearF
     'WithBias gradient device dataType inputEmbedDim vocabDim)
GLinear
  (NamedModel
     (TensorSpec
        gradient
        ('Layout 'Dense)
        device
        dataType
        ('Shape '[vocabDim, inputEmbedDim])))
  (NamedModel
     (TensorSpec
        gradient ('Layout 'Dense) device dataType ('Shape '[vocabDim])))
</span><a href="#local-6989586621679696734"><span class="hs-identifier hs-var">linearWithBiasSpec'</span></a></span><span>
</span><span id="line-285"></span><span>      </span><span class="annot"><a href="#local-6989586621679696736"><span class="hs-identifier hs-var">decoderSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; GLinear
     (NamedModel
        (TensorSpec
           gradient
           ('Layout 'Dense)
           device
           dataType
           ('Shape '[vocabDim, inputEmbedDim])))
     (NamedModel
        (TensorSpec
           gradient ('Layout 'Dense) device dataType ('Shape '[vocabDim])))
-&gt; NamedModel
     (GLinear
        (NamedModel
           (TensorSpec
              gradient
              ('Layout 'Dense)
              device
              dataType
              ('Shape '[vocabDim, inputEmbedDim])))
        (NamedModel
           (TensorSpec
              gradient ('Layout 'Dense) device dataType ('Shape '[vocabDim]))))
forall model. StateDictKey -&gt; model -&gt; NamedModel model
</span><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-var">NamedModel</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;decoder.&quot;</span></span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (GLinearF
     'WithBias gradient device dataType inputEmbedDim vocabDim)
GLinear
  (NamedModel
     (TensorSpec
        gradient
        ('Layout 'Dense)
        device
        dataType
        ('Shape '[vocabDim, inputEmbedDim])))
  (NamedModel
     (TensorSpec
        gradient ('Layout 'Dense) device dataType ('Shape '[vocabDim])))
</span><a href="#local-6989586621679696734"><span class="hs-identifier hs-var">linearWithBiasSpec'</span></a></span><span>
</span><span id="line-286"></span><span>      </span><span class="annot"><a href="#local-6989586621679696736"><span class="hs-identifier hs-var">decoderSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SGPT2"><span class="hs-identifier hs-var">SGPT2</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (LMHeadDecoderF
     style gradient device dataType inputEmbedDim vocabDim)
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-287"></span><span>      </span><span id="local-6989586621679696733"><span class="annot"><span class="annottext">biasSpec :: STransformerStyle style
-&gt; ModelSpec (LMHeadBiasF style gradient device dataType vocabDim)
</span><a href="#local-6989586621679696733"><span class="hs-identifier hs-var hs-var">biasSpec</span></a></span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">() -&gt; GBias ()
forall bias. bias -&gt; GBias bias
</span><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#GBias"><span class="hs-identifier hs-var">GBias</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-288"></span><span>      </span><span class="annot"><a href="#local-6989586621679696733"><span class="hs-identifier hs-var">biasSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">() -&gt; GBias ()
forall bias. bias -&gt; GBias bias
</span><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#GBias"><span class="hs-identifier hs-var">GBias</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-289"></span><span>      </span><span class="annot"><a href="#local-6989586621679696733"><span class="hs-identifier hs-var">biasSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">NamedModel
  (TensorSpec
     gradient
     ('Layout 'Dense)
     device
     dataType
     ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), vocabDim]))
-&gt; GBias
     (NamedModel
        (TensorSpec
           gradient
           ('Layout 'Dense)
           device
           dataType
           ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), vocabDim])))
forall bias. bias -&gt; GBias bias
</span><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#GBias"><span class="hs-identifier hs-var">GBias</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
-&gt; TensorSpec
     gradient
     ('Layout 'Dense)
     device
     dataType
     ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), vocabDim])
-&gt; NamedModel
     (TensorSpec
        gradient
        ('Layout 'Dense)
        device
        dataType
        ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), vocabDim]))
forall model. StateDictKey -&gt; model -&gt; NamedModel model
</span><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-var">NamedModel</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;final_logits_bias&quot;</span></span><span> </span><span class="annot"><span class="annottext">TensorSpec
  gradient
  ('Layout 'Dense)
  device
  dataType
  ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), vocabDim])
</span><a href="#local-6989586621679696732"><span class="hs-identifier hs-var">biasSpec'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-290"></span><span>      </span><span class="annot"><a href="#local-6989586621679696733"><span class="hs-identifier hs-var">biasSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">NamedModel
  (TensorSpec
     gradient
     ('Layout 'Dense)
     device
     dataType
     ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), vocabDim]))
-&gt; GBias
     (NamedModel
        (TensorSpec
           gradient
           ('Layout 'Dense)
           device
           dataType
           ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), vocabDim])))
forall bias. bias -&gt; GBias bias
</span><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#GBias"><span class="hs-identifier hs-var">GBias</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
-&gt; TensorSpec
     gradient
     ('Layout 'Dense)
     device
     dataType
     ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), vocabDim])
-&gt; NamedModel
     (TensorSpec
        gradient
        ('Layout 'Dense)
        device
        dataType
        ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), vocabDim]))
forall model. StateDictKey -&gt; model -&gt; NamedModel model
</span><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-var">NamedModel</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;final_logits_bias&quot;</span></span><span> </span><span class="annot"><span class="annottext">TensorSpec
  gradient
  ('Layout 'Dense)
  device
  dataType
  ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), vocabDim])
</span><a href="#local-6989586621679696732"><span class="hs-identifier hs-var">biasSpec'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-291"></span><span>      </span><span class="annot"><a href="#local-6989586621679696733"><span class="hs-identifier hs-var">biasSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">NamedModel
  (TensorSpec
     gradient
     ('Layout 'Dense)
     device
     dataType
     ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), vocabDim]))
-&gt; GBias
     (NamedModel
        (TensorSpec
           gradient
           ('Layout 'Dense)
           device
           dataType
           ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), vocabDim])))
forall bias. bias -&gt; GBias bias
</span><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#GBias"><span class="hs-identifier hs-var">GBias</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
-&gt; TensorSpec
     gradient
     ('Layout 'Dense)
     device
     dataType
     ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), vocabDim])
-&gt; NamedModel
     (TensorSpec
        gradient
        ('Layout 'Dense)
        device
        dataType
        ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), vocabDim]))
forall model. StateDictKey -&gt; model -&gt; NamedModel model
</span><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-var">NamedModel</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;final_logits_bias&quot;</span></span><span> </span><span class="annot"><span class="annottext">TensorSpec
  gradient
  ('Layout 'Dense)
  device
  dataType
  ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), vocabDim])
</span><a href="#local-6989586621679696732"><span class="hs-identifier hs-var">biasSpec'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-292"></span><span>      </span><span class="annot"><a href="#local-6989586621679696733"><span class="hs-identifier hs-var">biasSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">() -&gt; GBias ()
forall bias. bias -&gt; GBias bias
</span><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#GBias"><span class="hs-identifier hs-var">GBias</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-293"></span><span>      </span><span class="annot"><a href="#local-6989586621679696733"><span class="hs-identifier hs-var">biasSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">() -&gt; GBias ()
forall bias. bias -&gt; GBias bias
</span><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#GBias"><span class="hs-identifier hs-var">GBias</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-294"></span><span>      </span><span class="annot"><a href="#local-6989586621679696733"><span class="hs-identifier hs-var">biasSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SGPT2"><span class="hs-identifier hs-var">SGPT2</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec (LMHeadBiasF style gradient device dataType vocabDim)
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-295"></span><span>      </span><span class="annot"><a href="#local-6989586621679696731"><span class="hs-identifier hs-type">scalingSpec</span></a></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#STransformerStyle"><span class="hs-identifier hs-type">STransformerStyle</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696765"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadHasScaling"><span class="hs-identifier hs-type">LMHeadHasScaling</span></a></span><span>
</span><span id="line-296"></span><span>      </span><span id="local-6989586621679696731"><span class="annot"><span class="annottext">scalingSpec :: STransformerStyle style -&gt; LMHeadHasScaling
</span><a href="#local-6989586621679696731"><span class="hs-identifier hs-var hs-var">scalingSpec</span></a></span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">LMHeadHasScaling
</span><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadWithScaling"><span class="hs-identifier hs-var">LMHeadWithScaling</span></a></span><span>
</span><span id="line-297"></span><span>      </span><span class="annot"><a href="#local-6989586621679696731"><span class="hs-identifier hs-var">scalingSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">LMHeadHasScaling
</span><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadWithScaling"><span class="hs-identifier hs-var">LMHeadWithScaling</span></a></span><span>
</span><span id="line-298"></span><span>      </span><span class="annot"><a href="#local-6989586621679696731"><span class="hs-identifier hs-var">scalingSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">LMHeadHasScaling
</span><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadWithoutScaling"><span class="hs-identifier hs-var">LMHeadWithoutScaling</span></a></span><span>
</span><span id="line-299"></span><span>      </span><span class="annot"><a href="#local-6989586621679696731"><span class="hs-identifier hs-var">scalingSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">LMHeadHasScaling
</span><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadWithoutScaling"><span class="hs-identifier hs-var">LMHeadWithoutScaling</span></a></span><span>
</span><span id="line-300"></span><span>      </span><span class="annot"><a href="#local-6989586621679696731"><span class="hs-identifier hs-var">scalingSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">LMHeadHasScaling
</span><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadWithoutScaling"><span class="hs-identifier hs-var">LMHeadWithoutScaling</span></a></span><span>
</span><span id="line-301"></span><span>      </span><span class="annot"><a href="#local-6989586621679696731"><span class="hs-identifier hs-var">scalingSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">LMHeadHasScaling
</span><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadWithoutScaling"><span class="hs-identifier hs-var">LMHeadWithoutScaling</span></a></span><span>
</span><span id="line-302"></span><span>      </span><span class="annot"><a href="#local-6989586621679696731"><span class="hs-identifier hs-var">scalingSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">LMHeadHasScaling
</span><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadWithoutScaling"><span class="hs-identifier hs-var">LMHeadWithoutScaling</span></a></span><span>
</span><span id="line-303"></span><span>      </span><span class="annot"><a href="#local-6989586621679696731"><span class="hs-identifier hs-var">scalingSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SGPT2"><span class="hs-identifier hs-var">SGPT2</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">LMHeadHasScaling
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-304"></span><span>   </span><span class="hs-keyword">in</span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
-&gt; ModelSpec
     (LMHeadDenseF style gradient device dataType inputEmbedDim)
-&gt; ModelSpec (LMHeadActivationF style)
-&gt; ModelSpec
     (LMHeadLayerNormF style gradient device dataType inputEmbedDim)
-&gt; ModelSpec
     (LMHeadDecoderF
        style gradient device dataType inputEmbedDim vocabDim)
-&gt; ModelSpec (LMHeadBiasF style gradient device dataType vocabDim)
-&gt; LMHeadHasScaling
-&gt; GLMHead
     inputEmbedDim
     (ModelSpec
        (LMHeadDenseF style gradient device dataType inputEmbedDim))
     (ModelSpec (LMHeadActivationF style))
     (ModelSpec
        (LMHeadLayerNormF style gradient device dataType inputEmbedDim))
     (ModelSpec
        (LMHeadDecoderF
           style gradient device dataType inputEmbedDim vocabDim))
     (ModelSpec (LMHeadBiasF style gradient device dataType vocabDim))
forall (inputEmbedDim :: Dim (Name Symbol) (Size Nat)) dense
       activation layerNorm decoder bias.
SDim inputEmbedDim
-&gt; dense
-&gt; activation
-&gt; layerNorm
-&gt; decoder
-&gt; bias
-&gt; LMHeadHasScaling
-&gt; GLMHead inputEmbedDim dense activation layerNorm decoder bias
</span><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#GLMHead"><span class="hs-identifier hs-var">GLMHead</span></a></span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679696755"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; ModelSpec
     (LMHeadDenseF style gradient device dataType inputEmbedDim)
</span><a href="#local-6989586621679696752"><span class="hs-identifier hs-var">denseSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="#local-6989586621679696759"><span class="hs-identifier hs-var">style</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">STransformerStyle style -&gt; ModelSpec (LMHeadActivationF style)
</span><a href="#local-6989586621679696740"><span class="hs-identifier hs-var">activationSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="#local-6989586621679696759"><span class="hs-identifier hs-var">style</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; ModelSpec
     (LMHeadLayerNormF style gradient device dataType inputEmbedDim)
</span><a href="#local-6989586621679696738"><span class="hs-identifier hs-var">layerNormSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="#local-6989586621679696759"><span class="hs-identifier hs-var">style</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; ModelSpec
     (LMHeadDecoderF
        style gradient device dataType inputEmbedDim vocabDim)
</span><a href="#local-6989586621679696736"><span class="hs-identifier hs-var">decoderSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="#local-6989586621679696759"><span class="hs-identifier hs-var">style</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; ModelSpec (LMHeadBiasF style gradient device dataType vocabDim)
</span><a href="#local-6989586621679696733"><span class="hs-identifier hs-var">biasSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="#local-6989586621679696759"><span class="hs-identifier hs-var">style</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">STransformerStyle style -&gt; LMHeadHasScaling
</span><a href="#local-6989586621679696731"><span class="hs-identifier hs-var">scalingSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="#local-6989586621679696759"><span class="hs-identifier hs-var">style</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-305"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-306"></span><span>    </span><span id="local-6989586621679696744"><span class="annot"><span class="annottext">linearSpec' :: ModelSpec
  (GLinearF
     'WithBias gradient device dataType inputEmbedDim inputEmbedDim)
</span><a href="#local-6989586621679696744"><span class="hs-identifier hs-var hs-var">linearSpec'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SHasBias 'WithBias
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim inputEmbedDim
-&gt; SDim inputEmbedDim
-&gt; ModelSpec
     (GLinearF
        'WithBias gradient device dataType inputEmbedDim inputEmbedDim)
forall (hasBias :: HasBias) (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (inputDim :: Dim (Name Symbol) (Size Nat))
       (outputDim :: Dim (Name Symbol) (Size Nat)).
SHasBias hasBias
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim inputDim
-&gt; SDim outputDim
-&gt; ModelSpec
     (GLinearF hasBias gradient device dataType inputDim outputDim)
</span><a href="Torch.GraduallyTyped.NN.Linear.html#linearSpec"><span class="hs-identifier hs-var">linearSpec</span></a></span><span> </span><span class="annot"><span class="annottext">SHasBias 'WithBias
</span><a href="Torch.GraduallyTyped.NN.Type.html#SWithBias"><span class="hs-identifier hs-var">SWithBias</span></a></span><span> </span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679696758"><span class="hs-identifier hs-var">gradient</span></a></span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679696757"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679696756"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679696755"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679696755"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span>
</span><span id="line-307"></span><span>    </span><span id="local-6989586621679696732"><span class="annot"><span class="annottext">biasSpec' :: TensorSpec
  gradient
  ('Layout 'Dense)
  device
  dataType
  ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), vocabDim])
</span><a href="#local-6989586621679696732"><span class="hs-identifier hs-var hs-var">biasSpec'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SGradient gradient
-&gt; SLayout ('Layout 'Dense)
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SShape ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), vocabDim])
-&gt; TensorSpec
     gradient
     ('Layout 'Dense)
     device
     dataType
     ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), vocabDim])
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SShape shape
-&gt; TensorSpec gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorSpec"><span class="hs-identifier hs-var">TensorSpec</span></a></span><span> </span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679696758"><span class="hs-identifier hs-var">gradient</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SLayoutType 'Dense -&gt; SLayout ('Layout 'Dense)
forall (layoutType :: LayoutType).
SLayoutType layoutType -&gt; SLayout ('Layout layoutType)
</span><a href="Torch.GraduallyTyped.Layout.html#SLayout"><span class="hs-identifier hs-var">SLayout</span></a></span><span> </span><span class="annot"><span class="annottext">SLayoutType 'Dense
</span><a href="Torch.GraduallyTyped.Layout.html#SDense"><span class="hs-identifier hs-var">SDense</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679696757"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679696756"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SList '[ 'Dim ('Name &quot;*&quot;) ('Size 1), vocabDim]
-&gt; SShape ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), vocabDim])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList '[ 'Dim ('Name &quot;*&quot;) ('Size 1), vocabDim]
 -&gt; SShape ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), vocabDim]))
-&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 1), vocabDim]
-&gt; SShape ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), vocabDim])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize ('Size 1) -&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 1))
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownNat 1 =&gt; SSize ('Size 1)
forall (size :: Nat). KnownNat size =&gt; SSize ('Size size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier hs-var">SSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">1</span></span><span> </span><span class="annot"><span class="annottext">Sing ('Dim ('Name &quot;*&quot;) ('Size 1))
-&gt; SList '[vocabDim]
-&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 1), vocabDim]
forall a1 (a2 :: a1) (as :: [a1]).
Sing a2 -&gt; SList as -&gt; SList (a2 : as)
</span><a href="Torch.GraduallyTyped.Prelude.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">Sing vocabDim
SDim vocabDim
</span><a href="#local-6989586621679696754"><span class="hs-identifier hs-var">vocabDim</span></a></span><span> </span><span class="annot"><span class="annottext">Sing vocabDim -&gt; SList '[] -&gt; SList '[vocabDim]
forall a1 (a2 :: a1) (as :: [a1]).
Sing a2 -&gt; SList as -&gt; SList (a2 : as)
</span><a href="Torch.GraduallyTyped.Prelude.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/44d7539k7gqlplsaxjj66fck1zc772zc-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-308"></span><span>    </span><span id="local-6989586621679696737"><span class="annot"><span class="annottext">layerNormSpec' :: LayerNormSpec
  'WithBias gradient device dataType ('Shape '[inputEmbedDim])
</span><a href="#local-6989586621679696737"><span class="hs-identifier hs-var hs-var">layerNormSpec'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SHasBias 'WithBias
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SShape ('Shape '[inputEmbedDim])
-&gt; Double
-&gt; LayerNormSpec
     'WithBias gradient device dataType ('Shape '[inputEmbedDim])
forall (hasBias :: HasBias) (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (normalizedShape :: Shape [Dim (Name Symbol) (Size Nat)]).
SHasBias hasBias
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SShape normalizedShape
-&gt; Double
-&gt; LayerNormSpec hasBias gradient device dataType normalizedShape
</span><a href="Torch.GraduallyTyped.NN.Normalization.html#LayerNormSpec"><span class="hs-identifier hs-var">LayerNormSpec</span></a></span><span> </span><span class="annot"><span class="annottext">SHasBias 'WithBias
</span><a href="Torch.GraduallyTyped.NN.Type.html#SWithBias"><span class="hs-identifier hs-var">SWithBias</span></a></span><span> </span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679696758"><span class="hs-identifier hs-var">gradient</span></a></span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679696757"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679696756"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SList '[inputEmbedDim] -&gt; SShape ('Shape '[inputEmbedDim])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList '[inputEmbedDim] -&gt; SShape ('Shape '[inputEmbedDim]))
-&gt; SList '[inputEmbedDim] -&gt; SShape ('Shape '[inputEmbedDim])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">Sing inputEmbedDim
SDim inputEmbedDim
</span><a href="#local-6989586621679696755"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">Sing inputEmbedDim -&gt; SList '[] -&gt; SList '[inputEmbedDim]
forall a1 (a2 :: a1) (as :: [a1]).
Sing a2 -&gt; SList as -&gt; SList (a2 : as)
</span><a href="Torch.GraduallyTyped.Prelude.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/44d7539k7gqlplsaxjj66fck1zc772zc-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679696753"><span class="hs-identifier hs-var">eps</span></a></span><span>
</span><span id="line-309"></span><span>    </span><span id="local-6989586621679696735"><span class="annot"><span class="annottext">linearWithoutBiasSpec' :: ModelSpec
  (GLinearF
     'WithoutBias gradient device dataType inputEmbedDim vocabDim)
</span><a href="#local-6989586621679696735"><span class="hs-identifier hs-var hs-var">linearWithoutBiasSpec'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SHasBias 'WithoutBias
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim inputEmbedDim
-&gt; SDim vocabDim
-&gt; ModelSpec
     (GLinearF
        'WithoutBias gradient device dataType inputEmbedDim vocabDim)
forall (hasBias :: HasBias) (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (inputDim :: Dim (Name Symbol) (Size Nat))
       (outputDim :: Dim (Name Symbol) (Size Nat)).
SHasBias hasBias
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim inputDim
-&gt; SDim outputDim
-&gt; ModelSpec
     (GLinearF hasBias gradient device dataType inputDim outputDim)
</span><a href="Torch.GraduallyTyped.NN.Linear.html#linearSpec"><span class="hs-identifier hs-var">linearSpec</span></a></span><span> </span><span class="annot"><span class="annottext">SHasBias 'WithoutBias
</span><a href="Torch.GraduallyTyped.NN.Type.html#SWithoutBias"><span class="hs-identifier hs-var">SWithoutBias</span></a></span><span> </span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679696758"><span class="hs-identifier hs-var">gradient</span></a></span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679696757"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679696756"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679696755"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim vocabDim
</span><a href="#local-6989586621679696754"><span class="hs-identifier hs-var">vocabDim</span></a></span><span>
</span><span id="line-310"></span><span>    </span><span id="local-6989586621679696734"><span class="annot"><span class="annottext">linearWithBiasSpec' :: ModelSpec
  (GLinearF
     'WithBias gradient device dataType inputEmbedDim vocabDim)
</span><a href="#local-6989586621679696734"><span class="hs-identifier hs-var hs-var">linearWithBiasSpec'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SHasBias 'WithBias
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim inputEmbedDim
-&gt; SDim vocabDim
-&gt; ModelSpec
     (GLinearF
        'WithBias gradient device dataType inputEmbedDim vocabDim)
forall (hasBias :: HasBias) (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (inputDim :: Dim (Name Symbol) (Size Nat))
       (outputDim :: Dim (Name Symbol) (Size Nat)).
SHasBias hasBias
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim inputDim
-&gt; SDim outputDim
-&gt; ModelSpec
     (GLinearF hasBias gradient device dataType inputDim outputDim)
</span><a href="Torch.GraduallyTyped.NN.Linear.html#linearSpec"><span class="hs-identifier hs-var">linearSpec</span></a></span><span> </span><span class="annot"><span class="annottext">SHasBias 'WithBias
</span><a href="Torch.GraduallyTyped.NN.Type.html#SWithBias"><span class="hs-identifier hs-var">SWithBias</span></a></span><span> </span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679696758"><span class="hs-identifier hs-var">gradient</span></a></span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679696757"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679696756"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679696755"><span class="hs-identifier hs-var">inputEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim vocabDim
</span><a href="#local-6989586621679696754"><span class="hs-identifier hs-var">vocabDim</span></a></span><span>
</span><span id="line-311"></span><span>
</span><span id="line-312"></span><span id="local-6989586621679696705"><span id="local-6989586621679696706"><span id="local-6989586621679696707"><span id="local-6989586621679696708"><span id="local-6989586621679696709"><span id="local-6989586621679696710"><span id="local-6989586621679696711"><span id="local-6989586621679696712"><span id="local-6989586621679696713"><span id="local-6989586621679696714"><span id="local-6989586621679696715"><span id="local-6989586621679696716"><span id="local-6989586621679696717"><span id="local-6989586621679696718"><span id="local-6989586621679696719"><span id="local-6989586621679696720"><span id="local-6989586621679696721"><span class="hs-keyword">instance</span><span>
</span><span id="line-313"></span><span>  </span><span id="local-6989586621679696703"><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696721"><span class="hs-identifier hs-type">dense</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696720"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696719"><span class="hs-identifier hs-type">dense'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696718"><span class="hs-identifier hs-type">generatorDevice0</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-314"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696717"><span class="hs-identifier hs-type">activation</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696718"><span class="hs-identifier hs-type">generatorDevice0</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696716"><span class="hs-identifier hs-type">activation'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696715"><span class="hs-identifier hs-type">generatorDevice1</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-315"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696714"><span class="hs-identifier hs-type">layerNorm</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696715"><span class="hs-identifier hs-type">generatorDevice1</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696713"><span class="hs-identifier hs-type">layerNorm'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696712"><span class="hs-identifier hs-type">generatorDevice2</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-316"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696711"><span class="hs-identifier hs-type">decoder</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696712"><span class="hs-identifier hs-type">generatorDevice2</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696710"><span class="hs-identifier hs-type">decoder'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696709"><span class="hs-identifier hs-type">generatorDevice3</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-317"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696708"><span class="hs-identifier hs-type">bias</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696709"><span class="hs-identifier hs-type">generatorDevice3</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696707"><span class="hs-identifier hs-type">bias'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696706"><span class="hs-identifier hs-type">generatorOutputDevice</span></a></span><span>
</span><span id="line-318"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-319"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span>
</span><span id="line-320"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#GLMHead"><span class="hs-identifier hs-type">GLMHead</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696705"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696721"><span class="hs-identifier hs-type">dense</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696717"><span class="hs-identifier hs-type">activation</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696714"><span class="hs-identifier hs-type">layerNorm</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696711"><span class="hs-identifier hs-type">decoder</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696708"><span class="hs-identifier hs-type">bias</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-321"></span><span>    </span><span class="annot"><a href="#local-6989586621679696720"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-322"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#GLMHead"><span class="hs-identifier hs-type">GLMHead</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696705"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696719"><span class="hs-identifier hs-type">dense'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696716"><span class="hs-identifier hs-type">activation'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696713"><span class="hs-identifier hs-type">layerNorm'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696710"><span class="hs-identifier hs-type">decoder'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696707"><span class="hs-identifier hs-type">bias'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-323"></span><span>    </span><span class="annot"><a href="#local-6989586621679696706"><span class="hs-identifier hs-type">generatorOutputDevice</span></a></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span>
</span><span id="line-324"></span><span>
</span><span id="line-325"></span><span id="local-6989586621679696702"><span class="hs-keyword">instance</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#GBias"><span class="hs-identifier hs-type">GBias</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679696702"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#GBias"><span class="hs-identifier hs-type">GBias</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679696702"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-326"></span><span>  </span><span id="local-6989586621679696700"><span class="annot"><span class="annottext">initialize :: ModelSpec (GBias ())
-&gt; Generator generatorDevice
-&gt; m (GBias (), Generator generatorDevice)
</span><a href="#local-6989586621679696700"><span class="hs-identifier hs-var hs-var hs-var hs-var">initialize</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#GBias"><span class="hs-identifier hs-type">GBias</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span id="local-6989586621679696699"><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679696699"><span class="hs-identifier hs-var">g</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(GBias (), Generator generatorDevice)
-&gt; m (GBias (), Generator generatorDevice)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">() -&gt; GBias ()
forall bias. bias -&gt; GBias bias
</span><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#GBias"><span class="hs-identifier hs-var">GBias</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679696699"><span class="hs-identifier hs-var">g</span></a></span><span class="hs-special">)</span></span><span>
</span><span id="line-327"></span><span>
</span><span id="line-328"></span><span id="local-6989586621679696693"><span id="local-6989586621679696694"><span id="local-6989586621679696695"><span id="local-6989586621679696696"><span id="local-6989586621679696697"><span id="local-6989586621679696698"><span class="hs-keyword">instance</span><span>
</span><span id="line-329"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span>
</span><span id="line-330"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#GBias"><span class="hs-identifier hs-type">GBias</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696698"><span class="hs-identifier hs-type">biasGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696697"><span class="hs-identifier hs-type">biasLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696696"><span class="hs-identifier hs-type">biasDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696695"><span class="hs-identifier hs-type">biasDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696694"><span class="hs-identifier hs-type">biasShape</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-331"></span><span>    </span><span class="annot"><a href="#local-6989586621679696693"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-332"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#GBias"><span class="hs-identifier hs-type">GBias</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696698"><span class="hs-identifier hs-type">biasGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696697"><span class="hs-identifier hs-type">biasLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696696"><span class="hs-identifier hs-type">biasDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696695"><span class="hs-identifier hs-type">biasDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696694"><span class="hs-identifier hs-type">biasShape</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-333"></span><span>    </span><span class="annot"><a href="#local-6989586621679696693"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-334"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-335"></span><span>  </span><span id="local-6989586621679696691"><span class="annot"><span class="annottext">initialize :: ModelSpec
  (GBias
     (Tensor biasGradient biasLayout biasDevice biasDataType biasShape))
-&gt; Generator generatorDevice
-&gt; m (GBias
        (Tensor biasGradient biasLayout biasDevice biasDataType biasShape),
      Generator generatorDevice)
</span><a href="#local-6989586621679696691"><span class="hs-identifier hs-var hs-var hs-var hs-var">initialize</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#GBias"><span class="hs-identifier hs-type">GBias</span></a></span><span> </span><span id="local-6989586621679696690"><span class="annot"><a href="#local-6989586621679696690"><span class="hs-identifier hs-var">biasSpec</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-336"></span><span>    </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorDevice)
  (GBias
     (Tensor biasGradient biasLayout biasDevice biasDataType biasShape))
-&gt; Generator generatorDevice
-&gt; m (GBias
        (Tensor biasGradient biasLayout biasDevice biasDataType biasShape),
      Generator generatorDevice)
forall (m :: * -&gt; *) i j a. IxStateT m i j a -&gt; i -&gt; m (a, j)
</span><a href="../file:///nix/store/izdh8cwvq0acwzr2lk5vjhjfywaq1s9y-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var hs-var">runIxStateT</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Tensor biasGradient biasLayout biasDevice biasDataType biasShape
-&gt; GBias
     (Tensor biasGradient biasLayout biasDevice biasDataType biasShape)
forall bias. bias -&gt; GBias bias
</span><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#GBias"><span class="hs-identifier hs-var">GBias</span></a></span><span> </span><span class="annot"><span class="annottext">(Tensor biasGradient biasLayout biasDevice biasDataType biasShape
 -&gt; GBias
      (Tensor biasGradient biasLayout biasDevice biasDataType biasShape))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     (Tensor biasGradient biasLayout biasDevice biasDataType biasShape)
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     (GBias
        (Tensor biasGradient biasLayout biasDevice biasDataType biasShape))
forall k1 k2 (f :: k1 -&gt; k2 -&gt; * -&gt; *) a b (j :: k1) (k3 :: k2).
IxFunctor f =&gt;
(a -&gt; b) -&gt; f j k3 a -&gt; f j k3 b
</span><a href="../file:///nix/store/wpb5hggv8az7m3hh6dk4vnmz1z9va197-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&lt;&lt;$&gt;&gt;</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">m (Tensor
     biasGradient biasLayout biasDevice biasDataType biasShape)
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     (Tensor biasGradient biasLayout biasDevice biasDataType biasShape)
forall k (t :: (* -&gt; *) -&gt; k -&gt; k -&gt; * -&gt; *) (m :: * -&gt; *) a
       (i :: k).
(IxMonadTrans t, Monad m) =&gt;
m a -&gt; t m i i a
</span><a href="../file:///nix/store/wpb5hggv8az7m3hh6dk4vnmz1z9va197-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ilift</span></a></span><span> </span><span class="annot"><span class="annottext">(m (Tensor
      biasGradient biasLayout biasDevice biasDataType biasShape)
 -&gt; IxStateT
      m
      (Generator generatorDevice)
      (Generator generatorDevice)
      (Tensor biasGradient biasLayout biasDevice biasDataType biasShape))
-&gt; (TensorSpec
      biasGradient biasLayout biasDevice biasDataType biasShape
    -&gt; m (Tensor
            biasGradient biasLayout biasDevice biasDataType biasShape))
-&gt; TensorSpec
     biasGradient biasLayout biasDevice biasDataType biasShape
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     (Tensor biasGradient biasLayout biasDevice biasDataType biasShape)
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">TensorSpec
  biasGradient biasLayout biasDevice biasDataType biasShape
-&gt; m (Tensor
        biasGradient biasLayout biasDevice biasDataType biasShape)
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]) (m :: * -&gt; *).
MonadThrow m =&gt;
TensorSpec gradient layout device dataType shape
-&gt; m (Tensor gradient layout device dataType shape)
</span><a href="Torch.GraduallyTyped.Tensor.Creation.html#sZeros"><span class="hs-identifier hs-var">sZeros</span></a></span><span> </span><span class="annot"><span class="annottext">(TensorSpec
   biasGradient biasLayout biasDevice biasDataType biasShape
 -&gt; IxStateT
      m
      (Generator generatorDevice)
      (Generator generatorDevice)
      (Tensor biasGradient biasLayout biasDevice biasDataType biasShape))
-&gt; TensorSpec
     biasGradient biasLayout biasDevice biasDataType biasShape
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     (Tensor biasGradient biasLayout biasDevice biasDataType biasShape)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">TensorSpec
  biasGradient biasLayout biasDevice biasDataType biasShape
</span><a href="#local-6989586621679696690"><span class="hs-identifier hs-var">biasSpec</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span></span></span></span></span></span></span><span>
</span><span id="line-337"></span><span>
</span><span id="line-338"></span><span id="local-6989586621679696682"><span id="local-6989586621679696683"><span id="local-6989586621679696684"><span id="local-6989586621679696685"><span id="local-6989586621679696686"><span id="local-6989586621679696687"><span class="hs-keyword">instance</span><span>
</span><span id="line-339"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span>
</span><span id="line-340"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#GBias"><span class="hs-identifier hs-type">GBias</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-type">NamedModel</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696687"><span class="hs-identifier hs-type">biasGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696686"><span class="hs-identifier hs-type">biasLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696685"><span class="hs-identifier hs-type">biasDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696684"><span class="hs-identifier hs-type">biasDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696683"><span class="hs-identifier hs-type">biasShape</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-341"></span><span>    </span><span class="annot"><a href="#local-6989586621679696682"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-342"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#GBias"><span class="hs-identifier hs-type">GBias</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-type">NamedModel</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696687"><span class="hs-identifier hs-type">biasGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696686"><span class="hs-identifier hs-type">biasLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696685"><span class="hs-identifier hs-type">biasDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696684"><span class="hs-identifier hs-type">biasDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696683"><span class="hs-identifier hs-type">biasShape</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-343"></span><span>    </span><span class="annot"><a href="#local-6989586621679696682"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-344"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-345"></span><span>  </span><span id="local-6989586621679696680"><span class="annot"><span class="annottext">initialize :: ModelSpec
  (GBias
     (NamedModel
        (Tensor
           biasGradient biasLayout biasDevice biasDataType biasShape)))
-&gt; Generator generatorDevice
-&gt; m (GBias
        (NamedModel
           (Tensor
              biasGradient biasLayout biasDevice biasDataType biasShape)),
      Generator generatorDevice)
</span><a href="#local-6989586621679696680"><span class="hs-identifier hs-var hs-var hs-var hs-var">initialize</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#GBias"><span class="hs-identifier hs-type">GBias</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-type">NamedModel</span></a></span><span> </span><span id="local-6989586621679696679"><span class="annot"><a href="#local-6989586621679696679"><span class="hs-identifier hs-var">biasName</span></a></span></span><span> </span><span id="local-6989586621679696678"><span class="annot"><a href="#local-6989586621679696678"><span class="hs-identifier hs-var">biasSpec</span></a></span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-346"></span><span>    </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorDevice)
  (GBias
     (NamedModel
        (Tensor
           biasGradient biasLayout biasDevice biasDataType biasShape)))
-&gt; Generator generatorDevice
-&gt; m (GBias
        (NamedModel
           (Tensor
              biasGradient biasLayout biasDevice biasDataType biasShape)),
      Generator generatorDevice)
forall (m :: * -&gt; *) i j a. IxStateT m i j a -&gt; i -&gt; m (a, j)
</span><a href="../file:///nix/store/izdh8cwvq0acwzr2lk5vjhjfywaq1s9y-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var hs-var">runIxStateT</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">NamedModel
  (Tensor biasGradient biasLayout biasDevice biasDataType biasShape)
-&gt; GBias
     (NamedModel
        (Tensor biasGradient biasLayout biasDevice biasDataType biasShape))
forall bias. bias -&gt; GBias bias
</span><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#GBias"><span class="hs-identifier hs-var">GBias</span></a></span><span> </span><span class="annot"><span class="annottext">(NamedModel
   (Tensor biasGradient biasLayout biasDevice biasDataType biasShape)
 -&gt; GBias
      (NamedModel
         (Tensor
            biasGradient biasLayout biasDevice biasDataType biasShape)))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     (NamedModel
        (Tensor biasGradient biasLayout biasDevice biasDataType biasShape))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     (GBias
        (NamedModel
           (Tensor
              biasGradient biasLayout biasDevice biasDataType biasShape)))
forall k1 k2 (f :: k1 -&gt; k2 -&gt; * -&gt; *) a b (j :: k1) (k3 :: k2).
IxFunctor f =&gt;
(a -&gt; b) -&gt; f j k3 a -&gt; f j k3 b
</span><a href="../file:///nix/store/wpb5hggv8az7m3hh6dk4vnmz1z9va197-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&lt;&lt;$&gt;&gt;</span></a></span><span> </span><span class="annot"><span class="annottext">m (NamedModel
     (Tensor biasGradient biasLayout biasDevice biasDataType biasShape))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     (NamedModel
        (Tensor biasGradient biasLayout biasDevice biasDataType biasShape))
forall k (t :: (* -&gt; *) -&gt; k -&gt; k -&gt; * -&gt; *) (m :: * -&gt; *) a
       (i :: k).
(IxMonadTrans t, Monad m) =&gt;
m a -&gt; t m i i a
</span><a href="../file:///nix/store/wpb5hggv8az7m3hh6dk4vnmz1z9va197-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ilift</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
-&gt; Tensor biasGradient biasLayout biasDevice biasDataType biasShape
-&gt; NamedModel
     (Tensor biasGradient biasLayout biasDevice biasDataType biasShape)
forall model. StateDictKey -&gt; model -&gt; NamedModel model
</span><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-var">NamedModel</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679696679"><span class="hs-identifier hs-var">biasName</span></a></span><span> </span><span class="annot"><span class="annottext">(Tensor biasGradient biasLayout biasDevice biasDataType biasShape
 -&gt; NamedModel
      (Tensor biasGradient biasLayout biasDevice biasDataType biasShape))
-&gt; m (Tensor
        biasGradient biasLayout biasDevice biasDataType biasShape)
-&gt; m (NamedModel
        (Tensor biasGradient biasLayout biasDevice biasDataType biasShape))
forall (f :: * -&gt; *) a b. Functor f =&gt; (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;$&gt;</span></span><span> </span><span class="annot"><span class="annottext">TensorSpec
  biasGradient biasLayout biasDevice biasDataType biasShape
-&gt; m (Tensor
        biasGradient biasLayout biasDevice biasDataType biasShape)
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]) (m :: * -&gt; *).
MonadThrow m =&gt;
TensorSpec gradient layout device dataType shape
-&gt; m (Tensor gradient layout device dataType shape)
</span><a href="Torch.GraduallyTyped.Tensor.Creation.html#sZeros"><span class="hs-identifier hs-var">sZeros</span></a></span><span> </span><span class="annot"><span class="annottext">TensorSpec
  biasGradient biasLayout biasDevice biasDataType biasShape
</span><a href="#local-6989586621679696678"><span class="hs-identifier hs-var">biasSpec</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span></span></span></span></span></span></span><span>
</span><span id="line-347"></span><span>
</span><span id="line-348"></span><span id="local-6989586621679696671"><span id="local-6989586621679696672"><span id="local-6989586621679696673"><span id="local-6989586621679696674"><span id="local-6989586621679696675"><span id="local-6989586621679696676"><span class="hs-keyword">instance</span><span>
</span><span id="line-349"></span><span>  </span><span id="local-6989586621679696667"><span id="local-6989586621679696669"><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasStateDict"><span class="hs-identifier hs-type">HasStateDict</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696676"><span class="hs-identifier hs-type">dense</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-350"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasStateDict"><span class="hs-identifier hs-type">HasStateDict</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696675"><span class="hs-identifier hs-type">activation</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-351"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasStateDict"><span class="hs-identifier hs-type">HasStateDict</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696674"><span class="hs-identifier hs-type">layerNorm</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-352"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasStateDict"><span class="hs-identifier hs-type">HasStateDict</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696673"><span class="hs-identifier hs-type">decoder</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-353"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasStateDict"><span class="hs-identifier hs-type">HasStateDict</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696672"><span class="hs-identifier hs-type">bias</span></a></span><span>
</span><span id="line-354"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-355"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasStateDict"><span class="hs-identifier hs-type">HasStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#GLMHead"><span class="hs-identifier hs-type">GLMHead</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696671"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696676"><span class="hs-identifier hs-type">dense</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696675"><span class="hs-identifier hs-type">activation</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696674"><span class="hs-identifier hs-type">layerNorm</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696673"><span class="hs-identifier hs-type">decoder</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696672"><span class="hs-identifier hs-type">bias</span></a></span><span class="hs-special">)</span></span></span></span></span></span></span></span></span><span>
</span><span id="line-356"></span><span>
</span><span id="line-357"></span><span id="local-6989586621679696666"><span class="hs-keyword">instance</span><span> </span><span id="local-6989586621679696662"><span id="local-6989586621679696664"><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasStateDict"><span class="hs-identifier hs-type">HasStateDict</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696666"><span class="hs-identifier hs-type">bias</span></a></span><span> </span><span class="hs-glyph">=&gt;</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasStateDict"><span class="hs-identifier hs-type">HasStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#GBias"><span class="hs-identifier hs-type">GBias</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696666"><span class="hs-identifier hs-type">bias</span></a></span><span class="hs-special">)</span></span></span></span><span>
</span><span id="line-358"></span><span>
</span><span id="line-359"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span>
</span><span id="line-360"></span><span>  </span><span id="LMHeadOutputF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadOutputF"><span class="hs-identifier hs-var">LMHeadOutputF</span></a></span></span><span>
</span><span id="line-361"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679696660"><span class="annot"><a href="#local-6989586621679696660"><span class="hs-identifier hs-type">style</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerStyle"><span class="hs-identifier hs-type">TransformerStyle</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-362"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679696659"><span class="annot"><a href="#local-6989586621679696659"><span class="hs-identifier hs-type">decoderOutput</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span class="hs-special">)</span><span>
</span><span id="line-363"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679696658"><span class="annot"><a href="#local-6989586621679696658"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#RequiresGradient"><span class="hs-identifier hs-type">RequiresGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-364"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679696657"><span class="annot"><a href="#local-6989586621679696657"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier hs-type">Device</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#DeviceType"><span class="hs-identifier hs-type">DeviceType</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-365"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679696656"><span class="annot"><a href="#local-6989586621679696656"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier hs-type">DType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-366"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679696655"><span class="annot"><a href="#local-6989586621679696655"><span class="hs-identifier hs-type">vocabDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-367"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span>
</span><span id="line-368"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-369"></span><span>  </span><span id="LMHeadOutputF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadOutputF"><span class="hs-identifier hs-var">LMHeadOutputF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#T5"><span class="hs-identifier hs-type">T5</span></a></span><span> </span><span id="local-6989586621679696654"><span class="annot"><a href="#local-6989586621679696654"><span class="hs-identifier hs-type hs-type">decoderOutput</span></a></span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="#local-6989586621679696654"><span class="hs-identifier hs-type">decoderOutput</span></a></span><span>
</span><span id="line-370"></span><span>  </span><span id="LMHeadOutputF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadOutputF"><span class="hs-identifier hs-var">LMHeadOutputF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ByT5"><span class="hs-identifier hs-type">ByT5</span></a></span><span> </span><span id="local-6989586621679696653"><span class="annot"><a href="#local-6989586621679696653"><span class="hs-identifier hs-type hs-type">decoderOutput</span></a></span></span><span> </span><span id="local-6989586621679696652"><span class="annot"><a href="#local-6989586621679696652"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679696651"><span class="annot"><a href="#local-6989586621679696651"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679696650"><span class="annot"><a href="#local-6989586621679696650"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679696649"><span class="annot"><a href="#local-6989586621679696649"><span class="hs-identifier hs-type hs-type">vocabDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadOutputF"><span class="hs-identifier hs-type">LMHeadOutputF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#T5"><span class="hs-identifier hs-type">T5</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696653"><span class="hs-identifier hs-type">decoderOutput</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696652"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696651"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696650"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696649"><span class="hs-identifier hs-type">vocabDim</span></a></span><span>
</span><span id="line-371"></span><span>  </span><span id="LMHeadOutputF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadOutputF"><span class="hs-identifier hs-var">LMHeadOutputF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span id="local-6989586621679696648"><span class="annot"><a href="#local-6989586621679696648"><span class="hs-identifier hs-type hs-type">gradient'</span></a></span></span><span> </span><span id="local-6989586621679696647"><span class="annot"><a href="#local-6989586621679696647"><span class="hs-identifier hs-type hs-type">layout'</span></a></span></span><span> </span><span id="local-6989586621679696646"><span class="annot"><a href="#local-6989586621679696646"><span class="hs-identifier hs-type hs-type">device'</span></a></span></span><span> </span><span id="local-6989586621679696645"><span class="annot"><a href="#local-6989586621679696645"><span class="hs-identifier hs-type hs-type">dataType'</span></a></span></span><span> </span><span id="local-6989586621679696644"><span class="annot"><a href="#local-6989586621679696644"><span class="hs-identifier hs-type hs-type">shape'</span></a></span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679696643"><span class="annot"><a href="#local-6989586621679696643"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679696642"><span class="annot"><a href="#local-6989586621679696642"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679696641"><span class="annot"><a href="#local-6989586621679696641"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679696640"><span class="annot"><a href="#local-6989586621679696640"><span class="hs-identifier hs-type hs-type">vocabDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-372"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-373"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679696648"><span class="hs-identifier hs-type">gradient'</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696643"><span class="hs-identifier hs-type">gradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-374"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679696647"><span class="hs-identifier hs-type">layout'</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Dense"><span class="hs-identifier hs-type">Dense</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-375"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679696646"><span class="hs-identifier hs-type">device'</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696642"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-376"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679696645"><span class="hs-identifier hs-type">dataType'</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696641"><span class="hs-identifier hs-type">dataType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-377"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#BroadcastShapesF"><span class="hs-identifier hs-type">BroadcastShapesF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696644"><span class="hs-identifier hs-type">shape'</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679696640"><span class="hs-identifier hs-type">vocabDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-378"></span><span>  </span><span id="LMHeadOutputF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadOutputF"><span class="hs-identifier hs-var">LMHeadOutputF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MBART"><span class="hs-identifier hs-type">MBART</span></a></span><span> </span><span id="local-6989586621679696639"><span class="annot"><a href="#local-6989586621679696639"><span class="hs-identifier hs-type hs-type">decoderOutput</span></a></span></span><span> </span><span id="local-6989586621679696638"><span class="annot"><a href="#local-6989586621679696638"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679696637"><span class="annot"><a href="#local-6989586621679696637"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679696636"><span class="annot"><a href="#local-6989586621679696636"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679696635"><span class="annot"><a href="#local-6989586621679696635"><span class="hs-identifier hs-type hs-type">vocabDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadOutputF"><span class="hs-identifier hs-type">LMHeadOutputF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696639"><span class="hs-identifier hs-type">decoderOutput</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696638"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696637"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696636"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696635"><span class="hs-identifier hs-type">vocabDim</span></a></span><span>
</span><span id="line-379"></span><span>  </span><span id="LMHeadOutputF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadOutputF"><span class="hs-identifier hs-var">LMHeadOutputF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#Pegasus"><span class="hs-identifier hs-type">Pegasus</span></a></span><span> </span><span id="local-6989586621679696634"><span class="annot"><a href="#local-6989586621679696634"><span class="hs-identifier hs-type hs-type">decoderOutput</span></a></span></span><span> </span><span id="local-6989586621679696633"><span class="annot"><a href="#local-6989586621679696633"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679696632"><span class="annot"><a href="#local-6989586621679696632"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679696631"><span class="annot"><a href="#local-6989586621679696631"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679696630"><span class="annot"><a href="#local-6989586621679696630"><span class="hs-identifier hs-type hs-type">vocabDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadOutputF"><span class="hs-identifier hs-type">LMHeadOutputF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696634"><span class="hs-identifier hs-type">decoderOutput</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696633"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696632"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696631"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696630"><span class="hs-identifier hs-type">vocabDim</span></a></span><span>
</span><span id="line-380"></span><span>  </span><span id="LMHeadOutputF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadOutputF"><span class="hs-identifier hs-var">LMHeadOutputF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#RoBERTa"><span class="hs-identifier hs-type">RoBERTa</span></a></span><span> </span><span id="local-6989586621679696629"><span class="annot"><a href="#local-6989586621679696629"><span class="hs-identifier hs-type hs-type">decoderOutput</span></a></span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="#local-6989586621679696629"><span class="hs-identifier hs-type">decoderOutput</span></a></span><span>
</span><span id="line-381"></span><span>  </span><span id="LMHeadOutputF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadOutputF"><span class="hs-identifier hs-var">LMHeadOutputF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BERT"><span class="hs-identifier hs-type">BERT</span></a></span><span> </span><span id="local-6989586621679696628"><span class="annot"><a href="#local-6989586621679696628"><span class="hs-identifier hs-type hs-type">decoderOutput</span></a></span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="#local-6989586621679696628"><span class="hs-identifier hs-type">decoderOutput</span></a></span><span>
</span><span id="line-382"></span><span>
</span><span id="line-383"></span><span class="hs-comment">-- | 'HasForward' instance for 'LMHead'.</span><span>
</span><span id="line-384"></span><span class="hs-comment">--</span><span>
</span><span id="line-385"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-386"></span><span class="hs-comment">--     &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;</span><span>
</span><span id="line-387"></span><span class="hs-comment">--     &#9474; input &#9474;</span><span>
</span><span id="line-388"></span><span class="hs-comment">--     &#9492;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-389"></span><span class="hs-comment">--         &#9474;</span><span>
</span><span id="line-390"></span><span class="hs-comment">--         &#9660;</span><span>
</span><span id="line-391"></span><span class="hs-comment">--   (lmHeadDense)</span><span>
</span><span id="line-392"></span><span class="hs-comment">--         &#9660;</span><span>
</span><span id="line-393"></span><span class="hs-comment">-- (lmHeadActivation)</span><span>
</span><span id="line-394"></span><span class="hs-comment">--         &#9660;</span><span>
</span><span id="line-395"></span><span class="hs-comment">-- (lmHeadLayerNorm)</span><span>
</span><span id="line-396"></span><span class="hs-comment">--         &#9660;</span><span>
</span><span id="line-397"></span><span class="hs-comment">--   lmHeadDecoder</span><span>
</span><span id="line-398"></span><span class="hs-comment">--         &#9660;</span><span>
</span><span id="line-399"></span><span class="hs-comment">--     (scaling)</span><span>
</span><span id="line-400"></span><span class="hs-comment">--         &#9660;</span><span>
</span><span id="line-401"></span><span class="hs-comment">--    (lmHeadBias)</span><span>
</span><span id="line-402"></span><span class="hs-comment">--         &#9474;</span><span>
</span><span id="line-403"></span><span class="hs-comment">--         &#9660;</span><span>
</span><span id="line-404"></span><span class="hs-comment">-- &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;</span><span>
</span><span id="line-405"></span><span class="hs-comment">-- &#9474; decoderOutput &#9474;</span><span>
</span><span id="line-406"></span><span class="hs-comment">-- &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-407"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-408"></span><span id="local-6989586621679696602"><span id="local-6989586621679696603"><span id="local-6989586621679696604"><span id="local-6989586621679696605"><span id="local-6989586621679696606"><span id="local-6989586621679696607"><span id="local-6989586621679696608"><span id="local-6989586621679696609"><span id="local-6989586621679696610"><span id="local-6989586621679696611"><span id="local-6989586621679696612"><span id="local-6989586621679696613"><span id="local-6989586621679696614"><span id="local-6989586621679696615"><span id="local-6989586621679696616"><span id="local-6989586621679696617"><span id="local-6989586621679696618"><span id="local-6989586621679696619"><span id="local-6989586621679696620"><span id="local-6989586621679696621"><span id="local-6989586621679696622"><span id="local-6989586621679696623"><span id="local-6989586621679696624"><span id="local-6989586621679696625"><span id="local-6989586621679696626"><span id="local-6989586621679696627"><span class="hs-keyword">instance</span><span>
</span><span id="line-409"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-410"></span><span>      </span><span class="annot"><a href="#local-6989586621679696627"><span class="hs-identifier hs-type">dense</span></a></span><span>
</span><span id="line-411"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696626"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696625"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696624"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696623"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696622"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-412"></span><span>      </span><span class="annot"><a href="#local-6989586621679696621"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-413"></span><span>      </span><span class="annot"><a href="#local-6989586621679696620"><span class="hs-identifier hs-type">tensor0</span></a></span><span>
</span><span id="line-414"></span><span>      </span><span class="annot"><a href="#local-6989586621679696619"><span class="hs-identifier hs-type">generatorDevice0</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-415"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-416"></span><span>      </span><span class="annot"><a href="#local-6989586621679696618"><span class="hs-identifier hs-type">activation</span></a></span><span>
</span><span id="line-417"></span><span>      </span><span class="annot"><a href="#local-6989586621679696620"><span class="hs-identifier hs-type">tensor0</span></a></span><span>
</span><span id="line-418"></span><span>      </span><span class="annot"><a href="#local-6989586621679696619"><span class="hs-identifier hs-type">generatorDevice0</span></a></span><span>
</span><span id="line-419"></span><span>      </span><span class="annot"><a href="#local-6989586621679696617"><span class="hs-identifier hs-type">tensor1</span></a></span><span>
</span><span id="line-420"></span><span>      </span><span class="annot"><a href="#local-6989586621679696616"><span class="hs-identifier hs-type">generatorDevice1</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-421"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-422"></span><span>      </span><span class="annot"><a href="#local-6989586621679696615"><span class="hs-identifier hs-type">layerNorm</span></a></span><span>
</span><span id="line-423"></span><span>      </span><span class="annot"><a href="#local-6989586621679696617"><span class="hs-identifier hs-type">tensor1</span></a></span><span>
</span><span id="line-424"></span><span>      </span><span class="annot"><a href="#local-6989586621679696616"><span class="hs-identifier hs-type">generatorDevice1</span></a></span><span>
</span><span id="line-425"></span><span>      </span><span class="annot"><a href="#local-6989586621679696614"><span class="hs-identifier hs-type">tensor2</span></a></span><span>
</span><span id="line-426"></span><span>      </span><span class="annot"><a href="#local-6989586621679696613"><span class="hs-identifier hs-type">generatorDevice2</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-427"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-428"></span><span>      </span><span class="annot"><a href="#local-6989586621679696612"><span class="hs-identifier hs-type">decoder</span></a></span><span>
</span><span id="line-429"></span><span>      </span><span class="annot"><a href="#local-6989586621679696614"><span class="hs-identifier hs-type">tensor2</span></a></span><span>
</span><span id="line-430"></span><span>      </span><span class="annot"><a href="#local-6989586621679696613"><span class="hs-identifier hs-type">generatorDevice2</span></a></span><span>
</span><span id="line-431"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696611"><span class="hs-identifier hs-type">gradient3</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696610"><span class="hs-identifier hs-type">layout3</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696609"><span class="hs-identifier hs-type">device3</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696608"><span class="hs-identifier hs-type">dataType3</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696607"><span class="hs-identifier hs-type">shape3</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-432"></span><span>      </span><span class="annot"><a href="#local-6989586621679696606"><span class="hs-identifier hs-type">generatorDevice3</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-433"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-434"></span><span>      </span><span class="annot"><a href="#local-6989586621679696605"><span class="hs-identifier hs-type">bias</span></a></span><span>
</span><span id="line-435"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696611"><span class="hs-identifier hs-type">gradient3</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696610"><span class="hs-identifier hs-type">layout3</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696609"><span class="hs-identifier hs-type">device3</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696608"><span class="hs-identifier hs-type">dataType3</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696607"><span class="hs-identifier hs-type">shape3</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-436"></span><span>      </span><span class="annot"><a href="#local-6989586621679696606"><span class="hs-identifier hs-type">generatorDevice3</span></a></span><span>
</span><span id="line-437"></span><span>      </span><span class="annot"><a href="#local-6989586621679696604"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-438"></span><span>      </span><span class="annot"><a href="#local-6989586621679696603"><span class="hs-identifier hs-type">generatorOutputDevice</span></a></span><span>
</span><span id="line-439"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-440"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-441"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#GLMHead"><span class="hs-identifier hs-type">GLMHead</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696602"><span class="hs-identifier hs-type">inputEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696627"><span class="hs-identifier hs-type">dense</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696618"><span class="hs-identifier hs-type">activation</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696615"><span class="hs-identifier hs-type">layerNorm</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696612"><span class="hs-identifier hs-type">decoder</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696605"><span class="hs-identifier hs-type">bias</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-442"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696626"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696625"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696624"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696623"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696622"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-443"></span><span>    </span><span class="annot"><a href="#local-6989586621679696621"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-444"></span><span>    </span><span class="annot"><a href="#local-6989586621679696604"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-445"></span><span>    </span><span class="annot"><a href="#local-6989586621679696603"><span class="hs-identifier hs-type">generatorOutputDevice</span></a></span><span>
</span><span id="line-446"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-447"></span><span>  </span><span id="local-6989586621679696599"><span class="annot"><span class="annottext">forward :: GLMHead inputEmbedDim dense activation layerNorm decoder bias
-&gt; Tensor gradient layout device dataType shape
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var hs-var hs-var hs-var">forward</span></a></span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#GLMHead"><span class="hs-identifier hs-type">GLMHead</span></a></span><span> </span><span class="hs-special">{</span><span id="local-6989586621679696591"><span id="local-6989586621679696592"><span id="local-6989586621679696593"><span id="local-6989586621679696594"><span id="local-6989586621679696595"><span id="local-6989586621679696596"><span id="local-6989586621679696597"><span class="annot"><span class="annottext">dense
activation
layerNorm
decoder
bias
SDim inputEmbedDim
LMHeadHasScaling
lmHeadHasScaling :: LMHeadHasScaling
lmHeadBias :: bias
lmHeadDecoder :: decoder
lmHeadLayerNorm :: layerNorm
lmHeadActivation :: activation
lmHeadDense :: dense
lmHeadInputEmbedDim :: SDim inputEmbedDim
lmHeadHasScaling :: forall (inputEmbedDim :: Dim (Name Symbol) (Size Nat)) dense
       activation layerNorm decoder bias.
GLMHead inputEmbedDim dense activation layerNorm decoder bias
-&gt; LMHeadHasScaling
lmHeadBias :: forall (inputEmbedDim :: Dim (Name Symbol) (Size Nat)) dense
       activation layerNorm decoder bias.
GLMHead inputEmbedDim dense activation layerNorm decoder bias
-&gt; bias
lmHeadDecoder :: forall (inputEmbedDim :: Dim (Name Symbol) (Size Nat)) dense
       activation layerNorm decoder bias.
GLMHead inputEmbedDim dense activation layerNorm decoder bias
-&gt; decoder
lmHeadLayerNorm :: forall (inputEmbedDim :: Dim (Name Symbol) (Size Nat)) dense
       activation layerNorm decoder bias.
GLMHead inputEmbedDim dense activation layerNorm decoder bias
-&gt; layerNorm
lmHeadActivation :: forall (inputEmbedDim :: Dim (Name Symbol) (Size Nat)) dense
       activation layerNorm decoder bias.
GLMHead inputEmbedDim dense activation layerNorm decoder bias
-&gt; activation
lmHeadDense :: forall (inputEmbedDim :: Dim (Name Symbol) (Size Nat)) dense
       activation layerNorm decoder bias.
GLMHead inputEmbedDim dense activation layerNorm decoder bias
-&gt; dense
lmHeadInputEmbedDim :: forall (inputEmbedDim :: Dim (Name Symbol) (Size Nat)) dense
       activation layerNorm decoder bias.
GLMHead inputEmbedDim dense activation layerNorm decoder bias
-&gt; SDim inputEmbedDim
</span><a href="#local-6989586621679696591"><span class="hs-glyph hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">..</span></a></span></span></span></span></span></span></span></span><span class="hs-special">}</span><span> </span><span id="local-6989586621679696590"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679696590"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-448"></span><span>    </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679696589"><span class="annot"><span class="annottext">scaling :: Double
</span><a href="#local-6989586621679696589"><span class="hs-identifier hs-var hs-var">scaling</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Double
</span><span class="hs-number">1</span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Double -&gt; Double -&gt; Double
forall a. Fractional a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">/</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Double -&gt; Double
forall a. Floating a =&gt; a -&gt; a
</span><span class="hs-identifier hs-var">sqrt</span></span><span> </span><span class="annot"><span class="annottext">(Double -&gt; Double)
-&gt; (SDim inputEmbedDim -&gt; Double) -&gt; SDim inputEmbedDim -&gt; Double
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Integer -&gt; Double
forall a b. (Integral a, Num b) =&gt; a -&gt; b
</span><span class="hs-identifier hs-var">fromIntegral</span></span><span> </span><span class="annot"><span class="annottext">(Integer -&gt; Double)
-&gt; (SDim inputEmbedDim -&gt; Integer) -&gt; SDim inputEmbedDim -&gt; Double
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">IsChecked Integer -&gt; Integer
forall a. IsChecked a -&gt; a
</span><a href="Torch.GraduallyTyped.Prelude.html#forgetIsChecked"><span class="hs-identifier hs-var">forgetIsChecked</span></a></span><span> </span><span class="annot"><span class="annottext">(IsChecked Integer -&gt; Integer)
-&gt; (SDim inputEmbedDim -&gt; IsChecked Integer)
-&gt; SDim inputEmbedDim
-&gt; Integer
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Dim (IsChecked String) (IsChecked Integer) -&gt; IsChecked Integer
forall name size. Dim name size -&gt; size
</span><a href="Torch.GraduallyTyped.Shape.Type.html#dimSize"><span class="hs-identifier hs-var hs-var">dimSize</span></a></span><span> </span><span class="annot"><span class="annottext">(Dim (IsChecked String) (IsChecked Integer) -&gt; IsChecked Integer)
-&gt; (SDim inputEmbedDim
    -&gt; Dim (IsChecked String) (IsChecked Integer))
-&gt; SDim inputEmbedDim
-&gt; IsChecked Integer
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim -&gt; Dim (IsChecked String) (IsChecked Integer)
forall k (a :: k). SingKind k =&gt; Sing a -&gt; Demote k
</span><a href="../file:///nix/store/44d7539k7gqlplsaxjj66fck1zc772zc-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">fromSing</span></a></span><span> </span><span class="annot"><span class="annottext">(SDim inputEmbedDim -&gt; Double) -&gt; SDim inputEmbedDim -&gt; Double
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SDim inputEmbedDim
</span><a href="#local-6989586621679696597"><span class="hs-identifier hs-var">lmHeadInputEmbedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-449"></span><span>     </span><span class="hs-keyword">in</span><span> </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorOutputDevice)
  output
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
forall (m :: * -&gt; *) i j a. IxStateT m i j a -&gt; i -&gt; m (a, j)
</span><a href="../file:///nix/store/izdh8cwvq0acwzr2lk5vjhjfywaq1s9y-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var hs-var">runIxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">(IxStateT
   m
   (Generator generatorDevice)
   (Generator generatorOutputDevice)
   output
 -&gt; Generator generatorDevice
 -&gt; m (output, Generator generatorOutputDevice))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorOutputDevice)
     output
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-450"></span><span>          </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     (Tensor gradient layout device dataType shape)
forall k (m :: k -&gt; k -&gt; * -&gt; *) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/wpb5hggv8az7m3hh6dk4vnmz1z9va197-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679696590"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-451"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorDevice)
  (Tensor gradient layout device dataType shape)
-&gt; (Tensor gradient layout device dataType shape
    -&gt; IxStateT
         m (Generator generatorDevice) (Generator generatorDevice0) tensor0)
-&gt; IxStateT
     m (Generator generatorDevice) (Generator generatorDevice0) tensor0
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/wpb5hggv8az7m3hh6dk4vnmz1z9va197-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(Generator generatorDevice
 -&gt; m (tensor0, Generator generatorDevice0))
-&gt; IxStateT
     m (Generator generatorDevice) (Generator generatorDevice0) tensor0
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/izdh8cwvq0acwzr2lk5vjhjfywaq1s9y-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator generatorDevice
  -&gt; m (tensor0, Generator generatorDevice0))
 -&gt; IxStateT
      m (Generator generatorDevice) (Generator generatorDevice0) tensor0)
-&gt; (Tensor gradient layout device dataType shape
    -&gt; Generator generatorDevice
    -&gt; m (tensor0, Generator generatorDevice0))
-&gt; Tensor gradient layout device dataType shape
-&gt; IxStateT
     m (Generator generatorDevice) (Generator generatorDevice0) tensor0
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">dense
-&gt; Tensor gradient layout device dataType shape
-&gt; Generator generatorDevice
-&gt; m (tensor0, Generator generatorDevice0)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: * -&gt; *).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">dense
</span><a href="#local-6989586621679696596"><span class="hs-identifier hs-var">lmHeadDense</span></a></span><span>
</span><span id="line-452"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m (Generator generatorDevice) (Generator generatorDevice0) tensor0
-&gt; (tensor0
    -&gt; IxStateT
         m
         (Generator generatorDevice0)
         (Generator generatorDevice1)
         tensor1)
-&gt; IxStateT
     m (Generator generatorDevice) (Generator generatorDevice1) tensor1
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/wpb5hggv8az7m3hh6dk4vnmz1z9va197-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(Generator generatorDevice0
 -&gt; m (tensor1, Generator generatorDevice1))
-&gt; IxStateT
     m (Generator generatorDevice0) (Generator generatorDevice1) tensor1
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/izdh8cwvq0acwzr2lk5vjhjfywaq1s9y-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator generatorDevice0
  -&gt; m (tensor1, Generator generatorDevice1))
 -&gt; IxStateT
      m
      (Generator generatorDevice0)
      (Generator generatorDevice1)
      tensor1)
-&gt; (tensor0
    -&gt; Generator generatorDevice0
    -&gt; m (tensor1, Generator generatorDevice1))
-&gt; tensor0
-&gt; IxStateT
     m (Generator generatorDevice0) (Generator generatorDevice1) tensor1
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">activation
-&gt; tensor0
-&gt; Generator generatorDevice0
-&gt; m (tensor1, Generator generatorDevice1)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: * -&gt; *).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">activation
</span><a href="#local-6989586621679696595"><span class="hs-identifier hs-var">lmHeadActivation</span></a></span><span>
</span><span id="line-453"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m (Generator generatorDevice) (Generator generatorDevice1) tensor1
-&gt; (tensor1
    -&gt; IxStateT
         m
         (Generator generatorDevice1)
         (Generator generatorDevice2)
         tensor2)
-&gt; IxStateT
     m (Generator generatorDevice) (Generator generatorDevice2) tensor2
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/wpb5hggv8az7m3hh6dk4vnmz1z9va197-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(Generator generatorDevice1
 -&gt; m (tensor2, Generator generatorDevice2))
-&gt; IxStateT
     m (Generator generatorDevice1) (Generator generatorDevice2) tensor2
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/izdh8cwvq0acwzr2lk5vjhjfywaq1s9y-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator generatorDevice1
  -&gt; m (tensor2, Generator generatorDevice2))
 -&gt; IxStateT
      m
      (Generator generatorDevice1)
      (Generator generatorDevice2)
      tensor2)
-&gt; (tensor1
    -&gt; Generator generatorDevice1
    -&gt; m (tensor2, Generator generatorDevice2))
-&gt; tensor1
-&gt; IxStateT
     m (Generator generatorDevice1) (Generator generatorDevice2) tensor2
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">layerNorm
-&gt; tensor1
-&gt; Generator generatorDevice1
-&gt; m (tensor2, Generator generatorDevice2)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: * -&gt; *).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">layerNorm
</span><a href="#local-6989586621679696594"><span class="hs-identifier hs-var">lmHeadLayerNorm</span></a></span><span>
</span><span id="line-454"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m (Generator generatorDevice) (Generator generatorDevice2) tensor2
-&gt; (tensor2
    -&gt; IxStateT
         m
         (Generator generatorDevice2)
         (Generator generatorDevice3)
         (Tensor gradient3 layout3 device3 dataType3 shape3))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice3)
     (Tensor gradient3 layout3 device3 dataType3 shape3)
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/wpb5hggv8az7m3hh6dk4vnmz1z9va197-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(Generator generatorDevice2
 -&gt; m (Tensor gradient3 layout3 device3 dataType3 shape3,
       Generator generatorDevice3))
-&gt; IxStateT
     m
     (Generator generatorDevice2)
     (Generator generatorDevice3)
     (Tensor gradient3 layout3 device3 dataType3 shape3)
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/izdh8cwvq0acwzr2lk5vjhjfywaq1s9y-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator generatorDevice2
  -&gt; m (Tensor gradient3 layout3 device3 dataType3 shape3,
        Generator generatorDevice3))
 -&gt; IxStateT
      m
      (Generator generatorDevice2)
      (Generator generatorDevice3)
      (Tensor gradient3 layout3 device3 dataType3 shape3))
-&gt; (tensor2
    -&gt; Generator generatorDevice2
    -&gt; m (Tensor gradient3 layout3 device3 dataType3 shape3,
          Generator generatorDevice3))
-&gt; tensor2
-&gt; IxStateT
     m
     (Generator generatorDevice2)
     (Generator generatorDevice3)
     (Tensor gradient3 layout3 device3 dataType3 shape3)
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">decoder
-&gt; tensor2
-&gt; Generator generatorDevice2
-&gt; m (Tensor gradient3 layout3 device3 dataType3 shape3,
      Generator generatorDevice3)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: * -&gt; *).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">decoder
</span><a href="#local-6989586621679696593"><span class="hs-identifier hs-var">lmHeadDecoder</span></a></span><span>
</span><span id="line-455"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorDevice3)
  (Tensor gradient3 layout3 device3 dataType3 shape3)
-&gt; (Tensor gradient3 layout3 device3 dataType3 shape3
    -&gt; IxStateT
         m
         (Generator generatorDevice3)
         (Generator generatorDevice3)
         (Tensor gradient3 layout3 device3 dataType3 shape3))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice3)
     (Tensor gradient3 layout3 device3 dataType3 shape3)
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/wpb5hggv8az7m3hh6dk4vnmz1z9va197-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">m (Tensor gradient3 layout3 device3 dataType3 shape3)
-&gt; IxStateT
     m
     (Generator generatorDevice3)
     (Generator generatorDevice3)
     (Tensor gradient3 layout3 device3 dataType3 shape3)
forall k (t :: (* -&gt; *) -&gt; k -&gt; k -&gt; * -&gt; *) (m :: * -&gt; *) a
       (i :: k).
(IxMonadTrans t, Monad m) =&gt;
m a -&gt; t m i i a
</span><a href="../file:///nix/store/wpb5hggv8az7m3hh6dk4vnmz1z9va197-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ilift</span></a></span><span>
</span><span id="line-456"></span><span>              </span><span class="annot"><span class="annottext">(m (Tensor gradient3 layout3 device3 dataType3 shape3)
 -&gt; IxStateT
      m
      (Generator generatorDevice3)
      (Generator generatorDevice3)
      (Tensor gradient3 layout3 device3 dataType3 shape3))
-&gt; (Tensor gradient3 layout3 device3 dataType3 shape3
    -&gt; m (Tensor gradient3 layout3 device3 dataType3 shape3))
-&gt; Tensor gradient3 layout3 device3 dataType3 shape3
-&gt; IxStateT
     m
     (Generator generatorDevice3)
     (Generator generatorDevice3)
     (Tensor gradient3 layout3 device3 dataType3 shape3)
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="hs-special">(</span><span> </span><span class="hs-glyph">\</span><span class="hs-glyph">case</span><span>
</span><span id="line-457"></span><span>                    </span><span class="annot"><span class="annottext">LMHeadHasScaling
</span><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadWithoutScaling"><span class="hs-identifier hs-var">LMHeadWithoutScaling</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">Tensor gradient3 layout3 device3 dataType3 shape3
-&gt; m (Tensor gradient3 layout3 device3 dataType3 shape3)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span>
</span><span id="line-458"></span><span>                    </span><span class="annot"><span class="annottext">LMHeadHasScaling
</span><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#LMHeadWithScaling"><span class="hs-identifier hs-var">LMHeadWithScaling</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">(Tensor gradient3 layout3 device3 dataType3 shape3
 -&gt; Double -&gt; m (Tensor gradient3 layout3 device3 dataType3 shape3))
-&gt; Double
-&gt; Tensor gradient3 layout3 device3 dataType3 shape3
-&gt; m (Tensor gradient3 layout3 device3 dataType3 shape3)
forall a b c. (a -&gt; b -&gt; c) -&gt; b -&gt; a -&gt; c
</span><span class="hs-identifier hs-var">flip</span></span><span> </span><span class="annot"><span class="annottext">Tensor gradient3 layout3 device3 dataType3 shape3
-&gt; Double -&gt; m (Tensor gradient3 layout3 device3 dataType3 shape3)
forall other (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]) (m :: * -&gt; *).
(Scalar other, MonadThrow m) =&gt;
Tensor gradient layout device dataType shape
-&gt; other -&gt; m (Tensor gradient layout device dataType shape)
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#mulScalar"><span class="hs-identifier hs-var">mulScalar</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679696589"><span class="hs-identifier hs-var">scaling</span></a></span><span>
</span><span id="line-459"></span><span>                </span><span class="hs-special">)</span><span>
</span><span id="line-460"></span><span>                </span><span class="annot"><span class="annottext">LMHeadHasScaling
</span><a href="#local-6989586621679696591"><span class="hs-identifier hs-var">lmHeadHasScaling</span></a></span><span>
</span><span id="line-461"></span><span>            </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorDevice3)
  (Tensor gradient3 layout3 device3 dataType3 shape3)
-&gt; (Tensor gradient3 layout3 device3 dataType3 shape3
    -&gt; IxStateT
         m
         (Generator generatorDevice3)
         (Generator generatorOutputDevice)
         output)
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorOutputDevice)
     output
forall k1 (m :: k1 -&gt; k1 -&gt; * -&gt; *) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/wpb5hggv8az7m3hh6dk4vnmz1z9va197-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(Generator generatorDevice3
 -&gt; m (output, Generator generatorOutputDevice))
-&gt; IxStateT
     m
     (Generator generatorDevice3)
     (Generator generatorOutputDevice)
     output
forall (m :: * -&gt; *) i j a. (i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/izdh8cwvq0acwzr2lk5vjhjfywaq1s9y-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator generatorDevice3
  -&gt; m (output, Generator generatorOutputDevice))
 -&gt; IxStateT
      m
      (Generator generatorDevice3)
      (Generator generatorOutputDevice)
      output)
-&gt; (Tensor gradient3 layout3 device3 dataType3 shape3
    -&gt; Generator generatorDevice3
    -&gt; m (output, Generator generatorOutputDevice))
-&gt; Tensor gradient3 layout3 device3 dataType3 shape3
-&gt; IxStateT
     m
     (Generator generatorDevice3)
     (Generator generatorOutputDevice)
     output
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">bias
-&gt; Tensor gradient3 layout3 device3 dataType3 shape3
-&gt; Generator generatorDevice3
-&gt; m (output, Generator generatorOutputDevice)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: * -&gt; *).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">bias
</span><a href="#local-6989586621679696592"><span class="hs-identifier hs-var">lmHeadBias</span></a></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span>
</span><span id="line-462"></span><span>
</span><span id="line-463"></span><span id="local-6989586621679696577"><span id="local-6989586621679696578"><span id="local-6989586621679696579"><span id="local-6989586621679696580"><span id="local-6989586621679696581"><span id="local-6989586621679696582"><span class="hs-keyword">instance</span><span>
</span><span id="line-464"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-465"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#GBias"><span class="hs-identifier hs-type">GBias</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-466"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696582"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696581"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696580"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696579"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696578"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-467"></span><span>    </span><span class="annot"><a href="#local-6989586621679696577"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-468"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696582"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696581"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696580"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696579"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696578"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-469"></span><span>    </span><span class="annot"><a href="#local-6989586621679696577"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-470"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-471"></span><span>  </span><span id="local-6989586621679696575"><span class="annot"><span class="annottext">forward :: GBias ()
-&gt; Tensor gradient layout device dataType shape
-&gt; Generator generatorDevice
-&gt; m (Tensor gradient layout device dataType shape,
      Generator generatorDevice)
</span><a href="#local-6989586621679696575"><span class="hs-identifier hs-var hs-var hs-var hs-var">forward</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#GBias"><span class="hs-identifier hs-type">GBias</span></a></span><span> </span><span id="local-6989586621679696574"><span class="annot"><span class="annottext">()
</span><a href="#local-6989586621679696574"><span class="hs-identifier hs-var">bias</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">()
-&gt; Tensor gradient layout device dataType shape
-&gt; Generator generatorDevice
-&gt; m (Tensor gradient layout device dataType shape,
      Generator generatorDevice)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: * -&gt; *).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">()
</span><a href="#local-6989586621679696574"><span class="hs-identifier hs-var">bias</span></a></span></span></span></span></span></span></span><span>
</span><span id="line-472"></span><span>
</span><span id="line-473"></span><span id="local-6989586621679696561"><span id="local-6989586621679696562"><span id="local-6989586621679696563"><span id="local-6989586621679696564"><span id="local-6989586621679696565"><span id="local-6989586621679696566"><span id="local-6989586621679696567"><span id="local-6989586621679696568"><span id="local-6989586621679696569"><span id="local-6989586621679696570"><span id="local-6989586621679696571"><span id="local-6989586621679696572"><span id="local-6989586621679696573"><span class="hs-keyword">instance</span><span>
</span><span id="line-474"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="#local-6989586621679696573"><span class="hs-identifier hs-type">shape'</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#BroadcastShapesF"><span class="hs-identifier hs-type">BroadcastShapesF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696572"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696571"><span class="hs-identifier hs-type">biasShape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-475"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Catch"><span class="hs-identifier hs-type">Catch</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696573"><span class="hs-identifier hs-type">shape'</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-476"></span><span>    </span><span class="annot"><a href="#local-6989586621679696570"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-477"></span><span>      </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-478"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679696569"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696568"><span class="hs-identifier hs-type">biasGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-479"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679696567"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696566"><span class="hs-identifier hs-type">biasLayout</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-480"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679696565"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696564"><span class="hs-identifier hs-type">biasDevice</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-481"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679696563"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696562"><span class="hs-identifier hs-type">biasDataType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-482"></span><span>          </span><span class="annot"><a href="#local-6989586621679696573"><span class="hs-identifier hs-type">shape'</span></a></span><span>
</span><span id="line-483"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-484"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-485"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#GBias"><span class="hs-identifier hs-type">GBias</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696568"><span class="hs-identifier hs-type">biasGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696566"><span class="hs-identifier hs-type">biasLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696564"><span class="hs-identifier hs-type">biasDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696562"><span class="hs-identifier hs-type">biasDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696571"><span class="hs-identifier hs-type">biasShape</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-486"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696569"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696567"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696565"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696563"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696572"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-487"></span><span>    </span><span class="annot"><a href="#local-6989586621679696561"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-488"></span><span>    </span><span class="annot"><a href="#local-6989586621679696570"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-489"></span><span>    </span><span class="annot"><a href="#local-6989586621679696561"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-490"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-491"></span><span>  </span><span id="local-6989586621679696559"><span class="annot"><span class="annottext">forward :: GBias
  (Tensor biasGradient biasLayout biasDevice biasDataType biasShape)
-&gt; Tensor gradient layout device dataType shape
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorDevice)
</span><a href="#local-6989586621679696559"><span class="hs-identifier hs-var hs-var hs-var hs-var">forward</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#GBias"><span class="hs-identifier hs-type">GBias</span></a></span><span> </span><span id="local-6989586621679696558"><span class="annot"><span class="annottext">Tensor biasGradient biasLayout biasDevice biasDataType biasShape
</span><a href="#local-6989586621679696558"><span class="hs-identifier hs-var">bias</span></a></span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679696557"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679696557"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span id="local-6989586621679696556"><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679696556"><span class="hs-identifier hs-var">g</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-492"></span><span>    </span><span id="local-6989586621679696555"><span class="annot"><span class="annottext">output
</span><a href="#local-6989586621679696555"><span class="hs-identifier hs-var">r</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679696557"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
-&gt; Tensor biasGradient biasLayout biasDevice biasDataType biasShape
-&gt; m (Tensor
        (gradient &lt;|&gt; biasGradient)
        (layout &lt;+&gt; biasLayout)
        (device &lt;+&gt; biasDevice)
        (dataType &lt;+&gt; biasDataType)
        shape')
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (gradient' :: Gradient RequiresGradient)
       (layout' :: Layout LayoutType) (device' :: Device (DeviceType Nat))
       (dataType' :: DataType DType)
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)])
       (shape'' :: Shape [Dim (Name Symbol) (Size Nat)]) (m :: * -&gt; *).
(MonadThrow m, shape'' ~ BroadcastShapesF shape shape',
 Catch shape'') =&gt;
Tensor gradient layout device dataType shape
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; m (Tensor
        (gradient &lt;|&gt; gradient')
        (layout &lt;+&gt; layout')
        (device &lt;+&gt; device')
        (dataType &lt;+&gt; dataType')
        shape'')
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#add"><span class="hs-operator hs-var">`add`</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor biasGradient biasLayout biasDevice biasDataType biasShape
</span><a href="#local-6989586621679696558"><span class="hs-identifier hs-var">bias</span></a></span><span>
</span><span id="line-493"></span><span>    </span><span class="annot"><span class="annottext">(output, Generator generatorDevice)
-&gt; m (output, Generator generatorDevice)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">output
</span><a href="#local-6989586621679696555"><span class="hs-identifier hs-var">r</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679696556"><span class="hs-identifier hs-var">g</span></a></span><span class="hs-special">)</span></span></span></span></span></span></span></span></span></span></span></span></span></span><span>
</span><span id="line-494"></span><span>
</span><span id="line-495"></span><span id="local-6989586621679696542"><span id="local-6989586621679696543"><span id="local-6989586621679696544"><span id="local-6989586621679696545"><span id="local-6989586621679696546"><span id="local-6989586621679696547"><span id="local-6989586621679696548"><span id="local-6989586621679696549"><span id="local-6989586621679696550"><span id="local-6989586621679696551"><span id="local-6989586621679696552"><span id="local-6989586621679696553"><span id="local-6989586621679696554"><span class="hs-keyword">instance</span><span>
</span><span id="line-496"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="#local-6989586621679696554"><span class="hs-identifier hs-type">shape'</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#BroadcastShapesF"><span class="hs-identifier hs-type">BroadcastShapesF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696553"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696552"><span class="hs-identifier hs-type">biasShape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-497"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Catch"><span class="hs-identifier hs-type">Catch</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696554"><span class="hs-identifier hs-type">shape'</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-498"></span><span>    </span><span class="annot"><a href="#local-6989586621679696551"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-499"></span><span>      </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-500"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679696550"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696549"><span class="hs-identifier hs-type">biasGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-501"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679696548"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696547"><span class="hs-identifier hs-type">biasLayout</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-502"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679696546"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696545"><span class="hs-identifier hs-type">biasDevice</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-503"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679696544"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696543"><span class="hs-identifier hs-type">biasDataType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-504"></span><span>          </span><span class="annot"><a href="#local-6989586621679696554"><span class="hs-identifier hs-type">shape'</span></a></span><span>
</span><span id="line-505"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-506"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-507"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#GBias"><span class="hs-identifier hs-type">GBias</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-type">NamedModel</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696549"><span class="hs-identifier hs-type">biasGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696547"><span class="hs-identifier hs-type">biasLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696545"><span class="hs-identifier hs-type">biasDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696543"><span class="hs-identifier hs-type">biasDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696552"><span class="hs-identifier hs-type">biasShape</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-508"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696550"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696548"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696546"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696544"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679696553"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-509"></span><span>    </span><span class="annot"><a href="#local-6989586621679696542"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-510"></span><span>    </span><span class="annot"><a href="#local-6989586621679696551"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-511"></span><span>    </span><span class="annot"><a href="#local-6989586621679696542"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-512"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-513"></span><span>  </span><span id="local-6989586621679696540"><span class="annot"><span class="annottext">forward :: GBias
  (NamedModel
     (Tensor biasGradient biasLayout biasDevice biasDataType biasShape))
-&gt; Tensor gradient layout device dataType shape
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorDevice)
</span><a href="#local-6989586621679696540"><span class="hs-identifier hs-var hs-var hs-var hs-var">forward</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.GLMHead.html#GBias"><span class="hs-identifier hs-type">GBias</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#NamedModel"><span class="hs-identifier hs-type">NamedModel</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-identifier">_</span></span><span> </span><span id="local-6989586621679696539"><span class="annot"><span class="annottext">Tensor biasGradient biasLayout biasDevice biasDataType biasShape
</span><a href="#local-6989586621679696539"><span class="hs-identifier hs-var">bias</span></a></span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span id="local-6989586621679696538"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679696538"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span id="local-6989586621679696537"><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679696537"><span class="hs-identifier hs-var">g</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-514"></span><span>    </span><span id="local-6989586621679696536"><span class="annot"><span class="annottext">output
</span><a href="#local-6989586621679696536"><span class="hs-identifier hs-var">r</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679696538"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
-&gt; Tensor biasGradient biasLayout biasDevice biasDataType biasShape
-&gt; m (Tensor
        (gradient &lt;|&gt; biasGradient)
        (layout &lt;+&gt; biasLayout)
        (device &lt;+&gt; biasDevice)
        (dataType &lt;+&gt; biasDataType)
        shape')
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (gradient' :: Gradient RequiresGradient)
       (layout' :: Layout LayoutType) (device' :: Device (DeviceType Nat))
       (dataType' :: DataType DType)
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)])
       (shape'' :: Shape [Dim (Name Symbol) (Size Nat)]) (m :: * -&gt; *).
(MonadThrow m, shape'' ~ BroadcastShapesF shape shape',
 Catch shape'') =&gt;
Tensor gradient layout device dataType shape
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; m (Tensor
        (gradient &lt;|&gt; gradient')
        (layout &lt;+&gt; layout')
        (device &lt;+&gt; device')
        (dataType &lt;+&gt; dataType')
        shape'')
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#add"><span class="hs-operator hs-var">`add`</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor biasGradient biasLayout biasDevice biasDataType biasShape
</span><a href="#local-6989586621679696539"><span class="hs-identifier hs-var">bias</span></a></span><span>
</span><span id="line-515"></span><span>    </span><span class="annot"><span class="annottext">(output, Generator generatorDevice)
-&gt; m (output, Generator generatorDevice)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">output
</span><a href="#local-6989586621679696536"><span class="hs-identifier hs-var">r</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679696537"><span class="hs-identifier hs-var">g</span></a></span><span class="hs-special">)</span></span></span></span></span></span></span></span></span></span></span></span></span></span><span>
</span><span id="line-516"></span></pre></body></html>