<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><link rel="stylesheet" type="text/css" href="style.css" /><script type="text/javascript" src="highlight.js"></script></head><body><pre><span class="hs-pragma">{-# LANGUAGE DataKinds #-}</span><span>
</span><span id="line-2"></span><span class="hs-pragma">{-# LANGUAGE RankNTypes #-}</span><span>
</span><span id="line-3"></span><span class="hs-pragma">{-# LANGUAGE TypeOperators #-}</span><span>
</span><span id="line-4"></span><span>
</span><span id="line-5"></span><span class="hs-keyword">module</span><span> </span><span class="hs-identifier">Torch.GraduallyTyped.Tensor.MathOperations.Pointwise</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-6"></span><span>
</span><span id="line-7"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">System.IO.Unsafe</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier">unsafePerformIO</span></span><span class="hs-special">)</span><span>
</span><span id="line-8"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html"><span class="hs-identifier">Torch.GraduallyTyped.DType</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier">DType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier">DataType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-9"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html"><span class="hs-identifier">Torch.GraduallyTyped.RequiresGradient</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier">Gradient</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#RequiresGradient"><span class="hs-identifier">RequiresGradient</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-10"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Scalar.html"><span class="hs-identifier">Torch.GraduallyTyped.Scalar</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Scalar.html#Scalar"><span class="hs-identifier">Scalar</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-11"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.html"><span class="hs-identifier">Torch.GraduallyTyped.Shape</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#BroadcastShapesF"><span class="hs-identifier">BroadcastShapesF</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-12"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html"><span class="hs-identifier">Torch.GraduallyTyped.Tensor.Type</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier">Tensor</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-13"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html"><span class="hs-identifier">Torch.GraduallyTyped.Unify</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-keyword">type</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator">(&lt;+&gt;)</span></a></span><span class="hs-special">,</span><span> </span><span class="hs-keyword">type</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator">(&lt;|&gt;)</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-14"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier">Torch.Internal.Cast</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier">cast1</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier">cast2</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier">cast3</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier">cast4</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-15"></span><span class="hs-keyword">import</span><span> </span><span class="hs-keyword">qualified</span><span> </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier">Torch.Internal.Managed.Native</span></a></span><span> </span><span class="hs-keyword">as</span><span> </span><span class="annot"><span class="hs-identifier">ATen</span></span><span>
</span><span id="line-16"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">Prelude</span></span><span> </span><span class="hs-keyword">hiding</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier">abs</span></span><span class="hs-special">)</span><span>
</span><span id="line-17"></span><span>
</span><span id="line-18"></span><span class="hs-comment">-- $setup</span><span>
</span><span id="line-19"></span><span class="hs-comment">-- &gt;&gt;&gt; import Data.Singletons.Prelude.List (SList (..))</span><span>
</span><span id="line-20"></span><span class="hs-comment">-- &gt;&gt;&gt; import Torch.GraduallyTyped</span><span>
</span><span id="line-21"></span><span>
</span><span id="line-22"></span><span class="hs-comment">-- | Computes the element-wise absolute value of the given 'input' tensor:</span><span>
</span><span id="line-23"></span><span class="hs-comment">-- \[</span><span>
</span><span id="line-24"></span><span class="hs-comment">-- \mathrm{output}_i = \left|\mathrm{input}_i\right|.</span><span>
</span><span id="line-25"></span><span class="hs-comment">-- \]</span><span>
</span><span id="line-26"></span><span class="hs-comment">-- The result is returned as a new tensor.</span><span>
</span><span id="line-27"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#abs"><span class="hs-identifier hs-type">abs</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-28"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679521898"><span class="annot"><a href="#local-6989586621679521898"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679521897"><span class="annot"><a href="#local-6989586621679521897"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679521896"><span class="annot"><a href="#local-6989586621679521896"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679521895"><span class="annot"><a href="#local-6989586621679521895"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679521894"><span class="annot"><a href="#local-6989586621679521894"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-29"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-30"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521898"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521897"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521896"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521895"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521894"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-31"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-32"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521898"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521897"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521896"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521895"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521894"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-33"></span><span id="abs"><span class="annot"><span class="annottext">abs :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#abs"><span class="hs-identifier hs-var hs-var">abs</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; (Tensor gradient layout device dataType shape
    -&gt; IO (Tensor gradient layout device dataType shape))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.abs_t</span></a></span><span>
</span><span id="line-34"></span><span>
</span><span id="line-35"></span><span class="hs-comment">-- | Alias for 'abs'.</span><span>
</span><span id="line-36"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#absolute"><span class="hs-identifier hs-type">absolute</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-37"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679521408"><span class="annot"><a href="#local-6989586621679521408"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679521407"><span class="annot"><a href="#local-6989586621679521407"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679521406"><span class="annot"><a href="#local-6989586621679521406"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679521405"><span class="annot"><a href="#local-6989586621679521405"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679521404"><span class="annot"><a href="#local-6989586621679521404"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-38"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-39"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521408"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521407"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521406"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521405"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521404"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-40"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-41"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521408"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521407"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521406"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521405"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521404"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-42"></span><span id="absolute"><span class="annot"><span class="annottext">absolute :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#absolute"><span class="hs-identifier hs-var hs-var">absolute</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#abs"><span class="hs-identifier hs-var">abs</span></a></span><span>
</span><span id="line-43"></span><span>
</span><span id="line-44"></span><span class="hs-comment">-- | Returns a new tensor with the arccosine of the elements of 'input':</span><span>
</span><span id="line-45"></span><span class="hs-comment">-- \[</span><span>
</span><span id="line-46"></span><span class="hs-comment">-- \mathrm{output}_i = \cos^{-1} \left(\mathrm{input}_i\right).</span><span>
</span><span id="line-47"></span><span class="hs-comment">-- \]</span><span>
</span><span id="line-48"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#acos"><span class="hs-identifier hs-type">acos</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-49"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679521402"><span class="annot"><a href="#local-6989586621679521402"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679521401"><span class="annot"><a href="#local-6989586621679521401"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679521400"><span class="annot"><a href="#local-6989586621679521400"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679521399"><span class="annot"><a href="#local-6989586621679521399"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679521398"><span class="annot"><a href="#local-6989586621679521398"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-50"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-51"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521402"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521401"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521400"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521399"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521398"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-52"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-53"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521402"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521401"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521400"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521399"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521398"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-54"></span><span id="acos"><span class="annot"><span class="annottext">acos :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#acos"><span class="hs-identifier hs-var hs-var">acos</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; (Tensor gradient layout device dataType shape
    -&gt; IO (Tensor gradient layout device dataType shape))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.acos_t</span></a></span><span>
</span><span id="line-55"></span><span>
</span><span id="line-56"></span><span class="hs-comment">-- | Returns a new tensor with the arccosine of the elements of 'input':</span><span>
</span><span id="line-57"></span><span class="hs-comment">-- \[</span><span>
</span><span id="line-58"></span><span class="hs-comment">-- \mathrm{output}_i = \cosh^{-1} \left(\mathrm{input}_i\right).</span><span>
</span><span id="line-59"></span><span class="hs-comment">-- \]</span><span>
</span><span id="line-60"></span><span class="hs-comment">--</span><span>
</span><span id="line-61"></span><span class="hs-comment">-- Note that the domain of the inverse hyperbolic cosine is \([1, \infty)\), and</span><span>
</span><span id="line-62"></span><span class="hs-comment">-- values outside this range will be mapped to \(\mathrm{NaN}\),</span><span>
</span><span id="line-63"></span><span class="hs-comment">-- except for \(+\infty\) for which the output is mapped to \(+\infty\).</span><span>
</span><span id="line-64"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#acosh"><span class="hs-identifier hs-type">acosh</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-65"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679521395"><span class="annot"><a href="#local-6989586621679521395"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679521394"><span class="annot"><a href="#local-6989586621679521394"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679521393"><span class="annot"><a href="#local-6989586621679521393"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679521392"><span class="annot"><a href="#local-6989586621679521392"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679521391"><span class="annot"><a href="#local-6989586621679521391"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-66"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-67"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521395"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521394"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521393"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521392"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521391"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-68"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-69"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521395"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521394"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521393"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521392"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521391"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-70"></span><span id="acosh"><span class="annot"><span class="annottext">acosh :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#acosh"><span class="hs-identifier hs-var hs-var">acosh</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; (Tensor gradient layout device dataType shape
    -&gt; IO (Tensor gradient layout device dataType shape))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.acosh_t</span></a></span><span>
</span><span id="line-71"></span><span>
</span><span id="line-72"></span><span class="hs-comment">-- | Element-wise addition of one tensor and another:</span><span>
</span><span id="line-73"></span><span class="hs-comment">-- \[</span><span>
</span><span id="line-74"></span><span class="hs-comment">-- \mathrm{output}_i = \mathrm{input}_i + \mathrm{other}_i.</span><span>
</span><span id="line-75"></span><span class="hs-comment">-- \]</span><span>
</span><span id="line-76"></span><span class="hs-comment">-- The result is returned as a new tensor.</span><span>
</span><span id="line-77"></span><span class="hs-comment">--</span><span>
</span><span id="line-78"></span><span class="hs-comment">-- The shape of 'other' must be broadcastable with the shape of 'input'.</span><span>
</span><span id="line-79"></span><span class="hs-comment">-- See 'addScalar' for a version of this function where</span><span>
</span><span id="line-80"></span><span class="hs-comment">-- the 'other' input is a scalar.</span><span>
</span><span id="line-81"></span><span class="hs-comment">--</span><span>
</span><span id="line-82"></span><span class="hs-comment">-- &gt;&gt;&gt; g = sMkGenerator (SDevice SCPU) 0</span><span>
</span><span id="line-83"></span><span class="hs-comment">-- &gt;&gt;&gt; sRandn' = sRandn . TensorSpec (SGradient SWithGradient) (SLayout SDense) (SDevice SCPU) (SDataType SFloat)</span><span>
</span><span id="line-84"></span><span class="hs-comment">-- &gt;&gt;&gt; (a, g') &lt;- sRandn' (SShape $ SName @&quot;feature&quot; :&amp;: SSize @4 :|: SNil) g</span><span>
</span><span id="line-85"></span><span class="hs-comment">-- &gt;&gt;&gt; (b, _) &lt;- sRandn' (SShape $ SName @&quot;*&quot; :&amp;: SSize @4 :|: SName @&quot;*&quot; :&amp;: SSize @1 :|: SNil) g'</span><span>
</span><span id="line-86"></span><span class="hs-comment">-- &gt;&gt;&gt; :type a `add` b</span><span>
</span><span id="line-87"></span><span class="hs-comment">-- a `add` b</span><span>
</span><span id="line-88"></span><span class="hs-comment">--   :: Tensor</span><span>
</span><span id="line-89"></span><span class="hs-comment">--        ('Gradient 'WithGradient)</span><span>
</span><span id="line-90"></span><span class="hs-comment">--        ('Layout 'Dense)</span><span>
</span><span id="line-91"></span><span class="hs-comment">--        ('Device 'CPU)</span><span>
</span><span id="line-92"></span><span class="hs-comment">--        ('DataType 'Float)</span><span>
</span><span id="line-93"></span><span class="hs-comment">--        ('Shape</span><span>
</span><span id="line-94"></span><span class="hs-comment">--           '[ 'Dim ('Name &quot;*&quot;) ('Size 4), 'Dim ('Name &quot;feature&quot;) ('Size 4)])</span><span>
</span><span id="line-95"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#add"><span class="hs-identifier hs-type">add</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-96"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679521388"><span class="annot"><a href="#local-6989586621679521388"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679521387"><span class="annot"><a href="#local-6989586621679521387"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679521386"><span class="annot"><a href="#local-6989586621679521386"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679521385"><span class="annot"><a href="#local-6989586621679521385"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679521384"><span class="annot"><a href="#local-6989586621679521384"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679521383"><span class="annot"><a href="#local-6989586621679521383"><span class="hs-identifier hs-type">gradient'</span></a></span></span><span> </span><span id="local-6989586621679521382"><span class="annot"><a href="#local-6989586621679521382"><span class="hs-identifier hs-type">layout'</span></a></span></span><span> </span><span id="local-6989586621679521381"><span class="annot"><a href="#local-6989586621679521381"><span class="hs-identifier hs-type">device'</span></a></span></span><span> </span><span id="local-6989586621679521380"><span class="annot"><a href="#local-6989586621679521380"><span class="hs-identifier hs-type">dataType'</span></a></span></span><span> </span><span id="local-6989586621679521379"><span class="annot"><a href="#local-6989586621679521379"><span class="hs-identifier hs-type">shape'</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-97"></span><span>  </span><span class="hs-comment">-- | input tensor</span><span>
</span><span id="line-98"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521388"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521387"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521386"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521385"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521384"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-99"></span><span>  </span><span class="hs-comment">-- | other tensor</span><span>
</span><span id="line-100"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521383"><span class="hs-identifier hs-type">gradient'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521382"><span class="hs-identifier hs-type">layout'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521381"><span class="hs-identifier hs-type">device'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521380"><span class="hs-identifier hs-type">dataType'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521379"><span class="hs-identifier hs-type">shape'</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-101"></span><span>  </span><span class="hs-comment">-- | output tensor</span><span>
</span><span id="line-102"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-103"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679521388"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521383"><span class="hs-identifier hs-type">gradient'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-104"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679521387"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521382"><span class="hs-identifier hs-type">layout'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-105"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679521386"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521381"><span class="hs-identifier hs-type">device'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-106"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679521385"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521380"><span class="hs-identifier hs-type">dataType'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-107"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#BroadcastShapesF"><span class="hs-identifier hs-type">BroadcastShapesF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521384"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521379"><span class="hs-identifier hs-type">shape'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-108"></span><span id="local-6989586621679521378"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679521378"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span id="add"><span class="annot"><span class="annottext">add :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; Tensor
     (gradient &lt;|&gt; gradient')
     (layout &lt;+&gt; layout')
     (device &lt;+&gt; device')
     (dataType &lt;+&gt; dataType')
     (BroadcastShapesF shape shape')
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#add"><span class="hs-operator hs-var hs-var">`add`</span></a></span></span><span> </span><span id="local-6989586621679521377"><span class="annot"><span class="annottext">Tensor gradient' layout' device' dataType' shape'
</span><a href="#local-6989586621679521377"><span class="hs-identifier hs-var">other</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO
  (Tensor
     (Or (Gradient RequiresGradient) gradient gradient')
     (Unify (Layout LayoutType) layout layout')
     (Unify (Device (DeviceType Nat)) device device')
     (Unify (DataType DType) dataType dataType')
     (BroadcastShapesF shape shape'))
-&gt; Tensor
     (Or (Gradient RequiresGradient) gradient gradient')
     (Unify (Layout LayoutType) layout layout')
     (Unify (Device (DeviceType Nat)) device device')
     (Unify (DataType DType) dataType dataType')
     (BroadcastShapesF shape shape')
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO
   (Tensor
      (Or (Gradient RequiresGradient) gradient gradient')
      (Unify (Layout LayoutType) layout layout')
      (Unify (Device (DeviceType Nat)) device device')
      (Unify (DataType DType) dataType dataType')
      (BroadcastShapesF shape shape'))
 -&gt; Tensor
      (Or (Gradient RequiresGradient) gradient gradient')
      (Unify (Layout LayoutType) layout layout')
      (Unify (Device (DeviceType Nat)) device device')
      (Unify (DataType DType) dataType dataType')
      (BroadcastShapesF shape shape'))
-&gt; IO
     (Tensor
        (Or (Gradient RequiresGradient) gradient gradient')
        (Unify (Layout LayoutType) layout layout')
        (Unify (Device (DeviceType Nat)) device device')
        (Unify (DataType DType) dataType dataType')
        (BroadcastShapesF shape shape'))
-&gt; Tensor
     (Or (Gradient RequiresGradient) gradient gradient')
     (Unify (Layout LayoutType) layout layout')
     (Unify (Device (DeviceType Nat)) device device')
     (Unify (DataType DType) dataType dataType')
     (BroadcastShapesF shape shape')
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; IO
     (Tensor
        (Or (Gradient RequiresGradient) gradient gradient')
        (Unify (Layout LayoutType) layout layout')
        (Unify (Device (DeviceType Nat)) device device')
        (Unify (DataType DType) dataType dataType')
        (BroadcastShapesF shape shape'))
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.add_tt</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679521378"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient' layout' device' dataType' shape'
</span><a href="#local-6989586621679521377"><span class="hs-identifier hs-var">other</span></a></span><span>
</span><span id="line-109"></span><span>
</span><span id="line-110"></span><span class="hs-comment">-- | Adds a scalar 'other' to a tensor 'input':</span><span>
</span><span id="line-111"></span><span class="hs-comment">-- \[</span><span>
</span><span id="line-112"></span><span class="hs-comment">-- \mathrm{output}_i = \mathrm{input}_i + \mathrm{other}.</span><span>
</span><span id="line-113"></span><span class="hs-comment">-- \]</span><span>
</span><span id="line-114"></span><span class="hs-comment">-- The result is returned as a new tensor.</span><span>
</span><span id="line-115"></span><span class="hs-comment">-- See 'add' for a version of this function where</span><span>
</span><span id="line-116"></span><span class="hs-comment">-- the second argument is a tensor.</span><span>
</span><span id="line-117"></span><span class="hs-comment">--</span><span>
</span><span id="line-118"></span><span class="hs-comment">-- TODO: add data type unification of @other@ and @dataType@.</span><span>
</span><span id="line-119"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#addScalar"><span class="hs-identifier hs-type">addScalar</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-120"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679521374"><span class="annot"><a href="#local-6989586621679521374"><span class="hs-identifier hs-type">other</span></a></span></span><span> </span><span id="local-6989586621679521373"><span class="annot"><a href="#local-6989586621679521373"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679521372"><span class="annot"><a href="#local-6989586621679521372"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679521371"><span class="annot"><a href="#local-6989586621679521371"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679521370"><span class="annot"><a href="#local-6989586621679521370"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679521369"><span class="annot"><a href="#local-6989586621679521369"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-121"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Scalar.html#Scalar"><span class="hs-identifier hs-type">Scalar</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521374"><span class="hs-identifier hs-type">other</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-122"></span><span>  </span><span class="hs-comment">-- | input tensor</span><span>
</span><span id="line-123"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521373"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521372"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521371"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521370"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521369"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-124"></span><span>  </span><span class="hs-comment">-- | input scalar</span><span>
</span><span id="line-125"></span><span>  </span><span class="annot"><a href="#local-6989586621679521374"><span class="hs-identifier hs-type">other</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-126"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-127"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521373"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521372"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521371"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521370"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521369"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-128"></span><span id="local-6989586621679521368"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679521368"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span id="addScalar"><span class="annot"><span class="annottext">addScalar :: Tensor gradient layout device dataType shape
-&gt; other -&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#addScalar"><span class="hs-operator hs-var hs-var">`addScalar`</span></a></span></span><span> </span><span id="local-6989586621679521367"><span class="annot"><span class="annottext">other
</span><a href="#local-6989586621679521367"><span class="hs-identifier hs-var">other</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ForeignPtr Scalar -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; other
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr Scalar -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.add_ts</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679521368"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">other
</span><a href="#local-6989586621679521367"><span class="hs-identifier hs-var">other</span></a></span><span>
</span><span id="line-129"></span><span>
</span><span id="line-130"></span><span class="hs-comment">-- | Performs the element-wise division of 'tensor1' by 'tensor2',</span><span>
</span><span id="line-131"></span><span class="hs-comment">-- multiply the result by a scalar 'value' and add it to 'input':</span><span>
</span><span id="line-132"></span><span class="hs-comment">-- \[</span><span>
</span><span id="line-133"></span><span class="hs-comment">-- \mathrm{output}_i = \mathrm{input}_i + \mathrm{value} \times \frac{\mathrm{tensor1}_i}{\mathrm{tensor2}_i}.</span><span>
</span><span id="line-134"></span><span class="hs-comment">-- \]</span><span>
</span><span id="line-135"></span><span class="hs-comment">--</span><span>
</span><span id="line-136"></span><span class="hs-comment">-- See 'addcmul' for a version of this function where 'tensor1' and 'tensor2'</span><span>
</span><span id="line-137"></span><span class="hs-comment">-- are multiplied rather than divided.</span><span>
</span><span id="line-138"></span><span class="hs-comment">--</span><span>
</span><span id="line-139"></span><span class="hs-comment">-- Note further that for inputs of type 'Float' or 'Double',</span><span>
</span><span id="line-140"></span><span class="hs-comment">-- 'value' must be a real number, otherwise it must be an integer.</span><span>
</span><span id="line-141"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#addcdiv"><span class="hs-identifier hs-type">addcdiv</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-142"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679521364"><span class="annot"><a href="#local-6989586621679521364"><span class="hs-identifier hs-type">value</span></a></span></span><span> </span><span id="local-6989586621679521363"><span class="annot"><a href="#local-6989586621679521363"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679521362"><span class="annot"><a href="#local-6989586621679521362"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679521361"><span class="annot"><a href="#local-6989586621679521361"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679521360"><span class="annot"><a href="#local-6989586621679521360"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679521359"><span class="annot"><a href="#local-6989586621679521359"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-143"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Scalar.html#Scalar"><span class="hs-identifier hs-type">Scalar</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521364"><span class="hs-identifier hs-type">value</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-144"></span><span>  </span><span class="hs-comment">-- | input scalar</span><span>
</span><span id="line-145"></span><span>  </span><span class="annot"><a href="#local-6989586621679521364"><span class="hs-identifier hs-type">value</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-146"></span><span>  </span><span class="hs-comment">-- | first other tensor</span><span>
</span><span id="line-147"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521363"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521362"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521361"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521360"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521359"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-148"></span><span>  </span><span class="hs-comment">-- | second other tensor</span><span>
</span><span id="line-149"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521363"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521362"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521361"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521360"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521359"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-150"></span><span>  </span><span class="hs-comment">-- | input tensor</span><span>
</span><span id="line-151"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521363"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521362"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521361"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521360"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521359"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-152"></span><span>  </span><span class="hs-comment">-- | output tensor</span><span>
</span><span id="line-153"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521363"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521362"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521361"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521360"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521359"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-154"></span><span id="addcdiv"><span class="annot"><span class="annottext">addcdiv :: value
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#addcdiv"><span class="hs-identifier hs-var hs-var">addcdiv</span></a></span></span><span> </span><span id="local-6989586621679521358"><span class="annot"><span class="annottext">value
</span><a href="#local-6989586621679521358"><span class="hs-identifier hs-var">value</span></a></span></span><span> </span><span id="local-6989586621679521357"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679521357"><span class="hs-identifier hs-var">tensor1</span></a></span></span><span> </span><span id="local-6989586621679521356"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679521356"><span class="hs-identifier hs-var">tensor2</span></a></span></span><span> </span><span id="local-6989586621679521355"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679521355"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; ForeignPtr Scalar
 -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
-&gt; value
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca x1 cx1 x2 cx2 x3 cx3 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable x3 cx3,
 Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; cx3 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; x2 -&gt; x3 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast4</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; ForeignPtr Tensor
-&gt; ForeignPtr Tensor
-&gt; ForeignPtr Scalar
-&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.addcdiv_ttts</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679521355"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679521357"><span class="hs-identifier hs-var">tensor1</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679521356"><span class="hs-identifier hs-var">tensor2</span></a></span><span> </span><span class="annot"><span class="annottext">value
</span><a href="#local-6989586621679521358"><span class="hs-identifier hs-var">value</span></a></span><span>
</span><span id="line-155"></span><span>
</span><span id="line-156"></span><span class="hs-comment">-- | Performs the element-wise multiplication of 'tensor1' by 'tensor2',</span><span>
</span><span id="line-157"></span><span class="hs-comment">-- multiply the result by the scalar 'value' and add it to 'input':</span><span>
</span><span id="line-158"></span><span class="hs-comment">-- \[</span><span>
</span><span id="line-159"></span><span class="hs-comment">-- \mathrm{output}_i = \mathrm{input}_i + \mathrm{value} \times \mathrm{tensor1}_i \times \mathrm{tensor2}_i.</span><span>
</span><span id="line-160"></span><span class="hs-comment">-- \]</span><span>
</span><span id="line-161"></span><span class="hs-comment">--</span><span>
</span><span id="line-162"></span><span class="hs-comment">-- See 'addcdiv' for a version of this function where 'tensor1' and 'tensor2'</span><span>
</span><span id="line-163"></span><span class="hs-comment">-- are divided rather than multiplied.</span><span>
</span><span id="line-164"></span><span class="hs-comment">--</span><span>
</span><span id="line-165"></span><span class="hs-comment">-- Note further that for inputs of type 'Float' or 'Double',</span><span>
</span><span id="line-166"></span><span class="hs-comment">-- 'value' must be a real number, otherwise it must be an integer.</span><span>
</span><span id="line-167"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#addcmul"><span class="hs-identifier hs-type">addcmul</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-168"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679521352"><span class="annot"><a href="#local-6989586621679521352"><span class="hs-identifier hs-type">scalar</span></a></span></span><span> </span><span id="local-6989586621679521351"><span class="annot"><a href="#local-6989586621679521351"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679521350"><span class="annot"><a href="#local-6989586621679521350"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679521349"><span class="annot"><a href="#local-6989586621679521349"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679521348"><span class="annot"><a href="#local-6989586621679521348"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679521347"><span class="annot"><a href="#local-6989586621679521347"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-169"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Scalar.html#Scalar"><span class="hs-identifier hs-type">Scalar</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521352"><span class="hs-identifier hs-type">scalar</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-170"></span><span>  </span><span class="hs-comment">-- | input scalar</span><span>
</span><span id="line-171"></span><span>  </span><span class="annot"><a href="#local-6989586621679521352"><span class="hs-identifier hs-type">scalar</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-172"></span><span>  </span><span class="hs-comment">-- | first other tensor</span><span>
</span><span id="line-173"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521351"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521350"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521349"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521348"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521347"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-174"></span><span>  </span><span class="hs-comment">-- | second other tensor</span><span>
</span><span id="line-175"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521351"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521350"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521349"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521348"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521347"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-176"></span><span>  </span><span class="hs-comment">-- | input tensor</span><span>
</span><span id="line-177"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521351"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521350"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521349"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521348"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521347"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-178"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-179"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521351"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521350"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521349"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521348"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521347"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-180"></span><span id="addcmul"><span class="annot"><span class="annottext">addcmul :: scalar
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#addcmul"><span class="hs-identifier hs-var hs-var">addcmul</span></a></span></span><span> </span><span id="local-6989586621679521346"><span class="annot"><span class="annottext">scalar
</span><a href="#local-6989586621679521346"><span class="hs-identifier hs-var">scalar</span></a></span></span><span> </span><span id="local-6989586621679521345"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679521345"><span class="hs-identifier hs-var">tensor1</span></a></span></span><span> </span><span id="local-6989586621679521344"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679521344"><span class="hs-identifier hs-var">tensor2</span></a></span></span><span> </span><span id="local-6989586621679521343"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679521343"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; ForeignPtr Scalar
 -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
-&gt; scalar
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca x1 cx1 x2 cx2 x3 cx3 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable x3 cx3,
 Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; cx3 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; x2 -&gt; x3 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast4</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; ForeignPtr Tensor
-&gt; ForeignPtr Tensor
-&gt; ForeignPtr Scalar
-&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.addcmul_ttts</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679521343"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679521345"><span class="hs-identifier hs-var">tensor1</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679521344"><span class="hs-identifier hs-var">tensor2</span></a></span><span> </span><span class="annot"><span class="annottext">scalar
</span><a href="#local-6989586621679521346"><span class="hs-identifier hs-var">scalar</span></a></span><span>
</span><span id="line-181"></span><span>
</span><span id="line-182"></span><span class="hs-comment">-- | Returns a new tensor with the arcsine of the elements of 'input':</span><span>
</span><span id="line-183"></span><span class="hs-comment">-- \[</span><span>
</span><span id="line-184"></span><span class="hs-comment">-- \mathrm{output}_i = \sin^{-1} \left(\mathrm{input}_i\right).</span><span>
</span><span id="line-185"></span><span class="hs-comment">-- \]</span><span>
</span><span id="line-186"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#asin"><span class="hs-identifier hs-type">asin</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-187"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679521340"><span class="annot"><a href="#local-6989586621679521340"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679521339"><span class="annot"><a href="#local-6989586621679521339"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679521338"><span class="annot"><a href="#local-6989586621679521338"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679521337"><span class="annot"><a href="#local-6989586621679521337"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679521336"><span class="annot"><a href="#local-6989586621679521336"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-188"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-189"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521340"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521339"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521338"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521337"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521336"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-190"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-191"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521340"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521339"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521338"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521337"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521336"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-192"></span><span id="asin"><span class="annot"><span class="annottext">asin :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#asin"><span class="hs-identifier hs-var hs-var">asin</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; (Tensor gradient layout device dataType shape
    -&gt; IO (Tensor gradient layout device dataType shape))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.asin_t</span></a></span><span>
</span><span id="line-193"></span><span>
</span><span id="line-194"></span><span class="hs-comment">-- | Returns a new tensor with the inverse hyperbolic sine of the elements of 'input':</span><span>
</span><span id="line-195"></span><span class="hs-comment">-- \[</span><span>
</span><span id="line-196"></span><span class="hs-comment">-- \mathrm{output}_i = \sinh^{-1} \left(\mathrm{input}_i\right).</span><span>
</span><span id="line-197"></span><span class="hs-comment">-- \]</span><span>
</span><span id="line-198"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#asinh"><span class="hs-identifier hs-type">asinh</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-199"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679521333"><span class="annot"><a href="#local-6989586621679521333"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679521332"><span class="annot"><a href="#local-6989586621679521332"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679521331"><span class="annot"><a href="#local-6989586621679521331"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679521330"><span class="annot"><a href="#local-6989586621679521330"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679521329"><span class="annot"><a href="#local-6989586621679521329"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-200"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-201"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521333"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521332"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521331"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521330"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521329"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-202"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-203"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521333"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521332"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521331"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521330"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521329"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-204"></span><span id="asinh"><span class="annot"><span class="annottext">asinh :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#asinh"><span class="hs-identifier hs-var hs-var">asinh</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; (Tensor gradient layout device dataType shape
    -&gt; IO (Tensor gradient layout device dataType shape))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.asinh_t</span></a></span><span>
</span><span id="line-205"></span><span>
</span><span id="line-206"></span><span class="hs-comment">-- | Returns a new tensor with the arctangent of the elements of 'input':</span><span>
</span><span id="line-207"></span><span class="hs-comment">-- \[</span><span>
</span><span id="line-208"></span><span class="hs-comment">-- \mathrm{output}_i = \tan^{-1} \left(\mathrm{input}_i\right).</span><span>
</span><span id="line-209"></span><span class="hs-comment">-- \]</span><span>
</span><span id="line-210"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#atan"><span class="hs-identifier hs-type">atan</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-211"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679521326"><span class="annot"><a href="#local-6989586621679521326"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679521325"><span class="annot"><a href="#local-6989586621679521325"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679521324"><span class="annot"><a href="#local-6989586621679521324"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679521323"><span class="annot"><a href="#local-6989586621679521323"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679521322"><span class="annot"><a href="#local-6989586621679521322"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-212"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-213"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521326"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521325"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521324"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521323"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521322"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-214"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-215"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521326"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521325"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521324"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521323"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521322"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-216"></span><span id="atan"><span class="annot"><span class="annottext">atan :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#atan"><span class="hs-identifier hs-var hs-var">atan</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; (Tensor gradient layout device dataType shape
    -&gt; IO (Tensor gradient layout device dataType shape))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.atan_t</span></a></span><span>
</span><span id="line-217"></span><span>
</span><span id="line-218"></span><span class="hs-comment">-- | Returns a new tensor with the inverse hyperbolic tangent of the elements of 'input':</span><span>
</span><span id="line-219"></span><span class="hs-comment">-- \[</span><span>
</span><span id="line-220"></span><span class="hs-comment">-- \mathrm{output}_i = \tanh^{-1} \left(\mathrm{input}_i\right).</span><span>
</span><span id="line-221"></span><span class="hs-comment">-- \]</span><span>
</span><span id="line-222"></span><span class="hs-comment">--</span><span>
</span><span id="line-223"></span><span class="hs-comment">-- Note that the domain of the inverse hyperbolic tangent is \((-1, 1)\), and</span><span>
</span><span id="line-224"></span><span class="hs-comment">-- values outside this range will be mapped to \(\mathrm{NaN}\),</span><span>
</span><span id="line-225"></span><span class="hs-comment">-- except for the values \(1\) and \(-1\) for which the output is mapped to</span><span>
</span><span id="line-226"></span><span class="hs-comment">-- \(\pm \infty\) respectively.</span><span>
</span><span id="line-227"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#atanh"><span class="hs-identifier hs-type">atanh</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-228"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679521319"><span class="annot"><a href="#local-6989586621679521319"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679521318"><span class="annot"><a href="#local-6989586621679521318"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679521317"><span class="annot"><a href="#local-6989586621679521317"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679521316"><span class="annot"><a href="#local-6989586621679521316"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679521315"><span class="annot"><a href="#local-6989586621679521315"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-229"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-230"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521319"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521318"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521317"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521316"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521315"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-231"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-232"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521319"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521318"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521317"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521316"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521315"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-233"></span><span id="atanh"><span class="annot"><span class="annottext">atanh :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#atanh"><span class="hs-identifier hs-var hs-var">atanh</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; (Tensor gradient layout device dataType shape
    -&gt; IO (Tensor gradient layout device dataType shape))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.atanh_t</span></a></span><span>
</span><span id="line-234"></span><span>
</span><span id="line-235"></span><span class="hs-comment">-- | Element-wise arctangent of 'input' and 'other' with consideration of the quadrant.</span><span>
</span><span id="line-236"></span><span class="hs-comment">-- Returns a new tensor where each element is the signed angle in radians between</span><span>
</span><span id="line-237"></span><span class="hs-comment">-- the vectors \(\mathrm{other}_i, \mathrm{input}_i)\) and \((1,0)\).</span><span>
</span><span id="line-238"></span><span class="hs-comment">-- Here $\mathrm{other}_i$, the \(i\)-th element of the second argument of this function,</span><span>
</span><span id="line-239"></span><span class="hs-comment">-- is the x coordinate while $\mathrm{input}_i$, the \(i\)-th element of the first argument,</span><span>
</span><span id="line-240"></span><span class="hs-comment">-- is the y coordinate.</span><span>
</span><span id="line-241"></span><span class="hs-comment">--</span><span>
</span><span id="line-242"></span><span class="hs-comment">-- Note that the shapes of 'input' and 'other' must be broadcastable.</span><span>
</span><span id="line-243"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#atan2"><span class="hs-identifier hs-type">atan2</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-244"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679521312"><span class="annot"><a href="#local-6989586621679521312"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679521311"><span class="annot"><a href="#local-6989586621679521311"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679521310"><span class="annot"><a href="#local-6989586621679521310"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679521309"><span class="annot"><a href="#local-6989586621679521309"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679521308"><span class="annot"><a href="#local-6989586621679521308"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679521307"><span class="annot"><a href="#local-6989586621679521307"><span class="hs-identifier hs-type">gradient'</span></a></span></span><span> </span><span id="local-6989586621679521306"><span class="annot"><a href="#local-6989586621679521306"><span class="hs-identifier hs-type">layout'</span></a></span></span><span> </span><span id="local-6989586621679521305"><span class="annot"><a href="#local-6989586621679521305"><span class="hs-identifier hs-type">device'</span></a></span></span><span> </span><span id="local-6989586621679521304"><span class="annot"><a href="#local-6989586621679521304"><span class="hs-identifier hs-type">dataType'</span></a></span></span><span> </span><span id="local-6989586621679521303"><span class="annot"><a href="#local-6989586621679521303"><span class="hs-identifier hs-type">shape'</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-245"></span><span>  </span><span class="hs-comment">-- | input tensor</span><span>
</span><span id="line-246"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521312"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521311"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521310"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521309"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521308"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-247"></span><span>  </span><span class="hs-comment">-- | other input tensor</span><span>
</span><span id="line-248"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521307"><span class="hs-identifier hs-type">gradient'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521306"><span class="hs-identifier hs-type">layout'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521305"><span class="hs-identifier hs-type">device'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521304"><span class="hs-identifier hs-type">dataType'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521303"><span class="hs-identifier hs-type">shape'</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-249"></span><span>  </span><span class="hs-comment">-- | output tensor</span><span>
</span><span id="line-250"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-251"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679521312"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521307"><span class="hs-identifier hs-type">gradient'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-252"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679521311"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521306"><span class="hs-identifier hs-type">layout'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-253"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679521310"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521305"><span class="hs-identifier hs-type">device'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-254"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679521309"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521304"><span class="hs-identifier hs-type">dataType'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-255"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#BroadcastShapesF"><span class="hs-identifier hs-type">BroadcastShapesF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521308"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521303"><span class="hs-identifier hs-type">shape'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-256"></span><span id="atan2"><span class="annot"><span class="annottext">atan2 :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; Tensor
     (gradient &lt;|&gt; gradient')
     (layout &lt;+&gt; layout')
     (device &lt;+&gt; device')
     (dataType &lt;+&gt; dataType')
     (BroadcastShapesF shape shape')
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#atan2"><span class="hs-identifier hs-var hs-var">atan2</span></a></span></span><span> </span><span id="local-6989586621679521302"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679521302"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span id="local-6989586621679521301"><span class="annot"><span class="annottext">Tensor gradient' layout' device' dataType' shape'
</span><a href="#local-6989586621679521301"><span class="hs-identifier hs-var">other</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO
  (Tensor
     (Or (Gradient RequiresGradient) gradient gradient')
     (Unify (Layout LayoutType) layout layout')
     (Unify (Device (DeviceType Nat)) device device')
     (Unify (DataType DType) dataType dataType')
     (BroadcastShapesF shape shape'))
-&gt; Tensor
     (Or (Gradient RequiresGradient) gradient gradient')
     (Unify (Layout LayoutType) layout layout')
     (Unify (Device (DeviceType Nat)) device device')
     (Unify (DataType DType) dataType dataType')
     (BroadcastShapesF shape shape')
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO
   (Tensor
      (Or (Gradient RequiresGradient) gradient gradient')
      (Unify (Layout LayoutType) layout layout')
      (Unify (Device (DeviceType Nat)) device device')
      (Unify (DataType DType) dataType dataType')
      (BroadcastShapesF shape shape'))
 -&gt; Tensor
      (Or (Gradient RequiresGradient) gradient gradient')
      (Unify (Layout LayoutType) layout layout')
      (Unify (Device (DeviceType Nat)) device device')
      (Unify (DataType DType) dataType dataType')
      (BroadcastShapesF shape shape'))
-&gt; IO
     (Tensor
        (Or (Gradient RequiresGradient) gradient gradient')
        (Unify (Layout LayoutType) layout layout')
        (Unify (Device (DeviceType Nat)) device device')
        (Unify (DataType DType) dataType dataType')
        (BroadcastShapesF shape shape'))
-&gt; Tensor
     (Or (Gradient RequiresGradient) gradient gradient')
     (Unify (Layout LayoutType) layout layout')
     (Unify (Device (DeviceType Nat)) device device')
     (Unify (DataType DType) dataType dataType')
     (BroadcastShapesF shape shape')
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; IO
     (Tensor
        (Or (Gradient RequiresGradient) gradient gradient')
        (Unify (Layout LayoutType) layout layout')
        (Unify (Device (DeviceType Nat)) device device')
        (Unify (DataType DType) dataType dataType')
        (BroadcastShapesF shape shape'))
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.atan2_tt</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679521302"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient' layout' device' dataType' shape'
</span><a href="#local-6989586621679521301"><span class="hs-identifier hs-var">other</span></a></span><span>
</span><span id="line-257"></span><span>
</span><span id="line-258"></span><span class="hs-comment">-- | Computes the bitwise NOT of the given 'input' tensor.</span><span>
</span><span id="line-259"></span><span class="hs-comment">-- The data type of the 'input' tensor must be 'Bool' or an integral data type.</span><span>
</span><span id="line-260"></span><span class="hs-comment">-- For 'Bool' tensors, the function computes the logical NOT.</span><span>
</span><span id="line-261"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#bitwiseNot"><span class="hs-identifier hs-type">bitwiseNot</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-262"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679521298"><span class="annot"><a href="#local-6989586621679521298"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679521297"><span class="annot"><a href="#local-6989586621679521297"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679521296"><span class="annot"><a href="#local-6989586621679521296"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679521295"><span class="annot"><a href="#local-6989586621679521295"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679521294"><span class="annot"><a href="#local-6989586621679521294"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-263"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-264"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521298"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521297"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521296"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521295"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521294"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-265"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-266"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521298"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521297"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521296"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#Bool"><span class="hs-identifier hs-type">Bool</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679521294"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-267"></span><span id="bitwiseNot"><span class="annot"><span class="annottext">bitwiseNot :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device ('DataType 'Bool) shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#bitwiseNot"><span class="hs-identifier hs-var hs-var">bitwiseNot</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device ('DataType 'Bool) shape)
-&gt; Tensor gradient layout device ('DataType 'Bool) shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device ('DataType 'Bool) shape)
 -&gt; Tensor gradient layout device ('DataType 'Bool) shape)
-&gt; (Tensor gradient layout device dataType shape
    -&gt; IO (Tensor gradient layout device ('DataType 'Bool) shape))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device ('DataType 'Bool) shape
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; IO (Tensor gradient layout device ('DataType 'Bool) shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.bitwise_not_t</span></a></span><span>
</span><span id="line-268"></span><span>
</span><span id="line-269"></span><span class="hs-comment">-- | Computes the bitwise AND of the 'input' and the 'other' tensor.</span><span>
</span><span id="line-270"></span><span class="hs-comment">-- The data type of the tensors must be 'Bool' or an integral data type.</span><span>
</span><span id="line-271"></span><span class="hs-comment">-- For 'Bool' tensors, the function computes the logical AND.</span><span>
</span><span id="line-272"></span><span class="hs-comment">--</span><span>
</span><span id="line-273"></span><span class="hs-comment">-- See 'bitwiseAndScalar' for a version of this function where 'other'</span><span>
</span><span id="line-274"></span><span class="hs-comment">-- is a scalar.</span><span>
</span><span id="line-275"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#bitwiseAnd"><span class="hs-identifier hs-type">bitwiseAnd</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-276"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679521291"><span class="annot"><a href="#local-6989586621679521291"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679521290"><span class="annot"><a href="#local-6989586621679521290"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679521289"><span class="annot"><a href="#local-6989586621679521289"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679521288"><span class="annot"><a href="#local-6989586621679521288"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679521287"><span class="annot"><a href="#local-6989586621679521287"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-277"></span><span>  </span><span class="hs-comment">-- | input tensor</span><span>
</span><span id="line-278"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521291"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521290"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521289"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521288"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521287"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-279"></span><span>  </span><span class="hs-comment">-- | other tensor</span><span>
</span><span id="line-280"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521291"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521290"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521289"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521288"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521287"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-281"></span><span>  </span><span class="hs-comment">-- | output tensor</span><span>
</span><span id="line-282"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521291"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521290"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521289"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521288"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521287"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-283"></span><span id="local-6989586621679521286"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679521286"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span id="bitwiseAnd"><span class="annot"><span class="annottext">bitwiseAnd :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#bitwiseAnd"><span class="hs-operator hs-var hs-var">`bitwiseAnd`</span></a></span></span><span> </span><span id="local-6989586621679521285"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679521285"><span class="hs-identifier hs-var">other</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.bitwise_and_tt</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679521286"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679521285"><span class="hs-identifier hs-var">other</span></a></span><span>
</span><span id="line-284"></span><span>
</span><span id="line-285"></span><span class="hs-comment">-- | Computes the bitwise AND of the tensor 'input' and the scalar 'other'.</span><span>
</span><span id="line-286"></span><span class="hs-comment">-- The data type of the inputs must be 'Bool' or an integral data type.</span><span>
</span><span id="line-287"></span><span class="hs-comment">-- If the data type is 'Bool', then the function computes the logical AND.</span><span>
</span><span id="line-288"></span><span class="hs-comment">--</span><span>
</span><span id="line-289"></span><span class="hs-comment">-- See 'bitwiseAnd' for a version of this function where 'other'</span><span>
</span><span id="line-290"></span><span class="hs-comment">-- is a tensor.</span><span>
</span><span id="line-291"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#bitwiseAndScalar"><span class="hs-identifier hs-type">bitwiseAndScalar</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-292"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679521282"><span class="annot"><a href="#local-6989586621679521282"><span class="hs-identifier hs-type">other</span></a></span></span><span> </span><span id="local-6989586621679521281"><span class="annot"><a href="#local-6989586621679521281"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679521280"><span class="annot"><a href="#local-6989586621679521280"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679521279"><span class="annot"><a href="#local-6989586621679521279"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679521278"><span class="annot"><a href="#local-6989586621679521278"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679521277"><span class="annot"><a href="#local-6989586621679521277"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-293"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Scalar.html#Scalar"><span class="hs-identifier hs-type">Scalar</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521282"><span class="hs-identifier hs-type">other</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-294"></span><span>  </span><span class="hs-comment">-- | input tensor</span><span>
</span><span id="line-295"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521281"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521280"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521279"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521278"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521277"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-296"></span><span>  </span><span class="hs-comment">-- | other scalar</span><span>
</span><span id="line-297"></span><span>  </span><span class="annot"><a href="#local-6989586621679521282"><span class="hs-identifier hs-type">other</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-298"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-299"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521281"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521280"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521279"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521278"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521277"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-300"></span><span id="local-6989586621679521276"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679521276"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span id="bitwiseAndScalar"><span class="annot"><span class="annottext">bitwiseAndScalar :: Tensor gradient layout device dataType shape
-&gt; other -&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#bitwiseAndScalar"><span class="hs-operator hs-var hs-var">`bitwiseAndScalar`</span></a></span></span><span> </span><span id="local-6989586621679521275"><span class="annot"><span class="annottext">other
</span><a href="#local-6989586621679521275"><span class="hs-identifier hs-var">other</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ForeignPtr Scalar -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; other
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr Scalar -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.bitwise_and_ts</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679521276"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">other
</span><a href="#local-6989586621679521275"><span class="hs-identifier hs-var">other</span></a></span><span>
</span><span id="line-301"></span><span>
</span><span id="line-302"></span><span class="hs-comment">-- | Computes the bitwise OR of the 'input' and the 'other' tensor.</span><span>
</span><span id="line-303"></span><span class="hs-comment">-- The data type of the tensors must be 'Bool' or an integral data type.</span><span>
</span><span id="line-304"></span><span class="hs-comment">-- For 'Bool' tensors, the function computes the logical OR.</span><span>
</span><span id="line-305"></span><span class="hs-comment">--</span><span>
</span><span id="line-306"></span><span class="hs-comment">-- See 'bitwiseOrScalar' for a version of this function where 'other'</span><span>
</span><span id="line-307"></span><span class="hs-comment">-- is a scalar.</span><span>
</span><span id="line-308"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#bitwiseOr"><span class="hs-identifier hs-type">bitwiseOr</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-309"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679521272"><span class="annot"><a href="#local-6989586621679521272"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679521271"><span class="annot"><a href="#local-6989586621679521271"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679521270"><span class="annot"><a href="#local-6989586621679521270"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679521269"><span class="annot"><a href="#local-6989586621679521269"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679521268"><span class="annot"><a href="#local-6989586621679521268"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-310"></span><span>  </span><span class="hs-comment">-- | input tensor</span><span>
</span><span id="line-311"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521272"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521271"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521270"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521269"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521268"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-312"></span><span>  </span><span class="hs-comment">-- | other tensor</span><span>
</span><span id="line-313"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521272"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521271"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521270"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521269"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521268"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-314"></span><span>  </span><span class="hs-comment">-- | output tensor</span><span>
</span><span id="line-315"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521272"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521271"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521270"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521269"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521268"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-316"></span><span id="local-6989586621679521267"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679521267"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span id="bitwiseOr"><span class="annot"><span class="annottext">bitwiseOr :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#bitwiseOr"><span class="hs-operator hs-var hs-var">`bitwiseOr`</span></a></span></span><span> </span><span id="local-6989586621679521266"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679521266"><span class="hs-identifier hs-var">other</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.bitwise_or_tt</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679521267"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679521266"><span class="hs-identifier hs-var">other</span></a></span><span>
</span><span id="line-317"></span><span>
</span><span id="line-318"></span><span class="hs-comment">-- | Computes the bitwise OR of the tensor 'input' and the scalar 'other'.</span><span>
</span><span id="line-319"></span><span class="hs-comment">-- The data type of the inputs must be 'Bool' or an integral data type.</span><span>
</span><span id="line-320"></span><span class="hs-comment">-- If the data type is 'Bool', then the function computes the logical OR.</span><span>
</span><span id="line-321"></span><span class="hs-comment">--</span><span>
</span><span id="line-322"></span><span class="hs-comment">-- See 'bitwiseOr' for a version of this function where 'other'</span><span>
</span><span id="line-323"></span><span class="hs-comment">-- is a tensor.</span><span>
</span><span id="line-324"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#bitwiseOrScalar"><span class="hs-identifier hs-type">bitwiseOrScalar</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-325"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679521263"><span class="annot"><a href="#local-6989586621679521263"><span class="hs-identifier hs-type">other</span></a></span></span><span> </span><span id="local-6989586621679521262"><span class="annot"><a href="#local-6989586621679521262"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679521261"><span class="annot"><a href="#local-6989586621679521261"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679521260"><span class="annot"><a href="#local-6989586621679521260"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679521259"><span class="annot"><a href="#local-6989586621679521259"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679521258"><span class="annot"><a href="#local-6989586621679521258"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-326"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Scalar.html#Scalar"><span class="hs-identifier hs-type">Scalar</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521263"><span class="hs-identifier hs-type">other</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-327"></span><span>  </span><span class="hs-comment">-- | input tensor</span><span>
</span><span id="line-328"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521262"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521261"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521260"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521259"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521258"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-329"></span><span>  </span><span class="hs-comment">-- | other scalar</span><span>
</span><span id="line-330"></span><span>  </span><span class="annot"><a href="#local-6989586621679521263"><span class="hs-identifier hs-type">other</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-331"></span><span>  </span><span class="hs-comment">-- | output tensor</span><span>
</span><span id="line-332"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521262"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521261"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521260"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521259"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521258"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-333"></span><span id="local-6989586621679521257"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679521257"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span id="bitwiseOrScalar"><span class="annot"><span class="annottext">bitwiseOrScalar :: Tensor gradient layout device dataType shape
-&gt; other -&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#bitwiseOrScalar"><span class="hs-operator hs-var hs-var">`bitwiseOrScalar`</span></a></span></span><span> </span><span id="local-6989586621679521256"><span class="annot"><span class="annottext">other
</span><a href="#local-6989586621679521256"><span class="hs-identifier hs-var">other</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ForeignPtr Scalar -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; other
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr Scalar -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.bitwise_or_ts</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679521257"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">other
</span><a href="#local-6989586621679521256"><span class="hs-identifier hs-var">other</span></a></span><span>
</span><span id="line-334"></span><span>
</span><span id="line-335"></span><span class="hs-comment">-- | Computes the bitwise XOR of the 'input' and the 'other' tensor.</span><span>
</span><span id="line-336"></span><span class="hs-comment">-- The data type of the tensors must be 'Bool' or an integral data type.</span><span>
</span><span id="line-337"></span><span class="hs-comment">-- For 'Bool' tensors, the function computes the logical XOR.</span><span>
</span><span id="line-338"></span><span class="hs-comment">--</span><span>
</span><span id="line-339"></span><span class="hs-comment">-- See 'bitwiseXorScalar' for a version of this function where 'other'</span><span>
</span><span id="line-340"></span><span class="hs-comment">-- is a scalar.</span><span>
</span><span id="line-341"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#bitwiseXor"><span class="hs-identifier hs-type">bitwiseXor</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-342"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679521253"><span class="annot"><a href="#local-6989586621679521253"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679521252"><span class="annot"><a href="#local-6989586621679521252"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679521251"><span class="annot"><a href="#local-6989586621679521251"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679521250"><span class="annot"><a href="#local-6989586621679521250"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679521249"><span class="annot"><a href="#local-6989586621679521249"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-343"></span><span>  </span><span class="hs-comment">-- | input tensor</span><span>
</span><span id="line-344"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521253"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521252"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521251"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521250"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521249"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-345"></span><span>  </span><span class="hs-comment">-- | other tensor</span><span>
</span><span id="line-346"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521253"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521252"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521251"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521250"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521249"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-347"></span><span>  </span><span class="hs-comment">-- | output tensor</span><span>
</span><span id="line-348"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521253"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521252"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521251"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521250"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521249"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-349"></span><span id="local-6989586621679521248"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679521248"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span id="bitwiseXor"><span class="annot"><span class="annottext">bitwiseXor :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#bitwiseXor"><span class="hs-operator hs-var hs-var">`bitwiseXor`</span></a></span></span><span> </span><span id="local-6989586621679521247"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679521247"><span class="hs-identifier hs-var">other</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.bitwise_xor_tt</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679521248"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679521247"><span class="hs-identifier hs-var">other</span></a></span><span>
</span><span id="line-350"></span><span>
</span><span id="line-351"></span><span class="hs-comment">-- | Computes the bitwise XOR of the tensor 'input' and the scalar 'other'.</span><span>
</span><span id="line-352"></span><span class="hs-comment">-- The data type of the inputs must be 'Bool' or an integral data type.</span><span>
</span><span id="line-353"></span><span class="hs-comment">-- If the data type is 'Bool', then the function computes the logical XOR.</span><span>
</span><span id="line-354"></span><span class="hs-comment">--</span><span>
</span><span id="line-355"></span><span class="hs-comment">-- See 'bitwiseXor' for a version of this function where 'other'</span><span>
</span><span id="line-356"></span><span class="hs-comment">-- is a tensor.</span><span>
</span><span id="line-357"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#bitwiseXorScalar"><span class="hs-identifier hs-type">bitwiseXorScalar</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-358"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679521244"><span class="annot"><a href="#local-6989586621679521244"><span class="hs-identifier hs-type">other</span></a></span></span><span> </span><span id="local-6989586621679521243"><span class="annot"><a href="#local-6989586621679521243"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679521242"><span class="annot"><a href="#local-6989586621679521242"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679521241"><span class="annot"><a href="#local-6989586621679521241"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679521240"><span class="annot"><a href="#local-6989586621679521240"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679521239"><span class="annot"><a href="#local-6989586621679521239"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-359"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Scalar.html#Scalar"><span class="hs-identifier hs-type">Scalar</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521244"><span class="hs-identifier hs-type">other</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-360"></span><span>  </span><span class="hs-comment">-- | input tensor</span><span>
</span><span id="line-361"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521243"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521242"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521241"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521240"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521239"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-362"></span><span>  </span><span class="hs-comment">-- | other scalar</span><span>
</span><span id="line-363"></span><span>  </span><span class="annot"><a href="#local-6989586621679521244"><span class="hs-identifier hs-type">other</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-364"></span><span>  </span><span class="hs-comment">-- | output tensor</span><span>
</span><span id="line-365"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521243"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521242"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521241"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521240"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521239"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-366"></span><span id="local-6989586621679521238"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679521238"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span id="bitwiseXorScalar"><span class="annot"><span class="annottext">bitwiseXorScalar :: Tensor gradient layout device dataType shape
-&gt; other -&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#bitwiseXorScalar"><span class="hs-operator hs-var hs-var">`bitwiseXorScalar`</span></a></span></span><span> </span><span id="local-6989586621679521237"><span class="annot"><span class="annottext">other
</span><a href="#local-6989586621679521237"><span class="hs-identifier hs-var">other</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ForeignPtr Scalar -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; other
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr Scalar -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.bitwise_xor_ts</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679521238"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">other
</span><a href="#local-6989586621679521237"><span class="hs-identifier hs-var">other</span></a></span><span>
</span><span id="line-367"></span><span>
</span><span id="line-368"></span><span class="hs-comment">-- | Returns a new tensor with the ceil of the elements of 'input',</span><span>
</span><span id="line-369"></span><span class="hs-comment">-- that is, the smallest integer greater than or equal to each element:</span><span>
</span><span id="line-370"></span><span class="hs-comment">-- \[</span><span>
</span><span id="line-371"></span><span class="hs-comment">-- \mathrm{output}_i = \lceil\mathrm{input}_i\rceil = \lfloor\mathrm{input}_i\rfloor + 1,</span><span>
</span><span id="line-372"></span><span class="hs-comment">-- \]</span><span>
</span><span id="line-373"></span><span class="hs-comment">-- where \(\lfloor\mathrm{input}_i\rfloor\) is the floor of the \(i\)-th element of 'input'</span><span>
</span><span id="line-374"></span><span class="hs-comment">-- which can be computed with 'floor'.</span><span>
</span><span id="line-375"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#ceil"><span class="hs-identifier hs-type">ceil</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-376"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679521234"><span class="annot"><a href="#local-6989586621679521234"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679521233"><span class="annot"><a href="#local-6989586621679521233"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679521232"><span class="annot"><a href="#local-6989586621679521232"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679521231"><span class="annot"><a href="#local-6989586621679521231"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679521230"><span class="annot"><a href="#local-6989586621679521230"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-377"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-378"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521234"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521233"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521232"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521231"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521230"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-379"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-380"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521234"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521233"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521232"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521231"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521230"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-381"></span><span id="ceil"><span class="annot"><span class="annottext">ceil :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#ceil"><span class="hs-identifier hs-var hs-var">ceil</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; (Tensor gradient layout device dataType shape
    -&gt; IO (Tensor gradient layout device dataType shape))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.ceil_t</span></a></span><span>
</span><span id="line-382"></span><span>
</span><span id="line-383"></span><span class="hs-comment">-- | Clamp all elements in input into the range [ min, max ]</span><span>
</span><span id="line-384"></span><span class="hs-comment">-- and return the result as a new tensor.</span><span>
</span><span id="line-385"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#clamp"><span class="hs-identifier hs-type">clamp</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-386"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679521227"><span class="annot"><a href="#local-6989586621679521227"><span class="hs-identifier hs-type">min</span></a></span></span><span> </span><span id="local-6989586621679521226"><span class="annot"><a href="#local-6989586621679521226"><span class="hs-identifier hs-type">max</span></a></span></span><span> </span><span id="local-6989586621679521225"><span class="annot"><a href="#local-6989586621679521225"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679521224"><span class="annot"><a href="#local-6989586621679521224"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679521223"><span class="annot"><a href="#local-6989586621679521223"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679521222"><span class="annot"><a href="#local-6989586621679521222"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679521221"><span class="annot"><a href="#local-6989586621679521221"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-387"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Scalar.html#Scalar"><span class="hs-identifier hs-type">Scalar</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521227"><span class="hs-identifier hs-type">min</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Scalar.html#Scalar"><span class="hs-identifier hs-type">Scalar</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521226"><span class="hs-identifier hs-type">max</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-388"></span><span>  </span><span class="hs-comment">-- | min</span><span>
</span><span id="line-389"></span><span>  </span><span class="annot"><a href="#local-6989586621679521227"><span class="hs-identifier hs-type">min</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-390"></span><span>  </span><span class="hs-comment">-- | max</span><span>
</span><span id="line-391"></span><span>  </span><span class="annot"><a href="#local-6989586621679521226"><span class="hs-identifier hs-type">max</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-392"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-393"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521225"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521224"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521223"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521222"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521221"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-394"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-395"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521225"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521224"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521223"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521222"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521221"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-396"></span><span id="clamp"><span class="annot"><span class="annottext">clamp :: min
-&gt; max
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#clamp"><span class="hs-identifier hs-var hs-var">clamp</span></a></span></span><span> </span><span id="local-6989586621679521220"><span class="annot"><span class="annottext">min
</span><a href="#local-6989586621679521220"><span class="hs-identifier hs-var">min'</span></a></span></span><span> </span><span id="local-6989586621679521219"><span class="annot"><span class="annottext">max
</span><a href="#local-6989586621679521219"><span class="hs-identifier hs-var">max'</span></a></span></span><span> </span><span id="local-6989586621679521218"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679521218"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr Scalar
 -&gt; ForeignPtr Scalar
 -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; min
-&gt; max
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca x1 cx1 x2 cx2 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; x2 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast3</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; ForeignPtr Scalar -&gt; ForeignPtr Scalar -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.clamp__tss</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679521218"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">min
</span><a href="#local-6989586621679521220"><span class="hs-identifier hs-var">min'</span></a></span><span> </span><span class="annot"><span class="annottext">max
</span><a href="#local-6989586621679521219"><span class="hs-identifier hs-var">max'</span></a></span><span>
</span><span id="line-397"></span><span>
</span><span id="line-398"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#cos"><span class="hs-identifier hs-type">cos</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-399"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679521215"><span class="annot"><a href="#local-6989586621679521215"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679521214"><span class="annot"><a href="#local-6989586621679521214"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679521213"><span class="annot"><a href="#local-6989586621679521213"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679521212"><span class="annot"><a href="#local-6989586621679521212"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679521211"><span class="annot"><a href="#local-6989586621679521211"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-400"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-401"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521215"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521214"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521213"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521212"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521211"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-402"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-403"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521215"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521214"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521213"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521212"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521211"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-404"></span><span id="cos"><span class="annot"><span class="annottext">cos :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#cos"><span class="hs-identifier hs-var hs-var">cos</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; (Tensor gradient layout device dataType shape
    -&gt; IO (Tensor gradient layout device dataType shape))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cos_t</span></a></span><span>
</span><span id="line-405"></span><span>
</span><span id="line-406"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#cosh"><span class="hs-identifier hs-type">cosh</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-407"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679521208"><span class="annot"><a href="#local-6989586621679521208"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679521207"><span class="annot"><a href="#local-6989586621679521207"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679521206"><span class="annot"><a href="#local-6989586621679521206"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679521205"><span class="annot"><a href="#local-6989586621679521205"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679521204"><span class="annot"><a href="#local-6989586621679521204"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-408"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-409"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521208"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521207"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521206"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521205"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521204"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-410"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-411"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521208"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521207"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521206"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521205"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521204"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-412"></span><span id="cosh"><span class="annot"><span class="annottext">cosh :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#cosh"><span class="hs-identifier hs-var hs-var">cosh</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; (Tensor gradient layout device dataType shape
    -&gt; IO (Tensor gradient layout device dataType shape))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cosh_t</span></a></span><span>
</span><span id="line-413"></span><span>
</span><span id="line-414"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#deg2rad"><span class="hs-identifier hs-type">deg2rad</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-415"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679521201"><span class="annot"><a href="#local-6989586621679521201"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679521200"><span class="annot"><a href="#local-6989586621679521200"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679521199"><span class="annot"><a href="#local-6989586621679521199"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679521198"><span class="annot"><a href="#local-6989586621679521198"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679521197"><span class="annot"><a href="#local-6989586621679521197"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-416"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-417"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521201"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521200"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521199"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521198"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521197"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-418"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-419"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521201"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521200"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521199"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521198"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521197"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-420"></span><span id="deg2rad"><span class="annot"><span class="annottext">deg2rad :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#deg2rad"><span class="hs-identifier hs-var hs-var">deg2rad</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; (Tensor gradient layout device dataType shape
    -&gt; IO (Tensor gradient layout device dataType shape))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.deg2rad_t</span></a></span><span>
</span><span id="line-421"></span><span>
</span><span id="line-422"></span><span class="hs-comment">-- | Element-wise division of the first input tensor, the 'dividend',</span><span>
</span><span id="line-423"></span><span class="hs-comment">-- by the second input tensor, the 'divisor'.</span><span>
</span><span id="line-424"></span><span class="hs-comment">-- \[</span><span>
</span><span id="line-425"></span><span class="hs-comment">-- \mathrm{output}_i = \frac{dividend_i}{divisor_i}</span><span>
</span><span id="line-426"></span><span class="hs-comment">-- \]</span><span>
</span><span id="line-427"></span><span class="hs-comment">-- The result is returned as a new tensor.</span><span>
</span><span id="line-428"></span><span class="hs-comment">--</span><span>
</span><span id="line-429"></span><span class="hs-comment">-- See 'divScalar' for a version of this function where</span><span>
</span><span id="line-430"></span><span class="hs-comment">-- the 'divisor' is a scalar.</span><span>
</span><span id="line-431"></span><span class="hs-comment">--</span><span>
</span><span id="line-432"></span><span class="hs-comment">-- Note further that &quot;true divisions&quot; can be computed with</span><span>
</span><span id="line-433"></span><span class="hs-comment">-- 'trueDivide' or 'trueDivideScalar' which can come in handy</span><span>
</span><span id="line-434"></span><span class="hs-comment">-- when both the 'dividend' and the 'divisor' have 'Bool' or integer data types.</span><span>
</span><span id="line-435"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#div"><span class="hs-identifier hs-type">div</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-436"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679521194"><span class="annot"><a href="#local-6989586621679521194"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679521193"><span class="annot"><a href="#local-6989586621679521193"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679521192"><span class="annot"><a href="#local-6989586621679521192"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679521191"><span class="annot"><a href="#local-6989586621679521191"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679521190"><span class="annot"><a href="#local-6989586621679521190"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679521189"><span class="annot"><a href="#local-6989586621679521189"><span class="hs-identifier hs-type">gradient'</span></a></span></span><span> </span><span id="local-6989586621679521188"><span class="annot"><a href="#local-6989586621679521188"><span class="hs-identifier hs-type">layout'</span></a></span></span><span> </span><span id="local-6989586621679521187"><span class="annot"><a href="#local-6989586621679521187"><span class="hs-identifier hs-type">device'</span></a></span></span><span> </span><span id="local-6989586621679521186"><span class="annot"><a href="#local-6989586621679521186"><span class="hs-identifier hs-type">dataType'</span></a></span></span><span> </span><span id="local-6989586621679521185"><span class="annot"><a href="#local-6989586621679521185"><span class="hs-identifier hs-type">shape'</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-437"></span><span>  </span><span class="hs-comment">-- | tensor dividend</span><span>
</span><span id="line-438"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521194"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521193"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521192"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521191"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521190"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-439"></span><span>  </span><span class="hs-comment">-- | tensor divisor</span><span>
</span><span id="line-440"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521189"><span class="hs-identifier hs-type">gradient'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521188"><span class="hs-identifier hs-type">layout'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521187"><span class="hs-identifier hs-type">device'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521186"><span class="hs-identifier hs-type">dataType'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521185"><span class="hs-identifier hs-type">shape'</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-441"></span><span>  </span><span class="hs-comment">-- | tensor output</span><span>
</span><span id="line-442"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-443"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679521194"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521189"><span class="hs-identifier hs-type">gradient'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-444"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679521193"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521188"><span class="hs-identifier hs-type">layout'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-445"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679521192"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521187"><span class="hs-identifier hs-type">device'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-446"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679521191"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521186"><span class="hs-identifier hs-type">dataType'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-447"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#BroadcastShapesF"><span class="hs-identifier hs-type">BroadcastShapesF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521190"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521185"><span class="hs-identifier hs-type">shape'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-448"></span><span id="local-6989586621679521184"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679521184"><span class="hs-identifier hs-var">dividend</span></a></span></span><span> </span><span id="div"><span class="annot"><span class="annottext">div :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; Tensor
     (gradient &lt;|&gt; gradient')
     (layout &lt;+&gt; layout')
     (device &lt;+&gt; device')
     (dataType &lt;+&gt; dataType')
     (BroadcastShapesF shape shape')
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#div"><span class="hs-operator hs-var hs-var">`div`</span></a></span></span><span> </span><span id="local-6989586621679521183"><span class="annot"><span class="annottext">Tensor gradient' layout' device' dataType' shape'
</span><a href="#local-6989586621679521183"><span class="hs-identifier hs-var">divisor</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO
  (Tensor
     (Or (Gradient RequiresGradient) gradient gradient')
     (Unify (Layout LayoutType) layout layout')
     (Unify (Device (DeviceType Nat)) device device')
     (Unify (DataType DType) dataType dataType')
     (BroadcastShapesF shape shape'))
-&gt; Tensor
     (Or (Gradient RequiresGradient) gradient gradient')
     (Unify (Layout LayoutType) layout layout')
     (Unify (Device (DeviceType Nat)) device device')
     (Unify (DataType DType) dataType dataType')
     (BroadcastShapesF shape shape')
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO
   (Tensor
      (Or (Gradient RequiresGradient) gradient gradient')
      (Unify (Layout LayoutType) layout layout')
      (Unify (Device (DeviceType Nat)) device device')
      (Unify (DataType DType) dataType dataType')
      (BroadcastShapesF shape shape'))
 -&gt; Tensor
      (Or (Gradient RequiresGradient) gradient gradient')
      (Unify (Layout LayoutType) layout layout')
      (Unify (Device (DeviceType Nat)) device device')
      (Unify (DataType DType) dataType dataType')
      (BroadcastShapesF shape shape'))
-&gt; IO
     (Tensor
        (Or (Gradient RequiresGradient) gradient gradient')
        (Unify (Layout LayoutType) layout layout')
        (Unify (Device (DeviceType Nat)) device device')
        (Unify (DataType DType) dataType dataType')
        (BroadcastShapesF shape shape'))
-&gt; Tensor
     (Or (Gradient RequiresGradient) gradient gradient')
     (Unify (Layout LayoutType) layout layout')
     (Unify (Device (DeviceType Nat)) device device')
     (Unify (DataType DType) dataType dataType')
     (BroadcastShapesF shape shape')
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; IO
     (Tensor
        (Or (Gradient RequiresGradient) gradient gradient')
        (Unify (Layout LayoutType) layout layout')
        (Unify (Device (DeviceType Nat)) device device')
        (Unify (DataType DType) dataType dataType')
        (BroadcastShapesF shape shape'))
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.div_tt</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679521184"><span class="hs-identifier hs-var">dividend</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient' layout' device' dataType' shape'
</span><a href="#local-6989586621679521183"><span class="hs-identifier hs-var">divisor</span></a></span><span>
</span><span id="line-449"></span><span>
</span><span id="line-450"></span><span class="hs-comment">-- | Element-wise division of the first input, the 'dividend' tensor,</span><span>
</span><span id="line-451"></span><span class="hs-comment">-- by the second input, the 'divisor' scalar.</span><span>
</span><span id="line-452"></span><span class="hs-comment">-- \[</span><span>
</span><span id="line-453"></span><span class="hs-comment">-- \mathrm{output}_i = \frac{dividend_i}{divisor}</span><span>
</span><span id="line-454"></span><span class="hs-comment">-- \]</span><span>
</span><span id="line-455"></span><span class="hs-comment">-- The result is returned as a new tensor.</span><span>
</span><span id="line-456"></span><span class="hs-comment">--</span><span>
</span><span id="line-457"></span><span class="hs-comment">-- See 'div' for a version of this function where</span><span>
</span><span id="line-458"></span><span class="hs-comment">-- the divisor is a tensor.</span><span>
</span><span id="line-459"></span><span class="hs-comment">--</span><span>
</span><span id="line-460"></span><span class="hs-comment">-- Note further that &quot;true divisions&quot; can be computed with</span><span>
</span><span id="line-461"></span><span class="hs-comment">-- 'trueDivide' or 'trueDivideScalar' which can come in handy</span><span>
</span><span id="line-462"></span><span class="hs-comment">-- when both the dividend and the divisor have 'Bool' or integer data types.</span><span>
</span><span id="line-463"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#divScalar"><span class="hs-identifier hs-type">divScalar</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-464"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679521180"><span class="annot"><a href="#local-6989586621679521180"><span class="hs-identifier hs-type">divisor</span></a></span></span><span> </span><span id="local-6989586621679521179"><span class="annot"><a href="#local-6989586621679521179"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679521178"><span class="annot"><a href="#local-6989586621679521178"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679521177"><span class="annot"><a href="#local-6989586621679521177"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679521176"><span class="annot"><a href="#local-6989586621679521176"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679521175"><span class="annot"><a href="#local-6989586621679521175"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-465"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Scalar.html#Scalar"><span class="hs-identifier hs-type">Scalar</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521180"><span class="hs-identifier hs-type">divisor</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-466"></span><span>  </span><span class="hs-comment">-- | tensor dividend</span><span>
</span><span id="line-467"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521179"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521178"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521177"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521176"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521175"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-468"></span><span>  </span><span class="hs-comment">-- | scalar divisor</span><span>
</span><span id="line-469"></span><span>  </span><span class="annot"><a href="#local-6989586621679521180"><span class="hs-identifier hs-type">divisor</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-470"></span><span>  </span><span class="hs-comment">-- | tensor output</span><span>
</span><span id="line-471"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521179"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521178"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521177"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521176"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521175"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-472"></span><span id="local-6989586621679521174"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679521174"><span class="hs-identifier hs-var">dividend</span></a></span></span><span> </span><span id="divScalar"><span class="annot"><span class="annottext">divScalar :: Tensor gradient layout device dataType shape
-&gt; divisor -&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#divScalar"><span class="hs-operator hs-var hs-var">`divScalar`</span></a></span></span><span> </span><span id="local-6989586621679521173"><span class="annot"><span class="annottext">divisor
</span><a href="#local-6989586621679521173"><span class="hs-identifier hs-var">divisor</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ForeignPtr Scalar -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; divisor
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr Scalar -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.div_ts</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679521174"><span class="hs-identifier hs-var">dividend</span></a></span><span> </span><span class="annot"><span class="annottext">divisor
</span><a href="#local-6989586621679521173"><span class="hs-identifier hs-var">divisor</span></a></span><span>
</span><span id="line-473"></span><span>
</span><span id="line-474"></span><span class="hs-comment">-- | Computes the logarithmic derivative of the gamma function on 'input':</span><span>
</span><span id="line-475"></span><span class="hs-comment">-- \[</span><span>
</span><span id="line-476"></span><span class="hs-comment">-- \mathrm{output}_i = \psi\left(\mathrm{input}_i\right) = \frac{d}{d\mathrm{input}_i} \ln\left(\gamma\left(\mathrm{input}_i\right)\right).</span><span>
</span><span id="line-477"></span><span class="hs-comment">-- \]</span><span>
</span><span id="line-478"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#digamma"><span class="hs-identifier hs-type">digamma</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-479"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679521170"><span class="annot"><a href="#local-6989586621679521170"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679521169"><span class="annot"><a href="#local-6989586621679521169"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679521168"><span class="annot"><a href="#local-6989586621679521168"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679521167"><span class="annot"><a href="#local-6989586621679521167"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679521166"><span class="annot"><a href="#local-6989586621679521166"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-480"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-481"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521170"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521169"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521168"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521167"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521166"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-482"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-483"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521170"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521169"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521168"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521167"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521166"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-484"></span><span id="digamma"><span class="annot"><span class="annottext">digamma :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#digamma"><span class="hs-identifier hs-var hs-var">digamma</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; (Tensor gradient layout device dataType shape
    -&gt; IO (Tensor gradient layout device dataType shape))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.digamma_t</span></a></span><span>
</span><span id="line-485"></span><span>
</span><span id="line-486"></span><span class="hs-comment">-- | Computes and returns the error function of each element of 'input':</span><span>
</span><span id="line-487"></span><span class="hs-comment">-- \[</span><span>
</span><span id="line-488"></span><span class="hs-comment">-- \mathrm{output}_i = \mathop{erf}\left(\mathrm{input}_i\right) = \frac{2}{\sqrt{\pi}} \int_0^{\mathrm{output}_i} \exp\left(- t^2\right) dt.</span><span>
</span><span id="line-489"></span><span class="hs-comment">-- \]</span><span>
</span><span id="line-490"></span><span class="hs-comment">--</span><span>
</span><span id="line-491"></span><span class="hs-comment">-- See also 'erfc' that computes the complementary error function</span><span>
</span><span id="line-492"></span><span class="hs-comment">-- to high numerical accuracy</span><span>
</span><span id="line-493"></span><span class="hs-comment">-- and 'erfinv' that computes the inverse of the error function.</span><span>
</span><span id="line-494"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#erf"><span class="hs-identifier hs-type">erf</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-495"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679521163"><span class="annot"><a href="#local-6989586621679521163"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679521162"><span class="annot"><a href="#local-6989586621679521162"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679521161"><span class="annot"><a href="#local-6989586621679521161"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679521160"><span class="annot"><a href="#local-6989586621679521160"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679521159"><span class="annot"><a href="#local-6989586621679521159"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-496"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-497"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521163"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521162"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521161"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521160"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521159"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-498"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-499"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521163"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521162"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521161"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521160"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521159"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-500"></span><span id="erf"><span class="annot"><span class="annottext">erf :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#erf"><span class="hs-identifier hs-var hs-var">erf</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; (Tensor gradient layout device dataType shape
    -&gt; IO (Tensor gradient layout device dataType shape))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.erf_t</span></a></span><span>
</span><span id="line-501"></span><span>
</span><span id="line-502"></span><span class="hs-comment">-- | Computes the complementary error function of each element of 'input':</span><span>
</span><span id="line-503"></span><span class="hs-comment">-- \[</span><span>
</span><span id="line-504"></span><span class="hs-comment">-- \mathrm{output}_i = 1 - \mathop{erf}\left(\mathrm{input}_i\right) = 1 - \frac{2}{\sqrt{\pi}} \int_0^{\mathrm{output}_i} \exp\left(- t^2\right) dt.</span><span>
</span><span id="line-505"></span><span class="hs-comment">-- \]</span><span>
</span><span id="line-506"></span><span class="hs-comment">--</span><span>
</span><span id="line-507"></span><span class="hs-comment">-- See also 'erf' that computes the error function</span><span>
</span><span id="line-508"></span><span class="hs-comment">-- and 'erfinv' that computes the inverse of the error function.</span><span>
</span><span id="line-509"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#erfc"><span class="hs-identifier hs-type">erfc</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-510"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679521156"><span class="annot"><a href="#local-6989586621679521156"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679521155"><span class="annot"><a href="#local-6989586621679521155"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679521154"><span class="annot"><a href="#local-6989586621679521154"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679521153"><span class="annot"><a href="#local-6989586621679521153"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679521152"><span class="annot"><a href="#local-6989586621679521152"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-511"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-512"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521156"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521155"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521154"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521153"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521152"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-513"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-514"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521156"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521155"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521154"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521153"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521152"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-515"></span><span id="erfc"><span class="annot"><span class="annottext">erfc :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#erfc"><span class="hs-identifier hs-var hs-var">erfc</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; (Tensor gradient layout device dataType shape
    -&gt; IO (Tensor gradient layout device dataType shape))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.erfc_t</span></a></span><span>
</span><span id="line-516"></span><span>
</span><span id="line-517"></span><span class="hs-comment">-- | Computes the inverse error function of each element of 'input':</span><span>
</span><span id="line-518"></span><span class="hs-comment">-- \[</span><span>
</span><span id="line-519"></span><span class="hs-comment">-- \mathrm{output}_i = \mathop{erfinv}\left(\mathrm{input}_i\right)</span><span>
</span><span id="line-520"></span><span class="hs-comment">-- \]</span><span>
</span><span id="line-521"></span><span class="hs-comment">-- where \(\mathop{erfinv}\left(\mathop{erf}\left(x\right)\right) = x\)</span><span>
</span><span id="line-522"></span><span class="hs-comment">-- for \(x \in (-1, 1)\). 'erfinv' is not defined outside this interval.</span><span>
</span><span id="line-523"></span><span class="hs-comment">--</span><span>
</span><span id="line-524"></span><span class="hs-comment">-- See also 'erf' that computes the error function</span><span>
</span><span id="line-525"></span><span class="hs-comment">-- and 'erfc' that computes the complementary error function.</span><span>
</span><span id="line-526"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#erfinv"><span class="hs-identifier hs-type">erfinv</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-527"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679521149"><span class="annot"><a href="#local-6989586621679521149"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679521148"><span class="annot"><a href="#local-6989586621679521148"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679521147"><span class="annot"><a href="#local-6989586621679521147"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679521146"><span class="annot"><a href="#local-6989586621679521146"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679521145"><span class="annot"><a href="#local-6989586621679521145"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-528"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-529"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521149"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521148"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521147"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521146"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521145"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-530"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-531"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521149"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521148"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521147"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521146"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521145"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-532"></span><span id="erfinv"><span class="annot"><span class="annottext">erfinv :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#erfinv"><span class="hs-identifier hs-var hs-var">erfinv</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; (Tensor gradient layout device dataType shape
    -&gt; IO (Tensor gradient layout device dataType shape))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.erfinv_t</span></a></span><span>
</span><span id="line-533"></span><span>
</span><span id="line-534"></span><span class="hs-comment">-- | Returns a new tensor with the exponential of the elements of the input tensor 'input':</span><span>
</span><span id="line-535"></span><span class="hs-comment">-- \[</span><span>
</span><span id="line-536"></span><span class="hs-comment">-- \mathrm{output}_i = \exp\left(\mathrm{input}_i\right).</span><span>
</span><span id="line-537"></span><span class="hs-comment">-- \]</span><span>
</span><span id="line-538"></span><span class="hs-comment">--</span><span>
</span><span id="line-539"></span><span class="hs-comment">-- See also 'expm1' for a high-accuracy calculation of</span><span>
</span><span id="line-540"></span><span class="hs-comment">-- the exponential of the elements of 'input' minus 1.</span><span>
</span><span id="line-541"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#exp"><span class="hs-identifier hs-type">exp</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-542"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679521142"><span class="annot"><a href="#local-6989586621679521142"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679521141"><span class="annot"><a href="#local-6989586621679521141"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679521140"><span class="annot"><a href="#local-6989586621679521140"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679521139"><span class="annot"><a href="#local-6989586621679521139"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679521138"><span class="annot"><a href="#local-6989586621679521138"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-543"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-544"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521142"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521141"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521140"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521139"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521138"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-545"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-546"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521142"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521141"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521140"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521139"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521138"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-547"></span><span id="exp"><span class="annot"><span class="annottext">exp :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#exp"><span class="hs-identifier hs-var hs-var">exp</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; (Tensor gradient layout device dataType shape
    -&gt; IO (Tensor gradient layout device dataType shape))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.exp_t</span></a></span><span>
</span><span id="line-548"></span><span>
</span><span id="line-549"></span><span class="hs-comment">-- | Returns a new tensor with the exponential of the elements minus 1 of 'input':</span><span>
</span><span id="line-550"></span><span class="hs-comment">-- \[</span><span>
</span><span id="line-551"></span><span class="hs-comment">-- \mathrm{output}_i = \exp\left(\mathrm{input}_i\right) - 1.</span><span>
</span><span id="line-552"></span><span class="hs-comment">-- \]</span><span>
</span><span id="line-553"></span><span class="hs-comment">--</span><span>
</span><span id="line-554"></span><span class="hs-comment">-- See also 'exp' for the exponential function.</span><span>
</span><span id="line-555"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#expm1"><span class="hs-identifier hs-type">expm1</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-556"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679521135"><span class="annot"><a href="#local-6989586621679521135"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679521134"><span class="annot"><a href="#local-6989586621679521134"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679521133"><span class="annot"><a href="#local-6989586621679521133"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679521132"><span class="annot"><a href="#local-6989586621679521132"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679521131"><span class="annot"><a href="#local-6989586621679521131"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-557"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-558"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521135"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521134"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521133"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521132"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521131"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-559"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-560"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521135"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521134"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521133"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521132"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521131"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-561"></span><span id="expm1"><span class="annot"><span class="annottext">expm1 :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#expm1"><span class="hs-identifier hs-var hs-var">expm1</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; (Tensor gradient layout device dataType shape
    -&gt; IO (Tensor gradient layout device dataType shape))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.expm1_t</span></a></span><span>
</span><span id="line-562"></span><span>
</span><span id="line-563"></span><span class="hs-comment">-- | Returns a new tensor with the floor of the elements of 'input',</span><span>
</span><span id="line-564"></span><span class="hs-comment">-- that is, the largest integer less than or equal to each element.:</span><span>
</span><span id="line-565"></span><span class="hs-comment">-- \[</span><span>
</span><span id="line-566"></span><span class="hs-comment">-- \mathrm{output}_i = \lfloor\mathrm{input}_i\rfloor = \lceil\mathrm{input}_i\rceil - 1,</span><span>
</span><span id="line-567"></span><span class="hs-comment">-- \]</span><span>
</span><span id="line-568"></span><span class="hs-comment">-- where \(\lceil\mathrm{input}_i\rceil\) is the ceil of the \(i\)-th element of 'input'</span><span>
</span><span id="line-569"></span><span class="hs-comment">-- which can be computed with 'ceil'.</span><span>
</span><span id="line-570"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#floor"><span class="hs-identifier hs-type">floor</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-571"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679521128"><span class="annot"><a href="#local-6989586621679521128"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679521127"><span class="annot"><a href="#local-6989586621679521127"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679521126"><span class="annot"><a href="#local-6989586621679521126"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679521125"><span class="annot"><a href="#local-6989586621679521125"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679521124"><span class="annot"><a href="#local-6989586621679521124"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-572"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-573"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521128"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521127"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521126"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521125"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521124"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-574"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-575"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521128"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521127"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521126"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521125"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521124"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-576"></span><span id="floor"><span class="annot"><span class="annottext">floor :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#floor"><span class="hs-identifier hs-var hs-var">floor</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; (Tensor gradient layout device dataType shape
    -&gt; IO (Tensor gradient layout device dataType shape))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.floor_t</span></a></span><span>
</span><span id="line-577"></span><span>
</span><span id="line-578"></span><span class="hs-comment">-- | Return the element-wise division of the tensor 'dividend' by the tensor 'divisor'</span><span>
</span><span id="line-579"></span><span class="hs-comment">-- rounded down to the nearest integer:</span><span>
</span><span id="line-580"></span><span class="hs-comment">-- \[</span><span>
</span><span id="line-581"></span><span class="hs-comment">-- \mathrm{output}_i = \left\lfloor\frac{\mathrm{dividend}_i}{\mathrm{divisor}_i}\right\rfloor.</span><span>
</span><span id="line-582"></span><span class="hs-comment">-- \]</span><span>
</span><span id="line-583"></span><span class="hs-comment">--</span><span>
</span><span id="line-584"></span><span class="hs-comment">-- See 'floorDivideScalar' for a version of this function where</span><span>
</span><span id="line-585"></span><span class="hs-comment">-- 'divisor' is a scalar.</span><span>
</span><span id="line-586"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#floorDivide"><span class="hs-identifier hs-type">floorDivide</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-587"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679521121"><span class="annot"><a href="#local-6989586621679521121"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679521120"><span class="annot"><a href="#local-6989586621679521120"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679521119"><span class="annot"><a href="#local-6989586621679521119"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679521118"><span class="annot"><a href="#local-6989586621679521118"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679521117"><span class="annot"><a href="#local-6989586621679521117"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-588"></span><span>  </span><span class="hs-comment">-- | dividend tensor</span><span>
</span><span id="line-589"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521121"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521120"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521119"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521118"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521117"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-590"></span><span>  </span><span class="hs-comment">-- | divisor tensor</span><span>
</span><span id="line-591"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521121"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521120"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521119"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521118"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521117"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-592"></span><span>  </span><span class="hs-comment">-- | output tensor</span><span>
</span><span id="line-593"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521121"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521120"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521119"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521118"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521117"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-594"></span><span id="local-6989586621679521116"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679521116"><span class="hs-identifier hs-var">dividend</span></a></span></span><span> </span><span id="floorDivide"><span class="annot"><span class="annottext">floorDivide :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#floorDivide"><span class="hs-operator hs-var hs-var">`floorDivide`</span></a></span></span><span> </span><span id="local-6989586621679521115"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679521115"><span class="hs-identifier hs-var">divisor</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.floor_divide_tt</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679521116"><span class="hs-identifier hs-var">dividend</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679521115"><span class="hs-identifier hs-var">divisor</span></a></span><span>
</span><span id="line-595"></span><span>
</span><span id="line-596"></span><span class="hs-comment">-- | Return the division of the tensor 'dividend' by the scalar 'divisor'</span><span>
</span><span id="line-597"></span><span class="hs-comment">-- rounded down to the nearest integer:</span><span>
</span><span id="line-598"></span><span class="hs-comment">-- \[</span><span>
</span><span id="line-599"></span><span class="hs-comment">-- \mathrm{output}_i = \left\lfloor\frac{\mathrm{dividend}_i}{\mathrm{divisor}}\right\rfloor.</span><span>
</span><span id="line-600"></span><span class="hs-comment">-- \]</span><span>
</span><span id="line-601"></span><span class="hs-comment">--</span><span>
</span><span id="line-602"></span><span class="hs-comment">-- See 'floorDivide' for a version of this function where</span><span>
</span><span id="line-603"></span><span class="hs-comment">-- 'divisor' is a tensor.</span><span>
</span><span id="line-604"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#floorDivideScalar"><span class="hs-identifier hs-type">floorDivideScalar</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-605"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679521112"><span class="annot"><a href="#local-6989586621679521112"><span class="hs-identifier hs-type">divisor</span></a></span></span><span> </span><span id="local-6989586621679521111"><span class="annot"><a href="#local-6989586621679521111"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679521110"><span class="annot"><a href="#local-6989586621679521110"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679521109"><span class="annot"><a href="#local-6989586621679521109"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679521108"><span class="annot"><a href="#local-6989586621679521108"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679521107"><span class="annot"><a href="#local-6989586621679521107"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-606"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Scalar.html#Scalar"><span class="hs-identifier hs-type">Scalar</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521112"><span class="hs-identifier hs-type">divisor</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-607"></span><span>  </span><span class="hs-comment">-- | dividend tensor</span><span>
</span><span id="line-608"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521111"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521110"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521109"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521108"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521107"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-609"></span><span>  </span><span class="hs-comment">-- | divisor scalar</span><span>
</span><span id="line-610"></span><span>  </span><span class="annot"><a href="#local-6989586621679521112"><span class="hs-identifier hs-type">divisor</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-611"></span><span>  </span><span class="hs-comment">-- | output tensor</span><span>
</span><span id="line-612"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521111"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521110"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521109"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521108"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521107"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-613"></span><span id="local-6989586621679521106"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679521106"><span class="hs-identifier hs-var">dividend</span></a></span></span><span> </span><span id="floorDivideScalar"><span class="annot"><span class="annottext">floorDivideScalar :: Tensor gradient layout device dataType shape
-&gt; divisor -&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#floorDivideScalar"><span class="hs-operator hs-var hs-var">`floorDivideScalar`</span></a></span></span><span> </span><span id="local-6989586621679521105"><span class="annot"><span class="annottext">divisor
</span><a href="#local-6989586621679521105"><span class="hs-identifier hs-var">divisor</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ForeignPtr Scalar -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; divisor
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr Scalar -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.floor_divide_ts</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679521106"><span class="hs-identifier hs-var">dividend</span></a></span><span> </span><span class="annot"><span class="annottext">divisor
</span><a href="#local-6989586621679521105"><span class="hs-identifier hs-var">divisor</span></a></span><span>
</span><span id="line-614"></span><span>
</span><span id="line-615"></span><span class="hs-comment">-- | Computes the element-wise remainder of the division of</span><span>
</span><span id="line-616"></span><span class="hs-comment">-- the tensor 'dividend' by the tensor 'divisor'.</span><span>
</span><span id="line-617"></span><span class="hs-comment">-- The dividend and divisor may contain both for integer and floating point numbers.</span><span>
</span><span id="line-618"></span><span class="hs-comment">-- The remainder has the same sign as the 'dividend' input.</span><span>
</span><span id="line-619"></span><span class="hs-comment">--</span><span>
</span><span id="line-620"></span><span class="hs-comment">-- See 'fmodScalar' for a version of this function where</span><span>
</span><span id="line-621"></span><span class="hs-comment">-- 'divisor' is a scalar.</span><span>
</span><span id="line-622"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#fmod"><span class="hs-identifier hs-type">fmod</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-623"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679521102"><span class="annot"><a href="#local-6989586621679521102"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679521101"><span class="annot"><a href="#local-6989586621679521101"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679521100"><span class="annot"><a href="#local-6989586621679521100"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679521099"><span class="annot"><a href="#local-6989586621679521099"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679521098"><span class="annot"><a href="#local-6989586621679521098"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-624"></span><span>  </span><span class="hs-comment">-- | dividend tensor</span><span>
</span><span id="line-625"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521102"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521101"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521100"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521099"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521098"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-626"></span><span>  </span><span class="hs-comment">-- | divisor scalar</span><span>
</span><span id="line-627"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521102"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521101"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521100"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521099"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521098"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-628"></span><span>  </span><span class="hs-comment">-- | output tensor</span><span>
</span><span id="line-629"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521102"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521101"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521100"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521099"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521098"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-630"></span><span id="local-6989586621679521097"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679521097"><span class="hs-identifier hs-var">dividend</span></a></span></span><span> </span><span id="fmod"><span class="annot"><span class="annottext">fmod :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#fmod"><span class="hs-operator hs-var hs-var">`fmod`</span></a></span></span><span> </span><span id="local-6989586621679521096"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679521096"><span class="hs-identifier hs-var">divisor</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.fmod_tt</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679521097"><span class="hs-identifier hs-var">dividend</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679521096"><span class="hs-identifier hs-var">divisor</span></a></span><span>
</span><span id="line-631"></span><span>
</span><span id="line-632"></span><span class="hs-comment">-- | Computes the element-wise remainder of the division of</span><span>
</span><span id="line-633"></span><span class="hs-comment">-- the tensor 'dividend' by the scalar 'divisor'.</span><span>
</span><span id="line-634"></span><span class="hs-comment">-- The dividend and divisor may contain both for integer and floating point numbers.</span><span>
</span><span id="line-635"></span><span class="hs-comment">-- The remainder has the same sign as the 'dividend' input.</span><span>
</span><span id="line-636"></span><span class="hs-comment">--</span><span>
</span><span id="line-637"></span><span class="hs-comment">-- See 'fmodScalar' for a version of this function where</span><span>
</span><span id="line-638"></span><span class="hs-comment">-- 'divisor' is a scalar.</span><span>
</span><span id="line-639"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#fmodScalar"><span class="hs-identifier hs-type">fmodScalar</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-640"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679521093"><span class="annot"><a href="#local-6989586621679521093"><span class="hs-identifier hs-type">divisor</span></a></span></span><span> </span><span id="local-6989586621679521092"><span class="annot"><a href="#local-6989586621679521092"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679521091"><span class="annot"><a href="#local-6989586621679521091"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679521090"><span class="annot"><a href="#local-6989586621679521090"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679521089"><span class="annot"><a href="#local-6989586621679521089"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679521088"><span class="annot"><a href="#local-6989586621679521088"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-641"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Scalar.html#Scalar"><span class="hs-identifier hs-type">Scalar</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521093"><span class="hs-identifier hs-type">divisor</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-642"></span><span>  </span><span class="hs-comment">-- | divisor scalar</span><span>
</span><span id="line-643"></span><span>  </span><span class="annot"><a href="#local-6989586621679521093"><span class="hs-identifier hs-type">divisor</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-644"></span><span>  </span><span class="hs-comment">-- | dividend tensor</span><span>
</span><span id="line-645"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521092"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521091"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521090"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521089"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521088"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-646"></span><span>  </span><span class="hs-comment">-- | output tensor</span><span>
</span><span id="line-647"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521092"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521091"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521090"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521089"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521088"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-648"></span><span id="fmodScalar"><span class="annot"><span class="annottext">fmodScalar :: divisor
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#fmodScalar"><span class="hs-identifier hs-var hs-var">fmodScalar</span></a></span></span><span> </span><span id="local-6989586621679521087"><span class="annot"><span class="annottext">divisor
</span><a href="#local-6989586621679521087"><span class="hs-identifier hs-var">scalar</span></a></span></span><span> </span><span id="local-6989586621679521086"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679521086"><span class="hs-identifier hs-var">tensor</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ForeignPtr Scalar -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; divisor
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr Scalar -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.fmod_ts</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679521086"><span class="hs-identifier hs-var">tensor</span></a></span><span> </span><span class="annot"><span class="annottext">divisor
</span><a href="#local-6989586621679521087"><span class="hs-identifier hs-var">scalar</span></a></span><span>
</span><span id="line-649"></span><span>
</span><span id="line-650"></span><span class="hs-comment">-- | Computes the fractional portion of each element in 'input':</span><span>
</span><span id="line-651"></span><span class="hs-comment">-- \[</span><span>
</span><span id="line-652"></span><span class="hs-comment">-- \mathrm{output}_i = \mathrm{input}_i - \left\lfloor\left|\mathrm{input}_i\right|\right\rfloor \times \sgn\left(\mathrm{input}_i\right).</span><span>
</span><span id="line-653"></span><span class="hs-comment">-- \]</span><span>
</span><span id="line-654"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#frac"><span class="hs-identifier hs-type">frac</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-655"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679521083"><span class="annot"><a href="#local-6989586621679521083"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679521082"><span class="annot"><a href="#local-6989586621679521082"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679521081"><span class="annot"><a href="#local-6989586621679521081"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679521080"><span class="annot"><a href="#local-6989586621679521080"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679521079"><span class="annot"><a href="#local-6989586621679521079"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-656"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-657"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521083"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521082"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521081"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521080"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521079"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-658"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-659"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521083"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521082"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521081"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521080"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521079"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-660"></span><span id="frac"><span class="annot"><span class="annottext">frac :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#frac"><span class="hs-identifier hs-var hs-var">frac</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; (Tensor gradient layout device dataType shape
    -&gt; IO (Tensor gradient layout device dataType shape))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.frac_t</span></a></span><span>
</span><span id="line-661"></span><span>
</span><span id="line-662"></span><span class="hs-comment">-- | Linear interpolation of two tensors, 'start' and 'end', based on a tensor 'weight'.</span><span>
</span><span id="line-663"></span><span class="hs-comment">-- For linear interpolations based on a scalar see 'lerpScalar'.</span><span>
</span><span id="line-664"></span><span class="hs-comment">--</span><span>
</span><span id="line-665"></span><span class="hs-comment">-- Returned is the result of the following computation as a tensor:</span><span>
</span><span id="line-666"></span><span class="hs-comment">-- \[</span><span>
</span><span id="line-667"></span><span class="hs-comment">--   \mathrm{output}_i = \mathrm{start}_i + \mathrm{weight}_i \times \left(\mathrm{end}_i - \mathrm{start}_i\right).</span><span>
</span><span id="line-668"></span><span class="hs-comment">-- \]</span><span>
</span><span id="line-669"></span><span class="hs-comment">--</span><span>
</span><span id="line-670"></span><span class="hs-comment">-- Note that the shapes of 'start', 'end', and also 'weight' must be broadcastable.</span><span>
</span><span id="line-671"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#lerp"><span class="hs-identifier hs-type">lerp</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-672"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679521076"><span class="annot"><a href="#local-6989586621679521076"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679521075"><span class="annot"><a href="#local-6989586621679521075"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679521074"><span class="annot"><a href="#local-6989586621679521074"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679521073"><span class="annot"><a href="#local-6989586621679521073"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679521072"><span class="annot"><a href="#local-6989586621679521072"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-673"></span><span>  </span><span class="hs-comment">-- | weight</span><span>
</span><span id="line-674"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521076"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521075"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521074"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521073"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521072"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-675"></span><span>  </span><span class="hs-comment">-- | start</span><span>
</span><span id="line-676"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521076"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521075"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521074"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521073"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521072"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-677"></span><span>  </span><span class="hs-comment">-- | end</span><span>
</span><span id="line-678"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521076"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521075"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521074"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521073"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521072"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-679"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-680"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521076"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521075"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521074"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521073"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521072"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-681"></span><span id="lerp"><span class="annot"><span class="annottext">lerp :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#lerp"><span class="hs-identifier hs-var hs-var">lerp</span></a></span></span><span> </span><span id="local-6989586621679521071"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679521071"><span class="hs-identifier hs-var">weight</span></a></span></span><span> </span><span id="local-6989586621679521070"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679521070"><span class="hs-identifier hs-var">start</span></a></span></span><span> </span><span id="local-6989586621679521069"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679521069"><span class="hs-identifier hs-var">end</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca x1 cx1 x2 cx2 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; x2 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast3</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.lerp_ttt</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679521070"><span class="hs-identifier hs-var">start</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679521069"><span class="hs-identifier hs-var">end</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679521071"><span class="hs-identifier hs-var">weight</span></a></span><span>
</span><span id="line-682"></span><span>
</span><span id="line-683"></span><span class="hs-comment">-- | Linear interpolation of two tensors, 'start' and 'end', based on a scalar 'weight'.</span><span>
</span><span id="line-684"></span><span class="hs-comment">-- For linear interpolations based on a tensor see 'lerp'.</span><span>
</span><span id="line-685"></span><span class="hs-comment">--</span><span>
</span><span id="line-686"></span><span class="hs-comment">-- Returned is the result of the following computation as a tensor:</span><span>
</span><span id="line-687"></span><span class="hs-comment">-- \[</span><span>
</span><span id="line-688"></span><span class="hs-comment">--   \mathrm{output}_i = \mathrm{start}_i + \mathrm{weight} \times \left(\mathrm{end}_i - \mathrm{start}_i\right).</span><span>
</span><span id="line-689"></span><span class="hs-comment">-- \]</span><span>
</span><span id="line-690"></span><span class="hs-comment">--</span><span>
</span><span id="line-691"></span><span class="hs-comment">-- Note that the shapes of 'start' and 'end' must be broadcastable.</span><span>
</span><span id="line-692"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#lerpScalar"><span class="hs-identifier hs-type">lerpScalar</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-693"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679521066"><span class="annot"><a href="#local-6989586621679521066"><span class="hs-identifier hs-type">weight</span></a></span></span><span> </span><span id="local-6989586621679521065"><span class="annot"><a href="#local-6989586621679521065"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679521064"><span class="annot"><a href="#local-6989586621679521064"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679521063"><span class="annot"><a href="#local-6989586621679521063"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679521062"><span class="annot"><a href="#local-6989586621679521062"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679521061"><span class="annot"><a href="#local-6989586621679521061"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-694"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Scalar.html#Scalar"><span class="hs-identifier hs-type">Scalar</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521066"><span class="hs-identifier hs-type">weight</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-695"></span><span>  </span><span class="hs-comment">-- | weight</span><span>
</span><span id="line-696"></span><span>  </span><span class="annot"><a href="#local-6989586621679521066"><span class="hs-identifier hs-type">weight</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-697"></span><span>  </span><span class="hs-comment">-- | start</span><span>
</span><span id="line-698"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521065"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521064"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521063"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521062"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521061"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-699"></span><span>  </span><span class="hs-comment">-- | end</span><span>
</span><span id="line-700"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521065"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521064"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521063"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521062"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521061"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-701"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-702"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521065"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521064"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521063"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521062"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521061"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-703"></span><span id="lerpScalar"><span class="annot"><span class="annottext">lerpScalar :: weight
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#lerpScalar"><span class="hs-identifier hs-var hs-var">lerpScalar</span></a></span></span><span> </span><span id="local-6989586621679521060"><span class="annot"><span class="annottext">weight
</span><a href="#local-6989586621679521060"><span class="hs-identifier hs-var">weight</span></a></span></span><span> </span><span id="local-6989586621679521059"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679521059"><span class="hs-identifier hs-var">start</span></a></span></span><span> </span><span id="local-6989586621679521058"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679521058"><span class="hs-identifier hs-var">end</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; ForeignPtr Scalar
 -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
-&gt; weight
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca x1 cx1 x2 cx2 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; x2 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast3</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; ForeignPtr Tensor -&gt; ForeignPtr Scalar -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.lerp_tts</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679521059"><span class="hs-identifier hs-var">start</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679521058"><span class="hs-identifier hs-var">end</span></a></span><span> </span><span class="annot"><span class="annottext">weight
</span><a href="#local-6989586621679521060"><span class="hs-identifier hs-var">weight</span></a></span><span>
</span><span id="line-704"></span><span>
</span><span id="line-705"></span><span class="hs-comment">-- | Computes the logarithm of the gamma function on 'input':</span><span>
</span><span id="line-706"></span><span class="hs-comment">-- \[</span><span>
</span><span id="line-707"></span><span class="hs-comment">-- \mathrm{output}_i = \log \Gamma\left(\mathrm{input}_i\right).</span><span>
</span><span id="line-708"></span><span class="hs-comment">-- \]</span><span>
</span><span id="line-709"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#lgamma"><span class="hs-identifier hs-type">lgamma</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-710"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679521055"><span class="annot"><a href="#local-6989586621679521055"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679521054"><span class="annot"><a href="#local-6989586621679521054"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679521053"><span class="annot"><a href="#local-6989586621679521053"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679521052"><span class="annot"><a href="#local-6989586621679521052"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679521051"><span class="annot"><a href="#local-6989586621679521051"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-711"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-712"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521055"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521054"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521053"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521052"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521051"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-713"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-714"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521055"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521054"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521053"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521052"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521051"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-715"></span><span id="lgamma"><span class="annot"><span class="annottext">lgamma :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#lgamma"><span class="hs-identifier hs-var hs-var">lgamma</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; (Tensor gradient layout device dataType shape
    -&gt; IO (Tensor gradient layout device dataType shape))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.lgamma_t</span></a></span><span>
</span><span id="line-716"></span><span>
</span><span id="line-717"></span><span class="hs-comment">-- | Returns a new tensor with the natural logarithm of the elements of 'input':</span><span>
</span><span id="line-718"></span><span class="hs-comment">-- \[</span><span>
</span><span id="line-719"></span><span class="hs-comment">-- \mathrm{output}_i = \ln \left(\mathrm{input}_i\right) = \log_{\mathrm{e}} \left(\mathrm{input}_i\right).</span><span>
</span><span id="line-720"></span><span class="hs-comment">-- \]</span><span>
</span><span id="line-721"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#log"><span class="hs-identifier hs-type">log</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-722"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679521048"><span class="annot"><a href="#local-6989586621679521048"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679521047"><span class="annot"><a href="#local-6989586621679521047"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679521046"><span class="annot"><a href="#local-6989586621679521046"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679521045"><span class="annot"><a href="#local-6989586621679521045"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679521044"><span class="annot"><a href="#local-6989586621679521044"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-723"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-724"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521048"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521047"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521046"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521045"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521044"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-725"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-726"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521048"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521047"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521046"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521045"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521044"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-727"></span><span id="log"><span class="annot"><span class="annottext">log :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#log"><span class="hs-identifier hs-var hs-var">log</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; (Tensor gradient layout device dataType shape
    -&gt; IO (Tensor gradient layout device dataType shape))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.log_t</span></a></span><span>
</span><span id="line-728"></span><span>
</span><span id="line-729"></span><span class="hs-comment">-- | Returns a new tensor with the decimal logarithm of the elements of 'input':</span><span>
</span><span id="line-730"></span><span class="hs-comment">-- \[</span><span>
</span><span id="line-731"></span><span class="hs-comment">-- \mathrm{output}_i = \mathop{lg} \left(\mathrm{input}_i\right) = \log_{10} \left(\mathrm{input}_i\right).</span><span>
</span><span id="line-732"></span><span class="hs-comment">-- \]</span><span>
</span><span id="line-733"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#log10"><span class="hs-identifier hs-type">log10</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-734"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679521041"><span class="annot"><a href="#local-6989586621679521041"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679521040"><span class="annot"><a href="#local-6989586621679521040"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679521039"><span class="annot"><a href="#local-6989586621679521039"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679521038"><span class="annot"><a href="#local-6989586621679521038"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679521037"><span class="annot"><a href="#local-6989586621679521037"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-735"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-736"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521041"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521040"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521039"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521038"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521037"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-737"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-738"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521041"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521040"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521039"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521038"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521037"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-739"></span><span id="log10"><span class="annot"><span class="annottext">log10 :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#log10"><span class="hs-identifier hs-var hs-var">log10</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; (Tensor gradient layout device dataType shape
    -&gt; IO (Tensor gradient layout device dataType shape))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.log10_t</span></a></span><span>
</span><span id="line-740"></span><span>
</span><span id="line-741"></span><span class="hs-comment">-- | Returns a new tensor with the natural logarithm of \(1 + \mathrm{input}\):</span><span>
</span><span id="line-742"></span><span class="hs-comment">-- \[</span><span>
</span><span id="line-743"></span><span class="hs-comment">-- \mathrm{output}_i = \ln \left(1 + \mathrm{input}_i\right).</span><span>
</span><span id="line-744"></span><span class="hs-comment">-- \]</span><span>
</span><span id="line-745"></span><span class="hs-comment">--</span><span>
</span><span id="line-746"></span><span class="hs-comment">-- Consider using this function over a literal implementation using 'log'.</span><span>
</span><span id="line-747"></span><span class="hs-comment">-- 'log1p' is much more accurate for small values of 'input'.</span><span>
</span><span id="line-748"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#log1p"><span class="hs-identifier hs-type">log1p</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-749"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679521034"><span class="annot"><a href="#local-6989586621679521034"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679521033"><span class="annot"><a href="#local-6989586621679521033"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679521032"><span class="annot"><a href="#local-6989586621679521032"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679521031"><span class="annot"><a href="#local-6989586621679521031"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679521030"><span class="annot"><a href="#local-6989586621679521030"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-750"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-751"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521034"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521033"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521032"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521031"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521030"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-752"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-753"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521034"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521033"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521032"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521031"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521030"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-754"></span><span id="log1p"><span class="annot"><span class="annottext">log1p :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#log1p"><span class="hs-identifier hs-var hs-var">log1p</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; (Tensor gradient layout device dataType shape
    -&gt; IO (Tensor gradient layout device dataType shape))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.log1p_t</span></a></span><span>
</span><span id="line-755"></span><span>
</span><span id="line-756"></span><span class="hs-comment">-- | Returns a new tensor with the logarithm to the base 2 of the elements of 'input':</span><span>
</span><span id="line-757"></span><span class="hs-comment">-- \[</span><span>
</span><span id="line-758"></span><span class="hs-comment">-- \mathrm{output}_i = \log_2 \left(\mathrm{input}_i\right).</span><span>
</span><span id="line-759"></span><span class="hs-comment">-- \]</span><span>
</span><span id="line-760"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#log2"><span class="hs-identifier hs-type">log2</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-761"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679521027"><span class="annot"><a href="#local-6989586621679521027"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679521026"><span class="annot"><a href="#local-6989586621679521026"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679521025"><span class="annot"><a href="#local-6989586621679521025"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679521024"><span class="annot"><a href="#local-6989586621679521024"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679521023"><span class="annot"><a href="#local-6989586621679521023"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-762"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-763"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521027"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521026"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521025"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521024"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521023"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-764"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-765"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521027"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521026"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521025"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521024"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521023"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-766"></span><span id="log2"><span class="annot"><span class="annottext">log2 :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#log2"><span class="hs-identifier hs-var hs-var">log2</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; (Tensor gradient layout device dataType shape
    -&gt; IO (Tensor gradient layout device dataType shape))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.log2_t</span></a></span><span>
</span><span id="line-767"></span><span>
</span><span id="line-768"></span><span class="hs-comment">-- | Logarithm of the sum of exponentiations of the inputs.</span><span>
</span><span id="line-769"></span><span class="hs-comment">-- Calculates pointwise the function \(\log \left(\exp x + \exp y\right)\).</span><span>
</span><span id="line-770"></span><span class="hs-comment">--</span><span>
</span><span id="line-771"></span><span class="hs-comment">-- This function is useful in statistics where the calculated probabilities of</span><span>
</span><span id="line-772"></span><span class="hs-comment">-- events may be so small as to exceed the range of normal floating point numbers.</span><span>
</span><span id="line-773"></span><span class="hs-comment">-- In such cases the logarithm of the calculated probability is stored.</span><span>
</span><span id="line-774"></span><span class="hs-comment">-- This function allows adding probabilities stored in such a fashion.</span><span>
</span><span id="line-775"></span><span class="hs-comment">--</span><span>
</span><span id="line-776"></span><span class="hs-comment">-- 'logaddexp' must not be confused with 'logsumexp' which performs a reduction on a single tensor.</span><span>
</span><span id="line-777"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#logaddexp"><span class="hs-identifier hs-type">logaddexp</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-778"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679521020"><span class="annot"><a href="#local-6989586621679521020"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679521019"><span class="annot"><a href="#local-6989586621679521019"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679521018"><span class="annot"><a href="#local-6989586621679521018"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679521017"><span class="annot"><a href="#local-6989586621679521017"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679521016"><span class="annot"><a href="#local-6989586621679521016"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-779"></span><span>  </span><span class="hs-comment">-- | other</span><span>
</span><span id="line-780"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521020"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521019"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521018"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521017"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521016"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-781"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-782"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521020"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521019"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521018"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521017"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521016"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-783"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-784"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521020"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521019"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521018"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521017"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521016"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-785"></span><span id="logaddexp"><span class="annot"><span class="annottext">logaddexp :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#logaddexp"><span class="hs-identifier hs-var hs-var">logaddexp</span></a></span></span><span> </span><span id="local-6989586621679521015"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679521015"><span class="hs-identifier hs-var">other</span></a></span></span><span> </span><span id="local-6989586621679521014"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679521014"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.logaddexp_tt</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679521014"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679521015"><span class="hs-identifier hs-var">other</span></a></span><span>
</span><span id="line-786"></span><span>
</span><span id="line-787"></span><span class="hs-comment">-- | Logarithm of the sum of exponentiations of the inputs in base-2.</span><span>
</span><span id="line-788"></span><span class="hs-comment">-- Calculates pointwise the function \(\log_2 \left(2^x + 2^y\right)\).</span><span>
</span><span id="line-789"></span><span class="hs-comment">--</span><span>
</span><span id="line-790"></span><span class="hs-comment">-- See 'logaddexp' for further details.</span><span>
</span><span id="line-791"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#logaddexp2"><span class="hs-identifier hs-type">logaddexp2</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-792"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679521011"><span class="annot"><a href="#local-6989586621679521011"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679521010"><span class="annot"><a href="#local-6989586621679521010"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679521009"><span class="annot"><a href="#local-6989586621679521009"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679521008"><span class="annot"><a href="#local-6989586621679521008"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679521007"><span class="annot"><a href="#local-6989586621679521007"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-793"></span><span>  </span><span class="hs-comment">-- | other</span><span>
</span><span id="line-794"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521011"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521010"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521009"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521008"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521007"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-795"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-796"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521011"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521010"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521009"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521008"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521007"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-797"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-798"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521011"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521010"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521009"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521008"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521007"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-799"></span><span id="logaddexp2"><span class="annot"><span class="annottext">logaddexp2 :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#logaddexp2"><span class="hs-identifier hs-var hs-var">logaddexp2</span></a></span></span><span> </span><span id="local-6989586621679521006"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679521006"><span class="hs-identifier hs-var">other</span></a></span></span><span> </span><span id="local-6989586621679521005"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679521005"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.logaddexp2_tt</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679521005"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679521006"><span class="hs-identifier hs-var">other</span></a></span><span>
</span><span id="line-800"></span><span>
</span><span id="line-801"></span><span class="hs-comment">-- | Computes the element-wise logical AND of the given input tensors.</span><span>
</span><span id="line-802"></span><span class="hs-comment">-- The output tensor will have the 'Bool' data type.</span><span>
</span><span id="line-803"></span><span class="hs-comment">-- If the input tensors are not a bool tensors,</span><span>
</span><span id="line-804"></span><span class="hs-comment">-- then zeros are treated as 'False' and nonzeros are treated as 'True'.</span><span>
</span><span id="line-805"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#logicalAnd"><span class="hs-identifier hs-type">logicalAnd</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-806"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679521002"><span class="annot"><a href="#local-6989586621679521002"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679521001"><span class="annot"><a href="#local-6989586621679521001"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679521000"><span class="annot"><a href="#local-6989586621679521000"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679520999"><span class="annot"><a href="#local-6989586621679520999"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679520998"><span class="annot"><a href="#local-6989586621679520998"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-807"></span><span>  </span><span class="hs-comment">-- | the input tensor</span><span>
</span><span id="line-808"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521002"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521001"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521000"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520999"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520998"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-809"></span><span>  </span><span class="hs-comment">-- | the tensor to compute AND with</span><span>
</span><span id="line-810"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521002"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521001"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521000"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520999"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520998"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-811"></span><span>  </span><span class="hs-comment">-- | the output tensor</span><span>
</span><span id="line-812"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521002"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521001"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679521000"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#Bool"><span class="hs-identifier hs-type">Bool</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679520998"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-813"></span><span id="local-6989586621679520997"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679520997"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span id="logicalAnd"><span class="annot"><span class="annottext">logicalAnd :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device ('DataType 'Bool) shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#logicalAnd"><span class="hs-operator hs-var hs-var">`logicalAnd`</span></a></span></span><span> </span><span id="local-6989586621679520996"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679520996"><span class="hs-identifier hs-var">other</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device ('DataType 'Bool) shape)
-&gt; Tensor gradient layout device ('DataType 'Bool) shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device ('DataType 'Bool) shape)
 -&gt; Tensor gradient layout device ('DataType 'Bool) shape)
-&gt; IO (Tensor gradient layout device ('DataType 'Bool) shape)
-&gt; Tensor gradient layout device ('DataType 'Bool) shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
-&gt; IO (Tensor gradient layout device ('DataType 'Bool) shape)
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.logical_and_tt</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679520997"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679520996"><span class="hs-identifier hs-var">other</span></a></span><span>
</span><span id="line-814"></span><span>
</span><span id="line-815"></span><span class="hs-comment">-- | Computes the element-wise logical NOT of the given input tensor.</span><span>
</span><span id="line-816"></span><span class="hs-comment">-- The output tensor will have the 'Bool' data type.</span><span>
</span><span id="line-817"></span><span class="hs-comment">-- If the input tensor is not a bool tensor,</span><span>
</span><span id="line-818"></span><span class="hs-comment">-- zeros are treated as 'False' and non-zeros are treated as 'True'.</span><span>
</span><span id="line-819"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#logicalNot"><span class="hs-identifier hs-type">logicalNot</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-820"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679520993"><span class="annot"><a href="#local-6989586621679520993"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679520992"><span class="annot"><a href="#local-6989586621679520992"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679520991"><span class="annot"><a href="#local-6989586621679520991"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679520990"><span class="annot"><a href="#local-6989586621679520990"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679520989"><span class="annot"><a href="#local-6989586621679520989"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-821"></span><span>  </span><span class="hs-comment">-- | the input tensor</span><span>
</span><span id="line-822"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520993"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520992"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520991"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520990"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520989"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-823"></span><span>  </span><span class="hs-comment">-- | the output tensor</span><span>
</span><span id="line-824"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#WithoutGradient"><span class="hs-identifier hs-type">WithoutGradient</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679520992"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520991"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#Bool"><span class="hs-identifier hs-type">Bool</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679520989"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-825"></span><span id="logicalNot"><span class="annot"><span class="annottext">logicalNot :: Tensor gradient layout device dataType shape
-&gt; Tensor
     ('Gradient 'WithoutGradient) layout device ('DataType 'Bool) shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#logicalNot"><span class="hs-identifier hs-var hs-var">logicalNot</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO
  (Tensor
     ('Gradient 'WithoutGradient) layout device ('DataType 'Bool) shape)
-&gt; Tensor
     ('Gradient 'WithoutGradient) layout device ('DataType 'Bool) shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO
   (Tensor
      ('Gradient 'WithoutGradient) layout device ('DataType 'Bool) shape)
 -&gt; Tensor
      ('Gradient 'WithoutGradient) layout device ('DataType 'Bool) shape)
-&gt; (Tensor gradient layout device dataType shape
    -&gt; IO
         (Tensor
            ('Gradient 'WithoutGradient)
            layout
            device
            ('DataType 'Bool)
            shape))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor
     ('Gradient 'WithoutGradient) layout device ('DataType 'Bool) shape
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; IO
     (Tensor
        ('Gradient 'WithoutGradient) layout device ('DataType 'Bool) shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.logical_not_t</span></a></span><span>
</span><span id="line-826"></span><span>
</span><span id="line-827"></span><span class="hs-comment">-- | Computes the element-wise logical OR of the given input tensors.</span><span>
</span><span id="line-828"></span><span class="hs-comment">-- The output tensor will have the 'Bool' data type.</span><span>
</span><span id="line-829"></span><span class="hs-comment">-- If the input tensors are not a bool tensors,</span><span>
</span><span id="line-830"></span><span class="hs-comment">-- then zeros are treated as 'False' and nonzeros are treated as 'True'.</span><span>
</span><span id="line-831"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#logicalOr"><span class="hs-identifier hs-type">logicalOr</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-832"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679520986"><span class="annot"><a href="#local-6989586621679520986"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679520985"><span class="annot"><a href="#local-6989586621679520985"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679520984"><span class="annot"><a href="#local-6989586621679520984"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679520983"><span class="annot"><a href="#local-6989586621679520983"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679520982"><span class="annot"><a href="#local-6989586621679520982"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679520981"><span class="annot"><a href="#local-6989586621679520981"><span class="hs-identifier hs-type">gradient'</span></a></span></span><span> </span><span id="local-6989586621679520980"><span class="annot"><a href="#local-6989586621679520980"><span class="hs-identifier hs-type">layout'</span></a></span></span><span> </span><span id="local-6989586621679520979"><span class="annot"><a href="#local-6989586621679520979"><span class="hs-identifier hs-type">device'</span></a></span></span><span> </span><span id="local-6989586621679520978"><span class="annot"><a href="#local-6989586621679520978"><span class="hs-identifier hs-type">dataType'</span></a></span></span><span> </span><span id="local-6989586621679520977"><span class="annot"><a href="#local-6989586621679520977"><span class="hs-identifier hs-type">shape'</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-833"></span><span>  </span><span class="hs-comment">-- | the input tensor</span><span>
</span><span id="line-834"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520986"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520985"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520984"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520983"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520982"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-835"></span><span>  </span><span class="hs-comment">-- | the tensor to compute OR with</span><span>
</span><span id="line-836"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520981"><span class="hs-identifier hs-type">gradient'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520980"><span class="hs-identifier hs-type">layout'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520979"><span class="hs-identifier hs-type">device'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520978"><span class="hs-identifier hs-type">dataType'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520977"><span class="hs-identifier hs-type">shape'</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-837"></span><span>  </span><span class="hs-comment">-- | the output tensor</span><span>
</span><span id="line-838"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-839"></span><span>    </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#WithoutGradient"><span class="hs-identifier hs-type">WithoutGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-840"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679520985"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520980"><span class="hs-identifier hs-type">layout'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-841"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679520984"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520979"><span class="hs-identifier hs-type">device'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-842"></span><span>    </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#Bool"><span class="hs-identifier hs-type">Bool</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-843"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#BroadcastShapesF"><span class="hs-identifier hs-type">BroadcastShapesF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520982"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520977"><span class="hs-identifier hs-type">shape'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-844"></span><span id="local-6989586621679520976"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679520976"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span id="logicalOr"><span class="annot"><span class="annottext">logicalOr :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     (layout &lt;+&gt; layout')
     (device &lt;+&gt; device')
     ('DataType 'Bool)
     (BroadcastShapesF shape shape')
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#logicalOr"><span class="hs-operator hs-var hs-var">`logicalOr`</span></a></span></span><span> </span><span id="local-6989586621679520975"><span class="annot"><span class="annottext">Tensor gradient' layout' device' dataType' shape'
</span><a href="#local-6989586621679520975"><span class="hs-identifier hs-var">other</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO
  (Tensor
     ('Gradient 'WithoutGradient)
     (Unify (Layout LayoutType) layout layout')
     (Unify (Device (DeviceType Nat)) device device')
     ('DataType 'Bool)
     (BroadcastShapesF shape shape'))
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     (Unify (Layout LayoutType) layout layout')
     (Unify (Device (DeviceType Nat)) device device')
     ('DataType 'Bool)
     (BroadcastShapesF shape shape')
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO
   (Tensor
      ('Gradient 'WithoutGradient)
      (Unify (Layout LayoutType) layout layout')
      (Unify (Device (DeviceType Nat)) device device')
      ('DataType 'Bool)
      (BroadcastShapesF shape shape'))
 -&gt; Tensor
      ('Gradient 'WithoutGradient)
      (Unify (Layout LayoutType) layout layout')
      (Unify (Device (DeviceType Nat)) device device')
      ('DataType 'Bool)
      (BroadcastShapesF shape shape'))
-&gt; IO
     (Tensor
        ('Gradient 'WithoutGradient)
        (Unify (Layout LayoutType) layout layout')
        (Unify (Device (DeviceType Nat)) device device')
        ('DataType 'Bool)
        (BroadcastShapesF shape shape'))
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     (Unify (Layout LayoutType) layout layout')
     (Unify (Device (DeviceType Nat)) device device')
     ('DataType 'Bool)
     (BroadcastShapesF shape shape')
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; IO
     (Tensor
        ('Gradient 'WithoutGradient)
        (Unify (Layout LayoutType) layout layout')
        (Unify (Device (DeviceType Nat)) device device')
        ('DataType 'Bool)
        (BroadcastShapesF shape shape'))
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.logical_or_tt</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679520976"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient' layout' device' dataType' shape'
</span><a href="#local-6989586621679520975"><span class="hs-identifier hs-var">other</span></a></span><span>
</span><span id="line-845"></span><span>
</span><span id="line-846"></span><span class="hs-comment">-- | Computes the element-wise logical XOR of the given input tensors.</span><span>
</span><span id="line-847"></span><span class="hs-comment">-- The output tensor will have the 'Bool' data type.</span><span>
</span><span id="line-848"></span><span class="hs-comment">-- If the input tensors are not a bool tensors,</span><span>
</span><span id="line-849"></span><span class="hs-comment">-- then zeros are treated as 'False' and nonzeros are treated as 'True'.</span><span>
</span><span id="line-850"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#logicalXor"><span class="hs-identifier hs-type">logicalXor</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-851"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679520972"><span class="annot"><a href="#local-6989586621679520972"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679520971"><span class="annot"><a href="#local-6989586621679520971"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679520970"><span class="annot"><a href="#local-6989586621679520970"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679520969"><span class="annot"><a href="#local-6989586621679520969"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679520968"><span class="annot"><a href="#local-6989586621679520968"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-852"></span><span>  </span><span class="hs-comment">-- | the input tensor</span><span>
</span><span id="line-853"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520972"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520971"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520970"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520969"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520968"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-854"></span><span>  </span><span class="hs-comment">-- | the tensor to compute XOR with</span><span>
</span><span id="line-855"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520972"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520971"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520970"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520969"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520968"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-856"></span><span>  </span><span class="hs-comment">-- | the output tensor</span><span>
</span><span id="line-857"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520972"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520971"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520970"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#Bool"><span class="hs-identifier hs-type">Bool</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679520968"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-858"></span><span id="local-6989586621679520967"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679520967"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span id="logicalXor"><span class="annot"><span class="annottext">logicalXor :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device ('DataType 'Bool) shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#logicalXor"><span class="hs-operator hs-var hs-var">`logicalXor`</span></a></span></span><span> </span><span id="local-6989586621679520966"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679520966"><span class="hs-identifier hs-var">other</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device ('DataType 'Bool) shape)
-&gt; Tensor gradient layout device ('DataType 'Bool) shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device ('DataType 'Bool) shape)
 -&gt; Tensor gradient layout device ('DataType 'Bool) shape)
-&gt; IO (Tensor gradient layout device ('DataType 'Bool) shape)
-&gt; Tensor gradient layout device ('DataType 'Bool) shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
-&gt; IO (Tensor gradient layout device ('DataType 'Bool) shape)
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.logical_xor_tt</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679520967"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679520966"><span class="hs-identifier hs-var">other</span></a></span><span>
</span><span id="line-859"></span><span>
</span><span id="line-860"></span><span class="hs-comment">-- | Element-wise multiplication of two tensors:</span><span>
</span><span id="line-861"></span><span class="hs-comment">-- \[</span><span>
</span><span id="line-862"></span><span class="hs-comment">-- \mathrm{output}_i = \mathrm{input}_i \times \mathrm{other}_i.</span><span>
</span><span id="line-863"></span><span class="hs-comment">-- \]</span><span>
</span><span id="line-864"></span><span class="hs-comment">-- The result is returned as a new tensor.</span><span>
</span><span id="line-865"></span><span class="hs-comment">--</span><span>
</span><span id="line-866"></span><span class="hs-comment">-- The shape of 'other' must be broadcastable with the shape of 'input'.</span><span>
</span><span id="line-867"></span><span class="hs-comment">-- See 'mulScalar' for a version of this function where</span><span>
</span><span id="line-868"></span><span class="hs-comment">-- the 'other' input is a scalar.</span><span>
</span><span id="line-869"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#mul"><span class="hs-identifier hs-type">mul</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-870"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679520963"><span class="annot"><a href="#local-6989586621679520963"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679520962"><span class="annot"><a href="#local-6989586621679520962"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679520961"><span class="annot"><a href="#local-6989586621679520961"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679520960"><span class="annot"><a href="#local-6989586621679520960"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679520959"><span class="annot"><a href="#local-6989586621679520959"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679520958"><span class="annot"><a href="#local-6989586621679520958"><span class="hs-identifier hs-type">gradient'</span></a></span></span><span> </span><span id="local-6989586621679520957"><span class="annot"><a href="#local-6989586621679520957"><span class="hs-identifier hs-type">layout'</span></a></span></span><span> </span><span id="local-6989586621679520956"><span class="annot"><a href="#local-6989586621679520956"><span class="hs-identifier hs-type">device'</span></a></span></span><span> </span><span id="local-6989586621679520955"><span class="annot"><a href="#local-6989586621679520955"><span class="hs-identifier hs-type">dataType'</span></a></span></span><span> </span><span id="local-6989586621679520954"><span class="annot"><a href="#local-6989586621679520954"><span class="hs-identifier hs-type">shape'</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-871"></span><span>  </span><span class="hs-comment">-- | input tensor</span><span>
</span><span id="line-872"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520963"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520962"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520961"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520960"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520959"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-873"></span><span>  </span><span class="hs-comment">-- | other tensor</span><span>
</span><span id="line-874"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520958"><span class="hs-identifier hs-type">gradient'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520957"><span class="hs-identifier hs-type">layout'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520956"><span class="hs-identifier hs-type">device'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520955"><span class="hs-identifier hs-type">dataType'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520954"><span class="hs-identifier hs-type">shape'</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-875"></span><span>  </span><span class="hs-comment">-- | output tensor</span><span>
</span><span id="line-876"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-877"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679520963"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520958"><span class="hs-identifier hs-type">gradient'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-878"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679520962"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520957"><span class="hs-identifier hs-type">layout'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-879"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679520961"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520956"><span class="hs-identifier hs-type">device'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-880"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679520960"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520955"><span class="hs-identifier hs-type">dataType'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-881"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#BroadcastShapesF"><span class="hs-identifier hs-type">BroadcastShapesF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520959"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520954"><span class="hs-identifier hs-type">shape'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-882"></span><span id="local-6989586621679520953"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679520953"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span id="mul"><span class="annot"><span class="annottext">mul :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; Tensor
     (gradient &lt;|&gt; gradient')
     (layout &lt;+&gt; layout')
     (device &lt;+&gt; device')
     (dataType &lt;+&gt; dataType')
     (BroadcastShapesF shape shape')
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#mul"><span class="hs-operator hs-var hs-var">`mul`</span></a></span></span><span> </span><span id="local-6989586621679520952"><span class="annot"><span class="annottext">Tensor gradient' layout' device' dataType' shape'
</span><a href="#local-6989586621679520952"><span class="hs-identifier hs-var">other</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO
  (Tensor
     (Or (Gradient RequiresGradient) gradient gradient')
     (Unify (Layout LayoutType) layout layout')
     (Unify (Device (DeviceType Nat)) device device')
     (Unify (DataType DType) dataType dataType')
     (BroadcastShapesF shape shape'))
-&gt; Tensor
     (Or (Gradient RequiresGradient) gradient gradient')
     (Unify (Layout LayoutType) layout layout')
     (Unify (Device (DeviceType Nat)) device device')
     (Unify (DataType DType) dataType dataType')
     (BroadcastShapesF shape shape')
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO
   (Tensor
      (Or (Gradient RequiresGradient) gradient gradient')
      (Unify (Layout LayoutType) layout layout')
      (Unify (Device (DeviceType Nat)) device device')
      (Unify (DataType DType) dataType dataType')
      (BroadcastShapesF shape shape'))
 -&gt; Tensor
      (Or (Gradient RequiresGradient) gradient gradient')
      (Unify (Layout LayoutType) layout layout')
      (Unify (Device (DeviceType Nat)) device device')
      (Unify (DataType DType) dataType dataType')
      (BroadcastShapesF shape shape'))
-&gt; IO
     (Tensor
        (Or (Gradient RequiresGradient) gradient gradient')
        (Unify (Layout LayoutType) layout layout')
        (Unify (Device (DeviceType Nat)) device device')
        (Unify (DataType DType) dataType dataType')
        (BroadcastShapesF shape shape'))
-&gt; Tensor
     (Or (Gradient RequiresGradient) gradient gradient')
     (Unify (Layout LayoutType) layout layout')
     (Unify (Device (DeviceType Nat)) device device')
     (Unify (DataType DType) dataType dataType')
     (BroadcastShapesF shape shape')
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; IO
     (Tensor
        (Or (Gradient RequiresGradient) gradient gradient')
        (Unify (Layout LayoutType) layout layout')
        (Unify (Device (DeviceType Nat)) device device')
        (Unify (DataType DType) dataType dataType')
        (BroadcastShapesF shape shape'))
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.mul_tt</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679520953"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient' layout' device' dataType' shape'
</span><a href="#local-6989586621679520952"><span class="hs-identifier hs-var">other</span></a></span><span>
</span><span id="line-883"></span><span>
</span><span id="line-884"></span><span class="hs-comment">-- Multiplies each element of the input 'input' with the scalar 'other' and returns a new resulting tensor:</span><span>
</span><span id="line-885"></span><span class="hs-comment">-- \[</span><span>
</span><span id="line-886"></span><span class="hs-comment">-- \mathrm{output}_i = \mathrm{input}_i \times \mathrm{other}.</span><span>
</span><span id="line-887"></span><span class="hs-comment">-- \]</span><span>
</span><span id="line-888"></span><span class="hs-comment">--</span><span>
</span><span id="line-889"></span><span class="hs-comment">-- If 'input' is of the data type 'Float' or 'Double', 'other' should be a real number,</span><span>
</span><span id="line-890"></span><span class="hs-comment">-- otherwise it should be an 'integer'.</span><span>
</span><span id="line-891"></span><span class="hs-comment">-- See 'mul' for a version of this function where</span><span>
</span><span id="line-892"></span><span class="hs-comment">-- the 'other' input is a tensor.</span><span>
</span><span id="line-893"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#mulScalar"><span class="hs-identifier hs-type">mulScalar</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-894"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679520949"><span class="annot"><a href="#local-6989586621679520949"><span class="hs-identifier hs-type">other</span></a></span></span><span> </span><span id="local-6989586621679520948"><span class="annot"><a href="#local-6989586621679520948"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679520947"><span class="annot"><a href="#local-6989586621679520947"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679520946"><span class="annot"><a href="#local-6989586621679520946"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679520945"><span class="annot"><a href="#local-6989586621679520945"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679520944"><span class="annot"><a href="#local-6989586621679520944"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-895"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Scalar.html#Scalar"><span class="hs-identifier hs-type">Scalar</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520949"><span class="hs-identifier hs-type">other</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-896"></span><span>  </span><span class="hs-comment">-- | tensor input</span><span>
</span><span id="line-897"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520948"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520947"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520946"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520945"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520944"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-898"></span><span>  </span><span class="hs-comment">-- | scalar other input</span><span>
</span><span id="line-899"></span><span>  </span><span class="annot"><a href="#local-6989586621679520949"><span class="hs-identifier hs-type">other</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-900"></span><span>  </span><span class="hs-comment">-- | tensor output</span><span>
</span><span id="line-901"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520948"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520947"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520946"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520945"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520944"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-902"></span><span id="local-6989586621679520943"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679520943"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span id="mulScalar"><span class="annot"><span class="annottext">mulScalar :: Tensor gradient layout device dataType shape
-&gt; other -&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#mulScalar"><span class="hs-operator hs-var hs-var">`mulScalar`</span></a></span></span><span> </span><span id="local-6989586621679520942"><span class="annot"><span class="annottext">other
</span><a href="#local-6989586621679520942"><span class="hs-identifier hs-var">other</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ForeignPtr Scalar -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; other
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr Scalar -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.mul_ts</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679520943"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">other
</span><a href="#local-6989586621679520942"><span class="hs-identifier hs-var">other</span></a></span><span>
</span><span id="line-903"></span><span>
</span><span id="line-904"></span><span class="hs-comment">-- | Computes the multivariate log-gamma function with dimension 'p' element-wise, given by</span><span>
</span><span id="line-905"></span><span class="hs-comment">-- \[</span><span>
</span><span id="line-906"></span><span class="hs-comment">-- \log(\Gamma_p(\mathrm{input})) = C + \sum_{i=1}^{p} \log \left(\Gamma\left(\mathrm{input} - \frac{i-1}{2}\right)\right)</span><span>
</span><span id="line-907"></span><span class="hs-comment">-- \]</span><span>
</span><span id="line-908"></span><span class="hs-comment">-- where \(C = \log(\pi) \times \frac{p(p-1)}{4}\) and \(\Gamma(\dot)\) is the gamma function.</span><span>
</span><span id="line-909"></span><span class="hs-comment">--</span><span>
</span><span id="line-910"></span><span class="hs-comment">-- All elements of the input tensor must be greater than \(\frac{p-1}{2}\).</span><span>
</span><span id="line-911"></span><span class="hs-comment">-- Otherwise, the computation is halted and an exception is thrown.</span><span>
</span><span id="line-912"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#mvlgamma"><span class="hs-identifier hs-type">mvlgamma</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-913"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679520939"><span class="annot"><a href="#local-6989586621679520939"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679520938"><span class="annot"><a href="#local-6989586621679520938"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679520937"><span class="annot"><a href="#local-6989586621679520937"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679520936"><span class="annot"><a href="#local-6989586621679520936"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679520935"><span class="annot"><a href="#local-6989586621679520935"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-914"></span><span>  </span><span class="hs-comment">-- | the number of dimensions 'p'</span><span>
</span><span id="line-915"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-916"></span><span>  </span><span class="hs-comment">-- | the input tensor to compute the the multivariate log-gamma function for</span><span>
</span><span id="line-917"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520939"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520938"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520937"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520936"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520935"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-918"></span><span>  </span><span class="hs-comment">-- | the output tensor</span><span>
</span><span id="line-919"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520939"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520938"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520937"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520936"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520935"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-920"></span><span id="mvlgamma"><span class="annot"><span class="annottext">mvlgamma :: Int
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#mvlgamma"><span class="hs-identifier hs-var hs-var">mvlgamma</span></a></span></span><span> </span><span id="local-6989586621679520934"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679520934"><span class="hs-identifier hs-var">p</span></a></span></span><span> </span><span id="local-6989586621679520933"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679520933"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; Int64 -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; Int
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; Int64 -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.mvlgamma_tl</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679520933"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679520934"><span class="hs-identifier hs-var">p</span></a></span><span>
</span><span id="line-921"></span><span>
</span><span id="line-922"></span><span class="hs-comment">-- | Returns a new tensor with the negative of the elements of 'input':</span><span>
</span><span id="line-923"></span><span class="hs-comment">-- \[</span><span>
</span><span id="line-924"></span><span class="hs-comment">-- \mathrm{output}_i = - \mathrm{input}_i.</span><span>
</span><span id="line-925"></span><span class="hs-comment">-- \]</span><span>
</span><span id="line-926"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#neg"><span class="hs-identifier hs-type">neg</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-927"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679520930"><span class="annot"><a href="#local-6989586621679520930"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679520929"><span class="annot"><a href="#local-6989586621679520929"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679520928"><span class="annot"><a href="#local-6989586621679520928"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679520927"><span class="annot"><a href="#local-6989586621679520927"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679520926"><span class="annot"><a href="#local-6989586621679520926"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-928"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-929"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520930"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520929"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520928"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520927"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520926"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-930"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-931"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520930"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520929"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520928"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520927"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520926"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-932"></span><span id="neg"><span class="annot"><span class="annottext">neg :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#neg"><span class="hs-identifier hs-var hs-var">neg</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; (Tensor gradient layout device dataType shape
    -&gt; IO (Tensor gradient layout device dataType shape))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.neg_t</span></a></span><span>
</span><span id="line-933"></span><span>
</span><span id="line-934"></span><span class="hs-comment">-- | Computes the \(n\)-th derivative of the digamma function \(\psi\) on the 'input',</span><span>
</span><span id="line-935"></span><span class="hs-comment">-- where \(n \ge 0\).</span><span>
</span><span id="line-936"></span><span class="hs-comment">-- \(n\) is called the order of the polygamma function \(\psi^{(n)}\)</span><span>
</span><span id="line-937"></span><span class="hs-comment">-- that is defined as:</span><span>
</span><span id="line-938"></span><span class="hs-comment">-- \[</span><span>
</span><span id="line-939"></span><span class="hs-comment">-- \psi^{(n)}(\mathrm{input}) = \frac{d^{(n)}}{d\mathrm{input}^{(n)}} \psi(\mathrm{input})</span><span>
</span><span id="line-940"></span><span class="hs-comment">-- \]</span><span>
</span><span id="line-941"></span><span class="hs-comment">-- where \(\psi(\mathrm{input}) = \log(\Gamma(\mathrm{input}))\).</span><span>
</span><span id="line-942"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#polygamma"><span class="hs-identifier hs-type">polygamma</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-943"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679520923"><span class="annot"><a href="#local-6989586621679520923"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679520922"><span class="annot"><a href="#local-6989586621679520922"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679520921"><span class="annot"><a href="#local-6989586621679520921"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679520920"><span class="annot"><a href="#local-6989586621679520920"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679520919"><span class="annot"><a href="#local-6989586621679520919"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-944"></span><span>  </span><span class="hs-comment">-- | the order of the polygamma function</span><span>
</span><span id="line-945"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-946"></span><span>  </span><span class="hs-comment">-- | the input tensor</span><span>
</span><span id="line-947"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520923"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520922"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520921"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520920"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520919"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-948"></span><span>  </span><span class="hs-comment">-- | the output tensor</span><span>
</span><span id="line-949"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520923"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520922"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520921"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520920"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520919"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-950"></span><span id="polygamma"><span class="annot"><span class="annottext">polygamma :: Int
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#polygamma"><span class="hs-identifier hs-var hs-var">polygamma</span></a></span></span><span> </span><span id="local-6989586621679520918"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679520918"><span class="hs-identifier hs-var">n</span></a></span></span><span> </span><span id="local-6989586621679520917"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679520917"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(Int64 -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Int
-&gt; Tensor gradient layout device dataType shape
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast2</span></a></span><span> </span><span class="annot"><span class="annottext">Int64 -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.polygamma_lt</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679520918"><span class="hs-identifier hs-var">n</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679520917"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-951"></span><span>
</span><span id="line-952"></span><span class="hs-comment">-- | Takes the power of each element in the tensor 'input'</span><span>
</span><span id="line-953"></span><span class="hs-comment">-- with the corresponding element in the tensor 'exponent' and</span><span>
</span><span id="line-954"></span><span class="hs-comment">-- returns a tensor with the result.</span><span>
</span><span id="line-955"></span><span class="hs-comment">--</span><span>
</span><span id="line-956"></span><span class="hs-comment">-- Note that the 'exponent' and the 'input' must be tensors</span><span>
</span><span id="line-957"></span><span class="hs-comment">-- with broadcastable shapes.</span><span>
</span><span id="line-958"></span><span class="hs-comment">-- See 'powScalar' for a version that takes a scalar 'exponent' as argument</span><span>
</span><span id="line-959"></span><span class="hs-comment">-- and 'powTensor' for a version where the 'input' is a scalar and the 'exponent' a tensor.</span><span>
</span><span id="line-960"></span><span class="hs-comment">--</span><span>
</span><span id="line-961"></span><span class="hs-comment">-- The following operation is applied:</span><span>
</span><span id="line-962"></span><span class="hs-comment">-- \[</span><span>
</span><span id="line-963"></span><span class="hs-comment">-- \mathrm{output}_i = \mathrm{input}_i^{\mathrm{exponent}_i}.</span><span>
</span><span id="line-964"></span><span class="hs-comment">-- \]</span><span>
</span><span id="line-965"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#pow"><span class="hs-identifier hs-type">pow</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-966"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679520914"><span class="annot"><a href="#local-6989586621679520914"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679520913"><span class="annot"><a href="#local-6989586621679520913"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679520912"><span class="annot"><a href="#local-6989586621679520912"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679520911"><span class="annot"><a href="#local-6989586621679520911"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679520910"><span class="annot"><a href="#local-6989586621679520910"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679520909"><span class="annot"><a href="#local-6989586621679520909"><span class="hs-identifier hs-type">gradient'</span></a></span></span><span> </span><span id="local-6989586621679520908"><span class="annot"><a href="#local-6989586621679520908"><span class="hs-identifier hs-type">layout'</span></a></span></span><span> </span><span id="local-6989586621679520907"><span class="annot"><a href="#local-6989586621679520907"><span class="hs-identifier hs-type">device'</span></a></span></span><span> </span><span id="local-6989586621679520906"><span class="annot"><a href="#local-6989586621679520906"><span class="hs-identifier hs-type">dataType'</span></a></span></span><span> </span><span id="local-6989586621679520905"><span class="annot"><a href="#local-6989586621679520905"><span class="hs-identifier hs-type">shape'</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-967"></span><span>  </span><span class="hs-comment">-- | tensor input</span><span>
</span><span id="line-968"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520909"><span class="hs-identifier hs-type">gradient'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520908"><span class="hs-identifier hs-type">layout'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520907"><span class="hs-identifier hs-type">device'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520906"><span class="hs-identifier hs-type">dataType'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520905"><span class="hs-identifier hs-type">shape'</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-969"></span><span>  </span><span class="hs-comment">-- | tensor exponent</span><span>
</span><span id="line-970"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520914"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520913"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520912"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520911"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520910"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-971"></span><span>  </span><span class="hs-comment">-- | tensor output</span><span>
</span><span id="line-972"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-973"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679520914"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520909"><span class="hs-identifier hs-type">gradient'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-974"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679520913"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520908"><span class="hs-identifier hs-type">layout'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-975"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679520912"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520907"><span class="hs-identifier hs-type">device'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-976"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679520911"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520906"><span class="hs-identifier hs-type">dataType'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-977"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#BroadcastShapesF"><span class="hs-identifier hs-type">BroadcastShapesF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520910"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520905"><span class="hs-identifier hs-type">shape'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-978"></span><span id="local-6989586621679520904"><span class="annot"><span class="annottext">Tensor gradient' layout' device' dataType' shape'
</span><a href="#local-6989586621679520904"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span id="pow"><span class="annot"><span class="annottext">pow :: Tensor gradient' layout' device' dataType' shape'
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor
     (gradient &lt;|&gt; gradient')
     (layout &lt;+&gt; layout')
     (device &lt;+&gt; device')
     (dataType &lt;+&gt; dataType')
     (BroadcastShapesF shape shape')
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#pow"><span class="hs-operator hs-var hs-var">`pow`</span></a></span></span><span> </span><span id="local-6989586621679520903"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679520903"><span class="hs-identifier hs-var">exponent'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO
  (Tensor
     (Or (Gradient RequiresGradient) gradient gradient')
     (Unify (Layout LayoutType) layout layout')
     (Unify (Device (DeviceType Nat)) device device')
     (Unify (DataType DType) dataType dataType')
     (BroadcastShapesF shape shape'))
-&gt; Tensor
     (Or (Gradient RequiresGradient) gradient gradient')
     (Unify (Layout LayoutType) layout layout')
     (Unify (Device (DeviceType Nat)) device device')
     (Unify (DataType DType) dataType dataType')
     (BroadcastShapesF shape shape')
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO
   (Tensor
      (Or (Gradient RequiresGradient) gradient gradient')
      (Unify (Layout LayoutType) layout layout')
      (Unify (Device (DeviceType Nat)) device device')
      (Unify (DataType DType) dataType dataType')
      (BroadcastShapesF shape shape'))
 -&gt; Tensor
      (Or (Gradient RequiresGradient) gradient gradient')
      (Unify (Layout LayoutType) layout layout')
      (Unify (Device (DeviceType Nat)) device device')
      (Unify (DataType DType) dataType dataType')
      (BroadcastShapesF shape shape'))
-&gt; IO
     (Tensor
        (Or (Gradient RequiresGradient) gradient gradient')
        (Unify (Layout LayoutType) layout layout')
        (Unify (Device (DeviceType Nat)) device device')
        (Unify (DataType DType) dataType dataType')
        (BroadcastShapesF shape shape'))
-&gt; Tensor
     (Or (Gradient RequiresGradient) gradient gradient')
     (Unify (Layout LayoutType) layout layout')
     (Unify (Device (DeviceType Nat)) device device')
     (Unify (DataType DType) dataType dataType')
     (BroadcastShapesF shape shape')
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; Tensor gradient layout device dataType shape
-&gt; IO
     (Tensor
        (Or (Gradient RequiresGradient) gradient gradient')
        (Unify (Layout LayoutType) layout layout')
        (Unify (Device (DeviceType Nat)) device device')
        (Unify (DataType DType) dataType dataType')
        (BroadcastShapesF shape shape'))
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.pow_tt</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient' layout' device' dataType' shape'
</span><a href="#local-6989586621679520904"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679520903"><span class="hs-identifier hs-var">exponent'</span></a></span><span>
</span><span id="line-979"></span><span>
</span><span id="line-980"></span><span class="hs-comment">-- | Takes the power of each element in the tensor 'input' with the scalar 'exponent' and</span><span>
</span><span id="line-981"></span><span class="hs-comment">-- returns a tensor with the result.</span><span>
</span><span id="line-982"></span><span class="hs-comment">--</span><span>
</span><span id="line-983"></span><span class="hs-comment">-- Note that the 'exponent' is a scalar.</span><span>
</span><span id="line-984"></span><span class="hs-comment">-- See 'pow' for a version that takes a tensor 'exponent' as argument</span><span>
</span><span id="line-985"></span><span class="hs-comment">-- and 'powTensor' for a version where the 'input' is a scalar and the 'exponent' a tensor.</span><span>
</span><span id="line-986"></span><span class="hs-comment">--</span><span>
</span><span id="line-987"></span><span class="hs-comment">-- The following operation is applied:</span><span>
</span><span id="line-988"></span><span class="hs-comment">-- \[</span><span>
</span><span id="line-989"></span><span class="hs-comment">-- \mathrm{output}_i = \mathrm{input}_i^{\mathrm{exponent}}.</span><span>
</span><span id="line-990"></span><span class="hs-comment">-- \]</span><span>
</span><span id="line-991"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#powScalar"><span class="hs-identifier hs-type">powScalar</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-992"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679520900"><span class="annot"><a href="#local-6989586621679520900"><span class="hs-identifier hs-type">exponent</span></a></span></span><span> </span><span id="local-6989586621679520899"><span class="annot"><a href="#local-6989586621679520899"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679520898"><span class="annot"><a href="#local-6989586621679520898"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679520897"><span class="annot"><a href="#local-6989586621679520897"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679520896"><span class="annot"><a href="#local-6989586621679520896"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679520895"><span class="annot"><a href="#local-6989586621679520895"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-993"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Scalar.html#Scalar"><span class="hs-identifier hs-type">Scalar</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520900"><span class="hs-identifier hs-type">exponent</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-994"></span><span>  </span><span class="hs-comment">-- | tensor input</span><span>
</span><span id="line-995"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520899"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520898"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520897"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520896"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520895"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-996"></span><span>  </span><span class="hs-comment">-- | scalar exponent</span><span>
</span><span id="line-997"></span><span>  </span><span class="annot"><a href="#local-6989586621679520900"><span class="hs-identifier hs-type">exponent</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-998"></span><span>  </span><span class="hs-comment">-- | tensor output</span><span>
</span><span id="line-999"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520899"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520898"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520897"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520896"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520895"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-1000"></span><span id="local-6989586621679520894"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679520894"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span id="powScalar"><span class="annot"><span class="annottext">powScalar :: Tensor gradient layout device dataType shape
-&gt; exponent -&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#powScalar"><span class="hs-operator hs-var hs-var">`powScalar`</span></a></span></span><span> </span><span id="local-6989586621679520893"><span class="annot"><span class="annottext">exponent
</span><a href="#local-6989586621679520893"><span class="hs-identifier hs-var">exponent'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ForeignPtr Scalar -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; exponent
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr Scalar -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.pow_ts</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679520894"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">exponent
</span><a href="#local-6989586621679520893"><span class="hs-identifier hs-var">exponent'</span></a></span><span>
</span><span id="line-1001"></span><span>
</span><span id="line-1002"></span><span class="hs-comment">-- | Takes the power of the scalar 'input' with each element in the tensor 'exponent' and</span><span>
</span><span id="line-1003"></span><span class="hs-comment">-- returns a tensor with the result.</span><span>
</span><span id="line-1004"></span><span class="hs-comment">--</span><span>
</span><span id="line-1005"></span><span class="hs-comment">-- Note that the 'exponent' is a tensor while the 'input' is a scalar.</span><span>
</span><span id="line-1006"></span><span class="hs-comment">-- See 'pow' for a version that takes a tensor 'input' as argument</span><span>
</span><span id="line-1007"></span><span class="hs-comment">-- and 'powScalar' for a version where the 'input' is a tensor and the 'exponent' a scalar.</span><span>
</span><span id="line-1008"></span><span class="hs-comment">--</span><span>
</span><span id="line-1009"></span><span class="hs-comment">-- The following operation is applied:</span><span>
</span><span id="line-1010"></span><span class="hs-comment">-- \[</span><span>
</span><span id="line-1011"></span><span class="hs-comment">-- \mathrm{output}_i = \mathrm{input}^{\mathrm{exponent}_i}.</span><span>
</span><span id="line-1012"></span><span class="hs-comment">-- \]</span><span>
</span><span id="line-1013"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#powTensor"><span class="hs-identifier hs-type">powTensor</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-1014"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679520890"><span class="annot"><a href="#local-6989586621679520890"><span class="hs-identifier hs-type">input</span></a></span></span><span> </span><span id="local-6989586621679520889"><span class="annot"><a href="#local-6989586621679520889"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679520888"><span class="annot"><a href="#local-6989586621679520888"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679520887"><span class="annot"><a href="#local-6989586621679520887"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679520886"><span class="annot"><a href="#local-6989586621679520886"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679520885"><span class="annot"><a href="#local-6989586621679520885"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-1015"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Scalar.html#Scalar"><span class="hs-identifier hs-type">Scalar</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520890"><span class="hs-identifier hs-type">input</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-1016"></span><span>  </span><span class="hs-comment">-- | scalar input</span><span>
</span><span id="line-1017"></span><span>  </span><span class="annot"><a href="#local-6989586621679520890"><span class="hs-identifier hs-type">input</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1018"></span><span>  </span><span class="hs-comment">-- | tensor exponent</span><span>
</span><span id="line-1019"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520889"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520888"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520887"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520886"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520885"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1020"></span><span>  </span><span class="hs-comment">-- | tensor output</span><span>
</span><span id="line-1021"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520889"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520888"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520887"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520886"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520885"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-1022"></span><span id="local-6989586621679520884"><span class="annot"><span class="annottext">input
</span><a href="#local-6989586621679520884"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span id="powTensor"><span class="annot"><span class="annottext">powTensor :: input
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#powTensor"><span class="hs-operator hs-var hs-var">`powTensor`</span></a></span></span><span> </span><span id="local-6989586621679520883"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679520883"><span class="hs-identifier hs-var">exponent'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Scalar -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; input
-&gt; Tensor gradient layout device dataType shape
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Scalar -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.pow_st</span></a></span><span> </span><span class="annot"><span class="annottext">input
</span><a href="#local-6989586621679520884"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679520883"><span class="hs-identifier hs-var">exponent'</span></a></span><span>
</span><span id="line-1023"></span><span>
</span><span id="line-1024"></span><span class="hs-comment">-- | Returns a new tensor with each of the elements of 'input'</span><span>
</span><span id="line-1025"></span><span class="hs-comment">-- converted from angles in radians to degrees.</span><span>
</span><span id="line-1026"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#rad2deg"><span class="hs-identifier hs-type">rad2deg</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-1027"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679520880"><span class="annot"><a href="#local-6989586621679520880"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679520879"><span class="annot"><a href="#local-6989586621679520879"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679520878"><span class="annot"><a href="#local-6989586621679520878"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679520877"><span class="annot"><a href="#local-6989586621679520877"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679520876"><span class="annot"><a href="#local-6989586621679520876"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-1028"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-1029"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520880"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520879"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520878"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520877"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520876"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1030"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-1031"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520880"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520879"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520878"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520877"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520876"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-1032"></span><span id="rad2deg"><span class="annot"><span class="annottext">rad2deg :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#rad2deg"><span class="hs-identifier hs-var hs-var">rad2deg</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; (Tensor gradient layout device dataType shape
    -&gt; IO (Tensor gradient layout device dataType shape))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.rad2deg_t</span></a></span><span>
</span><span id="line-1033"></span><span>
</span><span id="line-1034"></span><span class="hs-comment">-- | Returns a new tensor with the reciprocal of the elements of 'input':</span><span>
</span><span id="line-1035"></span><span class="hs-comment">-- \[</span><span>
</span><span id="line-1036"></span><span class="hs-comment">-- \mathrm{output}_i = \frac{1}{\mathrm{input}_i}</span><span>
</span><span id="line-1037"></span><span class="hs-comment">-- \]</span><span>
</span><span id="line-1038"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#reciprocal"><span class="hs-identifier hs-type">reciprocal</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-1039"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679520873"><span class="annot"><a href="#local-6989586621679520873"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679520872"><span class="annot"><a href="#local-6989586621679520872"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679520871"><span class="annot"><a href="#local-6989586621679520871"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679520870"><span class="annot"><a href="#local-6989586621679520870"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679520869"><span class="annot"><a href="#local-6989586621679520869"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-1040"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-1041"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520873"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520872"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520871"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520870"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520869"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1042"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-1043"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520873"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520872"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520871"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520870"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520869"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-1044"></span><span id="reciprocal"><span class="annot"><span class="annottext">reciprocal :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#reciprocal"><span class="hs-identifier hs-var hs-var">reciprocal</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; (Tensor gradient layout device dataType shape
    -&gt; IO (Tensor gradient layout device dataType shape))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.reciprocal_t</span></a></span><span>
</span><span id="line-1045"></span><span>
</span><span id="line-1046"></span><span class="hs-comment">-- | Computes the element-wise remainder of division.</span><span>
</span><span id="line-1047"></span><span class="hs-comment">--</span><span>
</span><span id="line-1048"></span><span class="hs-comment">-- The dividend and divisor may contain integer and floating point numbers.</span><span>
</span><span id="line-1049"></span><span class="hs-comment">-- The remainder has the same sign as the divisor other.</span><span>
</span><span id="line-1050"></span><span class="hs-comment">--</span><span>
</span><span id="line-1051"></span><span class="hs-comment">-- When other is a tensor, the shapes of input and other must be broadcastable.</span><span>
</span><span id="line-1052"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#remainder"><span class="hs-identifier hs-type">remainder</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-1053"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679520866"><span class="annot"><a href="#local-6989586621679520866"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679520865"><span class="annot"><a href="#local-6989586621679520865"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679520864"><span class="annot"><a href="#local-6989586621679520864"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679520863"><span class="annot"><a href="#local-6989586621679520863"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679520862"><span class="annot"><a href="#local-6989586621679520862"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-1054"></span><span>  </span><span class="hs-comment">-- | dividend</span><span>
</span><span id="line-1055"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520866"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520865"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520864"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520863"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520862"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1056"></span><span>  </span><span class="hs-comment">-- | divisor</span><span>
</span><span id="line-1057"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520866"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520865"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520864"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520863"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520862"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1058"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520866"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520865"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520864"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520863"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520862"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-1059"></span><span id="local-6989586621679520861"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679520861"><span class="hs-identifier hs-var">dividend</span></a></span></span><span> </span><span id="remainder"><span class="annot"><span class="annottext">remainder :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#remainder"><span class="hs-operator hs-var hs-var">`remainder`</span></a></span></span><span> </span><span id="local-6989586621679520860"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679520860"><span class="hs-identifier hs-var">divisor</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.remainder_tt</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679520861"><span class="hs-identifier hs-var">dividend</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679520860"><span class="hs-identifier hs-var">divisor</span></a></span><span>
</span><span id="line-1060"></span><span>
</span><span id="line-1061"></span><span class="hs-comment">-- | Returns a new tensor with each of the elements of 'input' rounded to the closest integer.</span><span>
</span><span id="line-1062"></span><span class="hs-comment">-- Note that the data type is unchanged.</span><span>
</span><span id="line-1063"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#round"><span class="hs-identifier hs-type">round</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-1064"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679520857"><span class="annot"><a href="#local-6989586621679520857"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679520856"><span class="annot"><a href="#local-6989586621679520856"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679520855"><span class="annot"><a href="#local-6989586621679520855"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679520854"><span class="annot"><a href="#local-6989586621679520854"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679520853"><span class="annot"><a href="#local-6989586621679520853"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-1065"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-1066"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520857"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520856"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520855"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520854"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520853"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1067"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-1068"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520857"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520856"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520855"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520854"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520853"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-1069"></span><span id="round"><span class="annot"><span class="annottext">round :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#round"><span class="hs-identifier hs-var hs-var">round</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; (Tensor gradient layout device dataType shape
    -&gt; IO (Tensor gradient layout device dataType shape))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.round_t</span></a></span><span>
</span><span id="line-1070"></span><span>
</span><span id="line-1071"></span><span class="hs-comment">-- | Returns a new tensor with the reciprocal of the square-root of</span><span>
</span><span id="line-1072"></span><span class="hs-comment">-- each of the elements of 'input':</span><span>
</span><span id="line-1073"></span><span class="hs-comment">-- \[</span><span>
</span><span id="line-1074"></span><span class="hs-comment">-- \mathrm{output}_i = \frac{1}{\sqrt{\mathrm{input}_i}}.</span><span>
</span><span id="line-1075"></span><span class="hs-comment">-- \]</span><span>
</span><span id="line-1076"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#rsqrt"><span class="hs-identifier hs-type">rsqrt</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-1077"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679520850"><span class="annot"><a href="#local-6989586621679520850"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679520849"><span class="annot"><a href="#local-6989586621679520849"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679520848"><span class="annot"><a href="#local-6989586621679520848"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679520847"><span class="annot"><a href="#local-6989586621679520847"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679520846"><span class="annot"><a href="#local-6989586621679520846"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-1078"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-1079"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520850"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520849"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520848"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520847"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520846"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1080"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-1081"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520850"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520849"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520848"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520847"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520846"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-1082"></span><span id="rsqrt"><span class="annot"><span class="annottext">rsqrt :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#rsqrt"><span class="hs-identifier hs-var hs-var">rsqrt</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; (Tensor gradient layout device dataType shape
    -&gt; IO (Tensor gradient layout device dataType shape))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.rsqrt_t</span></a></span><span>
</span><span id="line-1083"></span><span>
</span><span id="line-1084"></span><span class="hs-comment">-- | Returns a new tensor with the sigmoid of the elements of 'input':</span><span>
</span><span id="line-1085"></span><span class="hs-comment">-- \[</span><span>
</span><span id="line-1086"></span><span class="hs-comment">-- \mathrm{output}_i = \frac{1}{1 + \exp \left(-\mathrm{input}_i\right)}</span><span>
</span><span id="line-1087"></span><span class="hs-comment">-- \]</span><span>
</span><span id="line-1088"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#sigmoid"><span class="hs-identifier hs-type">sigmoid</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-1089"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679520843"><span class="annot"><a href="#local-6989586621679520843"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679520842"><span class="annot"><a href="#local-6989586621679520842"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679520841"><span class="annot"><a href="#local-6989586621679520841"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679520840"><span class="annot"><a href="#local-6989586621679520840"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679520839"><span class="annot"><a href="#local-6989586621679520839"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-1090"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-1091"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520843"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520842"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520841"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520840"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520839"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1092"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-1093"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520843"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520842"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520841"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520840"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520839"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-1094"></span><span id="sigmoid"><span class="annot"><span class="annottext">sigmoid :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#sigmoid"><span class="hs-identifier hs-var hs-var">sigmoid</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; (Tensor gradient layout device dataType shape
    -&gt; IO (Tensor gradient layout device dataType shape))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.sigmoid_t</span></a></span><span>
</span><span id="line-1095"></span><span>
</span><span id="line-1096"></span><span class="hs-comment">-- | Returns a new tensor with the signs of the elements of 'input':</span><span>
</span><span id="line-1097"></span><span class="hs-comment">-- \[</span><span>
</span><span id="line-1098"></span><span class="hs-comment">-- \mathrm{output}_i = \begin{cases}</span><span>
</span><span id="line-1099"></span><span class="hs-comment">--   -1 &amp; \text{if } \mathrm{input}_i &lt; 0 \\</span><span>
</span><span id="line-1100"></span><span class="hs-comment">--   0  &amp; \text{if } \mathrm{input}_i = 0 \\</span><span>
</span><span id="line-1101"></span><span class="hs-comment">--   1  &amp; \text{if } \mathrm{input}_i &gt; 0.</span><span>
</span><span id="line-1102"></span><span class="hs-comment">-- \end{cases}</span><span>
</span><span id="line-1103"></span><span class="hs-comment">-- \]</span><span>
</span><span id="line-1104"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#sign"><span class="hs-identifier hs-type">sign</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-1105"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679520836"><span class="annot"><a href="#local-6989586621679520836"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679520835"><span class="annot"><a href="#local-6989586621679520835"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679520834"><span class="annot"><a href="#local-6989586621679520834"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679520833"><span class="annot"><a href="#local-6989586621679520833"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679520832"><span class="annot"><a href="#local-6989586621679520832"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-1106"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-1107"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520836"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520835"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520834"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520833"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520832"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1108"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-1109"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520836"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520835"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520834"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520833"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520832"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-1110"></span><span id="sign"><span class="annot"><span class="annottext">sign :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#sign"><span class="hs-identifier hs-var hs-var">sign</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; (Tensor gradient layout device dataType shape
    -&gt; IO (Tensor gradient layout device dataType shape))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.sign_t</span></a></span><span>
</span><span id="line-1111"></span><span>
</span><span id="line-1112"></span><span class="hs-comment">-- | Returns a new tensor with the sine of the elements of 'input':</span><span>
</span><span id="line-1113"></span><span class="hs-comment">-- \[</span><span>
</span><span id="line-1114"></span><span class="hs-comment">-- \mathrm{output}_i = \sin \left(\mathrm{input}_i\right).</span><span>
</span><span id="line-1115"></span><span class="hs-comment">-- \]</span><span>
</span><span id="line-1116"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#sin"><span class="hs-identifier hs-type">sin</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-1117"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679520829"><span class="annot"><a href="#local-6989586621679520829"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679520828"><span class="annot"><a href="#local-6989586621679520828"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679520827"><span class="annot"><a href="#local-6989586621679520827"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679520826"><span class="annot"><a href="#local-6989586621679520826"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679520825"><span class="annot"><a href="#local-6989586621679520825"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-1118"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-1119"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520829"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520828"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520827"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520826"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520825"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1120"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-1121"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520829"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520828"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520827"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520826"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520825"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-1122"></span><span id="sin"><span class="annot"><span class="annottext">sin :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#sin"><span class="hs-identifier hs-var hs-var">sin</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; (Tensor gradient layout device dataType shape
    -&gt; IO (Tensor gradient layout device dataType shape))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.sin_t</span></a></span><span>
</span><span id="line-1123"></span><span>
</span><span id="line-1124"></span><span class="hs-comment">-- | Returns a new tensor with the hyperbolic sine of the elements of 'input':</span><span>
</span><span id="line-1125"></span><span class="hs-comment">-- \[</span><span>
</span><span id="line-1126"></span><span class="hs-comment">-- \mathrm{output}_i = \sinh \left(\mathrm{input}_i\right).</span><span>
</span><span id="line-1127"></span><span class="hs-comment">-- \]</span><span>
</span><span id="line-1128"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#sinh"><span class="hs-identifier hs-type">sinh</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-1129"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679520822"><span class="annot"><a href="#local-6989586621679520822"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679520821"><span class="annot"><a href="#local-6989586621679520821"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679520820"><span class="annot"><a href="#local-6989586621679520820"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679520819"><span class="annot"><a href="#local-6989586621679520819"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679520818"><span class="annot"><a href="#local-6989586621679520818"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-1130"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-1131"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520822"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520821"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520820"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520819"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520818"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1132"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-1133"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520822"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520821"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520820"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520819"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520818"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-1134"></span><span id="sinh"><span class="annot"><span class="annottext">sinh :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#sinh"><span class="hs-identifier hs-var hs-var">sinh</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; (Tensor gradient layout device dataType shape
    -&gt; IO (Tensor gradient layout device dataType shape))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.sinh_t</span></a></span><span>
</span><span id="line-1135"></span><span>
</span><span id="line-1136"></span><span class="hs-comment">-- | Element-wise subtraction of one tensor from another:</span><span>
</span><span id="line-1137"></span><span class="hs-comment">-- \[</span><span>
</span><span id="line-1138"></span><span class="hs-comment">-- \mathrm{output}_i = \mathrm{input}_i - \mathrm{other}_i.</span><span>
</span><span id="line-1139"></span><span class="hs-comment">-- \]</span><span>
</span><span id="line-1140"></span><span class="hs-comment">-- The result is returned as a new tensor.</span><span>
</span><span id="line-1141"></span><span class="hs-comment">--</span><span>
</span><span id="line-1142"></span><span class="hs-comment">-- The shape of 'other' must be broadcastable with the shape of 'input'.</span><span>
</span><span id="line-1143"></span><span class="hs-comment">-- See 'subScalar' for a version of this function where</span><span>
</span><span id="line-1144"></span><span class="hs-comment">-- the 'other' input is a scalar.</span><span>
</span><span id="line-1145"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#sub"><span class="hs-identifier hs-type">sub</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-1146"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679520815"><span class="annot"><a href="#local-6989586621679520815"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679520814"><span class="annot"><a href="#local-6989586621679520814"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679520813"><span class="annot"><a href="#local-6989586621679520813"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679520812"><span class="annot"><a href="#local-6989586621679520812"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679520811"><span class="annot"><a href="#local-6989586621679520811"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679520810"><span class="annot"><a href="#local-6989586621679520810"><span class="hs-identifier hs-type">gradient'</span></a></span></span><span> </span><span id="local-6989586621679520809"><span class="annot"><a href="#local-6989586621679520809"><span class="hs-identifier hs-type">layout'</span></a></span></span><span> </span><span id="local-6989586621679520808"><span class="annot"><a href="#local-6989586621679520808"><span class="hs-identifier hs-type">device'</span></a></span></span><span> </span><span id="local-6989586621679520807"><span class="annot"><a href="#local-6989586621679520807"><span class="hs-identifier hs-type">dataType'</span></a></span></span><span> </span><span id="local-6989586621679520806"><span class="annot"><a href="#local-6989586621679520806"><span class="hs-identifier hs-type">shape'</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-1147"></span><span>  </span><span class="hs-comment">-- | input tensor</span><span>
</span><span id="line-1148"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520815"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520814"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520813"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520812"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520811"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1149"></span><span>  </span><span class="hs-comment">-- | other tensor</span><span>
</span><span id="line-1150"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520810"><span class="hs-identifier hs-type">gradient'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520809"><span class="hs-identifier hs-type">layout'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520808"><span class="hs-identifier hs-type">device'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520807"><span class="hs-identifier hs-type">dataType'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520806"><span class="hs-identifier hs-type">shape'</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1151"></span><span>  </span><span class="hs-comment">-- | output tensor</span><span>
</span><span id="line-1152"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-1153"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679520815"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520815"><span class="hs-identifier hs-type">gradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-1154"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679520814"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520809"><span class="hs-identifier hs-type">layout'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-1155"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679520813"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520808"><span class="hs-identifier hs-type">device'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-1156"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679520812"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520807"><span class="hs-identifier hs-type">dataType'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-1157"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#BroadcastShapesF"><span class="hs-identifier hs-type">BroadcastShapesF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520811"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520806"><span class="hs-identifier hs-type">shape'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-1158"></span><span id="local-6989586621679520805"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679520805"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span id="sub"><span class="annot"><span class="annottext">sub :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; Tensor
     (gradient &lt;|&gt; gradient)
     (layout &lt;+&gt; layout')
     (device &lt;+&gt; device')
     (dataType &lt;+&gt; dataType')
     (BroadcastShapesF shape shape')
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#sub"><span class="hs-operator hs-var hs-var">`sub`</span></a></span></span><span> </span><span id="local-6989586621679520804"><span class="annot"><span class="annottext">Tensor gradient' layout' device' dataType' shape'
</span><a href="#local-6989586621679520804"><span class="hs-identifier hs-var">other</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO
  (Tensor
     gradient
     (Unify (Layout LayoutType) layout layout')
     (Unify (Device (DeviceType Nat)) device device')
     (Unify (DataType DType) dataType dataType')
     (BroadcastShapesF shape shape'))
-&gt; Tensor
     gradient
     (Unify (Layout LayoutType) layout layout')
     (Unify (Device (DeviceType Nat)) device device')
     (Unify (DataType DType) dataType dataType')
     (BroadcastShapesF shape shape')
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO
   (Tensor
      gradient
      (Unify (Layout LayoutType) layout layout')
      (Unify (Device (DeviceType Nat)) device device')
      (Unify (DataType DType) dataType dataType')
      (BroadcastShapesF shape shape'))
 -&gt; Tensor
      gradient
      (Unify (Layout LayoutType) layout layout')
      (Unify (Device (DeviceType Nat)) device device')
      (Unify (DataType DType) dataType dataType')
      (BroadcastShapesF shape shape'))
-&gt; IO
     (Tensor
        gradient
        (Unify (Layout LayoutType) layout layout')
        (Unify (Device (DeviceType Nat)) device device')
        (Unify (DataType DType) dataType dataType')
        (BroadcastShapesF shape shape'))
-&gt; Tensor
     gradient
     (Unify (Layout LayoutType) layout layout')
     (Unify (Device (DeviceType Nat)) device device')
     (Unify (DataType DType) dataType dataType')
     (BroadcastShapesF shape shape')
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; IO
     (Tensor
        gradient
        (Unify (Layout LayoutType) layout layout')
        (Unify (Device (DeviceType Nat)) device device')
        (Unify (DataType DType) dataType dataType')
        (BroadcastShapesF shape shape'))
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.sub_tt</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679520805"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient' layout' device' dataType' shape'
</span><a href="#local-6989586621679520804"><span class="hs-identifier hs-var">other</span></a></span><span>
</span><span id="line-1159"></span><span>
</span><span id="line-1160"></span><span class="hs-comment">-- | Subtracts a scalar 'other' from a tensor 'input':</span><span>
</span><span id="line-1161"></span><span class="hs-comment">-- \[</span><span>
</span><span id="line-1162"></span><span class="hs-comment">-- \mathrm{output}_i = \mathrm{input}_i - \mathrm{other}.</span><span>
</span><span id="line-1163"></span><span class="hs-comment">-- \]</span><span>
</span><span id="line-1164"></span><span class="hs-comment">-- The result is returned as a new tensor.</span><span>
</span><span id="line-1165"></span><span class="hs-comment">-- See 'sub' for a version of this function where</span><span>
</span><span id="line-1166"></span><span class="hs-comment">-- the second argument is a tensor.</span><span>
</span><span id="line-1167"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#subScalar"><span class="hs-identifier hs-type">subScalar</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-1168"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679520801"><span class="annot"><a href="#local-6989586621679520801"><span class="hs-identifier hs-type">other</span></a></span></span><span> </span><span id="local-6989586621679520800"><span class="annot"><a href="#local-6989586621679520800"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679520799"><span class="annot"><a href="#local-6989586621679520799"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679520798"><span class="annot"><a href="#local-6989586621679520798"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679520797"><span class="annot"><a href="#local-6989586621679520797"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679520796"><span class="annot"><a href="#local-6989586621679520796"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-1169"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Scalar.html#Scalar"><span class="hs-identifier hs-type">Scalar</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520801"><span class="hs-identifier hs-type">other</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-1170"></span><span>  </span><span class="hs-comment">-- | input tensor</span><span>
</span><span id="line-1171"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520800"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520799"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520798"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520797"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520796"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1172"></span><span>  </span><span class="hs-comment">-- | input scalar</span><span>
</span><span id="line-1173"></span><span>  </span><span class="annot"><a href="#local-6989586621679520801"><span class="hs-identifier hs-type">other</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1174"></span><span>  </span><span class="hs-comment">-- | output tensor</span><span>
</span><span id="line-1175"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520800"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520799"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520798"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520797"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520796"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-1176"></span><span id="local-6989586621679520795"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679520795"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span id="subScalar"><span class="annot"><span class="annottext">subScalar :: Tensor gradient layout device dataType shape
-&gt; other -&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#subScalar"><span class="hs-operator hs-var hs-var">`subScalar`</span></a></span></span><span> </span><span id="local-6989586621679520794"><span class="annot"><span class="annottext">other
</span><a href="#local-6989586621679520794"><span class="hs-identifier hs-var">other</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ForeignPtr Scalar -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; other
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr Scalar -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.sub_ts</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679520795"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">other
</span><a href="#local-6989586621679520794"><span class="hs-identifier hs-var">other</span></a></span><span>
</span><span id="line-1177"></span><span>
</span><span id="line-1178"></span><span class="hs-comment">-- | Returns a new tensor with the square-root of the elements of 'input':</span><span>
</span><span id="line-1179"></span><span class="hs-comment">-- \[</span><span>
</span><span id="line-1180"></span><span class="hs-comment">-- \mathrm{output}_i = \sqrt{\mathrm{input}_i}.</span><span>
</span><span id="line-1181"></span><span class="hs-comment">-- \]</span><span>
</span><span id="line-1182"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#sqrt"><span class="hs-identifier hs-type">sqrt</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-1183"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679520791"><span class="annot"><a href="#local-6989586621679520791"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679520790"><span class="annot"><a href="#local-6989586621679520790"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679520789"><span class="annot"><a href="#local-6989586621679520789"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679520788"><span class="annot"><a href="#local-6989586621679520788"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679520787"><span class="annot"><a href="#local-6989586621679520787"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-1184"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-1185"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520791"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520790"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520789"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520788"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520787"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1186"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-1187"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520791"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520790"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520789"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520788"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520787"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-1188"></span><span id="sqrt"><span class="annot"><span class="annottext">sqrt :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#sqrt"><span class="hs-identifier hs-var hs-var">sqrt</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; (Tensor gradient layout device dataType shape
    -&gt; IO (Tensor gradient layout device dataType shape))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.sqrt_t</span></a></span><span>
</span><span id="line-1189"></span><span>
</span><span id="line-1190"></span><span class="hs-comment">-- | Returns a new tensor with the square of the elements of 'input':</span><span>
</span><span id="line-1191"></span><span class="hs-comment">-- \[</span><span>
</span><span id="line-1192"></span><span class="hs-comment">-- \mathrm{output}_i = \mathrm{input}_i^2.</span><span>
</span><span id="line-1193"></span><span class="hs-comment">-- \]</span><span>
</span><span id="line-1194"></span><span class="hs-comment">--</span><span>
</span><span id="line-1195"></span><span class="hs-comment">-- See 'pow', 'powScalar', or 'powTensor' for exponentiation with respect to arbitrary exponents.</span><span>
</span><span id="line-1196"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#square"><span class="hs-identifier hs-type">square</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-1197"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679520784"><span class="annot"><a href="#local-6989586621679520784"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679520783"><span class="annot"><a href="#local-6989586621679520783"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679520782"><span class="annot"><a href="#local-6989586621679520782"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679520781"><span class="annot"><a href="#local-6989586621679520781"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679520780"><span class="annot"><a href="#local-6989586621679520780"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-1198"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-1199"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520784"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520783"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520782"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520781"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520780"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1200"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-1201"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520784"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520783"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520782"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520781"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520780"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-1202"></span><span id="square"><span class="annot"><span class="annottext">square :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#square"><span class="hs-identifier hs-var hs-var">square</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; (Tensor gradient layout device dataType shape
    -&gt; IO (Tensor gradient layout device dataType shape))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.square_t</span></a></span><span>
</span><span id="line-1203"></span><span>
</span><span id="line-1204"></span><span class="hs-comment">-- | Returns a new tensor with the tangent of the elements of 'input':</span><span>
</span><span id="line-1205"></span><span class="hs-comment">-- \[</span><span>
</span><span id="line-1206"></span><span class="hs-comment">-- \mathrm{output}_i = \tan \left(\mathrm{input}_i\right).</span><span>
</span><span id="line-1207"></span><span class="hs-comment">-- \]</span><span>
</span><span id="line-1208"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#tan"><span class="hs-identifier hs-type">tan</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-1209"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679520777"><span class="annot"><a href="#local-6989586621679520777"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679520776"><span class="annot"><a href="#local-6989586621679520776"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679520775"><span class="annot"><a href="#local-6989586621679520775"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679520774"><span class="annot"><a href="#local-6989586621679520774"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679520773"><span class="annot"><a href="#local-6989586621679520773"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-1210"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-1211"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520777"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520776"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520775"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520774"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520773"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1212"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-1213"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520777"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520776"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520775"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520774"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520773"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-1214"></span><span id="tan"><span class="annot"><span class="annottext">tan :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#tan"><span class="hs-identifier hs-var hs-var">tan</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; (Tensor gradient layout device dataType shape
    -&gt; IO (Tensor gradient layout device dataType shape))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.tan_t</span></a></span><span>
</span><span id="line-1215"></span><span>
</span><span id="line-1216"></span><span class="hs-comment">-- | Returns a new tensor with the hyperbolic tangent of the elements of 'input':</span><span>
</span><span id="line-1217"></span><span class="hs-comment">-- \[</span><span>
</span><span id="line-1218"></span><span class="hs-comment">-- \mathrm{output}_i = \tanh \left(\mathrm{input}_i\right).</span><span>
</span><span id="line-1219"></span><span class="hs-comment">-- \]</span><span>
</span><span id="line-1220"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#tanh"><span class="hs-identifier hs-type">tanh</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-1221"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679520770"><span class="annot"><a href="#local-6989586621679520770"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679520769"><span class="annot"><a href="#local-6989586621679520769"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679520768"><span class="annot"><a href="#local-6989586621679520768"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679520767"><span class="annot"><a href="#local-6989586621679520767"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679520766"><span class="annot"><a href="#local-6989586621679520766"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-1222"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-1223"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520770"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520769"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520768"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520767"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520766"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1224"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-1225"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520770"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520769"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520768"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520767"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520766"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-1226"></span><span id="tanh"><span class="annot"><span class="annottext">tanh :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#tanh"><span class="hs-identifier hs-var hs-var">tanh</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; (Tensor gradient layout device dataType shape
    -&gt; IO (Tensor gradient layout device dataType shape))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.tanh_t</span></a></span><span>
</span><span id="line-1227"></span><span>
</span><span id="line-1228"></span><span class="hs-comment">-- | Performs &#8220;true division&#8221;</span><span>
</span><span id="line-1229"></span><span class="hs-comment">-- that always computes the division in floating point:</span><span>
</span><span id="line-1230"></span><span class="hs-comment">-- \[</span><span>
</span><span id="line-1231"></span><span class="hs-comment">-- \mathrm{output}_i = \frac{\mathrm{dividend}_i}{\mathrm{divisor}_i}.</span><span>
</span><span id="line-1232"></span><span class="hs-comment">-- \]</span><span>
</span><span id="line-1233"></span><span class="hs-comment">--</span><span>
</span><span id="line-1234"></span><span class="hs-comment">-- 'trueDivide' is completely equivalent to division using 'div'</span><span>
</span><span id="line-1235"></span><span class="hs-comment">-- except when both inputs have 'Bool' or integer data types,</span><span>
</span><span id="line-1236"></span><span class="hs-comment">-- in which case the inputs are converted to floating data types</span><span>
</span><span id="line-1237"></span><span class="hs-comment">-- before performing the division.</span><span>
</span><span id="line-1238"></span><span class="hs-comment">--</span><span>
</span><span id="line-1239"></span><span class="hs-comment">-- See 'trueDivideScalar' for a version of this function</span><span>
</span><span id="line-1240"></span><span class="hs-comment">-- where the divisor is a scalar.</span><span>
</span><span id="line-1241"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#trueDivide"><span class="hs-identifier hs-type">trueDivide</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-1242"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679520763"><span class="annot"><a href="#local-6989586621679520763"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679520762"><span class="annot"><a href="#local-6989586621679520762"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679520761"><span class="annot"><a href="#local-6989586621679520761"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679520760"><span class="annot"><a href="#local-6989586621679520760"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679520759"><span class="annot"><a href="#local-6989586621679520759"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679520758"><span class="annot"><a href="#local-6989586621679520758"><span class="hs-identifier hs-type">gradient'</span></a></span></span><span> </span><span id="local-6989586621679520757"><span class="annot"><a href="#local-6989586621679520757"><span class="hs-identifier hs-type">layout'</span></a></span></span><span> </span><span id="local-6989586621679520756"><span class="annot"><a href="#local-6989586621679520756"><span class="hs-identifier hs-type">device'</span></a></span></span><span> </span><span id="local-6989586621679520755"><span class="annot"><a href="#local-6989586621679520755"><span class="hs-identifier hs-type">dataType'</span></a></span></span><span> </span><span id="local-6989586621679520754"><span class="annot"><a href="#local-6989586621679520754"><span class="hs-identifier hs-type">shape'</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-1243"></span><span>  </span><span class="hs-comment">-- | tensor dividend</span><span>
</span><span id="line-1244"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520763"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520762"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520761"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520760"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520759"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1245"></span><span>  </span><span class="hs-comment">-- | tensor divisor</span><span>
</span><span id="line-1246"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520758"><span class="hs-identifier hs-type">gradient'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520757"><span class="hs-identifier hs-type">layout'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520756"><span class="hs-identifier hs-type">device'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520755"><span class="hs-identifier hs-type">dataType'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520754"><span class="hs-identifier hs-type">shape'</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1247"></span><span>  </span><span class="hs-comment">-- | tensor output</span><span>
</span><span id="line-1248"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-1249"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679520763"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520758"><span class="hs-identifier hs-type">gradient'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-1250"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679520762"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520757"><span class="hs-identifier hs-type">layout'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-1251"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679520761"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520756"><span class="hs-identifier hs-type">device'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-1252"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679520760"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520755"><span class="hs-identifier hs-type">dataType'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-1253"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679520759"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520754"><span class="hs-identifier hs-type">shape'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-1254"></span><span id="local-6989586621679520753"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679520753"><span class="hs-identifier hs-var">dividend</span></a></span></span><span> </span><span id="trueDivide"><span class="annot"><span class="annottext">trueDivide :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; Tensor
     (gradient &lt;|&gt; gradient')
     (layout &lt;+&gt; layout')
     (device &lt;+&gt; device')
     (dataType &lt;+&gt; dataType')
     (shape &lt;+&gt; shape')
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#trueDivide"><span class="hs-operator hs-var hs-var">`trueDivide`</span></a></span></span><span> </span><span id="local-6989586621679520752"><span class="annot"><span class="annottext">Tensor gradient' layout' device' dataType' shape'
</span><a href="#local-6989586621679520752"><span class="hs-identifier hs-var">divisor</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO
  (Tensor
     (Or (Gradient RequiresGradient) gradient gradient')
     (Unify (Layout LayoutType) layout layout')
     (Unify (Device (DeviceType Nat)) device device')
     (Unify (DataType DType) dataType dataType')
     (Unify (Shape [Dim (Name Symbol) (Size Nat)]) shape shape'))
-&gt; Tensor
     (Or (Gradient RequiresGradient) gradient gradient')
     (Unify (Layout LayoutType) layout layout')
     (Unify (Device (DeviceType Nat)) device device')
     (Unify (DataType DType) dataType dataType')
     (Unify (Shape [Dim (Name Symbol) (Size Nat)]) shape shape')
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO
   (Tensor
      (Or (Gradient RequiresGradient) gradient gradient')
      (Unify (Layout LayoutType) layout layout')
      (Unify (Device (DeviceType Nat)) device device')
      (Unify (DataType DType) dataType dataType')
      (Unify (Shape [Dim (Name Symbol) (Size Nat)]) shape shape'))
 -&gt; Tensor
      (Or (Gradient RequiresGradient) gradient gradient')
      (Unify (Layout LayoutType) layout layout')
      (Unify (Device (DeviceType Nat)) device device')
      (Unify (DataType DType) dataType dataType')
      (Unify (Shape [Dim (Name Symbol) (Size Nat)]) shape shape'))
-&gt; IO
     (Tensor
        (Or (Gradient RequiresGradient) gradient gradient')
        (Unify (Layout LayoutType) layout layout')
        (Unify (Device (DeviceType Nat)) device device')
        (Unify (DataType DType) dataType dataType')
        (Unify (Shape [Dim (Name Symbol) (Size Nat)]) shape shape'))
-&gt; Tensor
     (Or (Gradient RequiresGradient) gradient gradient')
     (Unify (Layout LayoutType) layout layout')
     (Unify (Device (DeviceType Nat)) device device')
     (Unify (DataType DType) dataType dataType')
     (Unify (Shape [Dim (Name Symbol) (Size Nat)]) shape shape')
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; IO
     (Tensor
        (Or (Gradient RequiresGradient) gradient gradient')
        (Unify (Layout LayoutType) layout layout')
        (Unify (Device (DeviceType Nat)) device device')
        (Unify (DataType DType) dataType dataType')
        (Unify (Shape [Dim (Name Symbol) (Size Nat)]) shape shape'))
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.true_divide_tt</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679520753"><span class="hs-identifier hs-var">dividend</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient' layout' device' dataType' shape'
</span><a href="#local-6989586621679520752"><span class="hs-identifier hs-var">divisor</span></a></span><span>
</span><span id="line-1255"></span><span>
</span><span id="line-1256"></span><span class="hs-comment">-- | Performs &#8220;true division&#8221;</span><span>
</span><span id="line-1257"></span><span class="hs-comment">-- that always computes the division in floating point:</span><span>
</span><span id="line-1258"></span><span class="hs-comment">-- \[</span><span>
</span><span id="line-1259"></span><span class="hs-comment">-- \mathrm{output}_i = \frac{\mathrm{dividend}_i}{\mathrm{divisor}}.</span><span>
</span><span id="line-1260"></span><span class="hs-comment">-- \]</span><span>
</span><span id="line-1261"></span><span class="hs-comment">--</span><span>
</span><span id="line-1262"></span><span class="hs-comment">-- 'trueDivideScalar' is completely equivalent to division using 'divScalar'</span><span>
</span><span id="line-1263"></span><span class="hs-comment">-- except when both inputs have 'Bool' or integer data types,</span><span>
</span><span id="line-1264"></span><span class="hs-comment">-- in which case the inputs are converted to floating data types</span><span>
</span><span id="line-1265"></span><span class="hs-comment">-- before performing the division.</span><span>
</span><span id="line-1266"></span><span class="hs-comment">--</span><span>
</span><span id="line-1267"></span><span class="hs-comment">-- See 'trueDivide' for a version of this function</span><span>
</span><span id="line-1268"></span><span class="hs-comment">-- where the divisor is a tensor.</span><span>
</span><span id="line-1269"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#trueDivideScalar"><span class="hs-identifier hs-type">trueDivideScalar</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-1270"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679520749"><span class="annot"><a href="#local-6989586621679520749"><span class="hs-identifier hs-type">other</span></a></span></span><span> </span><span id="local-6989586621679520748"><span class="annot"><a href="#local-6989586621679520748"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679520747"><span class="annot"><a href="#local-6989586621679520747"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679520746"><span class="annot"><a href="#local-6989586621679520746"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679520745"><span class="annot"><a href="#local-6989586621679520745"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679520744"><span class="annot"><a href="#local-6989586621679520744"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-1271"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Scalar.html#Scalar"><span class="hs-identifier hs-type">Scalar</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520749"><span class="hs-identifier hs-type">other</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-1272"></span><span>  </span><span class="hs-comment">-- | tensor dividend</span><span>
</span><span id="line-1273"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520748"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520747"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520746"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520745"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520744"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1274"></span><span>  </span><span class="hs-comment">-- | scalar divisor</span><span>
</span><span id="line-1275"></span><span>  </span><span class="annot"><a href="#local-6989586621679520749"><span class="hs-identifier hs-type">other</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1276"></span><span>  </span><span class="hs-comment">-- | tensor output</span><span>
</span><span id="line-1277"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520748"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520747"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520746"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520745"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520744"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-1278"></span><span id="local-6989586621679520743"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679520743"><span class="hs-identifier hs-var">dividend</span></a></span></span><span> </span><span id="trueDivideScalar"><span class="annot"><span class="annottext">trueDivideScalar :: Tensor gradient layout device dataType shape
-&gt; other -&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#trueDivideScalar"><span class="hs-operator hs-var hs-var">`trueDivideScalar`</span></a></span></span><span> </span><span id="local-6989586621679520742"><span class="annot"><span class="annottext">other
</span><a href="#local-6989586621679520742"><span class="hs-identifier hs-var">divisor</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ForeignPtr Scalar -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; other
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr Scalar -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.true_divide_ts</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679520743"><span class="hs-identifier hs-var">dividend</span></a></span><span> </span><span class="annot"><span class="annottext">other
</span><a href="#local-6989586621679520742"><span class="hs-identifier hs-var">divisor</span></a></span><span>
</span><span id="line-1279"></span><span>
</span><span id="line-1280"></span><span class="hs-comment">-- Returns a new tensor with the truncated integer values of the elements of 'input'.</span><span>
</span><span id="line-1281"></span><span class="hs-comment">--</span><span>
</span><span id="line-1282"></span><span class="hs-comment">-- Note that the data type of the 'output' tensor matches that of the 'input'.</span><span>
</span><span id="line-1283"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#trunc"><span class="hs-identifier hs-type">trunc</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-1284"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679520739"><span class="annot"><a href="#local-6989586621679520739"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679520738"><span class="annot"><a href="#local-6989586621679520738"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679520737"><span class="annot"><a href="#local-6989586621679520737"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679520736"><span class="annot"><a href="#local-6989586621679520736"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679520735"><span class="annot"><a href="#local-6989586621679520735"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-1285"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-1286"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520739"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520738"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520737"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520736"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520735"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1287"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-1288"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520739"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520738"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520737"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520736"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679520735"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-1289"></span><span id="trunc"><span class="annot"><span class="annottext">trunc :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#trunc"><span class="hs-identifier hs-var hs-var">trunc</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; (Tensor gradient layout device dataType shape
    -&gt; IO (Tensor gradient layout device dataType shape))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.trunc_t</span></a></span><span>
</span><span id="line-1290"></span></pre></body></html>