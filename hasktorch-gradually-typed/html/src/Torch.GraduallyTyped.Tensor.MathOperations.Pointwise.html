<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><link rel="stylesheet" type="text/css" href="style.css" /><script type="text/javascript" src="highlight.js"></script></head><body><pre><span class="hs-pragma">{-# LANGUAGE DataKinds #-}</span><span>
</span><span id="line-2"></span><span class="hs-pragma">{-# LANGUAGE GADTs #-}</span><span>
</span><span id="line-3"></span><span class="hs-pragma">{-# LANGUAGE RankNTypes #-}</span><span>
</span><span id="line-4"></span><span class="hs-pragma">{-# LANGUAGE TypeOperators #-}</span><span>
</span><span id="line-5"></span><span>
</span><span id="line-6"></span><span class="hs-keyword">module</span><span> </span><span class="hs-identifier">Torch.GraduallyTyped.Tensor.MathOperations.Pointwise</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-7"></span><span>
</span><span id="line-8"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier">Control.Monad.Catch</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier">MonadThrow</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-9"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">System.IO.Unsafe</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier">unsafePerformIO</span></span><span class="hs-special">)</span><span>
</span><span id="line-10"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html"><span class="hs-identifier">Torch.GraduallyTyped.DType</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier">DType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier">DataType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-11"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html"><span class="hs-identifier">Torch.GraduallyTyped.Prelude</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Catch"><span class="hs-identifier">Catch</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-12"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html"><span class="hs-identifier">Torch.GraduallyTyped.RequiresGradient</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier">Gradient</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#RequiresGradient"><span class="hs-identifier">RequiresGradient</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-13"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Scalar.html"><span class="hs-identifier">Torch.GraduallyTyped.Scalar</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Scalar.html#Scalar"><span class="hs-identifier">Scalar</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-14"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.html"><span class="hs-identifier">Torch.GraduallyTyped.Shape</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#BroadcastShapesF"><span class="hs-identifier">BroadcastShapesF</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-15"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html"><span class="hs-identifier">Torch.GraduallyTyped.Tensor.Type</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier">Tensor</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-16"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html"><span class="hs-identifier">Torch.GraduallyTyped.Unify</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-keyword">type</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator">(&lt;+&gt;)</span></a></span><span class="hs-special">,</span><span> </span><span class="hs-keyword">type</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator">(&lt;|&gt;)</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-17"></span><span class="hs-keyword">import</span><span> </span><span class="hs-keyword">qualified</span><span> </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier">Torch.Internal.Cast</span></a></span><span> </span><span class="hs-keyword">as</span><span> </span><span class="annot"><span class="hs-identifier">ATen</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier">cast1</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier">cast2</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier">cast3</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier">cast4</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-18"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier">Torch.Internal.GC</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier">unsafeThrowableIO</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-19"></span><span class="hs-keyword">import</span><span> </span><span class="hs-keyword">qualified</span><span> </span><span class="annot"><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier">Torch.Internal.Managed.Native</span></a></span><span> </span><span class="hs-keyword">as</span><span> </span><span class="annot"><span class="hs-identifier">ATen</span></span><span>
</span><span id="line-20"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">Prelude</span></span><span> </span><span class="hs-keyword">hiding</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier">abs</span></span><span class="hs-special">)</span><span>
</span><span id="line-21"></span><span>
</span><span id="line-22"></span><span class="hs-comment">-- $setup</span><span>
</span><span id="line-23"></span><span class="hs-comment">-- &gt;&gt;&gt; import Torch.GraduallyTyped.Prelude.List (SList (..))</span><span>
</span><span id="line-24"></span><span class="hs-comment">-- &gt;&gt;&gt; import Torch.GraduallyTyped</span><span>
</span><span id="line-25"></span><span>
</span><span id="line-26"></span><span class="hs-comment">-- | Computes the element-wise absolute value of the given 'input' tensor:</span><span>
</span><span id="line-27"></span><span class="hs-comment">-- \[</span><span>
</span><span id="line-28"></span><span class="hs-comment">-- \mathrm{output}_i = \left|\mathrm{input}_i\right|.</span><span>
</span><span id="line-29"></span><span class="hs-comment">-- \]</span><span>
</span><span id="line-30"></span><span class="hs-comment">-- The result is returned as a new tensor.</span><span>
</span><span id="line-31"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#abs"><span class="hs-identifier hs-type">abs</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-32"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679668095"><span class="annot"><a href="#local-6989586621679668095"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679668094"><span class="annot"><a href="#local-6989586621679668094"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679668093"><span class="annot"><a href="#local-6989586621679668093"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679668092"><span class="annot"><a href="#local-6989586621679668092"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679668091"><span class="annot"><a href="#local-6989586621679668091"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-33"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-34"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679668095"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679668094"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679668093"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679668092"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679668091"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-35"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-36"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679668095"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679668094"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679668093"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679668092"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679668091"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-37"></span><span id="abs"><span class="annot"><span class="annottext">abs :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#abs"><span class="hs-identifier hs-var hs-var">abs</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; (Tensor gradient layout device dataType shape
    -&gt; IO (Tensor gradient layout device dataType shape))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.abs_t</span></a></span><span>
</span><span id="line-38"></span><span>
</span><span id="line-39"></span><span class="hs-comment">-- | Alias for 'abs'.</span><span>
</span><span id="line-40"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#absolute"><span class="hs-identifier hs-type">absolute</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-41"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679667476"><span class="annot"><a href="#local-6989586621679667476"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679667475"><span class="annot"><a href="#local-6989586621679667475"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679667474"><span class="annot"><a href="#local-6989586621679667474"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679667473"><span class="annot"><a href="#local-6989586621679667473"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679667472"><span class="annot"><a href="#local-6989586621679667472"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-42"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-43"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667476"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667475"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667474"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667473"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667472"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-44"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-45"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667476"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667475"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667474"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667473"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667472"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-46"></span><span id="absolute"><span class="annot"><span class="annottext">absolute :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#absolute"><span class="hs-identifier hs-var hs-var">absolute</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#abs"><span class="hs-identifier hs-var">abs</span></a></span><span>
</span><span id="line-47"></span><span>
</span><span id="line-48"></span><span class="hs-comment">-- | Returns a new tensor with the arccosine of the elements of 'input':</span><span>
</span><span id="line-49"></span><span class="hs-comment">-- \[</span><span>
</span><span id="line-50"></span><span class="hs-comment">-- \mathrm{output}_i = \cos^{-1} \left(\mathrm{input}_i\right).</span><span>
</span><span id="line-51"></span><span class="hs-comment">-- \]</span><span>
</span><span id="line-52"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#acos"><span class="hs-identifier hs-type">acos</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-53"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679667470"><span class="annot"><a href="#local-6989586621679667470"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679667469"><span class="annot"><a href="#local-6989586621679667469"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679667468"><span class="annot"><a href="#local-6989586621679667468"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679667467"><span class="annot"><a href="#local-6989586621679667467"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679667466"><span class="annot"><a href="#local-6989586621679667466"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-54"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-55"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667470"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667469"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667468"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667467"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667466"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-56"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-57"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667470"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667469"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667468"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667467"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667466"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-58"></span><span id="acos"><span class="annot"><span class="annottext">acos :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#acos"><span class="hs-identifier hs-var hs-var">acos</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; (Tensor gradient layout device dataType shape
    -&gt; IO (Tensor gradient layout device dataType shape))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.acos_t</span></a></span><span>
</span><span id="line-59"></span><span>
</span><span id="line-60"></span><span class="hs-comment">-- | Returns a new tensor with the arccosine of the elements of 'input':</span><span>
</span><span id="line-61"></span><span class="hs-comment">-- \[</span><span>
</span><span id="line-62"></span><span class="hs-comment">-- \mathrm{output}_i = \cosh^{-1} \left(\mathrm{input}_i\right).</span><span>
</span><span id="line-63"></span><span class="hs-comment">-- \]</span><span>
</span><span id="line-64"></span><span class="hs-comment">--</span><span>
</span><span id="line-65"></span><span class="hs-comment">-- Note that the domain of the inverse hyperbolic cosine is \([1, \infty)\), and</span><span>
</span><span id="line-66"></span><span class="hs-comment">-- values outside this range will be mapped to \(\mathrm{NaN}\),</span><span>
</span><span id="line-67"></span><span class="hs-comment">-- except for \(+\infty\) for which the output is mapped to \(+\infty\).</span><span>
</span><span id="line-68"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#acosh"><span class="hs-identifier hs-type">acosh</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-69"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679667463"><span class="annot"><a href="#local-6989586621679667463"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679667462"><span class="annot"><a href="#local-6989586621679667462"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679667461"><span class="annot"><a href="#local-6989586621679667461"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679667460"><span class="annot"><a href="#local-6989586621679667460"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679667459"><span class="annot"><a href="#local-6989586621679667459"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-70"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-71"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667463"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667462"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667461"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667460"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667459"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-72"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-73"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667463"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667462"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667461"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667460"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667459"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-74"></span><span id="acosh"><span class="annot"><span class="annottext">acosh :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#acosh"><span class="hs-identifier hs-var hs-var">acosh</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; (Tensor gradient layout device dataType shape
    -&gt; IO (Tensor gradient layout device dataType shape))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.acosh_t</span></a></span><span>
</span><span id="line-75"></span><span>
</span><span id="line-76"></span><span class="hs-comment">-- | Element-wise addition of one tensor and another:</span><span>
</span><span id="line-77"></span><span class="hs-comment">-- \[</span><span>
</span><span id="line-78"></span><span class="hs-comment">-- \mathrm{output}_i = \mathrm{input}_i + \mathrm{other}_i.</span><span>
</span><span id="line-79"></span><span class="hs-comment">-- \]</span><span>
</span><span id="line-80"></span><span class="hs-comment">-- The result is returned as a new tensor.</span><span>
</span><span id="line-81"></span><span class="hs-comment">--</span><span>
</span><span id="line-82"></span><span class="hs-comment">-- The shape of 'other' must be broadcastable with the shape of 'input'.</span><span>
</span><span id="line-83"></span><span class="hs-comment">-- See 'addScalar' for a version of this function where</span><span>
</span><span id="line-84"></span><span class="hs-comment">-- the 'other' input is a scalar.</span><span>
</span><span id="line-85"></span><span class="hs-comment">--</span><span>
</span><span id="line-86"></span><span class="hs-comment">-- &gt;&gt;&gt; g &lt;- sMkGenerator (SDevice SCPU) 0</span><span>
</span><span id="line-87"></span><span class="hs-comment">-- &gt;&gt;&gt; sRandn' = sRandn . TensorSpec (SGradient SWithGradient) (SLayout SDense) (SDevice SCPU) (SDataType SFloat)</span><span>
</span><span id="line-88"></span><span class="hs-comment">-- &gt;&gt;&gt; (a, g') &lt;- sRandn' (SShape $ SName @&quot;feature&quot; :&amp;: SSize @4 :|: SNil) g</span><span>
</span><span id="line-89"></span><span class="hs-comment">-- &gt;&gt;&gt; (b, _) &lt;- sRandn' (SShape $ SName @&quot;*&quot; :&amp;: SSize @4 :|: SName @&quot;*&quot; :&amp;: SSize @1 :|: SNil) g'</span><span>
</span><span id="line-90"></span><span class="hs-comment">-- &gt;&gt;&gt; result &lt;- a `add` b</span><span>
</span><span id="line-91"></span><span class="hs-comment">-- &gt;&gt;&gt; :type result</span><span>
</span><span id="line-92"></span><span class="hs-comment">-- result</span><span>
</span><span id="line-93"></span><span class="hs-comment">--   :: Tensor</span><span>
</span><span id="line-94"></span><span class="hs-comment">--        ('Gradient 'WithGradient)</span><span>
</span><span id="line-95"></span><span class="hs-comment">--        ('Layout 'Dense)</span><span>
</span><span id="line-96"></span><span class="hs-comment">--        ('Device 'CPU)</span><span>
</span><span id="line-97"></span><span class="hs-comment">--        ('DataType 'Float)</span><span>
</span><span id="line-98"></span><span class="hs-comment">--        ('Shape</span><span>
</span><span id="line-99"></span><span class="hs-comment">--           '[ 'Dim ('Name &quot;*&quot;) ('Size 4), 'Dim ('Name &quot;feature&quot;) ('Size 4)])</span><span>
</span><span id="line-100"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#add"><span class="hs-identifier hs-type">add</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-101"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679667456"><span class="annot"><a href="#local-6989586621679667456"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679667455"><span class="annot"><a href="#local-6989586621679667455"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679667454"><span class="annot"><a href="#local-6989586621679667454"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679667453"><span class="annot"><a href="#local-6989586621679667453"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679667452"><span class="annot"><a href="#local-6989586621679667452"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679667451"><span class="annot"><a href="#local-6989586621679667451"><span class="hs-identifier hs-type">gradient'</span></a></span></span><span> </span><span id="local-6989586621679667450"><span class="annot"><a href="#local-6989586621679667450"><span class="hs-identifier hs-type">layout'</span></a></span></span><span> </span><span id="local-6989586621679667449"><span class="annot"><a href="#local-6989586621679667449"><span class="hs-identifier hs-type">device'</span></a></span></span><span> </span><span id="local-6989586621679667448"><span class="annot"><a href="#local-6989586621679667448"><span class="hs-identifier hs-type">dataType'</span></a></span></span><span> </span><span id="local-6989586621679667447"><span class="annot"><a href="#local-6989586621679667447"><span class="hs-identifier hs-type">shape'</span></a></span></span><span> </span><span id="local-6989586621679667446"><span class="annot"><a href="#local-6989586621679667446"><span class="hs-identifier hs-type">shape''</span></a></span></span><span> </span><span id="local-6989586621679667445"><span class="annot"><a href="#local-6989586621679667445"><span class="hs-identifier hs-type">m</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-102"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier hs-type">MonadThrow</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667445"><span class="hs-identifier hs-type">m</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679667446"><span class="hs-identifier hs-type">shape''</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#BroadcastShapesF"><span class="hs-identifier hs-type">BroadcastShapesF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667452"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667447"><span class="hs-identifier hs-type">shape'</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Catch"><span class="hs-identifier hs-type">Catch</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667446"><span class="hs-identifier hs-type">shape''</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-103"></span><span>  </span><span class="hs-comment">-- | input tensor</span><span>
</span><span id="line-104"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667456"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667455"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667454"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667453"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667452"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-105"></span><span>  </span><span class="hs-comment">-- | other tensor</span><span>
</span><span id="line-106"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667451"><span class="hs-identifier hs-type">gradient'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667450"><span class="hs-identifier hs-type">layout'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667449"><span class="hs-identifier hs-type">device'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667448"><span class="hs-identifier hs-type">dataType'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667447"><span class="hs-identifier hs-type">shape'</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-107"></span><span>  </span><span class="hs-comment">-- | output tensor</span><span>
</span><span id="line-108"></span><span>  </span><span class="annot"><a href="#local-6989586621679667445"><span class="hs-identifier hs-type">m</span></a></span><span>
</span><span id="line-109"></span><span>    </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-110"></span><span>        </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679667456"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667451"><span class="hs-identifier hs-type">gradient'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-111"></span><span>        </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679667455"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667450"><span class="hs-identifier hs-type">layout'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-112"></span><span>        </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679667454"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667449"><span class="hs-identifier hs-type">device'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-113"></span><span>        </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679667453"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667448"><span class="hs-identifier hs-type">dataType'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-114"></span><span>        </span><span class="annot"><a href="#local-6989586621679667446"><span class="hs-identifier hs-type">shape''</span></a></span><span>
</span><span id="line-115"></span><span>    </span><span class="hs-special">)</span><span>
</span><span id="line-116"></span><span id="local-6989586621679667444"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679667444"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span id="add"><span class="annot"><span class="annottext">add :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; m (Tensor
        (gradient &lt;|&gt; gradient')
        (layout &lt;+&gt; layout')
        (device &lt;+&gt; device')
        (dataType &lt;+&gt; dataType')
        shape'')
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#add"><span class="hs-operator hs-var hs-var">`add`</span></a></span></span><span> </span><span id="local-6989586621679667443"><span class="annot"><span class="annottext">Tensor gradient' layout' device' dataType' shape'
</span><a href="#local-6989586621679667443"><span class="hs-identifier hs-var">other</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO
  (Tensor
     (Or (Gradient RequiresGradient) gradient gradient')
     (Unify (Layout LayoutType) layout layout')
     (Unify (Device (DeviceType Nat)) device device')
     (Unify (DataType DType) dataType dataType')
     shape'')
-&gt; m (Tensor
        (Or (Gradient RequiresGradient) gradient gradient')
        (Unify (Layout LayoutType) layout layout')
        (Unify (Device (DeviceType Nat)) device device')
        (Unify (DataType DType) dataType dataType')
        shape'')
forall a (m :: * -&gt; *). MonadThrow m =&gt; IO a -&gt; m a
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">unsafeThrowableIO</span></a></span><span> </span><span class="annot"><span class="annottext">(IO
   (Tensor
      (Or (Gradient RequiresGradient) gradient gradient')
      (Unify (Layout LayoutType) layout layout')
      (Unify (Device (DeviceType Nat)) device device')
      (Unify (DataType DType) dataType dataType')
      shape'')
 -&gt; m (Tensor
         (Or (Gradient RequiresGradient) gradient gradient')
         (Unify (Layout LayoutType) layout layout')
         (Unify (Device (DeviceType Nat)) device device')
         (Unify (DataType DType) dataType dataType')
         shape''))
-&gt; IO
     (Tensor
        (Or (Gradient RequiresGradient) gradient gradient')
        (Unify (Layout LayoutType) layout layout')
        (Unify (Device (DeviceType Nat)) device device')
        (Unify (DataType DType) dataType dataType')
        shape'')
-&gt; m (Tensor
        (Or (Gradient RequiresGradient) gradient gradient')
        (Unify (Layout LayoutType) layout layout')
        (Unify (Device (DeviceType Nat)) device device')
        (Unify (DataType DType) dataType dataType')
        shape'')
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; IO
     (Tensor
        (Or (Gradient RequiresGradient) gradient gradient')
        (Unify (Layout LayoutType) layout layout')
        (Unify (Device (DeviceType Nat)) device device')
        (Unify (DataType DType) dataType dataType')
        shape'')
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.add_tt</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679667444"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient' layout' device' dataType' shape'
</span><a href="#local-6989586621679667443"><span class="hs-identifier hs-var">other</span></a></span><span>
</span><span id="line-117"></span><span>
</span><span id="line-118"></span><span class="hs-comment">-- | Adds a scalar 'other' to a tensor 'input':</span><span>
</span><span id="line-119"></span><span class="hs-comment">-- \[</span><span>
</span><span id="line-120"></span><span class="hs-comment">-- \mathrm{output}_i = \mathrm{input}_i + \mathrm{other}.</span><span>
</span><span id="line-121"></span><span class="hs-comment">-- \]</span><span>
</span><span id="line-122"></span><span class="hs-comment">-- The result is returned as a new tensor.</span><span>
</span><span id="line-123"></span><span class="hs-comment">-- See 'add' for a version of this function where</span><span>
</span><span id="line-124"></span><span class="hs-comment">-- the second argument is a tensor.</span><span>
</span><span id="line-125"></span><span class="hs-comment">--</span><span>
</span><span id="line-126"></span><span class="hs-comment">-- TODO: add data type unification of @other@ and @dataType@.</span><span>
</span><span id="line-127"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#addScalar"><span class="hs-identifier hs-type">addScalar</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-128"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679667440"><span class="annot"><a href="#local-6989586621679667440"><span class="hs-identifier hs-type">other</span></a></span></span><span> </span><span id="local-6989586621679667439"><span class="annot"><a href="#local-6989586621679667439"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679667438"><span class="annot"><a href="#local-6989586621679667438"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679667437"><span class="annot"><a href="#local-6989586621679667437"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679667436"><span class="annot"><a href="#local-6989586621679667436"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679667435"><span class="annot"><a href="#local-6989586621679667435"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-129"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Scalar.html#Scalar"><span class="hs-identifier hs-type">Scalar</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667440"><span class="hs-identifier hs-type">other</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-130"></span><span>  </span><span class="hs-comment">-- | input tensor</span><span>
</span><span id="line-131"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667439"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667438"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667437"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667436"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667435"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-132"></span><span>  </span><span class="hs-comment">-- | input scalar</span><span>
</span><span id="line-133"></span><span>  </span><span class="annot"><a href="#local-6989586621679667440"><span class="hs-identifier hs-type">other</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-134"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-135"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667439"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667438"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667437"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667436"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667435"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-136"></span><span id="local-6989586621679667434"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679667434"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span id="addScalar"><span class="annot"><span class="annottext">addScalar :: Tensor gradient layout device dataType shape
-&gt; other -&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#addScalar"><span class="hs-operator hs-var hs-var">`addScalar`</span></a></span></span><span> </span><span id="local-6989586621679667433"><span class="annot"><span class="annottext">other
</span><a href="#local-6989586621679667433"><span class="hs-identifier hs-var">other</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ForeignPtr Scalar -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; other
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr Scalar -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.add_ts</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679667434"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">other
</span><a href="#local-6989586621679667433"><span class="hs-identifier hs-var">other</span></a></span><span>
</span><span id="line-137"></span><span>
</span><span id="line-138"></span><span class="hs-comment">-- | Performs the element-wise division of 'tensor1' by 'tensor2',</span><span>
</span><span id="line-139"></span><span class="hs-comment">-- multiply the result by a scalar 'value' and add it to 'input':</span><span>
</span><span id="line-140"></span><span class="hs-comment">-- \[</span><span>
</span><span id="line-141"></span><span class="hs-comment">-- \mathrm{output}_i = \mathrm{input}_i + \mathrm{value} \times \frac{\mathrm{tensor1}_i}{\mathrm{tensor2}_i}.</span><span>
</span><span id="line-142"></span><span class="hs-comment">-- \]</span><span>
</span><span id="line-143"></span><span class="hs-comment">--</span><span>
</span><span id="line-144"></span><span class="hs-comment">-- See 'addcmul' for a version of this function where 'tensor1' and 'tensor2'</span><span>
</span><span id="line-145"></span><span class="hs-comment">-- are multiplied rather than divided.</span><span>
</span><span id="line-146"></span><span class="hs-comment">--</span><span>
</span><span id="line-147"></span><span class="hs-comment">-- Note further that for inputs of type 'Float' or 'Double',</span><span>
</span><span id="line-148"></span><span class="hs-comment">-- 'value' must be a real number, otherwise it must be an integer.</span><span>
</span><span id="line-149"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#addcdiv"><span class="hs-identifier hs-type">addcdiv</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-150"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679667430"><span class="annot"><a href="#local-6989586621679667430"><span class="hs-identifier hs-type">value</span></a></span></span><span> </span><span id="local-6989586621679667429"><span class="annot"><a href="#local-6989586621679667429"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679667428"><span class="annot"><a href="#local-6989586621679667428"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679667427"><span class="annot"><a href="#local-6989586621679667427"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679667426"><span class="annot"><a href="#local-6989586621679667426"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679667425"><span class="annot"><a href="#local-6989586621679667425"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679667424"><span class="annot"><a href="#local-6989586621679667424"><span class="hs-identifier hs-type">gradient'</span></a></span></span><span> </span><span id="local-6989586621679667423"><span class="annot"><a href="#local-6989586621679667423"><span class="hs-identifier hs-type">layout'</span></a></span></span><span> </span><span id="local-6989586621679667422"><span class="annot"><a href="#local-6989586621679667422"><span class="hs-identifier hs-type">device'</span></a></span></span><span> </span><span id="local-6989586621679667421"><span class="annot"><a href="#local-6989586621679667421"><span class="hs-identifier hs-type">dataType'</span></a></span></span><span> </span><span id="local-6989586621679667420"><span class="annot"><a href="#local-6989586621679667420"><span class="hs-identifier hs-type">shape'</span></a></span></span><span> </span><span id="local-6989586621679667419"><span class="annot"><a href="#local-6989586621679667419"><span class="hs-identifier hs-type">gradient''</span></a></span></span><span> </span><span id="local-6989586621679667418"><span class="annot"><a href="#local-6989586621679667418"><span class="hs-identifier hs-type">layout''</span></a></span></span><span> </span><span id="local-6989586621679667417"><span class="annot"><a href="#local-6989586621679667417"><span class="hs-identifier hs-type">device''</span></a></span></span><span> </span><span id="local-6989586621679667416"><span class="annot"><a href="#local-6989586621679667416"><span class="hs-identifier hs-type">dataType''</span></a></span></span><span> </span><span id="local-6989586621679667415"><span class="annot"><a href="#local-6989586621679667415"><span class="hs-identifier hs-type">shape''</span></a></span></span><span> </span><span id="local-6989586621679667414"><span class="annot"><a href="#local-6989586621679667414"><span class="hs-identifier hs-type">m</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-151"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Scalar.html#Scalar"><span class="hs-identifier hs-type">Scalar</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667430"><span class="hs-identifier hs-type">value</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier hs-type">MonadThrow</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667414"><span class="hs-identifier hs-type">m</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-152"></span><span>  </span><span class="hs-comment">-- | input scalar</span><span>
</span><span id="line-153"></span><span>  </span><span class="annot"><a href="#local-6989586621679667430"><span class="hs-identifier hs-type">value</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-154"></span><span>  </span><span class="hs-comment">-- | first other tensor</span><span>
</span><span id="line-155"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667429"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667428"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667427"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667426"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667425"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-156"></span><span>  </span><span class="hs-comment">-- | second other tensor</span><span>
</span><span id="line-157"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667424"><span class="hs-identifier hs-type">gradient'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667423"><span class="hs-identifier hs-type">layout'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667422"><span class="hs-identifier hs-type">device'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667421"><span class="hs-identifier hs-type">dataType'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667420"><span class="hs-identifier hs-type">shape'</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-158"></span><span>  </span><span class="hs-comment">-- | input tensor</span><span>
</span><span id="line-159"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667419"><span class="hs-identifier hs-type">gradient''</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667418"><span class="hs-identifier hs-type">layout''</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667417"><span class="hs-identifier hs-type">device''</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667416"><span class="hs-identifier hs-type">dataType''</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667415"><span class="hs-identifier hs-type">shape''</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-160"></span><span>  </span><span class="hs-comment">-- | output tensor</span><span>
</span><span id="line-161"></span><span>  </span><span class="annot"><a href="#local-6989586621679667414"><span class="hs-identifier hs-type">m</span></a></span><span>
</span><span id="line-162"></span><span>    </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-163"></span><span>        </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679667429"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667424"><span class="hs-identifier hs-type">gradient'</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667419"><span class="hs-identifier hs-type">gradient''</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-164"></span><span>        </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679667428"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667423"><span class="hs-identifier hs-type">layout'</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667418"><span class="hs-identifier hs-type">layout''</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-165"></span><span>        </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679667427"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667422"><span class="hs-identifier hs-type">device'</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667417"><span class="hs-identifier hs-type">device''</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-166"></span><span>        </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679667426"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667421"><span class="hs-identifier hs-type">dataType'</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667416"><span class="hs-identifier hs-type">dataType''</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-167"></span><span>        </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679667425"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667420"><span class="hs-identifier hs-type">shape'</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667415"><span class="hs-identifier hs-type">shape''</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-168"></span><span>    </span><span class="hs-special">)</span><span>
</span><span id="line-169"></span><span id="addcdiv"><span class="annot"><span class="annottext">addcdiv :: value
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; Tensor gradient'' layout'' device'' dataType'' shape''
-&gt; m (Tensor
        (gradient &lt;|&gt; (gradient' &lt;|&gt; gradient''))
        (layout &lt;+&gt; (layout' &lt;+&gt; layout''))
        (device &lt;+&gt; (device' &lt;+&gt; device''))
        (dataType &lt;+&gt; (dataType' &lt;+&gt; dataType''))
        (shape &lt;+&gt; (shape' &lt;+&gt; shape'')))
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#addcdiv"><span class="hs-identifier hs-var hs-var">addcdiv</span></a></span></span><span> </span><span id="local-6989586621679667413"><span class="annot"><span class="annottext">value
</span><a href="#local-6989586621679667413"><span class="hs-identifier hs-var">value</span></a></span></span><span> </span><span id="local-6989586621679667412"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679667412"><span class="hs-identifier hs-var">tensor1</span></a></span></span><span> </span><span id="local-6989586621679667411"><span class="annot"><span class="annottext">Tensor gradient' layout' device' dataType' shape'
</span><a href="#local-6989586621679667411"><span class="hs-identifier hs-var">tensor2</span></a></span></span><span> </span><span id="local-6989586621679667410"><span class="annot"><span class="annottext">Tensor gradient'' layout'' device'' dataType'' shape''
</span><a href="#local-6989586621679667410"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO
  (Tensor
     (Or
        (Gradient RequiresGradient)
        gradient
        (Or (Gradient RequiresGradient) gradient' gradient''))
     (Unify
        (Layout LayoutType)
        layout
        (Unify (Layout LayoutType) layout' layout''))
     (Unify
        (Device (DeviceType Nat))
        device
        (Unify (Device (DeviceType Nat)) device' device''))
     (Unify
        (DataType DType)
        dataType
        (Unify (DataType DType) dataType' dataType''))
     (Unify
        (Shape [Dim (Name Symbol) (Size Nat)])
        shape
        (Unify (Shape [Dim (Name Symbol) (Size Nat)]) shape' shape'')))
-&gt; m (Tensor
        (Or
           (Gradient RequiresGradient)
           gradient
           (Or (Gradient RequiresGradient) gradient' gradient''))
        (Unify
           (Layout LayoutType)
           layout
           (Unify (Layout LayoutType) layout' layout''))
        (Unify
           (Device (DeviceType Nat))
           device
           (Unify (Device (DeviceType Nat)) device' device''))
        (Unify
           (DataType DType)
           dataType
           (Unify (DataType DType) dataType' dataType''))
        (Unify
           (Shape [Dim (Name Symbol) (Size Nat)])
           shape
           (Unify (Shape [Dim (Name Symbol) (Size Nat)]) shape' shape'')))
forall a (m :: * -&gt; *). MonadThrow m =&gt; IO a -&gt; m a
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">unsafeThrowableIO</span></a></span><span> </span><span class="annot"><span class="annottext">(IO
   (Tensor
      (Or
         (Gradient RequiresGradient)
         gradient
         (Or (Gradient RequiresGradient) gradient' gradient''))
      (Unify
         (Layout LayoutType)
         layout
         (Unify (Layout LayoutType) layout' layout''))
      (Unify
         (Device (DeviceType Nat))
         device
         (Unify (Device (DeviceType Nat)) device' device''))
      (Unify
         (DataType DType)
         dataType
         (Unify (DataType DType) dataType' dataType''))
      (Unify
         (Shape [Dim (Name Symbol) (Size Nat)])
         shape
         (Unify (Shape [Dim (Name Symbol) (Size Nat)]) shape' shape'')))
 -&gt; m (Tensor
         (Or
            (Gradient RequiresGradient)
            gradient
            (Or (Gradient RequiresGradient) gradient' gradient''))
         (Unify
            (Layout LayoutType)
            layout
            (Unify (Layout LayoutType) layout' layout''))
         (Unify
            (Device (DeviceType Nat))
            device
            (Unify (Device (DeviceType Nat)) device' device''))
         (Unify
            (DataType DType)
            dataType
            (Unify (DataType DType) dataType' dataType''))
         (Unify
            (Shape [Dim (Name Symbol) (Size Nat)])
            shape
            (Unify (Shape [Dim (Name Symbol) (Size Nat)]) shape' shape''))))
-&gt; IO
     (Tensor
        (Or
           (Gradient RequiresGradient)
           gradient
           (Or (Gradient RequiresGradient) gradient' gradient''))
        (Unify
           (Layout LayoutType)
           layout
           (Unify (Layout LayoutType) layout' layout''))
        (Unify
           (Device (DeviceType Nat))
           device
           (Unify (Device (DeviceType Nat)) device' device''))
        (Unify
           (DataType DType)
           dataType
           (Unify (DataType DType) dataType' dataType''))
        (Unify
           (Shape [Dim (Name Symbol) (Size Nat)])
           shape
           (Unify (Shape [Dim (Name Symbol) (Size Nat)]) shape' shape'')))
-&gt; m (Tensor
        (Or
           (Gradient RequiresGradient)
           gradient
           (Or (Gradient RequiresGradient) gradient' gradient''))
        (Unify
           (Layout LayoutType)
           layout
           (Unify (Layout LayoutType) layout' layout''))
        (Unify
           (Device (DeviceType Nat))
           device
           (Unify (Device (DeviceType Nat)) device' device''))
        (Unify
           (DataType DType)
           dataType
           (Unify (DataType DType) dataType' dataType''))
        (Unify
           (Shape [Dim (Name Symbol) (Size Nat)])
           shape
           (Unify (Shape [Dim (Name Symbol) (Size Nat)]) shape' shape'')))
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; ForeignPtr Scalar
 -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient'' layout'' device'' dataType'' shape''
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; value
-&gt; IO
     (Tensor
        (Or
           (Gradient RequiresGradient)
           gradient
           (Or (Gradient RequiresGradient) gradient' gradient''))
        (Unify
           (Layout LayoutType)
           layout
           (Unify (Layout LayoutType) layout' layout''))
        (Unify
           (Device (DeviceType Nat))
           device
           (Unify (Device (DeviceType Nat)) device' device''))
        (Unify
           (DataType DType)
           dataType
           (Unify (DataType DType) dataType' dataType''))
        (Unify
           (Shape [Dim (Name Symbol) (Size Nat)])
           shape
           (Unify (Shape [Dim (Name Symbol) (Size Nat)]) shape' shape'')))
forall a ca x1 cx1 x2 cx2 x3 cx3 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable x3 cx3,
 Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; cx3 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; x2 -&gt; x3 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast4</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; ForeignPtr Tensor
-&gt; ForeignPtr Tensor
-&gt; ForeignPtr Scalar
-&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.addcdiv_ttts</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient'' layout'' device'' dataType'' shape''
</span><a href="#local-6989586621679667410"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679667412"><span class="hs-identifier hs-var">tensor1</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient' layout' device' dataType' shape'
</span><a href="#local-6989586621679667411"><span class="hs-identifier hs-var">tensor2</span></a></span><span> </span><span class="annot"><span class="annottext">value
</span><a href="#local-6989586621679667413"><span class="hs-identifier hs-var">value</span></a></span><span>
</span><span id="line-170"></span><span>
</span><span id="line-171"></span><span class="hs-comment">-- | Performs the element-wise multiplication of 'tensor1' by 'tensor2',</span><span>
</span><span id="line-172"></span><span class="hs-comment">-- multiply the result by the scalar 'value' and add it to 'input':</span><span>
</span><span id="line-173"></span><span class="hs-comment">-- \[</span><span>
</span><span id="line-174"></span><span class="hs-comment">-- \mathrm{output}_i = \mathrm{input}_i + \mathrm{value} \times \mathrm{tensor1}_i \times \mathrm{tensor2}_i.</span><span>
</span><span id="line-175"></span><span class="hs-comment">-- \]</span><span>
</span><span id="line-176"></span><span class="hs-comment">--</span><span>
</span><span id="line-177"></span><span class="hs-comment">-- See 'addcdiv' for a version of this function where 'tensor1' and 'tensor2'</span><span>
</span><span id="line-178"></span><span class="hs-comment">-- are divided rather than multiplied.</span><span>
</span><span id="line-179"></span><span class="hs-comment">--</span><span>
</span><span id="line-180"></span><span class="hs-comment">-- Note further that for inputs of type 'Float' or 'Double',</span><span>
</span><span id="line-181"></span><span class="hs-comment">-- 'value' must be a real number, otherwise it must be an integer.</span><span>
</span><span id="line-182"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#addcmul"><span class="hs-identifier hs-type">addcmul</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-183"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679667407"><span class="annot"><a href="#local-6989586621679667407"><span class="hs-identifier hs-type">scalar</span></a></span></span><span> </span><span id="local-6989586621679667406"><span class="annot"><a href="#local-6989586621679667406"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679667405"><span class="annot"><a href="#local-6989586621679667405"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679667404"><span class="annot"><a href="#local-6989586621679667404"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679667403"><span class="annot"><a href="#local-6989586621679667403"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679667402"><span class="annot"><a href="#local-6989586621679667402"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679667401"><span class="annot"><a href="#local-6989586621679667401"><span class="hs-identifier hs-type">gradient'</span></a></span></span><span> </span><span id="local-6989586621679667400"><span class="annot"><a href="#local-6989586621679667400"><span class="hs-identifier hs-type">layout'</span></a></span></span><span> </span><span id="local-6989586621679667399"><span class="annot"><a href="#local-6989586621679667399"><span class="hs-identifier hs-type">device'</span></a></span></span><span> </span><span id="local-6989586621679667398"><span class="annot"><a href="#local-6989586621679667398"><span class="hs-identifier hs-type">dataType'</span></a></span></span><span> </span><span id="local-6989586621679667397"><span class="annot"><a href="#local-6989586621679667397"><span class="hs-identifier hs-type">shape'</span></a></span></span><span> </span><span id="local-6989586621679667396"><span class="annot"><a href="#local-6989586621679667396"><span class="hs-identifier hs-type">gradient''</span></a></span></span><span> </span><span id="local-6989586621679667395"><span class="annot"><a href="#local-6989586621679667395"><span class="hs-identifier hs-type">layout''</span></a></span></span><span> </span><span id="local-6989586621679667394"><span class="annot"><a href="#local-6989586621679667394"><span class="hs-identifier hs-type">device''</span></a></span></span><span> </span><span id="local-6989586621679667393"><span class="annot"><a href="#local-6989586621679667393"><span class="hs-identifier hs-type">dataType''</span></a></span></span><span> </span><span id="local-6989586621679667392"><span class="annot"><a href="#local-6989586621679667392"><span class="hs-identifier hs-type">shape''</span></a></span></span><span> </span><span id="local-6989586621679667391"><span class="annot"><a href="#local-6989586621679667391"><span class="hs-identifier hs-type">m</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-184"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Scalar.html#Scalar"><span class="hs-identifier hs-type">Scalar</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667407"><span class="hs-identifier hs-type">scalar</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier hs-type">MonadThrow</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667391"><span class="hs-identifier hs-type">m</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-185"></span><span>  </span><span class="hs-comment">-- | input scalar</span><span>
</span><span id="line-186"></span><span>  </span><span class="annot"><a href="#local-6989586621679667407"><span class="hs-identifier hs-type">scalar</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-187"></span><span>  </span><span class="hs-comment">-- | first other tensor</span><span>
</span><span id="line-188"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667406"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667405"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667404"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667403"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667402"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-189"></span><span>  </span><span class="hs-comment">-- | second other tensor</span><span>
</span><span id="line-190"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667401"><span class="hs-identifier hs-type">gradient'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667400"><span class="hs-identifier hs-type">layout'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667399"><span class="hs-identifier hs-type">device'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667398"><span class="hs-identifier hs-type">dataType'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667397"><span class="hs-identifier hs-type">shape'</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-191"></span><span>  </span><span class="hs-comment">-- | input tensor</span><span>
</span><span id="line-192"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667396"><span class="hs-identifier hs-type">gradient''</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667395"><span class="hs-identifier hs-type">layout''</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667394"><span class="hs-identifier hs-type">device''</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667393"><span class="hs-identifier hs-type">dataType''</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667392"><span class="hs-identifier hs-type">shape''</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-193"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-194"></span><span>  </span><span class="annot"><a href="#local-6989586621679667391"><span class="hs-identifier hs-type">m</span></a></span><span>
</span><span id="line-195"></span><span>    </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-196"></span><span>        </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679667406"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667401"><span class="hs-identifier hs-type">gradient'</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667396"><span class="hs-identifier hs-type">gradient''</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-197"></span><span>        </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679667405"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667400"><span class="hs-identifier hs-type">layout'</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667395"><span class="hs-identifier hs-type">layout''</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-198"></span><span>        </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679667404"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667399"><span class="hs-identifier hs-type">device'</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667394"><span class="hs-identifier hs-type">device''</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-199"></span><span>        </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679667403"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667398"><span class="hs-identifier hs-type">dataType'</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667393"><span class="hs-identifier hs-type">dataType''</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-200"></span><span>        </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679667402"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667397"><span class="hs-identifier hs-type">shape'</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667392"><span class="hs-identifier hs-type">shape''</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-201"></span><span>    </span><span class="hs-special">)</span><span>
</span><span id="line-202"></span><span id="addcmul"><span class="annot"><span class="annottext">addcmul :: scalar
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; Tensor gradient'' layout'' device'' dataType'' shape''
-&gt; m (Tensor
        (gradient &lt;|&gt; (gradient' &lt;|&gt; gradient''))
        (layout &lt;+&gt; (layout' &lt;+&gt; layout''))
        (device &lt;+&gt; (device' &lt;+&gt; device''))
        (dataType &lt;+&gt; (dataType' &lt;+&gt; dataType''))
        (shape &lt;+&gt; (shape' &lt;+&gt; shape'')))
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#addcmul"><span class="hs-identifier hs-var hs-var">addcmul</span></a></span></span><span> </span><span id="local-6989586621679667390"><span class="annot"><span class="annottext">scalar
</span><a href="#local-6989586621679667390"><span class="hs-identifier hs-var">scalar</span></a></span></span><span> </span><span id="local-6989586621679667389"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679667389"><span class="hs-identifier hs-var">tensor1</span></a></span></span><span> </span><span id="local-6989586621679667388"><span class="annot"><span class="annottext">Tensor gradient' layout' device' dataType' shape'
</span><a href="#local-6989586621679667388"><span class="hs-identifier hs-var">tensor2</span></a></span></span><span> </span><span id="local-6989586621679667387"><span class="annot"><span class="annottext">Tensor gradient'' layout'' device'' dataType'' shape''
</span><a href="#local-6989586621679667387"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO
  (Tensor
     (Or
        (Gradient RequiresGradient)
        gradient
        (Or (Gradient RequiresGradient) gradient' gradient''))
     (Unify
        (Layout LayoutType)
        layout
        (Unify (Layout LayoutType) layout' layout''))
     (Unify
        (Device (DeviceType Nat))
        device
        (Unify (Device (DeviceType Nat)) device' device''))
     (Unify
        (DataType DType)
        dataType
        (Unify (DataType DType) dataType' dataType''))
     (Unify
        (Shape [Dim (Name Symbol) (Size Nat)])
        shape
        (Unify (Shape [Dim (Name Symbol) (Size Nat)]) shape' shape'')))
-&gt; m (Tensor
        (Or
           (Gradient RequiresGradient)
           gradient
           (Or (Gradient RequiresGradient) gradient' gradient''))
        (Unify
           (Layout LayoutType)
           layout
           (Unify (Layout LayoutType) layout' layout''))
        (Unify
           (Device (DeviceType Nat))
           device
           (Unify (Device (DeviceType Nat)) device' device''))
        (Unify
           (DataType DType)
           dataType
           (Unify (DataType DType) dataType' dataType''))
        (Unify
           (Shape [Dim (Name Symbol) (Size Nat)])
           shape
           (Unify (Shape [Dim (Name Symbol) (Size Nat)]) shape' shape'')))
forall a (m :: * -&gt; *). MonadThrow m =&gt; IO a -&gt; m a
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">unsafeThrowableIO</span></a></span><span> </span><span class="annot"><span class="annottext">(IO
   (Tensor
      (Or
         (Gradient RequiresGradient)
         gradient
         (Or (Gradient RequiresGradient) gradient' gradient''))
      (Unify
         (Layout LayoutType)
         layout
         (Unify (Layout LayoutType) layout' layout''))
      (Unify
         (Device (DeviceType Nat))
         device
         (Unify (Device (DeviceType Nat)) device' device''))
      (Unify
         (DataType DType)
         dataType
         (Unify (DataType DType) dataType' dataType''))
      (Unify
         (Shape [Dim (Name Symbol) (Size Nat)])
         shape
         (Unify (Shape [Dim (Name Symbol) (Size Nat)]) shape' shape'')))
 -&gt; m (Tensor
         (Or
            (Gradient RequiresGradient)
            gradient
            (Or (Gradient RequiresGradient) gradient' gradient''))
         (Unify
            (Layout LayoutType)
            layout
            (Unify (Layout LayoutType) layout' layout''))
         (Unify
            (Device (DeviceType Nat))
            device
            (Unify (Device (DeviceType Nat)) device' device''))
         (Unify
            (DataType DType)
            dataType
            (Unify (DataType DType) dataType' dataType''))
         (Unify
            (Shape [Dim (Name Symbol) (Size Nat)])
            shape
            (Unify (Shape [Dim (Name Symbol) (Size Nat)]) shape' shape''))))
-&gt; IO
     (Tensor
        (Or
           (Gradient RequiresGradient)
           gradient
           (Or (Gradient RequiresGradient) gradient' gradient''))
        (Unify
           (Layout LayoutType)
           layout
           (Unify (Layout LayoutType) layout' layout''))
        (Unify
           (Device (DeviceType Nat))
           device
           (Unify (Device (DeviceType Nat)) device' device''))
        (Unify
           (DataType DType)
           dataType
           (Unify (DataType DType) dataType' dataType''))
        (Unify
           (Shape [Dim (Name Symbol) (Size Nat)])
           shape
           (Unify (Shape [Dim (Name Symbol) (Size Nat)]) shape' shape'')))
-&gt; m (Tensor
        (Or
           (Gradient RequiresGradient)
           gradient
           (Or (Gradient RequiresGradient) gradient' gradient''))
        (Unify
           (Layout LayoutType)
           layout
           (Unify (Layout LayoutType) layout' layout''))
        (Unify
           (Device (DeviceType Nat))
           device
           (Unify (Device (DeviceType Nat)) device' device''))
        (Unify
           (DataType DType)
           dataType
           (Unify (DataType DType) dataType' dataType''))
        (Unify
           (Shape [Dim (Name Symbol) (Size Nat)])
           shape
           (Unify (Shape [Dim (Name Symbol) (Size Nat)]) shape' shape'')))
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; ForeignPtr Scalar
 -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient'' layout'' device'' dataType'' shape''
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; scalar
-&gt; IO
     (Tensor
        (Or
           (Gradient RequiresGradient)
           gradient
           (Or (Gradient RequiresGradient) gradient' gradient''))
        (Unify
           (Layout LayoutType)
           layout
           (Unify (Layout LayoutType) layout' layout''))
        (Unify
           (Device (DeviceType Nat))
           device
           (Unify (Device (DeviceType Nat)) device' device''))
        (Unify
           (DataType DType)
           dataType
           (Unify (DataType DType) dataType' dataType''))
        (Unify
           (Shape [Dim (Name Symbol) (Size Nat)])
           shape
           (Unify (Shape [Dim (Name Symbol) (Size Nat)]) shape' shape'')))
forall a ca x1 cx1 x2 cx2 x3 cx3 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable x3 cx3,
 Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; cx3 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; x2 -&gt; x3 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast4</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; ForeignPtr Tensor
-&gt; ForeignPtr Tensor
-&gt; ForeignPtr Scalar
-&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.addcmul_ttts</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient'' layout'' device'' dataType'' shape''
</span><a href="#local-6989586621679667387"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679667389"><span class="hs-identifier hs-var">tensor1</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient' layout' device' dataType' shape'
</span><a href="#local-6989586621679667388"><span class="hs-identifier hs-var">tensor2</span></a></span><span> </span><span class="annot"><span class="annottext">scalar
</span><a href="#local-6989586621679667390"><span class="hs-identifier hs-var">scalar</span></a></span><span>
</span><span id="line-203"></span><span>
</span><span id="line-204"></span><span class="hs-comment">-- | Returns a new tensor with the arcsine of the elements of 'input':</span><span>
</span><span id="line-205"></span><span class="hs-comment">-- \[</span><span>
</span><span id="line-206"></span><span class="hs-comment">-- \mathrm{output}_i = \sin^{-1} \left(\mathrm{input}_i\right).</span><span>
</span><span id="line-207"></span><span class="hs-comment">-- \]</span><span>
</span><span id="line-208"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#asin"><span class="hs-identifier hs-type">asin</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-209"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679667384"><span class="annot"><a href="#local-6989586621679667384"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679667383"><span class="annot"><a href="#local-6989586621679667383"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679667382"><span class="annot"><a href="#local-6989586621679667382"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679667381"><span class="annot"><a href="#local-6989586621679667381"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679667380"><span class="annot"><a href="#local-6989586621679667380"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-210"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-211"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667384"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667383"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667382"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667381"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667380"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-212"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-213"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667384"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667383"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667382"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667381"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667380"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-214"></span><span id="asin"><span class="annot"><span class="annottext">asin :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#asin"><span class="hs-identifier hs-var hs-var">asin</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; (Tensor gradient layout device dataType shape
    -&gt; IO (Tensor gradient layout device dataType shape))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.asin_t</span></a></span><span>
</span><span id="line-215"></span><span>
</span><span id="line-216"></span><span class="hs-comment">-- | Returns a new tensor with the inverse hyperbolic sine of the elements of 'input':</span><span>
</span><span id="line-217"></span><span class="hs-comment">-- \[</span><span>
</span><span id="line-218"></span><span class="hs-comment">-- \mathrm{output}_i = \sinh^{-1} \left(\mathrm{input}_i\right).</span><span>
</span><span id="line-219"></span><span class="hs-comment">-- \]</span><span>
</span><span id="line-220"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#asinh"><span class="hs-identifier hs-type">asinh</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-221"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679667377"><span class="annot"><a href="#local-6989586621679667377"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679667376"><span class="annot"><a href="#local-6989586621679667376"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679667375"><span class="annot"><a href="#local-6989586621679667375"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679667374"><span class="annot"><a href="#local-6989586621679667374"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679667373"><span class="annot"><a href="#local-6989586621679667373"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-222"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-223"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667377"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667376"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667375"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667374"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667373"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-224"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-225"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667377"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667376"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667375"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667374"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667373"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-226"></span><span id="asinh"><span class="annot"><span class="annottext">asinh :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#asinh"><span class="hs-identifier hs-var hs-var">asinh</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; (Tensor gradient layout device dataType shape
    -&gt; IO (Tensor gradient layout device dataType shape))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.asinh_t</span></a></span><span>
</span><span id="line-227"></span><span>
</span><span id="line-228"></span><span class="hs-comment">-- | Returns a new tensor with the arctangent of the elements of 'input':</span><span>
</span><span id="line-229"></span><span class="hs-comment">-- \[</span><span>
</span><span id="line-230"></span><span class="hs-comment">-- \mathrm{output}_i = \tan^{-1} \left(\mathrm{input}_i\right).</span><span>
</span><span id="line-231"></span><span class="hs-comment">-- \]</span><span>
</span><span id="line-232"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#atan"><span class="hs-identifier hs-type">atan</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-233"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679667370"><span class="annot"><a href="#local-6989586621679667370"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679667369"><span class="annot"><a href="#local-6989586621679667369"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679667368"><span class="annot"><a href="#local-6989586621679667368"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679667367"><span class="annot"><a href="#local-6989586621679667367"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679667366"><span class="annot"><a href="#local-6989586621679667366"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-234"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-235"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667370"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667369"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667368"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667367"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667366"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-236"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-237"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667370"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667369"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667368"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667367"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667366"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-238"></span><span id="atan"><span class="annot"><span class="annottext">atan :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#atan"><span class="hs-identifier hs-var hs-var">atan</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; (Tensor gradient layout device dataType shape
    -&gt; IO (Tensor gradient layout device dataType shape))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.atan_t</span></a></span><span>
</span><span id="line-239"></span><span>
</span><span id="line-240"></span><span class="hs-comment">-- | Returns a new tensor with the inverse hyperbolic tangent of the elements of 'input':</span><span>
</span><span id="line-241"></span><span class="hs-comment">-- \[</span><span>
</span><span id="line-242"></span><span class="hs-comment">-- \mathrm{output}_i = \tanh^{-1} \left(\mathrm{input}_i\right).</span><span>
</span><span id="line-243"></span><span class="hs-comment">-- \]</span><span>
</span><span id="line-244"></span><span class="hs-comment">--</span><span>
</span><span id="line-245"></span><span class="hs-comment">-- Note that the domain of the inverse hyperbolic tangent is \((-1, 1)\), and</span><span>
</span><span id="line-246"></span><span class="hs-comment">-- values outside this range will be mapped to \(\mathrm{NaN}\),</span><span>
</span><span id="line-247"></span><span class="hs-comment">-- except for the values \(1\) and \(-1\) for which the output is mapped to</span><span>
</span><span id="line-248"></span><span class="hs-comment">-- \(\pm \infty\) respectively.</span><span>
</span><span id="line-249"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#atanh"><span class="hs-identifier hs-type">atanh</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-250"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679667363"><span class="annot"><a href="#local-6989586621679667363"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679667362"><span class="annot"><a href="#local-6989586621679667362"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679667361"><span class="annot"><a href="#local-6989586621679667361"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679667360"><span class="annot"><a href="#local-6989586621679667360"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679667359"><span class="annot"><a href="#local-6989586621679667359"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-251"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-252"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667363"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667362"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667361"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667360"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667359"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-253"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-254"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667363"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667362"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667361"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667360"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667359"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-255"></span><span id="atanh"><span class="annot"><span class="annottext">atanh :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#atanh"><span class="hs-identifier hs-var hs-var">atanh</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; (Tensor gradient layout device dataType shape
    -&gt; IO (Tensor gradient layout device dataType shape))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.atanh_t</span></a></span><span>
</span><span id="line-256"></span><span>
</span><span id="line-257"></span><span class="hs-comment">-- | Element-wise arctangent of 'input' and 'other' with consideration of the quadrant.</span><span>
</span><span id="line-258"></span><span class="hs-comment">-- Returns a new tensor where each element is the signed angle in radians between</span><span>
</span><span id="line-259"></span><span class="hs-comment">-- the vectors \(\mathrm{other}_i, \mathrm{input}_i)\) and \((1,0)\).</span><span>
</span><span id="line-260"></span><span class="hs-comment">-- Here $\mathrm{other}_i$, the \(i\)-th element of the second argument of this function,</span><span>
</span><span id="line-261"></span><span class="hs-comment">-- is the x coordinate while $\mathrm{input}_i$, the \(i\)-th element of the first argument,</span><span>
</span><span id="line-262"></span><span class="hs-comment">-- is the y coordinate.</span><span>
</span><span id="line-263"></span><span class="hs-comment">--</span><span>
</span><span id="line-264"></span><span class="hs-comment">-- Note that the shapes of 'input' and 'other' must be broadcastable.</span><span>
</span><span id="line-265"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#atan2"><span class="hs-identifier hs-type">atan2</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-266"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679667356"><span class="annot"><a href="#local-6989586621679667356"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679667355"><span class="annot"><a href="#local-6989586621679667355"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679667354"><span class="annot"><a href="#local-6989586621679667354"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679667353"><span class="annot"><a href="#local-6989586621679667353"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679667352"><span class="annot"><a href="#local-6989586621679667352"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679667351"><span class="annot"><a href="#local-6989586621679667351"><span class="hs-identifier hs-type">gradient'</span></a></span></span><span> </span><span id="local-6989586621679667350"><span class="annot"><a href="#local-6989586621679667350"><span class="hs-identifier hs-type">layout'</span></a></span></span><span> </span><span id="local-6989586621679667349"><span class="annot"><a href="#local-6989586621679667349"><span class="hs-identifier hs-type">device'</span></a></span></span><span> </span><span id="local-6989586621679667348"><span class="annot"><a href="#local-6989586621679667348"><span class="hs-identifier hs-type">dataType'</span></a></span></span><span> </span><span id="local-6989586621679667347"><span class="annot"><a href="#local-6989586621679667347"><span class="hs-identifier hs-type">shape'</span></a></span></span><span> </span><span id="local-6989586621679667346"><span class="annot"><a href="#local-6989586621679667346"><span class="hs-identifier hs-type">shape''</span></a></span></span><span> </span><span id="local-6989586621679667345"><span class="annot"><a href="#local-6989586621679667345"><span class="hs-identifier hs-type">m</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-267"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier hs-type">MonadThrow</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667345"><span class="hs-identifier hs-type">m</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679667346"><span class="hs-identifier hs-type">shape''</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#BroadcastShapesF"><span class="hs-identifier hs-type">BroadcastShapesF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667352"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667347"><span class="hs-identifier hs-type">shape'</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Catch"><span class="hs-identifier hs-type">Catch</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667346"><span class="hs-identifier hs-type">shape''</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-268"></span><span>  </span><span class="hs-comment">-- | input tensor</span><span>
</span><span id="line-269"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667356"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667355"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667354"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667353"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667352"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-270"></span><span>  </span><span class="hs-comment">-- | other input tensor</span><span>
</span><span id="line-271"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667351"><span class="hs-identifier hs-type">gradient'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667350"><span class="hs-identifier hs-type">layout'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667349"><span class="hs-identifier hs-type">device'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667348"><span class="hs-identifier hs-type">dataType'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667347"><span class="hs-identifier hs-type">shape'</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-272"></span><span>  </span><span class="hs-comment">-- | output tensor</span><span>
</span><span id="line-273"></span><span>  </span><span class="annot"><a href="#local-6989586621679667345"><span class="hs-identifier hs-type">m</span></a></span><span>
</span><span id="line-274"></span><span>    </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-275"></span><span>        </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679667356"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667351"><span class="hs-identifier hs-type">gradient'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-276"></span><span>        </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679667355"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667350"><span class="hs-identifier hs-type">layout'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-277"></span><span>        </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679667354"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667349"><span class="hs-identifier hs-type">device'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-278"></span><span>        </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679667353"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667348"><span class="hs-identifier hs-type">dataType'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-279"></span><span>        </span><span class="annot"><a href="#local-6989586621679667346"><span class="hs-identifier hs-type">shape''</span></a></span><span>
</span><span id="line-280"></span><span>    </span><span class="hs-special">)</span><span>
</span><span id="line-281"></span><span id="atan2"><span class="annot"><span class="annottext">atan2 :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; m (Tensor
        (gradient &lt;|&gt; gradient')
        (layout &lt;+&gt; layout')
        (device &lt;+&gt; device')
        (dataType &lt;+&gt; dataType')
        shape'')
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#atan2"><span class="hs-identifier hs-var hs-var">atan2</span></a></span></span><span> </span><span id="local-6989586621679667344"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679667344"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span id="local-6989586621679667343"><span class="annot"><span class="annottext">Tensor gradient' layout' device' dataType' shape'
</span><a href="#local-6989586621679667343"><span class="hs-identifier hs-var">other</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO
  (Tensor
     (Or (Gradient RequiresGradient) gradient gradient')
     (Unify (Layout LayoutType) layout layout')
     (Unify (Device (DeviceType Nat)) device device')
     (Unify (DataType DType) dataType dataType')
     shape'')
-&gt; m (Tensor
        (Or (Gradient RequiresGradient) gradient gradient')
        (Unify (Layout LayoutType) layout layout')
        (Unify (Device (DeviceType Nat)) device device')
        (Unify (DataType DType) dataType dataType')
        shape'')
forall a (m :: * -&gt; *). MonadThrow m =&gt; IO a -&gt; m a
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">unsafeThrowableIO</span></a></span><span> </span><span class="annot"><span class="annottext">(IO
   (Tensor
      (Or (Gradient RequiresGradient) gradient gradient')
      (Unify (Layout LayoutType) layout layout')
      (Unify (Device (DeviceType Nat)) device device')
      (Unify (DataType DType) dataType dataType')
      shape'')
 -&gt; m (Tensor
         (Or (Gradient RequiresGradient) gradient gradient')
         (Unify (Layout LayoutType) layout layout')
         (Unify (Device (DeviceType Nat)) device device')
         (Unify (DataType DType) dataType dataType')
         shape''))
-&gt; IO
     (Tensor
        (Or (Gradient RequiresGradient) gradient gradient')
        (Unify (Layout LayoutType) layout layout')
        (Unify (Device (DeviceType Nat)) device device')
        (Unify (DataType DType) dataType dataType')
        shape'')
-&gt; m (Tensor
        (Or (Gradient RequiresGradient) gradient gradient')
        (Unify (Layout LayoutType) layout layout')
        (Unify (Device (DeviceType Nat)) device device')
        (Unify (DataType DType) dataType dataType')
        shape'')
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; IO
     (Tensor
        (Or (Gradient RequiresGradient) gradient gradient')
        (Unify (Layout LayoutType) layout layout')
        (Unify (Device (DeviceType Nat)) device device')
        (Unify (DataType DType) dataType dataType')
        shape'')
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.atan2_tt</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679667344"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient' layout' device' dataType' shape'
</span><a href="#local-6989586621679667343"><span class="hs-identifier hs-var">other</span></a></span><span>
</span><span id="line-282"></span><span>
</span><span id="line-283"></span><span class="hs-comment">-- | Computes the bitwise NOT of the given 'input' tensor.</span><span>
</span><span id="line-284"></span><span class="hs-comment">-- The data type of the 'input' tensor must be 'Bool' or an integral data type.</span><span>
</span><span id="line-285"></span><span class="hs-comment">-- For 'Bool' tensors, the function computes the logical NOT.</span><span>
</span><span id="line-286"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#bitwiseNot"><span class="hs-identifier hs-type">bitwiseNot</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-287"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679667340"><span class="annot"><a href="#local-6989586621679667340"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679667339"><span class="annot"><a href="#local-6989586621679667339"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679667338"><span class="annot"><a href="#local-6989586621679667338"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679667337"><span class="annot"><a href="#local-6989586621679667337"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679667336"><span class="annot"><a href="#local-6989586621679667336"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-288"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-289"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667340"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667339"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667338"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667337"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667336"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-290"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-291"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667340"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667339"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667338"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#Bool"><span class="hs-identifier hs-type">Bool</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679667336"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-292"></span><span id="bitwiseNot"><span class="annot"><span class="annottext">bitwiseNot :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device ('DataType 'Bool) shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#bitwiseNot"><span class="hs-identifier hs-var hs-var">bitwiseNot</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device ('DataType 'Bool) shape)
-&gt; Tensor gradient layout device ('DataType 'Bool) shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device ('DataType 'Bool) shape)
 -&gt; Tensor gradient layout device ('DataType 'Bool) shape)
-&gt; (Tensor gradient layout device dataType shape
    -&gt; IO (Tensor gradient layout device ('DataType 'Bool) shape))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device ('DataType 'Bool) shape
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; IO (Tensor gradient layout device ('DataType 'Bool) shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.bitwise_not_t</span></a></span><span>
</span><span id="line-293"></span><span>
</span><span id="line-294"></span><span class="hs-comment">-- | Computes the bitwise AND of the 'input' and the 'other' tensor.</span><span>
</span><span id="line-295"></span><span class="hs-comment">-- The data type of the tensors must be 'Bool' or an integral data type.</span><span>
</span><span id="line-296"></span><span class="hs-comment">-- For 'Bool' tensors, the function computes the logical AND.</span><span>
</span><span id="line-297"></span><span class="hs-comment">--</span><span>
</span><span id="line-298"></span><span class="hs-comment">-- See 'bitwiseAndScalar' for a version of this function where 'other'</span><span>
</span><span id="line-299"></span><span class="hs-comment">-- is a scalar.</span><span>
</span><span id="line-300"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#bitwiseAnd"><span class="hs-identifier hs-type">bitwiseAnd</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-301"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679667333"><span class="annot"><a href="#local-6989586621679667333"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679667332"><span class="annot"><a href="#local-6989586621679667332"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679667331"><span class="annot"><a href="#local-6989586621679667331"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679667330"><span class="annot"><a href="#local-6989586621679667330"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679667329"><span class="annot"><a href="#local-6989586621679667329"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679667328"><span class="annot"><a href="#local-6989586621679667328"><span class="hs-identifier hs-type">gradient'</span></a></span></span><span> </span><span id="local-6989586621679667327"><span class="annot"><a href="#local-6989586621679667327"><span class="hs-identifier hs-type">layout'</span></a></span></span><span> </span><span id="local-6989586621679667326"><span class="annot"><a href="#local-6989586621679667326"><span class="hs-identifier hs-type">device'</span></a></span></span><span> </span><span id="local-6989586621679667325"><span class="annot"><a href="#local-6989586621679667325"><span class="hs-identifier hs-type">dataType'</span></a></span></span><span> </span><span id="local-6989586621679667324"><span class="annot"><a href="#local-6989586621679667324"><span class="hs-identifier hs-type">shape'</span></a></span></span><span> </span><span id="local-6989586621679667323"><span class="annot"><a href="#local-6989586621679667323"><span class="hs-identifier hs-type">m</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-302"></span><span>  </span><span class="annot"><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier hs-type">MonadThrow</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667323"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-303"></span><span>  </span><span class="hs-comment">-- | input tensor</span><span>
</span><span id="line-304"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667333"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667332"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667331"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667330"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667329"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-305"></span><span>  </span><span class="hs-comment">-- | other tensor</span><span>
</span><span id="line-306"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667328"><span class="hs-identifier hs-type">gradient'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667327"><span class="hs-identifier hs-type">layout'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667326"><span class="hs-identifier hs-type">device'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667325"><span class="hs-identifier hs-type">dataType'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667324"><span class="hs-identifier hs-type">shape'</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-307"></span><span>  </span><span class="hs-comment">-- | output tensor</span><span>
</span><span id="line-308"></span><span>  </span><span class="annot"><a href="#local-6989586621679667323"><span class="hs-identifier hs-type">m</span></a></span><span>
</span><span id="line-309"></span><span>    </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-310"></span><span>        </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679667333"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667328"><span class="hs-identifier hs-type">gradient'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-311"></span><span>        </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679667332"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667327"><span class="hs-identifier hs-type">layout'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-312"></span><span>        </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679667331"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667326"><span class="hs-identifier hs-type">device'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-313"></span><span>        </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679667330"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667325"><span class="hs-identifier hs-type">dataType'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-314"></span><span>        </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679667329"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667324"><span class="hs-identifier hs-type">shape'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-315"></span><span>    </span><span class="hs-special">)</span><span>
</span><span id="line-316"></span><span id="local-6989586621679667322"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679667322"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span id="bitwiseAnd"><span class="annot"><span class="annottext">bitwiseAnd :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; m (Tensor
        (gradient &lt;|&gt; gradient')
        (layout &lt;+&gt; layout')
        (device &lt;+&gt; device')
        (dataType &lt;+&gt; dataType')
        (shape &lt;+&gt; shape'))
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#bitwiseAnd"><span class="hs-operator hs-var hs-var">`bitwiseAnd`</span></a></span></span><span> </span><span id="local-6989586621679667321"><span class="annot"><span class="annottext">Tensor gradient' layout' device' dataType' shape'
</span><a href="#local-6989586621679667321"><span class="hs-identifier hs-var">other</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO
  (Tensor
     (Or (Gradient RequiresGradient) gradient gradient')
     (Unify (Layout LayoutType) layout layout')
     (Unify (Device (DeviceType Nat)) device device')
     (Unify (DataType DType) dataType dataType')
     (Unify (Shape [Dim (Name Symbol) (Size Nat)]) shape shape'))
-&gt; m (Tensor
        (Or (Gradient RequiresGradient) gradient gradient')
        (Unify (Layout LayoutType) layout layout')
        (Unify (Device (DeviceType Nat)) device device')
        (Unify (DataType DType) dataType dataType')
        (Unify (Shape [Dim (Name Symbol) (Size Nat)]) shape shape'))
forall a (m :: * -&gt; *). MonadThrow m =&gt; IO a -&gt; m a
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">unsafeThrowableIO</span></a></span><span> </span><span class="annot"><span class="annottext">(IO
   (Tensor
      (Or (Gradient RequiresGradient) gradient gradient')
      (Unify (Layout LayoutType) layout layout')
      (Unify (Device (DeviceType Nat)) device device')
      (Unify (DataType DType) dataType dataType')
      (Unify (Shape [Dim (Name Symbol) (Size Nat)]) shape shape'))
 -&gt; m (Tensor
         (Or (Gradient RequiresGradient) gradient gradient')
         (Unify (Layout LayoutType) layout layout')
         (Unify (Device (DeviceType Nat)) device device')
         (Unify (DataType DType) dataType dataType')
         (Unify (Shape [Dim (Name Symbol) (Size Nat)]) shape shape')))
-&gt; IO
     (Tensor
        (Or (Gradient RequiresGradient) gradient gradient')
        (Unify (Layout LayoutType) layout layout')
        (Unify (Device (DeviceType Nat)) device device')
        (Unify (DataType DType) dataType dataType')
        (Unify (Shape [Dim (Name Symbol) (Size Nat)]) shape shape'))
-&gt; m (Tensor
        (Or (Gradient RequiresGradient) gradient gradient')
        (Unify (Layout LayoutType) layout layout')
        (Unify (Device (DeviceType Nat)) device device')
        (Unify (DataType DType) dataType dataType')
        (Unify (Shape [Dim (Name Symbol) (Size Nat)]) shape shape'))
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; IO
     (Tensor
        (Or (Gradient RequiresGradient) gradient gradient')
        (Unify (Layout LayoutType) layout layout')
        (Unify (Device (DeviceType Nat)) device device')
        (Unify (DataType DType) dataType dataType')
        (Unify (Shape [Dim (Name Symbol) (Size Nat)]) shape shape'))
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.bitwise_and_tt</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679667322"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient' layout' device' dataType' shape'
</span><a href="#local-6989586621679667321"><span class="hs-identifier hs-var">other</span></a></span><span>
</span><span id="line-317"></span><span>
</span><span id="line-318"></span><span class="hs-comment">-- | Computes the bitwise AND of the tensor 'input' and the scalar 'other'.</span><span>
</span><span id="line-319"></span><span class="hs-comment">-- The data type of the inputs must be 'Bool' or an integral data type.</span><span>
</span><span id="line-320"></span><span class="hs-comment">-- If the data type is 'Bool', then the function computes the logical AND.</span><span>
</span><span id="line-321"></span><span class="hs-comment">--</span><span>
</span><span id="line-322"></span><span class="hs-comment">-- See 'bitwiseAnd' for a version of this function where 'other'</span><span>
</span><span id="line-323"></span><span class="hs-comment">-- is a tensor.</span><span>
</span><span id="line-324"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#bitwiseAndScalar"><span class="hs-identifier hs-type">bitwiseAndScalar</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-325"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679667318"><span class="annot"><a href="#local-6989586621679667318"><span class="hs-identifier hs-type">other</span></a></span></span><span> </span><span id="local-6989586621679667317"><span class="annot"><a href="#local-6989586621679667317"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679667316"><span class="annot"><a href="#local-6989586621679667316"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679667315"><span class="annot"><a href="#local-6989586621679667315"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679667314"><span class="annot"><a href="#local-6989586621679667314"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679667313"><span class="annot"><a href="#local-6989586621679667313"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-326"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Scalar.html#Scalar"><span class="hs-identifier hs-type">Scalar</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667318"><span class="hs-identifier hs-type">other</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-327"></span><span>  </span><span class="hs-comment">-- | input tensor</span><span>
</span><span id="line-328"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667317"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667316"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667315"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667314"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667313"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-329"></span><span>  </span><span class="hs-comment">-- | other scalar</span><span>
</span><span id="line-330"></span><span>  </span><span class="annot"><a href="#local-6989586621679667318"><span class="hs-identifier hs-type">other</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-331"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-332"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667317"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667316"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667315"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667314"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667313"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-333"></span><span id="local-6989586621679667312"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679667312"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span id="bitwiseAndScalar"><span class="annot"><span class="annottext">bitwiseAndScalar :: Tensor gradient layout device dataType shape
-&gt; other -&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#bitwiseAndScalar"><span class="hs-operator hs-var hs-var">`bitwiseAndScalar`</span></a></span></span><span> </span><span id="local-6989586621679667311"><span class="annot"><span class="annottext">other
</span><a href="#local-6989586621679667311"><span class="hs-identifier hs-var">other</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ForeignPtr Scalar -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; other
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr Scalar -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.bitwise_and_ts</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679667312"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">other
</span><a href="#local-6989586621679667311"><span class="hs-identifier hs-var">other</span></a></span><span>
</span><span id="line-334"></span><span>
</span><span id="line-335"></span><span class="hs-comment">-- | Computes the bitwise OR of the 'input' and the 'other' tensor.</span><span>
</span><span id="line-336"></span><span class="hs-comment">-- The data type of the tensors must be 'Bool' or an integral data type.</span><span>
</span><span id="line-337"></span><span class="hs-comment">-- For 'Bool' tensors, the function computes the logical OR.</span><span>
</span><span id="line-338"></span><span class="hs-comment">--</span><span>
</span><span id="line-339"></span><span class="hs-comment">-- See 'bitwiseOrScalar' for a version of this function where 'other'</span><span>
</span><span id="line-340"></span><span class="hs-comment">-- is a scalar.</span><span>
</span><span id="line-341"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#bitwiseOr"><span class="hs-identifier hs-type">bitwiseOr</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-342"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679667308"><span class="annot"><a href="#local-6989586621679667308"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679667307"><span class="annot"><a href="#local-6989586621679667307"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679667306"><span class="annot"><a href="#local-6989586621679667306"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679667305"><span class="annot"><a href="#local-6989586621679667305"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679667304"><span class="annot"><a href="#local-6989586621679667304"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679667303"><span class="annot"><a href="#local-6989586621679667303"><span class="hs-identifier hs-type">gradient'</span></a></span></span><span> </span><span id="local-6989586621679667302"><span class="annot"><a href="#local-6989586621679667302"><span class="hs-identifier hs-type">layout'</span></a></span></span><span> </span><span id="local-6989586621679667301"><span class="annot"><a href="#local-6989586621679667301"><span class="hs-identifier hs-type">device'</span></a></span></span><span> </span><span id="local-6989586621679667300"><span class="annot"><a href="#local-6989586621679667300"><span class="hs-identifier hs-type">dataType'</span></a></span></span><span> </span><span id="local-6989586621679667299"><span class="annot"><a href="#local-6989586621679667299"><span class="hs-identifier hs-type">shape'</span></a></span></span><span> </span><span id="local-6989586621679667298"><span class="annot"><a href="#local-6989586621679667298"><span class="hs-identifier hs-type">m</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-343"></span><span>  </span><span class="annot"><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier hs-type">MonadThrow</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667298"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-344"></span><span>  </span><span class="hs-comment">-- | input tensor</span><span>
</span><span id="line-345"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667308"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667307"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667306"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667305"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667304"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-346"></span><span>  </span><span class="hs-comment">-- | other tensor</span><span>
</span><span id="line-347"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667303"><span class="hs-identifier hs-type">gradient'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667302"><span class="hs-identifier hs-type">layout'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667301"><span class="hs-identifier hs-type">device'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667300"><span class="hs-identifier hs-type">dataType'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667299"><span class="hs-identifier hs-type">shape'</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-348"></span><span>  </span><span class="hs-comment">-- | output tensor</span><span>
</span><span id="line-349"></span><span>  </span><span class="annot"><a href="#local-6989586621679667298"><span class="hs-identifier hs-type">m</span></a></span><span>
</span><span id="line-350"></span><span>    </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-351"></span><span>        </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679667308"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667303"><span class="hs-identifier hs-type">gradient'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-352"></span><span>        </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679667307"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667302"><span class="hs-identifier hs-type">layout'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-353"></span><span>        </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679667306"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667301"><span class="hs-identifier hs-type">device'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-354"></span><span>        </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679667305"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667300"><span class="hs-identifier hs-type">dataType'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-355"></span><span>        </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679667304"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667299"><span class="hs-identifier hs-type">shape'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-356"></span><span>    </span><span class="hs-special">)</span><span>
</span><span id="line-357"></span><span id="local-6989586621679667297"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679667297"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span id="bitwiseOr"><span class="annot"><span class="annottext">bitwiseOr :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; m (Tensor
        (gradient &lt;|&gt; gradient')
        (layout &lt;+&gt; layout')
        (device &lt;+&gt; device')
        (dataType &lt;+&gt; dataType')
        (shape &lt;+&gt; shape'))
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#bitwiseOr"><span class="hs-operator hs-var hs-var">`bitwiseOr`</span></a></span></span><span> </span><span id="local-6989586621679667296"><span class="annot"><span class="annottext">Tensor gradient' layout' device' dataType' shape'
</span><a href="#local-6989586621679667296"><span class="hs-identifier hs-var">other</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO
  (Tensor
     (Or (Gradient RequiresGradient) gradient gradient')
     (Unify (Layout LayoutType) layout layout')
     (Unify (Device (DeviceType Nat)) device device')
     (Unify (DataType DType) dataType dataType')
     (Unify (Shape [Dim (Name Symbol) (Size Nat)]) shape shape'))
-&gt; m (Tensor
        (Or (Gradient RequiresGradient) gradient gradient')
        (Unify (Layout LayoutType) layout layout')
        (Unify (Device (DeviceType Nat)) device device')
        (Unify (DataType DType) dataType dataType')
        (Unify (Shape [Dim (Name Symbol) (Size Nat)]) shape shape'))
forall a (m :: * -&gt; *). MonadThrow m =&gt; IO a -&gt; m a
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">unsafeThrowableIO</span></a></span><span> </span><span class="annot"><span class="annottext">(IO
   (Tensor
      (Or (Gradient RequiresGradient) gradient gradient')
      (Unify (Layout LayoutType) layout layout')
      (Unify (Device (DeviceType Nat)) device device')
      (Unify (DataType DType) dataType dataType')
      (Unify (Shape [Dim (Name Symbol) (Size Nat)]) shape shape'))
 -&gt; m (Tensor
         (Or (Gradient RequiresGradient) gradient gradient')
         (Unify (Layout LayoutType) layout layout')
         (Unify (Device (DeviceType Nat)) device device')
         (Unify (DataType DType) dataType dataType')
         (Unify (Shape [Dim (Name Symbol) (Size Nat)]) shape shape')))
-&gt; IO
     (Tensor
        (Or (Gradient RequiresGradient) gradient gradient')
        (Unify (Layout LayoutType) layout layout')
        (Unify (Device (DeviceType Nat)) device device')
        (Unify (DataType DType) dataType dataType')
        (Unify (Shape [Dim (Name Symbol) (Size Nat)]) shape shape'))
-&gt; m (Tensor
        (Or (Gradient RequiresGradient) gradient gradient')
        (Unify (Layout LayoutType) layout layout')
        (Unify (Device (DeviceType Nat)) device device')
        (Unify (DataType DType) dataType dataType')
        (Unify (Shape [Dim (Name Symbol) (Size Nat)]) shape shape'))
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; IO
     (Tensor
        (Or (Gradient RequiresGradient) gradient gradient')
        (Unify (Layout LayoutType) layout layout')
        (Unify (Device (DeviceType Nat)) device device')
        (Unify (DataType DType) dataType dataType')
        (Unify (Shape [Dim (Name Symbol) (Size Nat)]) shape shape'))
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.bitwise_or_tt</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679667297"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient' layout' device' dataType' shape'
</span><a href="#local-6989586621679667296"><span class="hs-identifier hs-var">other</span></a></span><span>
</span><span id="line-358"></span><span>
</span><span id="line-359"></span><span class="hs-comment">-- | Computes the bitwise OR of the tensor 'input' and the scalar 'other'.</span><span>
</span><span id="line-360"></span><span class="hs-comment">-- The data type of the inputs must be 'Bool' or an integral data type.</span><span>
</span><span id="line-361"></span><span class="hs-comment">-- If the data type is 'Bool', then the function computes the logical OR.</span><span>
</span><span id="line-362"></span><span class="hs-comment">--</span><span>
</span><span id="line-363"></span><span class="hs-comment">-- See 'bitwiseOr' for a version of this function where 'other'</span><span>
</span><span id="line-364"></span><span class="hs-comment">-- is a tensor.</span><span>
</span><span id="line-365"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#bitwiseOrScalar"><span class="hs-identifier hs-type">bitwiseOrScalar</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-366"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679667293"><span class="annot"><a href="#local-6989586621679667293"><span class="hs-identifier hs-type">other</span></a></span></span><span> </span><span id="local-6989586621679667292"><span class="annot"><a href="#local-6989586621679667292"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679667291"><span class="annot"><a href="#local-6989586621679667291"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679667290"><span class="annot"><a href="#local-6989586621679667290"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679667289"><span class="annot"><a href="#local-6989586621679667289"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679667288"><span class="annot"><a href="#local-6989586621679667288"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-367"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Scalar.html#Scalar"><span class="hs-identifier hs-type">Scalar</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667293"><span class="hs-identifier hs-type">other</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-368"></span><span>  </span><span class="hs-comment">-- | input tensor</span><span>
</span><span id="line-369"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667292"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667291"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667290"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667289"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667288"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-370"></span><span>  </span><span class="hs-comment">-- | other scalar</span><span>
</span><span id="line-371"></span><span>  </span><span class="annot"><a href="#local-6989586621679667293"><span class="hs-identifier hs-type">other</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-372"></span><span>  </span><span class="hs-comment">-- | output tensor</span><span>
</span><span id="line-373"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667292"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667291"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667290"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667289"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667288"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-374"></span><span id="local-6989586621679667287"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679667287"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span id="bitwiseOrScalar"><span class="annot"><span class="annottext">bitwiseOrScalar :: Tensor gradient layout device dataType shape
-&gt; other -&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#bitwiseOrScalar"><span class="hs-operator hs-var hs-var">`bitwiseOrScalar`</span></a></span></span><span> </span><span id="local-6989586621679667286"><span class="annot"><span class="annottext">other
</span><a href="#local-6989586621679667286"><span class="hs-identifier hs-var">other</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ForeignPtr Scalar -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; other
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr Scalar -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.bitwise_or_ts</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679667287"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">other
</span><a href="#local-6989586621679667286"><span class="hs-identifier hs-var">other</span></a></span><span>
</span><span id="line-375"></span><span>
</span><span id="line-376"></span><span class="hs-comment">-- | Computes the bitwise XOR of the 'input' and the 'other' tensor.</span><span>
</span><span id="line-377"></span><span class="hs-comment">-- The data type of the tensors must be 'Bool' or an integral data type.</span><span>
</span><span id="line-378"></span><span class="hs-comment">-- For 'Bool' tensors, the function computes the logical XOR.</span><span>
</span><span id="line-379"></span><span class="hs-comment">--</span><span>
</span><span id="line-380"></span><span class="hs-comment">-- See 'bitwiseXorScalar' for a version of this function where 'other'</span><span>
</span><span id="line-381"></span><span class="hs-comment">-- is a scalar.</span><span>
</span><span id="line-382"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#bitwiseXor"><span class="hs-identifier hs-type">bitwiseXor</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-383"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679667283"><span class="annot"><a href="#local-6989586621679667283"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679667282"><span class="annot"><a href="#local-6989586621679667282"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679667281"><span class="annot"><a href="#local-6989586621679667281"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679667280"><span class="annot"><a href="#local-6989586621679667280"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679667279"><span class="annot"><a href="#local-6989586621679667279"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679667278"><span class="annot"><a href="#local-6989586621679667278"><span class="hs-identifier hs-type">gradient'</span></a></span></span><span> </span><span id="local-6989586621679667277"><span class="annot"><a href="#local-6989586621679667277"><span class="hs-identifier hs-type">layout'</span></a></span></span><span> </span><span id="local-6989586621679667276"><span class="annot"><a href="#local-6989586621679667276"><span class="hs-identifier hs-type">device'</span></a></span></span><span> </span><span id="local-6989586621679667275"><span class="annot"><a href="#local-6989586621679667275"><span class="hs-identifier hs-type">dataType'</span></a></span></span><span> </span><span id="local-6989586621679667274"><span class="annot"><a href="#local-6989586621679667274"><span class="hs-identifier hs-type">shape'</span></a></span></span><span> </span><span id="local-6989586621679667273"><span class="annot"><a href="#local-6989586621679667273"><span class="hs-identifier hs-type">m</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-384"></span><span>  </span><span class="annot"><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier hs-type">MonadThrow</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667273"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-385"></span><span>  </span><span class="hs-comment">-- | input tensor</span><span>
</span><span id="line-386"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667283"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667282"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667281"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667280"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667279"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-387"></span><span>  </span><span class="hs-comment">-- | other tensor</span><span>
</span><span id="line-388"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667278"><span class="hs-identifier hs-type">gradient'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667277"><span class="hs-identifier hs-type">layout'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667276"><span class="hs-identifier hs-type">device'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667275"><span class="hs-identifier hs-type">dataType'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667274"><span class="hs-identifier hs-type">shape'</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-389"></span><span>  </span><span class="hs-comment">-- | output tensor</span><span>
</span><span id="line-390"></span><span>  </span><span class="annot"><a href="#local-6989586621679667273"><span class="hs-identifier hs-type">m</span></a></span><span>
</span><span id="line-391"></span><span>    </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-392"></span><span>        </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679667283"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667278"><span class="hs-identifier hs-type">gradient'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-393"></span><span>        </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679667282"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667277"><span class="hs-identifier hs-type">layout'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-394"></span><span>        </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679667281"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667276"><span class="hs-identifier hs-type">device'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-395"></span><span>        </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679667280"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667275"><span class="hs-identifier hs-type">dataType'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-396"></span><span>        </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679667279"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667274"><span class="hs-identifier hs-type">shape'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-397"></span><span>    </span><span class="hs-special">)</span><span>
</span><span id="line-398"></span><span id="local-6989586621679667272"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679667272"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span id="bitwiseXor"><span class="annot"><span class="annottext">bitwiseXor :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; m (Tensor
        (gradient &lt;|&gt; gradient')
        (layout &lt;+&gt; layout')
        (device &lt;+&gt; device')
        (dataType &lt;+&gt; dataType')
        (shape &lt;+&gt; shape'))
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#bitwiseXor"><span class="hs-operator hs-var hs-var">`bitwiseXor`</span></a></span></span><span> </span><span id="local-6989586621679667271"><span class="annot"><span class="annottext">Tensor gradient' layout' device' dataType' shape'
</span><a href="#local-6989586621679667271"><span class="hs-identifier hs-var">other</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO
  (Tensor
     (Or (Gradient RequiresGradient) gradient gradient')
     (Unify (Layout LayoutType) layout layout')
     (Unify (Device (DeviceType Nat)) device device')
     (Unify (DataType DType) dataType dataType')
     (Unify (Shape [Dim (Name Symbol) (Size Nat)]) shape shape'))
-&gt; m (Tensor
        (Or (Gradient RequiresGradient) gradient gradient')
        (Unify (Layout LayoutType) layout layout')
        (Unify (Device (DeviceType Nat)) device device')
        (Unify (DataType DType) dataType dataType')
        (Unify (Shape [Dim (Name Symbol) (Size Nat)]) shape shape'))
forall a (m :: * -&gt; *). MonadThrow m =&gt; IO a -&gt; m a
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">unsafeThrowableIO</span></a></span><span> </span><span class="annot"><span class="annottext">(IO
   (Tensor
      (Or (Gradient RequiresGradient) gradient gradient')
      (Unify (Layout LayoutType) layout layout')
      (Unify (Device (DeviceType Nat)) device device')
      (Unify (DataType DType) dataType dataType')
      (Unify (Shape [Dim (Name Symbol) (Size Nat)]) shape shape'))
 -&gt; m (Tensor
         (Or (Gradient RequiresGradient) gradient gradient')
         (Unify (Layout LayoutType) layout layout')
         (Unify (Device (DeviceType Nat)) device device')
         (Unify (DataType DType) dataType dataType')
         (Unify (Shape [Dim (Name Symbol) (Size Nat)]) shape shape')))
-&gt; IO
     (Tensor
        (Or (Gradient RequiresGradient) gradient gradient')
        (Unify (Layout LayoutType) layout layout')
        (Unify (Device (DeviceType Nat)) device device')
        (Unify (DataType DType) dataType dataType')
        (Unify (Shape [Dim (Name Symbol) (Size Nat)]) shape shape'))
-&gt; m (Tensor
        (Or (Gradient RequiresGradient) gradient gradient')
        (Unify (Layout LayoutType) layout layout')
        (Unify (Device (DeviceType Nat)) device device')
        (Unify (DataType DType) dataType dataType')
        (Unify (Shape [Dim (Name Symbol) (Size Nat)]) shape shape'))
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; IO
     (Tensor
        (Or (Gradient RequiresGradient) gradient gradient')
        (Unify (Layout LayoutType) layout layout')
        (Unify (Device (DeviceType Nat)) device device')
        (Unify (DataType DType) dataType dataType')
        (Unify (Shape [Dim (Name Symbol) (Size Nat)]) shape shape'))
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.bitwise_xor_tt</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679667272"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient' layout' device' dataType' shape'
</span><a href="#local-6989586621679667271"><span class="hs-identifier hs-var">other</span></a></span><span>
</span><span id="line-399"></span><span>
</span><span id="line-400"></span><span class="hs-comment">-- | Computes the bitwise XOR of the tensor 'input' and the scalar 'other'.</span><span>
</span><span id="line-401"></span><span class="hs-comment">-- The data type of the inputs must be 'Bool' or an integral data type.</span><span>
</span><span id="line-402"></span><span class="hs-comment">-- If the data type is 'Bool', then the function computes the logical XOR.</span><span>
</span><span id="line-403"></span><span class="hs-comment">--</span><span>
</span><span id="line-404"></span><span class="hs-comment">-- See 'bitwiseXor' for a version of this function where 'other'</span><span>
</span><span id="line-405"></span><span class="hs-comment">-- is a tensor.</span><span>
</span><span id="line-406"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#bitwiseXorScalar"><span class="hs-identifier hs-type">bitwiseXorScalar</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-407"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679667268"><span class="annot"><a href="#local-6989586621679667268"><span class="hs-identifier hs-type">other</span></a></span></span><span> </span><span id="local-6989586621679667267"><span class="annot"><a href="#local-6989586621679667267"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679667266"><span class="annot"><a href="#local-6989586621679667266"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679667265"><span class="annot"><a href="#local-6989586621679667265"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679667264"><span class="annot"><a href="#local-6989586621679667264"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679667263"><span class="annot"><a href="#local-6989586621679667263"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-408"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Scalar.html#Scalar"><span class="hs-identifier hs-type">Scalar</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667268"><span class="hs-identifier hs-type">other</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-409"></span><span>  </span><span class="hs-comment">-- | input tensor</span><span>
</span><span id="line-410"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667267"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667266"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667265"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667264"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667263"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-411"></span><span>  </span><span class="hs-comment">-- | other scalar</span><span>
</span><span id="line-412"></span><span>  </span><span class="annot"><a href="#local-6989586621679667268"><span class="hs-identifier hs-type">other</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-413"></span><span>  </span><span class="hs-comment">-- | output tensor</span><span>
</span><span id="line-414"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667267"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667266"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667265"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667264"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667263"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-415"></span><span id="local-6989586621679667262"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679667262"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span id="bitwiseXorScalar"><span class="annot"><span class="annottext">bitwiseXorScalar :: Tensor gradient layout device dataType shape
-&gt; other -&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#bitwiseXorScalar"><span class="hs-operator hs-var hs-var">`bitwiseXorScalar`</span></a></span></span><span> </span><span id="local-6989586621679667261"><span class="annot"><span class="annottext">other
</span><a href="#local-6989586621679667261"><span class="hs-identifier hs-var">other</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ForeignPtr Scalar -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; other
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr Scalar -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.bitwise_xor_ts</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679667262"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">other
</span><a href="#local-6989586621679667261"><span class="hs-identifier hs-var">other</span></a></span><span>
</span><span id="line-416"></span><span>
</span><span id="line-417"></span><span class="hs-comment">-- | Returns a new tensor with the ceil of the elements of 'input',</span><span>
</span><span id="line-418"></span><span class="hs-comment">-- that is, the smallest integer greater than or equal to each element:</span><span>
</span><span id="line-419"></span><span class="hs-comment">-- \[</span><span>
</span><span id="line-420"></span><span class="hs-comment">-- \mathrm{output}_i = \lceil\mathrm{input}_i\rceil = \lfloor\mathrm{input}_i\rfloor + 1,</span><span>
</span><span id="line-421"></span><span class="hs-comment">-- \]</span><span>
</span><span id="line-422"></span><span class="hs-comment">-- where \(\lfloor\mathrm{input}_i\rfloor\) is the floor of the \(i\)-th element of 'input'</span><span>
</span><span id="line-423"></span><span class="hs-comment">-- which can be computed with 'floor'.</span><span>
</span><span id="line-424"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#ceil"><span class="hs-identifier hs-type">ceil</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-425"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679667258"><span class="annot"><a href="#local-6989586621679667258"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679667257"><span class="annot"><a href="#local-6989586621679667257"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679667256"><span class="annot"><a href="#local-6989586621679667256"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679667255"><span class="annot"><a href="#local-6989586621679667255"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679667254"><span class="annot"><a href="#local-6989586621679667254"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-426"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-427"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667258"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667257"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667256"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667255"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667254"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-428"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-429"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667258"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667257"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667256"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667255"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667254"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-430"></span><span id="ceil"><span class="annot"><span class="annottext">ceil :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#ceil"><span class="hs-identifier hs-var hs-var">ceil</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; (Tensor gradient layout device dataType shape
    -&gt; IO (Tensor gradient layout device dataType shape))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.ceil_t</span></a></span><span>
</span><span id="line-431"></span><span>
</span><span id="line-432"></span><span class="hs-comment">-- | Clamp all elements in input into the range [ min, max ]</span><span>
</span><span id="line-433"></span><span class="hs-comment">-- and return the result as a new tensor.</span><span>
</span><span id="line-434"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#clamp"><span class="hs-identifier hs-type">clamp</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-435"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679667251"><span class="annot"><a href="#local-6989586621679667251"><span class="hs-identifier hs-type">min</span></a></span></span><span> </span><span id="local-6989586621679667250"><span class="annot"><a href="#local-6989586621679667250"><span class="hs-identifier hs-type">max</span></a></span></span><span> </span><span id="local-6989586621679667249"><span class="annot"><a href="#local-6989586621679667249"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679667248"><span class="annot"><a href="#local-6989586621679667248"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679667247"><span class="annot"><a href="#local-6989586621679667247"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679667246"><span class="annot"><a href="#local-6989586621679667246"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679667245"><span class="annot"><a href="#local-6989586621679667245"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-436"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Scalar.html#Scalar"><span class="hs-identifier hs-type">Scalar</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667251"><span class="hs-identifier hs-type">min</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Scalar.html#Scalar"><span class="hs-identifier hs-type">Scalar</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667250"><span class="hs-identifier hs-type">max</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-437"></span><span>  </span><span class="hs-comment">-- | min</span><span>
</span><span id="line-438"></span><span>  </span><span class="annot"><a href="#local-6989586621679667251"><span class="hs-identifier hs-type">min</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-439"></span><span>  </span><span class="hs-comment">-- | max</span><span>
</span><span id="line-440"></span><span>  </span><span class="annot"><a href="#local-6989586621679667250"><span class="hs-identifier hs-type">max</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-441"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-442"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667249"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667248"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667247"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667246"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667245"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-443"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-444"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667249"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667248"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667247"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667246"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667245"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-445"></span><span id="clamp"><span class="annot"><span class="annottext">clamp :: min
-&gt; max
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#clamp"><span class="hs-identifier hs-var hs-var">clamp</span></a></span></span><span> </span><span id="local-6989586621679667244"><span class="annot"><span class="annottext">min
</span><a href="#local-6989586621679667244"><span class="hs-identifier hs-var">min'</span></a></span></span><span> </span><span id="local-6989586621679667243"><span class="annot"><span class="annottext">max
</span><a href="#local-6989586621679667243"><span class="hs-identifier hs-var">max'</span></a></span></span><span> </span><span id="local-6989586621679667242"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679667242"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr Scalar
 -&gt; ForeignPtr Scalar
 -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; min
-&gt; max
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca x1 cx1 x2 cx2 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; x2 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast3</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; ForeignPtr Scalar -&gt; ForeignPtr Scalar -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.clamp__tss</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679667242"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">min
</span><a href="#local-6989586621679667244"><span class="hs-identifier hs-var">min'</span></a></span><span> </span><span class="annot"><span class="annottext">max
</span><a href="#local-6989586621679667243"><span class="hs-identifier hs-var">max'</span></a></span><span>
</span><span id="line-446"></span><span>
</span><span id="line-447"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#cos"><span class="hs-identifier hs-type">cos</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-448"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679667239"><span class="annot"><a href="#local-6989586621679667239"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679667238"><span class="annot"><a href="#local-6989586621679667238"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679667237"><span class="annot"><a href="#local-6989586621679667237"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679667236"><span class="annot"><a href="#local-6989586621679667236"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679667235"><span class="annot"><a href="#local-6989586621679667235"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-449"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-450"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667239"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667238"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667237"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667236"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667235"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-451"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-452"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667239"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667238"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667237"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667236"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667235"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-453"></span><span id="cos"><span class="annot"><span class="annottext">cos :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#cos"><span class="hs-identifier hs-var hs-var">cos</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; (Tensor gradient layout device dataType shape
    -&gt; IO (Tensor gradient layout device dataType shape))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cos_t</span></a></span><span>
</span><span id="line-454"></span><span>
</span><span id="line-455"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#cosh"><span class="hs-identifier hs-type">cosh</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-456"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679667232"><span class="annot"><a href="#local-6989586621679667232"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679667231"><span class="annot"><a href="#local-6989586621679667231"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679667230"><span class="annot"><a href="#local-6989586621679667230"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679667229"><span class="annot"><a href="#local-6989586621679667229"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679667228"><span class="annot"><a href="#local-6989586621679667228"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-457"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-458"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667232"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667231"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667230"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667229"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667228"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-459"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-460"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667232"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667231"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667230"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667229"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667228"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-461"></span><span id="cosh"><span class="annot"><span class="annottext">cosh :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#cosh"><span class="hs-identifier hs-var hs-var">cosh</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; (Tensor gradient layout device dataType shape
    -&gt; IO (Tensor gradient layout device dataType shape))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cosh_t</span></a></span><span>
</span><span id="line-462"></span><span>
</span><span id="line-463"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#deg2rad"><span class="hs-identifier hs-type">deg2rad</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-464"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679667225"><span class="annot"><a href="#local-6989586621679667225"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679667224"><span class="annot"><a href="#local-6989586621679667224"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679667223"><span class="annot"><a href="#local-6989586621679667223"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679667222"><span class="annot"><a href="#local-6989586621679667222"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679667221"><span class="annot"><a href="#local-6989586621679667221"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-465"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-466"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667225"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667224"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667223"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667222"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667221"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-467"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-468"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667225"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667224"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667223"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667222"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667221"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-469"></span><span id="deg2rad"><span class="annot"><span class="annottext">deg2rad :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#deg2rad"><span class="hs-identifier hs-var hs-var">deg2rad</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; (Tensor gradient layout device dataType shape
    -&gt; IO (Tensor gradient layout device dataType shape))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.deg2rad_t</span></a></span><span>
</span><span id="line-470"></span><span>
</span><span id="line-471"></span><span class="hs-comment">-- | Element-wise division of the first input tensor, the 'dividend',</span><span>
</span><span id="line-472"></span><span class="hs-comment">-- by the second input tensor, the 'divisor'.</span><span>
</span><span id="line-473"></span><span class="hs-comment">-- \[</span><span>
</span><span id="line-474"></span><span class="hs-comment">-- \mathrm{output}_i = \frac{dividend_i}{divisor_i}</span><span>
</span><span id="line-475"></span><span class="hs-comment">-- \]</span><span>
</span><span id="line-476"></span><span class="hs-comment">-- The result is returned as a new tensor.</span><span>
</span><span id="line-477"></span><span class="hs-comment">--</span><span>
</span><span id="line-478"></span><span class="hs-comment">-- See 'divScalar' for a version of this function where</span><span>
</span><span id="line-479"></span><span class="hs-comment">-- the 'divisor' is a scalar.</span><span>
</span><span id="line-480"></span><span class="hs-comment">--</span><span>
</span><span id="line-481"></span><span class="hs-comment">-- Note further that &quot;true divisions&quot; can be computed with</span><span>
</span><span id="line-482"></span><span class="hs-comment">-- 'trueDivide' or 'trueDivideScalar' which can come in handy</span><span>
</span><span id="line-483"></span><span class="hs-comment">-- when both the 'dividend' and the 'divisor' have 'Bool' or integer data types.</span><span>
</span><span id="line-484"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#div"><span class="hs-identifier hs-type">div</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-485"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679667218"><span class="annot"><a href="#local-6989586621679667218"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679667217"><span class="annot"><a href="#local-6989586621679667217"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679667216"><span class="annot"><a href="#local-6989586621679667216"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679667215"><span class="annot"><a href="#local-6989586621679667215"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679667214"><span class="annot"><a href="#local-6989586621679667214"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679667213"><span class="annot"><a href="#local-6989586621679667213"><span class="hs-identifier hs-type">gradient'</span></a></span></span><span> </span><span id="local-6989586621679667212"><span class="annot"><a href="#local-6989586621679667212"><span class="hs-identifier hs-type">layout'</span></a></span></span><span> </span><span id="local-6989586621679667211"><span class="annot"><a href="#local-6989586621679667211"><span class="hs-identifier hs-type">device'</span></a></span></span><span> </span><span id="local-6989586621679667210"><span class="annot"><a href="#local-6989586621679667210"><span class="hs-identifier hs-type">dataType'</span></a></span></span><span> </span><span id="local-6989586621679667209"><span class="annot"><a href="#local-6989586621679667209"><span class="hs-identifier hs-type">shape'</span></a></span></span><span> </span><span id="local-6989586621679667208"><span class="annot"><a href="#local-6989586621679667208"><span class="hs-identifier hs-type">shape''</span></a></span></span><span> </span><span id="local-6989586621679667207"><span class="annot"><a href="#local-6989586621679667207"><span class="hs-identifier hs-type">m</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-486"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier hs-type">MonadThrow</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667207"><span class="hs-identifier hs-type">m</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679667208"><span class="hs-identifier hs-type">shape''</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#BroadcastShapesF"><span class="hs-identifier hs-type">BroadcastShapesF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667214"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667209"><span class="hs-identifier hs-type">shape'</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Catch"><span class="hs-identifier hs-type">Catch</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667208"><span class="hs-identifier hs-type">shape''</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-487"></span><span>  </span><span class="hs-comment">-- | tensor dividend</span><span>
</span><span id="line-488"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667218"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667217"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667216"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667215"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667214"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-489"></span><span>  </span><span class="hs-comment">-- | tensor divisor</span><span>
</span><span id="line-490"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667213"><span class="hs-identifier hs-type">gradient'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667212"><span class="hs-identifier hs-type">layout'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667211"><span class="hs-identifier hs-type">device'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667210"><span class="hs-identifier hs-type">dataType'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667209"><span class="hs-identifier hs-type">shape'</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-491"></span><span>  </span><span class="hs-comment">-- | tensor output</span><span>
</span><span id="line-492"></span><span>  </span><span class="annot"><a href="#local-6989586621679667207"><span class="hs-identifier hs-type">m</span></a></span><span>
</span><span id="line-493"></span><span>    </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-494"></span><span>        </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679667218"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667213"><span class="hs-identifier hs-type">gradient'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-495"></span><span>        </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679667217"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667212"><span class="hs-identifier hs-type">layout'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-496"></span><span>        </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679667216"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667211"><span class="hs-identifier hs-type">device'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-497"></span><span>        </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679667215"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667210"><span class="hs-identifier hs-type">dataType'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-498"></span><span>        </span><span class="annot"><a href="#local-6989586621679667208"><span class="hs-identifier hs-type">shape''</span></a></span><span>
</span><span id="line-499"></span><span>    </span><span class="hs-special">)</span><span>
</span><span id="line-500"></span><span id="local-6989586621679667206"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679667206"><span class="hs-identifier hs-var">dividend</span></a></span></span><span> </span><span id="div"><span class="annot"><span class="annottext">div :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; m (Tensor
        (gradient &lt;|&gt; gradient')
        (layout &lt;+&gt; layout')
        (device &lt;+&gt; device')
        (dataType &lt;+&gt; dataType')
        shape'')
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#div"><span class="hs-operator hs-var hs-var">`div`</span></a></span></span><span> </span><span id="local-6989586621679667205"><span class="annot"><span class="annottext">Tensor gradient' layout' device' dataType' shape'
</span><a href="#local-6989586621679667205"><span class="hs-identifier hs-var">divisor</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO
  (Tensor
     (Or (Gradient RequiresGradient) gradient gradient')
     (Unify (Layout LayoutType) layout layout')
     (Unify (Device (DeviceType Nat)) device device')
     (Unify (DataType DType) dataType dataType')
     shape'')
-&gt; m (Tensor
        (Or (Gradient RequiresGradient) gradient gradient')
        (Unify (Layout LayoutType) layout layout')
        (Unify (Device (DeviceType Nat)) device device')
        (Unify (DataType DType) dataType dataType')
        shape'')
forall a (m :: * -&gt; *). MonadThrow m =&gt; IO a -&gt; m a
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">unsafeThrowableIO</span></a></span><span> </span><span class="annot"><span class="annottext">(IO
   (Tensor
      (Or (Gradient RequiresGradient) gradient gradient')
      (Unify (Layout LayoutType) layout layout')
      (Unify (Device (DeviceType Nat)) device device')
      (Unify (DataType DType) dataType dataType')
      shape'')
 -&gt; m (Tensor
         (Or (Gradient RequiresGradient) gradient gradient')
         (Unify (Layout LayoutType) layout layout')
         (Unify (Device (DeviceType Nat)) device device')
         (Unify (DataType DType) dataType dataType')
         shape''))
-&gt; IO
     (Tensor
        (Or (Gradient RequiresGradient) gradient gradient')
        (Unify (Layout LayoutType) layout layout')
        (Unify (Device (DeviceType Nat)) device device')
        (Unify (DataType DType) dataType dataType')
        shape'')
-&gt; m (Tensor
        (Or (Gradient RequiresGradient) gradient gradient')
        (Unify (Layout LayoutType) layout layout')
        (Unify (Device (DeviceType Nat)) device device')
        (Unify (DataType DType) dataType dataType')
        shape'')
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; IO
     (Tensor
        (Or (Gradient RequiresGradient) gradient gradient')
        (Unify (Layout LayoutType) layout layout')
        (Unify (Device (DeviceType Nat)) device device')
        (Unify (DataType DType) dataType dataType')
        shape'')
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.div_tt</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679667206"><span class="hs-identifier hs-var">dividend</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient' layout' device' dataType' shape'
</span><a href="#local-6989586621679667205"><span class="hs-identifier hs-var">divisor</span></a></span><span>
</span><span id="line-501"></span><span>
</span><span id="line-502"></span><span class="hs-comment">-- | Element-wise division of the first input, the 'dividend' tensor,</span><span>
</span><span id="line-503"></span><span class="hs-comment">-- by the second input, the 'divisor' scalar.</span><span>
</span><span id="line-504"></span><span class="hs-comment">-- \[</span><span>
</span><span id="line-505"></span><span class="hs-comment">-- \mathrm{output}_i = \frac{dividend_i}{divisor}</span><span>
</span><span id="line-506"></span><span class="hs-comment">-- \]</span><span>
</span><span id="line-507"></span><span class="hs-comment">-- The result is returned as a new tensor.</span><span>
</span><span id="line-508"></span><span class="hs-comment">--</span><span>
</span><span id="line-509"></span><span class="hs-comment">-- See 'div' for a version of this function where</span><span>
</span><span id="line-510"></span><span class="hs-comment">-- the divisor is a tensor.</span><span>
</span><span id="line-511"></span><span class="hs-comment">--</span><span>
</span><span id="line-512"></span><span class="hs-comment">-- Note further that &quot;true divisions&quot; can be computed with</span><span>
</span><span id="line-513"></span><span class="hs-comment">-- 'trueDivide' or 'trueDivideScalar' which can come in handy</span><span>
</span><span id="line-514"></span><span class="hs-comment">-- when both the dividend and the divisor have 'Bool' or integer data types.</span><span>
</span><span id="line-515"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#divScalar"><span class="hs-identifier hs-type">divScalar</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-516"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679667202"><span class="annot"><a href="#local-6989586621679667202"><span class="hs-identifier hs-type">divisor</span></a></span></span><span> </span><span id="local-6989586621679667201"><span class="annot"><a href="#local-6989586621679667201"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679667200"><span class="annot"><a href="#local-6989586621679667200"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679667199"><span class="annot"><a href="#local-6989586621679667199"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679667198"><span class="annot"><a href="#local-6989586621679667198"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679667197"><span class="annot"><a href="#local-6989586621679667197"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-517"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Scalar.html#Scalar"><span class="hs-identifier hs-type">Scalar</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667202"><span class="hs-identifier hs-type">divisor</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-518"></span><span>  </span><span class="hs-comment">-- | tensor dividend</span><span>
</span><span id="line-519"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667201"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667200"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667199"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667198"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667197"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-520"></span><span>  </span><span class="hs-comment">-- | scalar divisor</span><span>
</span><span id="line-521"></span><span>  </span><span class="annot"><a href="#local-6989586621679667202"><span class="hs-identifier hs-type">divisor</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-522"></span><span>  </span><span class="hs-comment">-- | tensor output</span><span>
</span><span id="line-523"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667201"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667200"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667199"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667198"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667197"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-524"></span><span id="local-6989586621679667196"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679667196"><span class="hs-identifier hs-var">dividend</span></a></span></span><span> </span><span id="divScalar"><span class="annot"><span class="annottext">divScalar :: Tensor gradient layout device dataType shape
-&gt; divisor -&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#divScalar"><span class="hs-operator hs-var hs-var">`divScalar`</span></a></span></span><span> </span><span id="local-6989586621679667195"><span class="annot"><span class="annottext">divisor
</span><a href="#local-6989586621679667195"><span class="hs-identifier hs-var">divisor</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ForeignPtr Scalar -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; divisor
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr Scalar -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.div_ts</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679667196"><span class="hs-identifier hs-var">dividend</span></a></span><span> </span><span class="annot"><span class="annottext">divisor
</span><a href="#local-6989586621679667195"><span class="hs-identifier hs-var">divisor</span></a></span><span>
</span><span id="line-525"></span><span>
</span><span id="line-526"></span><span class="hs-comment">-- | Computes the logarithmic derivative of the gamma function on 'input':</span><span>
</span><span id="line-527"></span><span class="hs-comment">-- \[</span><span>
</span><span id="line-528"></span><span class="hs-comment">-- \mathrm{output}_i = \psi\left(\mathrm{input}_i\right) = \frac{d}{d\mathrm{input}_i} \ln\left(\gamma\left(\mathrm{input}_i\right)\right).</span><span>
</span><span id="line-529"></span><span class="hs-comment">-- \]</span><span>
</span><span id="line-530"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#digamma"><span class="hs-identifier hs-type">digamma</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-531"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679667192"><span class="annot"><a href="#local-6989586621679667192"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679667191"><span class="annot"><a href="#local-6989586621679667191"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679667190"><span class="annot"><a href="#local-6989586621679667190"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679667189"><span class="annot"><a href="#local-6989586621679667189"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679667188"><span class="annot"><a href="#local-6989586621679667188"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-532"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-533"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667192"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667191"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667190"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667189"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667188"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-534"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-535"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667192"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667191"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667190"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667189"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667188"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-536"></span><span id="digamma"><span class="annot"><span class="annottext">digamma :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#digamma"><span class="hs-identifier hs-var hs-var">digamma</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; (Tensor gradient layout device dataType shape
    -&gt; IO (Tensor gradient layout device dataType shape))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.digamma_t</span></a></span><span>
</span><span id="line-537"></span><span>
</span><span id="line-538"></span><span class="hs-comment">-- | Computes and returns the error function of each element of 'input':</span><span>
</span><span id="line-539"></span><span class="hs-comment">-- \[</span><span>
</span><span id="line-540"></span><span class="hs-comment">-- \mathrm{output}_i = \mathop{erf}\left(\mathrm{input}_i\right) = \frac{2}{\sqrt{\pi}} \int_0^{\mathrm{output}_i} \exp\left(- t^2\right) dt.</span><span>
</span><span id="line-541"></span><span class="hs-comment">-- \]</span><span>
</span><span id="line-542"></span><span class="hs-comment">--</span><span>
</span><span id="line-543"></span><span class="hs-comment">-- See also 'erfc' that computes the complementary error function</span><span>
</span><span id="line-544"></span><span class="hs-comment">-- to high numerical accuracy</span><span>
</span><span id="line-545"></span><span class="hs-comment">-- and 'erfinv' that computes the inverse of the error function.</span><span>
</span><span id="line-546"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#erf"><span class="hs-identifier hs-type">erf</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-547"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679667185"><span class="annot"><a href="#local-6989586621679667185"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679667184"><span class="annot"><a href="#local-6989586621679667184"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679667183"><span class="annot"><a href="#local-6989586621679667183"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679667182"><span class="annot"><a href="#local-6989586621679667182"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679667181"><span class="annot"><a href="#local-6989586621679667181"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-548"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-549"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667185"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667184"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667183"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667182"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667181"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-550"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-551"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667185"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667184"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667183"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667182"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667181"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-552"></span><span id="erf"><span class="annot"><span class="annottext">erf :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#erf"><span class="hs-identifier hs-var hs-var">erf</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; (Tensor gradient layout device dataType shape
    -&gt; IO (Tensor gradient layout device dataType shape))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.erf_t</span></a></span><span>
</span><span id="line-553"></span><span>
</span><span id="line-554"></span><span class="hs-comment">-- | Computes the complementary error function of each element of 'input':</span><span>
</span><span id="line-555"></span><span class="hs-comment">-- \[</span><span>
</span><span id="line-556"></span><span class="hs-comment">-- \mathrm{output}_i = 1 - \mathop{erf}\left(\mathrm{input}_i\right) = 1 - \frac{2}{\sqrt{\pi}} \int_0^{\mathrm{output}_i} \exp\left(- t^2\right) dt.</span><span>
</span><span id="line-557"></span><span class="hs-comment">-- \]</span><span>
</span><span id="line-558"></span><span class="hs-comment">--</span><span>
</span><span id="line-559"></span><span class="hs-comment">-- See also 'erf' that computes the error function</span><span>
</span><span id="line-560"></span><span class="hs-comment">-- and 'erfinv' that computes the inverse of the error function.</span><span>
</span><span id="line-561"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#erfc"><span class="hs-identifier hs-type">erfc</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-562"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679667178"><span class="annot"><a href="#local-6989586621679667178"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679667177"><span class="annot"><a href="#local-6989586621679667177"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679667176"><span class="annot"><a href="#local-6989586621679667176"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679667175"><span class="annot"><a href="#local-6989586621679667175"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679667174"><span class="annot"><a href="#local-6989586621679667174"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-563"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-564"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667178"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667177"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667176"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667175"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667174"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-565"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-566"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667178"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667177"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667176"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667175"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667174"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-567"></span><span id="erfc"><span class="annot"><span class="annottext">erfc :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#erfc"><span class="hs-identifier hs-var hs-var">erfc</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; (Tensor gradient layout device dataType shape
    -&gt; IO (Tensor gradient layout device dataType shape))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.erfc_t</span></a></span><span>
</span><span id="line-568"></span><span>
</span><span id="line-569"></span><span class="hs-comment">-- | Computes the inverse error function of each element of 'input':</span><span>
</span><span id="line-570"></span><span class="hs-comment">-- \[</span><span>
</span><span id="line-571"></span><span class="hs-comment">-- \mathrm{output}_i = \mathop{erfinv}\left(\mathrm{input}_i\right)</span><span>
</span><span id="line-572"></span><span class="hs-comment">-- \]</span><span>
</span><span id="line-573"></span><span class="hs-comment">-- where \(\mathop{erfinv}\left(\mathop{erf}\left(x\right)\right) = x\)</span><span>
</span><span id="line-574"></span><span class="hs-comment">-- for \(x \in (-1, 1)\). 'erfinv' is not defined outside this interval.</span><span>
</span><span id="line-575"></span><span class="hs-comment">--</span><span>
</span><span id="line-576"></span><span class="hs-comment">-- See also 'erf' that computes the error function</span><span>
</span><span id="line-577"></span><span class="hs-comment">-- and 'erfc' that computes the complementary error function.</span><span>
</span><span id="line-578"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#erfinv"><span class="hs-identifier hs-type">erfinv</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-579"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679667171"><span class="annot"><a href="#local-6989586621679667171"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679667170"><span class="annot"><a href="#local-6989586621679667170"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679667169"><span class="annot"><a href="#local-6989586621679667169"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679667168"><span class="annot"><a href="#local-6989586621679667168"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679667167"><span class="annot"><a href="#local-6989586621679667167"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-580"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-581"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667171"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667170"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667169"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667168"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667167"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-582"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-583"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667171"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667170"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667169"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667168"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667167"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-584"></span><span id="erfinv"><span class="annot"><span class="annottext">erfinv :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#erfinv"><span class="hs-identifier hs-var hs-var">erfinv</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; (Tensor gradient layout device dataType shape
    -&gt; IO (Tensor gradient layout device dataType shape))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.erfinv_t</span></a></span><span>
</span><span id="line-585"></span><span>
</span><span id="line-586"></span><span class="hs-comment">-- | Returns a new tensor with the exponential of the elements of the input tensor 'input':</span><span>
</span><span id="line-587"></span><span class="hs-comment">-- \[</span><span>
</span><span id="line-588"></span><span class="hs-comment">-- \mathrm{output}_i = \exp\left(\mathrm{input}_i\right).</span><span>
</span><span id="line-589"></span><span class="hs-comment">-- \]</span><span>
</span><span id="line-590"></span><span class="hs-comment">--</span><span>
</span><span id="line-591"></span><span class="hs-comment">-- See also 'expm1' for a high-accuracy calculation of</span><span>
</span><span id="line-592"></span><span class="hs-comment">-- the exponential of the elements of 'input' minus 1.</span><span>
</span><span id="line-593"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#exp"><span class="hs-identifier hs-type">exp</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-594"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679667164"><span class="annot"><a href="#local-6989586621679667164"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679667163"><span class="annot"><a href="#local-6989586621679667163"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679667162"><span class="annot"><a href="#local-6989586621679667162"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679667161"><span class="annot"><a href="#local-6989586621679667161"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679667160"><span class="annot"><a href="#local-6989586621679667160"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-595"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-596"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667164"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667163"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667162"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667161"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667160"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-597"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-598"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667164"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667163"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667162"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667161"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667160"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-599"></span><span id="exp"><span class="annot"><span class="annottext">exp :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#exp"><span class="hs-identifier hs-var hs-var">exp</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; (Tensor gradient layout device dataType shape
    -&gt; IO (Tensor gradient layout device dataType shape))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.exp_t</span></a></span><span>
</span><span id="line-600"></span><span>
</span><span id="line-601"></span><span class="hs-comment">-- | Returns a new tensor with the exponential of the elements minus 1 of 'input':</span><span>
</span><span id="line-602"></span><span class="hs-comment">-- \[</span><span>
</span><span id="line-603"></span><span class="hs-comment">-- \mathrm{output}_i = \exp\left(\mathrm{input}_i\right) - 1.</span><span>
</span><span id="line-604"></span><span class="hs-comment">-- \]</span><span>
</span><span id="line-605"></span><span class="hs-comment">--</span><span>
</span><span id="line-606"></span><span class="hs-comment">-- See also 'exp' for the exponential function.</span><span>
</span><span id="line-607"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#expm1"><span class="hs-identifier hs-type">expm1</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-608"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679667157"><span class="annot"><a href="#local-6989586621679667157"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679667156"><span class="annot"><a href="#local-6989586621679667156"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679667155"><span class="annot"><a href="#local-6989586621679667155"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679667154"><span class="annot"><a href="#local-6989586621679667154"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679667153"><span class="annot"><a href="#local-6989586621679667153"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-609"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-610"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667157"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667156"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667155"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667154"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667153"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-611"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-612"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667157"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667156"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667155"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667154"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667153"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-613"></span><span id="expm1"><span class="annot"><span class="annottext">expm1 :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#expm1"><span class="hs-identifier hs-var hs-var">expm1</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; (Tensor gradient layout device dataType shape
    -&gt; IO (Tensor gradient layout device dataType shape))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.expm1_t</span></a></span><span>
</span><span id="line-614"></span><span>
</span><span id="line-615"></span><span class="hs-comment">-- | Returns a new tensor with the floor of the elements of 'input',</span><span>
</span><span id="line-616"></span><span class="hs-comment">-- that is, the largest integer less than or equal to each element.:</span><span>
</span><span id="line-617"></span><span class="hs-comment">-- \[</span><span>
</span><span id="line-618"></span><span class="hs-comment">-- \mathrm{output}_i = \lfloor\mathrm{input}_i\rfloor = \lceil\mathrm{input}_i\rceil - 1,</span><span>
</span><span id="line-619"></span><span class="hs-comment">-- \]</span><span>
</span><span id="line-620"></span><span class="hs-comment">-- where \(\lceil\mathrm{input}_i\rceil\) is the ceil of the \(i\)-th element of 'input'</span><span>
</span><span id="line-621"></span><span class="hs-comment">-- which can be computed with 'ceil'.</span><span>
</span><span id="line-622"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#floor"><span class="hs-identifier hs-type">floor</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-623"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679667150"><span class="annot"><a href="#local-6989586621679667150"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679667149"><span class="annot"><a href="#local-6989586621679667149"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679667148"><span class="annot"><a href="#local-6989586621679667148"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679667147"><span class="annot"><a href="#local-6989586621679667147"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679667146"><span class="annot"><a href="#local-6989586621679667146"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-624"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-625"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667150"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667149"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667148"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667147"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667146"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-626"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-627"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667150"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667149"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667148"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667147"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667146"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-628"></span><span id="floor"><span class="annot"><span class="annottext">floor :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#floor"><span class="hs-identifier hs-var hs-var">floor</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; (Tensor gradient layout device dataType shape
    -&gt; IO (Tensor gradient layout device dataType shape))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.floor_t</span></a></span><span>
</span><span id="line-629"></span><span>
</span><span id="line-630"></span><span class="hs-comment">-- | Return the element-wise division of the tensor 'dividend' by the tensor 'divisor'</span><span>
</span><span id="line-631"></span><span class="hs-comment">-- rounded down to the nearest integer:</span><span>
</span><span id="line-632"></span><span class="hs-comment">-- \[</span><span>
</span><span id="line-633"></span><span class="hs-comment">-- \mathrm{output}_i = \left\lfloor\frac{\mathrm{dividend}_i}{\mathrm{divisor}_i}\right\rfloor.</span><span>
</span><span id="line-634"></span><span class="hs-comment">-- \]</span><span>
</span><span id="line-635"></span><span class="hs-comment">--</span><span>
</span><span id="line-636"></span><span class="hs-comment">-- See 'floorDivideScalar' for a version of this function where</span><span>
</span><span id="line-637"></span><span class="hs-comment">-- 'divisor' is a scalar.</span><span>
</span><span id="line-638"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#floorDivide"><span class="hs-identifier hs-type">floorDivide</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-639"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679667143"><span class="annot"><a href="#local-6989586621679667143"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679667142"><span class="annot"><a href="#local-6989586621679667142"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679667141"><span class="annot"><a href="#local-6989586621679667141"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679667140"><span class="annot"><a href="#local-6989586621679667140"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679667139"><span class="annot"><a href="#local-6989586621679667139"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679667138"><span class="annot"><a href="#local-6989586621679667138"><span class="hs-identifier hs-type">gradient'</span></a></span></span><span> </span><span id="local-6989586621679667137"><span class="annot"><a href="#local-6989586621679667137"><span class="hs-identifier hs-type">layout'</span></a></span></span><span> </span><span id="local-6989586621679667136"><span class="annot"><a href="#local-6989586621679667136"><span class="hs-identifier hs-type">device'</span></a></span></span><span> </span><span id="local-6989586621679667135"><span class="annot"><a href="#local-6989586621679667135"><span class="hs-identifier hs-type">dataType'</span></a></span></span><span> </span><span id="local-6989586621679667134"><span class="annot"><a href="#local-6989586621679667134"><span class="hs-identifier hs-type">shape'</span></a></span></span><span> </span><span id="local-6989586621679667133"><span class="annot"><a href="#local-6989586621679667133"><span class="hs-identifier hs-type">shape''</span></a></span></span><span> </span><span id="local-6989586621679667132"><span class="annot"><a href="#local-6989586621679667132"><span class="hs-identifier hs-type">m</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-640"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier hs-type">MonadThrow</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667132"><span class="hs-identifier hs-type">m</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679667133"><span class="hs-identifier hs-type">shape''</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#BroadcastShapesF"><span class="hs-identifier hs-type">BroadcastShapesF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667139"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667134"><span class="hs-identifier hs-type">shape'</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Catch"><span class="hs-identifier hs-type">Catch</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667133"><span class="hs-identifier hs-type">shape''</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-641"></span><span>  </span><span class="hs-comment">-- | dividend tensor</span><span>
</span><span id="line-642"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667143"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667142"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667141"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667140"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667139"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-643"></span><span>  </span><span class="hs-comment">-- | divisor tensor</span><span>
</span><span id="line-644"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667138"><span class="hs-identifier hs-type">gradient'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667137"><span class="hs-identifier hs-type">layout'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667136"><span class="hs-identifier hs-type">device'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667135"><span class="hs-identifier hs-type">dataType'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667134"><span class="hs-identifier hs-type">shape'</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-645"></span><span>  </span><span class="hs-comment">-- | output tensor</span><span>
</span><span id="line-646"></span><span>  </span><span class="annot"><a href="#local-6989586621679667132"><span class="hs-identifier hs-type">m</span></a></span><span>
</span><span id="line-647"></span><span>    </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-648"></span><span>        </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679667143"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667138"><span class="hs-identifier hs-type">gradient'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-649"></span><span>        </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679667142"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667137"><span class="hs-identifier hs-type">layout'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-650"></span><span>        </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679667141"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667136"><span class="hs-identifier hs-type">device'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-651"></span><span>        </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679667140"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667135"><span class="hs-identifier hs-type">dataType'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-652"></span><span>        </span><span class="annot"><a href="#local-6989586621679667133"><span class="hs-identifier hs-type">shape''</span></a></span><span>
</span><span id="line-653"></span><span>    </span><span class="hs-special">)</span><span>
</span><span id="line-654"></span><span id="local-6989586621679667131"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679667131"><span class="hs-identifier hs-var">dividend</span></a></span></span><span> </span><span id="floorDivide"><span class="annot"><span class="annottext">floorDivide :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; m (Tensor
        (gradient &lt;|&gt; gradient')
        (layout &lt;+&gt; layout')
        (device &lt;+&gt; device')
        (dataType &lt;+&gt; dataType')
        shape'')
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#floorDivide"><span class="hs-operator hs-var hs-var">`floorDivide`</span></a></span></span><span> </span><span id="local-6989586621679667130"><span class="annot"><span class="annottext">Tensor gradient' layout' device' dataType' shape'
</span><a href="#local-6989586621679667130"><span class="hs-identifier hs-var">divisor</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO
  (Tensor
     (Or (Gradient RequiresGradient) gradient gradient')
     (Unify (Layout LayoutType) layout layout')
     (Unify (Device (DeviceType Nat)) device device')
     (Unify (DataType DType) dataType dataType')
     shape'')
-&gt; m (Tensor
        (Or (Gradient RequiresGradient) gradient gradient')
        (Unify (Layout LayoutType) layout layout')
        (Unify (Device (DeviceType Nat)) device device')
        (Unify (DataType DType) dataType dataType')
        shape'')
forall a (m :: * -&gt; *). MonadThrow m =&gt; IO a -&gt; m a
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">unsafeThrowableIO</span></a></span><span> </span><span class="annot"><span class="annottext">(IO
   (Tensor
      (Or (Gradient RequiresGradient) gradient gradient')
      (Unify (Layout LayoutType) layout layout')
      (Unify (Device (DeviceType Nat)) device device')
      (Unify (DataType DType) dataType dataType')
      shape'')
 -&gt; m (Tensor
         (Or (Gradient RequiresGradient) gradient gradient')
         (Unify (Layout LayoutType) layout layout')
         (Unify (Device (DeviceType Nat)) device device')
         (Unify (DataType DType) dataType dataType')
         shape''))
-&gt; IO
     (Tensor
        (Or (Gradient RequiresGradient) gradient gradient')
        (Unify (Layout LayoutType) layout layout')
        (Unify (Device (DeviceType Nat)) device device')
        (Unify (DataType DType) dataType dataType')
        shape'')
-&gt; m (Tensor
        (Or (Gradient RequiresGradient) gradient gradient')
        (Unify (Layout LayoutType) layout layout')
        (Unify (Device (DeviceType Nat)) device device')
        (Unify (DataType DType) dataType dataType')
        shape'')
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; IO
     (Tensor
        (Or (Gradient RequiresGradient) gradient gradient')
        (Unify (Layout LayoutType) layout layout')
        (Unify (Device (DeviceType Nat)) device device')
        (Unify (DataType DType) dataType dataType')
        shape'')
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.floor_divide_tt</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679667131"><span class="hs-identifier hs-var">dividend</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient' layout' device' dataType' shape'
</span><a href="#local-6989586621679667130"><span class="hs-identifier hs-var">divisor</span></a></span><span>
</span><span id="line-655"></span><span>
</span><span id="line-656"></span><span class="hs-comment">-- | Return the division of the tensor 'dividend' by the scalar 'divisor'</span><span>
</span><span id="line-657"></span><span class="hs-comment">-- rounded down to the nearest integer:</span><span>
</span><span id="line-658"></span><span class="hs-comment">-- \[</span><span>
</span><span id="line-659"></span><span class="hs-comment">-- \mathrm{output}_i = \left\lfloor\frac{\mathrm{dividend}_i}{\mathrm{divisor}}\right\rfloor.</span><span>
</span><span id="line-660"></span><span class="hs-comment">-- \]</span><span>
</span><span id="line-661"></span><span class="hs-comment">--</span><span>
</span><span id="line-662"></span><span class="hs-comment">-- See 'floorDivide' for a version of this function where</span><span>
</span><span id="line-663"></span><span class="hs-comment">-- 'divisor' is a tensor.</span><span>
</span><span id="line-664"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#floorDivideScalar"><span class="hs-identifier hs-type">floorDivideScalar</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-665"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679667127"><span class="annot"><a href="#local-6989586621679667127"><span class="hs-identifier hs-type">divisor</span></a></span></span><span> </span><span id="local-6989586621679667126"><span class="annot"><a href="#local-6989586621679667126"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679667125"><span class="annot"><a href="#local-6989586621679667125"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679667124"><span class="annot"><a href="#local-6989586621679667124"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679667123"><span class="annot"><a href="#local-6989586621679667123"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679667122"><span class="annot"><a href="#local-6989586621679667122"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-666"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Scalar.html#Scalar"><span class="hs-identifier hs-type">Scalar</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667127"><span class="hs-identifier hs-type">divisor</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-667"></span><span>  </span><span class="hs-comment">-- | dividend tensor</span><span>
</span><span id="line-668"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667126"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667125"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667124"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667123"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667122"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-669"></span><span>  </span><span class="hs-comment">-- | divisor scalar</span><span>
</span><span id="line-670"></span><span>  </span><span class="annot"><a href="#local-6989586621679667127"><span class="hs-identifier hs-type">divisor</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-671"></span><span>  </span><span class="hs-comment">-- | output tensor</span><span>
</span><span id="line-672"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667126"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667125"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667124"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667123"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667122"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-673"></span><span id="local-6989586621679667121"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679667121"><span class="hs-identifier hs-var">dividend</span></a></span></span><span> </span><span id="floorDivideScalar"><span class="annot"><span class="annottext">floorDivideScalar :: Tensor gradient layout device dataType shape
-&gt; divisor -&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#floorDivideScalar"><span class="hs-operator hs-var hs-var">`floorDivideScalar`</span></a></span></span><span> </span><span id="local-6989586621679667120"><span class="annot"><span class="annottext">divisor
</span><a href="#local-6989586621679667120"><span class="hs-identifier hs-var">divisor</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ForeignPtr Scalar -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; divisor
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr Scalar -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.floor_divide_ts</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679667121"><span class="hs-identifier hs-var">dividend</span></a></span><span> </span><span class="annot"><span class="annottext">divisor
</span><a href="#local-6989586621679667120"><span class="hs-identifier hs-var">divisor</span></a></span><span>
</span><span id="line-674"></span><span>
</span><span id="line-675"></span><span class="hs-comment">-- | Computes the element-wise remainder of the division of</span><span>
</span><span id="line-676"></span><span class="hs-comment">-- the tensor 'dividend' by the tensor 'divisor'.</span><span>
</span><span id="line-677"></span><span class="hs-comment">-- The dividend and divisor may contain both for integer and floating point numbers.</span><span>
</span><span id="line-678"></span><span class="hs-comment">-- The remainder has the same sign as the 'dividend' input.</span><span>
</span><span id="line-679"></span><span class="hs-comment">--</span><span>
</span><span id="line-680"></span><span class="hs-comment">-- See 'fmodScalar' for a version of this function where</span><span>
</span><span id="line-681"></span><span class="hs-comment">-- 'divisor' is a scalar.</span><span>
</span><span id="line-682"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#fmod"><span class="hs-identifier hs-type">fmod</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-683"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679667117"><span class="annot"><a href="#local-6989586621679667117"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679667116"><span class="annot"><a href="#local-6989586621679667116"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679667115"><span class="annot"><a href="#local-6989586621679667115"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679667114"><span class="annot"><a href="#local-6989586621679667114"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679667113"><span class="annot"><a href="#local-6989586621679667113"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679667112"><span class="annot"><a href="#local-6989586621679667112"><span class="hs-identifier hs-type">gradient'</span></a></span></span><span> </span><span id="local-6989586621679667111"><span class="annot"><a href="#local-6989586621679667111"><span class="hs-identifier hs-type">layout'</span></a></span></span><span> </span><span id="local-6989586621679667110"><span class="annot"><a href="#local-6989586621679667110"><span class="hs-identifier hs-type">device'</span></a></span></span><span> </span><span id="local-6989586621679667109"><span class="annot"><a href="#local-6989586621679667109"><span class="hs-identifier hs-type">dataType'</span></a></span></span><span> </span><span id="local-6989586621679667108"><span class="annot"><a href="#local-6989586621679667108"><span class="hs-identifier hs-type">shape'</span></a></span></span><span> </span><span id="local-6989586621679667107"><span class="annot"><a href="#local-6989586621679667107"><span class="hs-identifier hs-type">shape''</span></a></span></span><span> </span><span id="local-6989586621679667106"><span class="annot"><a href="#local-6989586621679667106"><span class="hs-identifier hs-type">m</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-684"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier hs-type">MonadThrow</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667106"><span class="hs-identifier hs-type">m</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679667107"><span class="hs-identifier hs-type">shape''</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#BroadcastShapesF"><span class="hs-identifier hs-type">BroadcastShapesF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667113"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667108"><span class="hs-identifier hs-type">shape'</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Catch"><span class="hs-identifier hs-type">Catch</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667107"><span class="hs-identifier hs-type">shape''</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-685"></span><span>  </span><span class="hs-comment">-- | dividend tensor</span><span>
</span><span id="line-686"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667117"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667116"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667115"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667114"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667113"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-687"></span><span>  </span><span class="hs-comment">-- | divisor scalar</span><span>
</span><span id="line-688"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667112"><span class="hs-identifier hs-type">gradient'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667111"><span class="hs-identifier hs-type">layout'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667110"><span class="hs-identifier hs-type">device'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667109"><span class="hs-identifier hs-type">dataType'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667108"><span class="hs-identifier hs-type">shape'</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-689"></span><span>  </span><span class="hs-comment">-- | output tensor</span><span>
</span><span id="line-690"></span><span>  </span><span class="annot"><a href="#local-6989586621679667106"><span class="hs-identifier hs-type">m</span></a></span><span>
</span><span id="line-691"></span><span>    </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-692"></span><span>        </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679667117"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667112"><span class="hs-identifier hs-type">gradient'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-693"></span><span>        </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679667116"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667111"><span class="hs-identifier hs-type">layout'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-694"></span><span>        </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679667115"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667110"><span class="hs-identifier hs-type">device'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-695"></span><span>        </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679667114"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667109"><span class="hs-identifier hs-type">dataType'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-696"></span><span>        </span><span class="annot"><a href="#local-6989586621679667107"><span class="hs-identifier hs-type">shape''</span></a></span><span>
</span><span id="line-697"></span><span>    </span><span class="hs-special">)</span><span>
</span><span id="line-698"></span><span id="local-6989586621679667105"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679667105"><span class="hs-identifier hs-var">dividend</span></a></span></span><span> </span><span id="fmod"><span class="annot"><span class="annottext">fmod :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; m (Tensor
        (gradient &lt;|&gt; gradient')
        (layout &lt;+&gt; layout')
        (device &lt;+&gt; device')
        (dataType &lt;+&gt; dataType')
        shape'')
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#fmod"><span class="hs-operator hs-var hs-var">`fmod`</span></a></span></span><span> </span><span id="local-6989586621679667104"><span class="annot"><span class="annottext">Tensor gradient' layout' device' dataType' shape'
</span><a href="#local-6989586621679667104"><span class="hs-identifier hs-var">divisor</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO
  (Tensor
     (Or (Gradient RequiresGradient) gradient gradient')
     (Unify (Layout LayoutType) layout layout')
     (Unify (Device (DeviceType Nat)) device device')
     (Unify (DataType DType) dataType dataType')
     shape'')
-&gt; m (Tensor
        (Or (Gradient RequiresGradient) gradient gradient')
        (Unify (Layout LayoutType) layout layout')
        (Unify (Device (DeviceType Nat)) device device')
        (Unify (DataType DType) dataType dataType')
        shape'')
forall a (m :: * -&gt; *). MonadThrow m =&gt; IO a -&gt; m a
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">unsafeThrowableIO</span></a></span><span> </span><span class="annot"><span class="annottext">(IO
   (Tensor
      (Or (Gradient RequiresGradient) gradient gradient')
      (Unify (Layout LayoutType) layout layout')
      (Unify (Device (DeviceType Nat)) device device')
      (Unify (DataType DType) dataType dataType')
      shape'')
 -&gt; m (Tensor
         (Or (Gradient RequiresGradient) gradient gradient')
         (Unify (Layout LayoutType) layout layout')
         (Unify (Device (DeviceType Nat)) device device')
         (Unify (DataType DType) dataType dataType')
         shape''))
-&gt; IO
     (Tensor
        (Or (Gradient RequiresGradient) gradient gradient')
        (Unify (Layout LayoutType) layout layout')
        (Unify (Device (DeviceType Nat)) device device')
        (Unify (DataType DType) dataType dataType')
        shape'')
-&gt; m (Tensor
        (Or (Gradient RequiresGradient) gradient gradient')
        (Unify (Layout LayoutType) layout layout')
        (Unify (Device (DeviceType Nat)) device device')
        (Unify (DataType DType) dataType dataType')
        shape'')
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; IO
     (Tensor
        (Or (Gradient RequiresGradient) gradient gradient')
        (Unify (Layout LayoutType) layout layout')
        (Unify (Device (DeviceType Nat)) device device')
        (Unify (DataType DType) dataType dataType')
        shape'')
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.fmod_tt</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679667105"><span class="hs-identifier hs-var">dividend</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient' layout' device' dataType' shape'
</span><a href="#local-6989586621679667104"><span class="hs-identifier hs-var">divisor</span></a></span><span>
</span><span id="line-699"></span><span>
</span><span id="line-700"></span><span class="hs-comment">-- | Computes the element-wise remainder of the division of</span><span>
</span><span id="line-701"></span><span class="hs-comment">-- the tensor 'dividend' by the scalar 'divisor'.</span><span>
</span><span id="line-702"></span><span class="hs-comment">-- The dividend and divisor may contain both for integer and floating point numbers.</span><span>
</span><span id="line-703"></span><span class="hs-comment">-- The remainder has the same sign as the 'dividend' input.</span><span>
</span><span id="line-704"></span><span class="hs-comment">--</span><span>
</span><span id="line-705"></span><span class="hs-comment">-- See 'fmodScalar' for a version of this function where</span><span>
</span><span id="line-706"></span><span class="hs-comment">-- 'divisor' is a scalar.</span><span>
</span><span id="line-707"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#fmodScalar"><span class="hs-identifier hs-type">fmodScalar</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-708"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679667101"><span class="annot"><a href="#local-6989586621679667101"><span class="hs-identifier hs-type">divisor</span></a></span></span><span> </span><span id="local-6989586621679667100"><span class="annot"><a href="#local-6989586621679667100"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679667099"><span class="annot"><a href="#local-6989586621679667099"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679667098"><span class="annot"><a href="#local-6989586621679667098"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679667097"><span class="annot"><a href="#local-6989586621679667097"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679667096"><span class="annot"><a href="#local-6989586621679667096"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-709"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Scalar.html#Scalar"><span class="hs-identifier hs-type">Scalar</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667101"><span class="hs-identifier hs-type">divisor</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-710"></span><span>  </span><span class="hs-comment">-- | divisor scalar</span><span>
</span><span id="line-711"></span><span>  </span><span class="annot"><a href="#local-6989586621679667101"><span class="hs-identifier hs-type">divisor</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-712"></span><span>  </span><span class="hs-comment">-- | dividend tensor</span><span>
</span><span id="line-713"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667100"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667099"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667098"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667097"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667096"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-714"></span><span>  </span><span class="hs-comment">-- | output tensor</span><span>
</span><span id="line-715"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667100"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667099"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667098"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667097"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667096"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-716"></span><span id="fmodScalar"><span class="annot"><span class="annottext">fmodScalar :: divisor
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#fmodScalar"><span class="hs-identifier hs-var hs-var">fmodScalar</span></a></span></span><span> </span><span id="local-6989586621679667095"><span class="annot"><span class="annottext">divisor
</span><a href="#local-6989586621679667095"><span class="hs-identifier hs-var">scalar</span></a></span></span><span> </span><span id="local-6989586621679667094"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679667094"><span class="hs-identifier hs-var">tensor</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ForeignPtr Scalar -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; divisor
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr Scalar -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.fmod_ts</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679667094"><span class="hs-identifier hs-var">tensor</span></a></span><span> </span><span class="annot"><span class="annottext">divisor
</span><a href="#local-6989586621679667095"><span class="hs-identifier hs-var">scalar</span></a></span><span>
</span><span id="line-717"></span><span>
</span><span id="line-718"></span><span class="hs-comment">-- | Computes the fractional portion of each element in 'input':</span><span>
</span><span id="line-719"></span><span class="hs-comment">-- \[</span><span>
</span><span id="line-720"></span><span class="hs-comment">-- \mathrm{output}_i = \mathrm{input}_i - \left\lfloor\left|\mathrm{input}_i\right|\right\rfloor \times \sgn\left(\mathrm{input}_i\right).</span><span>
</span><span id="line-721"></span><span class="hs-comment">-- \]</span><span>
</span><span id="line-722"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#frac"><span class="hs-identifier hs-type">frac</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-723"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679667091"><span class="annot"><a href="#local-6989586621679667091"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679667090"><span class="annot"><a href="#local-6989586621679667090"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679667089"><span class="annot"><a href="#local-6989586621679667089"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679667088"><span class="annot"><a href="#local-6989586621679667088"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679667087"><span class="annot"><a href="#local-6989586621679667087"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-724"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-725"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667091"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667090"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667089"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667088"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667087"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-726"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-727"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667091"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667090"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667089"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667088"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667087"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-728"></span><span id="frac"><span class="annot"><span class="annottext">frac :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#frac"><span class="hs-identifier hs-var hs-var">frac</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; (Tensor gradient layout device dataType shape
    -&gt; IO (Tensor gradient layout device dataType shape))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.frac_t</span></a></span><span>
</span><span id="line-729"></span><span>
</span><span id="line-730"></span><span class="hs-comment">-- | Linear interpolation of two tensors, 'start' and 'end', based on a tensor 'weight'.</span><span>
</span><span id="line-731"></span><span class="hs-comment">-- For linear interpolations based on a scalar see 'lerpScalar'.</span><span>
</span><span id="line-732"></span><span class="hs-comment">--</span><span>
</span><span id="line-733"></span><span class="hs-comment">-- Returned is the result of the following computation as a tensor:</span><span>
</span><span id="line-734"></span><span class="hs-comment">-- \[</span><span>
</span><span id="line-735"></span><span class="hs-comment">--   \mathrm{output}_i = \mathrm{start}_i + \mathrm{weight}_i \times \left(\mathrm{end}_i - \mathrm{start}_i\right).</span><span>
</span><span id="line-736"></span><span class="hs-comment">-- \]</span><span>
</span><span id="line-737"></span><span class="hs-comment">--</span><span>
</span><span id="line-738"></span><span class="hs-comment">-- Note that the shapes of 'start', 'end', and also 'weight' must be broadcastable.</span><span>
</span><span id="line-739"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#lerp"><span class="hs-identifier hs-type">lerp</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-740"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679667084"><span class="annot"><a href="#local-6989586621679667084"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679667083"><span class="annot"><a href="#local-6989586621679667083"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679667082"><span class="annot"><a href="#local-6989586621679667082"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679667081"><span class="annot"><a href="#local-6989586621679667081"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679667080"><span class="annot"><a href="#local-6989586621679667080"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679667079"><span class="annot"><a href="#local-6989586621679667079"><span class="hs-identifier hs-type">gradient'</span></a></span></span><span> </span><span id="local-6989586621679667078"><span class="annot"><a href="#local-6989586621679667078"><span class="hs-identifier hs-type">layout'</span></a></span></span><span> </span><span id="local-6989586621679667077"><span class="annot"><a href="#local-6989586621679667077"><span class="hs-identifier hs-type">device'</span></a></span></span><span> </span><span id="local-6989586621679667076"><span class="annot"><a href="#local-6989586621679667076"><span class="hs-identifier hs-type">dataType'</span></a></span></span><span> </span><span id="local-6989586621679667075"><span class="annot"><a href="#local-6989586621679667075"><span class="hs-identifier hs-type">shape'</span></a></span></span><span> </span><span id="local-6989586621679667074"><span class="annot"><a href="#local-6989586621679667074"><span class="hs-identifier hs-type">gradient''</span></a></span></span><span> </span><span id="local-6989586621679667073"><span class="annot"><a href="#local-6989586621679667073"><span class="hs-identifier hs-type">layout''</span></a></span></span><span> </span><span id="local-6989586621679667072"><span class="annot"><a href="#local-6989586621679667072"><span class="hs-identifier hs-type">device''</span></a></span></span><span> </span><span id="local-6989586621679667071"><span class="annot"><a href="#local-6989586621679667071"><span class="hs-identifier hs-type">dataType''</span></a></span></span><span> </span><span id="local-6989586621679667070"><span class="annot"><a href="#local-6989586621679667070"><span class="hs-identifier hs-type">shape''</span></a></span></span><span> </span><span id="local-6989586621679667069"><span class="annot"><a href="#local-6989586621679667069"><span class="hs-identifier hs-type">shape'''</span></a></span></span><span> </span><span id="local-6989586621679667068"><span class="annot"><a href="#local-6989586621679667068"><span class="hs-identifier hs-type">m</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-741"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier hs-type">MonadThrow</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667068"><span class="hs-identifier hs-type">m</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679667069"><span class="hs-identifier hs-type">shape'''</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#BroadcastShapesF"><span class="hs-identifier hs-type">BroadcastShapesF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667080"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#BroadcastShapesF"><span class="hs-identifier hs-type">BroadcastShapesF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667075"><span class="hs-identifier hs-type">shape'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667070"><span class="hs-identifier hs-type">shape''</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Catch"><span class="hs-identifier hs-type">Catch</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667069"><span class="hs-identifier hs-type">shape'''</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-742"></span><span>  </span><span class="hs-comment">-- | weight</span><span>
</span><span id="line-743"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667084"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667083"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667082"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667081"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667080"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-744"></span><span>  </span><span class="hs-comment">-- | start</span><span>
</span><span id="line-745"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667079"><span class="hs-identifier hs-type">gradient'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667078"><span class="hs-identifier hs-type">layout'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667077"><span class="hs-identifier hs-type">device'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667076"><span class="hs-identifier hs-type">dataType'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667075"><span class="hs-identifier hs-type">shape'</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-746"></span><span>  </span><span class="hs-comment">-- | end</span><span>
</span><span id="line-747"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667074"><span class="hs-identifier hs-type">gradient''</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667073"><span class="hs-identifier hs-type">layout''</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667072"><span class="hs-identifier hs-type">device''</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667071"><span class="hs-identifier hs-type">dataType''</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667070"><span class="hs-identifier hs-type">shape''</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-748"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-749"></span><span>  </span><span class="annot"><a href="#local-6989586621679667068"><span class="hs-identifier hs-type">m</span></a></span><span>
</span><span id="line-750"></span><span>    </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-751"></span><span>        </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679667084"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667079"><span class="hs-identifier hs-type">gradient'</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667074"><span class="hs-identifier hs-type">gradient''</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-752"></span><span>        </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679667083"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667078"><span class="hs-identifier hs-type">layout'</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667073"><span class="hs-identifier hs-type">layout''</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-753"></span><span>        </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679667082"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667077"><span class="hs-identifier hs-type">device'</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667072"><span class="hs-identifier hs-type">device''</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-754"></span><span>        </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679667081"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667076"><span class="hs-identifier hs-type">dataType'</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667071"><span class="hs-identifier hs-type">dataType''</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-755"></span><span>        </span><span class="annot"><a href="#local-6989586621679667069"><span class="hs-identifier hs-type">shape'''</span></a></span><span>
</span><span id="line-756"></span><span>    </span><span class="hs-special">)</span><span>
</span><span id="line-757"></span><span id="lerp"><span class="annot"><span class="annottext">lerp :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; Tensor gradient'' layout'' device'' dataType'' shape''
-&gt; m (Tensor
        (gradient &lt;|&gt; (gradient' &lt;|&gt; gradient''))
        (layout &lt;+&gt; (layout' &lt;+&gt; layout''))
        (device &lt;+&gt; (device' &lt;+&gt; device''))
        (dataType &lt;+&gt; (dataType' &lt;+&gt; dataType''))
        shape''')
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#lerp"><span class="hs-identifier hs-var hs-var">lerp</span></a></span></span><span> </span><span id="local-6989586621679667067"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679667067"><span class="hs-identifier hs-var">weight</span></a></span></span><span> </span><span id="local-6989586621679667066"><span class="annot"><span class="annottext">Tensor gradient' layout' device' dataType' shape'
</span><a href="#local-6989586621679667066"><span class="hs-identifier hs-var">start</span></a></span></span><span> </span><span id="local-6989586621679667065"><span class="annot"><span class="annottext">Tensor gradient'' layout'' device'' dataType'' shape''
</span><a href="#local-6989586621679667065"><span class="hs-identifier hs-var">end</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO
  (Tensor
     (Or
        (Gradient RequiresGradient)
        gradient
        (Or (Gradient RequiresGradient) gradient' gradient''))
     (Unify
        (Layout LayoutType)
        layout
        (Unify (Layout LayoutType) layout' layout''))
     (Unify
        (Device (DeviceType Nat))
        device
        (Unify (Device (DeviceType Nat)) device' device''))
     (Unify
        (DataType DType)
        dataType
        (Unify (DataType DType) dataType' dataType''))
     shape''')
-&gt; m (Tensor
        (Or
           (Gradient RequiresGradient)
           gradient
           (Or (Gradient RequiresGradient) gradient' gradient''))
        (Unify
           (Layout LayoutType)
           layout
           (Unify (Layout LayoutType) layout' layout''))
        (Unify
           (Device (DeviceType Nat))
           device
           (Unify (Device (DeviceType Nat)) device' device''))
        (Unify
           (DataType DType)
           dataType
           (Unify (DataType DType) dataType' dataType''))
        shape''')
forall a (m :: * -&gt; *). MonadThrow m =&gt; IO a -&gt; m a
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">unsafeThrowableIO</span></a></span><span> </span><span class="annot"><span class="annottext">(IO
   (Tensor
      (Or
         (Gradient RequiresGradient)
         gradient
         (Or (Gradient RequiresGradient) gradient' gradient''))
      (Unify
         (Layout LayoutType)
         layout
         (Unify (Layout LayoutType) layout' layout''))
      (Unify
         (Device (DeviceType Nat))
         device
         (Unify (Device (DeviceType Nat)) device' device''))
      (Unify
         (DataType DType)
         dataType
         (Unify (DataType DType) dataType' dataType''))
      shape''')
 -&gt; m (Tensor
         (Or
            (Gradient RequiresGradient)
            gradient
            (Or (Gradient RequiresGradient) gradient' gradient''))
         (Unify
            (Layout LayoutType)
            layout
            (Unify (Layout LayoutType) layout' layout''))
         (Unify
            (Device (DeviceType Nat))
            device
            (Unify (Device (DeviceType Nat)) device' device''))
         (Unify
            (DataType DType)
            dataType
            (Unify (DataType DType) dataType' dataType''))
         shape'''))
-&gt; IO
     (Tensor
        (Or
           (Gradient RequiresGradient)
           gradient
           (Or (Gradient RequiresGradient) gradient' gradient''))
        (Unify
           (Layout LayoutType)
           layout
           (Unify (Layout LayoutType) layout' layout''))
        (Unify
           (Device (DeviceType Nat))
           device
           (Unify (Device (DeviceType Nat)) device' device''))
        (Unify
           (DataType DType)
           dataType
           (Unify (DataType DType) dataType' dataType''))
        shape''')
-&gt; m (Tensor
        (Or
           (Gradient RequiresGradient)
           gradient
           (Or (Gradient RequiresGradient) gradient' gradient''))
        (Unify
           (Layout LayoutType)
           layout
           (Unify (Layout LayoutType) layout' layout''))
        (Unify
           (Device (DeviceType Nat))
           device
           (Unify (Device (DeviceType Nat)) device' device''))
        (Unify
           (DataType DType)
           dataType
           (Unify (DataType DType) dataType' dataType''))
        shape''')
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; Tensor gradient'' layout'' device'' dataType'' shape''
-&gt; Tensor gradient layout device dataType shape
-&gt; IO
     (Tensor
        (Or
           (Gradient RequiresGradient)
           gradient
           (Or (Gradient RequiresGradient) gradient' gradient''))
        (Unify
           (Layout LayoutType)
           layout
           (Unify (Layout LayoutType) layout' layout''))
        (Unify
           (Device (DeviceType Nat))
           device
           (Unify (Device (DeviceType Nat)) device' device''))
        (Unify
           (DataType DType)
           dataType
           (Unify (DataType DType) dataType' dataType''))
        shape''')
forall a ca x1 cx1 x2 cx2 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; x2 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast3</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.lerp_ttt</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient' layout' device' dataType' shape'
</span><a href="#local-6989586621679667066"><span class="hs-identifier hs-var">start</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient'' layout'' device'' dataType'' shape''
</span><a href="#local-6989586621679667065"><span class="hs-identifier hs-var">end</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679667067"><span class="hs-identifier hs-var">weight</span></a></span><span>
</span><span id="line-758"></span><span>
</span><span id="line-759"></span><span class="hs-comment">-- | Linear interpolation of two tensors, 'start' and 'end', based on a scalar 'weight'.</span><span>
</span><span id="line-760"></span><span class="hs-comment">-- For linear interpolations based on a tensor see 'lerp'.</span><span>
</span><span id="line-761"></span><span class="hs-comment">--</span><span>
</span><span id="line-762"></span><span class="hs-comment">-- Returned is the result of the following computation as a tensor:</span><span>
</span><span id="line-763"></span><span class="hs-comment">-- \[</span><span>
</span><span id="line-764"></span><span class="hs-comment">--   \mathrm{output}_i = \mathrm{start}_i + \mathrm{weight} \times \left(\mathrm{end}_i - \mathrm{start}_i\right).</span><span>
</span><span id="line-765"></span><span class="hs-comment">-- \]</span><span>
</span><span id="line-766"></span><span class="hs-comment">--</span><span>
</span><span id="line-767"></span><span class="hs-comment">-- Note that the shapes of 'start' and 'end' must be broadcastable.</span><span>
</span><span id="line-768"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#lerpScalar"><span class="hs-identifier hs-type">lerpScalar</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-769"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679667062"><span class="annot"><a href="#local-6989586621679667062"><span class="hs-identifier hs-type">weight</span></a></span></span><span> </span><span id="local-6989586621679667061"><span class="annot"><a href="#local-6989586621679667061"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679667060"><span class="annot"><a href="#local-6989586621679667060"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679667059"><span class="annot"><a href="#local-6989586621679667059"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679667058"><span class="annot"><a href="#local-6989586621679667058"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679667057"><span class="annot"><a href="#local-6989586621679667057"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679667056"><span class="annot"><a href="#local-6989586621679667056"><span class="hs-identifier hs-type">gradient'</span></a></span></span><span> </span><span id="local-6989586621679667055"><span class="annot"><a href="#local-6989586621679667055"><span class="hs-identifier hs-type">layout'</span></a></span></span><span> </span><span id="local-6989586621679667054"><span class="annot"><a href="#local-6989586621679667054"><span class="hs-identifier hs-type">device'</span></a></span></span><span> </span><span id="local-6989586621679667053"><span class="annot"><a href="#local-6989586621679667053"><span class="hs-identifier hs-type">dataType'</span></a></span></span><span> </span><span id="local-6989586621679667052"><span class="annot"><a href="#local-6989586621679667052"><span class="hs-identifier hs-type">shape'</span></a></span></span><span> </span><span id="local-6989586621679667051"><span class="annot"><a href="#local-6989586621679667051"><span class="hs-identifier hs-type">shape''</span></a></span></span><span> </span><span id="local-6989586621679667050"><span class="annot"><a href="#local-6989586621679667050"><span class="hs-identifier hs-type">m</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-770"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Scalar.html#Scalar"><span class="hs-identifier hs-type">Scalar</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667062"><span class="hs-identifier hs-type">weight</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier hs-type">MonadThrow</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667050"><span class="hs-identifier hs-type">m</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679667051"><span class="hs-identifier hs-type">shape''</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#BroadcastShapesF"><span class="hs-identifier hs-type">BroadcastShapesF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667057"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667052"><span class="hs-identifier hs-type">shape'</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Catch"><span class="hs-identifier hs-type">Catch</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667051"><span class="hs-identifier hs-type">shape''</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-771"></span><span>  </span><span class="hs-comment">-- | weight</span><span>
</span><span id="line-772"></span><span>  </span><span class="annot"><a href="#local-6989586621679667062"><span class="hs-identifier hs-type">weight</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-773"></span><span>  </span><span class="hs-comment">-- | start</span><span>
</span><span id="line-774"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667061"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667060"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667059"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667058"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667057"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-775"></span><span>  </span><span class="hs-comment">-- | end</span><span>
</span><span id="line-776"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667056"><span class="hs-identifier hs-type">gradient'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667055"><span class="hs-identifier hs-type">layout'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667054"><span class="hs-identifier hs-type">device'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667053"><span class="hs-identifier hs-type">dataType'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667052"><span class="hs-identifier hs-type">shape'</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-777"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-778"></span><span>  </span><span class="annot"><a href="#local-6989586621679667050"><span class="hs-identifier hs-type">m</span></a></span><span>
</span><span id="line-779"></span><span>    </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-780"></span><span>        </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679667061"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667056"><span class="hs-identifier hs-type">gradient'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-781"></span><span>        </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679667060"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667055"><span class="hs-identifier hs-type">layout'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-782"></span><span>        </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679667059"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667054"><span class="hs-identifier hs-type">device'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-783"></span><span>        </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679667058"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667053"><span class="hs-identifier hs-type">dataType'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-784"></span><span>        </span><span class="annot"><a href="#local-6989586621679667051"><span class="hs-identifier hs-type">shape''</span></a></span><span>
</span><span id="line-785"></span><span>    </span><span class="hs-special">)</span><span>
</span><span id="line-786"></span><span id="lerpScalar"><span class="annot"><span class="annottext">lerpScalar :: weight
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; m (Tensor
        (gradient &lt;|&gt; gradient')
        (layout &lt;+&gt; layout')
        (device &lt;+&gt; device')
        (dataType &lt;+&gt; dataType')
        shape'')
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#lerpScalar"><span class="hs-identifier hs-var hs-var">lerpScalar</span></a></span></span><span> </span><span id="local-6989586621679667049"><span class="annot"><span class="annottext">weight
</span><a href="#local-6989586621679667049"><span class="hs-identifier hs-var">weight</span></a></span></span><span> </span><span id="local-6989586621679667048"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679667048"><span class="hs-identifier hs-var">start</span></a></span></span><span> </span><span id="local-6989586621679667047"><span class="annot"><span class="annottext">Tensor gradient' layout' device' dataType' shape'
</span><a href="#local-6989586621679667047"><span class="hs-identifier hs-var">end</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO
  (Tensor
     (Or (Gradient RequiresGradient) gradient gradient')
     (Unify (Layout LayoutType) layout layout')
     (Unify (Device (DeviceType Nat)) device device')
     (Unify (DataType DType) dataType dataType')
     shape'')
-&gt; m (Tensor
        (Or (Gradient RequiresGradient) gradient gradient')
        (Unify (Layout LayoutType) layout layout')
        (Unify (Device (DeviceType Nat)) device device')
        (Unify (DataType DType) dataType dataType')
        shape'')
forall a (m :: * -&gt; *). MonadThrow m =&gt; IO a -&gt; m a
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">unsafeThrowableIO</span></a></span><span> </span><span class="annot"><span class="annottext">(IO
   (Tensor
      (Or (Gradient RequiresGradient) gradient gradient')
      (Unify (Layout LayoutType) layout layout')
      (Unify (Device (DeviceType Nat)) device device')
      (Unify (DataType DType) dataType dataType')
      shape'')
 -&gt; m (Tensor
         (Or (Gradient RequiresGradient) gradient gradient')
         (Unify (Layout LayoutType) layout layout')
         (Unify (Device (DeviceType Nat)) device device')
         (Unify (DataType DType) dataType dataType')
         shape''))
-&gt; IO
     (Tensor
        (Or (Gradient RequiresGradient) gradient gradient')
        (Unify (Layout LayoutType) layout layout')
        (Unify (Device (DeviceType Nat)) device device')
        (Unify (DataType DType) dataType dataType')
        shape'')
-&gt; m (Tensor
        (Or (Gradient RequiresGradient) gradient gradient')
        (Unify (Layout LayoutType) layout layout')
        (Unify (Device (DeviceType Nat)) device device')
        (Unify (DataType DType) dataType dataType')
        shape'')
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor
 -&gt; ForeignPtr Tensor
 -&gt; ForeignPtr Scalar
 -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; weight
-&gt; IO
     (Tensor
        (Or (Gradient RequiresGradient) gradient gradient')
        (Unify (Layout LayoutType) layout layout')
        (Unify (Device (DeviceType Nat)) device device')
        (Unify (DataType DType) dataType dataType')
        shape'')
forall a ca x1 cx1 x2 cx2 y cy.
(Castable a ca, Castable x1 cx1, Castable x2 cx2, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; cx2 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; x2 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast3</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor
-&gt; ForeignPtr Tensor -&gt; ForeignPtr Scalar -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.lerp_tts</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679667048"><span class="hs-identifier hs-var">start</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient' layout' device' dataType' shape'
</span><a href="#local-6989586621679667047"><span class="hs-identifier hs-var">end</span></a></span><span> </span><span class="annot"><span class="annottext">weight
</span><a href="#local-6989586621679667049"><span class="hs-identifier hs-var">weight</span></a></span><span>
</span><span id="line-787"></span><span>
</span><span id="line-788"></span><span class="hs-comment">-- | Computes the logarithm of the gamma function on 'input':</span><span>
</span><span id="line-789"></span><span class="hs-comment">-- \[</span><span>
</span><span id="line-790"></span><span class="hs-comment">-- \mathrm{output}_i = \log \Gamma\left(\mathrm{input}_i\right).</span><span>
</span><span id="line-791"></span><span class="hs-comment">-- \]</span><span>
</span><span id="line-792"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#lgamma"><span class="hs-identifier hs-type">lgamma</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-793"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679667044"><span class="annot"><a href="#local-6989586621679667044"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679667043"><span class="annot"><a href="#local-6989586621679667043"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679667042"><span class="annot"><a href="#local-6989586621679667042"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679667041"><span class="annot"><a href="#local-6989586621679667041"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679667040"><span class="annot"><a href="#local-6989586621679667040"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-794"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-795"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667044"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667043"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667042"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667041"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667040"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-796"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-797"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667044"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667043"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667042"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667041"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667040"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-798"></span><span id="lgamma"><span class="annot"><span class="annottext">lgamma :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#lgamma"><span class="hs-identifier hs-var hs-var">lgamma</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; (Tensor gradient layout device dataType shape
    -&gt; IO (Tensor gradient layout device dataType shape))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.lgamma_t</span></a></span><span>
</span><span id="line-799"></span><span>
</span><span id="line-800"></span><span class="hs-comment">-- | Returns a new tensor with the natural logarithm of the elements of 'input':</span><span>
</span><span id="line-801"></span><span class="hs-comment">-- \[</span><span>
</span><span id="line-802"></span><span class="hs-comment">-- \mathrm{output}_i = \ln \left(\mathrm{input}_i\right) = \log_{\mathrm{e}} \left(\mathrm{input}_i\right).</span><span>
</span><span id="line-803"></span><span class="hs-comment">-- \]</span><span>
</span><span id="line-804"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#log"><span class="hs-identifier hs-type">log</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-805"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679667037"><span class="annot"><a href="#local-6989586621679667037"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679667036"><span class="annot"><a href="#local-6989586621679667036"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679667035"><span class="annot"><a href="#local-6989586621679667035"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679667034"><span class="annot"><a href="#local-6989586621679667034"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679667033"><span class="annot"><a href="#local-6989586621679667033"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-806"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-807"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667037"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667036"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667035"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667034"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667033"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-808"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-809"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667037"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667036"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667035"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667034"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667033"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-810"></span><span id="log"><span class="annot"><span class="annottext">log :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#log"><span class="hs-identifier hs-var hs-var">log</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; (Tensor gradient layout device dataType shape
    -&gt; IO (Tensor gradient layout device dataType shape))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.log_t</span></a></span><span>
</span><span id="line-811"></span><span>
</span><span id="line-812"></span><span class="hs-comment">-- | Returns a new tensor with the decimal logarithm of the elements of 'input':</span><span>
</span><span id="line-813"></span><span class="hs-comment">-- \[</span><span>
</span><span id="line-814"></span><span class="hs-comment">-- \mathrm{output}_i = \mathop{lg} \left(\mathrm{input}_i\right) = \log_{10} \left(\mathrm{input}_i\right).</span><span>
</span><span id="line-815"></span><span class="hs-comment">-- \]</span><span>
</span><span id="line-816"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#log10"><span class="hs-identifier hs-type">log10</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-817"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679667030"><span class="annot"><a href="#local-6989586621679667030"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679667029"><span class="annot"><a href="#local-6989586621679667029"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679667028"><span class="annot"><a href="#local-6989586621679667028"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679667027"><span class="annot"><a href="#local-6989586621679667027"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679667026"><span class="annot"><a href="#local-6989586621679667026"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-818"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-819"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667030"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667029"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667028"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667027"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667026"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-820"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-821"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667030"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667029"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667028"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667027"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667026"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-822"></span><span id="log10"><span class="annot"><span class="annottext">log10 :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#log10"><span class="hs-identifier hs-var hs-var">log10</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; (Tensor gradient layout device dataType shape
    -&gt; IO (Tensor gradient layout device dataType shape))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.log10_t</span></a></span><span>
</span><span id="line-823"></span><span>
</span><span id="line-824"></span><span class="hs-comment">-- | Returns a new tensor with the natural logarithm of \(1 + \mathrm{input}\):</span><span>
</span><span id="line-825"></span><span class="hs-comment">-- \[</span><span>
</span><span id="line-826"></span><span class="hs-comment">-- \mathrm{output}_i = \ln \left(1 + \mathrm{input}_i\right).</span><span>
</span><span id="line-827"></span><span class="hs-comment">-- \]</span><span>
</span><span id="line-828"></span><span class="hs-comment">--</span><span>
</span><span id="line-829"></span><span class="hs-comment">-- Consider using this function over a literal implementation using 'log'.</span><span>
</span><span id="line-830"></span><span class="hs-comment">-- 'log1p' is much more accurate for small values of 'input'.</span><span>
</span><span id="line-831"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#log1p"><span class="hs-identifier hs-type">log1p</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-832"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679667023"><span class="annot"><a href="#local-6989586621679667023"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679667022"><span class="annot"><a href="#local-6989586621679667022"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679667021"><span class="annot"><a href="#local-6989586621679667021"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679667020"><span class="annot"><a href="#local-6989586621679667020"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679667019"><span class="annot"><a href="#local-6989586621679667019"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-833"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-834"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667023"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667022"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667021"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667020"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667019"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-835"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-836"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667023"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667022"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667021"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667020"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667019"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-837"></span><span id="log1p"><span class="annot"><span class="annottext">log1p :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#log1p"><span class="hs-identifier hs-var hs-var">log1p</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; (Tensor gradient layout device dataType shape
    -&gt; IO (Tensor gradient layout device dataType shape))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.log1p_t</span></a></span><span>
</span><span id="line-838"></span><span>
</span><span id="line-839"></span><span class="hs-comment">-- | Returns a new tensor with the logarithm to the base 2 of the elements of 'input':</span><span>
</span><span id="line-840"></span><span class="hs-comment">-- \[</span><span>
</span><span id="line-841"></span><span class="hs-comment">-- \mathrm{output}_i = \log_2 \left(\mathrm{input}_i\right).</span><span>
</span><span id="line-842"></span><span class="hs-comment">-- \]</span><span>
</span><span id="line-843"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#log2"><span class="hs-identifier hs-type">log2</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-844"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679667016"><span class="annot"><a href="#local-6989586621679667016"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679667015"><span class="annot"><a href="#local-6989586621679667015"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679667014"><span class="annot"><a href="#local-6989586621679667014"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679667013"><span class="annot"><a href="#local-6989586621679667013"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679667012"><span class="annot"><a href="#local-6989586621679667012"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-845"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-846"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667016"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667015"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667014"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667013"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667012"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-847"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-848"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667016"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667015"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667014"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667013"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667012"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-849"></span><span id="log2"><span class="annot"><span class="annottext">log2 :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#log2"><span class="hs-identifier hs-var hs-var">log2</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; (Tensor gradient layout device dataType shape
    -&gt; IO (Tensor gradient layout device dataType shape))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.log2_t</span></a></span><span>
</span><span id="line-850"></span><span>
</span><span id="line-851"></span><span class="hs-comment">-- | Logarithm of the sum of exponentiations of the inputs.</span><span>
</span><span id="line-852"></span><span class="hs-comment">-- Calculates pointwise the function \(\log \left(\exp x + \exp y\right)\).</span><span>
</span><span id="line-853"></span><span class="hs-comment">--</span><span>
</span><span id="line-854"></span><span class="hs-comment">-- This function is useful in statistics where the calculated probabilities of</span><span>
</span><span id="line-855"></span><span class="hs-comment">-- events may be so small as to exceed the range of normal floating point numbers.</span><span>
</span><span id="line-856"></span><span class="hs-comment">-- In such cases the logarithm of the calculated probability is stored.</span><span>
</span><span id="line-857"></span><span class="hs-comment">-- This function allows adding probabilities stored in such a fashion.</span><span>
</span><span id="line-858"></span><span class="hs-comment">--</span><span>
</span><span id="line-859"></span><span class="hs-comment">-- 'logaddexp' must not be confused with 'logsumexp' which performs a reduction on a single tensor.</span><span>
</span><span id="line-860"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#logaddexp"><span class="hs-identifier hs-type">logaddexp</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-861"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679667009"><span class="annot"><a href="#local-6989586621679667009"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679667008"><span class="annot"><a href="#local-6989586621679667008"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679667007"><span class="annot"><a href="#local-6989586621679667007"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679667006"><span class="annot"><a href="#local-6989586621679667006"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679667005"><span class="annot"><a href="#local-6989586621679667005"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679667004"><span class="annot"><a href="#local-6989586621679667004"><span class="hs-identifier hs-type">gradient'</span></a></span></span><span> </span><span id="local-6989586621679667003"><span class="annot"><a href="#local-6989586621679667003"><span class="hs-identifier hs-type">layout'</span></a></span></span><span> </span><span id="local-6989586621679667002"><span class="annot"><a href="#local-6989586621679667002"><span class="hs-identifier hs-type">device'</span></a></span></span><span> </span><span id="local-6989586621679667001"><span class="annot"><a href="#local-6989586621679667001"><span class="hs-identifier hs-type">dataType'</span></a></span></span><span> </span><span id="local-6989586621679667000"><span class="annot"><a href="#local-6989586621679667000"><span class="hs-identifier hs-type">shape'</span></a></span></span><span> </span><span id="local-6989586621679666999"><span class="annot"><a href="#local-6989586621679666999"><span class="hs-identifier hs-type">shape''</span></a></span></span><span> </span><span id="local-6989586621679666998"><span class="annot"><a href="#local-6989586621679666998"><span class="hs-identifier hs-type">m</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-862"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier hs-type">MonadThrow</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666998"><span class="hs-identifier hs-type">m</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679666999"><span class="hs-identifier hs-type">shape''</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#BroadcastShapesF"><span class="hs-identifier hs-type">BroadcastShapesF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667005"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667000"><span class="hs-identifier hs-type">shape'</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Catch"><span class="hs-identifier hs-type">Catch</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666999"><span class="hs-identifier hs-type">shape''</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-863"></span><span>  </span><span class="hs-comment">-- | other</span><span>
</span><span id="line-864"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667009"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667008"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667007"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667006"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667005"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-865"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-866"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667004"><span class="hs-identifier hs-type">gradient'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667003"><span class="hs-identifier hs-type">layout'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667002"><span class="hs-identifier hs-type">device'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667001"><span class="hs-identifier hs-type">dataType'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667000"><span class="hs-identifier hs-type">shape'</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-867"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-868"></span><span>  </span><span class="annot"><a href="#local-6989586621679666998"><span class="hs-identifier hs-type">m</span></a></span><span>
</span><span id="line-869"></span><span>    </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-870"></span><span>        </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679667009"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667004"><span class="hs-identifier hs-type">gradient'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-871"></span><span>        </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679667008"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667003"><span class="hs-identifier hs-type">layout'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-872"></span><span>        </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679667007"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667002"><span class="hs-identifier hs-type">device'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-873"></span><span>        </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679667006"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679667001"><span class="hs-identifier hs-type">dataType'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-874"></span><span>        </span><span class="annot"><a href="#local-6989586621679666999"><span class="hs-identifier hs-type">shape''</span></a></span><span>
</span><span id="line-875"></span><span>    </span><span class="hs-special">)</span><span>
</span><span id="line-876"></span><span id="logaddexp"><span class="annot"><span class="annottext">logaddexp :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; m (Tensor
        (gradient &lt;|&gt; gradient')
        (layout &lt;+&gt; layout')
        (device &lt;+&gt; device')
        (dataType &lt;+&gt; dataType')
        shape'')
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#logaddexp"><span class="hs-identifier hs-var hs-var">logaddexp</span></a></span></span><span> </span><span id="local-6989586621679666997"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679666997"><span class="hs-identifier hs-var">other</span></a></span></span><span> </span><span id="local-6989586621679666996"><span class="annot"><span class="annottext">Tensor gradient' layout' device' dataType' shape'
</span><a href="#local-6989586621679666996"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO
  (Tensor
     (Or (Gradient RequiresGradient) gradient gradient')
     (Unify (Layout LayoutType) layout layout')
     (Unify (Device (DeviceType Nat)) device device')
     (Unify (DataType DType) dataType dataType')
     shape'')
-&gt; m (Tensor
        (Or (Gradient RequiresGradient) gradient gradient')
        (Unify (Layout LayoutType) layout layout')
        (Unify (Device (DeviceType Nat)) device device')
        (Unify (DataType DType) dataType dataType')
        shape'')
forall a (m :: * -&gt; *). MonadThrow m =&gt; IO a -&gt; m a
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">unsafeThrowableIO</span></a></span><span> </span><span class="annot"><span class="annottext">(IO
   (Tensor
      (Or (Gradient RequiresGradient) gradient gradient')
      (Unify (Layout LayoutType) layout layout')
      (Unify (Device (DeviceType Nat)) device device')
      (Unify (DataType DType) dataType dataType')
      shape'')
 -&gt; m (Tensor
         (Or (Gradient RequiresGradient) gradient gradient')
         (Unify (Layout LayoutType) layout layout')
         (Unify (Device (DeviceType Nat)) device device')
         (Unify (DataType DType) dataType dataType')
         shape''))
-&gt; IO
     (Tensor
        (Or (Gradient RequiresGradient) gradient gradient')
        (Unify (Layout LayoutType) layout layout')
        (Unify (Device (DeviceType Nat)) device device')
        (Unify (DataType DType) dataType dataType')
        shape'')
-&gt; m (Tensor
        (Or (Gradient RequiresGradient) gradient gradient')
        (Unify (Layout LayoutType) layout layout')
        (Unify (Device (DeviceType Nat)) device device')
        (Unify (DataType DType) dataType dataType')
        shape'')
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; Tensor gradient layout device dataType shape
-&gt; IO
     (Tensor
        (Or (Gradient RequiresGradient) gradient gradient')
        (Unify (Layout LayoutType) layout layout')
        (Unify (Device (DeviceType Nat)) device device')
        (Unify (DataType DType) dataType dataType')
        shape'')
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.logaddexp_tt</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient' layout' device' dataType' shape'
</span><a href="#local-6989586621679666996"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679666997"><span class="hs-identifier hs-var">other</span></a></span><span>
</span><span id="line-877"></span><span>
</span><span id="line-878"></span><span class="hs-comment">-- | Logarithm of the sum of exponentiations of the inputs in base-2.</span><span>
</span><span id="line-879"></span><span class="hs-comment">-- Calculates pointwise the function \(\log_2 \left(2^x + 2^y\right)\).</span><span>
</span><span id="line-880"></span><span class="hs-comment">--</span><span>
</span><span id="line-881"></span><span class="hs-comment">-- See 'logaddexp' for further details.</span><span>
</span><span id="line-882"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#logaddexp2"><span class="hs-identifier hs-type">logaddexp2</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-883"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679666993"><span class="annot"><a href="#local-6989586621679666993"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679666992"><span class="annot"><a href="#local-6989586621679666992"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679666991"><span class="annot"><a href="#local-6989586621679666991"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679666990"><span class="annot"><a href="#local-6989586621679666990"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679666989"><span class="annot"><a href="#local-6989586621679666989"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679666988"><span class="annot"><a href="#local-6989586621679666988"><span class="hs-identifier hs-type">gradient'</span></a></span></span><span> </span><span id="local-6989586621679666987"><span class="annot"><a href="#local-6989586621679666987"><span class="hs-identifier hs-type">layout'</span></a></span></span><span> </span><span id="local-6989586621679666986"><span class="annot"><a href="#local-6989586621679666986"><span class="hs-identifier hs-type">device'</span></a></span></span><span> </span><span id="local-6989586621679666985"><span class="annot"><a href="#local-6989586621679666985"><span class="hs-identifier hs-type">dataType'</span></a></span></span><span> </span><span id="local-6989586621679666984"><span class="annot"><a href="#local-6989586621679666984"><span class="hs-identifier hs-type">shape'</span></a></span></span><span> </span><span id="local-6989586621679666983"><span class="annot"><a href="#local-6989586621679666983"><span class="hs-identifier hs-type">shape''</span></a></span></span><span> </span><span id="local-6989586621679666982"><span class="annot"><a href="#local-6989586621679666982"><span class="hs-identifier hs-type">m</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-884"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier hs-type">MonadThrow</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666982"><span class="hs-identifier hs-type">m</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679666983"><span class="hs-identifier hs-type">shape''</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#BroadcastShapesF"><span class="hs-identifier hs-type">BroadcastShapesF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666989"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666984"><span class="hs-identifier hs-type">shape'</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Catch"><span class="hs-identifier hs-type">Catch</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666983"><span class="hs-identifier hs-type">shape''</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-885"></span><span>  </span><span class="hs-comment">-- | other</span><span>
</span><span id="line-886"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666993"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666992"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666991"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666990"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666989"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-887"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-888"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666988"><span class="hs-identifier hs-type">gradient'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666987"><span class="hs-identifier hs-type">layout'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666986"><span class="hs-identifier hs-type">device'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666985"><span class="hs-identifier hs-type">dataType'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666984"><span class="hs-identifier hs-type">shape'</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-889"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-890"></span><span>  </span><span class="annot"><a href="#local-6989586621679666982"><span class="hs-identifier hs-type">m</span></a></span><span>
</span><span id="line-891"></span><span>    </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-892"></span><span>        </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679666993"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666988"><span class="hs-identifier hs-type">gradient'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-893"></span><span>        </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679666992"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666987"><span class="hs-identifier hs-type">layout'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-894"></span><span>        </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679666991"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666986"><span class="hs-identifier hs-type">device'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-895"></span><span>        </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679666990"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666985"><span class="hs-identifier hs-type">dataType'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-896"></span><span>        </span><span class="annot"><a href="#local-6989586621679666983"><span class="hs-identifier hs-type">shape''</span></a></span><span>
</span><span id="line-897"></span><span>    </span><span class="hs-special">)</span><span>
</span><span id="line-898"></span><span id="logaddexp2"><span class="annot"><span class="annottext">logaddexp2 :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; m (Tensor
        (gradient &lt;|&gt; gradient')
        (layout &lt;+&gt; layout')
        (device &lt;+&gt; device')
        (dataType &lt;+&gt; dataType')
        shape'')
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#logaddexp2"><span class="hs-identifier hs-var hs-var">logaddexp2</span></a></span></span><span> </span><span id="local-6989586621679666981"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679666981"><span class="hs-identifier hs-var">other</span></a></span></span><span> </span><span id="local-6989586621679666980"><span class="annot"><span class="annottext">Tensor gradient' layout' device' dataType' shape'
</span><a href="#local-6989586621679666980"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO
  (Tensor
     (Or (Gradient RequiresGradient) gradient gradient')
     (Unify (Layout LayoutType) layout layout')
     (Unify (Device (DeviceType Nat)) device device')
     (Unify (DataType DType) dataType dataType')
     shape'')
-&gt; m (Tensor
        (Or (Gradient RequiresGradient) gradient gradient')
        (Unify (Layout LayoutType) layout layout')
        (Unify (Device (DeviceType Nat)) device device')
        (Unify (DataType DType) dataType dataType')
        shape'')
forall a (m :: * -&gt; *). MonadThrow m =&gt; IO a -&gt; m a
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">unsafeThrowableIO</span></a></span><span> </span><span class="annot"><span class="annottext">(IO
   (Tensor
      (Or (Gradient RequiresGradient) gradient gradient')
      (Unify (Layout LayoutType) layout layout')
      (Unify (Device (DeviceType Nat)) device device')
      (Unify (DataType DType) dataType dataType')
      shape'')
 -&gt; m (Tensor
         (Or (Gradient RequiresGradient) gradient gradient')
         (Unify (Layout LayoutType) layout layout')
         (Unify (Device (DeviceType Nat)) device device')
         (Unify (DataType DType) dataType dataType')
         shape''))
-&gt; IO
     (Tensor
        (Or (Gradient RequiresGradient) gradient gradient')
        (Unify (Layout LayoutType) layout layout')
        (Unify (Device (DeviceType Nat)) device device')
        (Unify (DataType DType) dataType dataType')
        shape'')
-&gt; m (Tensor
        (Or (Gradient RequiresGradient) gradient gradient')
        (Unify (Layout LayoutType) layout layout')
        (Unify (Device (DeviceType Nat)) device device')
        (Unify (DataType DType) dataType dataType')
        shape'')
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; Tensor gradient layout device dataType shape
-&gt; IO
     (Tensor
        (Or (Gradient RequiresGradient) gradient gradient')
        (Unify (Layout LayoutType) layout layout')
        (Unify (Device (DeviceType Nat)) device device')
        (Unify (DataType DType) dataType dataType')
        shape'')
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.logaddexp2_tt</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient' layout' device' dataType' shape'
</span><a href="#local-6989586621679666980"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679666981"><span class="hs-identifier hs-var">other</span></a></span><span>
</span><span id="line-899"></span><span>
</span><span id="line-900"></span><span class="hs-comment">-- | Computes the element-wise logical AND of the given input tensors.</span><span>
</span><span id="line-901"></span><span class="hs-comment">-- The output tensor will have the 'Bool' data type.</span><span>
</span><span id="line-902"></span><span class="hs-comment">-- If the input tensors are not a bool tensors,</span><span>
</span><span id="line-903"></span><span class="hs-comment">-- then zeros are treated as 'False' and nonzeros are treated as 'True'.</span><span>
</span><span id="line-904"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#logicalAnd"><span class="hs-identifier hs-type">logicalAnd</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-905"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679666977"><span class="annot"><a href="#local-6989586621679666977"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679666976"><span class="annot"><a href="#local-6989586621679666976"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679666975"><span class="annot"><a href="#local-6989586621679666975"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679666974"><span class="annot"><a href="#local-6989586621679666974"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679666973"><span class="annot"><a href="#local-6989586621679666973"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679666972"><span class="annot"><a href="#local-6989586621679666972"><span class="hs-identifier hs-type">gradient'</span></a></span></span><span> </span><span id="local-6989586621679666971"><span class="annot"><a href="#local-6989586621679666971"><span class="hs-identifier hs-type">layout'</span></a></span></span><span> </span><span id="local-6989586621679666970"><span class="annot"><a href="#local-6989586621679666970"><span class="hs-identifier hs-type">device'</span></a></span></span><span> </span><span id="local-6989586621679666969"><span class="annot"><a href="#local-6989586621679666969"><span class="hs-identifier hs-type">dataType'</span></a></span></span><span> </span><span id="local-6989586621679666968"><span class="annot"><a href="#local-6989586621679666968"><span class="hs-identifier hs-type">shape'</span></a></span></span><span> </span><span id="local-6989586621679666967"><span class="annot"><a href="#local-6989586621679666967"><span class="hs-identifier hs-type">shape''</span></a></span></span><span> </span><span id="local-6989586621679666966"><span class="annot"><a href="#local-6989586621679666966"><span class="hs-identifier hs-type">m</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-906"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier hs-type">MonadThrow</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666966"><span class="hs-identifier hs-type">m</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679666967"><span class="hs-identifier hs-type">shape''</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#BroadcastShapesF"><span class="hs-identifier hs-type">BroadcastShapesF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666973"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666968"><span class="hs-identifier hs-type">shape'</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Catch"><span class="hs-identifier hs-type">Catch</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666967"><span class="hs-identifier hs-type">shape''</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-907"></span><span>  </span><span class="hs-comment">-- | the input tensor</span><span>
</span><span id="line-908"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666977"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666976"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666975"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666974"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666973"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-909"></span><span>  </span><span class="hs-comment">-- | the tensor to compute AND with</span><span>
</span><span id="line-910"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666972"><span class="hs-identifier hs-type">gradient'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666971"><span class="hs-identifier hs-type">layout'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666970"><span class="hs-identifier hs-type">device'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666969"><span class="hs-identifier hs-type">dataType'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666968"><span class="hs-identifier hs-type">shape'</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-911"></span><span>  </span><span class="hs-comment">-- | the output tensor</span><span>
</span><span id="line-912"></span><span>  </span><span class="annot"><a href="#local-6989586621679666966"><span class="hs-identifier hs-type">m</span></a></span><span>
</span><span id="line-913"></span><span>    </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-914"></span><span>        </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#WithoutGradient"><span class="hs-identifier hs-type">WithoutGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-915"></span><span>        </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679666976"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666971"><span class="hs-identifier hs-type">layout'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-916"></span><span>        </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679666975"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666970"><span class="hs-identifier hs-type">device'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-917"></span><span>        </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#Bool"><span class="hs-identifier hs-type">Bool</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-918"></span><span>        </span><span class="annot"><a href="#local-6989586621679666967"><span class="hs-identifier hs-type">shape''</span></a></span><span>
</span><span id="line-919"></span><span>    </span><span class="hs-special">)</span><span>
</span><span id="line-920"></span><span id="local-6989586621679666965"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679666965"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span id="logicalAnd"><span class="annot"><span class="annottext">logicalAnd :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; m (Tensor
        ('Gradient 'WithoutGradient)
        (layout &lt;+&gt; layout')
        (device &lt;+&gt; device')
        ('DataType 'Bool)
        shape'')
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#logicalAnd"><span class="hs-operator hs-var hs-var">`logicalAnd`</span></a></span></span><span> </span><span id="local-6989586621679666964"><span class="annot"><span class="annottext">Tensor gradient' layout' device' dataType' shape'
</span><a href="#local-6989586621679666964"><span class="hs-identifier hs-var">other</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO
  (Tensor
     ('Gradient 'WithoutGradient)
     (Unify (Layout LayoutType) layout layout')
     (Unify (Device (DeviceType Nat)) device device')
     ('DataType 'Bool)
     shape'')
-&gt; m (Tensor
        ('Gradient 'WithoutGradient)
        (Unify (Layout LayoutType) layout layout')
        (Unify (Device (DeviceType Nat)) device device')
        ('DataType 'Bool)
        shape'')
forall a (m :: * -&gt; *). MonadThrow m =&gt; IO a -&gt; m a
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">unsafeThrowableIO</span></a></span><span> </span><span class="annot"><span class="annottext">(IO
   (Tensor
      ('Gradient 'WithoutGradient)
      (Unify (Layout LayoutType) layout layout')
      (Unify (Device (DeviceType Nat)) device device')
      ('DataType 'Bool)
      shape'')
 -&gt; m (Tensor
         ('Gradient 'WithoutGradient)
         (Unify (Layout LayoutType) layout layout')
         (Unify (Device (DeviceType Nat)) device device')
         ('DataType 'Bool)
         shape''))
-&gt; IO
     (Tensor
        ('Gradient 'WithoutGradient)
        (Unify (Layout LayoutType) layout layout')
        (Unify (Device (DeviceType Nat)) device device')
        ('DataType 'Bool)
        shape'')
-&gt; m (Tensor
        ('Gradient 'WithoutGradient)
        (Unify (Layout LayoutType) layout layout')
        (Unify (Device (DeviceType Nat)) device device')
        ('DataType 'Bool)
        shape'')
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; IO
     (Tensor
        ('Gradient 'WithoutGradient)
        (Unify (Layout LayoutType) layout layout')
        (Unify (Device (DeviceType Nat)) device device')
        ('DataType 'Bool)
        shape'')
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.logical_and_tt</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679666965"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient' layout' device' dataType' shape'
</span><a href="#local-6989586621679666964"><span class="hs-identifier hs-var">other</span></a></span><span>
</span><span id="line-921"></span><span>
</span><span id="line-922"></span><span class="hs-comment">-- | Computes the element-wise logical NOT of the given input tensor.</span><span>
</span><span id="line-923"></span><span class="hs-comment">-- The output tensor will have the 'Bool' data type.</span><span>
</span><span id="line-924"></span><span class="hs-comment">-- If the input tensor is not a bool tensor,</span><span>
</span><span id="line-925"></span><span class="hs-comment">-- zeros are treated as 'False' and non-zeros are treated as 'True'.</span><span>
</span><span id="line-926"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#logicalNot"><span class="hs-identifier hs-type">logicalNot</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-927"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679666961"><span class="annot"><a href="#local-6989586621679666961"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679666960"><span class="annot"><a href="#local-6989586621679666960"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679666959"><span class="annot"><a href="#local-6989586621679666959"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679666958"><span class="annot"><a href="#local-6989586621679666958"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679666957"><span class="annot"><a href="#local-6989586621679666957"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-928"></span><span>  </span><span class="hs-comment">-- | the input tensor</span><span>
</span><span id="line-929"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666961"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666960"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666959"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666958"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666957"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-930"></span><span>  </span><span class="hs-comment">-- | the output tensor</span><span>
</span><span id="line-931"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#WithoutGradient"><span class="hs-identifier hs-type">WithoutGradient</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679666960"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666959"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#Bool"><span class="hs-identifier hs-type">Bool</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679666957"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-932"></span><span id="logicalNot"><span class="annot"><span class="annottext">logicalNot :: Tensor gradient layout device dataType shape
-&gt; Tensor
     ('Gradient 'WithoutGradient) layout device ('DataType 'Bool) shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#logicalNot"><span class="hs-identifier hs-var hs-var">logicalNot</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO
  (Tensor
     ('Gradient 'WithoutGradient) layout device ('DataType 'Bool) shape)
-&gt; Tensor
     ('Gradient 'WithoutGradient) layout device ('DataType 'Bool) shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO
   (Tensor
      ('Gradient 'WithoutGradient) layout device ('DataType 'Bool) shape)
 -&gt; Tensor
      ('Gradient 'WithoutGradient) layout device ('DataType 'Bool) shape)
-&gt; (Tensor gradient layout device dataType shape
    -&gt; IO
         (Tensor
            ('Gradient 'WithoutGradient)
            layout
            device
            ('DataType 'Bool)
            shape))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor
     ('Gradient 'WithoutGradient) layout device ('DataType 'Bool) shape
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; IO
     (Tensor
        ('Gradient 'WithoutGradient) layout device ('DataType 'Bool) shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.logical_not_t</span></a></span><span>
</span><span id="line-933"></span><span>
</span><span id="line-934"></span><span class="hs-comment">-- | Computes the element-wise logical OR of the given input tensors.</span><span>
</span><span id="line-935"></span><span class="hs-comment">-- The output tensor will have the 'Bool' data type.</span><span>
</span><span id="line-936"></span><span class="hs-comment">-- If the input tensors are not a bool tensors,</span><span>
</span><span id="line-937"></span><span class="hs-comment">-- then zeros are treated as 'False' and nonzeros are treated as 'True'.</span><span>
</span><span id="line-938"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#logicalOr"><span class="hs-identifier hs-type">logicalOr</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-939"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679666954"><span class="annot"><a href="#local-6989586621679666954"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679666953"><span class="annot"><a href="#local-6989586621679666953"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679666952"><span class="annot"><a href="#local-6989586621679666952"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679666951"><span class="annot"><a href="#local-6989586621679666951"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679666950"><span class="annot"><a href="#local-6989586621679666950"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679666949"><span class="annot"><a href="#local-6989586621679666949"><span class="hs-identifier hs-type">gradient'</span></a></span></span><span> </span><span id="local-6989586621679666948"><span class="annot"><a href="#local-6989586621679666948"><span class="hs-identifier hs-type">layout'</span></a></span></span><span> </span><span id="local-6989586621679666947"><span class="annot"><a href="#local-6989586621679666947"><span class="hs-identifier hs-type">device'</span></a></span></span><span> </span><span id="local-6989586621679666946"><span class="annot"><a href="#local-6989586621679666946"><span class="hs-identifier hs-type">dataType'</span></a></span></span><span> </span><span id="local-6989586621679666945"><span class="annot"><a href="#local-6989586621679666945"><span class="hs-identifier hs-type">shape'</span></a></span></span><span> </span><span id="local-6989586621679666944"><span class="annot"><a href="#local-6989586621679666944"><span class="hs-identifier hs-type">shape''</span></a></span></span><span> </span><span id="local-6989586621679666943"><span class="annot"><a href="#local-6989586621679666943"><span class="hs-identifier hs-type">m</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-940"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier hs-type">MonadThrow</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666943"><span class="hs-identifier hs-type">m</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679666944"><span class="hs-identifier hs-type">shape''</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#BroadcastShapesF"><span class="hs-identifier hs-type">BroadcastShapesF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666950"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666945"><span class="hs-identifier hs-type">shape'</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Catch"><span class="hs-identifier hs-type">Catch</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666944"><span class="hs-identifier hs-type">shape''</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-941"></span><span>  </span><span class="hs-comment">-- | the input tensor</span><span>
</span><span id="line-942"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666954"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666953"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666952"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666951"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666950"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-943"></span><span>  </span><span class="hs-comment">-- | the tensor to compute OR with</span><span>
</span><span id="line-944"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666949"><span class="hs-identifier hs-type">gradient'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666948"><span class="hs-identifier hs-type">layout'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666947"><span class="hs-identifier hs-type">device'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666946"><span class="hs-identifier hs-type">dataType'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666945"><span class="hs-identifier hs-type">shape'</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-945"></span><span>  </span><span class="hs-comment">-- | the output tensor</span><span>
</span><span id="line-946"></span><span>  </span><span class="annot"><a href="#local-6989586621679666943"><span class="hs-identifier hs-type">m</span></a></span><span>
</span><span id="line-947"></span><span>    </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-948"></span><span>        </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#WithoutGradient"><span class="hs-identifier hs-type">WithoutGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-949"></span><span>        </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679666953"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666948"><span class="hs-identifier hs-type">layout'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-950"></span><span>        </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679666952"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666947"><span class="hs-identifier hs-type">device'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-951"></span><span>        </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#Bool"><span class="hs-identifier hs-type">Bool</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-952"></span><span>        </span><span class="annot"><a href="#local-6989586621679666944"><span class="hs-identifier hs-type">shape''</span></a></span><span>
</span><span id="line-953"></span><span>    </span><span class="hs-special">)</span><span>
</span><span id="line-954"></span><span id="local-6989586621679666942"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679666942"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span id="logicalOr"><span class="annot"><span class="annottext">logicalOr :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; m (Tensor
        ('Gradient 'WithoutGradient)
        (layout &lt;+&gt; layout')
        (device &lt;+&gt; device')
        ('DataType 'Bool)
        shape'')
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#logicalOr"><span class="hs-operator hs-var hs-var">`logicalOr`</span></a></span></span><span> </span><span id="local-6989586621679666941"><span class="annot"><span class="annottext">Tensor gradient' layout' device' dataType' shape'
</span><a href="#local-6989586621679666941"><span class="hs-identifier hs-var">other</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO
  (Tensor
     ('Gradient 'WithoutGradient)
     (Unify (Layout LayoutType) layout layout')
     (Unify (Device (DeviceType Nat)) device device')
     ('DataType 'Bool)
     shape'')
-&gt; m (Tensor
        ('Gradient 'WithoutGradient)
        (Unify (Layout LayoutType) layout layout')
        (Unify (Device (DeviceType Nat)) device device')
        ('DataType 'Bool)
        shape'')
forall a (m :: * -&gt; *). MonadThrow m =&gt; IO a -&gt; m a
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">unsafeThrowableIO</span></a></span><span> </span><span class="annot"><span class="annottext">(IO
   (Tensor
      ('Gradient 'WithoutGradient)
      (Unify (Layout LayoutType) layout layout')
      (Unify (Device (DeviceType Nat)) device device')
      ('DataType 'Bool)
      shape'')
 -&gt; m (Tensor
         ('Gradient 'WithoutGradient)
         (Unify (Layout LayoutType) layout layout')
         (Unify (Device (DeviceType Nat)) device device')
         ('DataType 'Bool)
         shape''))
-&gt; IO
     (Tensor
        ('Gradient 'WithoutGradient)
        (Unify (Layout LayoutType) layout layout')
        (Unify (Device (DeviceType Nat)) device device')
        ('DataType 'Bool)
        shape'')
-&gt; m (Tensor
        ('Gradient 'WithoutGradient)
        (Unify (Layout LayoutType) layout layout')
        (Unify (Device (DeviceType Nat)) device device')
        ('DataType 'Bool)
        shape'')
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; IO
     (Tensor
        ('Gradient 'WithoutGradient)
        (Unify (Layout LayoutType) layout layout')
        (Unify (Device (DeviceType Nat)) device device')
        ('DataType 'Bool)
        shape'')
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.logical_or_tt</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679666942"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient' layout' device' dataType' shape'
</span><a href="#local-6989586621679666941"><span class="hs-identifier hs-var">other</span></a></span><span>
</span><span id="line-955"></span><span>
</span><span id="line-956"></span><span class="hs-comment">-- | Computes the element-wise logical XOR of the given input tensors.</span><span>
</span><span id="line-957"></span><span class="hs-comment">-- The output tensor will have the 'Bool' data type.</span><span>
</span><span id="line-958"></span><span class="hs-comment">-- If the input tensors are not a bool tensors,</span><span>
</span><span id="line-959"></span><span class="hs-comment">-- then zeros are treated as 'False' and nonzeros are treated as 'True'.</span><span>
</span><span id="line-960"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#logicalXor"><span class="hs-identifier hs-type">logicalXor</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-961"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679666938"><span class="annot"><a href="#local-6989586621679666938"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679666937"><span class="annot"><a href="#local-6989586621679666937"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679666936"><span class="annot"><a href="#local-6989586621679666936"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679666935"><span class="annot"><a href="#local-6989586621679666935"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679666934"><span class="annot"><a href="#local-6989586621679666934"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679666933"><span class="annot"><a href="#local-6989586621679666933"><span class="hs-identifier hs-type">gradient'</span></a></span></span><span> </span><span id="local-6989586621679666932"><span class="annot"><a href="#local-6989586621679666932"><span class="hs-identifier hs-type">layout'</span></a></span></span><span> </span><span id="local-6989586621679666931"><span class="annot"><a href="#local-6989586621679666931"><span class="hs-identifier hs-type">device'</span></a></span></span><span> </span><span id="local-6989586621679666930"><span class="annot"><a href="#local-6989586621679666930"><span class="hs-identifier hs-type">dataType'</span></a></span></span><span> </span><span id="local-6989586621679666929"><span class="annot"><a href="#local-6989586621679666929"><span class="hs-identifier hs-type">shape'</span></a></span></span><span> </span><span id="local-6989586621679666928"><span class="annot"><a href="#local-6989586621679666928"><span class="hs-identifier hs-type">shape''</span></a></span></span><span> </span><span id="local-6989586621679666927"><span class="annot"><a href="#local-6989586621679666927"><span class="hs-identifier hs-type">m</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-962"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier hs-type">MonadThrow</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666927"><span class="hs-identifier hs-type">m</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679666928"><span class="hs-identifier hs-type">shape''</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#BroadcastShapesF"><span class="hs-identifier hs-type">BroadcastShapesF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666934"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666929"><span class="hs-identifier hs-type">shape'</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Catch"><span class="hs-identifier hs-type">Catch</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666928"><span class="hs-identifier hs-type">shape''</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-963"></span><span>  </span><span class="hs-comment">-- | the input tensor</span><span>
</span><span id="line-964"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666938"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666937"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666936"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666935"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666934"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-965"></span><span>  </span><span class="hs-comment">-- | the tensor to compute XOR with</span><span>
</span><span id="line-966"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666933"><span class="hs-identifier hs-type">gradient'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666932"><span class="hs-identifier hs-type">layout'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666931"><span class="hs-identifier hs-type">device'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666930"><span class="hs-identifier hs-type">dataType'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666929"><span class="hs-identifier hs-type">shape'</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-967"></span><span>  </span><span class="hs-comment">-- | the output tensor</span><span>
</span><span id="line-968"></span><span>  </span><span class="annot"><a href="#local-6989586621679666927"><span class="hs-identifier hs-type">m</span></a></span><span>
</span><span id="line-969"></span><span>    </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-970"></span><span>        </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#WithoutGradient"><span class="hs-identifier hs-type">WithoutGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-971"></span><span>        </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679666937"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666932"><span class="hs-identifier hs-type">layout'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-972"></span><span>        </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679666936"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666931"><span class="hs-identifier hs-type">device'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-973"></span><span>        </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#Bool"><span class="hs-identifier hs-type">Bool</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-974"></span><span>        </span><span class="annot"><a href="#local-6989586621679666928"><span class="hs-identifier hs-type">shape''</span></a></span><span>
</span><span id="line-975"></span><span>    </span><span class="hs-special">)</span><span>
</span><span id="line-976"></span><span id="local-6989586621679666926"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679666926"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span id="logicalXor"><span class="annot"><span class="annottext">logicalXor :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; m (Tensor
        ('Gradient 'WithoutGradient)
        (layout &lt;+&gt; layout')
        (device &lt;+&gt; device')
        ('DataType 'Bool)
        shape'')
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#logicalXor"><span class="hs-operator hs-var hs-var">`logicalXor`</span></a></span></span><span> </span><span id="local-6989586621679666925"><span class="annot"><span class="annottext">Tensor gradient' layout' device' dataType' shape'
</span><a href="#local-6989586621679666925"><span class="hs-identifier hs-var">other</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO
  (Tensor
     ('Gradient 'WithoutGradient)
     (Unify (Layout LayoutType) layout layout')
     (Unify (Device (DeviceType Nat)) device device')
     ('DataType 'Bool)
     shape'')
-&gt; m (Tensor
        ('Gradient 'WithoutGradient)
        (Unify (Layout LayoutType) layout layout')
        (Unify (Device (DeviceType Nat)) device device')
        ('DataType 'Bool)
        shape'')
forall a (m :: * -&gt; *). MonadThrow m =&gt; IO a -&gt; m a
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">unsafeThrowableIO</span></a></span><span> </span><span class="annot"><span class="annottext">(IO
   (Tensor
      ('Gradient 'WithoutGradient)
      (Unify (Layout LayoutType) layout layout')
      (Unify (Device (DeviceType Nat)) device device')
      ('DataType 'Bool)
      shape'')
 -&gt; m (Tensor
         ('Gradient 'WithoutGradient)
         (Unify (Layout LayoutType) layout layout')
         (Unify (Device (DeviceType Nat)) device device')
         ('DataType 'Bool)
         shape''))
-&gt; IO
     (Tensor
        ('Gradient 'WithoutGradient)
        (Unify (Layout LayoutType) layout layout')
        (Unify (Device (DeviceType Nat)) device device')
        ('DataType 'Bool)
        shape'')
-&gt; m (Tensor
        ('Gradient 'WithoutGradient)
        (Unify (Layout LayoutType) layout layout')
        (Unify (Device (DeviceType Nat)) device device')
        ('DataType 'Bool)
        shape'')
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; IO
     (Tensor
        ('Gradient 'WithoutGradient)
        (Unify (Layout LayoutType) layout layout')
        (Unify (Device (DeviceType Nat)) device device')
        ('DataType 'Bool)
        shape'')
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.logical_xor_tt</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679666926"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient' layout' device' dataType' shape'
</span><a href="#local-6989586621679666925"><span class="hs-identifier hs-var">other</span></a></span><span>
</span><span id="line-977"></span><span>
</span><span id="line-978"></span><span class="hs-comment">-- | Element-wise multiplication of two tensors:</span><span>
</span><span id="line-979"></span><span class="hs-comment">-- \[</span><span>
</span><span id="line-980"></span><span class="hs-comment">-- \mathrm{output}_i = \mathrm{input}_i \times \mathrm{other}_i.</span><span>
</span><span id="line-981"></span><span class="hs-comment">-- \]</span><span>
</span><span id="line-982"></span><span class="hs-comment">-- The result is returned as a new tensor.</span><span>
</span><span id="line-983"></span><span class="hs-comment">--</span><span>
</span><span id="line-984"></span><span class="hs-comment">-- The shape of 'other' must be broadcastable with the shape of 'input'.</span><span>
</span><span id="line-985"></span><span class="hs-comment">-- See 'mulScalar' for a version of this function where</span><span>
</span><span id="line-986"></span><span class="hs-comment">-- the 'other' input is a scalar.</span><span>
</span><span id="line-987"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#mul"><span class="hs-identifier hs-type">mul</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-988"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679666922"><span class="annot"><a href="#local-6989586621679666922"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679666921"><span class="annot"><a href="#local-6989586621679666921"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679666920"><span class="annot"><a href="#local-6989586621679666920"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679666919"><span class="annot"><a href="#local-6989586621679666919"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679666918"><span class="annot"><a href="#local-6989586621679666918"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679666917"><span class="annot"><a href="#local-6989586621679666917"><span class="hs-identifier hs-type">gradient'</span></a></span></span><span> </span><span id="local-6989586621679666916"><span class="annot"><a href="#local-6989586621679666916"><span class="hs-identifier hs-type">layout'</span></a></span></span><span> </span><span id="local-6989586621679666915"><span class="annot"><a href="#local-6989586621679666915"><span class="hs-identifier hs-type">device'</span></a></span></span><span> </span><span id="local-6989586621679666914"><span class="annot"><a href="#local-6989586621679666914"><span class="hs-identifier hs-type">dataType'</span></a></span></span><span> </span><span id="local-6989586621679666913"><span class="annot"><a href="#local-6989586621679666913"><span class="hs-identifier hs-type">shape'</span></a></span></span><span> </span><span id="local-6989586621679666912"><span class="annot"><a href="#local-6989586621679666912"><span class="hs-identifier hs-type">shape''</span></a></span></span><span> </span><span id="local-6989586621679666911"><span class="annot"><a href="#local-6989586621679666911"><span class="hs-identifier hs-type">m</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-989"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier hs-type">MonadThrow</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666911"><span class="hs-identifier hs-type">m</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679666912"><span class="hs-identifier hs-type">shape''</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#BroadcastShapesF"><span class="hs-identifier hs-type">BroadcastShapesF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666918"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666913"><span class="hs-identifier hs-type">shape'</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Catch"><span class="hs-identifier hs-type">Catch</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666912"><span class="hs-identifier hs-type">shape''</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-990"></span><span>  </span><span class="hs-comment">-- | input tensor</span><span>
</span><span id="line-991"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666922"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666921"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666920"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666919"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666918"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-992"></span><span>  </span><span class="hs-comment">-- | other tensor</span><span>
</span><span id="line-993"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666917"><span class="hs-identifier hs-type">gradient'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666916"><span class="hs-identifier hs-type">layout'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666915"><span class="hs-identifier hs-type">device'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666914"><span class="hs-identifier hs-type">dataType'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666913"><span class="hs-identifier hs-type">shape'</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-994"></span><span>  </span><span class="hs-comment">-- | output tensor</span><span>
</span><span id="line-995"></span><span>  </span><span class="annot"><a href="#local-6989586621679666911"><span class="hs-identifier hs-type">m</span></a></span><span>
</span><span id="line-996"></span><span>    </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-997"></span><span>        </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679666922"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666917"><span class="hs-identifier hs-type">gradient'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-998"></span><span>        </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679666921"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666916"><span class="hs-identifier hs-type">layout'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-999"></span><span>        </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679666920"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666915"><span class="hs-identifier hs-type">device'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-1000"></span><span>        </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679666919"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666914"><span class="hs-identifier hs-type">dataType'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-1001"></span><span>        </span><span class="annot"><a href="#local-6989586621679666912"><span class="hs-identifier hs-type">shape''</span></a></span><span>
</span><span id="line-1002"></span><span>    </span><span class="hs-special">)</span><span>
</span><span id="line-1003"></span><span id="local-6989586621679666910"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679666910"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span id="mul"><span class="annot"><span class="annottext">mul :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; m (Tensor
        (gradient &lt;|&gt; gradient')
        (layout &lt;+&gt; layout')
        (device &lt;+&gt; device')
        (dataType &lt;+&gt; dataType')
        shape'')
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#mul"><span class="hs-operator hs-var hs-var">`mul`</span></a></span></span><span> </span><span id="local-6989586621679666909"><span class="annot"><span class="annottext">Tensor gradient' layout' device' dataType' shape'
</span><a href="#local-6989586621679666909"><span class="hs-identifier hs-var">other</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO
  (Tensor
     (Or (Gradient RequiresGradient) gradient gradient')
     (Unify (Layout LayoutType) layout layout')
     (Unify (Device (DeviceType Nat)) device device')
     (Unify (DataType DType) dataType dataType')
     shape'')
-&gt; m (Tensor
        (Or (Gradient RequiresGradient) gradient gradient')
        (Unify (Layout LayoutType) layout layout')
        (Unify (Device (DeviceType Nat)) device device')
        (Unify (DataType DType) dataType dataType')
        shape'')
forall a (m :: * -&gt; *). MonadThrow m =&gt; IO a -&gt; m a
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">unsafeThrowableIO</span></a></span><span> </span><span class="annot"><span class="annottext">(IO
   (Tensor
      (Or (Gradient RequiresGradient) gradient gradient')
      (Unify (Layout LayoutType) layout layout')
      (Unify (Device (DeviceType Nat)) device device')
      (Unify (DataType DType) dataType dataType')
      shape'')
 -&gt; m (Tensor
         (Or (Gradient RequiresGradient) gradient gradient')
         (Unify (Layout LayoutType) layout layout')
         (Unify (Device (DeviceType Nat)) device device')
         (Unify (DataType DType) dataType dataType')
         shape''))
-&gt; IO
     (Tensor
        (Or (Gradient RequiresGradient) gradient gradient')
        (Unify (Layout LayoutType) layout layout')
        (Unify (Device (DeviceType Nat)) device device')
        (Unify (DataType DType) dataType dataType')
        shape'')
-&gt; m (Tensor
        (Or (Gradient RequiresGradient) gradient gradient')
        (Unify (Layout LayoutType) layout layout')
        (Unify (Device (DeviceType Nat)) device device')
        (Unify (DataType DType) dataType dataType')
        shape'')
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; IO
     (Tensor
        (Or (Gradient RequiresGradient) gradient gradient')
        (Unify (Layout LayoutType) layout layout')
        (Unify (Device (DeviceType Nat)) device device')
        (Unify (DataType DType) dataType dataType')
        shape'')
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.mul_tt</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679666910"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient' layout' device' dataType' shape'
</span><a href="#local-6989586621679666909"><span class="hs-identifier hs-var">other</span></a></span><span>
</span><span id="line-1004"></span><span>
</span><span id="line-1005"></span><span class="hs-comment">-- Multiplies each element of the input 'input' with the scalar 'other' and returns a new resulting tensor:</span><span>
</span><span id="line-1006"></span><span class="hs-comment">-- \[</span><span>
</span><span id="line-1007"></span><span class="hs-comment">-- \mathrm{output}_i = \mathrm{input}_i \times \mathrm{other}.</span><span>
</span><span id="line-1008"></span><span class="hs-comment">-- \]</span><span>
</span><span id="line-1009"></span><span class="hs-comment">--</span><span>
</span><span id="line-1010"></span><span class="hs-comment">-- If 'input' is of the data type 'Float' or 'Double', 'other' should be a real number,</span><span>
</span><span id="line-1011"></span><span class="hs-comment">-- otherwise it should be an 'integer'.</span><span>
</span><span id="line-1012"></span><span class="hs-comment">-- See 'mul' for a version of this function where</span><span>
</span><span id="line-1013"></span><span class="hs-comment">-- the 'other' input is a tensor.</span><span>
</span><span id="line-1014"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#mulScalar"><span class="hs-identifier hs-type">mulScalar</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-1015"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679666906"><span class="annot"><a href="#local-6989586621679666906"><span class="hs-identifier hs-type">other</span></a></span></span><span> </span><span id="local-6989586621679666905"><span class="annot"><a href="#local-6989586621679666905"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679666904"><span class="annot"><a href="#local-6989586621679666904"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679666903"><span class="annot"><a href="#local-6989586621679666903"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679666902"><span class="annot"><a href="#local-6989586621679666902"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679666901"><span class="annot"><a href="#local-6989586621679666901"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-1016"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Scalar.html#Scalar"><span class="hs-identifier hs-type">Scalar</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666906"><span class="hs-identifier hs-type">other</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-1017"></span><span>  </span><span class="hs-comment">-- | tensor input</span><span>
</span><span id="line-1018"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666905"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666904"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666903"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666902"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666901"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1019"></span><span>  </span><span class="hs-comment">-- | scalar other input</span><span>
</span><span id="line-1020"></span><span>  </span><span class="annot"><a href="#local-6989586621679666906"><span class="hs-identifier hs-type">other</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1021"></span><span>  </span><span class="hs-comment">-- | tensor output</span><span>
</span><span id="line-1022"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666905"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666904"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666903"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666902"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666901"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-1023"></span><span id="local-6989586621679666900"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679666900"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span id="mulScalar"><span class="annot"><span class="annottext">mulScalar :: Tensor gradient layout device dataType shape
-&gt; other -&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#mulScalar"><span class="hs-operator hs-var hs-var">`mulScalar`</span></a></span></span><span> </span><span id="local-6989586621679666899"><span class="annot"><span class="annottext">other
</span><a href="#local-6989586621679666899"><span class="hs-identifier hs-var">other</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ForeignPtr Scalar -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; other
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr Scalar -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.mul_ts</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679666900"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">other
</span><a href="#local-6989586621679666899"><span class="hs-identifier hs-var">other</span></a></span><span>
</span><span id="line-1024"></span><span>
</span><span id="line-1025"></span><span class="hs-comment">-- | Computes the multivariate log-gamma function with dimension 'p' element-wise, given by</span><span>
</span><span id="line-1026"></span><span class="hs-comment">-- \[</span><span>
</span><span id="line-1027"></span><span class="hs-comment">-- \log(\Gamma_p(\mathrm{input})) = C + \sum_{i=1}^{p} \log \left(\Gamma\left(\mathrm{input} - \frac{i-1}{2}\right)\right)</span><span>
</span><span id="line-1028"></span><span class="hs-comment">-- \]</span><span>
</span><span id="line-1029"></span><span class="hs-comment">-- where \(C = \log(\pi) \times \frac{p(p-1)}{4}\) and \(\Gamma(\dot)\) is the gamma function.</span><span>
</span><span id="line-1030"></span><span class="hs-comment">--</span><span>
</span><span id="line-1031"></span><span class="hs-comment">-- All elements of the input tensor must be greater than \(\frac{p-1}{2}\).</span><span>
</span><span id="line-1032"></span><span class="hs-comment">-- Otherwise, the computation is halted and an exception is thrown.</span><span>
</span><span id="line-1033"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#mvlgamma"><span class="hs-identifier hs-type">mvlgamma</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-1034"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679666896"><span class="annot"><a href="#local-6989586621679666896"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679666895"><span class="annot"><a href="#local-6989586621679666895"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679666894"><span class="annot"><a href="#local-6989586621679666894"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679666893"><span class="annot"><a href="#local-6989586621679666893"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679666892"><span class="annot"><a href="#local-6989586621679666892"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-1035"></span><span>  </span><span class="hs-comment">-- | the number of dimensions 'p'</span><span>
</span><span id="line-1036"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1037"></span><span>  </span><span class="hs-comment">-- | the input tensor to compute the the multivariate log-gamma function for</span><span>
</span><span id="line-1038"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666896"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666895"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666894"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666893"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666892"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1039"></span><span>  </span><span class="hs-comment">-- | the output tensor</span><span>
</span><span id="line-1040"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666896"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666895"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666894"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666893"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666892"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-1041"></span><span id="mvlgamma"><span class="annot"><span class="annottext">mvlgamma :: Int
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#mvlgamma"><span class="hs-identifier hs-var hs-var">mvlgamma</span></a></span></span><span> </span><span id="local-6989586621679666891"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679666891"><span class="hs-identifier hs-var">p</span></a></span></span><span> </span><span id="local-6989586621679666890"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679666890"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; Int64 -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; Int
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; Int64 -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.mvlgamma_tl</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679666890"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679666891"><span class="hs-identifier hs-var">p</span></a></span><span>
</span><span id="line-1042"></span><span>
</span><span id="line-1043"></span><span class="hs-comment">-- | Returns a new tensor with the negative of the elements of 'input':</span><span>
</span><span id="line-1044"></span><span class="hs-comment">-- \[</span><span>
</span><span id="line-1045"></span><span class="hs-comment">-- \mathrm{output}_i = - \mathrm{input}_i.</span><span>
</span><span id="line-1046"></span><span class="hs-comment">-- \]</span><span>
</span><span id="line-1047"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#neg"><span class="hs-identifier hs-type">neg</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-1048"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679666887"><span class="annot"><a href="#local-6989586621679666887"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679666886"><span class="annot"><a href="#local-6989586621679666886"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679666885"><span class="annot"><a href="#local-6989586621679666885"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679666884"><span class="annot"><a href="#local-6989586621679666884"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679666883"><span class="annot"><a href="#local-6989586621679666883"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-1049"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-1050"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666887"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666886"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666885"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666884"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666883"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1051"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-1052"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666887"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666886"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666885"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666884"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666883"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-1053"></span><span id="neg"><span class="annot"><span class="annottext">neg :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#neg"><span class="hs-identifier hs-var hs-var">neg</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; (Tensor gradient layout device dataType shape
    -&gt; IO (Tensor gradient layout device dataType shape))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.neg_t</span></a></span><span>
</span><span id="line-1054"></span><span>
</span><span id="line-1055"></span><span class="hs-comment">-- | Computes the \(n\)-th derivative of the digamma function \(\psi\) on the 'input',</span><span>
</span><span id="line-1056"></span><span class="hs-comment">-- where \(n \ge 0\).</span><span>
</span><span id="line-1057"></span><span class="hs-comment">-- \(n\) is called the order of the polygamma function \(\psi^{(n)}\)</span><span>
</span><span id="line-1058"></span><span class="hs-comment">-- that is defined as:</span><span>
</span><span id="line-1059"></span><span class="hs-comment">-- \[</span><span>
</span><span id="line-1060"></span><span class="hs-comment">-- \psi^{(n)}(\mathrm{input}) = \frac{d^{(n)}}{d\mathrm{input}^{(n)}} \psi(\mathrm{input})</span><span>
</span><span id="line-1061"></span><span class="hs-comment">-- \]</span><span>
</span><span id="line-1062"></span><span class="hs-comment">-- where \(\psi(\mathrm{input}) = \log(\Gamma(\mathrm{input}))\).</span><span>
</span><span id="line-1063"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#polygamma"><span class="hs-identifier hs-type">polygamma</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-1064"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679666880"><span class="annot"><a href="#local-6989586621679666880"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679666879"><span class="annot"><a href="#local-6989586621679666879"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679666878"><span class="annot"><a href="#local-6989586621679666878"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679666877"><span class="annot"><a href="#local-6989586621679666877"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679666876"><span class="annot"><a href="#local-6989586621679666876"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-1065"></span><span>  </span><span class="hs-comment">-- | the order of the polygamma function</span><span>
</span><span id="line-1066"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1067"></span><span>  </span><span class="hs-comment">-- | the input tensor</span><span>
</span><span id="line-1068"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666880"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666879"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666878"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666877"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666876"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1069"></span><span>  </span><span class="hs-comment">-- | the output tensor</span><span>
</span><span id="line-1070"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666880"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666879"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666878"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666877"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666876"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-1071"></span><span id="polygamma"><span class="annot"><span class="annottext">polygamma :: Int
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#polygamma"><span class="hs-identifier hs-var hs-var">polygamma</span></a></span></span><span> </span><span id="local-6989586621679666875"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679666875"><span class="hs-identifier hs-var">n</span></a></span></span><span> </span><span id="local-6989586621679666874"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679666874"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(Int64 -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Int
-&gt; Tensor gradient layout device dataType shape
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast2</span></a></span><span> </span><span class="annot"><span class="annottext">Int64 -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.polygamma_lt</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679666875"><span class="hs-identifier hs-var">n</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679666874"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-1072"></span><span>
</span><span id="line-1073"></span><span class="hs-comment">-- | Takes the power of each element in the tensor 'input'</span><span>
</span><span id="line-1074"></span><span class="hs-comment">-- with the corresponding element in the tensor 'exponent' and</span><span>
</span><span id="line-1075"></span><span class="hs-comment">-- returns a tensor with the result.</span><span>
</span><span id="line-1076"></span><span class="hs-comment">--</span><span>
</span><span id="line-1077"></span><span class="hs-comment">-- Note that the 'exponent' and the 'input' must be tensors</span><span>
</span><span id="line-1078"></span><span class="hs-comment">-- with broadcastable shapes.</span><span>
</span><span id="line-1079"></span><span class="hs-comment">-- See 'powScalar' for a version that takes a scalar 'exponent' as argument</span><span>
</span><span id="line-1080"></span><span class="hs-comment">-- and 'powTensor' for a version where the 'input' is a scalar and the 'exponent' a tensor.</span><span>
</span><span id="line-1081"></span><span class="hs-comment">--</span><span>
</span><span id="line-1082"></span><span class="hs-comment">-- The following operation is applied:</span><span>
</span><span id="line-1083"></span><span class="hs-comment">-- \[</span><span>
</span><span id="line-1084"></span><span class="hs-comment">-- \mathrm{output}_i = \mathrm{input}_i^{\mathrm{exponent}_i}.</span><span>
</span><span id="line-1085"></span><span class="hs-comment">-- \]</span><span>
</span><span id="line-1086"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#pow"><span class="hs-identifier hs-type">pow</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-1087"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679666871"><span class="annot"><a href="#local-6989586621679666871"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679666870"><span class="annot"><a href="#local-6989586621679666870"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679666869"><span class="annot"><a href="#local-6989586621679666869"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679666868"><span class="annot"><a href="#local-6989586621679666868"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679666867"><span class="annot"><a href="#local-6989586621679666867"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679666866"><span class="annot"><a href="#local-6989586621679666866"><span class="hs-identifier hs-type">gradient'</span></a></span></span><span> </span><span id="local-6989586621679666865"><span class="annot"><a href="#local-6989586621679666865"><span class="hs-identifier hs-type">layout'</span></a></span></span><span> </span><span id="local-6989586621679666864"><span class="annot"><a href="#local-6989586621679666864"><span class="hs-identifier hs-type">device'</span></a></span></span><span> </span><span id="local-6989586621679666863"><span class="annot"><a href="#local-6989586621679666863"><span class="hs-identifier hs-type">dataType'</span></a></span></span><span> </span><span id="local-6989586621679666862"><span class="annot"><a href="#local-6989586621679666862"><span class="hs-identifier hs-type">shape'</span></a></span></span><span> </span><span id="local-6989586621679666861"><span class="annot"><a href="#local-6989586621679666861"><span class="hs-identifier hs-type">shape''</span></a></span></span><span> </span><span id="local-6989586621679666860"><span class="annot"><a href="#local-6989586621679666860"><span class="hs-identifier hs-type">m</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-1088"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier hs-type">MonadThrow</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666860"><span class="hs-identifier hs-type">m</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679666861"><span class="hs-identifier hs-type">shape''</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#BroadcastShapesF"><span class="hs-identifier hs-type">BroadcastShapesF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666867"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666862"><span class="hs-identifier hs-type">shape'</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Catch"><span class="hs-identifier hs-type">Catch</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666861"><span class="hs-identifier hs-type">shape''</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-1089"></span><span>  </span><span class="hs-comment">-- | tensor input</span><span>
</span><span id="line-1090"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666866"><span class="hs-identifier hs-type">gradient'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666865"><span class="hs-identifier hs-type">layout'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666864"><span class="hs-identifier hs-type">device'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666863"><span class="hs-identifier hs-type">dataType'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666862"><span class="hs-identifier hs-type">shape'</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1091"></span><span>  </span><span class="hs-comment">-- | tensor exponent</span><span>
</span><span id="line-1092"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666871"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666870"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666869"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666868"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666867"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1093"></span><span>  </span><span class="hs-comment">-- | tensor output</span><span>
</span><span id="line-1094"></span><span>  </span><span class="annot"><a href="#local-6989586621679666860"><span class="hs-identifier hs-type">m</span></a></span><span>
</span><span id="line-1095"></span><span>    </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-1096"></span><span>        </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679666871"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666866"><span class="hs-identifier hs-type">gradient'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-1097"></span><span>        </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679666870"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666865"><span class="hs-identifier hs-type">layout'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-1098"></span><span>        </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679666869"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666864"><span class="hs-identifier hs-type">device'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-1099"></span><span>        </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679666868"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666863"><span class="hs-identifier hs-type">dataType'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-1100"></span><span>        </span><span class="annot"><a href="#local-6989586621679666861"><span class="hs-identifier hs-type">shape''</span></a></span><span>
</span><span id="line-1101"></span><span>    </span><span class="hs-special">)</span><span>
</span><span id="line-1102"></span><span id="local-6989586621679666859"><span class="annot"><span class="annottext">Tensor gradient' layout' device' dataType' shape'
</span><a href="#local-6989586621679666859"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span id="pow"><span class="annot"><span class="annottext">pow :: Tensor gradient' layout' device' dataType' shape'
-&gt; Tensor gradient layout device dataType shape
-&gt; m (Tensor
        (gradient &lt;|&gt; gradient')
        (layout &lt;+&gt; layout')
        (device &lt;+&gt; device')
        (dataType &lt;+&gt; dataType')
        shape'')
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#pow"><span class="hs-operator hs-var hs-var">`pow`</span></a></span></span><span> </span><span id="local-6989586621679666858"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679666858"><span class="hs-identifier hs-var">exponent'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO
  (Tensor
     (Or (Gradient RequiresGradient) gradient gradient')
     (Unify (Layout LayoutType) layout layout')
     (Unify (Device (DeviceType Nat)) device device')
     (Unify (DataType DType) dataType dataType')
     shape'')
-&gt; m (Tensor
        (Or (Gradient RequiresGradient) gradient gradient')
        (Unify (Layout LayoutType) layout layout')
        (Unify (Device (DeviceType Nat)) device device')
        (Unify (DataType DType) dataType dataType')
        shape'')
forall a (m :: * -&gt; *). MonadThrow m =&gt; IO a -&gt; m a
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">unsafeThrowableIO</span></a></span><span> </span><span class="annot"><span class="annottext">(IO
   (Tensor
      (Or (Gradient RequiresGradient) gradient gradient')
      (Unify (Layout LayoutType) layout layout')
      (Unify (Device (DeviceType Nat)) device device')
      (Unify (DataType DType) dataType dataType')
      shape'')
 -&gt; m (Tensor
         (Or (Gradient RequiresGradient) gradient gradient')
         (Unify (Layout LayoutType) layout layout')
         (Unify (Device (DeviceType Nat)) device device')
         (Unify (DataType DType) dataType dataType')
         shape''))
-&gt; IO
     (Tensor
        (Or (Gradient RequiresGradient) gradient gradient')
        (Unify (Layout LayoutType) layout layout')
        (Unify (Device (DeviceType Nat)) device device')
        (Unify (DataType DType) dataType dataType')
        shape'')
-&gt; m (Tensor
        (Or (Gradient RequiresGradient) gradient gradient')
        (Unify (Layout LayoutType) layout layout')
        (Unify (Device (DeviceType Nat)) device device')
        (Unify (DataType DType) dataType dataType')
        shape'')
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; Tensor gradient layout device dataType shape
-&gt; IO
     (Tensor
        (Or (Gradient RequiresGradient) gradient gradient')
        (Unify (Layout LayoutType) layout layout')
        (Unify (Device (DeviceType Nat)) device device')
        (Unify (DataType DType) dataType dataType')
        shape'')
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.pow_tt</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient' layout' device' dataType' shape'
</span><a href="#local-6989586621679666859"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679666858"><span class="hs-identifier hs-var">exponent'</span></a></span><span>
</span><span id="line-1103"></span><span>
</span><span id="line-1104"></span><span class="hs-comment">-- | Takes the power of each element in the tensor 'input' with the scalar 'exponent' and</span><span>
</span><span id="line-1105"></span><span class="hs-comment">-- returns a tensor with the result.</span><span>
</span><span id="line-1106"></span><span class="hs-comment">--</span><span>
</span><span id="line-1107"></span><span class="hs-comment">-- Note that the 'exponent' is a scalar.</span><span>
</span><span id="line-1108"></span><span class="hs-comment">-- See 'pow' for a version that takes a tensor 'exponent' as argument</span><span>
</span><span id="line-1109"></span><span class="hs-comment">-- and 'powTensor' for a version where the 'input' is a scalar and the 'exponent' a tensor.</span><span>
</span><span id="line-1110"></span><span class="hs-comment">--</span><span>
</span><span id="line-1111"></span><span class="hs-comment">-- The following operation is applied:</span><span>
</span><span id="line-1112"></span><span class="hs-comment">-- \[</span><span>
</span><span id="line-1113"></span><span class="hs-comment">-- \mathrm{output}_i = \mathrm{input}_i^{\mathrm{exponent}}.</span><span>
</span><span id="line-1114"></span><span class="hs-comment">-- \]</span><span>
</span><span id="line-1115"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#powScalar"><span class="hs-identifier hs-type">powScalar</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-1116"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679666855"><span class="annot"><a href="#local-6989586621679666855"><span class="hs-identifier hs-type">exponent</span></a></span></span><span> </span><span id="local-6989586621679666854"><span class="annot"><a href="#local-6989586621679666854"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679666853"><span class="annot"><a href="#local-6989586621679666853"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679666852"><span class="annot"><a href="#local-6989586621679666852"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679666851"><span class="annot"><a href="#local-6989586621679666851"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679666850"><span class="annot"><a href="#local-6989586621679666850"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-1117"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Scalar.html#Scalar"><span class="hs-identifier hs-type">Scalar</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666855"><span class="hs-identifier hs-type">exponent</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-1118"></span><span>  </span><span class="hs-comment">-- | tensor input</span><span>
</span><span id="line-1119"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666854"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666853"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666852"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666851"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666850"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1120"></span><span>  </span><span class="hs-comment">-- | scalar exponent</span><span>
</span><span id="line-1121"></span><span>  </span><span class="annot"><a href="#local-6989586621679666855"><span class="hs-identifier hs-type">exponent</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1122"></span><span>  </span><span class="hs-comment">-- | tensor output</span><span>
</span><span id="line-1123"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666854"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666853"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666852"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666851"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666850"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-1124"></span><span id="local-6989586621679666849"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679666849"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span id="powScalar"><span class="annot"><span class="annottext">powScalar :: Tensor gradient layout device dataType shape
-&gt; exponent -&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#powScalar"><span class="hs-operator hs-var hs-var">`powScalar`</span></a></span></span><span> </span><span id="local-6989586621679666848"><span class="annot"><span class="annottext">exponent
</span><a href="#local-6989586621679666848"><span class="hs-identifier hs-var">exponent'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ForeignPtr Scalar -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; exponent
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr Scalar -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.pow_ts</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679666849"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">exponent
</span><a href="#local-6989586621679666848"><span class="hs-identifier hs-var">exponent'</span></a></span><span>
</span><span id="line-1125"></span><span>
</span><span id="line-1126"></span><span class="hs-comment">-- | Takes the power of the scalar 'input' with each element in the tensor 'exponent' and</span><span>
</span><span id="line-1127"></span><span class="hs-comment">-- returns a tensor with the result.</span><span>
</span><span id="line-1128"></span><span class="hs-comment">--</span><span>
</span><span id="line-1129"></span><span class="hs-comment">-- Note that the 'exponent' is a tensor while the 'input' is a scalar.</span><span>
</span><span id="line-1130"></span><span class="hs-comment">-- See 'pow' for a version that takes a tensor 'input' as argument</span><span>
</span><span id="line-1131"></span><span class="hs-comment">-- and 'powScalar' for a version where the 'input' is a tensor and the 'exponent' a scalar.</span><span>
</span><span id="line-1132"></span><span class="hs-comment">--</span><span>
</span><span id="line-1133"></span><span class="hs-comment">-- The following operation is applied:</span><span>
</span><span id="line-1134"></span><span class="hs-comment">-- \[</span><span>
</span><span id="line-1135"></span><span class="hs-comment">-- \mathrm{output}_i = \mathrm{input}^{\mathrm{exponent}_i}.</span><span>
</span><span id="line-1136"></span><span class="hs-comment">-- \]</span><span>
</span><span id="line-1137"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#powTensor"><span class="hs-identifier hs-type">powTensor</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-1138"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679666845"><span class="annot"><a href="#local-6989586621679666845"><span class="hs-identifier hs-type">input</span></a></span></span><span> </span><span id="local-6989586621679666844"><span class="annot"><a href="#local-6989586621679666844"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679666843"><span class="annot"><a href="#local-6989586621679666843"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679666842"><span class="annot"><a href="#local-6989586621679666842"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679666841"><span class="annot"><a href="#local-6989586621679666841"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679666840"><span class="annot"><a href="#local-6989586621679666840"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-1139"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Scalar.html#Scalar"><span class="hs-identifier hs-type">Scalar</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666845"><span class="hs-identifier hs-type">input</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-1140"></span><span>  </span><span class="hs-comment">-- | scalar input</span><span>
</span><span id="line-1141"></span><span>  </span><span class="annot"><a href="#local-6989586621679666845"><span class="hs-identifier hs-type">input</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1142"></span><span>  </span><span class="hs-comment">-- | tensor exponent</span><span>
</span><span id="line-1143"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666844"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666843"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666842"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666841"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666840"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1144"></span><span>  </span><span class="hs-comment">-- | tensor output</span><span>
</span><span id="line-1145"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666844"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666843"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666842"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666841"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666840"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-1146"></span><span id="local-6989586621679666839"><span class="annot"><span class="annottext">input
</span><a href="#local-6989586621679666839"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span id="powTensor"><span class="annot"><span class="annottext">powTensor :: input
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#powTensor"><span class="hs-operator hs-var hs-var">`powTensor`</span></a></span></span><span> </span><span id="local-6989586621679666838"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679666838"><span class="hs-identifier hs-var">exponent'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Scalar -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; input
-&gt; Tensor gradient layout device dataType shape
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Scalar -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.pow_st</span></a></span><span> </span><span class="annot"><span class="annottext">input
</span><a href="#local-6989586621679666839"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679666838"><span class="hs-identifier hs-var">exponent'</span></a></span><span>
</span><span id="line-1147"></span><span>
</span><span id="line-1148"></span><span class="hs-comment">-- | Returns a new tensor with each of the elements of 'input'</span><span>
</span><span id="line-1149"></span><span class="hs-comment">-- converted from angles in radians to degrees.</span><span>
</span><span id="line-1150"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#rad2deg"><span class="hs-identifier hs-type">rad2deg</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-1151"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679666835"><span class="annot"><a href="#local-6989586621679666835"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679666834"><span class="annot"><a href="#local-6989586621679666834"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679666833"><span class="annot"><a href="#local-6989586621679666833"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679666832"><span class="annot"><a href="#local-6989586621679666832"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679666831"><span class="annot"><a href="#local-6989586621679666831"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-1152"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-1153"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666835"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666834"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666833"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666832"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666831"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1154"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-1155"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666835"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666834"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666833"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666832"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666831"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-1156"></span><span id="rad2deg"><span class="annot"><span class="annottext">rad2deg :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#rad2deg"><span class="hs-identifier hs-var hs-var">rad2deg</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; (Tensor gradient layout device dataType shape
    -&gt; IO (Tensor gradient layout device dataType shape))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.rad2deg_t</span></a></span><span>
</span><span id="line-1157"></span><span>
</span><span id="line-1158"></span><span class="hs-comment">-- | Returns a new tensor with the reciprocal of the elements of 'input':</span><span>
</span><span id="line-1159"></span><span class="hs-comment">-- \[</span><span>
</span><span id="line-1160"></span><span class="hs-comment">-- \mathrm{output}_i = \frac{1}{\mathrm{input}_i}</span><span>
</span><span id="line-1161"></span><span class="hs-comment">-- \]</span><span>
</span><span id="line-1162"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#reciprocal"><span class="hs-identifier hs-type">reciprocal</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-1163"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679666828"><span class="annot"><a href="#local-6989586621679666828"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679666827"><span class="annot"><a href="#local-6989586621679666827"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679666826"><span class="annot"><a href="#local-6989586621679666826"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679666825"><span class="annot"><a href="#local-6989586621679666825"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679666824"><span class="annot"><a href="#local-6989586621679666824"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-1164"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-1165"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666828"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666827"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666826"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666825"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666824"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1166"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-1167"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666828"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666827"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666826"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666825"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666824"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-1168"></span><span id="reciprocal"><span class="annot"><span class="annottext">reciprocal :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#reciprocal"><span class="hs-identifier hs-var hs-var">reciprocal</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; (Tensor gradient layout device dataType shape
    -&gt; IO (Tensor gradient layout device dataType shape))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.reciprocal_t</span></a></span><span>
</span><span id="line-1169"></span><span>
</span><span id="line-1170"></span><span class="hs-comment">-- | Computes the element-wise remainder of division.</span><span>
</span><span id="line-1171"></span><span class="hs-comment">--</span><span>
</span><span id="line-1172"></span><span class="hs-comment">-- The dividend and divisor may contain integer and floating point numbers.</span><span>
</span><span id="line-1173"></span><span class="hs-comment">-- The remainder has the same sign as the divisor other.</span><span>
</span><span id="line-1174"></span><span class="hs-comment">--</span><span>
</span><span id="line-1175"></span><span class="hs-comment">-- When other is a tensor, the shapes of input and other must be broadcastable.</span><span>
</span><span id="line-1176"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#remainder"><span class="hs-identifier hs-type">remainder</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-1177"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679666821"><span class="annot"><a href="#local-6989586621679666821"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679666820"><span class="annot"><a href="#local-6989586621679666820"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679666819"><span class="annot"><a href="#local-6989586621679666819"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679666818"><span class="annot"><a href="#local-6989586621679666818"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679666817"><span class="annot"><a href="#local-6989586621679666817"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679666816"><span class="annot"><a href="#local-6989586621679666816"><span class="hs-identifier hs-type">gradient'</span></a></span></span><span> </span><span id="local-6989586621679666815"><span class="annot"><a href="#local-6989586621679666815"><span class="hs-identifier hs-type">layout'</span></a></span></span><span> </span><span id="local-6989586621679666814"><span class="annot"><a href="#local-6989586621679666814"><span class="hs-identifier hs-type">device'</span></a></span></span><span> </span><span id="local-6989586621679666813"><span class="annot"><a href="#local-6989586621679666813"><span class="hs-identifier hs-type">dataType'</span></a></span></span><span> </span><span id="local-6989586621679666812"><span class="annot"><a href="#local-6989586621679666812"><span class="hs-identifier hs-type">shape'</span></a></span></span><span> </span><span id="local-6989586621679666811"><span class="annot"><a href="#local-6989586621679666811"><span class="hs-identifier hs-type">shape''</span></a></span></span><span> </span><span id="local-6989586621679666810"><span class="annot"><a href="#local-6989586621679666810"><span class="hs-identifier hs-type">m</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-1178"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier hs-type">MonadThrow</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666810"><span class="hs-identifier hs-type">m</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679666811"><span class="hs-identifier hs-type">shape''</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#BroadcastShapesF"><span class="hs-identifier hs-type">BroadcastShapesF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666817"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666812"><span class="hs-identifier hs-type">shape'</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Catch"><span class="hs-identifier hs-type">Catch</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666811"><span class="hs-identifier hs-type">shape''</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-1179"></span><span>  </span><span class="hs-comment">-- | dividend</span><span>
</span><span id="line-1180"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666821"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666820"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666819"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666818"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666817"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1181"></span><span>  </span><span class="hs-comment">-- | divisor</span><span>
</span><span id="line-1182"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666816"><span class="hs-identifier hs-type">gradient'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666815"><span class="hs-identifier hs-type">layout'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666814"><span class="hs-identifier hs-type">device'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666813"><span class="hs-identifier hs-type">dataType'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666812"><span class="hs-identifier hs-type">shape'</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1183"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-1184"></span><span>  </span><span class="annot"><a href="#local-6989586621679666810"><span class="hs-identifier hs-type">m</span></a></span><span>
</span><span id="line-1185"></span><span>    </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-1186"></span><span>        </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679666821"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666816"><span class="hs-identifier hs-type">gradient'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-1187"></span><span>        </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679666820"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666815"><span class="hs-identifier hs-type">layout'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-1188"></span><span>        </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679666819"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666814"><span class="hs-identifier hs-type">device'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-1189"></span><span>        </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679666818"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666813"><span class="hs-identifier hs-type">dataType'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-1190"></span><span>        </span><span class="annot"><a href="#local-6989586621679666811"><span class="hs-identifier hs-type">shape''</span></a></span><span>
</span><span id="line-1191"></span><span>    </span><span class="hs-special">)</span><span>
</span><span id="line-1192"></span><span id="local-6989586621679666809"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679666809"><span class="hs-identifier hs-var">dividend</span></a></span></span><span> </span><span id="remainder"><span class="annot"><span class="annottext">remainder :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; m (Tensor
        (gradient &lt;|&gt; gradient')
        (layout &lt;+&gt; layout')
        (device &lt;+&gt; device')
        (dataType &lt;+&gt; dataType')
        shape'')
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#remainder"><span class="hs-operator hs-var hs-var">`remainder`</span></a></span></span><span> </span><span id="local-6989586621679666808"><span class="annot"><span class="annottext">Tensor gradient' layout' device' dataType' shape'
</span><a href="#local-6989586621679666808"><span class="hs-identifier hs-var">divisor</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO
  (Tensor
     (Or (Gradient RequiresGradient) gradient gradient')
     (Unify (Layout LayoutType) layout layout')
     (Unify (Device (DeviceType Nat)) device device')
     (Unify (DataType DType) dataType dataType')
     shape'')
-&gt; m (Tensor
        (Or (Gradient RequiresGradient) gradient gradient')
        (Unify (Layout LayoutType) layout layout')
        (Unify (Device (DeviceType Nat)) device device')
        (Unify (DataType DType) dataType dataType')
        shape'')
forall a (m :: * -&gt; *). MonadThrow m =&gt; IO a -&gt; m a
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">unsafeThrowableIO</span></a></span><span> </span><span class="annot"><span class="annottext">(IO
   (Tensor
      (Or (Gradient RequiresGradient) gradient gradient')
      (Unify (Layout LayoutType) layout layout')
      (Unify (Device (DeviceType Nat)) device device')
      (Unify (DataType DType) dataType dataType')
      shape'')
 -&gt; m (Tensor
         (Or (Gradient RequiresGradient) gradient gradient')
         (Unify (Layout LayoutType) layout layout')
         (Unify (Device (DeviceType Nat)) device device')
         (Unify (DataType DType) dataType dataType')
         shape''))
-&gt; IO
     (Tensor
        (Or (Gradient RequiresGradient) gradient gradient')
        (Unify (Layout LayoutType) layout layout')
        (Unify (Device (DeviceType Nat)) device device')
        (Unify (DataType DType) dataType dataType')
        shape'')
-&gt; m (Tensor
        (Or (Gradient RequiresGradient) gradient gradient')
        (Unify (Layout LayoutType) layout layout')
        (Unify (Device (DeviceType Nat)) device device')
        (Unify (DataType DType) dataType dataType')
        shape'')
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; IO
     (Tensor
        (Or (Gradient RequiresGradient) gradient gradient')
        (Unify (Layout LayoutType) layout layout')
        (Unify (Device (DeviceType Nat)) device device')
        (Unify (DataType DType) dataType dataType')
        shape'')
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.remainder_tt</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679666809"><span class="hs-identifier hs-var">dividend</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient' layout' device' dataType' shape'
</span><a href="#local-6989586621679666808"><span class="hs-identifier hs-var">divisor</span></a></span><span>
</span><span id="line-1193"></span><span>
</span><span id="line-1194"></span><span class="hs-comment">-- | Returns a new tensor with each of the elements of 'input' rounded to the closest integer.</span><span>
</span><span id="line-1195"></span><span class="hs-comment">-- Note that the data type is unchanged.</span><span>
</span><span id="line-1196"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#round"><span class="hs-identifier hs-type">round</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-1197"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679666805"><span class="annot"><a href="#local-6989586621679666805"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679666804"><span class="annot"><a href="#local-6989586621679666804"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679666803"><span class="annot"><a href="#local-6989586621679666803"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679666802"><span class="annot"><a href="#local-6989586621679666802"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679666801"><span class="annot"><a href="#local-6989586621679666801"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-1198"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-1199"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666805"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666804"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666803"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666802"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666801"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1200"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-1201"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666805"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666804"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666803"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666802"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666801"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-1202"></span><span id="round"><span class="annot"><span class="annottext">round :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#round"><span class="hs-identifier hs-var hs-var">round</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; (Tensor gradient layout device dataType shape
    -&gt; IO (Tensor gradient layout device dataType shape))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.round_t</span></a></span><span>
</span><span id="line-1203"></span><span>
</span><span id="line-1204"></span><span class="hs-comment">-- | Returns a new tensor with the reciprocal of the square-root of</span><span>
</span><span id="line-1205"></span><span class="hs-comment">-- each of the elements of 'input':</span><span>
</span><span id="line-1206"></span><span class="hs-comment">-- \[</span><span>
</span><span id="line-1207"></span><span class="hs-comment">-- \mathrm{output}_i = \frac{1}{\sqrt{\mathrm{input}_i}}.</span><span>
</span><span id="line-1208"></span><span class="hs-comment">-- \]</span><span>
</span><span id="line-1209"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#rsqrt"><span class="hs-identifier hs-type">rsqrt</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-1210"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679666798"><span class="annot"><a href="#local-6989586621679666798"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679666797"><span class="annot"><a href="#local-6989586621679666797"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679666796"><span class="annot"><a href="#local-6989586621679666796"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679666795"><span class="annot"><a href="#local-6989586621679666795"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679666794"><span class="annot"><a href="#local-6989586621679666794"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-1211"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-1212"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666798"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666797"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666796"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666795"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666794"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1213"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-1214"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666798"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666797"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666796"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666795"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666794"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-1215"></span><span id="rsqrt"><span class="annot"><span class="annottext">rsqrt :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#rsqrt"><span class="hs-identifier hs-var hs-var">rsqrt</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; (Tensor gradient layout device dataType shape
    -&gt; IO (Tensor gradient layout device dataType shape))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.rsqrt_t</span></a></span><span>
</span><span id="line-1216"></span><span>
</span><span id="line-1217"></span><span class="hs-comment">-- | Returns a new tensor with the sigmoid of the elements of 'input':</span><span>
</span><span id="line-1218"></span><span class="hs-comment">-- \[</span><span>
</span><span id="line-1219"></span><span class="hs-comment">-- \mathrm{output}_i = \frac{1}{1 + \exp \left(-\mathrm{input}_i\right)}</span><span>
</span><span id="line-1220"></span><span class="hs-comment">-- \]</span><span>
</span><span id="line-1221"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#sigmoid"><span class="hs-identifier hs-type">sigmoid</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-1222"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679666791"><span class="annot"><a href="#local-6989586621679666791"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679666790"><span class="annot"><a href="#local-6989586621679666790"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679666789"><span class="annot"><a href="#local-6989586621679666789"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679666788"><span class="annot"><a href="#local-6989586621679666788"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679666787"><span class="annot"><a href="#local-6989586621679666787"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-1223"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-1224"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666791"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666790"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666789"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666788"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666787"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1225"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-1226"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666791"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666790"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666789"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666788"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666787"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-1227"></span><span id="sigmoid"><span class="annot"><span class="annottext">sigmoid :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#sigmoid"><span class="hs-identifier hs-var hs-var">sigmoid</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; (Tensor gradient layout device dataType shape
    -&gt; IO (Tensor gradient layout device dataType shape))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.sigmoid_t</span></a></span><span>
</span><span id="line-1228"></span><span>
</span><span id="line-1229"></span><span class="hs-comment">-- | Returns a new tensor with the signs of the elements of 'input':</span><span>
</span><span id="line-1230"></span><span class="hs-comment">-- \[</span><span>
</span><span id="line-1231"></span><span class="hs-comment">-- \mathrm{output}_i = \begin{cases}</span><span>
</span><span id="line-1232"></span><span class="hs-comment">--   -1 &amp; \text{if } \mathrm{input}_i &lt; 0 \\</span><span>
</span><span id="line-1233"></span><span class="hs-comment">--   0  &amp; \text{if } \mathrm{input}_i = 0 \\</span><span>
</span><span id="line-1234"></span><span class="hs-comment">--   1  &amp; \text{if } \mathrm{input}_i &gt; 0.</span><span>
</span><span id="line-1235"></span><span class="hs-comment">-- \end{cases}</span><span>
</span><span id="line-1236"></span><span class="hs-comment">-- \]</span><span>
</span><span id="line-1237"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#sign"><span class="hs-identifier hs-type">sign</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-1238"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679666784"><span class="annot"><a href="#local-6989586621679666784"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679666783"><span class="annot"><a href="#local-6989586621679666783"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679666782"><span class="annot"><a href="#local-6989586621679666782"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679666781"><span class="annot"><a href="#local-6989586621679666781"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679666780"><span class="annot"><a href="#local-6989586621679666780"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-1239"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-1240"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666784"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666783"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666782"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666781"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666780"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1241"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-1242"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666784"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666783"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666782"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666781"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666780"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-1243"></span><span id="sign"><span class="annot"><span class="annottext">sign :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#sign"><span class="hs-identifier hs-var hs-var">sign</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; (Tensor gradient layout device dataType shape
    -&gt; IO (Tensor gradient layout device dataType shape))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.sign_t</span></a></span><span>
</span><span id="line-1244"></span><span>
</span><span id="line-1245"></span><span class="hs-comment">-- | Returns a new tensor with the sine of the elements of 'input':</span><span>
</span><span id="line-1246"></span><span class="hs-comment">-- \[</span><span>
</span><span id="line-1247"></span><span class="hs-comment">-- \mathrm{output}_i = \sin \left(\mathrm{input}_i\right).</span><span>
</span><span id="line-1248"></span><span class="hs-comment">-- \]</span><span>
</span><span id="line-1249"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#sin"><span class="hs-identifier hs-type">sin</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-1250"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679666777"><span class="annot"><a href="#local-6989586621679666777"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679666776"><span class="annot"><a href="#local-6989586621679666776"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679666775"><span class="annot"><a href="#local-6989586621679666775"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679666774"><span class="annot"><a href="#local-6989586621679666774"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679666773"><span class="annot"><a href="#local-6989586621679666773"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-1251"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-1252"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666777"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666776"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666775"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666774"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666773"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1253"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-1254"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666777"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666776"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666775"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666774"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666773"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-1255"></span><span id="sin"><span class="annot"><span class="annottext">sin :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#sin"><span class="hs-identifier hs-var hs-var">sin</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; (Tensor gradient layout device dataType shape
    -&gt; IO (Tensor gradient layout device dataType shape))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.sin_t</span></a></span><span>
</span><span id="line-1256"></span><span>
</span><span id="line-1257"></span><span class="hs-comment">-- | Returns a new tensor with the hyperbolic sine of the elements of 'input':</span><span>
</span><span id="line-1258"></span><span class="hs-comment">-- \[</span><span>
</span><span id="line-1259"></span><span class="hs-comment">-- \mathrm{output}_i = \sinh \left(\mathrm{input}_i\right).</span><span>
</span><span id="line-1260"></span><span class="hs-comment">-- \]</span><span>
</span><span id="line-1261"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#sinh"><span class="hs-identifier hs-type">sinh</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-1262"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679666770"><span class="annot"><a href="#local-6989586621679666770"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679666769"><span class="annot"><a href="#local-6989586621679666769"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679666768"><span class="annot"><a href="#local-6989586621679666768"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679666767"><span class="annot"><a href="#local-6989586621679666767"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679666766"><span class="annot"><a href="#local-6989586621679666766"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-1263"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-1264"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666770"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666769"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666768"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666767"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666766"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1265"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-1266"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666770"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666769"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666768"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666767"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666766"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-1267"></span><span id="sinh"><span class="annot"><span class="annottext">sinh :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#sinh"><span class="hs-identifier hs-var hs-var">sinh</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; (Tensor gradient layout device dataType shape
    -&gt; IO (Tensor gradient layout device dataType shape))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.sinh_t</span></a></span><span>
</span><span id="line-1268"></span><span>
</span><span id="line-1269"></span><span class="hs-comment">-- | Element-wise subtraction of one tensor from another:</span><span>
</span><span id="line-1270"></span><span class="hs-comment">-- \[</span><span>
</span><span id="line-1271"></span><span class="hs-comment">-- \mathrm{output}_i = \mathrm{input}_i - \mathrm{other}_i.</span><span>
</span><span id="line-1272"></span><span class="hs-comment">-- \]</span><span>
</span><span id="line-1273"></span><span class="hs-comment">-- The result is returned as a new tensor.</span><span>
</span><span id="line-1274"></span><span class="hs-comment">--</span><span>
</span><span id="line-1275"></span><span class="hs-comment">-- The shape of 'other' must be broadcastable with the shape of 'input'.</span><span>
</span><span id="line-1276"></span><span class="hs-comment">-- See 'subScalar' for a version of this function where</span><span>
</span><span id="line-1277"></span><span class="hs-comment">-- the 'other' input is a scalar.</span><span>
</span><span id="line-1278"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#sub"><span class="hs-identifier hs-type">sub</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-1279"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679666763"><span class="annot"><a href="#local-6989586621679666763"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679666762"><span class="annot"><a href="#local-6989586621679666762"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679666761"><span class="annot"><a href="#local-6989586621679666761"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679666760"><span class="annot"><a href="#local-6989586621679666760"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679666759"><span class="annot"><a href="#local-6989586621679666759"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679666758"><span class="annot"><a href="#local-6989586621679666758"><span class="hs-identifier hs-type">gradient'</span></a></span></span><span> </span><span id="local-6989586621679666757"><span class="annot"><a href="#local-6989586621679666757"><span class="hs-identifier hs-type">layout'</span></a></span></span><span> </span><span id="local-6989586621679666756"><span class="annot"><a href="#local-6989586621679666756"><span class="hs-identifier hs-type">device'</span></a></span></span><span> </span><span id="local-6989586621679666755"><span class="annot"><a href="#local-6989586621679666755"><span class="hs-identifier hs-type">dataType'</span></a></span></span><span> </span><span id="local-6989586621679666754"><span class="annot"><a href="#local-6989586621679666754"><span class="hs-identifier hs-type">shape'</span></a></span></span><span> </span><span id="local-6989586621679666753"><span class="annot"><a href="#local-6989586621679666753"><span class="hs-identifier hs-type">shape''</span></a></span></span><span> </span><span id="local-6989586621679666752"><span class="annot"><a href="#local-6989586621679666752"><span class="hs-identifier hs-type">m</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-1280"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier hs-type">MonadThrow</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666752"><span class="hs-identifier hs-type">m</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679666753"><span class="hs-identifier hs-type">shape''</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#BroadcastShapesF"><span class="hs-identifier hs-type">BroadcastShapesF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666759"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666754"><span class="hs-identifier hs-type">shape'</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Catch"><span class="hs-identifier hs-type">Catch</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666753"><span class="hs-identifier hs-type">shape''</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-1281"></span><span>  </span><span class="hs-comment">-- | input tensor</span><span>
</span><span id="line-1282"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666763"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666762"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666761"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666760"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666759"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1283"></span><span>  </span><span class="hs-comment">-- | other tensor</span><span>
</span><span id="line-1284"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666758"><span class="hs-identifier hs-type">gradient'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666757"><span class="hs-identifier hs-type">layout'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666756"><span class="hs-identifier hs-type">device'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666755"><span class="hs-identifier hs-type">dataType'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666754"><span class="hs-identifier hs-type">shape'</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1285"></span><span>  </span><span class="hs-comment">-- | output tensor</span><span>
</span><span id="line-1286"></span><span>  </span><span class="annot"><a href="#local-6989586621679666752"><span class="hs-identifier hs-type">m</span></a></span><span>
</span><span id="line-1287"></span><span>    </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-1288"></span><span>        </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679666763"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666763"><span class="hs-identifier hs-type">gradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-1289"></span><span>        </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679666762"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666757"><span class="hs-identifier hs-type">layout'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-1290"></span><span>        </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679666761"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666756"><span class="hs-identifier hs-type">device'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-1291"></span><span>        </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679666760"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666755"><span class="hs-identifier hs-type">dataType'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-1292"></span><span>        </span><span class="annot"><a href="#local-6989586621679666753"><span class="hs-identifier hs-type">shape''</span></a></span><span>
</span><span id="line-1293"></span><span>    </span><span class="hs-special">)</span><span>
</span><span id="line-1294"></span><span id="local-6989586621679666751"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679666751"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span id="sub"><span class="annot"><span class="annottext">sub :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; m (Tensor
        (gradient &lt;|&gt; gradient)
        (layout &lt;+&gt; layout')
        (device &lt;+&gt; device')
        (dataType &lt;+&gt; dataType')
        shape'')
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#sub"><span class="hs-operator hs-var hs-var">`sub`</span></a></span></span><span> </span><span id="local-6989586621679666750"><span class="annot"><span class="annottext">Tensor gradient' layout' device' dataType' shape'
</span><a href="#local-6989586621679666750"><span class="hs-identifier hs-var">other</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO
  (Tensor
     gradient
     (Unify (Layout LayoutType) layout layout')
     (Unify (Device (DeviceType Nat)) device device')
     (Unify (DataType DType) dataType dataType')
     shape'')
-&gt; m (Tensor
        gradient
        (Unify (Layout LayoutType) layout layout')
        (Unify (Device (DeviceType Nat)) device device')
        (Unify (DataType DType) dataType dataType')
        shape'')
forall a (m :: * -&gt; *). MonadThrow m =&gt; IO a -&gt; m a
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">unsafeThrowableIO</span></a></span><span> </span><span class="annot"><span class="annottext">(IO
   (Tensor
      gradient
      (Unify (Layout LayoutType) layout layout')
      (Unify (Device (DeviceType Nat)) device device')
      (Unify (DataType DType) dataType dataType')
      shape'')
 -&gt; m (Tensor
         gradient
         (Unify (Layout LayoutType) layout layout')
         (Unify (Device (DeviceType Nat)) device device')
         (Unify (DataType DType) dataType dataType')
         shape''))
-&gt; IO
     (Tensor
        gradient
        (Unify (Layout LayoutType) layout layout')
        (Unify (Device (DeviceType Nat)) device device')
        (Unify (DataType DType) dataType dataType')
        shape'')
-&gt; m (Tensor
        gradient
        (Unify (Layout LayoutType) layout layout')
        (Unify (Device (DeviceType Nat)) device device')
        (Unify (DataType DType) dataType dataType')
        shape'')
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; IO
     (Tensor
        gradient
        (Unify (Layout LayoutType) layout layout')
        (Unify (Device (DeviceType Nat)) device device')
        (Unify (DataType DType) dataType dataType')
        shape'')
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.sub_tt</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679666751"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient' layout' device' dataType' shape'
</span><a href="#local-6989586621679666750"><span class="hs-identifier hs-var">other</span></a></span><span>
</span><span id="line-1295"></span><span>
</span><span id="line-1296"></span><span class="hs-comment">-- | Subtracts a scalar 'other' from a tensor 'input':</span><span>
</span><span id="line-1297"></span><span class="hs-comment">-- \[</span><span>
</span><span id="line-1298"></span><span class="hs-comment">-- \mathrm{output}_i = \mathrm{input}_i - \mathrm{other}.</span><span>
</span><span id="line-1299"></span><span class="hs-comment">-- \]</span><span>
</span><span id="line-1300"></span><span class="hs-comment">-- The result is returned as a new tensor.</span><span>
</span><span id="line-1301"></span><span class="hs-comment">-- See 'sub' for a version of this function where</span><span>
</span><span id="line-1302"></span><span class="hs-comment">-- the second argument is a tensor.</span><span>
</span><span id="line-1303"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#subScalar"><span class="hs-identifier hs-type">subScalar</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-1304"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679666747"><span class="annot"><a href="#local-6989586621679666747"><span class="hs-identifier hs-type">other</span></a></span></span><span> </span><span id="local-6989586621679666746"><span class="annot"><a href="#local-6989586621679666746"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679666745"><span class="annot"><a href="#local-6989586621679666745"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679666744"><span class="annot"><a href="#local-6989586621679666744"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679666743"><span class="annot"><a href="#local-6989586621679666743"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679666742"><span class="annot"><a href="#local-6989586621679666742"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-1305"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Scalar.html#Scalar"><span class="hs-identifier hs-type">Scalar</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666747"><span class="hs-identifier hs-type">other</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-1306"></span><span>  </span><span class="hs-comment">-- | input tensor</span><span>
</span><span id="line-1307"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666746"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666745"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666744"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666743"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666742"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1308"></span><span>  </span><span class="hs-comment">-- | input scalar</span><span>
</span><span id="line-1309"></span><span>  </span><span class="annot"><a href="#local-6989586621679666747"><span class="hs-identifier hs-type">other</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1310"></span><span>  </span><span class="hs-comment">-- | output tensor</span><span>
</span><span id="line-1311"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666746"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666745"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666744"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666743"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666742"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-1312"></span><span id="local-6989586621679666741"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679666741"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span id="subScalar"><span class="annot"><span class="annottext">subScalar :: Tensor gradient layout device dataType shape
-&gt; other -&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#subScalar"><span class="hs-operator hs-var hs-var">`subScalar`</span></a></span></span><span> </span><span id="local-6989586621679666740"><span class="annot"><span class="annottext">other
</span><a href="#local-6989586621679666740"><span class="hs-identifier hs-var">other</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ForeignPtr Scalar -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; other
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr Scalar -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.sub_ts</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679666741"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">other
</span><a href="#local-6989586621679666740"><span class="hs-identifier hs-var">other</span></a></span><span>
</span><span id="line-1313"></span><span>
</span><span id="line-1314"></span><span class="hs-comment">-- | Returns a new tensor with the square-root of the elements of 'input':</span><span>
</span><span id="line-1315"></span><span class="hs-comment">-- \[</span><span>
</span><span id="line-1316"></span><span class="hs-comment">-- \mathrm{output}_i = \sqrt{\mathrm{input}_i}.</span><span>
</span><span id="line-1317"></span><span class="hs-comment">-- \]</span><span>
</span><span id="line-1318"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#sqrt"><span class="hs-identifier hs-type">sqrt</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-1319"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679666737"><span class="annot"><a href="#local-6989586621679666737"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679666736"><span class="annot"><a href="#local-6989586621679666736"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679666735"><span class="annot"><a href="#local-6989586621679666735"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679666734"><span class="annot"><a href="#local-6989586621679666734"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679666733"><span class="annot"><a href="#local-6989586621679666733"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-1320"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-1321"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666737"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666736"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666735"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666734"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666733"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1322"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-1323"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666737"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666736"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666735"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666734"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666733"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-1324"></span><span id="sqrt"><span class="annot"><span class="annottext">sqrt :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#sqrt"><span class="hs-identifier hs-var hs-var">sqrt</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; (Tensor gradient layout device dataType shape
    -&gt; IO (Tensor gradient layout device dataType shape))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.sqrt_t</span></a></span><span>
</span><span id="line-1325"></span><span>
</span><span id="line-1326"></span><span class="hs-comment">-- | Returns a new tensor with the square of the elements of 'input':</span><span>
</span><span id="line-1327"></span><span class="hs-comment">-- \[</span><span>
</span><span id="line-1328"></span><span class="hs-comment">-- \mathrm{output}_i = \mathrm{input}_i^2.</span><span>
</span><span id="line-1329"></span><span class="hs-comment">-- \]</span><span>
</span><span id="line-1330"></span><span class="hs-comment">--</span><span>
</span><span id="line-1331"></span><span class="hs-comment">-- See 'pow', 'powScalar', or 'powTensor' for exponentiation with respect to arbitrary exponents.</span><span>
</span><span id="line-1332"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#square"><span class="hs-identifier hs-type">square</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-1333"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679666730"><span class="annot"><a href="#local-6989586621679666730"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679666729"><span class="annot"><a href="#local-6989586621679666729"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679666728"><span class="annot"><a href="#local-6989586621679666728"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679666727"><span class="annot"><a href="#local-6989586621679666727"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679666726"><span class="annot"><a href="#local-6989586621679666726"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-1334"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-1335"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666730"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666729"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666728"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666727"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666726"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1336"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-1337"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666730"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666729"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666728"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666727"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666726"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-1338"></span><span id="square"><span class="annot"><span class="annottext">square :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#square"><span class="hs-identifier hs-var hs-var">square</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; (Tensor gradient layout device dataType shape
    -&gt; IO (Tensor gradient layout device dataType shape))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.square_t</span></a></span><span>
</span><span id="line-1339"></span><span>
</span><span id="line-1340"></span><span class="hs-comment">-- | Returns a new tensor with the tangent of the elements of 'input':</span><span>
</span><span id="line-1341"></span><span class="hs-comment">-- \[</span><span>
</span><span id="line-1342"></span><span class="hs-comment">-- \mathrm{output}_i = \tan \left(\mathrm{input}_i\right).</span><span>
</span><span id="line-1343"></span><span class="hs-comment">-- \]</span><span>
</span><span id="line-1344"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#tan"><span class="hs-identifier hs-type">tan</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-1345"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679666723"><span class="annot"><a href="#local-6989586621679666723"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679666722"><span class="annot"><a href="#local-6989586621679666722"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679666721"><span class="annot"><a href="#local-6989586621679666721"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679666720"><span class="annot"><a href="#local-6989586621679666720"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679666719"><span class="annot"><a href="#local-6989586621679666719"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-1346"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-1347"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666723"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666722"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666721"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666720"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666719"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1348"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-1349"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666723"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666722"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666721"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666720"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666719"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-1350"></span><span id="tan"><span class="annot"><span class="annottext">tan :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#tan"><span class="hs-identifier hs-var hs-var">tan</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; (Tensor gradient layout device dataType shape
    -&gt; IO (Tensor gradient layout device dataType shape))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.tan_t</span></a></span><span>
</span><span id="line-1351"></span><span>
</span><span id="line-1352"></span><span class="hs-comment">-- | Returns a new tensor with the hyperbolic tangent of the elements of 'input':</span><span>
</span><span id="line-1353"></span><span class="hs-comment">-- \[</span><span>
</span><span id="line-1354"></span><span class="hs-comment">-- \mathrm{output}_i = \tanh \left(\mathrm{input}_i\right).</span><span>
</span><span id="line-1355"></span><span class="hs-comment">-- \]</span><span>
</span><span id="line-1356"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#tanh"><span class="hs-identifier hs-type">tanh</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-1357"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679666716"><span class="annot"><a href="#local-6989586621679666716"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679666715"><span class="annot"><a href="#local-6989586621679666715"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679666714"><span class="annot"><a href="#local-6989586621679666714"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679666713"><span class="annot"><a href="#local-6989586621679666713"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679666712"><span class="annot"><a href="#local-6989586621679666712"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-1358"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-1359"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666716"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666715"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666714"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666713"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666712"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1360"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-1361"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666716"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666715"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666714"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666713"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666712"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-1362"></span><span id="tanh"><span class="annot"><span class="annottext">tanh :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#tanh"><span class="hs-identifier hs-var hs-var">tanh</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; (Tensor gradient layout device dataType shape
    -&gt; IO (Tensor gradient layout device dataType shape))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.tanh_t</span></a></span><span>
</span><span id="line-1363"></span><span>
</span><span id="line-1364"></span><span class="hs-comment">-- | Performs &#8220;true division&#8221;</span><span>
</span><span id="line-1365"></span><span class="hs-comment">-- that always computes the division in floating point:</span><span>
</span><span id="line-1366"></span><span class="hs-comment">-- \[</span><span>
</span><span id="line-1367"></span><span class="hs-comment">-- \mathrm{output}_i = \frac{\mathrm{dividend}_i}{\mathrm{divisor}_i}.</span><span>
</span><span id="line-1368"></span><span class="hs-comment">-- \]</span><span>
</span><span id="line-1369"></span><span class="hs-comment">--</span><span>
</span><span id="line-1370"></span><span class="hs-comment">-- 'trueDivide' is completely equivalent to division using 'div'</span><span>
</span><span id="line-1371"></span><span class="hs-comment">-- except when both inputs have 'Bool' or integer data types,</span><span>
</span><span id="line-1372"></span><span class="hs-comment">-- in which case the inputs are converted to floating data types</span><span>
</span><span id="line-1373"></span><span class="hs-comment">-- before performing the division.</span><span>
</span><span id="line-1374"></span><span class="hs-comment">--</span><span>
</span><span id="line-1375"></span><span class="hs-comment">-- See 'trueDivideScalar' for a version of this function</span><span>
</span><span id="line-1376"></span><span class="hs-comment">-- where the divisor is a scalar.</span><span>
</span><span id="line-1377"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#trueDivide"><span class="hs-identifier hs-type">trueDivide</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-1378"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679666709"><span class="annot"><a href="#local-6989586621679666709"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679666708"><span class="annot"><a href="#local-6989586621679666708"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679666707"><span class="annot"><a href="#local-6989586621679666707"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679666706"><span class="annot"><a href="#local-6989586621679666706"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679666705"><span class="annot"><a href="#local-6989586621679666705"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679666704"><span class="annot"><a href="#local-6989586621679666704"><span class="hs-identifier hs-type">gradient'</span></a></span></span><span> </span><span id="local-6989586621679666703"><span class="annot"><a href="#local-6989586621679666703"><span class="hs-identifier hs-type">layout'</span></a></span></span><span> </span><span id="local-6989586621679666702"><span class="annot"><a href="#local-6989586621679666702"><span class="hs-identifier hs-type">device'</span></a></span></span><span> </span><span id="local-6989586621679666701"><span class="annot"><a href="#local-6989586621679666701"><span class="hs-identifier hs-type">dataType'</span></a></span></span><span> </span><span id="local-6989586621679666700"><span class="annot"><a href="#local-6989586621679666700"><span class="hs-identifier hs-type">shape'</span></a></span></span><span> </span><span id="local-6989586621679666699"><span class="annot"><a href="#local-6989586621679666699"><span class="hs-identifier hs-type">shape''</span></a></span></span><span> </span><span id="local-6989586621679666698"><span class="annot"><a href="#local-6989586621679666698"><span class="hs-identifier hs-type">m</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-1379"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier hs-type">MonadThrow</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666698"><span class="hs-identifier hs-type">m</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679666699"><span class="hs-identifier hs-type">shape''</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#BroadcastShapesF"><span class="hs-identifier hs-type">BroadcastShapesF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666705"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666700"><span class="hs-identifier hs-type">shape'</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Catch"><span class="hs-identifier hs-type">Catch</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666699"><span class="hs-identifier hs-type">shape''</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-1380"></span><span>  </span><span class="hs-comment">-- | tensor dividend</span><span>
</span><span id="line-1381"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666709"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666708"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666707"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666706"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666705"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1382"></span><span>  </span><span class="hs-comment">-- | tensor divisor</span><span>
</span><span id="line-1383"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666704"><span class="hs-identifier hs-type">gradient'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666703"><span class="hs-identifier hs-type">layout'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666702"><span class="hs-identifier hs-type">device'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666701"><span class="hs-identifier hs-type">dataType'</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666700"><span class="hs-identifier hs-type">shape'</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1384"></span><span>  </span><span class="hs-comment">-- | tensor output</span><span>
</span><span id="line-1385"></span><span>  </span><span class="annot"><a href="#local-6989586621679666698"><span class="hs-identifier hs-type">m</span></a></span><span>
</span><span id="line-1386"></span><span>    </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-1387"></span><span>        </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679666709"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666704"><span class="hs-identifier hs-type">gradient'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-1388"></span><span>        </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679666708"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666703"><span class="hs-identifier hs-type">layout'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-1389"></span><span>        </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679666707"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666702"><span class="hs-identifier hs-type">device'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-1390"></span><span>        </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679666706"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666701"><span class="hs-identifier hs-type">dataType'</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-1391"></span><span>        </span><span class="annot"><a href="#local-6989586621679666699"><span class="hs-identifier hs-type">shape''</span></a></span><span>
</span><span id="line-1392"></span><span>    </span><span class="hs-special">)</span><span>
</span><span id="line-1393"></span><span id="local-6989586621679666697"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679666697"><span class="hs-identifier hs-var">dividend</span></a></span></span><span> </span><span id="trueDivide"><span class="annot"><span class="annottext">trueDivide :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; m (Tensor
        (gradient &lt;|&gt; gradient')
        (layout &lt;+&gt; layout')
        (device &lt;+&gt; device')
        (dataType &lt;+&gt; dataType')
        shape'')
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#trueDivide"><span class="hs-operator hs-var hs-var">`trueDivide`</span></a></span></span><span> </span><span id="local-6989586621679666696"><span class="annot"><span class="annottext">Tensor gradient' layout' device' dataType' shape'
</span><a href="#local-6989586621679666696"><span class="hs-identifier hs-var">divisor</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO
  (Tensor
     (Or (Gradient RequiresGradient) gradient gradient')
     (Unify (Layout LayoutType) layout layout')
     (Unify (Device (DeviceType Nat)) device device')
     (Unify (DataType DType) dataType dataType')
     shape'')
-&gt; m (Tensor
        (Or (Gradient RequiresGradient) gradient gradient')
        (Unify (Layout LayoutType) layout layout')
        (Unify (Device (DeviceType Nat)) device device')
        (Unify (DataType DType) dataType dataType')
        shape'')
forall a (m :: * -&gt; *). MonadThrow m =&gt; IO a -&gt; m a
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">unsafeThrowableIO</span></a></span><span> </span><span class="annot"><span class="annottext">(IO
   (Tensor
      (Or (Gradient RequiresGradient) gradient gradient')
      (Unify (Layout LayoutType) layout layout')
      (Unify (Device (DeviceType Nat)) device device')
      (Unify (DataType DType) dataType dataType')
      shape'')
 -&gt; m (Tensor
         (Or (Gradient RequiresGradient) gradient gradient')
         (Unify (Layout LayoutType) layout layout')
         (Unify (Device (DeviceType Nat)) device device')
         (Unify (DataType DType) dataType dataType')
         shape''))
-&gt; IO
     (Tensor
        (Or (Gradient RequiresGradient) gradient gradient')
        (Unify (Layout LayoutType) layout layout')
        (Unify (Device (DeviceType Nat)) device device')
        (Unify (DataType DType) dataType dataType')
        shape'')
-&gt; m (Tensor
        (Or (Gradient RequiresGradient) gradient gradient')
        (Unify (Layout LayoutType) layout layout')
        (Unify (Device (DeviceType Nat)) device device')
        (Unify (DataType DType) dataType dataType')
        shape'')
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; IO
     (Tensor
        (Or (Gradient RequiresGradient) gradient gradient')
        (Unify (Layout LayoutType) layout layout')
        (Unify (Device (DeviceType Nat)) device device')
        (Unify (DataType DType) dataType dataType')
        shape'')
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.true_divide_tt</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679666697"><span class="hs-identifier hs-var">dividend</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient' layout' device' dataType' shape'
</span><a href="#local-6989586621679666696"><span class="hs-identifier hs-var">divisor</span></a></span><span>
</span><span id="line-1394"></span><span>
</span><span id="line-1395"></span><span class="hs-comment">-- | Performs &#8220;true division&#8221;</span><span>
</span><span id="line-1396"></span><span class="hs-comment">-- that always computes the division in floating point:</span><span>
</span><span id="line-1397"></span><span class="hs-comment">-- \[</span><span>
</span><span id="line-1398"></span><span class="hs-comment">-- \mathrm{output}_i = \frac{\mathrm{dividend}_i}{\mathrm{divisor}}.</span><span>
</span><span id="line-1399"></span><span class="hs-comment">-- \]</span><span>
</span><span id="line-1400"></span><span class="hs-comment">--</span><span>
</span><span id="line-1401"></span><span class="hs-comment">-- 'trueDivideScalar' is completely equivalent to division using 'divScalar'</span><span>
</span><span id="line-1402"></span><span class="hs-comment">-- except when both inputs have 'Bool' or integer data types,</span><span>
</span><span id="line-1403"></span><span class="hs-comment">-- in which case the inputs are converted to floating data types</span><span>
</span><span id="line-1404"></span><span class="hs-comment">-- before performing the division.</span><span>
</span><span id="line-1405"></span><span class="hs-comment">--</span><span>
</span><span id="line-1406"></span><span class="hs-comment">-- See 'trueDivide' for a version of this function</span><span>
</span><span id="line-1407"></span><span class="hs-comment">-- where the divisor is a tensor.</span><span>
</span><span id="line-1408"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#trueDivideScalar"><span class="hs-identifier hs-type">trueDivideScalar</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-1409"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679666693"><span class="annot"><a href="#local-6989586621679666693"><span class="hs-identifier hs-type">other</span></a></span></span><span> </span><span id="local-6989586621679666692"><span class="annot"><a href="#local-6989586621679666692"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679666691"><span class="annot"><a href="#local-6989586621679666691"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679666690"><span class="annot"><a href="#local-6989586621679666690"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679666689"><span class="annot"><a href="#local-6989586621679666689"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679666688"><span class="annot"><a href="#local-6989586621679666688"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-1410"></span><span>  </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Scalar.html#Scalar"><span class="hs-identifier hs-type">Scalar</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666693"><span class="hs-identifier hs-type">other</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-1411"></span><span>  </span><span class="hs-comment">-- | tensor dividend</span><span>
</span><span id="line-1412"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666692"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666691"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666690"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666689"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666688"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1413"></span><span>  </span><span class="hs-comment">-- | scalar divisor</span><span>
</span><span id="line-1414"></span><span>  </span><span class="annot"><a href="#local-6989586621679666693"><span class="hs-identifier hs-type">other</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1415"></span><span>  </span><span class="hs-comment">-- | tensor output</span><span>
</span><span id="line-1416"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666692"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666691"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666690"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666689"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666688"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-1417"></span><span id="local-6989586621679666687"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679666687"><span class="hs-identifier hs-var">dividend</span></a></span></span><span> </span><span id="trueDivideScalar"><span class="annot"><span class="annottext">trueDivideScalar :: Tensor gradient layout device dataType shape
-&gt; other -&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#trueDivideScalar"><span class="hs-operator hs-var hs-var">`trueDivideScalar`</span></a></span></span><span> </span><span id="local-6989586621679666686"><span class="annot"><span class="annottext">other
</span><a href="#local-6989586621679666686"><span class="hs-identifier hs-var">divisor</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; ForeignPtr Scalar -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; other
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca x1 cx1 y cy.
(Castable a ca, Castable x1 cx1, Castable y cy) =&gt;
(ca -&gt; cx1 -&gt; IO cy) -&gt; a -&gt; x1 -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast2</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; ForeignPtr Scalar -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.true_divide_ts</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679666687"><span class="hs-identifier hs-var">dividend</span></a></span><span> </span><span class="annot"><span class="annottext">other
</span><a href="#local-6989586621679666686"><span class="hs-identifier hs-var">divisor</span></a></span><span>
</span><span id="line-1418"></span><span>
</span><span id="line-1419"></span><span class="hs-comment">-- Returns a new tensor with the truncated integer values of the elements of 'input'.</span><span>
</span><span id="line-1420"></span><span class="hs-comment">--</span><span>
</span><span id="line-1421"></span><span class="hs-comment">-- Note that the data type of the 'output' tensor matches that of the 'input'.</span><span>
</span><span id="line-1422"></span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#trunc"><span class="hs-identifier hs-type">trunc</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-1423"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679666683"><span class="annot"><a href="#local-6989586621679666683"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679666682"><span class="annot"><a href="#local-6989586621679666682"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679666681"><span class="annot"><a href="#local-6989586621679666681"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679666680"><span class="annot"><a href="#local-6989586621679666680"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679666679"><span class="annot"><a href="#local-6989586621679666679"><span class="hs-identifier hs-type">shape</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-1424"></span><span>  </span><span class="hs-comment">-- | input</span><span>
</span><span id="line-1425"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666683"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666682"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666681"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666680"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666679"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-1426"></span><span>  </span><span class="hs-comment">-- | output</span><span>
</span><span id="line-1427"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666683"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666682"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666681"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666680"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679666679"><span class="hs-identifier hs-type">shape</span></a></span><span>
</span><span id="line-1428"></span><span id="trunc"><span class="annot"><span class="annottext">trunc :: Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#trunc"><span class="hs-identifier hs-var hs-var">trunc</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IO (Tensor gradient layout device dataType shape)
-&gt; Tensor gradient layout device dataType shape
forall a. IO a -&gt; a
</span><span class="hs-identifier hs-var">unsafePerformIO</span></span><span> </span><span class="annot"><span class="annottext">(IO (Tensor gradient layout device dataType shape)
 -&gt; Tensor gradient layout device dataType shape)
-&gt; (Tensor gradient layout device dataType shape
    -&gt; IO (Tensor gradient layout device dataType shape))
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">(ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor))
-&gt; Tensor gradient layout device dataType shape
-&gt; IO (Tensor gradient layout device dataType shape)
forall a ca y cy.
(Castable a ca, Castable y cy) =&gt;
(ca -&gt; IO cy) -&gt; a -&gt; IO y
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.cast1</span></a></span><span> </span><span class="annot"><span class="annottext">ForeignPtr Tensor -&gt; IO (ForeignPtr Tensor)
</span><a href="../../../../libtorch-ffi/html/src"><span class="hs-identifier hs-var">ATen.trunc_t</span></a></span><span>
</span><span id="line-1429"></span></pre></body></html>