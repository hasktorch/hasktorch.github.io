<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><link rel="stylesheet" type="text/css" href="style.css" /><script type="text/javascript" src="highlight.js"></script></head><body><pre><span class="hs-pragma">{-# LANGUAGE AllowAmbiguousTypes #-}</span><span>
</span><span id="line-2"></span><span class="hs-pragma">{-# LANGUAGE ConstraintKinds #-}</span><span>
</span><span id="line-3"></span><span class="hs-pragma">{-# LANGUAGE DataKinds #-}</span><span>
</span><span id="line-4"></span><span class="hs-pragma">{-# LANGUAGE FlexibleContexts #-}</span><span>
</span><span id="line-5"></span><span class="hs-pragma">{-# LANGUAGE FlexibleInstances #-}</span><span>
</span><span id="line-6"></span><span class="hs-pragma">{-# LANGUAGE GADTs #-}</span><span>
</span><span id="line-7"></span><span class="hs-pragma">{-# LANGUAGE KindSignatures #-}</span><span>
</span><span id="line-8"></span><span class="hs-pragma">{-# LANGUAGE MultiParamTypeClasses #-}</span><span>
</span><span id="line-9"></span><span class="hs-pragma">{-# LANGUAGE PartialTypeSignatures #-}</span><span>
</span><span id="line-10"></span><span class="hs-pragma">{-# LANGUAGE PatternSynonyms #-}</span><span>
</span><span id="line-11"></span><span class="hs-pragma">{-# LANGUAGE RecordWildCards #-}</span><span>
</span><span id="line-12"></span><span class="hs-pragma">{-# LANGUAGE ScopedTypeVariables #-}</span><span>
</span><span id="line-13"></span><span class="hs-pragma">{-# LANGUAGE StandaloneKindSignatures #-}</span><span>
</span><span id="line-14"></span><span class="hs-pragma">{-# LANGUAGE TypeApplications #-}</span><span>
</span><span id="line-15"></span><span class="hs-pragma">{-# LANGUAGE TypeFamilies #-}</span><span>
</span><span id="line-16"></span><span class="hs-pragma">{-# LANGUAGE TypeOperators #-}</span><span>
</span><span id="line-17"></span><span class="hs-pragma">{-# LANGUAGE UndecidableInstances #-}</span><span>
</span><span id="line-18"></span><span class="hs-pragma">{-# LANGUAGE NoStarIsType #-}</span><span>
</span><span id="line-19"></span><span class="hs-pragma">{-# OPTIONS_GHC -fplugin TypeLevel.Rewrite
                -fplugin-opt=TypeLevel.Rewrite:Torch.GraduallyTyped.Unify.UnifyRightAssociativeL
                -fplugin-opt=TypeLevel.Rewrite:Torch.GraduallyTyped.Unify.UnifyIdempotenceL2
                -fplugin-opt=TypeLevel.Rewrite:Torch.GraduallyTyped.Unify.UnifyIdempotenceL2C
                -fplugin-opt=TypeLevel.Rewrite:Torch.GraduallyTyped.Unify.UnifyIdempotenceL3
                -fplugin-opt=TypeLevel.Rewrite:Torch.GraduallyTyped.Unify.UnifyIdempotenceL3C
                -fplugin-opt=TypeLevel.Rewrite:Torch.GraduallyTyped.Unify.UnifyIdempotenceL4
                -fplugin-opt=TypeLevel.Rewrite:Torch.GraduallyTyped.Unify.UnifyIdempotenceL4C
                -fplugin-opt=TypeLevel.Rewrite:Torch.GraduallyTyped.Unify.UnifyIdempotenceL5
                -fplugin-opt=TypeLevel.Rewrite:Torch.GraduallyTyped.Unify.UnifyIdempotenceL5C
                -fplugin-opt=TypeLevel.Rewrite:Torch.GraduallyTyped.Unify.UnifyIdempotenceL6
                -fplugin-opt=TypeLevel.Rewrite:Torch.GraduallyTyped.Unify.UnifyIdempotenceL6C
                -fplugin-opt=TypeLevel.Rewrite:Torch.GraduallyTyped.Unify.UnifyIdempotenceL7
                -fplugin-opt=TypeLevel.Rewrite:Torch.GraduallyTyped.Unify.UnifyIdempotenceL7C
                -fplugin-opt=TypeLevel.Rewrite:Torch.GraduallyTyped.Unify.UnifyIdempotenceL8
                -fplugin-opt=TypeLevel.Rewrite:Torch.GraduallyTyped.Unify.UnifyIdempotenceL8C
                -fplugin-opt=TypeLevel.Rewrite:Torch.GraduallyTyped.Unify.OrIdempotenceL2
                -fplugin-opt=TypeLevel.Rewrite:Torch.GraduallyTyped.Unify.OrIdempotenceL2C
                -fplugin-opt=TypeLevel.Rewrite:Torch.GraduallyTyped.Unify.OrIdempotenceL3
                -fplugin-opt=TypeLevel.Rewrite:Torch.GraduallyTyped.Unify.OrIdempotenceL3C #-}</span><span>
</span><span id="line-39"></span><span class="hs-pragma">{-# OPTIONS_GHC -v2 -Wall #-}</span><span>
</span><span id="line-40"></span><span>
</span><span id="line-41"></span><span class="hs-keyword">module</span><span> </span><span class="hs-identifier">Torch.GraduallyTyped.NN.Transformer.CrossAttention</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-42"></span><span>
</span><span id="line-43"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier">Control.Monad.Indexed</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier">IxPointed</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier">ireturn</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator">(&gt;&gt;&gt;=)</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-44"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier">Control.Monad.Indexed.State</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier">IxStateT</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-45"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">Control.Monad.State</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier">evalStateT</span></span><span class="hs-special">)</span><span>
</span><span id="line-46"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier">Data.Functor.Indexed</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator">(&lt;&lt;$&gt;&gt;)</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator">(&lt;&lt;*&gt;&gt;)</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-47"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">Data.Kind</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier">Type</span></span><span class="hs-special">)</span><span>
</span><span id="line-48"></span><span class="hs-keyword">import</span><span> </span><span class="hs-keyword">qualified</span><span> </span><span class="annot"><span class="hs-identifier">Data.Map</span></span><span> </span><span class="hs-keyword">as</span><span> </span><span class="annot"><span class="hs-identifier">Map</span></span><span>
</span><span id="line-49"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">Data.Singletons</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">SingI</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">sing</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-50"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">Data.Singletons.Prelude.List</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">SList</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-51"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">GHC.TypeLits</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier">Nat</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier">Symbol</span></span><span class="hs-special">)</span><span>
</span><span id="line-52"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html"><span class="hs-identifier">Torch.GraduallyTyped.DType</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier">DType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier">DataType</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#SDType"><span class="hs-identifier">SDType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier">SDataType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-53"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html"><span class="hs-identifier">Torch.GraduallyTyped.Device</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier">Device</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#DeviceType"><span class="hs-identifier">DeviceType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#SDevice"><span class="hs-identifier">SDevice</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#SDeviceType"><span class="hs-identifier">SDeviceType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-54"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html"><span class="hs-identifier">Torch.GraduallyTyped.Layout</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier">Layout</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#LayoutType"><span class="hs-identifier">LayoutType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#SLayout"><span class="hs-identifier">SLayout</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#SLayoutType"><span class="hs-identifier">SLayoutType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-55"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html"><span class="hs-identifier">Torch.GraduallyTyped.NN.Class</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier">HasForward</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier">HasInitialize</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasStateDict"><span class="hs-identifier">HasStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier">ModelSpec</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-56"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Dropout.html"><span class="hs-identifier">Torch.GraduallyTyped.NN.Dropout</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Dropout.html#Dropout"><span class="hs-identifier">Dropout</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-57"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Functional.Normalization.html"><span class="hs-identifier">Torch.GraduallyTyped.NN.Functional.Normalization</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Functional.Normalization.html#LayerNormWithBiasF"><span class="hs-identifier">LayerNormWithBiasF</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-58"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Normalization.html"><span class="hs-identifier">Torch.GraduallyTyped.NN.Normalization</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Normalization.html#LayerNorm"><span class="hs-identifier">LayerNorm</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Normalization.html#LayerNormSpec"><span class="hs-identifier">LayerNormSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-59"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.MultiHeadAttention.html"><span class="hs-identifier">Torch.GraduallyTyped.NN.Transformer.MultiHeadAttention</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.MultiHeadAttention.html#MultiHeadAttention"><span class="hs-identifier">MultiHeadAttention</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.MultiHeadAttention.html#MultiHeadAttentionSpec"><span class="hs-identifier">MultiHeadAttentionSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-60"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html"><span class="hs-identifier">Torch.GraduallyTyped.NN.Transformer.Type</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#STransformerStyle"><span class="hs-identifier">STransformerStyle</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerStyle"><span class="hs-identifier">TransformerStyle</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-61"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Type.html"><span class="hs-identifier">Torch.GraduallyTyped.NN.Type</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Type.html#HasBias"><span class="hs-identifier">HasBias</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Type.html#SHasBias"><span class="hs-identifier">SHasBias</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-62"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Random.html"><span class="hs-identifier">Torch.GraduallyTyped.Random</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Random.html#sGeneratorToDevice"><span class="hs-identifier">sGeneratorToDevice</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Random.html#sMkGenerator"><span class="hs-identifier">sMkGenerator</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-63"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html"><span class="hs-identifier">Torch.GraduallyTyped.RequiresGradient</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier">Gradient</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#RequiresGradient"><span class="hs-identifier">RequiresGradient</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier">SGradient</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#SRequiresGradient"><span class="hs-identifier">SRequiresGradient</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-64"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html"><span class="hs-identifier">Torch.GraduallyTyped.Shape.Class</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#BroadcastShapesF"><span class="hs-identifier">BroadcastShapesF</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-65"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html"><span class="hs-identifier">Torch.GraduallyTyped.Shape.Type</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier">Name</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier">SDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier">SName</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier">SShape</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier">SSize</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier">Shape</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier">Size</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="hs-keyword">pattern</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator">(:&amp;:)</span></a></span><span class="hs-special">,</span><span> </span><span class="hs-keyword">pattern</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator">(:|:)</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-66"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Creation.html"><span class="hs-identifier">Torch.GraduallyTyped.Tensor.Creation</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Creation.html#sOnes"><span class="hs-identifier">sOnes</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-67"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html"><span class="hs-identifier">Torch.GraduallyTyped.Tensor.MathOperations.Pointwise</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#add"><span class="hs-identifier">add</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-68"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html"><span class="hs-identifier">Torch.GraduallyTyped.Tensor.Type</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetDim"><span class="hs-identifier">SGetDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier">Tensor</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorSpec"><span class="hs-identifier">TensorSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-69"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html"><span class="hs-identifier">Torch.GraduallyTyped.Unify</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-keyword">type</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator">(&lt;+&gt;)</span></a></span><span class="hs-special">,</span><span> </span><span class="hs-keyword">type</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator">(&lt;|&gt;)</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-70"></span><span>
</span><span id="line-71"></span><span class="hs-comment">-- | Generic cross-attention layer.</span><span>
</span><span id="line-72"></span><span class="hs-comment">-- Needs to be specialized to a given transformer type, e.g. 'T5'.</span><span>
</span><span id="line-73"></span><span class="hs-comment">-- See 'CrossAttention'.</span><span>
</span><span id="line-74"></span><span class="hs-keyword">data</span><span>
</span><span id="line-75"></span><span>  </span><span id="GCrossAttention"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.CrossAttention.html#GCrossAttention"><span class="hs-identifier hs-var">GCrossAttention</span></a></span></span><span>
</span><span id="line-76"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679805141"><span class="annot"><a href="#local-6989586621679805141"><span class="hs-identifier hs-type">mha</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span class="hs-special">)</span><span>
</span><span id="line-77"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679805140"><span class="annot"><a href="#local-6989586621679805140"><span class="hs-identifier hs-type">layerNorm</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span class="hs-special">)</span><span>
</span><span id="line-78"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679805139"><span class="annot"><a href="#local-6989586621679805139"><span class="hs-identifier hs-type">dropout</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span class="hs-special">)</span><span>
</span><span id="line-79"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-80"></span><span>  </span><span id="GCrossAttention"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.CrossAttention.html#GCrossAttention"><span class="hs-identifier hs-var">GCrossAttention</span></a></span></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-81"></span><span>    </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679805442"><span class="annot"><a href="#local-6989586621679805442"><span class="hs-identifier hs-type">mha</span></a></span></span><span> </span><span id="local-6989586621679805441"><span class="annot"><a href="#local-6989586621679805441"><span class="hs-identifier hs-type">layerNorm</span></a></span></span><span> </span><span id="local-6989586621679805440"><span class="annot"><a href="#local-6989586621679805440"><span class="hs-identifier hs-type">dropout</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-82"></span><span>    </span><span class="hs-special">{</span><span> </span><span class="hs-comment">-- | cross-attention</span><span>
</span><span id="line-83"></span><span>      </span><span id="caMultiHeadAttention"><span class="annot"><span class="annottext">GCrossAttention mha layerNorm dropout -&gt; mha
</span><a href="Torch.GraduallyTyped.NN.Transformer.CrossAttention.html#caMultiHeadAttention"><span class="hs-identifier hs-var hs-var">caMultiHeadAttention</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679805442"><span class="hs-identifier hs-type">mha</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-84"></span><span>      </span><span class="hs-comment">-- | layer norm</span><span>
</span><span id="line-85"></span><span>      </span><span id="caLayerNorm"><span class="annot"><span class="annottext">GCrossAttention mha layerNorm dropout -&gt; layerNorm
</span><a href="Torch.GraduallyTyped.NN.Transformer.CrossAttention.html#caLayerNorm"><span class="hs-identifier hs-var hs-var">caLayerNorm</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679805441"><span class="hs-identifier hs-type">layerNorm</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-86"></span><span>      </span><span class="hs-comment">-- | dropout</span><span>
</span><span id="line-87"></span><span>      </span><span id="caDropout"><span class="annot"><span class="annottext">GCrossAttention mha layerNorm dropout -&gt; dropout
</span><a href="Torch.GraduallyTyped.NN.Transformer.CrossAttention.html#caDropout"><span class="hs-identifier hs-var hs-var">caDropout</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="#local-6989586621679805440"><span class="hs-identifier hs-type">dropout</span></a></span><span>
</span><span id="line-88"></span><span>    </span><span class="hs-special">}</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-89"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.CrossAttention.html#GCrossAttention"><span class="hs-identifier hs-type">GCrossAttention</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805442"><span class="hs-identifier hs-type">mha</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805441"><span class="hs-identifier hs-type">layerNorm</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805440"><span class="hs-identifier hs-type">dropout</span></a></span><span>
</span><span id="line-90"></span><span>
</span><span id="line-91"></span><span class="hs-comment">-- | Cross-attention layer.</span><span>
</span><span id="line-92"></span><span class="hs-keyword">newtype</span><span>
</span><span id="line-93"></span><span>  </span><span id="CrossAttention"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.CrossAttention.html#CrossAttention"><span class="hs-identifier hs-var">CrossAttention</span></a></span></span><span>
</span><span id="line-94"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679805134"><span class="annot"><a href="#local-6989586621679805134"><span class="hs-identifier hs-type">style</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerStyle"><span class="hs-identifier hs-type">TransformerStyle</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-95"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679805133"><span class="annot"><a href="#local-6989586621679805133"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#RequiresGradient"><span class="hs-identifier hs-type">RequiresGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-96"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679805132"><span class="annot"><a href="#local-6989586621679805132"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier hs-type">Device</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#DeviceType"><span class="hs-identifier hs-type">DeviceType</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-97"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679805131"><span class="annot"><a href="#local-6989586621679805131"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier hs-type">DType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-98"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679805130"><span class="annot"><a href="#local-6989586621679805130"><span class="hs-identifier hs-type">headDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-99"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679805129"><span class="annot"><a href="#local-6989586621679805129"><span class="hs-identifier hs-type">headEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-100"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679805128"><span class="annot"><a href="#local-6989586621679805128"><span class="hs-identifier hs-type">embedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-101"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679805127"><span class="annot"><a href="#local-6989586621679805127"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-102"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679805126"><span class="annot"><a href="#local-6989586621679805126"><span class="hs-identifier hs-type">keyEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-103"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-104"></span><span>  </span><span id="CrossAttention"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.CrossAttention.html#CrossAttention"><span class="hs-identifier hs-var">CrossAttention</span></a></span></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-105"></span><span>    </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679805410"><span class="annot"><a href="#local-6989586621679805410"><span class="hs-identifier hs-type">style</span></a></span></span><span> </span><span id="local-6989586621679805409"><span class="annot"><a href="#local-6989586621679805409"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679805408"><span class="annot"><a href="#local-6989586621679805408"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679805407"><span class="annot"><a href="#local-6989586621679805407"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679805406"><span class="annot"><a href="#local-6989586621679805406"><span class="hs-identifier hs-type">headDim</span></a></span></span><span> </span><span id="local-6989586621679805405"><span class="annot"><a href="#local-6989586621679805405"><span class="hs-identifier hs-type">headEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679805404"><span class="annot"><a href="#local-6989586621679805404"><span class="hs-identifier hs-type">embedDim</span></a></span></span><span> </span><span id="local-6989586621679805403"><span class="annot"><a href="#local-6989586621679805403"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679805402"><span class="annot"><a href="#local-6989586621679805402"><span class="hs-identifier hs-type">keyEmbedDim</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-106"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.CrossAttention.html#GCrossAttention"><span class="hs-identifier hs-type">GCrossAttention</span></a></span><span>
</span><span id="line-107"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.CrossAttention.html#CAMultiheadAttentionF"><span class="hs-identifier hs-type">CAMultiheadAttentionF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805410"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805409"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805408"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805407"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805406"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805405"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805404"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805403"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805402"><span class="hs-identifier hs-type">keyEmbedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-108"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.CrossAttention.html#CALayerNormF"><span class="hs-identifier hs-type">CALayerNormF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805410"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805409"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805408"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805407"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805403"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-109"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.CrossAttention.html#CADropoutF"><span class="hs-identifier hs-type">CADropoutF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805410"><span class="hs-identifier hs-type">style</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-110"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.CrossAttention.html#CrossAttention"><span class="hs-identifier hs-type">CrossAttention</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805410"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805409"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805408"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805407"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805406"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805405"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805404"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805403"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805402"><span class="hs-identifier hs-type">keyEmbedDim</span></a></span><span>
</span><span id="line-111"></span><span>
</span><span id="line-112"></span><span class="hs-keyword">data</span><span>
</span><span id="line-113"></span><span>  </span><span id="CrossAttentionSpec"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.CrossAttention.html#CrossAttentionSpec"><span class="hs-identifier hs-var">CrossAttentionSpec</span></a></span></span><span>
</span><span id="line-114"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679805124"><span class="annot"><a href="#local-6989586621679805124"><span class="hs-identifier hs-type">style</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerStyle"><span class="hs-identifier hs-type">TransformerStyle</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-115"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679805123"><span class="annot"><a href="#local-6989586621679805123"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#RequiresGradient"><span class="hs-identifier hs-type">RequiresGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-116"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679805122"><span class="annot"><a href="#local-6989586621679805122"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier hs-type">Device</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#DeviceType"><span class="hs-identifier hs-type">DeviceType</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-117"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679805121"><span class="annot"><a href="#local-6989586621679805121"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier hs-type">DType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-118"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679805120"><span class="annot"><a href="#local-6989586621679805120"><span class="hs-identifier hs-type">headDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-119"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679805119"><span class="annot"><a href="#local-6989586621679805119"><span class="hs-identifier hs-type">headEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-120"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679805118"><span class="annot"><a href="#local-6989586621679805118"><span class="hs-identifier hs-type">embedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-121"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679805117"><span class="annot"><a href="#local-6989586621679805117"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-122"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679805116"><span class="annot"><a href="#local-6989586621679805116"><span class="hs-identifier hs-type">keyEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-123"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-124"></span><span>  </span><span id="CrossAttentionSpec"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.CrossAttention.html#CrossAttentionSpec"><span class="hs-identifier hs-var">CrossAttentionSpec</span></a></span></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-125"></span><span>    </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679805288"><span class="annot"><a href="#local-6989586621679805288"><span class="hs-identifier hs-type">style</span></a></span></span><span> </span><span id="local-6989586621679805287"><span class="annot"><a href="#local-6989586621679805287"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679805286"><span class="annot"><a href="#local-6989586621679805286"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679805285"><span class="annot"><a href="#local-6989586621679805285"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679805284"><span class="annot"><a href="#local-6989586621679805284"><span class="hs-identifier hs-type">headDim</span></a></span></span><span> </span><span id="local-6989586621679805283"><span class="annot"><a href="#local-6989586621679805283"><span class="hs-identifier hs-type">headEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679805282"><span class="annot"><a href="#local-6989586621679805282"><span class="hs-identifier hs-type">embedDim</span></a></span></span><span> </span><span id="local-6989586621679805281"><span class="annot"><a href="#local-6989586621679805281"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679805280"><span class="annot"><a href="#local-6989586621679805280"><span class="hs-identifier hs-type">keyEmbedDim</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-126"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#STransformerStyle"><span class="hs-identifier hs-type">STransformerStyle</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805288"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-127"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier hs-type">SGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805287"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-128"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#SDevice"><span class="hs-identifier hs-type">SDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805286"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-129"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier hs-type">SDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805285"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-130"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805284"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-131"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805283"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-132"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805282"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-133"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805281"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-134"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805280"><span class="hs-identifier hs-type">keyEmbedDim</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-135"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-136"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-137"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.CrossAttention.html#CrossAttentionSpec"><span class="hs-identifier hs-type">CrossAttentionSpec</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805288"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805287"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805286"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805285"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805284"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805283"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805282"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805281"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805280"><span class="hs-identifier hs-type">keyEmbedDim</span></a></span><span>
</span><span id="line-138"></span><span>
</span><span id="line-139"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">instance</span><span> </span><span id="ModelSpec"><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier hs-var">ModelSpec</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.CrossAttention.html#CrossAttention"><span class="hs-identifier hs-type">CrossAttention</span></a></span><span> </span><span id="local-6989586621679805114"><span class="annot"><a href="#local-6989586621679805114"><span class="hs-identifier hs-type hs-type">style</span></a></span></span><span> </span><span id="local-6989586621679805113"><span class="annot"><a href="#local-6989586621679805113"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679805112"><span class="annot"><a href="#local-6989586621679805112"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679805111"><span class="annot"><a href="#local-6989586621679805111"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679805110"><span class="annot"><a href="#local-6989586621679805110"><span class="hs-identifier hs-type hs-type">headDim</span></a></span></span><span> </span><span id="local-6989586621679805109"><span class="annot"><a href="#local-6989586621679805109"><span class="hs-identifier hs-type hs-type">headEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679805108"><span class="annot"><a href="#local-6989586621679805108"><span class="hs-identifier hs-type hs-type">embedDim</span></a></span></span><span> </span><span id="local-6989586621679805107"><span class="annot"><a href="#local-6989586621679805107"><span class="hs-identifier hs-type hs-type">queryEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679805106"><span class="annot"><a href="#local-6989586621679805106"><span class="hs-identifier hs-type hs-type">keyEmbedDim</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.CrossAttention.html#CrossAttentionSpec"><span class="hs-identifier hs-type">CrossAttentionSpec</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805114"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805113"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805112"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805111"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805110"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805109"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805108"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805107"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805106"><span class="hs-identifier hs-type">keyEmbedDim</span></a></span><span>
</span><span id="line-140"></span><span>
</span><span id="line-141"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span>
</span><span id="line-142"></span><span>  </span><span id="CAMultiheadAttentionF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.CrossAttention.html#CAMultiheadAttentionF"><span class="hs-identifier hs-var">CAMultiheadAttentionF</span></a></span></span><span>
</span><span id="line-143"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679805105"><span class="annot"><a href="#local-6989586621679805105"><span class="hs-identifier hs-type">style</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerStyle"><span class="hs-identifier hs-type">TransformerStyle</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-144"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679805104"><span class="annot"><a href="#local-6989586621679805104"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#RequiresGradient"><span class="hs-identifier hs-type">RequiresGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-145"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679805103"><span class="annot"><a href="#local-6989586621679805103"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier hs-type">Device</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#DeviceType"><span class="hs-identifier hs-type">DeviceType</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-146"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679805102"><span class="annot"><a href="#local-6989586621679805102"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier hs-type">DType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-147"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679805101"><span class="annot"><a href="#local-6989586621679805101"><span class="hs-identifier hs-type">headDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-148"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679805100"><span class="annot"><a href="#local-6989586621679805100"><span class="hs-identifier hs-type">headEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-149"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679805099"><span class="annot"><a href="#local-6989586621679805099"><span class="hs-identifier hs-type">embedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-150"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679805098"><span class="annot"><a href="#local-6989586621679805098"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-151"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679805097"><span class="annot"><a href="#local-6989586621679805097"><span class="hs-identifier hs-type">keyEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-152"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span>
</span><span id="line-153"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-154"></span><span>  </span><span id="CAMultiheadAttentionF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.CrossAttention.html#CAMultiheadAttentionF"><span class="hs-identifier hs-var">CAMultiheadAttentionF</span></a></span></span><span> </span><span id="local-6989586621679805096"><span class="annot"><a href="#local-6989586621679805096"><span class="hs-identifier hs-type hs-type">style</span></a></span></span><span> </span><span id="local-6989586621679805095"><span class="annot"><a href="#local-6989586621679805095"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679805094"><span class="annot"><a href="#local-6989586621679805094"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679805093"><span class="annot"><a href="#local-6989586621679805093"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679805092"><span class="annot"><a href="#local-6989586621679805092"><span class="hs-identifier hs-type hs-type">headDim</span></a></span></span><span> </span><span id="local-6989586621679805091"><span class="annot"><a href="#local-6989586621679805091"><span class="hs-identifier hs-type hs-type">headEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679805090"><span class="annot"><a href="#local-6989586621679805090"><span class="hs-identifier hs-type hs-type">embedDim</span></a></span></span><span> </span><span id="local-6989586621679805089"><span class="annot"><a href="#local-6989586621679805089"><span class="hs-identifier hs-type hs-type">queryEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679805088"><span class="annot"><a href="#local-6989586621679805088"><span class="hs-identifier hs-type hs-type">keyEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-155"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.MultiHeadAttention.html#MultiHeadAttention"><span class="hs-identifier hs-type">MultiHeadAttention</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805096"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805095"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805094"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805093"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805092"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805091"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805090"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805089"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805088"><span class="hs-identifier hs-type">keyEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805088"><span class="hs-identifier hs-type">keyEmbedDim</span></a></span><span>
</span><span id="line-156"></span><span>
</span><span id="line-157"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span>
</span><span id="line-158"></span><span>  </span><span id="CALayerNormF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.CrossAttention.html#CALayerNormF"><span class="hs-identifier hs-var">CALayerNormF</span></a></span></span><span>
</span><span id="line-159"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679805087"><span class="annot"><a href="#local-6989586621679805087"><span class="hs-identifier hs-type">style</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerStyle"><span class="hs-identifier hs-type">TransformerStyle</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-160"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679805086"><span class="annot"><a href="#local-6989586621679805086"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#RequiresGradient"><span class="hs-identifier hs-type">RequiresGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-161"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679805085"><span class="annot"><a href="#local-6989586621679805085"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier hs-type">Device</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#DeviceType"><span class="hs-identifier hs-type">DeviceType</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-162"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679805084"><span class="annot"><a href="#local-6989586621679805084"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier hs-type">DType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-163"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679805083"><span class="annot"><a href="#local-6989586621679805083"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-164"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span>
</span><span id="line-165"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-166"></span><span>  </span><span id="CALayerNormF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.CrossAttention.html#CALayerNormF"><span class="hs-identifier hs-var">CALayerNormF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#T5"><span class="hs-identifier hs-type">T5</span></a></span><span> </span><span id="local-6989586621679805082"><span class="annot"><a href="#local-6989586621679805082"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679805081"><span class="annot"><a href="#local-6989586621679805081"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679805080"><span class="annot"><a href="#local-6989586621679805080"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679805079"><span class="annot"><a href="#local-6989586621679805079"><span class="hs-identifier hs-type hs-type">queryEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Normalization.html#LayerNorm"><span class="hs-identifier hs-type">LayerNorm</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Type.html#WithoutBias"><span class="hs-identifier hs-type">WithoutBias</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805082"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805081"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805080"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679805079"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-167"></span><span>  </span><span id="CALayerNormF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.CrossAttention.html#CALayerNormF"><span class="hs-identifier hs-var">CALayerNormF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ByT5"><span class="hs-identifier hs-type">ByT5</span></a></span><span> </span><span id="local-6989586621679805078"><span class="annot"><a href="#local-6989586621679805078"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679805077"><span class="annot"><a href="#local-6989586621679805077"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679805076"><span class="annot"><a href="#local-6989586621679805076"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679805075"><span class="annot"><a href="#local-6989586621679805075"><span class="hs-identifier hs-type hs-type">queryEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.CrossAttention.html#CALayerNormF"><span class="hs-identifier hs-type">CALayerNormF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#T5"><span class="hs-identifier hs-type">T5</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805078"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805077"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805076"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805075"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span>
</span><span id="line-168"></span><span>  </span><span id="CALayerNormF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.CrossAttention.html#CALayerNormF"><span class="hs-identifier hs-var">CALayerNormF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span> </span><span id="local-6989586621679805074"><span class="annot"><a href="#local-6989586621679805074"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679805073"><span class="annot"><a href="#local-6989586621679805073"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679805072"><span class="annot"><a href="#local-6989586621679805072"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679805071"><span class="annot"><a href="#local-6989586621679805071"><span class="hs-identifier hs-type hs-type">queryEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Normalization.html#LayerNorm"><span class="hs-identifier hs-type">LayerNorm</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Type.html#WithBias"><span class="hs-identifier hs-type">WithBias</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805074"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805073"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805072"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679805071"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-169"></span><span>  </span><span id="CALayerNormF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.CrossAttention.html#CALayerNormF"><span class="hs-identifier hs-var">CALayerNormF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MBART"><span class="hs-identifier hs-type">MBART</span></a></span><span> </span><span id="local-6989586621679805070"><span class="annot"><a href="#local-6989586621679805070"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679805069"><span class="annot"><a href="#local-6989586621679805069"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679805068"><span class="annot"><a href="#local-6989586621679805068"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679805067"><span class="annot"><a href="#local-6989586621679805067"><span class="hs-identifier hs-type hs-type">queryEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.CrossAttention.html#CALayerNormF"><span class="hs-identifier hs-type">CALayerNormF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805070"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805069"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805068"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805067"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span>
</span><span id="line-170"></span><span>  </span><span id="CALayerNormF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.CrossAttention.html#CALayerNormF"><span class="hs-identifier hs-var">CALayerNormF</span></a></span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#Pegasus"><span class="hs-identifier hs-type">Pegasus</span></a></span><span> </span><span id="local-6989586621679805066"><span class="annot"><a href="#local-6989586621679805066"><span class="hs-identifier hs-type hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679805065"><span class="annot"><a href="#local-6989586621679805065"><span class="hs-identifier hs-type hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679805064"><span class="annot"><a href="#local-6989586621679805064"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679805063"><span class="annot"><a href="#local-6989586621679805063"><span class="hs-identifier hs-type hs-type">queryEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.CrossAttention.html#CALayerNormF"><span class="hs-identifier hs-type">CALayerNormF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805066"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805065"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805064"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805063"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span>
</span><span id="line-171"></span><span>
</span><span id="line-172"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">family</span><span>
</span><span id="line-173"></span><span>  </span><span id="CADropoutF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.CrossAttention.html#CADropoutF"><span class="hs-identifier hs-var">CADropoutF</span></a></span></span><span>
</span><span id="line-174"></span><span>    </span><span class="hs-special">(</span><span id="local-6989586621679805062"><span class="annot"><a href="#local-6989586621679805062"><span class="hs-identifier hs-type">style</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerStyle"><span class="hs-identifier hs-type">TransformerStyle</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-175"></span><span>    </span><span class="annot"><span class="hs-identifier hs-type">Type</span></span><span>
</span><span id="line-176"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-177"></span><span>  </span><span id="CADropoutF"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.CrossAttention.html#CADropoutF"><span class="hs-identifier hs-var">CADropoutF</span></a></span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Dropout.html#Dropout"><span class="hs-identifier hs-type">Dropout</span></a></span><span>
</span><span id="line-178"></span><span>
</span><span id="line-179"></span><span id="local-6989586621679805049"><span id="local-6989586621679805050"><span id="local-6989586621679805051"><span id="local-6989586621679805052"><span id="local-6989586621679805053"><span id="local-6989586621679805054"><span id="local-6989586621679805055"><span id="local-6989586621679805056"><span id="local-6989586621679805057"><span id="local-6989586621679805058"><span id="local-6989586621679805059"><span id="local-6989586621679805060"><span id="local-6989586621679805061"><span class="hs-keyword">instance</span><span>
</span><span id="line-180"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="#local-6989586621679805061"><span class="hs-identifier hs-type">multiHeadAttention</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.CrossAttention.html#CAMultiheadAttentionF"><span class="hs-identifier hs-type">CAMultiheadAttentionF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805060"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805059"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805058"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805057"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805056"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805055"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805054"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805053"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805052"><span class="hs-identifier hs-type">keyEmbedDim</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-181"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805061"><span class="hs-identifier hs-type">multiHeadAttention</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805058"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805061"><span class="hs-identifier hs-type">multiHeadAttention</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805058"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-182"></span><span>    </span><span class="annot"><a href="#local-6989586621679805051"><span class="hs-identifier hs-type">layerNorm</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.CrossAttention.html#CALayerNormF"><span class="hs-identifier hs-type">CALayerNormF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805060"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805059"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805058"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805057"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805053"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-183"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805051"><span class="hs-identifier hs-type">layerNorm</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805058"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805051"><span class="hs-identifier hs-type">layerNorm</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805058"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-184"></span><span>    </span><span class="annot"><a href="#local-6989586621679805050"><span class="hs-identifier hs-type">dropout</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.CrossAttention.html#CADropoutF"><span class="hs-identifier hs-type">CADropoutF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805060"><span class="hs-identifier hs-type">style</span></a></span><span>
</span><span id="line-185"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-186"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span>
</span><span id="line-187"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.CrossAttention.html#CrossAttention"><span class="hs-identifier hs-type">CrossAttention</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805060"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805059"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805058"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805057"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805056"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805055"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805054"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805053"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805052"><span class="hs-identifier hs-type">keyEmbedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-188"></span><span>    </span><span class="annot"><a href="#local-6989586621679805049"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-189"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.CrossAttention.html#CrossAttention"><span class="hs-identifier hs-type">CrossAttention</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805060"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805059"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805058"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805057"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805056"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805055"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805054"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805053"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805052"><span class="hs-identifier hs-type">keyEmbedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-190"></span><span>    </span><span class="annot"><a href="#local-6989586621679805058"><span class="hs-identifier hs-type">device</span></a></span><span>
</span><span id="line-191"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-192"></span><span>  </span><span id="local-6989586621679805046"><span class="annot"><span class="annottext">initialize :: ModelSpec
  (CrossAttention
     style
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     keyEmbedDim)
-&gt; Generator generatorDevice
-&gt; m (CrossAttention
        style
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        queryEmbedDim
        keyEmbedDim,
      Generator device)
</span><a href="Torch.GraduallyTyped.NN.Class.html#initialize"><span class="hs-identifier hs-var hs-var hs-var hs-var">initialize</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.CrossAttention.html#CrossAttentionSpec"><span class="hs-identifier hs-type">CrossAttentionSpec</span></a></span><span> </span><span id="local-6989586621679805044"><span class="annot"><a href="#local-6989586621679805044"><span class="hs-identifier hs-var">style</span></a></span></span><span> </span><span id="local-6989586621679805043"><span class="annot"><a href="#local-6989586621679805043"><span class="hs-identifier hs-var">gradient</span></a></span></span><span> </span><span id="local-6989586621679805042"><span class="annot"><a href="#local-6989586621679805042"><span class="hs-identifier hs-var">device</span></a></span></span><span> </span><span id="local-6989586621679805041"><span class="annot"><a href="#local-6989586621679805041"><span class="hs-identifier hs-var">dataType</span></a></span></span><span> </span><span id="local-6989586621679805040"><span class="annot"><a href="#local-6989586621679805040"><span class="hs-identifier hs-var">headDim</span></a></span></span><span> </span><span id="local-6989586621679805039"><span class="annot"><a href="#local-6989586621679805039"><span class="hs-identifier hs-var">headEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679805038"><span class="annot"><a href="#local-6989586621679805038"><span class="hs-identifier hs-var">embedDim</span></a></span></span><span> </span><span id="local-6989586621679805037"><span class="annot"><a href="#local-6989586621679805037"><span class="hs-identifier hs-var">queryEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679805036"><span class="annot"><a href="#local-6989586621679805036"><span class="hs-identifier hs-var">keyEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679805035"><span class="annot"><a href="#local-6989586621679805035"><span class="hs-identifier hs-var">dropoutP</span></a></span></span><span> </span><span id="local-6989586621679805034"><span class="annot"><a href="#local-6989586621679805034"><span class="hs-identifier hs-var">eps</span></a></span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679805033"><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679805033"><span class="hs-identifier hs-var">generator</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-193"></span><span>    </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679805032"><span class="annot"><span class="annottext">generator' :: Generator device
</span><a href="#local-6989586621679805032"><span class="hs-identifier hs-var hs-var">generator'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SDevice device -&gt; Generator generatorDevice -&gt; Generator device
forall (generatorDevice' :: Device (DeviceType Nat))
       (generatorDevice :: Device (DeviceType Nat)).
SDevice generatorDevice'
-&gt; Generator generatorDevice -&gt; Generator generatorDevice'
</span><a href="Torch.GraduallyTyped.Random.html#sGeneratorToDevice"><span class="hs-identifier hs-var">sGeneratorToDevice</span></a></span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679805042"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679805033"><span class="hs-identifier hs-var">generator</span></a></span><span>
</span><span id="line-194"></span><span>        </span><span id="local-6989586621679805031"><span class="annot"><span class="annottext">multiHeadAttention :: IxStateT
  m
  (Generator device)
  (Generator device)
  (MultiHeadAttention
     style
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     keyEmbedDim
     keyEmbedDim)
</span><a href="#local-6989586621679805031"><span class="hs-identifier hs-var hs-var">multiHeadAttention</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(Generator device
 -&gt; m (MultiHeadAttention
         style
         gradient
         device
         dataType
         headDim
         headEmbedDim
         embedDim
         queryEmbedDim
         keyEmbedDim
         keyEmbedDim,
       Generator device))
-&gt; IxStateT
     m
     (Generator device)
     (Generator device)
     (MultiHeadAttention
        style
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        queryEmbedDim
        keyEmbedDim
        keyEmbedDim)
forall (m :: Type -&gt; Type) i j a.
(i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator device
  -&gt; m (MultiHeadAttention
          style
          gradient
          device
          dataType
          headDim
          headEmbedDim
          embedDim
          queryEmbedDim
          keyEmbedDim
          keyEmbedDim,
        Generator device))
 -&gt; IxStateT
      m
      (Generator device)
      (Generator device)
      (MultiHeadAttention
         style
         gradient
         device
         dataType
         headDim
         headEmbedDim
         embedDim
         queryEmbedDim
         keyEmbedDim
         keyEmbedDim))
-&gt; (MultiHeadAttentionSpec
      style
      gradient
      device
      dataType
      headDim
      headEmbedDim
      embedDim
      queryEmbedDim
      keyEmbedDim
      keyEmbedDim
    -&gt; Generator device
    -&gt; m (MultiHeadAttention
            style
            gradient
            device
            dataType
            headDim
            headEmbedDim
            embedDim
            queryEmbedDim
            keyEmbedDim
            keyEmbedDim,
          Generator device))
-&gt; MultiHeadAttentionSpec
     style
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     keyEmbedDim
     keyEmbedDim
-&gt; IxStateT
     m
     (Generator device)
     (Generator device)
     (MultiHeadAttention
        style
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        queryEmbedDim
        keyEmbedDim
        keyEmbedDim)
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">forall model (generatorDevice :: Device (DeviceType Nat)) output
       (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: Type -&gt; Type).
(HasInitialize model generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
ModelSpec model
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
forall (generatorDevice :: Device (DeviceType Nat)) output
       (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: Type -&gt; Type).
(HasInitialize
   multiHeadAttention generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
ModelSpec multiHeadAttention
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#initialize"><span class="hs-identifier hs-var">initialize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679805061"><span class="hs-identifier hs-type">multiHeadAttention</span></a></span><span> </span><span class="annot"><span class="annottext">(MultiHeadAttentionSpec
   style
   gradient
   device
   dataType
   headDim
   headEmbedDim
   embedDim
   queryEmbedDim
   keyEmbedDim
   keyEmbedDim
 -&gt; IxStateT
      m
      (Generator device)
      (Generator device)
      (MultiHeadAttention
         style
         gradient
         device
         dataType
         headDim
         headEmbedDim
         embedDim
         queryEmbedDim
         keyEmbedDim
         keyEmbedDim))
-&gt; MultiHeadAttentionSpec
     style
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     keyEmbedDim
     keyEmbedDim
-&gt; IxStateT
     m
     (Generator device)
     (Generator device)
     (MultiHeadAttention
        style
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        queryEmbedDim
        keyEmbedDim
        keyEmbedDim)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim headDim
-&gt; SDim headEmbedDim
-&gt; SDim embedDim
-&gt; SDim queryEmbedDim
-&gt; SDim keyEmbedDim
-&gt; SDim keyEmbedDim
-&gt; Double
-&gt; MultiHeadAttentionSpec
     style
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     keyEmbedDim
     keyEmbedDim
forall (style :: TransformerStyle)
       (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (headDim :: Dim (Name Symbol) (Size Nat))
       (headEmbedDim :: Dim (Name Symbol) (Size Nat))
       (embedDim :: Dim (Name Symbol) (Size Nat))
       (queryEmbedDim :: Dim (Name Symbol) (Size Nat))
       (keyEmbedDim :: Dim (Name Symbol) (Size Nat))
       (valueEmbedDim :: Dim (Name Symbol) (Size Nat)).
STransformerStyle style
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim headDim
-&gt; SDim headEmbedDim
-&gt; SDim embedDim
-&gt; SDim queryEmbedDim
-&gt; SDim keyEmbedDim
-&gt; SDim valueEmbedDim
-&gt; Double
-&gt; MultiHeadAttentionSpec
     style
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     keyEmbedDim
     valueEmbedDim
</span><a href="Torch.GraduallyTyped.NN.Transformer.MultiHeadAttention.html#MultiHeadAttentionSpec"><span class="hs-identifier hs-var">MultiHeadAttentionSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="#local-6989586621679805044"><span class="hs-identifier hs-var">style</span></a></span><span> </span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679805043"><span class="hs-identifier hs-var">gradient</span></a></span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679805042"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679805041"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="annot"><span class="annottext">SDim headDim
</span><a href="#local-6989586621679805040"><span class="hs-identifier hs-var">headDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim headEmbedDim
</span><a href="#local-6989586621679805039"><span class="hs-identifier hs-var">headEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim embedDim
</span><a href="#local-6989586621679805038"><span class="hs-identifier hs-var">embedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim queryEmbedDim
</span><a href="#local-6989586621679805037"><span class="hs-identifier hs-var">queryEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim keyEmbedDim
</span><a href="#local-6989586621679805036"><span class="hs-identifier hs-var">keyEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim keyEmbedDim
</span><a href="#local-6989586621679805036"><span class="hs-identifier hs-var">keyEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679805035"><span class="hs-identifier hs-var">dropoutP</span></a></span><span>
</span><span id="line-195"></span><span>        </span><span id="local-6989586621679805027"><span class="annot"><span class="annottext">layerNormWithoutBiasSpec :: LayerNormSpec
  'WithoutBias gradient device dataType ('Shape '[queryEmbedDim])
</span><a href="#local-6989586621679805027"><span class="hs-identifier hs-var hs-var">layerNormWithoutBiasSpec</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SHasBias 'WithoutBias
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SShape ('Shape '[queryEmbedDim])
-&gt; Double
-&gt; LayerNormSpec
     'WithoutBias gradient device dataType ('Shape '[queryEmbedDim])
forall (hasBias :: HasBias) (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (normalizedShape :: Shape [Dim (Name Symbol) (Size Nat)]).
SHasBias hasBias
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SShape normalizedShape
-&gt; Double
-&gt; LayerNormSpec hasBias gradient device dataType normalizedShape
</span><a href="Torch.GraduallyTyped.NN.Normalization.html#LayerNormSpec"><span class="hs-identifier hs-var">LayerNormSpec</span></a></span><span> </span><span class="annot"><span class="annottext">SHasBias 'WithoutBias
</span><a href="Torch.GraduallyTyped.NN.Type.html#SWithoutBias"><span class="hs-identifier hs-var">SWithoutBias</span></a></span><span> </span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679805043"><span class="hs-identifier hs-var">gradient</span></a></span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679805042"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679805041"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SList '[queryEmbedDim] -&gt; SShape ('Shape '[queryEmbedDim])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList '[queryEmbedDim] -&gt; SShape ('Shape '[queryEmbedDim]))
-&gt; SList '[queryEmbedDim] -&gt; SShape ('Shape '[queryEmbedDim])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SDim queryEmbedDim
</span><a href="#local-6989586621679805037"><span class="hs-identifier hs-var">queryEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim queryEmbedDim -&gt; SList '[] -&gt; SList '[queryEmbedDim]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679805034"><span class="hs-identifier hs-var">eps</span></a></span><span>
</span><span id="line-196"></span><span>        </span><span id="local-6989586621679805022"><span class="annot"><span class="annottext">layerNormWithBiasSpec :: LayerNormSpec
  'WithBias gradient device dataType ('Shape '[queryEmbedDim])
</span><a href="#local-6989586621679805022"><span class="hs-identifier hs-var hs-var">layerNormWithBiasSpec</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SHasBias 'WithBias
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SShape ('Shape '[queryEmbedDim])
-&gt; Double
-&gt; LayerNormSpec
     'WithBias gradient device dataType ('Shape '[queryEmbedDim])
forall (hasBias :: HasBias) (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (normalizedShape :: Shape [Dim (Name Symbol) (Size Nat)]).
SHasBias hasBias
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SShape normalizedShape
-&gt; Double
-&gt; LayerNormSpec hasBias gradient device dataType normalizedShape
</span><a href="Torch.GraduallyTyped.NN.Normalization.html#LayerNormSpec"><span class="hs-identifier hs-var">LayerNormSpec</span></a></span><span> </span><span class="annot"><span class="annottext">SHasBias 'WithBias
</span><a href="Torch.GraduallyTyped.NN.Type.html#SWithBias"><span class="hs-identifier hs-var">SWithBias</span></a></span><span> </span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679805043"><span class="hs-identifier hs-var">gradient</span></a></span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679805042"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679805041"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SList '[queryEmbedDim] -&gt; SShape ('Shape '[queryEmbedDim])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList '[queryEmbedDim] -&gt; SShape ('Shape '[queryEmbedDim]))
-&gt; SList '[queryEmbedDim] -&gt; SShape ('Shape '[queryEmbedDim])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SDim queryEmbedDim
</span><a href="#local-6989586621679805037"><span class="hs-identifier hs-var">queryEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim queryEmbedDim -&gt; SList '[] -&gt; SList '[queryEmbedDim]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679805034"><span class="hs-identifier hs-var">eps</span></a></span><span>
</span><span id="line-197"></span><span>        </span><span id="local-6989586621679805020"><span class="annot"><span class="annottext">layerNorm :: IxStateT m (Generator device) (Generator device) layerNorm
</span><a href="#local-6989586621679805020"><span class="hs-identifier hs-var hs-var">layerNorm</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(Generator device -&gt; m (layerNorm, Generator device))
-&gt; IxStateT m (Generator device) (Generator device) layerNorm
forall (m :: Type -&gt; Type) i j a.
(i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator device -&gt; m (layerNorm, Generator device))
 -&gt; IxStateT m (Generator device) (Generator device) layerNorm)
-&gt; (ModelSpec layerNorm
    -&gt; Generator device -&gt; m (layerNorm, Generator device))
-&gt; ModelSpec layerNorm
-&gt; IxStateT m (Generator device) (Generator device) layerNorm
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">forall model (generatorDevice :: Device (DeviceType Nat)) output
       (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: Type -&gt; Type).
(HasInitialize model generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
ModelSpec model
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
forall (generatorDevice :: Device (DeviceType Nat)) output
       (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: Type -&gt; Type).
(HasInitialize
   layerNorm generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
ModelSpec layerNorm
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#initialize"><span class="hs-identifier hs-var">initialize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679805051"><span class="hs-identifier hs-type">layerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">(ModelSpec layerNorm
 -&gt; IxStateT m (Generator device) (Generator device) layerNorm)
-&gt; ModelSpec layerNorm
-&gt; IxStateT m (Generator device) (Generator device) layerNorm
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-keyword">case</span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="#local-6989586621679805044"><span class="hs-identifier hs-var">style</span></a></span><span> </span><span class="hs-keyword">of</span><span>
</span><span id="line-198"></span><span>          </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">ModelSpec layerNorm
LayerNormSpec
  'WithoutBias gradient device dataType ('Shape '[queryEmbedDim])
</span><a href="#local-6989586621679805027"><span class="hs-identifier hs-var">layerNormWithoutBiasSpec</span></a></span><span>
</span><span id="line-199"></span><span>          </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">ModelSpec layerNorm
LayerNormSpec
  'WithoutBias gradient device dataType ('Shape '[queryEmbedDim])
</span><a href="#local-6989586621679805027"><span class="hs-identifier hs-var">layerNormWithoutBiasSpec</span></a></span><span>
</span><span id="line-200"></span><span>          </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">ModelSpec layerNorm
LayerNormSpec
  'WithBias gradient device dataType ('Shape '[queryEmbedDim])
</span><a href="#local-6989586621679805022"><span class="hs-identifier hs-var">layerNormWithBiasSpec</span></a></span><span>
</span><span id="line-201"></span><span>          </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">ModelSpec layerNorm
LayerNormSpec
  'WithBias gradient device dataType ('Shape '[queryEmbedDim])
</span><a href="#local-6989586621679805022"><span class="hs-identifier hs-var">layerNormWithBiasSpec</span></a></span><span>
</span><span id="line-202"></span><span>          </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">ModelSpec layerNorm
LayerNormSpec
  'WithBias gradient device dataType ('Shape '[queryEmbedDim])
</span><a href="#local-6989586621679805022"><span class="hs-identifier hs-var">layerNormWithBiasSpec</span></a></span><span>
</span><span id="line-203"></span><span>          </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">ModelSpec layerNorm
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-204"></span><span>          </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">ModelSpec layerNorm
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-205"></span><span>          </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SGPT2"><span class="hs-identifier hs-var">SGPT2</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">ModelSpec layerNorm
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-206"></span><span>        </span><span id="local-6989586621679805010"><span class="annot"><span class="annottext">dropout :: IxStateT m (Generator device) (Generator device) Dropout
</span><a href="#local-6989586621679805010"><span class="hs-identifier hs-var hs-var">dropout</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(Generator device -&gt; m (Dropout, Generator device))
-&gt; IxStateT m (Generator device) (Generator device) Dropout
forall (m :: Type -&gt; Type) i j a.
(i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator device -&gt; m (Dropout, Generator device))
 -&gt; IxStateT m (Generator device) (Generator device) Dropout)
-&gt; (Dropout -&gt; Generator device -&gt; m (Dropout, Generator device))
-&gt; Dropout
-&gt; IxStateT m (Generator device) (Generator device) Dropout
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Dropout -&gt; Generator device -&gt; m (Dropout, Generator device)
forall model (generatorDevice :: Device (DeviceType Nat)) output
       (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: Type -&gt; Type).
(HasInitialize model generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
ModelSpec model
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#initialize"><span class="hs-identifier hs-var">initialize</span></a></span><span> </span><span class="annot"><span class="annottext">(Dropout
 -&gt; IxStateT m (Generator device) (Generator device) Dropout)
-&gt; Dropout
-&gt; IxStateT m (Generator device) (Generator device) Dropout
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">Double -&gt; Dropout
</span><a href="Torch.GraduallyTyped.NN.Dropout.html#Dropout"><span class="hs-identifier hs-var">Dropout</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679805035"><span class="hs-identifier hs-var">dropoutP</span></a></span><span>
</span><span id="line-207"></span><span>     </span><span class="hs-keyword">in</span><span> </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator device)
  (Generator device)
  (CrossAttention
     style
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     keyEmbedDim)
-&gt; Generator device
-&gt; m (CrossAttention
        style
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        queryEmbedDim
        keyEmbedDim,
      Generator device)
forall (m :: Type -&gt; Type) i j a. IxStateT m i j a -&gt; i -&gt; m (a, j)
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var hs-var">runIxStateT</span></a></span><span>
</span><span id="line-208"></span><span>          </span><span class="hs-special">(</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">MultiHeadAttention
  style
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  queryEmbedDim
  keyEmbedDim
  keyEmbedDim
-&gt; layerNorm
-&gt; Dropout
-&gt; GCrossAttention
     (MultiHeadAttention
        style
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        queryEmbedDim
        keyEmbedDim
        keyEmbedDim)
     layerNorm
     Dropout
forall mha layerNorm dropout.
mha
-&gt; layerNorm -&gt; dropout -&gt; GCrossAttention mha layerNorm dropout
</span><a href="Torch.GraduallyTyped.NN.Transformer.CrossAttention.html#GCrossAttention"><span class="hs-identifier hs-var">GCrossAttention</span></a></span><span> </span><span class="annot"><span class="annottext">(MultiHeadAttention
   style
   gradient
   device
   dataType
   headDim
   headEmbedDim
   embedDim
   queryEmbedDim
   keyEmbedDim
   keyEmbedDim
 -&gt; layerNorm
 -&gt; Dropout
 -&gt; GCrossAttention
      (MultiHeadAttention
         style
         gradient
         device
         dataType
         headDim
         headEmbedDim
         embedDim
         queryEmbedDim
         keyEmbedDim
         keyEmbedDim)
      layerNorm
      Dropout)
-&gt; IxStateT
     m
     (Generator device)
     (Generator device)
     (MultiHeadAttention
        style
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        queryEmbedDim
        keyEmbedDim
        keyEmbedDim)
-&gt; IxStateT
     m
     (Generator device)
     (Generator device)
     (layerNorm
      -&gt; Dropout
      -&gt; GCrossAttention
           (MultiHeadAttention
              style
              gradient
              device
              dataType
              headDim
              headEmbedDim
              embedDim
              queryEmbedDim
              keyEmbedDim
              keyEmbedDim)
           layerNorm
           Dropout)
forall k1 k2 (f :: k1 -&gt; k2 -&gt; Type -&gt; Type) a b (j :: k1)
       (k3 :: k2).
IxFunctor f =&gt;
(a -&gt; b) -&gt; f j k3 a -&gt; f j k3 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&lt;&lt;$&gt;&gt;</span></a></span><span> </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator device)
  (Generator device)
  (MultiHeadAttention
     style
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     keyEmbedDim
     keyEmbedDim)
</span><a href="#local-6989586621679805031"><span class="hs-identifier hs-var">multiHeadAttention</span></a></span><span> </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator device)
  (Generator device)
  (layerNorm
   -&gt; Dropout
   -&gt; GCrossAttention
        (MultiHeadAttention
           style
           gradient
           device
           dataType
           headDim
           headEmbedDim
           embedDim
           queryEmbedDim
           keyEmbedDim
           keyEmbedDim)
        layerNorm
        Dropout)
-&gt; IxStateT m (Generator device) (Generator device) layerNorm
-&gt; IxStateT
     m
     (Generator device)
     (Generator device)
     (Dropout
      -&gt; GCrossAttention
           (MultiHeadAttention
              style
              gradient
              device
              dataType
              headDim
              headEmbedDim
              embedDim
              queryEmbedDim
              keyEmbedDim
              keyEmbedDim)
           layerNorm
           Dropout)
forall k1 (f :: k1 -&gt; k1 -&gt; Type -&gt; Type) (i :: k1) (j :: k1) a b
       (k2 :: k1).
IxApplicative f =&gt;
f i j (a -&gt; b) -&gt; f j k2 a -&gt; f i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&lt;&lt;*&gt;&gt;</span></a></span><span> </span><span class="annot"><span class="annottext">IxStateT m (Generator device) (Generator device) layerNorm
</span><a href="#local-6989586621679805020"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator device)
  (Generator device)
  (Dropout
   -&gt; GCrossAttention
        (MultiHeadAttention
           style
           gradient
           device
           dataType
           headDim
           headEmbedDim
           embedDim
           queryEmbedDim
           keyEmbedDim
           keyEmbedDim)
        layerNorm
        Dropout)
-&gt; IxStateT m (Generator device) (Generator device) Dropout
-&gt; IxStateT
     m
     (Generator device)
     (Generator device)
     (GCrossAttention
        (MultiHeadAttention
           style
           gradient
           device
           dataType
           headDim
           headEmbedDim
           embedDim
           queryEmbedDim
           keyEmbedDim
           keyEmbedDim)
        layerNorm
        Dropout)
forall k1 (f :: k1 -&gt; k1 -&gt; Type -&gt; Type) (i :: k1) (j :: k1) a b
       (k2 :: k1).
IxApplicative f =&gt;
f i j (a -&gt; b) -&gt; f j k2 a -&gt; f i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&lt;&lt;*&gt;&gt;</span></a></span><span> </span><span class="annot"><span class="annottext">IxStateT m (Generator device) (Generator device) Dropout
</span><a href="#local-6989586621679805010"><span class="hs-identifier hs-var">dropout</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-209"></span><span>              </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator device)
  (Generator device)
  (GCrossAttention
     (MultiHeadAttention
        style
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        queryEmbedDim
        keyEmbedDim
        keyEmbedDim)
     layerNorm
     Dropout)
-&gt; (GCrossAttention
      (MultiHeadAttention
         style
         gradient
         device
         dataType
         headDim
         headEmbedDim
         embedDim
         queryEmbedDim
         keyEmbedDim
         keyEmbedDim)
      layerNorm
      Dropout
    -&gt; IxStateT
         m
         (Generator device)
         (Generator device)
         (CrossAttention
            style
            gradient
            device
            dataType
            headDim
            headEmbedDim
            embedDim
            queryEmbedDim
            keyEmbedDim))
-&gt; IxStateT
     m
     (Generator device)
     (Generator device)
     (CrossAttention
        style
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        queryEmbedDim
        keyEmbedDim)
forall k1 (m :: k1 -&gt; k1 -&gt; Type -&gt; Type) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">CrossAttention
  style
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  queryEmbedDim
  keyEmbedDim
-&gt; IxStateT
     m
     (Generator device)
     (Generator device)
     (CrossAttention
        style
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        queryEmbedDim
        keyEmbedDim)
forall k (m :: k -&gt; k -&gt; Type -&gt; Type) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">(CrossAttention
   style
   gradient
   device
   dataType
   headDim
   headEmbedDim
   embedDim
   queryEmbedDim
   keyEmbedDim
 -&gt; IxStateT
      m
      (Generator device)
      (Generator device)
      (CrossAttention
         style
         gradient
         device
         dataType
         headDim
         headEmbedDim
         embedDim
         queryEmbedDim
         keyEmbedDim))
-&gt; (GCrossAttention
      (MultiHeadAttention
         style
         gradient
         device
         dataType
         headDim
         headEmbedDim
         embedDim
         queryEmbedDim
         keyEmbedDim
         keyEmbedDim)
      layerNorm
      Dropout
    -&gt; CrossAttention
         style
         gradient
         device
         dataType
         headDim
         headEmbedDim
         embedDim
         queryEmbedDim
         keyEmbedDim)
-&gt; GCrossAttention
     (MultiHeadAttention
        style
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        queryEmbedDim
        keyEmbedDim
        keyEmbedDim)
     layerNorm
     Dropout
-&gt; IxStateT
     m
     (Generator device)
     (Generator device)
     (CrossAttention
        style
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        queryEmbedDim
        keyEmbedDim)
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">GCrossAttention
  (MultiHeadAttention
     style
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     keyEmbedDim
     keyEmbedDim)
  layerNorm
  Dropout
-&gt; CrossAttention
     style
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     keyEmbedDim
forall (style :: TransformerStyle)
       (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (headDim :: Dim (Name Symbol) (Size Nat))
       (headEmbedDim :: Dim (Name Symbol) (Size Nat))
       (embedDim :: Dim (Name Symbol) (Size Nat))
       (queryEmbedDim :: Dim (Name Symbol) (Size Nat))
       (keyEmbedDim :: Dim (Name Symbol) (Size Nat)).
GCrossAttention
  (CAMultiheadAttentionF
     style
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     keyEmbedDim)
  (CALayerNormF style gradient device dataType queryEmbedDim)
  (CADropoutF style)
-&gt; CrossAttention
     style
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     keyEmbedDim
</span><a href="Torch.GraduallyTyped.NN.Transformer.CrossAttention.html#CrossAttention"><span class="hs-identifier hs-var">CrossAttention</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-210"></span><span>          </span><span class="hs-special">)</span><span>
</span><span id="line-211"></span><span>          </span><span class="annot"><span class="annottext">Generator device
</span><a href="#local-6989586621679805032"><span class="hs-identifier hs-var">generator'</span></a></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span>
</span><span id="line-212"></span><span>
</span><span id="line-213"></span><span id="local-6989586621679804999"><span id="local-6989586621679805000"><span id="local-6989586621679805001"><span id="local-6989586621679805002"><span id="local-6989586621679805003"><span id="local-6989586621679805004"><span id="local-6989586621679805005"><span id="local-6989586621679805006"><span id="local-6989586621679805007"><span class="hs-keyword">instance</span><span>
</span><span id="line-214"></span><span>  </span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-type">SingI</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805007"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-215"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasStateDict"><span class="hs-identifier hs-type">HasStateDict</span></a></span><span>
</span><span id="line-216"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.CrossAttention.html#CrossAttention"><span class="hs-identifier hs-type">CrossAttention</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805007"><span class="hs-identifier hs-type">style</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805006"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805005"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805004"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805003"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805002"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805001"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679805000"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804999"><span class="hs-identifier hs-type">keyEmbedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-217"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-218"></span><span>  </span><span id="local-6989586621679804995"><span class="annot"><span class="annottext">fromStateDict :: ModelSpec
  (CrossAttention
     style
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     keyEmbedDim)
-&gt; StateDictKey
-&gt; m (CrossAttention
        style
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        queryEmbedDim
        keyEmbedDim)
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var hs-var hs-var hs-var">fromStateDict</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.CrossAttention.html#CrossAttentionSpec"><span class="hs-identifier hs-type">CrossAttentionSpec</span></a></span><span> </span><span id="local-6989586621679804993"><span class="annot"><a href="#local-6989586621679804993"><span class="hs-identifier hs-var">style</span></a></span></span><span> </span><span id="local-6989586621679804992"><span class="annot"><a href="#local-6989586621679804992"><span class="hs-identifier hs-var">gradient</span></a></span></span><span> </span><span id="local-6989586621679804991"><span class="annot"><a href="#local-6989586621679804991"><span class="hs-identifier hs-var">device</span></a></span></span><span> </span><span id="local-6989586621679804990"><span class="annot"><a href="#local-6989586621679804990"><span class="hs-identifier hs-var">dataType</span></a></span></span><span> </span><span id="local-6989586621679804989"><span class="annot"><a href="#local-6989586621679804989"><span class="hs-identifier hs-var">headDim</span></a></span></span><span> </span><span id="local-6989586621679804988"><span class="annot"><a href="#local-6989586621679804988"><span class="hs-identifier hs-var">headEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679804987"><span class="annot"><a href="#local-6989586621679804987"><span class="hs-identifier hs-var">embedDim</span></a></span></span><span> </span><span id="local-6989586621679804986"><span class="annot"><a href="#local-6989586621679804986"><span class="hs-identifier hs-var">queryEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679804985"><span class="annot"><a href="#local-6989586621679804985"><span class="hs-identifier hs-var">keyEmbedDim</span></a></span></span><span> </span><span id="local-6989586621679804984"><span class="annot"><a href="#local-6989586621679804984"><span class="hs-identifier hs-var">dropoutP</span></a></span></span><span> </span><span id="local-6989586621679804983"><span class="annot"><a href="#local-6989586621679804983"><span class="hs-identifier hs-var">eps</span></a></span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679804982"><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679804982"><span class="hs-identifier hs-var">k</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-219"></span><span>    </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679804981"><span class="annot"><span class="annottext">multiHeadAttentionSpec :: MultiHeadAttentionSpec
  style
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  queryEmbedDim
  keyEmbedDim
  keyEmbedDim
</span><a href="#local-6989586621679804981"><span class="hs-identifier hs-var hs-var">multiHeadAttentionSpec</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim headDim
-&gt; SDim headEmbedDim
-&gt; SDim embedDim
-&gt; SDim queryEmbedDim
-&gt; SDim keyEmbedDim
-&gt; SDim keyEmbedDim
-&gt; Double
-&gt; MultiHeadAttentionSpec
     style
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     keyEmbedDim
     keyEmbedDim
forall (style :: TransformerStyle)
       (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (headDim :: Dim (Name Symbol) (Size Nat))
       (headEmbedDim :: Dim (Name Symbol) (Size Nat))
       (embedDim :: Dim (Name Symbol) (Size Nat))
       (queryEmbedDim :: Dim (Name Symbol) (Size Nat))
       (keyEmbedDim :: Dim (Name Symbol) (Size Nat))
       (valueEmbedDim :: Dim (Name Symbol) (Size Nat)).
STransformerStyle style
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim headDim
-&gt; SDim headEmbedDim
-&gt; SDim embedDim
-&gt; SDim queryEmbedDim
-&gt; SDim keyEmbedDim
-&gt; SDim valueEmbedDim
-&gt; Double
-&gt; MultiHeadAttentionSpec
     style
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     keyEmbedDim
     valueEmbedDim
</span><a href="Torch.GraduallyTyped.NN.Transformer.MultiHeadAttention.html#MultiHeadAttentionSpec"><span class="hs-identifier hs-var">MultiHeadAttentionSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="#local-6989586621679804993"><span class="hs-identifier hs-var">style</span></a></span><span> </span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679804992"><span class="hs-identifier hs-var">gradient</span></a></span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679804991"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679804990"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="annot"><span class="annottext">SDim headDim
</span><a href="#local-6989586621679804989"><span class="hs-identifier hs-var">headDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim headEmbedDim
</span><a href="#local-6989586621679804988"><span class="hs-identifier hs-var">headEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim embedDim
</span><a href="#local-6989586621679804987"><span class="hs-identifier hs-var">embedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim queryEmbedDim
</span><a href="#local-6989586621679804986"><span class="hs-identifier hs-var">queryEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim keyEmbedDim
</span><a href="#local-6989586621679804985"><span class="hs-identifier hs-var">keyEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim keyEmbedDim
</span><a href="#local-6989586621679804985"><span class="hs-identifier hs-var">keyEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679804984"><span class="hs-identifier hs-var">dropoutP</span></a></span><span>
</span><span id="line-220"></span><span>        </span><span id="local-6989586621679804980"><span class="annot"><span class="annottext">multiHeadAttention :: STransformerStyle style
-&gt; m (MultiHeadAttention
        style
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        queryEmbedDim
        keyEmbedDim
        keyEmbedDim)
</span><a href="#local-6989586621679804980"><span class="hs-identifier hs-var hs-var">multiHeadAttention</span></a></span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (MultiHeadAttention
     'T5
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     keyEmbedDim
     keyEmbedDim)
-&gt; StateDictKey
-&gt; m (MultiHeadAttention
        'T5
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        queryEmbedDim
        keyEmbedDim
        keyEmbedDim)
forall model (m :: Type -&gt; Type).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
ModelSpec model -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (MultiHeadAttention
     'T5
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     keyEmbedDim
     keyEmbedDim)
MultiHeadAttentionSpec
  style
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  queryEmbedDim
  keyEmbedDim
  keyEmbedDim
</span><a href="#local-6989586621679804981"><span class="hs-identifier hs-var">multiHeadAttentionSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679804982"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;EncDecAttention.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-221"></span><span>        </span><span class="annot"><a href="#local-6989586621679804980"><span class="hs-identifier hs-var">multiHeadAttention</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (MultiHeadAttention
     'ByT5
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     keyEmbedDim
     keyEmbedDim)
-&gt; StateDictKey
-&gt; m (MultiHeadAttention
        'ByT5
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        queryEmbedDim
        keyEmbedDim
        keyEmbedDim)
forall model (m :: Type -&gt; Type).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
ModelSpec model -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (MultiHeadAttention
     'ByT5
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     keyEmbedDim
     keyEmbedDim)
MultiHeadAttentionSpec
  style
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  queryEmbedDim
  keyEmbedDim
  keyEmbedDim
</span><a href="#local-6989586621679804981"><span class="hs-identifier hs-var">multiHeadAttentionSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679804982"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;EncDecAttention.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-222"></span><span>        </span><span class="annot"><a href="#local-6989586621679804980"><span class="hs-identifier hs-var">multiHeadAttention</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (MultiHeadAttention
     'BART
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     keyEmbedDim
     keyEmbedDim)
-&gt; StateDictKey
-&gt; m (MultiHeadAttention
        'BART
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        queryEmbedDim
        keyEmbedDim
        keyEmbedDim)
forall model (m :: Type -&gt; Type).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
ModelSpec model -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (MultiHeadAttention
     'BART
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     keyEmbedDim
     keyEmbedDim)
MultiHeadAttentionSpec
  style
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  queryEmbedDim
  keyEmbedDim
  keyEmbedDim
</span><a href="#local-6989586621679804981"><span class="hs-identifier hs-var">multiHeadAttentionSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679804982"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;encoder_attn.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-223"></span><span>        </span><span class="annot"><a href="#local-6989586621679804980"><span class="hs-identifier hs-var">multiHeadAttention</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (MultiHeadAttention
     'MBART
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     keyEmbedDim
     keyEmbedDim)
-&gt; StateDictKey
-&gt; m (MultiHeadAttention
        'MBART
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        queryEmbedDim
        keyEmbedDim
        keyEmbedDim)
forall model (m :: Type -&gt; Type).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
ModelSpec model -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (MultiHeadAttention
     'MBART
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     keyEmbedDim
     keyEmbedDim)
MultiHeadAttentionSpec
  style
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  queryEmbedDim
  keyEmbedDim
  keyEmbedDim
</span><a href="#local-6989586621679804981"><span class="hs-identifier hs-var">multiHeadAttentionSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679804982"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;encoder_attn.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-224"></span><span>        </span><span class="annot"><a href="#local-6989586621679804980"><span class="hs-identifier hs-var">multiHeadAttention</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (MultiHeadAttention
     'Pegasus
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     keyEmbedDim
     keyEmbedDim)
-&gt; StateDictKey
-&gt; m (MultiHeadAttention
        'Pegasus
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        queryEmbedDim
        keyEmbedDim
        keyEmbedDim)
forall model (m :: Type -&gt; Type).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
ModelSpec model -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (MultiHeadAttention
     'Pegasus
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     keyEmbedDim
     keyEmbedDim)
MultiHeadAttentionSpec
  style
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  queryEmbedDim
  keyEmbedDim
  keyEmbedDim
</span><a href="#local-6989586621679804981"><span class="hs-identifier hs-var">multiHeadAttentionSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679804982"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;encoder_attn.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-225"></span><span>        </span><span class="annot"><a href="#local-6989586621679804980"><span class="hs-identifier hs-var">multiHeadAttention</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">m (MultiHeadAttention
     style
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     keyEmbedDim
     keyEmbedDim)
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-226"></span><span>        </span><span class="annot"><a href="#local-6989586621679804980"><span class="hs-identifier hs-var">multiHeadAttention</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">m (MultiHeadAttention
     style
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     keyEmbedDim
     keyEmbedDim)
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-227"></span><span>        </span><span class="annot"><a href="#local-6989586621679804980"><span class="hs-identifier hs-var">multiHeadAttention</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SGPT2"><span class="hs-identifier hs-var">SGPT2</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">m (MultiHeadAttention
     style
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     keyEmbedDim
     keyEmbedDim)
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-228"></span><span>        </span><span id="local-6989586621679804979"><span class="annot"><span class="annottext">layerNormWithoutBiasSpec :: LayerNormSpec
  'WithoutBias gradient device dataType ('Shape '[queryEmbedDim])
</span><a href="#local-6989586621679804979"><span class="hs-identifier hs-var hs-var">layerNormWithoutBiasSpec</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SHasBias 'WithoutBias
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SShape ('Shape '[queryEmbedDim])
-&gt; Double
-&gt; LayerNormSpec
     'WithoutBias gradient device dataType ('Shape '[queryEmbedDim])
forall (hasBias :: HasBias) (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (normalizedShape :: Shape [Dim (Name Symbol) (Size Nat)]).
SHasBias hasBias
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SShape normalizedShape
-&gt; Double
-&gt; LayerNormSpec hasBias gradient device dataType normalizedShape
</span><a href="Torch.GraduallyTyped.NN.Normalization.html#LayerNormSpec"><span class="hs-identifier hs-var">LayerNormSpec</span></a></span><span> </span><span class="annot"><span class="annottext">SHasBias 'WithoutBias
</span><a href="Torch.GraduallyTyped.NN.Type.html#SWithoutBias"><span class="hs-identifier hs-var">SWithoutBias</span></a></span><span> </span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679804992"><span class="hs-identifier hs-var">gradient</span></a></span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679804991"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679804990"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SList '[queryEmbedDim] -&gt; SShape ('Shape '[queryEmbedDim])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList '[queryEmbedDim] -&gt; SShape ('Shape '[queryEmbedDim]))
-&gt; SList '[queryEmbedDim] -&gt; SShape ('Shape '[queryEmbedDim])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SDim queryEmbedDim
</span><a href="#local-6989586621679804986"><span class="hs-identifier hs-var">queryEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim queryEmbedDim -&gt; SList '[] -&gt; SList '[queryEmbedDim]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679804983"><span class="hs-identifier hs-var">eps</span></a></span><span>
</span><span id="line-229"></span><span>        </span><span id="local-6989586621679804978"><span class="annot"><span class="annottext">layerNormWithBiasSpec :: LayerNormSpec
  'WithBias gradient device dataType ('Shape '[queryEmbedDim])
</span><a href="#local-6989586621679804978"><span class="hs-identifier hs-var hs-var">layerNormWithBiasSpec</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SHasBias 'WithBias
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SShape ('Shape '[queryEmbedDim])
-&gt; Double
-&gt; LayerNormSpec
     'WithBias gradient device dataType ('Shape '[queryEmbedDim])
forall (hasBias :: HasBias) (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (normalizedShape :: Shape [Dim (Name Symbol) (Size Nat)]).
SHasBias hasBias
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SShape normalizedShape
-&gt; Double
-&gt; LayerNormSpec hasBias gradient device dataType normalizedShape
</span><a href="Torch.GraduallyTyped.NN.Normalization.html#LayerNormSpec"><span class="hs-identifier hs-var">LayerNormSpec</span></a></span><span> </span><span class="annot"><span class="annottext">SHasBias 'WithBias
</span><a href="Torch.GraduallyTyped.NN.Type.html#SWithBias"><span class="hs-identifier hs-var">SWithBias</span></a></span><span> </span><span class="annot"><span class="annottext">SGradient gradient
</span><a href="#local-6989586621679804992"><span class="hs-identifier hs-var">gradient</span></a></span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679804991"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679804990"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SList '[queryEmbedDim] -&gt; SShape ('Shape '[queryEmbedDim])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList '[queryEmbedDim] -&gt; SShape ('Shape '[queryEmbedDim]))
-&gt; SList '[queryEmbedDim] -&gt; SShape ('Shape '[queryEmbedDim])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SDim queryEmbedDim
</span><a href="#local-6989586621679804986"><span class="hs-identifier hs-var">queryEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim queryEmbedDim -&gt; SList '[] -&gt; SList '[queryEmbedDim]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679804983"><span class="hs-identifier hs-var">eps</span></a></span><span>
</span><span id="line-230"></span><span>        </span><span id="local-6989586621679804977"><span class="annot"><span class="annottext">layerNorm :: STransformerStyle style
-&gt; m (CALayerNormF style gradient device dataType queryEmbedDim)
</span><a href="#local-6989586621679804977"><span class="hs-identifier hs-var hs-var">layerNorm</span></a></span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (LayerNorm
     'WithoutBias gradient device dataType ('Shape '[queryEmbedDim]))
-&gt; StateDictKey
-&gt; m (LayerNorm
        'WithoutBias gradient device dataType ('Shape '[queryEmbedDim]))
forall model (m :: Type -&gt; Type).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
ModelSpec model -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (LayerNorm
     'WithoutBias gradient device dataType ('Shape '[queryEmbedDim]))
LayerNormSpec
  'WithoutBias gradient device dataType ('Shape '[queryEmbedDim])
</span><a href="#local-6989586621679804979"><span class="hs-identifier hs-var">layerNormWithoutBiasSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679804982"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;layer_norm.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-231"></span><span>        </span><span class="annot"><a href="#local-6989586621679804977"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (LayerNorm
     'WithoutBias gradient device dataType ('Shape '[queryEmbedDim]))
-&gt; StateDictKey
-&gt; m (LayerNorm
        'WithoutBias gradient device dataType ('Shape '[queryEmbedDim]))
forall model (m :: Type -&gt; Type).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
ModelSpec model -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (LayerNorm
     'WithoutBias gradient device dataType ('Shape '[queryEmbedDim]))
LayerNormSpec
  'WithoutBias gradient device dataType ('Shape '[queryEmbedDim])
</span><a href="#local-6989586621679804979"><span class="hs-identifier hs-var">layerNormWithoutBiasSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679804982"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;layer_norm.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-232"></span><span>        </span><span class="annot"><a href="#local-6989586621679804977"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (LayerNorm
     'WithBias gradient device dataType ('Shape '[queryEmbedDim]))
-&gt; StateDictKey
-&gt; m (LayerNorm
        'WithBias gradient device dataType ('Shape '[queryEmbedDim]))
forall model (m :: Type -&gt; Type).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
ModelSpec model -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (LayerNorm
     'WithBias gradient device dataType ('Shape '[queryEmbedDim]))
LayerNormSpec
  'WithBias gradient device dataType ('Shape '[queryEmbedDim])
</span><a href="#local-6989586621679804978"><span class="hs-identifier hs-var">layerNormWithBiasSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679804982"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;encoder_attn_layer_norm.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-233"></span><span>        </span><span class="annot"><a href="#local-6989586621679804977"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (LayerNorm
     'WithBias gradient device dataType ('Shape '[queryEmbedDim]))
-&gt; StateDictKey
-&gt; m (LayerNorm
        'WithBias gradient device dataType ('Shape '[queryEmbedDim]))
forall model (m :: Type -&gt; Type).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
ModelSpec model -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (LayerNorm
     'WithBias gradient device dataType ('Shape '[queryEmbedDim]))
LayerNormSpec
  'WithBias gradient device dataType ('Shape '[queryEmbedDim])
</span><a href="#local-6989586621679804978"><span class="hs-identifier hs-var">layerNormWithBiasSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679804982"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;encoder_attn_layer_norm.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-234"></span><span>        </span><span class="annot"><a href="#local-6989586621679804977"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (LayerNorm
     'WithBias gradient device dataType ('Shape '[queryEmbedDim]))
-&gt; StateDictKey
-&gt; m (LayerNorm
        'WithBias gradient device dataType ('Shape '[queryEmbedDim]))
forall model (m :: Type -&gt; Type).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
ModelSpec model -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">ModelSpec
  (LayerNorm
     'WithBias gradient device dataType ('Shape '[queryEmbedDim]))
LayerNormSpec
  'WithBias gradient device dataType ('Shape '[queryEmbedDim])
</span><a href="#local-6989586621679804978"><span class="hs-identifier hs-var">layerNormWithBiasSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679804982"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;encoder_attn_layer_norm.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-235"></span><span>        </span><span class="annot"><a href="#local-6989586621679804977"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">m (CALayerNormF style gradient device dataType queryEmbedDim)
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-236"></span><span>        </span><span class="annot"><a href="#local-6989586621679804977"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">m (CALayerNormF style gradient device dataType queryEmbedDim)
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-237"></span><span>        </span><span class="annot"><a href="#local-6989586621679804977"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SGPT2"><span class="hs-identifier hs-var">SGPT2</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">m (CALayerNormF style gradient device dataType queryEmbedDim)
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-238"></span><span>        </span><span id="local-6989586621679804976"><span class="annot"><span class="annottext">dropout :: STransformerStyle style -&gt; m Dropout
</span><a href="#local-6989586621679804976"><span class="hs-identifier hs-var hs-var">dropout</span></a></span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ModelSpec Dropout -&gt; StateDictKey -&gt; m Dropout
forall model (m :: Type -&gt; Type).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
ModelSpec model -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Double -&gt; Dropout
</span><a href="Torch.GraduallyTyped.NN.Dropout.html#Dropout"><span class="hs-identifier hs-var">Dropout</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679804984"><span class="hs-identifier hs-var">dropoutP</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679804982"><span class="hs-identifier hs-var">k</span></a></span><span>
</span><span id="line-239"></span><span>     </span><span class="hs-keyword">in</span><span> </span><span class="annot"><span class="annottext">GCrossAttention
  (MultiHeadAttention
     style
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     keyEmbedDim
     keyEmbedDim)
  (CALayerNormF style gradient device dataType queryEmbedDim)
  Dropout
-&gt; CrossAttention
     style
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     keyEmbedDim
forall (style :: TransformerStyle)
       (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (headDim :: Dim (Name Symbol) (Size Nat))
       (headEmbedDim :: Dim (Name Symbol) (Size Nat))
       (embedDim :: Dim (Name Symbol) (Size Nat))
       (queryEmbedDim :: Dim (Name Symbol) (Size Nat))
       (keyEmbedDim :: Dim (Name Symbol) (Size Nat)).
GCrossAttention
  (CAMultiheadAttentionF
     style
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     keyEmbedDim)
  (CALayerNormF style gradient device dataType queryEmbedDim)
  (CADropoutF style)
-&gt; CrossAttention
     style
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     keyEmbedDim
</span><a href="Torch.GraduallyTyped.NN.Transformer.CrossAttention.html#CrossAttention"><span class="hs-identifier hs-var">CrossAttention</span></a></span><span>
</span><span id="line-240"></span><span>          </span><span class="annot"><span class="annottext">(GCrossAttention
   (MultiHeadAttention
      style
      gradient
      device
      dataType
      headDim
      headEmbedDim
      embedDim
      queryEmbedDim
      keyEmbedDim
      keyEmbedDim)
   (CALayerNormF style gradient device dataType queryEmbedDim)
   Dropout
 -&gt; CrossAttention
      style
      gradient
      device
      dataType
      headDim
      headEmbedDim
      embedDim
      queryEmbedDim
      keyEmbedDim)
-&gt; m (GCrossAttention
        (MultiHeadAttention
           style
           gradient
           device
           dataType
           headDim
           headEmbedDim
           embedDim
           queryEmbedDim
           keyEmbedDim
           keyEmbedDim)
        (CALayerNormF style gradient device dataType queryEmbedDim)
        Dropout)
-&gt; m (CrossAttention
        style
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        queryEmbedDim
        keyEmbedDim)
forall (f :: Type -&gt; Type) a b. Functor f =&gt; (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;$&gt;</span></span><span> </span><span class="hs-special">(</span><span> </span><span class="annot"><span class="annottext">MultiHeadAttention
  style
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  queryEmbedDim
  keyEmbedDim
  keyEmbedDim
-&gt; CALayerNormF style gradient device dataType queryEmbedDim
-&gt; Dropout
-&gt; GCrossAttention
     (MultiHeadAttention
        style
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        queryEmbedDim
        keyEmbedDim
        keyEmbedDim)
     (CALayerNormF style gradient device dataType queryEmbedDim)
     Dropout
forall mha layerNorm dropout.
mha
-&gt; layerNorm -&gt; dropout -&gt; GCrossAttention mha layerNorm dropout
</span><a href="Torch.GraduallyTyped.NN.Transformer.CrossAttention.html#GCrossAttention"><span class="hs-identifier hs-var">GCrossAttention</span></a></span><span>
</span><span id="line-241"></span><span>                  </span><span class="annot"><span class="annottext">(MultiHeadAttention
   style
   gradient
   device
   dataType
   headDim
   headEmbedDim
   embedDim
   queryEmbedDim
   keyEmbedDim
   keyEmbedDim
 -&gt; CALayerNormF style gradient device dataType queryEmbedDim
 -&gt; Dropout
 -&gt; GCrossAttention
      (MultiHeadAttention
         style
         gradient
         device
         dataType
         headDim
         headEmbedDim
         embedDim
         queryEmbedDim
         keyEmbedDim
         keyEmbedDim)
      (CALayerNormF style gradient device dataType queryEmbedDim)
      Dropout)
-&gt; m (MultiHeadAttention
        style
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        queryEmbedDim
        keyEmbedDim
        keyEmbedDim)
-&gt; m (CALayerNormF style gradient device dataType queryEmbedDim
      -&gt; Dropout
      -&gt; GCrossAttention
           (MultiHeadAttention
              style
              gradient
              device
              dataType
              headDim
              headEmbedDim
              embedDim
              queryEmbedDim
              keyEmbedDim
              keyEmbedDim)
           (CALayerNormF style gradient device dataType queryEmbedDim)
           Dropout)
forall (f :: Type -&gt; Type) a b. Functor f =&gt; (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;$&gt;</span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; m (MultiHeadAttention
        style
        gradient
        device
        dataType
        headDim
        headEmbedDim
        embedDim
        queryEmbedDim
        keyEmbedDim
        keyEmbedDim)
</span><a href="#local-6989586621679804980"><span class="hs-identifier hs-var">multiHeadAttention</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SingI style =&gt; Sing style
forall k (a :: k). SingI a =&gt; Sing a
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">sing</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679805007"><span class="hs-identifier hs-type">style</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-242"></span><span>                  </span><span class="annot"><span class="annottext">m (CALayerNormF style gradient device dataType queryEmbedDim
   -&gt; Dropout
   -&gt; GCrossAttention
        (MultiHeadAttention
           style
           gradient
           device
           dataType
           headDim
           headEmbedDim
           embedDim
           queryEmbedDim
           keyEmbedDim
           keyEmbedDim)
        (CALayerNormF style gradient device dataType queryEmbedDim)
        Dropout)
-&gt; m (CALayerNormF style gradient device dataType queryEmbedDim)
-&gt; m (Dropout
      -&gt; GCrossAttention
           (MultiHeadAttention
              style
              gradient
              device
              dataType
              headDim
              headEmbedDim
              embedDim
              queryEmbedDim
              keyEmbedDim
              keyEmbedDim)
           (CALayerNormF style gradient device dataType queryEmbedDim)
           Dropout)
forall (f :: Type -&gt; Type) a b.
Applicative f =&gt;
f (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;*&gt;</span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; m (CALayerNormF style gradient device dataType queryEmbedDim)
</span><a href="#local-6989586621679804977"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SingI style =&gt; Sing style
forall k (a :: k). SingI a =&gt; Sing a
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">sing</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679805007"><span class="hs-identifier hs-type">style</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-243"></span><span>                  </span><span class="annot"><span class="annottext">m (Dropout
   -&gt; GCrossAttention
        (MultiHeadAttention
           style
           gradient
           device
           dataType
           headDim
           headEmbedDim
           embedDim
           queryEmbedDim
           keyEmbedDim
           keyEmbedDim)
        (CALayerNormF style gradient device dataType queryEmbedDim)
        Dropout)
-&gt; m Dropout
-&gt; m (GCrossAttention
        (MultiHeadAttention
           style
           gradient
           device
           dataType
           headDim
           headEmbedDim
           embedDim
           queryEmbedDim
           keyEmbedDim
           keyEmbedDim)
        (CALayerNormF style gradient device dataType queryEmbedDim)
        Dropout)
forall (f :: Type -&gt; Type) a b.
Applicative f =&gt;
f (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;*&gt;</span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style -&gt; m Dropout
</span><a href="#local-6989586621679804976"><span class="hs-identifier hs-var">dropout</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SingI style =&gt; Sing style
forall k (a :: k). SingI a =&gt; Sing a
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">sing</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679805007"><span class="hs-identifier hs-type">style</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-244"></span><span>              </span><span class="hs-special">)</span><span>
</span><span id="line-245"></span><span>  </span><span id="local-6989586621679804974"><span class="annot"><span class="annottext">toStateDict :: StateDictKey
-&gt; CrossAttention
     style
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     keyEmbedDim
-&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var hs-var hs-var hs-var">toStateDict</span></a></span></span><span> </span><span id="local-6989586621679804972"><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679804972"><span class="hs-identifier hs-var">k</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.CrossAttention.html#CrossAttention"><span class="hs-identifier hs-type">CrossAttention</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.CrossAttention.html#GCrossAttention"><span class="hs-identifier hs-type">GCrossAttention</span></a></span><span> </span><span class="hs-special">{</span><span id="local-6989586621679804969"><span id="local-6989586621679804970"><span id="local-6989586621679804971"><span class="annot"><span class="annottext">CADropoutF style
CALayerNormF style gradient device dataType queryEmbedDim
CAMultiheadAttentionF
  style
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  queryEmbedDim
  keyEmbedDim
caDropout :: CADropoutF style
caLayerNorm :: CALayerNormF style gradient device dataType queryEmbedDim
caMultiHeadAttention :: CAMultiheadAttentionF
  style
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  queryEmbedDim
  keyEmbedDim
caDropout :: forall mha layerNorm dropout.
GCrossAttention mha layerNorm dropout -&gt; dropout
caLayerNorm :: forall mha layerNorm dropout.
GCrossAttention mha layerNorm dropout -&gt; layerNorm
caMultiHeadAttention :: forall mha layerNorm dropout.
GCrossAttention mha layerNorm dropout -&gt; mha
</span><a href="#local-6989586621679804969"><span class="hs-glyph hs-var hs-var hs-var hs-var hs-var hs-var">..</span></a></span></span></span></span><span class="hs-special">}</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-246"></span><span>    </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679804968"><span class="annot"><span class="annottext">multiHeadAttention :: STransformerStyle style
-&gt; MultiHeadAttention
     style
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     keyEmbedDim
     keyEmbedDim
-&gt; m ()
</span><a href="#local-6989586621679804968"><span class="hs-identifier hs-var hs-var">multiHeadAttention</span></a></span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; MultiHeadAttention
     'T5
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     keyEmbedDim
     keyEmbedDim
-&gt; m ()
forall model (m :: Type -&gt; Type).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679804972"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;EncDecAttention.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-247"></span><span>        </span><span class="annot"><a href="#local-6989586621679804968"><span class="hs-identifier hs-var">multiHeadAttention</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; MultiHeadAttention
     'ByT5
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     keyEmbedDim
     keyEmbedDim
-&gt; m ()
forall model (m :: Type -&gt; Type).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679804972"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;EncDecAttention.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-248"></span><span>        </span><span class="annot"><a href="#local-6989586621679804968"><span class="hs-identifier hs-var">multiHeadAttention</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; MultiHeadAttention
     'BART
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     keyEmbedDim
     keyEmbedDim
-&gt; m ()
forall model (m :: Type -&gt; Type).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679804972"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;encoder_attn.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-249"></span><span>        </span><span class="annot"><a href="#local-6989586621679804968"><span class="hs-identifier hs-var">multiHeadAttention</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; MultiHeadAttention
     'MBART
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     keyEmbedDim
     keyEmbedDim
-&gt; m ()
forall model (m :: Type -&gt; Type).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679804972"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;encoder_attn.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-250"></span><span>        </span><span class="annot"><a href="#local-6989586621679804968"><span class="hs-identifier hs-var">multiHeadAttention</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; MultiHeadAttention
     'Pegasus
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     keyEmbedDim
     keyEmbedDim
-&gt; m ()
forall model (m :: Type -&gt; Type).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679804972"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;encoder_attn.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-251"></span><span>        </span><span class="annot"><a href="#local-6989586621679804968"><span class="hs-identifier hs-var">multiHeadAttention</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">MultiHeadAttention
  style
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  queryEmbedDim
  keyEmbedDim
  keyEmbedDim
-&gt; m ()
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-252"></span><span>        </span><span class="annot"><a href="#local-6989586621679804968"><span class="hs-identifier hs-var">multiHeadAttention</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">MultiHeadAttention
  style
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  queryEmbedDim
  keyEmbedDim
  keyEmbedDim
-&gt; m ()
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-253"></span><span>        </span><span class="annot"><a href="#local-6989586621679804968"><span class="hs-identifier hs-var">multiHeadAttention</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SGPT2"><span class="hs-identifier hs-var">SGPT2</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">MultiHeadAttention
  style
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  queryEmbedDim
  keyEmbedDim
  keyEmbedDim
-&gt; m ()
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-254"></span><span>        </span><span id="local-6989586621679804967"><span class="annot"><span class="annottext">layerNorm :: STransformerStyle style
-&gt; CALayerNormF style gradient device dataType queryEmbedDim
-&gt; m ()
</span><a href="#local-6989586621679804967"><span class="hs-identifier hs-var hs-var">layerNorm</span></a></span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; LayerNorm
     'WithoutBias gradient device dataType ('Shape '[queryEmbedDim])
-&gt; m ()
forall model (m :: Type -&gt; Type).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679804972"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;layer_norm.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-255"></span><span>        </span><span class="annot"><a href="#local-6989586621679804967"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SByT5"><span class="hs-identifier hs-var">SByT5</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; LayerNorm
     'WithoutBias gradient device dataType ('Shape '[queryEmbedDim])
-&gt; m ()
forall model (m :: Type -&gt; Type).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679804972"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;layer_norm.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-256"></span><span>        </span><span class="annot"><a href="#local-6989586621679804967"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBART"><span class="hs-identifier hs-var">SBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; LayerNorm
     'WithBias gradient device dataType ('Shape '[queryEmbedDim])
-&gt; m ()
forall model (m :: Type -&gt; Type).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679804972"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;encoder_attn_layer_norm.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-257"></span><span>        </span><span class="annot"><a href="#local-6989586621679804967"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SMBART"><span class="hs-identifier hs-var">SMBART</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; LayerNorm
     'WithBias gradient device dataType ('Shape '[queryEmbedDim])
-&gt; m ()
forall model (m :: Type -&gt; Type).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679804972"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;encoder_attn_layer_norm.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-258"></span><span>        </span><span class="annot"><a href="#local-6989586621679804967"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SPegasus"><span class="hs-identifier hs-var">SPegasus</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey
-&gt; LayerNorm
     'WithBias gradient device dataType ('Shape '[queryEmbedDim])
-&gt; m ()
forall model (m :: Type -&gt; Type).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679804972"><span class="hs-identifier hs-var">k</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; StateDictKey -&gt; StateDictKey
forall a. Semigroup a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">&lt;&gt;</span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;encoder_attn_layer_norm.&quot;</span></span><span class="hs-special">)</span><span>
</span><span id="line-259"></span><span>        </span><span class="annot"><a href="#local-6989586621679804967"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SBERT"><span class="hs-identifier hs-var">SBERT</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">CALayerNormF style gradient device dataType queryEmbedDim -&gt; m ()
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-260"></span><span>        </span><span class="annot"><a href="#local-6989586621679804967"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SRoBERTa"><span class="hs-identifier hs-var">SRoBERTa</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">CALayerNormF style gradient device dataType queryEmbedDim -&gt; m ()
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-261"></span><span>        </span><span class="annot"><a href="#local-6989586621679804967"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#SGPT2"><span class="hs-identifier hs-var">SGPT2</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">CALayerNormF style gradient device dataType queryEmbedDim -&gt; m ()
forall a. HasCallStack =&gt; a
</span><span class="hs-identifier hs-var">undefined</span></span><span>
</span><span id="line-262"></span><span>        </span><span id="local-6989586621679804966"><span class="annot"><span class="annottext">dropout :: STransformerStyle style -&gt; Dropout -&gt; m ()
</span><a href="#local-6989586621679804966"><span class="hs-identifier hs-var hs-var">dropout</span></a></span></span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
</span><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">StateDictKey -&gt; Dropout -&gt; m ()
forall model (m :: Type -&gt; Type).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><a href="#local-6989586621679804972"><span class="hs-identifier hs-var">k</span></a></span><span>
</span><span id="line-263"></span><span>     </span><span class="hs-keyword">in</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-264"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; MultiHeadAttention
     style
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     keyEmbedDim
     keyEmbedDim
-&gt; m ()
</span><a href="#local-6989586621679804968"><span class="hs-identifier hs-var">multiHeadAttention</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SingI style =&gt; Sing style
forall k (a :: k). SingI a =&gt; Sing a
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">sing</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679805007"><span class="hs-identifier hs-type">style</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">MultiHeadAttention
  style
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  queryEmbedDim
  keyEmbedDim
  keyEmbedDim
CAMultiheadAttentionF
  style
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  queryEmbedDim
  keyEmbedDim
</span><a href="#local-6989586621679804971"><span class="hs-identifier hs-var">caMultiHeadAttention</span></a></span><span>
</span><span id="line-265"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">STransformerStyle style
-&gt; CALayerNormF style gradient device dataType queryEmbedDim
-&gt; m ()
</span><a href="#local-6989586621679804967"><span class="hs-identifier hs-var">layerNorm</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SingI style =&gt; Sing style
forall k (a :: k). SingI a =&gt; Sing a
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">sing</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679805007"><span class="hs-identifier hs-type">style</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">CALayerNormF style gradient device dataType queryEmbedDim
</span><a href="#local-6989586621679804970"><span class="hs-identifier hs-var">caLayerNorm</span></a></span><span>
</span><span id="line-266"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">)</span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">STransformerStyle style -&gt; Dropout -&gt; m ()
</span><a href="#local-6989586621679804966"><span class="hs-identifier hs-var">dropout</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SingI style =&gt; Sing style
forall k (a :: k). SingI a =&gt; Sing a
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">sing</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><a href="#local-6989586621679805007"><span class="hs-identifier hs-type">style</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Dropout
CADropoutF style
</span><a href="#local-6989586621679804969"><span class="hs-identifier hs-var">caDropout</span></a></span><span>
</span><span id="line-267"></span><span>          </span><span class="annot"><span class="annottext">() -&gt; m ()
forall (f :: Type -&gt; Type) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span></span></span></span></span></span></span></span></span></span><span>
</span><span id="line-268"></span><span>
</span><span id="line-269"></span><span class="hs-comment">-- | 'HasForward' instance for @CrossAttention 'T5@.</span><span>
</span><span id="line-270"></span><span class="hs-comment">--</span><span>
</span><span id="line-271"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-272"></span><span class="hs-comment">--    &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;  &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;  &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;</span><span>
</span><span id="line-273"></span><span class="hs-comment">--    &#9474; query &#9474;  &#9474; key &#9474;  &#9474; attentionBias &#9474;</span><span>
</span><span id="line-274"></span><span class="hs-comment">--    &#9492;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9496;  &#9492;&#9472;&#9472;&#9516;&#9472;&#9472;&#9496;  &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-275"></span><span class="hs-comment">--        &#9474;         &#9474;             &#9474;</span><span>
</span><span id="line-276"></span><span class="hs-comment">-- &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9508;         &#9474;             &#9474;</span><span>
</span><span id="line-277"></span><span class="hs-comment">-- &#9474;      &#9474;         &#9474;             &#9474;</span><span>
</span><span id="line-278"></span><span class="hs-comment">-- &#9474;      &#9660;         &#9474;             &#9474;</span><span>
</span><span id="line-279"></span><span class="hs-comment">-- &#9474; caLayerNorm    &#9474;             &#9474;</span><span>
</span><span id="line-280"></span><span class="hs-comment">-- &#9474;      &#9474;         &#9474;             &#9474;</span><span>
</span><span id="line-281"></span><span class="hs-comment">-- &#9474;      &#9474;      &#9484;&#9472;&#9472;&#9524;&#9472;&#9472;&#9488;          &#9474;</span><span>
</span><span id="line-282"></span><span class="hs-comment">-- &#9474;      &#9474;      &#9474;     &#9474;          &#9474;</span><span>
</span><span id="line-283"></span><span class="hs-comment">-- &#9474;      &#9660;      &#9660;     &#9660;          &#9474;</span><span>
</span><span id="line-284"></span><span class="hs-comment">-- &#9474;   caMultiheadAttention&#9668;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-285"></span><span class="hs-comment">-- &#9474;             &#9474;</span><span>
</span><span id="line-286"></span><span class="hs-comment">-- &#9474;             &#9660;</span><span>
</span><span id="line-287"></span><span class="hs-comment">-- &#9474;         caDropout</span><span>
</span><span id="line-288"></span><span class="hs-comment">-- &#9474;             &#9474;</span><span>
</span><span id="line-289"></span><span class="hs-comment">-- &#9492;&#9472;&#9472;&#9472;&#9472;&#9658;add&#9668;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-290"></span><span class="hs-comment">--        &#9474;</span><span>
</span><span id="line-291"></span><span class="hs-comment">--        &#9660;</span><span>
</span><span id="line-292"></span><span class="hs-comment">--    &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;</span><span>
</span><span id="line-293"></span><span class="hs-comment">--    &#9474; query &#9474;</span><span>
</span><span id="line-294"></span><span class="hs-comment">--    &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-295"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-296"></span><span id="local-6989586621679804939"><span id="local-6989586621679804940"><span id="local-6989586621679804941"><span id="local-6989586621679804942"><span id="local-6989586621679804943"><span id="local-6989586621679804944"><span id="local-6989586621679804945"><span id="local-6989586621679804946"><span id="local-6989586621679804947"><span id="local-6989586621679804948"><span id="local-6989586621679804949"><span id="local-6989586621679804950"><span id="local-6989586621679804951"><span id="local-6989586621679804952"><span id="local-6989586621679804953"><span id="local-6989586621679804954"><span id="local-6989586621679804955"><span id="local-6989586621679804956"><span id="local-6989586621679804957"><span id="local-6989586621679804958"><span id="local-6989586621679804959"><span id="local-6989586621679804960"><span id="local-6989586621679804961"><span id="local-6989586621679804962"><span id="local-6989586621679804963"><span id="local-6989586621679804964"><span id="local-6989586621679804965"><span class="hs-keyword">instance</span><span>
</span><span id="line-297"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetDim"><span class="hs-identifier hs-type">SGetDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804965"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-298"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-299"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.CrossAttention.html#CALayerNormF"><span class="hs-identifier hs-type">CALayerNormF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#T5"><span class="hs-identifier hs-type">T5</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804964"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804963"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804962"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804965"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-300"></span><span>      </span><span class="annot"><a href="#local-6989586621679804961"><span class="hs-identifier hs-type">query</span></a></span><span>
</span><span id="line-301"></span><span>      </span><span class="annot"><a href="#local-6989586621679804960"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-302"></span><span>      </span><span class="annot"><a href="#local-6989586621679804959"><span class="hs-identifier hs-type">layerNormOutput</span></a></span><span>
</span><span id="line-303"></span><span>      </span><span class="annot"><a href="#local-6989586621679804960"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-304"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-305"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.CrossAttention.html#CAMultiheadAttentionF"><span class="hs-identifier hs-type">CAMultiheadAttentionF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#T5"><span class="hs-identifier hs-type">T5</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804964"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804963"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804962"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804958"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804957"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804956"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804965"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804955"><span class="hs-identifier hs-type">keyEmbedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-306"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679804959"><span class="hs-identifier hs-type">layerNormOutput</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679804954"><span class="hs-identifier hs-type">key</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679804954"><span class="hs-identifier hs-type">key</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679804953"><span class="hs-identifier hs-type">attentionBias</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-307"></span><span>      </span><span class="annot"><a href="#local-6989586621679804960"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-308"></span><span>      </span><span class="annot"><a href="#local-6989586621679804952"><span class="hs-identifier hs-type">mhaOutput</span></a></span><span>
</span><span id="line-309"></span><span>      </span><span class="annot"><a href="#local-6989586621679804951"><span class="hs-identifier hs-type">device2</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-310"></span><span>    </span><span class="annot"><a href="#local-6989586621679804961"><span class="hs-identifier hs-type">query</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804950"><span class="hs-identifier hs-type">gradient0</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804949"><span class="hs-identifier hs-type">layout0</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804948"><span class="hs-identifier hs-type">device0</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804947"><span class="hs-identifier hs-type">dataType0</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804946"><span class="hs-identifier hs-type">shape0</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-311"></span><span>    </span><span class="annot"><a href="#local-6989586621679804952"><span class="hs-identifier hs-type">mhaOutput</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804945"><span class="hs-identifier hs-type">gradient1</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804944"><span class="hs-identifier hs-type">layout1</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804943"><span class="hs-identifier hs-type">device1</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804942"><span class="hs-identifier hs-type">dataType1</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804941"><span class="hs-identifier hs-type">shape1</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-312"></span><span>    </span><span class="annot"><a href="#local-6989586621679804940"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-313"></span><span>      </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-314"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679804950"><span class="hs-identifier hs-type">gradient0</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804945"><span class="hs-identifier hs-type">gradient1</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-315"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679804949"><span class="hs-identifier hs-type">layout0</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804944"><span class="hs-identifier hs-type">layout1</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-316"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679804948"><span class="hs-identifier hs-type">device0</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804943"><span class="hs-identifier hs-type">device1</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804951"><span class="hs-identifier hs-type">device2</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-317"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679804947"><span class="hs-identifier hs-type">dataType0</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804942"><span class="hs-identifier hs-type">dataType1</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-318"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#BroadcastShapesF"><span class="hs-identifier hs-type">BroadcastShapesF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804946"><span class="hs-identifier hs-type">shape0</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804941"><span class="hs-identifier hs-type">shape1</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-319"></span><span>    </span><span class="annot"><a href="#local-6989586621679804939"><span class="hs-identifier hs-type">generatorOutputDevice</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679804943"><span class="hs-identifier hs-type">device1</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804951"><span class="hs-identifier hs-type">device2</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-320"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-321"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-322"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.CrossAttention.html#CrossAttention"><span class="hs-identifier hs-type">CrossAttention</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#T5"><span class="hs-identifier hs-type">T5</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804964"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804963"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804962"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804958"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804957"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804956"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804965"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804955"><span class="hs-identifier hs-type">keyEmbedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-323"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679804961"><span class="hs-identifier hs-type">query</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679804954"><span class="hs-identifier hs-type">key</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679804953"><span class="hs-identifier hs-type">attentionBias</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-324"></span><span>    </span><span class="annot"><a href="#local-6989586621679804960"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-325"></span><span>    </span><span class="annot"><a href="#local-6989586621679804940"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-326"></span><span>    </span><span class="annot"><a href="#local-6989586621679804939"><span class="hs-identifier hs-type">generatorOutputDevice</span></a></span><span>
</span><span id="line-327"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-328"></span><span>  </span><span id="local-6989586621679804936"><span class="annot"><span class="annottext">forward :: CrossAttention
  'T5
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  queryEmbedDim
  keyEmbedDim
-&gt; (query, key, attentionBias)
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var hs-var hs-var hs-var">forward</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.CrossAttention.html#CrossAttention"><span class="hs-identifier hs-type">CrossAttention</span></a></span><span> </span><span id="local-6989586621679804934"><span class="annot"><span class="annottext">GCrossAttention
  (CAMultiheadAttentionF
     'T5
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     keyEmbedDim)
  (CALayerNormF 'T5 gradient device dataType queryEmbedDim)
  (CADropoutF 'T5)
</span><a href="#local-6989586621679804934"><span class="hs-identifier hs-var">ca</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679804933"><span class="annot"><span class="annottext">query
</span><a href="#local-6989586621679804933"><span class="hs-identifier hs-var">query</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679804932"><span class="annot"><span class="annottext">key
</span><a href="#local-6989586621679804932"><span class="hs-identifier hs-var">key</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679804931"><span class="annot"><span class="annottext">attentionBias
</span><a href="#local-6989586621679804931"><span class="hs-identifier hs-var">attentionBias</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-329"></span><span>    </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorOutputDevice)
  output
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
forall (m :: Type -&gt; Type) i j a. IxStateT m i j a -&gt; i -&gt; m (a, j)
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var hs-var">runIxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">(IxStateT
   m
   (Generator generatorDevice)
   (Generator generatorOutputDevice)
   output
 -&gt; Generator generatorDevice
 -&gt; m (output, Generator generatorOutputDevice))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorOutputDevice)
     output
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-330"></span><span>      </span><span class="annot"><span class="annottext">query
-&gt; IxStateT
     m (Generator generatorDevice) (Generator generatorDevice) query
forall k (m :: k -&gt; k -&gt; Type -&gt; Type) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">query
</span><a href="#local-6989586621679804933"><span class="hs-identifier hs-var">query</span></a></span><span>
</span><span id="line-331"></span><span>        </span><span class="annot"><span class="annottext">IxStateT
  m (Generator generatorDevice) (Generator generatorDevice) query
-&gt; (query
    -&gt; IxStateT
         m
         (Generator generatorDevice)
         (Generator generatorDevice)
         layerNormOutput)
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     layerNormOutput
forall k1 (m :: k1 -&gt; k1 -&gt; Type -&gt; Type) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(Generator generatorDevice
 -&gt; m (layerNormOutput, Generator generatorDevice))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     layerNormOutput
forall (m :: Type -&gt; Type) i j a.
(i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator generatorDevice
  -&gt; m (layerNormOutput, Generator generatorDevice))
 -&gt; IxStateT
      m
      (Generator generatorDevice)
      (Generator generatorDevice)
      layerNormOutput)
-&gt; (query
    -&gt; Generator generatorDevice
    -&gt; m (layerNormOutput, Generator generatorDevice))
-&gt; query
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     layerNormOutput
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">LayerNorm
  'WithoutBias gradient device dataType ('Shape '[queryEmbedDim])
-&gt; query
-&gt; Generator generatorDevice
-&gt; m (layerNormOutput, Generator generatorDevice)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: Type -&gt; Type).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">GCrossAttention
  (MultiHeadAttention
     'T5
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     keyEmbedDim
     keyEmbedDim)
  (LayerNorm
     'WithoutBias gradient device dataType ('Shape '[queryEmbedDim]))
  Dropout
-&gt; LayerNorm
     'WithoutBias gradient device dataType ('Shape '[queryEmbedDim])
forall mha layerNorm dropout.
GCrossAttention mha layerNorm dropout -&gt; layerNorm
</span><a href="Torch.GraduallyTyped.NN.Transformer.CrossAttention.html#caLayerNorm"><span class="hs-identifier hs-var hs-var">caLayerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">GCrossAttention
  (MultiHeadAttention
     'T5
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     keyEmbedDim
     keyEmbedDim)
  (LayerNorm
     'WithoutBias gradient device dataType ('Shape '[queryEmbedDim]))
  Dropout
GCrossAttention
  (CAMultiheadAttentionF
     'T5
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     keyEmbedDim)
  (CALayerNormF 'T5 gradient device dataType queryEmbedDim)
  (CADropoutF 'T5)
</span><a href="#local-6989586621679804934"><span class="hs-identifier hs-var">ca</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-332"></span><span>        </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorDevice)
  layerNormOutput
-&gt; (layerNormOutput
    -&gt; IxStateT
         m
         (Generator generatorDevice)
         (Generator device2)
         (Tensor gradient1 layout1 device1 dataType1 shape1))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator device2)
     (Tensor gradient1 layout1 device1 dataType1 shape1)
forall k1 (m :: k1 -&gt; k1 -&gt; Type -&gt; Type) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">\</span><span id="local-6989586621679804930"><span class="annot"><span class="annottext">layerNormOutput
</span><a href="#local-6989586621679804930"><span class="hs-identifier hs-var">query'</span></a></span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">(Generator generatorDevice
 -&gt; m (Tensor gradient1 layout1 device1 dataType1 shape1,
       Generator device2))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator device2)
     (Tensor gradient1 layout1 device1 dataType1 shape1)
forall (m :: Type -&gt; Type) i j a.
(i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator generatorDevice
  -&gt; m (Tensor gradient1 layout1 device1 dataType1 shape1,
        Generator device2))
 -&gt; IxStateT
      m
      (Generator generatorDevice)
      (Generator device2)
      (Tensor gradient1 layout1 device1 dataType1 shape1))
-&gt; (Generator generatorDevice
    -&gt; m (Tensor gradient1 layout1 device1 dataType1 shape1,
          Generator device2))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator device2)
     (Tensor gradient1 layout1 device1 dataType1 shape1)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">MultiHeadAttention
  'T5
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  queryEmbedDim
  keyEmbedDim
  keyEmbedDim
-&gt; (layerNormOutput, key, key, attentionBias)
-&gt; Generator generatorDevice
-&gt; m (Tensor gradient1 layout1 device1 dataType1 shape1,
      Generator device2)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: Type -&gt; Type).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">GCrossAttention
  (MultiHeadAttention
     'T5
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     keyEmbedDim
     keyEmbedDim)
  (LayerNorm
     'WithoutBias gradient device dataType ('Shape '[queryEmbedDim]))
  Dropout
-&gt; MultiHeadAttention
     'T5
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     keyEmbedDim
     keyEmbedDim
forall mha layerNorm dropout.
GCrossAttention mha layerNorm dropout -&gt; mha
</span><a href="Torch.GraduallyTyped.NN.Transformer.CrossAttention.html#caMultiHeadAttention"><span class="hs-identifier hs-var hs-var">caMultiHeadAttention</span></a></span><span> </span><span class="annot"><span class="annottext">GCrossAttention
  (MultiHeadAttention
     'T5
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     keyEmbedDim
     keyEmbedDim)
  (LayerNorm
     'WithoutBias gradient device dataType ('Shape '[queryEmbedDim]))
  Dropout
GCrossAttention
  (CAMultiheadAttentionF
     'T5
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     keyEmbedDim)
  (CALayerNormF 'T5 gradient device dataType queryEmbedDim)
  (CADropoutF 'T5)
</span><a href="#local-6989586621679804934"><span class="hs-identifier hs-var">ca</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">layerNormOutput
</span><a href="#local-6989586621679804930"><span class="hs-identifier hs-var">query'</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">key
</span><a href="#local-6989586621679804932"><span class="hs-identifier hs-var">key</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">key
</span><a href="#local-6989586621679804932"><span class="hs-identifier hs-var">key</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">attentionBias
</span><a href="#local-6989586621679804931"><span class="hs-identifier hs-var">attentionBias</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-333"></span><span>        </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator device2)
  (Tensor gradient1 layout1 device1 dataType1 shape1)
-&gt; (Tensor gradient1 layout1 device1 dataType1 shape1
    -&gt; IxStateT
         m
         (Generator device2)
         (Generator generatorOutputDevice)
         (Tensor gradient1 layout1 generatorOutputDevice dataType1 shape1))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorOutputDevice)
     (Tensor gradient1 layout1 generatorOutputDevice dataType1 shape1)
forall k1 (m :: k1 -&gt; k1 -&gt; Type -&gt; Type) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(Generator device2
 -&gt; m (Tensor
         gradient1 layout1 generatorOutputDevice dataType1 shape1,
       Generator generatorOutputDevice))
-&gt; IxStateT
     m
     (Generator device2)
     (Generator generatorOutputDevice)
     (Tensor gradient1 layout1 generatorOutputDevice dataType1 shape1)
forall (m :: Type -&gt; Type) i j a.
(i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator device2
  -&gt; m (Tensor
          gradient1 layout1 generatorOutputDevice dataType1 shape1,
        Generator generatorOutputDevice))
 -&gt; IxStateT
      m
      (Generator device2)
      (Generator generatorOutputDevice)
      (Tensor gradient1 layout1 generatorOutputDevice dataType1 shape1))
-&gt; (Tensor gradient1 layout1 device1 dataType1 shape1
    -&gt; Generator device2
    -&gt; m (Tensor
            gradient1 layout1 generatorOutputDevice dataType1 shape1,
          Generator generatorOutputDevice))
-&gt; Tensor gradient1 layout1 device1 dataType1 shape1
-&gt; IxStateT
     m
     (Generator device2)
     (Generator generatorOutputDevice)
     (Tensor gradient1 layout1 generatorOutputDevice dataType1 shape1)
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Dropout
-&gt; Tensor gradient1 layout1 device1 dataType1 shape1
-&gt; Generator device2
-&gt; m (Tensor
        gradient1 layout1 generatorOutputDevice dataType1 shape1,
      Generator generatorOutputDevice)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: Type -&gt; Type).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">GCrossAttention
  (MultiHeadAttention
     'T5
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     keyEmbedDim
     keyEmbedDim)
  (LayerNorm
     'WithoutBias gradient device dataType ('Shape '[queryEmbedDim]))
  Dropout
-&gt; Dropout
forall mha layerNorm dropout.
GCrossAttention mha layerNorm dropout -&gt; dropout
</span><a href="Torch.GraduallyTyped.NN.Transformer.CrossAttention.html#caDropout"><span class="hs-identifier hs-var hs-var">caDropout</span></a></span><span> </span><span class="annot"><span class="annottext">GCrossAttention
  (MultiHeadAttention
     'T5
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     keyEmbedDim
     keyEmbedDim)
  (LayerNorm
     'WithoutBias gradient device dataType ('Shape '[queryEmbedDim]))
  Dropout
GCrossAttention
  (CAMultiheadAttentionF
     'T5
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     keyEmbedDim)
  (CALayerNormF 'T5 gradient device dataType queryEmbedDim)
  (CADropoutF 'T5)
</span><a href="#local-6989586621679804934"><span class="hs-identifier hs-var">ca</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-334"></span><span>        </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorOutputDevice)
  (Tensor gradient1 layout1 generatorOutputDevice dataType1 shape1)
-&gt; (Tensor gradient1 layout1 generatorOutputDevice dataType1 shape1
    -&gt; IxStateT
         m
         (Generator generatorOutputDevice)
         (Generator generatorOutputDevice)
         output)
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorOutputDevice)
     output
forall k1 (m :: k1 -&gt; k1 -&gt; Type -&gt; Type) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">output
-&gt; IxStateT
     m
     (Generator generatorOutputDevice)
     (Generator generatorOutputDevice)
     output
forall k (m :: k -&gt; k -&gt; Type -&gt; Type) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">(output
 -&gt; IxStateT
      m
      (Generator generatorOutputDevice)
      (Generator generatorOutputDevice)
      output)
-&gt; (Tensor gradient1 layout1 generatorOutputDevice dataType1 shape1
    -&gt; output)
-&gt; Tensor gradient1 layout1 generatorOutputDevice dataType1 shape1
-&gt; IxStateT
     m
     (Generator generatorOutputDevice)
     (Generator generatorOutputDevice)
     output
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">query
Tensor gradient0 layout0 device0 dataType0 shape0
</span><a href="#local-6989586621679804933"><span class="hs-identifier hs-var">query</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient0 layout0 device0 dataType0 shape0
-&gt; Tensor gradient1 layout1 generatorOutputDevice dataType1 shape1
-&gt; Tensor
     (gradient0 &lt;|&gt; gradient1)
     (layout0 &lt;+&gt; layout1)
     (device0 &lt;+&gt; generatorOutputDevice)
     (dataType0 &lt;+&gt; dataType1)
     (BroadcastShapesF shape0 shape1)
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (gradient' :: Gradient RequiresGradient)
       (layout' :: Layout LayoutType) (device' :: Device (DeviceType Nat))
       (dataType' :: DataType DType)
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]).
Tensor gradient layout device dataType shape
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; Tensor
     (gradient &lt;|&gt; gradient')
     (layout &lt;+&gt; layout')
     (device &lt;+&gt; device')
     (dataType &lt;+&gt; dataType')
     (BroadcastShapesF shape shape')
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#add"><span class="hs-operator hs-var">`add`</span></a></span><span class="hs-special">)</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span>
</span><span id="line-335"></span><span>
</span><span id="line-336"></span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.CrossAttention.html#testCA"><span class="hs-identifier hs-type">testCA</span></a></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">IO</span></span><span> </span><span class="annot"><span class="hs-identifier">_</span></span><span>
</span><span id="line-337"></span><span id="testCA"><span class="annot"><span class="annottext">testCA :: IO
  (Tensor
     ('Gradient 'WithGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     ('DataType 'Float)
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 4),
           'Dim ('Name &quot;*&quot;) ('Size 512)]))
</span><a href="Torch.GraduallyTyped.NN.Transformer.CrossAttention.html#testCA"><span class="hs-identifier hs-var hs-var">testCA</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-338"></span><span>  </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679804928"><span class="annot"><span class="annottext">gradient :: SGradient ('Gradient 'WithGradient)
</span><a href="#local-6989586621679804928"><span class="hs-identifier hs-var hs-var">gradient</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SRequiresGradient 'WithGradient
-&gt; SGradient ('Gradient 'WithGradient)
forall (requiresGradient :: RequiresGradient).
SRequiresGradient requiresGradient
-&gt; SGradient ('Gradient requiresGradient)
</span><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier hs-var">SGradient</span></a></span><span> </span><span class="annot"><span class="annottext">SRequiresGradient 'WithGradient
</span><a href="Torch.GraduallyTyped.RequiresGradient.html#SWithGradient"><span class="hs-identifier hs-var">SWithGradient</span></a></span><span>
</span><span id="line-339"></span><span>      </span><span id="local-6989586621679804925"><span class="annot"><span class="annottext">device :: SDevice ('Device 'CPU)
</span><a href="#local-6989586621679804925"><span class="hs-identifier hs-var hs-var">device</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SDeviceType 'CPU -&gt; SDevice ('Device 'CPU)
forall (deviceType :: DeviceType Nat).
SDeviceType deviceType -&gt; SDevice ('Device deviceType)
</span><a href="Torch.GraduallyTyped.Device.html#SDevice"><span class="hs-identifier hs-var">SDevice</span></a></span><span> </span><span class="annot"><span class="annottext">SDeviceType 'CPU
</span><a href="Torch.GraduallyTyped.Device.html#SCPU"><span class="hs-identifier hs-var">SCPU</span></a></span><span>
</span><span id="line-340"></span><span>      </span><span id="local-6989586621679804922"><span class="annot"><span class="annottext">dataType :: SDataType ('DataType 'Float)
</span><a href="#local-6989586621679804922"><span class="hs-identifier hs-var hs-var">dataType</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SDType 'Float -&gt; SDataType ('DataType 'Float)
forall (dType :: DType).
SDType dType -&gt; SDataType ('DataType dType)
</span><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier hs-var">SDataType</span></a></span><span> </span><span class="annot"><span class="annottext">SDType 'Float
</span><a href="Torch.GraduallyTyped.DType.html#SFloat"><span class="hs-identifier hs-var">SFloat</span></a></span><span>
</span><span id="line-341"></span><span>      </span><span id="local-6989586621679804919"><span class="annot"><span class="annottext">headDim :: SDim ('Dim ('Name &quot;*&quot;) ('Size 8))
</span><a href="#local-6989586621679804919"><span class="hs-identifier hs-var hs-var">headDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize ('Size 8) -&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 8))
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownNat 8 =&gt; SSize ('Size 8)
forall (size :: Nat). KnownNat size =&gt; SSize ('Size size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier hs-var">SSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">8</span></span><span>
</span><span id="line-342"></span><span>      </span><span id="local-6989586621679804916"><span class="annot"><span class="annottext">headEmbedDim :: SDim ('Dim ('Name &quot;*&quot;) ('Size 64))
</span><a href="#local-6989586621679804916"><span class="hs-identifier hs-var hs-var">headEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize ('Size 64) -&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 64))
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownNat 64 =&gt; SSize ('Size 64)
forall (size :: Nat). KnownNat size =&gt; SSize ('Size size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier hs-var">SSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">64</span></span><span>
</span><span id="line-343"></span><span>      </span><span id="local-6989586621679804915"><span class="annot"><span class="annottext">embedDim :: SDim ('Dim ('Name &quot;*&quot;) ('Size 512))
</span><a href="#local-6989586621679804915"><span class="hs-identifier hs-var hs-var">embedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize ('Size 512) -&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 512))
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownNat 512 =&gt; SSize ('Size 512)
forall (size :: Nat). KnownNat size =&gt; SSize ('Size size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier hs-var">SSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">512</span></span><span>
</span><span id="line-344"></span><span>      </span><span id="local-6989586621679804914"><span class="annot"><span class="annottext">queryEmbedDim :: SDim ('Dim ('Name &quot;*&quot;) ('Size 512))
</span><a href="#local-6989586621679804914"><span class="hs-identifier hs-var hs-var">queryEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize ('Size 512) -&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 512))
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownNat 512 =&gt; SSize ('Size 512)
forall (size :: Nat). KnownNat size =&gt; SSize ('Size size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier hs-var">SSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">512</span></span><span>
</span><span id="line-345"></span><span>      </span><span id="local-6989586621679804913"><span class="annot"><span class="annottext">keyEmbedDim :: SDim ('Dim ('Name &quot;*&quot;) ('Size 512))
</span><a href="#local-6989586621679804913"><span class="hs-identifier hs-var hs-var">keyEmbedDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 512))
</span><a href="#local-6989586621679804914"><span class="hs-identifier hs-var">queryEmbedDim</span></a></span><span>
</span><span id="line-346"></span><span>      </span><span id="local-6989586621679804912"><span class="annot"><span class="annottext">dropoutP :: Double
</span><a href="#local-6989586621679804912"><span class="hs-identifier hs-var hs-var">dropoutP</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Double
</span><span class="hs-number">0.0</span></span><span>
</span><span id="line-347"></span><span>      </span><span id="local-6989586621679804911"><span class="annot"><span class="annottext">eps :: Double
</span><a href="#local-6989586621679804911"><span class="hs-identifier hs-var hs-var">eps</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Double
</span><span class="hs-number">1e-6</span></span><span>
</span><span id="line-348"></span><span>  </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679804910"><span class="annot"><span class="annottext">g :: Generator ('Device 'CPU)
</span><a href="#local-6989586621679804910"><span class="hs-identifier hs-var hs-var">g</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SDevice ('Device 'CPU) -&gt; Word64 -&gt; Generator ('Device 'CPU)
forall (device :: Device (DeviceType Nat)).
SDevice device -&gt; Word64 -&gt; Generator device
</span><a href="Torch.GraduallyTyped.Random.html#sMkGenerator"><span class="hs-identifier hs-var">sMkGenerator</span></a></span><span> </span><span class="annot"><span class="annottext">SDevice ('Device 'CPU)
</span><a href="#local-6989586621679804925"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">Word64
</span><span class="hs-number">0</span></span><span>
</span><span id="line-349"></span><span>  </span><span class="hs-special">(</span><span id="local-6989586621679804909"><span class="annot"><span class="annottext">CrossAttention
  'T5
  ('Gradient 'WithGradient)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Dim ('Name &quot;*&quot;) ('Size 8))
  ('Dim ('Name &quot;*&quot;) ('Size 64))
  ('Dim ('Name &quot;*&quot;) ('Size 512))
  ('Dim ('Name &quot;*&quot;) ('Size 512))
  ('Dim ('Name &quot;*&quot;) ('Size 512))
</span><a href="#local-6989586621679804909"><span class="hs-identifier hs-var">ca</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679804908"><span class="annot"><span class="annottext">Generator ('Device 'CPU)
</span><a href="#local-6989586621679804908"><span class="hs-identifier hs-var">g'</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">&lt;-</span><span>
</span><span id="line-350"></span><span>    </span><span class="annot"><span class="annottext">ModelSpec
  (CrossAttention
     'T5
     ('Gradient 'WithGradient)
     ('Device 'CPU)
     ('DataType 'Float)
     ('Dim ('Name &quot;*&quot;) ('Size 8))
     ('Dim ('Name &quot;*&quot;) ('Size 64))
     ('Dim ('Name &quot;*&quot;) ('Size 512))
     ('Dim ('Name &quot;*&quot;) ('Size 512))
     ('Dim ('Name &quot;*&quot;) ('Size 512)))
-&gt; Generator ('Device 'CPU)
-&gt; IO
     (CrossAttention
        'T5
        ('Gradient 'WithGradient)
        ('Device 'CPU)
        ('DataType 'Float)
        ('Dim ('Name &quot;*&quot;) ('Size 8))
        ('Dim ('Name &quot;*&quot;) ('Size 64))
        ('Dim ('Name &quot;*&quot;) ('Size 512))
        ('Dim ('Name &quot;*&quot;) ('Size 512))
        ('Dim ('Name &quot;*&quot;) ('Size 512)),
      Generator ('Device 'CPU))
forall model (generatorDevice :: Device (DeviceType Nat)) output
       (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: Type -&gt; Type).
(HasInitialize model generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
ModelSpec model
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#initialize"><span class="hs-identifier hs-var">initialize</span></a></span><span>
</span><span id="line-351"></span><span>      </span><span class="hs-special">(</span><span class="annot"><span class="annottext">STransformerStyle 'T5
-&gt; SGradient ('Gradient 'WithGradient)
-&gt; SDevice ('Device 'CPU)
-&gt; SDataType ('DataType 'Float)
-&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 8))
-&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 64))
-&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 512))
-&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 512))
-&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 512))
-&gt; Double
-&gt; Double
-&gt; CrossAttentionSpec
     'T5
     ('Gradient 'WithGradient)
     ('Device 'CPU)
     ('DataType 'Float)
     ('Dim ('Name &quot;*&quot;) ('Size 8))
     ('Dim ('Name &quot;*&quot;) ('Size 64))
     ('Dim ('Name &quot;*&quot;) ('Size 512))
     ('Dim ('Name &quot;*&quot;) ('Size 512))
     ('Dim ('Name &quot;*&quot;) ('Size 512))
forall (style :: TransformerStyle)
       (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (headDim :: Dim (Name Symbol) (Size Nat))
       (headEmbedDim :: Dim (Name Symbol) (Size Nat))
       (embedDim :: Dim (Name Symbol) (Size Nat))
       (queryEmbedDim :: Dim (Name Symbol) (Size Nat))
       (keyEmbedDim :: Dim (Name Symbol) (Size Nat)).
STransformerStyle style
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim headDim
-&gt; SDim headEmbedDim
-&gt; SDim embedDim
-&gt; SDim queryEmbedDim
-&gt; SDim keyEmbedDim
-&gt; Double
-&gt; Double
-&gt; CrossAttentionSpec
     style
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     keyEmbedDim
</span><a href="Torch.GraduallyTyped.NN.Transformer.CrossAttention.html#CrossAttentionSpec"><span class="hs-identifier hs-var">CrossAttentionSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle 'T5
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="annot"><span class="annottext">SGradient ('Gradient 'WithGradient)
</span><a href="#local-6989586621679804928"><span class="hs-identifier hs-var">gradient</span></a></span><span> </span><span class="annot"><span class="annottext">SDevice ('Device 'CPU)
</span><a href="#local-6989586621679804925"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType ('DataType 'Float)
</span><a href="#local-6989586621679804922"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 8))
</span><a href="#local-6989586621679804919"><span class="hs-identifier hs-var">headDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 64))
</span><a href="#local-6989586621679804916"><span class="hs-identifier hs-var">headEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 512))
</span><a href="#local-6989586621679804915"><span class="hs-identifier hs-var">embedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 512))
</span><a href="#local-6989586621679804914"><span class="hs-identifier hs-var">queryEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 512))
</span><a href="#local-6989586621679804913"><span class="hs-identifier hs-var">keyEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679804912"><span class="hs-identifier hs-var">dropoutP</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679804911"><span class="hs-identifier hs-var">eps</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-352"></span><span>      </span><span class="annot"><span class="annottext">Generator ('Device 'CPU)
</span><a href="#local-6989586621679804910"><span class="hs-identifier hs-var">g</span></a></span><span>
</span><span id="line-353"></span><span>  </span><span id="local-6989586621679804907"><span class="annot"><span class="annottext">CrossAttention
  'T5
  ('Gradient 'WithGradient)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Dim ('Name &quot;*&quot;) ('Size 8))
  ('Dim ('Name &quot;*&quot;) ('Size 64))
  ('Dim ('Name &quot;*&quot;) ('Size 512))
  ('Dim ('Name &quot;*&quot;) ('Size 512))
  ('Dim ('Name &quot;*&quot;) ('Size 512))
</span><a href="#local-6989586621679804907"><span class="hs-identifier hs-var">ca'</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">(StateT
   StateDict
   IO
   (CrossAttention
      'T5
      ('Gradient 'WithGradient)
      ('Device 'CPU)
      ('DataType 'Float)
      ('Dim ('Name &quot;*&quot;) ('Size 8))
      ('Dim ('Name &quot;*&quot;) ('Size 64))
      ('Dim ('Name &quot;*&quot;) ('Size 512))
      ('Dim ('Name &quot;*&quot;) ('Size 512))
      ('Dim ('Name &quot;*&quot;) ('Size 512)))
 -&gt; StateDict
 -&gt; IO
      (CrossAttention
         'T5
         ('Gradient 'WithGradient)
         ('Device 'CPU)
         ('DataType 'Float)
         ('Dim ('Name &quot;*&quot;) ('Size 8))
         ('Dim ('Name &quot;*&quot;) ('Size 64))
         ('Dim ('Name &quot;*&quot;) ('Size 512))
         ('Dim ('Name &quot;*&quot;) ('Size 512))
         ('Dim ('Name &quot;*&quot;) ('Size 512))))
-&gt; StateDict
-&gt; StateT
     StateDict
     IO
     (CrossAttention
        'T5
        ('Gradient 'WithGradient)
        ('Device 'CPU)
        ('DataType 'Float)
        ('Dim ('Name &quot;*&quot;) ('Size 8))
        ('Dim ('Name &quot;*&quot;) ('Size 64))
        ('Dim ('Name &quot;*&quot;) ('Size 512))
        ('Dim ('Name &quot;*&quot;) ('Size 512))
        ('Dim ('Name &quot;*&quot;) ('Size 512)))
-&gt; IO
     (CrossAttention
        'T5
        ('Gradient 'WithGradient)
        ('Device 'CPU)
        ('DataType 'Float)
        ('Dim ('Name &quot;*&quot;) ('Size 8))
        ('Dim ('Name &quot;*&quot;) ('Size 64))
        ('Dim ('Name &quot;*&quot;) ('Size 512))
        ('Dim ('Name &quot;*&quot;) ('Size 512))
        ('Dim ('Name &quot;*&quot;) ('Size 512)))
forall a b c. (a -&gt; b -&gt; c) -&gt; b -&gt; a -&gt; c
</span><span class="hs-identifier hs-var">flip</span></span><span> </span><span class="annot"><span class="annottext">StateT
  StateDict
  IO
  (CrossAttention
     'T5
     ('Gradient 'WithGradient)
     ('Device 'CPU)
     ('DataType 'Float)
     ('Dim ('Name &quot;*&quot;) ('Size 8))
     ('Dim ('Name &quot;*&quot;) ('Size 64))
     ('Dim ('Name &quot;*&quot;) ('Size 512))
     ('Dim ('Name &quot;*&quot;) ('Size 512))
     ('Dim ('Name &quot;*&quot;) ('Size 512)))
-&gt; StateDict
-&gt; IO
     (CrossAttention
        'T5
        ('Gradient 'WithGradient)
        ('Device 'CPU)
        ('DataType 'Float)
        ('Dim ('Name &quot;*&quot;) ('Size 8))
        ('Dim ('Name &quot;*&quot;) ('Size 64))
        ('Dim ('Name &quot;*&quot;) ('Size 512))
        ('Dim ('Name &quot;*&quot;) ('Size 512))
        ('Dim ('Name &quot;*&quot;) ('Size 512)))
forall (m :: Type -&gt; Type) s a. Monad m =&gt; StateT s m a -&gt; s -&gt; m a
</span><span class="hs-identifier hs-var">evalStateT</span></span><span> </span><span class="annot"><span class="annottext">StateDict
forall k a. Map k a
</span><span class="hs-identifier hs-var">Map.empty</span></span><span> </span><span class="annot"><span class="annottext">(StateT
   StateDict
   IO
   (CrossAttention
      'T5
      ('Gradient 'WithGradient)
      ('Device 'CPU)
      ('DataType 'Float)
      ('Dim ('Name &quot;*&quot;) ('Size 8))
      ('Dim ('Name &quot;*&quot;) ('Size 64))
      ('Dim ('Name &quot;*&quot;) ('Size 512))
      ('Dim ('Name &quot;*&quot;) ('Size 512))
      ('Dim ('Name &quot;*&quot;) ('Size 512)))
 -&gt; IO
      (CrossAttention
         'T5
         ('Gradient 'WithGradient)
         ('Device 'CPU)
         ('DataType 'Float)
         ('Dim ('Name &quot;*&quot;) ('Size 8))
         ('Dim ('Name &quot;*&quot;) ('Size 64))
         ('Dim ('Name &quot;*&quot;) ('Size 512))
         ('Dim ('Name &quot;*&quot;) ('Size 512))
         ('Dim ('Name &quot;*&quot;) ('Size 512))))
-&gt; StateT
     StateDict
     IO
     (CrossAttention
        'T5
        ('Gradient 'WithGradient)
        ('Device 'CPU)
        ('DataType 'Float)
        ('Dim ('Name &quot;*&quot;) ('Size 8))
        ('Dim ('Name &quot;*&quot;) ('Size 64))
        ('Dim ('Name &quot;*&quot;) ('Size 512))
        ('Dim ('Name &quot;*&quot;) ('Size 512))
        ('Dim ('Name &quot;*&quot;) ('Size 512)))
-&gt; IO
     (CrossAttention
        'T5
        ('Gradient 'WithGradient)
        ('Device 'CPU)
        ('DataType 'Float)
        ('Dim ('Name &quot;*&quot;) ('Size 8))
        ('Dim ('Name &quot;*&quot;) ('Size 64))
        ('Dim ('Name &quot;*&quot;) ('Size 512))
        ('Dim ('Name &quot;*&quot;) ('Size 512))
        ('Dim ('Name &quot;*&quot;) ('Size 512)))
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-354"></span><span>    </span><span class="annot"><span class="annottext">StateDictKey
-&gt; CrossAttention
     'T5
     ('Gradient 'WithGradient)
     ('Device 'CPU)
     ('DataType 'Float)
     ('Dim ('Name &quot;*&quot;) ('Size 8))
     ('Dim ('Name &quot;*&quot;) ('Size 64))
     ('Dim ('Name &quot;*&quot;) ('Size 512))
     ('Dim ('Name &quot;*&quot;) ('Size 512))
     ('Dim ('Name &quot;*&quot;) ('Size 512))
-&gt; StateT StateDict IO ()
forall model (m :: Type -&gt; Type).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
StateDictKey -&gt; model -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var">toStateDict</span></a></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;ca.&quot;</span></span><span> </span><span class="annot"><span class="annottext">CrossAttention
  'T5
  ('Gradient 'WithGradient)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Dim ('Name &quot;*&quot;) ('Size 8))
  ('Dim ('Name &quot;*&quot;) ('Size 64))
  ('Dim ('Name &quot;*&quot;) ('Size 512))
  ('Dim ('Name &quot;*&quot;) ('Size 512))
  ('Dim ('Name &quot;*&quot;) ('Size 512))
</span><a href="#local-6989586621679804909"><span class="hs-identifier hs-var">ca</span></a></span><span>
</span><span id="line-355"></span><span>    </span><span class="annot"><span class="annottext">ModelSpec
  (CrossAttention
     'T5
     ('Gradient 'WithGradient)
     ('Device 'CPU)
     ('DataType 'Float)
     ('Dim ('Name &quot;*&quot;) ('Size 8))
     ('Dim ('Name &quot;*&quot;) ('Size 64))
     ('Dim ('Name &quot;*&quot;) ('Size 512))
     ('Dim ('Name &quot;*&quot;) ('Size 512))
     ('Dim ('Name &quot;*&quot;) ('Size 512)))
-&gt; StateDictKey
-&gt; StateT
     StateDict
     IO
     (CrossAttention
        'T5
        ('Gradient 'WithGradient)
        ('Device 'CPU)
        ('DataType 'Float)
        ('Dim ('Name &quot;*&quot;) ('Size 8))
        ('Dim ('Name &quot;*&quot;) ('Size 64))
        ('Dim ('Name &quot;*&quot;) ('Size 512))
        ('Dim ('Name &quot;*&quot;) ('Size 512))
        ('Dim ('Name &quot;*&quot;) ('Size 512)))
forall model (m :: Type -&gt; Type).
(HasStateDict model, MonadThrow m, MonadState StateDict m) =&gt;
ModelSpec model -&gt; StateDictKey -&gt; m model
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var">fromStateDict</span></a></span><span>
</span><span id="line-356"></span><span>      </span><span class="hs-special">(</span><span class="annot"><span class="annottext">STransformerStyle 'T5
-&gt; SGradient ('Gradient 'WithGradient)
-&gt; SDevice ('Device 'CPU)
-&gt; SDataType ('DataType 'Float)
-&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 8))
-&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 64))
-&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 512))
-&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 512))
-&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 512))
-&gt; Double
-&gt; Double
-&gt; CrossAttentionSpec
     'T5
     ('Gradient 'WithGradient)
     ('Device 'CPU)
     ('DataType 'Float)
     ('Dim ('Name &quot;*&quot;) ('Size 8))
     ('Dim ('Name &quot;*&quot;) ('Size 64))
     ('Dim ('Name &quot;*&quot;) ('Size 512))
     ('Dim ('Name &quot;*&quot;) ('Size 512))
     ('Dim ('Name &quot;*&quot;) ('Size 512))
forall (style :: TransformerStyle)
       (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (headDim :: Dim (Name Symbol) (Size Nat))
       (headEmbedDim :: Dim (Name Symbol) (Size Nat))
       (embedDim :: Dim (Name Symbol) (Size Nat))
       (queryEmbedDim :: Dim (Name Symbol) (Size Nat))
       (keyEmbedDim :: Dim (Name Symbol) (Size Nat)).
STransformerStyle style
-&gt; SGradient gradient
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SDim headDim
-&gt; SDim headEmbedDim
-&gt; SDim embedDim
-&gt; SDim queryEmbedDim
-&gt; SDim keyEmbedDim
-&gt; Double
-&gt; Double
-&gt; CrossAttentionSpec
     style
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     keyEmbedDim
</span><a href="Torch.GraduallyTyped.NN.Transformer.CrossAttention.html#CrossAttentionSpec"><span class="hs-identifier hs-var">CrossAttentionSpec</span></a></span><span> </span><span class="annot"><span class="annottext">STransformerStyle 'T5
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ST5"><span class="hs-identifier hs-var">ST5</span></a></span><span> </span><span class="annot"><span class="annottext">SGradient ('Gradient 'WithGradient)
</span><a href="#local-6989586621679804928"><span class="hs-identifier hs-var">gradient</span></a></span><span> </span><span class="annot"><span class="annottext">SDevice ('Device 'CPU)
</span><a href="#local-6989586621679804925"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType ('DataType 'Float)
</span><a href="#local-6989586621679804922"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 8))
</span><a href="#local-6989586621679804919"><span class="hs-identifier hs-var">headDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 64))
</span><a href="#local-6989586621679804916"><span class="hs-identifier hs-var">headEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 512))
</span><a href="#local-6989586621679804915"><span class="hs-identifier hs-var">embedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 512))
</span><a href="#local-6989586621679804914"><span class="hs-identifier hs-var">queryEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 512))
</span><a href="#local-6989586621679804913"><span class="hs-identifier hs-var">keyEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679804912"><span class="hs-identifier hs-var">dropoutP</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679804911"><span class="hs-identifier hs-var">eps</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-357"></span><span>      </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-string">&quot;ca.&quot;</span></span><span>
</span><span id="line-358"></span><span>  </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679804904"><span class="annot"><span class="annottext">batchDim :: SDim ('Dim ('Name &quot;*&quot;) ('Size 3))
</span><a href="#local-6989586621679804904"><span class="hs-identifier hs-var hs-var">batchDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize ('Size 3) -&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 3))
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownNat 3 =&gt; SSize ('Size 3)
forall (size :: Nat). KnownNat size =&gt; SSize ('Size size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier hs-var">SSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">3</span></span><span>
</span><span id="line-359"></span><span>      </span><span id="local-6989586621679804903"><span class="annot"><span class="annottext">seqDim :: SDim ('Dim ('Name &quot;*&quot;) ('Size 4))
</span><a href="#local-6989586621679804903"><span class="hs-identifier hs-var hs-var">seqDim</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize ('Size 4) -&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 4))
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownNat 4 =&gt; SSize ('Size 4)
forall (size :: Nat). KnownNat size =&gt; SSize ('Size size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier hs-var">SSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">4</span></span><span>
</span><span id="line-360"></span><span>      </span><span id="local-6989586621679804902"><span class="annot"><span class="annottext">sOnes' :: SDataType dataType
-&gt; SShape shape
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     dataType
     shape
</span><a href="#local-6989586621679804902"><span class="hs-identifier hs-var hs-var">sOnes'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">TensorSpec
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  dataType
  shape
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     dataType
     shape
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
TensorSpec gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.Creation.html#sOnes"><span class="hs-identifier hs-var">sOnes</span></a></span><span> </span><span class="annot"><span class="annottext">(TensorSpec
   ('Gradient 'WithoutGradient)
   ('Layout 'Dense)
   ('Device 'CPU)
   dataType
   shape
 -&gt; Tensor
      ('Gradient 'WithoutGradient)
      ('Layout 'Dense)
      ('Device 'CPU)
      dataType
      shape)
-&gt; (SShape shape
    -&gt; TensorSpec
         ('Gradient 'WithoutGradient)
         ('Layout 'Dense)
         ('Device 'CPU)
         dataType
         shape)
-&gt; SShape shape
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     dataType
     shape
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">((SShape shape
  -&gt; TensorSpec
       ('Gradient 'WithoutGradient)
       ('Layout 'Dense)
       ('Device 'CPU)
       dataType
       shape)
 -&gt; SShape shape
 -&gt; Tensor
      ('Gradient 'WithoutGradient)
      ('Layout 'Dense)
      ('Device 'CPU)
      dataType
      shape)
-&gt; (SDataType dataType
    -&gt; SShape shape
    -&gt; TensorSpec
         ('Gradient 'WithoutGradient)
         ('Layout 'Dense)
         ('Device 'CPU)
         dataType
         shape)
-&gt; SDataType dataType
-&gt; SShape shape
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     dataType
     shape
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">SGradient ('Gradient 'WithoutGradient)
-&gt; SLayout ('Layout 'Dense)
-&gt; SDevice ('Device 'CPU)
-&gt; SDataType dataType
-&gt; SShape shape
-&gt; TensorSpec
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     dataType
     shape
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SShape shape
-&gt; TensorSpec gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorSpec"><span class="hs-identifier hs-var">TensorSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SRequiresGradient 'WithoutGradient
-&gt; SGradient ('Gradient 'WithoutGradient)
forall (requiresGradient :: RequiresGradient).
SRequiresGradient requiresGradient
-&gt; SGradient ('Gradient requiresGradient)
</span><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier hs-var">SGradient</span></a></span><span> </span><span class="annot"><span class="annottext">SRequiresGradient 'WithoutGradient
</span><a href="Torch.GraduallyTyped.RequiresGradient.html#SWithoutGradient"><span class="hs-identifier hs-var">SWithoutGradient</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SLayoutType 'Dense -&gt; SLayout ('Layout 'Dense)
forall (layoutType :: LayoutType).
SLayoutType layoutType -&gt; SLayout ('Layout layoutType)
</span><a href="Torch.GraduallyTyped.Layout.html#SLayout"><span class="hs-identifier hs-var">SLayout</span></a></span><span> </span><span class="annot"><span class="annottext">SLayoutType 'Dense
</span><a href="Torch.GraduallyTyped.Layout.html#SDense"><span class="hs-identifier hs-var">SDense</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">SDevice ('Device 'CPU)
</span><a href="#local-6989586621679804925"><span class="hs-identifier hs-var">device</span></a></span><span>
</span><span id="line-361"></span><span>      </span><span id="local-6989586621679804897"><span class="annot"><span class="annottext">query :: Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 4),
        'Dim ('Name &quot;*&quot;) ('Size 512)])
</span><a href="#local-6989586621679804897"><span class="hs-identifier hs-var hs-var">query</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SDataType ('DataType 'Float)
-&gt; SShape
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 4),
           'Dim ('Name &quot;*&quot;) ('Size 512)])
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     ('DataType 'Float)
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 4),
           'Dim ('Name &quot;*&quot;) ('Size 512)])
forall (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SDataType dataType
-&gt; SShape shape
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     dataType
     shape
</span><a href="#local-6989586621679804902"><span class="hs-identifier hs-var">sOnes'</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType ('DataType 'Float)
</span><a href="#local-6989586621679804922"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SList
  '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 4),
     'Dim ('Name &quot;*&quot;) ('Size 512)]
-&gt; SShape
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 4),
           'Dim ('Name &quot;*&quot;) ('Size 512)])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList
   '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 4),
      'Dim ('Name &quot;*&quot;) ('Size 512)]
 -&gt; SShape
      ('Shape
         '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 4),
            'Dim ('Name &quot;*&quot;) ('Size 512)]))
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 4),
        'Dim ('Name &quot;*&quot;) ('Size 512)]
-&gt; SShape
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 4),
           'Dim ('Name &quot;*&quot;) ('Size 512)])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 3))
</span><a href="#local-6989586621679804904"><span class="hs-identifier hs-var">batchDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 3))
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 4), 'Dim ('Name &quot;*&quot;) ('Size 512)]
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 4),
        'Dim ('Name &quot;*&quot;) ('Size 512)]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 4))
</span><a href="#local-6989586621679804903"><span class="hs-identifier hs-var">seqDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 4))
-&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 512)]
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 4), 'Dim ('Name &quot;*&quot;) ('Size 512)]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 512))
</span><a href="#local-6989586621679804914"><span class="hs-identifier hs-var">queryEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 512))
-&gt; SList '[] -&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 512)]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-362"></span><span>      </span><span id="local-6989586621679804896"><span class="annot"><span class="annottext">key :: Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 4),
        'Dim ('Name &quot;*&quot;) ('Size 512)])
</span><a href="#local-6989586621679804896"><span class="hs-identifier hs-var hs-var">key</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SDataType ('DataType 'Float)
-&gt; SShape
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 4),
           'Dim ('Name &quot;*&quot;) ('Size 512)])
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     ('DataType 'Float)
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 4),
           'Dim ('Name &quot;*&quot;) ('Size 512)])
forall (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SDataType dataType
-&gt; SShape shape
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     dataType
     shape
</span><a href="#local-6989586621679804902"><span class="hs-identifier hs-var">sOnes'</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType ('DataType 'Float)
</span><a href="#local-6989586621679804922"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SList
  '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 4),
     'Dim ('Name &quot;*&quot;) ('Size 512)]
-&gt; SShape
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 4),
           'Dim ('Name &quot;*&quot;) ('Size 512)])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList
   '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 4),
      'Dim ('Name &quot;*&quot;) ('Size 512)]
 -&gt; SShape
      ('Shape
         '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 4),
            'Dim ('Name &quot;*&quot;) ('Size 512)]))
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 4),
        'Dim ('Name &quot;*&quot;) ('Size 512)]
-&gt; SShape
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 4),
           'Dim ('Name &quot;*&quot;) ('Size 512)])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 3))
</span><a href="#local-6989586621679804904"><span class="hs-identifier hs-var">batchDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 3))
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 4), 'Dim ('Name &quot;*&quot;) ('Size 512)]
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 4),
        'Dim ('Name &quot;*&quot;) ('Size 512)]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 4))
</span><a href="#local-6989586621679804903"><span class="hs-identifier hs-var">seqDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 4))
-&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 512)]
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 4), 'Dim ('Name &quot;*&quot;) ('Size 512)]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 512))
</span><a href="#local-6989586621679804913"><span class="hs-identifier hs-var">keyEmbedDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 512))
-&gt; SList '[] -&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 512)]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-363"></span><span>      </span><span id="local-6989586621679804895"><span class="annot"><span class="annottext">attentionBias :: Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 1),
        'Dim ('Name &quot;*&quot;) ('Size 4), 'Dim ('Name &quot;*&quot;) ('Size 4)])
</span><a href="#local-6989586621679804895"><span class="hs-identifier hs-var hs-var">attentionBias</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SDataType ('DataType 'Float)
-&gt; SShape
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 1),
           'Dim ('Name &quot;*&quot;) ('Size 4), 'Dim ('Name &quot;*&quot;) ('Size 4)])
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     ('DataType 'Float)
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 1),
           'Dim ('Name &quot;*&quot;) ('Size 4), 'Dim ('Name &quot;*&quot;) ('Size 4)])
forall (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SDataType dataType
-&gt; SShape shape
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     ('Device 'CPU)
     dataType
     shape
</span><a href="#local-6989586621679804902"><span class="hs-identifier hs-var">sOnes'</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType ('DataType 'Float)
</span><a href="#local-6989586621679804922"><span class="hs-identifier hs-var">dataType</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SList
  '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 1),
     'Dim ('Name &quot;*&quot;) ('Size 4), 'Dim ('Name &quot;*&quot;) ('Size 4)]
-&gt; SShape
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 1),
           'Dim ('Name &quot;*&quot;) ('Size 4), 'Dim ('Name &quot;*&quot;) ('Size 4)])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList
   '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 1),
      'Dim ('Name &quot;*&quot;) ('Size 4), 'Dim ('Name &quot;*&quot;) ('Size 4)]
 -&gt; SShape
      ('Shape
         '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 1),
            'Dim ('Name &quot;*&quot;) ('Size 4), 'Dim ('Name &quot;*&quot;) ('Size 4)]))
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 1),
        'Dim ('Name &quot;*&quot;) ('Size 4), 'Dim ('Name &quot;*&quot;) ('Size 4)]
-&gt; SShape
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 1),
           'Dim ('Name &quot;*&quot;) ('Size 4), 'Dim ('Name &quot;*&quot;) ('Size 4)])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 3))
</span><a href="#local-6989586621679804904"><span class="hs-identifier hs-var">batchDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 3))
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 4),
        'Dim ('Name &quot;*&quot;) ('Size 4)]
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 1),
        'Dim ('Name &quot;*&quot;) ('Size 4), 'Dim ('Name &quot;*&quot;) ('Size 4)]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize ('Size 1) -&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 1))
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownNat 1 =&gt; SSize ('Size 1)
forall (size :: Nat). KnownNat size =&gt; SSize ('Size size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier hs-var">SSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">1</span></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 1))
-&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 4), 'Dim ('Name &quot;*&quot;) ('Size 4)]
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) ('Size 4),
        'Dim ('Name &quot;*&quot;) ('Size 4)]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 4))
</span><a href="#local-6989586621679804903"><span class="hs-identifier hs-var">seqDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 4))
-&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 4)]
-&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 4), 'Dim ('Name &quot;*&quot;) ('Size 4)]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 4))
</span><a href="#local-6989586621679804903"><span class="hs-identifier hs-var">seqDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 4))
-&gt; SList '[] -&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 4)]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-364"></span><span>  </span><span class="hs-special">(</span><span id="local-6989586621679804894"><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 4),
        'Dim ('Name &quot;*&quot;) ('Size 512)])
</span><a href="#local-6989586621679804894"><span class="hs-identifier hs-var">output</span></a></span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Generator ('Device 'CPU)
</span><span class="hs-identifier">_</span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">CrossAttention
  'T5
  ('Gradient 'WithGradient)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Dim ('Name &quot;*&quot;) ('Size 8))
  ('Dim ('Name &quot;*&quot;) ('Size 64))
  ('Dim ('Name &quot;*&quot;) ('Size 512))
  ('Dim ('Name &quot;*&quot;) ('Size 512))
  ('Dim ('Name &quot;*&quot;) ('Size 512))
-&gt; (Tensor
      ('Gradient 'WithoutGradient)
      ('Layout 'Dense)
      ('Device 'CPU)
      ('DataType 'Float)
      ('Shape
         '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 4),
            'Dim ('Name &quot;*&quot;) ('Size 512)]),
    Tensor
      ('Gradient 'WithoutGradient)
      ('Layout 'Dense)
      ('Device 'CPU)
      ('DataType 'Float)
      ('Shape
         '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 4),
            'Dim ('Name &quot;*&quot;) ('Size 512)]),
    Tensor
      ('Gradient 'WithoutGradient)
      ('Layout 'Dense)
      ('Device 'CPU)
      ('DataType 'Float)
      ('Shape
         '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 1),
            'Dim ('Name &quot;*&quot;) ('Size 4), 'Dim ('Name &quot;*&quot;) ('Size 4)]))
-&gt; Generator ('Device 'CPU)
-&gt; IO
     (Tensor
        ('Gradient 'WithGradient)
        ('Layout 'Dense)
        ('Device 'CPU)
        ('DataType 'Float)
        ('Shape
           '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 4),
              'Dim ('Name &quot;*&quot;) ('Size 512)]),
      Generator ('Device 'CPU))
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: Type -&gt; Type).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><span class="annottext">CrossAttention
  'T5
  ('Gradient 'WithGradient)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Dim ('Name &quot;*&quot;) ('Size 8))
  ('Dim ('Name &quot;*&quot;) ('Size 64))
  ('Dim ('Name &quot;*&quot;) ('Size 512))
  ('Dim ('Name &quot;*&quot;) ('Size 512))
  ('Dim ('Name &quot;*&quot;) ('Size 512))
</span><a href="#local-6989586621679804907"><span class="hs-identifier hs-var">ca'</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 4),
        'Dim ('Name &quot;*&quot;) ('Size 512)])
</span><a href="#local-6989586621679804897"><span class="hs-identifier hs-var">query</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 4),
        'Dim ('Name &quot;*&quot;) ('Size 512)])
</span><a href="#local-6989586621679804896"><span class="hs-identifier hs-var">key</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 1),
        'Dim ('Name &quot;*&quot;) ('Size 4), 'Dim ('Name &quot;*&quot;) ('Size 4)])
</span><a href="#local-6989586621679804895"><span class="hs-identifier hs-var">attentionBias</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Generator ('Device 'CPU)
</span><a href="#local-6989586621679804908"><span class="hs-identifier hs-var">g'</span></a></span><span>
</span><span id="line-365"></span><span>  </span><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 4),
        'Dim ('Name &quot;*&quot;) ('Size 512)])
-&gt; IO
     (Tensor
        ('Gradient 'WithGradient)
        ('Layout 'Dense)
        ('Device 'CPU)
        ('DataType 'Float)
        ('Shape
           '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 4),
              'Dim ('Name &quot;*&quot;) ('Size 512)]))
forall (f :: Type -&gt; Type) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithGradient)
  ('Layout 'Dense)
  ('Device 'CPU)
  ('DataType 'Float)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 3), 'Dim ('Name &quot;*&quot;) ('Size 4),
        'Dim ('Name &quot;*&quot;) ('Size 512)])
</span><a href="#local-6989586621679804894"><span class="hs-identifier hs-var">output</span></a></span><span>
</span><span id="line-366"></span><span>
</span><span id="line-367"></span><span class="hs-comment">-- | 'HasForward' instance for @CrossAttention 'ByT5@.</span><span>
</span><span id="line-368"></span><span class="hs-comment">--</span><span>
</span><span id="line-369"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-370"></span><span class="hs-comment">--    &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;  &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;  &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;</span><span>
</span><span id="line-371"></span><span class="hs-comment">--    &#9474; query &#9474;  &#9474; key &#9474;  &#9474; attentionBias &#9474;</span><span>
</span><span id="line-372"></span><span class="hs-comment">--    &#9492;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9496;  &#9492;&#9472;&#9472;&#9516;&#9472;&#9472;&#9496;  &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-373"></span><span class="hs-comment">--        &#9474;         &#9474;             &#9474;</span><span>
</span><span id="line-374"></span><span class="hs-comment">-- &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9508;         &#9474;             &#9474;</span><span>
</span><span id="line-375"></span><span class="hs-comment">-- &#9474;      &#9474;         &#9474;             &#9474;</span><span>
</span><span id="line-376"></span><span class="hs-comment">-- &#9474;      &#9660;         &#9474;             &#9474;</span><span>
</span><span id="line-377"></span><span class="hs-comment">-- &#9474; caLayerNorm    &#9474;             &#9474;</span><span>
</span><span id="line-378"></span><span class="hs-comment">-- &#9474;      &#9474;         &#9474;             &#9474;</span><span>
</span><span id="line-379"></span><span class="hs-comment">-- &#9474;      &#9474;      &#9484;&#9472;&#9472;&#9524;&#9472;&#9472;&#9488;          &#9474;</span><span>
</span><span id="line-380"></span><span class="hs-comment">-- &#9474;      &#9474;      &#9474;     &#9474;          &#9474;</span><span>
</span><span id="line-381"></span><span class="hs-comment">-- &#9474;      &#9660;      &#9660;     &#9660;          &#9474;</span><span>
</span><span id="line-382"></span><span class="hs-comment">-- &#9474;   caMultiheadAttention&#9668;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-383"></span><span class="hs-comment">-- &#9474;             &#9474;</span><span>
</span><span id="line-384"></span><span class="hs-comment">-- &#9474;             &#9660;</span><span>
</span><span id="line-385"></span><span class="hs-comment">-- &#9474;         caDropout</span><span>
</span><span id="line-386"></span><span class="hs-comment">-- &#9474;             &#9474;</span><span>
</span><span id="line-387"></span><span class="hs-comment">-- &#9492;&#9472;&#9472;&#9472;&#9472;&#9658;add&#9668;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-388"></span><span class="hs-comment">--        &#9474;</span><span>
</span><span id="line-389"></span><span class="hs-comment">--        &#9660;</span><span>
</span><span id="line-390"></span><span class="hs-comment">--    &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;</span><span>
</span><span id="line-391"></span><span class="hs-comment">--    &#9474; query &#9474;</span><span>
</span><span id="line-392"></span><span class="hs-comment">--    &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-393"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-394"></span><span id="local-6989586621679804867"><span id="local-6989586621679804868"><span id="local-6989586621679804869"><span id="local-6989586621679804870"><span id="local-6989586621679804871"><span id="local-6989586621679804872"><span id="local-6989586621679804873"><span id="local-6989586621679804874"><span id="local-6989586621679804875"><span id="local-6989586621679804876"><span id="local-6989586621679804877"><span id="local-6989586621679804878"><span id="local-6989586621679804879"><span id="local-6989586621679804880"><span id="local-6989586621679804881"><span id="local-6989586621679804882"><span id="local-6989586621679804883"><span id="local-6989586621679804884"><span id="local-6989586621679804885"><span id="local-6989586621679804886"><span id="local-6989586621679804887"><span id="local-6989586621679804888"><span id="local-6989586621679804889"><span id="local-6989586621679804890"><span id="local-6989586621679804891"><span id="local-6989586621679804892"><span id="local-6989586621679804893"><span class="hs-keyword">instance</span><span>
</span><span id="line-395"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetDim"><span class="hs-identifier hs-type">SGetDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804893"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-396"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-397"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.CrossAttention.html#CALayerNormF"><span class="hs-identifier hs-type">CALayerNormF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ByT5"><span class="hs-identifier hs-type">ByT5</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804892"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804891"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804890"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804893"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-398"></span><span>      </span><span class="annot"><a href="#local-6989586621679804889"><span class="hs-identifier hs-type">query</span></a></span><span>
</span><span id="line-399"></span><span>      </span><span class="annot"><a href="#local-6989586621679804888"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-400"></span><span>      </span><span class="annot"><a href="#local-6989586621679804887"><span class="hs-identifier hs-type">layerNormOutput</span></a></span><span>
</span><span id="line-401"></span><span>      </span><span class="annot"><a href="#local-6989586621679804888"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-402"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-403"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.CrossAttention.html#CAMultiheadAttentionF"><span class="hs-identifier hs-type">CAMultiheadAttentionF</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ByT5"><span class="hs-identifier hs-type">ByT5</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804892"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804891"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804890"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804886"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804885"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804884"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804893"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804883"><span class="hs-identifier hs-type">keyEmbedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-404"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679804887"><span class="hs-identifier hs-type">layerNormOutput</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679804882"><span class="hs-identifier hs-type">key</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679804882"><span class="hs-identifier hs-type">key</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679804881"><span class="hs-identifier hs-type">attentionBias</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-405"></span><span>      </span><span class="annot"><a href="#local-6989586621679804888"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-406"></span><span>      </span><span class="annot"><a href="#local-6989586621679804880"><span class="hs-identifier hs-type">mhaOutput</span></a></span><span>
</span><span id="line-407"></span><span>      </span><span class="annot"><a href="#local-6989586621679804879"><span class="hs-identifier hs-type">device2</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-408"></span><span>    </span><span class="annot"><a href="#local-6989586621679804889"><span class="hs-identifier hs-type">query</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804878"><span class="hs-identifier hs-type">gradient0</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804877"><span class="hs-identifier hs-type">layout0</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804876"><span class="hs-identifier hs-type">device0</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804875"><span class="hs-identifier hs-type">dataType0</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804874"><span class="hs-identifier hs-type">shape0</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-409"></span><span>    </span><span class="annot"><a href="#local-6989586621679804880"><span class="hs-identifier hs-type">mhaOutput</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804873"><span class="hs-identifier hs-type">gradient1</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804872"><span class="hs-identifier hs-type">layout1</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804871"><span class="hs-identifier hs-type">device1</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804870"><span class="hs-identifier hs-type">dataType1</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804869"><span class="hs-identifier hs-type">shape1</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-410"></span><span>    </span><span class="annot"><a href="#local-6989586621679804868"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-411"></span><span>      </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-412"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679804878"><span class="hs-identifier hs-type">gradient0</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804873"><span class="hs-identifier hs-type">gradient1</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-413"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679804877"><span class="hs-identifier hs-type">layout0</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804872"><span class="hs-identifier hs-type">layout1</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-414"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679804876"><span class="hs-identifier hs-type">device0</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804871"><span class="hs-identifier hs-type">device1</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804879"><span class="hs-identifier hs-type">device2</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-415"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679804875"><span class="hs-identifier hs-type">dataType0</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804870"><span class="hs-identifier hs-type">dataType1</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-416"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#BroadcastShapesF"><span class="hs-identifier hs-type">BroadcastShapesF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804874"><span class="hs-identifier hs-type">shape0</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804869"><span class="hs-identifier hs-type">shape1</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-417"></span><span>    </span><span class="annot"><a href="#local-6989586621679804867"><span class="hs-identifier hs-type">generatorOutputDevice</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679804871"><span class="hs-identifier hs-type">device1</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804879"><span class="hs-identifier hs-type">device2</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-418"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-419"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-420"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.CrossAttention.html#CrossAttention"><span class="hs-identifier hs-type">CrossAttention</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ByT5"><span class="hs-identifier hs-type">ByT5</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804892"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804891"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804890"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804886"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804885"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804884"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804893"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804883"><span class="hs-identifier hs-type">keyEmbedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-421"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679804889"><span class="hs-identifier hs-type">query</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679804882"><span class="hs-identifier hs-type">key</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679804881"><span class="hs-identifier hs-type">attentionBias</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-422"></span><span>    </span><span class="annot"><a href="#local-6989586621679804888"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-423"></span><span>    </span><span class="annot"><a href="#local-6989586621679804868"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-424"></span><span>    </span><span class="annot"><a href="#local-6989586621679804867"><span class="hs-identifier hs-type">generatorOutputDevice</span></a></span><span>
</span><span id="line-425"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-426"></span><span>  </span><span id="local-6989586621679804865"><span class="annot"><span class="annottext">forward :: CrossAttention
  'ByT5
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  queryEmbedDim
  keyEmbedDim
-&gt; (query, key, attentionBias)
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="#local-6989586621679804865"><span class="hs-identifier hs-var hs-var hs-var hs-var">forward</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.CrossAttention.html#CrossAttention"><span class="hs-identifier hs-type">CrossAttention</span></a></span><span> </span><span id="local-6989586621679804864"><span class="annot"><span class="annottext">GCrossAttention
  (CAMultiheadAttentionF
     'ByT5
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     keyEmbedDim)
  (CALayerNormF 'ByT5 gradient device dataType queryEmbedDim)
  (CADropoutF 'ByT5)
</span><a href="#local-6989586621679804864"><span class="hs-identifier hs-var">ca</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679804863"><span class="annot"><span class="annottext">query
</span><a href="#local-6989586621679804863"><span class="hs-identifier hs-var">query</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679804862"><span class="annot"><span class="annottext">key
</span><a href="#local-6989586621679804862"><span class="hs-identifier hs-var">key</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679804861"><span class="annot"><span class="annottext">attentionBias
</span><a href="#local-6989586621679804861"><span class="hs-identifier hs-var">attentionBias</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-427"></span><span>    </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorOutputDevice)
  output
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
forall (m :: Type -&gt; Type) i j a. IxStateT m i j a -&gt; i -&gt; m (a, j)
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var hs-var">runIxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">(IxStateT
   m
   (Generator generatorDevice)
   (Generator generatorOutputDevice)
   output
 -&gt; Generator generatorDevice
 -&gt; m (output, Generator generatorOutputDevice))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorOutputDevice)
     output
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-428"></span><span>      </span><span class="annot"><span class="annottext">query
-&gt; IxStateT
     m (Generator generatorDevice) (Generator generatorDevice) query
forall k (m :: k -&gt; k -&gt; Type -&gt; Type) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">query
</span><a href="#local-6989586621679804863"><span class="hs-identifier hs-var">query</span></a></span><span>
</span><span id="line-429"></span><span>        </span><span class="annot"><span class="annottext">IxStateT
  m (Generator generatorDevice) (Generator generatorDevice) query
-&gt; (query
    -&gt; IxStateT
         m
         (Generator generatorDevice)
         (Generator generatorDevice)
         layerNormOutput)
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     layerNormOutput
forall k1 (m :: k1 -&gt; k1 -&gt; Type -&gt; Type) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(Generator generatorDevice
 -&gt; m (layerNormOutput, Generator generatorDevice))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     layerNormOutput
forall (m :: Type -&gt; Type) i j a.
(i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator generatorDevice
  -&gt; m (layerNormOutput, Generator generatorDevice))
 -&gt; IxStateT
      m
      (Generator generatorDevice)
      (Generator generatorDevice)
      layerNormOutput)
-&gt; (query
    -&gt; Generator generatorDevice
    -&gt; m (layerNormOutput, Generator generatorDevice))
-&gt; query
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     layerNormOutput
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">LayerNorm
  'WithoutBias gradient device dataType ('Shape '[queryEmbedDim])
-&gt; query
-&gt; Generator generatorDevice
-&gt; m (layerNormOutput, Generator generatorDevice)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: Type -&gt; Type).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">GCrossAttention
  (MultiHeadAttention
     'ByT5
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     keyEmbedDim
     keyEmbedDim)
  (LayerNorm
     'WithoutBias gradient device dataType ('Shape '[queryEmbedDim]))
  Dropout
-&gt; LayerNorm
     'WithoutBias gradient device dataType ('Shape '[queryEmbedDim])
forall mha layerNorm dropout.
GCrossAttention mha layerNorm dropout -&gt; layerNorm
</span><a href="Torch.GraduallyTyped.NN.Transformer.CrossAttention.html#caLayerNorm"><span class="hs-identifier hs-var hs-var">caLayerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">GCrossAttention
  (MultiHeadAttention
     'ByT5
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     keyEmbedDim
     keyEmbedDim)
  (LayerNorm
     'WithoutBias gradient device dataType ('Shape '[queryEmbedDim]))
  Dropout
GCrossAttention
  (CAMultiheadAttentionF
     'ByT5
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     keyEmbedDim)
  (CALayerNormF 'ByT5 gradient device dataType queryEmbedDim)
  (CADropoutF 'ByT5)
</span><a href="#local-6989586621679804864"><span class="hs-identifier hs-var">ca</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-430"></span><span>        </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorDevice)
  layerNormOutput
-&gt; (layerNormOutput
    -&gt; IxStateT
         m
         (Generator generatorDevice)
         (Generator device2)
         (Tensor gradient1 layout1 device1 dataType1 shape1))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator device2)
     (Tensor gradient1 layout1 device1 dataType1 shape1)
forall k1 (m :: k1 -&gt; k1 -&gt; Type -&gt; Type) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">\</span><span id="local-6989586621679804860"><span class="annot"><span class="annottext">layerNormOutput
</span><a href="#local-6989586621679804860"><span class="hs-identifier hs-var">query'</span></a></span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">(Generator generatorDevice
 -&gt; m (Tensor gradient1 layout1 device1 dataType1 shape1,
       Generator device2))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator device2)
     (Tensor gradient1 layout1 device1 dataType1 shape1)
forall (m :: Type -&gt; Type) i j a.
(i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator generatorDevice
  -&gt; m (Tensor gradient1 layout1 device1 dataType1 shape1,
        Generator device2))
 -&gt; IxStateT
      m
      (Generator generatorDevice)
      (Generator device2)
      (Tensor gradient1 layout1 device1 dataType1 shape1))
-&gt; (Generator generatorDevice
    -&gt; m (Tensor gradient1 layout1 device1 dataType1 shape1,
          Generator device2))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator device2)
     (Tensor gradient1 layout1 device1 dataType1 shape1)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">MultiHeadAttention
  'ByT5
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  queryEmbedDim
  keyEmbedDim
  keyEmbedDim
-&gt; (layerNormOutput, key, key, attentionBias)
-&gt; Generator generatorDevice
-&gt; m (Tensor gradient1 layout1 device1 dataType1 shape1,
      Generator device2)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: Type -&gt; Type).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">GCrossAttention
  (MultiHeadAttention
     'ByT5
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     keyEmbedDim
     keyEmbedDim)
  (LayerNorm
     'WithoutBias gradient device dataType ('Shape '[queryEmbedDim]))
  Dropout
-&gt; MultiHeadAttention
     'ByT5
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     keyEmbedDim
     keyEmbedDim
forall mha layerNorm dropout.
GCrossAttention mha layerNorm dropout -&gt; mha
</span><a href="Torch.GraduallyTyped.NN.Transformer.CrossAttention.html#caMultiHeadAttention"><span class="hs-identifier hs-var hs-var">caMultiHeadAttention</span></a></span><span> </span><span class="annot"><span class="annottext">GCrossAttention
  (MultiHeadAttention
     'ByT5
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     keyEmbedDim
     keyEmbedDim)
  (LayerNorm
     'WithoutBias gradient device dataType ('Shape '[queryEmbedDim]))
  Dropout
GCrossAttention
  (CAMultiheadAttentionF
     'ByT5
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     keyEmbedDim)
  (CALayerNormF 'ByT5 gradient device dataType queryEmbedDim)
  (CADropoutF 'ByT5)
</span><a href="#local-6989586621679804864"><span class="hs-identifier hs-var">ca</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">layerNormOutput
</span><a href="#local-6989586621679804860"><span class="hs-identifier hs-var">query'</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">key
</span><a href="#local-6989586621679804862"><span class="hs-identifier hs-var">key</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">key
</span><a href="#local-6989586621679804862"><span class="hs-identifier hs-var">key</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">attentionBias
</span><a href="#local-6989586621679804861"><span class="hs-identifier hs-var">attentionBias</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-431"></span><span>        </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator device2)
  (Tensor gradient1 layout1 device1 dataType1 shape1)
-&gt; (Tensor gradient1 layout1 device1 dataType1 shape1
    -&gt; IxStateT
         m
         (Generator device2)
         (Generator generatorOutputDevice)
         (Tensor gradient1 layout1 generatorOutputDevice dataType1 shape1))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorOutputDevice)
     (Tensor gradient1 layout1 generatorOutputDevice dataType1 shape1)
forall k1 (m :: k1 -&gt; k1 -&gt; Type -&gt; Type) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(Generator device2
 -&gt; m (Tensor
         gradient1 layout1 generatorOutputDevice dataType1 shape1,
       Generator generatorOutputDevice))
-&gt; IxStateT
     m
     (Generator device2)
     (Generator generatorOutputDevice)
     (Tensor gradient1 layout1 generatorOutputDevice dataType1 shape1)
forall (m :: Type -&gt; Type) i j a.
(i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator device2
  -&gt; m (Tensor
          gradient1 layout1 generatorOutputDevice dataType1 shape1,
        Generator generatorOutputDevice))
 -&gt; IxStateT
      m
      (Generator device2)
      (Generator generatorOutputDevice)
      (Tensor gradient1 layout1 generatorOutputDevice dataType1 shape1))
-&gt; (Tensor gradient1 layout1 device1 dataType1 shape1
    -&gt; Generator device2
    -&gt; m (Tensor
            gradient1 layout1 generatorOutputDevice dataType1 shape1,
          Generator generatorOutputDevice))
-&gt; Tensor gradient1 layout1 device1 dataType1 shape1
-&gt; IxStateT
     m
     (Generator device2)
     (Generator generatorOutputDevice)
     (Tensor gradient1 layout1 generatorOutputDevice dataType1 shape1)
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Dropout
-&gt; Tensor gradient1 layout1 device1 dataType1 shape1
-&gt; Generator device2
-&gt; m (Tensor
        gradient1 layout1 generatorOutputDevice dataType1 shape1,
      Generator generatorOutputDevice)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: Type -&gt; Type).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">GCrossAttention
  (MultiHeadAttention
     'ByT5
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     keyEmbedDim
     keyEmbedDim)
  (LayerNorm
     'WithoutBias gradient device dataType ('Shape '[queryEmbedDim]))
  Dropout
-&gt; Dropout
forall mha layerNorm dropout.
GCrossAttention mha layerNorm dropout -&gt; dropout
</span><a href="Torch.GraduallyTyped.NN.Transformer.CrossAttention.html#caDropout"><span class="hs-identifier hs-var hs-var">caDropout</span></a></span><span> </span><span class="annot"><span class="annottext">GCrossAttention
  (MultiHeadAttention
     'ByT5
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     keyEmbedDim
     keyEmbedDim)
  (LayerNorm
     'WithoutBias gradient device dataType ('Shape '[queryEmbedDim]))
  Dropout
GCrossAttention
  (CAMultiheadAttentionF
     'ByT5
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     keyEmbedDim)
  (CALayerNormF 'ByT5 gradient device dataType queryEmbedDim)
  (CADropoutF 'ByT5)
</span><a href="#local-6989586621679804864"><span class="hs-identifier hs-var">ca</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-432"></span><span>        </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorOutputDevice)
  (Tensor gradient1 layout1 generatorOutputDevice dataType1 shape1)
-&gt; (Tensor gradient1 layout1 generatorOutputDevice dataType1 shape1
    -&gt; IxStateT
         m
         (Generator generatorOutputDevice)
         (Generator generatorOutputDevice)
         output)
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorOutputDevice)
     output
forall k1 (m :: k1 -&gt; k1 -&gt; Type -&gt; Type) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">output
-&gt; IxStateT
     m
     (Generator generatorOutputDevice)
     (Generator generatorOutputDevice)
     output
forall k (m :: k -&gt; k -&gt; Type -&gt; Type) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">(output
 -&gt; IxStateT
      m
      (Generator generatorOutputDevice)
      (Generator generatorOutputDevice)
      output)
-&gt; (Tensor gradient1 layout1 generatorOutputDevice dataType1 shape1
    -&gt; output)
-&gt; Tensor gradient1 layout1 generatorOutputDevice dataType1 shape1
-&gt; IxStateT
     m
     (Generator generatorOutputDevice)
     (Generator generatorOutputDevice)
     output
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">query
Tensor gradient0 layout0 device0 dataType0 shape0
</span><a href="#local-6989586621679804863"><span class="hs-identifier hs-var">query</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient0 layout0 device0 dataType0 shape0
-&gt; Tensor gradient1 layout1 generatorOutputDevice dataType1 shape1
-&gt; Tensor
     (gradient0 &lt;|&gt; gradient1)
     (layout0 &lt;+&gt; layout1)
     (device0 &lt;+&gt; generatorOutputDevice)
     (dataType0 &lt;+&gt; dataType1)
     (BroadcastShapesF shape0 shape1)
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (gradient' :: Gradient RequiresGradient)
       (layout' :: Layout LayoutType) (device' :: Device (DeviceType Nat))
       (dataType' :: DataType DType)
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]).
Tensor gradient layout device dataType shape
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; Tensor
     (gradient &lt;|&gt; gradient')
     (layout &lt;+&gt; layout')
     (device &lt;+&gt; device')
     (dataType &lt;+&gt; dataType')
     (BroadcastShapesF shape shape')
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#add"><span class="hs-operator hs-var">`add`</span></a></span><span class="hs-special">)</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span>
</span><span id="line-433"></span><span>
</span><span id="line-434"></span><span class="hs-comment">-- | 'HasForward' instance for @CrossAttenton 'BART@.</span><span>
</span><span id="line-435"></span><span class="hs-comment">--</span><span>
</span><span id="line-436"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-437"></span><span class="hs-comment">--    &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;  &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;  &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;</span><span>
</span><span id="line-438"></span><span class="hs-comment">--    &#9474; query &#9474;  &#9474; key &#9474;  &#9474; attentionBias &#9474;</span><span>
</span><span id="line-439"></span><span class="hs-comment">--    &#9492;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9496;  &#9492;&#9472;&#9472;&#9516;&#9472;&#9472;&#9496;  &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-440"></span><span class="hs-comment">--        &#9474;         &#9474;             &#9474;</span><span>
</span><span id="line-441"></span><span class="hs-comment">-- &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9508;      &#9484;&#9472;&#9472;&#9524;&#9472;&#9472;&#9488;          &#9474;</span><span>
</span><span id="line-442"></span><span class="hs-comment">-- &#9474;      &#9474;      &#9474;     &#9474;          &#9474;</span><span>
</span><span id="line-443"></span><span class="hs-comment">-- &#9474;      &#9660;      &#9660;     &#9660;          &#9474;</span><span>
</span><span id="line-444"></span><span class="hs-comment">-- &#9474;   caMultiheadAttention&#9668;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-445"></span><span class="hs-comment">-- &#9474;             &#9474;</span><span>
</span><span id="line-446"></span><span class="hs-comment">-- &#9474;             &#9660;</span><span>
</span><span id="line-447"></span><span class="hs-comment">-- &#9474;         caDropout</span><span>
</span><span id="line-448"></span><span class="hs-comment">-- &#9474;             &#9474;</span><span>
</span><span id="line-449"></span><span class="hs-comment">-- &#9492;&#9472;&#9472;&#9472;&#9472;&#9658;add&#9668;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-450"></span><span class="hs-comment">--        &#9474;</span><span>
</span><span id="line-451"></span><span class="hs-comment">--        &#9660;</span><span>
</span><span id="line-452"></span><span class="hs-comment">--   caLayerNorm</span><span>
</span><span id="line-453"></span><span class="hs-comment">--        &#9474;</span><span>
</span><span id="line-454"></span><span class="hs-comment">--        &#9660;</span><span>
</span><span id="line-455"></span><span class="hs-comment">--    &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;</span><span>
</span><span id="line-456"></span><span class="hs-comment">--    &#9474; query &#9474;</span><span>
</span><span id="line-457"></span><span class="hs-comment">--    &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-458"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-459"></span><span id="local-6989586621679804830"><span id="local-6989586621679804831"><span id="local-6989586621679804832"><span id="local-6989586621679804833"><span id="local-6989586621679804834"><span id="local-6989586621679804835"><span id="local-6989586621679804836"><span id="local-6989586621679804837"><span id="local-6989586621679804838"><span id="local-6989586621679804839"><span id="local-6989586621679804840"><span id="local-6989586621679804841"><span id="local-6989586621679804842"><span id="local-6989586621679804843"><span id="local-6989586621679804844"><span id="local-6989586621679804845"><span id="local-6989586621679804846"><span id="local-6989586621679804847"><span id="local-6989586621679804848"><span id="local-6989586621679804849"><span id="local-6989586621679804850"><span id="local-6989586621679804851"><span id="local-6989586621679804852"><span id="local-6989586621679804853"><span id="local-6989586621679804854"><span id="local-6989586621679804855"><span id="local-6989586621679804856"><span id="local-6989586621679804857"><span id="local-6989586621679804858"><span id="local-6989586621679804859"><span class="hs-keyword">instance</span><span>
</span><span id="line-460"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetDim"><span class="hs-identifier hs-type">SGetDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804859"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-461"></span><span>    </span><span class="annot"><a href="#local-6989586621679804858"><span class="hs-identifier hs-type">query</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804857"><span class="hs-identifier hs-type">queryGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804856"><span class="hs-identifier hs-type">queryLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804855"><span class="hs-identifier hs-type">queryDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804854"><span class="hs-identifier hs-type">queryDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804853"><span class="hs-identifier hs-type">queryShape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-462"></span><span>    </span><span class="annot"><a href="#local-6989586621679804852"><span class="hs-identifier hs-type">key</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804851"><span class="hs-identifier hs-type">keyGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804850"><span class="hs-identifier hs-type">keyLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804849"><span class="hs-identifier hs-type">keyDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804848"><span class="hs-identifier hs-type">keyDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804847"><span class="hs-identifier hs-type">keyShape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-463"></span><span>    </span><span class="annot"><a href="#local-6989586621679804846"><span class="hs-identifier hs-type">attentionBias</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804845"><span class="hs-identifier hs-type">attentionBiasGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804844"><span class="hs-identifier hs-type">attentionBiasLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804843"><span class="hs-identifier hs-type">attentionBiasDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804842"><span class="hs-identifier hs-type">attentionBiasDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804841"><span class="hs-identifier hs-type">attentionBiasShape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-464"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-465"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.MultiHeadAttention.html#MultiHeadAttention"><span class="hs-identifier hs-type">MultiHeadAttention</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804840"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804839"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804838"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804837"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804836"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804835"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804859"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804834"><span class="hs-identifier hs-type">keyEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804834"><span class="hs-identifier hs-type">keyEmbedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-466"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679804858"><span class="hs-identifier hs-type">query</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679804852"><span class="hs-identifier hs-type">key</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679804852"><span class="hs-identifier hs-type">key</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679804846"><span class="hs-identifier hs-type">attentionBias</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-467"></span><span>      </span><span class="annot"><a href="#local-6989586621679804833"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-468"></span><span>      </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-469"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679804840"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804857"><span class="hs-identifier hs-type">queryGradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804851"><span class="hs-identifier hs-type">keyGradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804845"><span class="hs-identifier hs-type">attentionBiasGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-470"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Dense"><span class="hs-identifier hs-type">Dense</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804856"><span class="hs-identifier hs-type">queryLayout</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804850"><span class="hs-identifier hs-type">keyLayout</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804844"><span class="hs-identifier hs-type">attentionBiasLayout</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-471"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679804839"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804855"><span class="hs-identifier hs-type">queryDevice</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804849"><span class="hs-identifier hs-type">keyDevice</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804843"><span class="hs-identifier hs-type">attentionBiasDevice</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804833"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-472"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679804838"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804854"><span class="hs-identifier hs-type">queryDataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804848"><span class="hs-identifier hs-type">keyDataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804842"><span class="hs-identifier hs-type">attentionBiasDataType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-473"></span><span>          </span><span class="annot"><a href="#local-6989586621679804832"><span class="hs-identifier hs-type">mhaOutputShape</span></a></span><span>
</span><span id="line-474"></span><span>      </span><span class="hs-special">)</span><span>
</span><span id="line-475"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679804839"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804855"><span class="hs-identifier hs-type">queryDevice</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804849"><span class="hs-identifier hs-type">keyDevice</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804843"><span class="hs-identifier hs-type">attentionBiasDevice</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804833"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-476"></span><span>    </span><span class="annot"><a href="#local-6989586621679804831"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-477"></span><span>      </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-478"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679804840"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804857"><span class="hs-identifier hs-type">queryGradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804851"><span class="hs-identifier hs-type">keyGradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804845"><span class="hs-identifier hs-type">attentionBiasGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-479"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Dense"><span class="hs-identifier hs-type">Dense</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804856"><span class="hs-identifier hs-type">queryLayout</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804850"><span class="hs-identifier hs-type">keyLayout</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804844"><span class="hs-identifier hs-type">attentionBiasLayout</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-480"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679804839"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804855"><span class="hs-identifier hs-type">queryDevice</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804849"><span class="hs-identifier hs-type">keyDevice</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804843"><span class="hs-identifier hs-type">attentionBiasDevice</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804833"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-481"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679804838"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804854"><span class="hs-identifier hs-type">queryDataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804848"><span class="hs-identifier hs-type">keyDataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804842"><span class="hs-identifier hs-type">attentionBiasDataType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-482"></span><span>          </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Functional.Normalization.html#LayerNormWithBiasF"><span class="hs-identifier hs-type">LayerNormWithBiasF</span></a></span><span>
</span><span id="line-483"></span><span>              </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679804859"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-484"></span><span>              </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679804859"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-485"></span><span>              </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#BroadcastShapesF"><span class="hs-identifier hs-type">BroadcastShapesF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804853"><span class="hs-identifier hs-type">queryShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804832"><span class="hs-identifier hs-type">mhaOutputShape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-486"></span><span>          </span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-487"></span><span>    </span><span class="annot"><a href="#local-6989586621679804830"><span class="hs-identifier hs-type">generatorOutputDevice</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679804839"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804855"><span class="hs-identifier hs-type">queryDevice</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804849"><span class="hs-identifier hs-type">keyDevice</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804843"><span class="hs-identifier hs-type">attentionBiasDevice</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804833"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-488"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-489"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-490"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.CrossAttention.html#CrossAttention"><span class="hs-identifier hs-type">CrossAttention</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-type">BART</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804840"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804839"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804838"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804837"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804836"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804835"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804859"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804834"><span class="hs-identifier hs-type">keyEmbedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-491"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679804858"><span class="hs-identifier hs-type">query</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679804852"><span class="hs-identifier hs-type">key</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679804846"><span class="hs-identifier hs-type">attentionBias</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-492"></span><span>    </span><span class="annot"><a href="#local-6989586621679804833"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-493"></span><span>    </span><span class="annot"><a href="#local-6989586621679804831"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-494"></span><span>    </span><span class="annot"><a href="#local-6989586621679804830"><span class="hs-identifier hs-type">generatorOutputDevice</span></a></span><span>
</span><span id="line-495"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-496"></span><span>  </span><span id="local-6989586621679804828"><span class="annot"><span class="annottext">forward :: CrossAttention
  'BART
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  queryEmbedDim
  keyEmbedDim
-&gt; (query, key, attentionBias)
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="#local-6989586621679804828"><span class="hs-identifier hs-var hs-var hs-var hs-var">forward</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.CrossAttention.html#CrossAttention"><span class="hs-identifier hs-type">CrossAttention</span></a></span><span> </span><span id="local-6989586621679804827"><span class="annot"><span class="annottext">GCrossAttention
  (CAMultiheadAttentionF
     'BART
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     keyEmbedDim)
  (CALayerNormF 'BART gradient device dataType queryEmbedDim)
  (CADropoutF 'BART)
</span><a href="#local-6989586621679804827"><span class="hs-identifier hs-var">ca</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679804826"><span class="annot"><span class="annottext">query
</span><a href="#local-6989586621679804826"><span class="hs-identifier hs-var">query</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679804825"><span class="annot"><span class="annottext">key
</span><a href="#local-6989586621679804825"><span class="hs-identifier hs-var">key</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679804824"><span class="annot"><span class="annottext">attentionBias
</span><a href="#local-6989586621679804824"><span class="hs-identifier hs-var">attentionBias</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-497"></span><span>    </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorOutputDevice)
  output
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
forall (m :: Type -&gt; Type) i j a. IxStateT m i j a -&gt; i -&gt; m (a, j)
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var hs-var">runIxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">(IxStateT
   m
   (Generator generatorDevice)
   (Generator generatorOutputDevice)
   output
 -&gt; Generator generatorDevice
 -&gt; m (output, Generator generatorOutputDevice))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorOutputDevice)
     output
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-498"></span><span>      </span><span class="annot"><span class="annottext">query
-&gt; IxStateT
     m (Generator generatorDevice) (Generator generatorDevice) query
forall k (m :: k -&gt; k -&gt; Type -&gt; Type) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">query
</span><a href="#local-6989586621679804826"><span class="hs-identifier hs-var">query</span></a></span><span>
</span><span id="line-499"></span><span>        </span><span class="annot"><span class="annottext">IxStateT
  m (Generator generatorDevice) (Generator generatorDevice) query
-&gt; (query
    -&gt; IxStateT
         m
         (Generator generatorDevice)
         (Generator generatorOutputDevice)
         (Tensor
            (Or
               (Gradient RequiresGradient)
               gradient
               (Or
                  (Gradient RequiresGradient)
                  queryGradient
                  (Or
                     (Gradient RequiresGradient) keyGradient attentionBiasGradient)))
            (Unify
               (Layout LayoutType)
               ('Layout 'Dense)
               (Unify
                  (Layout LayoutType)
                  queryLayout
                  (Unify (Layout LayoutType) keyLayout attentionBiasLayout)))
            generatorOutputDevice
            (Unify
               (DataType DType)
               dataType
               (Unify
                  (DataType DType)
                  queryDataType
                  (Unify (DataType DType) keyDataType attentionBiasDataType)))
            mhaOutputShape))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorOutputDevice)
     (Tensor
        (Or
           (Gradient RequiresGradient)
           gradient
           (Or
              (Gradient RequiresGradient)
              queryGradient
              (Or
                 (Gradient RequiresGradient) keyGradient attentionBiasGradient)))
        (Unify
           (Layout LayoutType)
           ('Layout 'Dense)
           (Unify
              (Layout LayoutType)
              queryLayout
              (Unify (Layout LayoutType) keyLayout attentionBiasLayout)))
        generatorOutputDevice
        (Unify
           (DataType DType)
           dataType
           (Unify
              (DataType DType)
              queryDataType
              (Unify (DataType DType) keyDataType attentionBiasDataType)))
        mhaOutputShape)
forall k1 (m :: k1 -&gt; k1 -&gt; Type -&gt; Type) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">\</span><span id="local-6989586621679804823"><span class="annot"><span class="annottext">query
</span><a href="#local-6989586621679804823"><span class="hs-identifier hs-var">query'</span></a></span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">(Generator generatorDevice
 -&gt; m (Tensor
         (Or
            (Gradient RequiresGradient)
            gradient
            (Or
               (Gradient RequiresGradient)
               queryGradient
               (Or
                  (Gradient RequiresGradient) keyGradient attentionBiasGradient)))
         (Unify
            (Layout LayoutType)
            ('Layout 'Dense)
            (Unify
               (Layout LayoutType)
               queryLayout
               (Unify (Layout LayoutType) keyLayout attentionBiasLayout)))
         generatorOutputDevice
         (Unify
            (DataType DType)
            dataType
            (Unify
               (DataType DType)
               queryDataType
               (Unify (DataType DType) keyDataType attentionBiasDataType)))
         mhaOutputShape,
       Generator generatorOutputDevice))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorOutputDevice)
     (Tensor
        (Or
           (Gradient RequiresGradient)
           gradient
           (Or
              (Gradient RequiresGradient)
              queryGradient
              (Or
                 (Gradient RequiresGradient) keyGradient attentionBiasGradient)))
        (Unify
           (Layout LayoutType)
           ('Layout 'Dense)
           (Unify
              (Layout LayoutType)
              queryLayout
              (Unify (Layout LayoutType) keyLayout attentionBiasLayout)))
        generatorOutputDevice
        (Unify
           (DataType DType)
           dataType
           (Unify
              (DataType DType)
              queryDataType
              (Unify (DataType DType) keyDataType attentionBiasDataType)))
        mhaOutputShape)
forall (m :: Type -&gt; Type) i j a.
(i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator generatorDevice
  -&gt; m (Tensor
          (Or
             (Gradient RequiresGradient)
             gradient
             (Or
                (Gradient RequiresGradient)
                queryGradient
                (Or
                   (Gradient RequiresGradient) keyGradient attentionBiasGradient)))
          (Unify
             (Layout LayoutType)
             ('Layout 'Dense)
             (Unify
                (Layout LayoutType)
                queryLayout
                (Unify (Layout LayoutType) keyLayout attentionBiasLayout)))
          generatorOutputDevice
          (Unify
             (DataType DType)
             dataType
             (Unify
                (DataType DType)
                queryDataType
                (Unify (DataType DType) keyDataType attentionBiasDataType)))
          mhaOutputShape,
        Generator generatorOutputDevice))
 -&gt; IxStateT
      m
      (Generator generatorDevice)
      (Generator generatorOutputDevice)
      (Tensor
         (Or
            (Gradient RequiresGradient)
            gradient
            (Or
               (Gradient RequiresGradient)
               queryGradient
               (Or
                  (Gradient RequiresGradient) keyGradient attentionBiasGradient)))
         (Unify
            (Layout LayoutType)
            ('Layout 'Dense)
            (Unify
               (Layout LayoutType)
               queryLayout
               (Unify (Layout LayoutType) keyLayout attentionBiasLayout)))
         generatorOutputDevice
         (Unify
            (DataType DType)
            dataType
            (Unify
               (DataType DType)
               queryDataType
               (Unify (DataType DType) keyDataType attentionBiasDataType)))
         mhaOutputShape))
-&gt; (Generator generatorDevice
    -&gt; m (Tensor
            (Or
               (Gradient RequiresGradient)
               gradient
               (Or
                  (Gradient RequiresGradient)
                  queryGradient
                  (Or
                     (Gradient RequiresGradient) keyGradient attentionBiasGradient)))
            (Unify
               (Layout LayoutType)
               ('Layout 'Dense)
               (Unify
                  (Layout LayoutType)
                  queryLayout
                  (Unify (Layout LayoutType) keyLayout attentionBiasLayout)))
            generatorOutputDevice
            (Unify
               (DataType DType)
               dataType
               (Unify
                  (DataType DType)
                  queryDataType
                  (Unify (DataType DType) keyDataType attentionBiasDataType)))
            mhaOutputShape,
          Generator generatorOutputDevice))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorOutputDevice)
     (Tensor
        (Or
           (Gradient RequiresGradient)
           gradient
           (Or
              (Gradient RequiresGradient)
              queryGradient
              (Or
                 (Gradient RequiresGradient) keyGradient attentionBiasGradient)))
        (Unify
           (Layout LayoutType)
           ('Layout 'Dense)
           (Unify
              (Layout LayoutType)
              queryLayout
              (Unify (Layout LayoutType) keyLayout attentionBiasLayout)))
        generatorOutputDevice
        (Unify
           (DataType DType)
           dataType
           (Unify
              (DataType DType)
              queryDataType
              (Unify (DataType DType) keyDataType attentionBiasDataType)))
        mhaOutputShape)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">MultiHeadAttention
  'BART
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  queryEmbedDim
  keyEmbedDim
  keyEmbedDim
-&gt; (query, key, key, attentionBias)
-&gt; Generator generatorDevice
-&gt; m (Tensor
        (Or
           (Gradient RequiresGradient)
           gradient
           (Or
              (Gradient RequiresGradient)
              queryGradient
              (Or
                 (Gradient RequiresGradient) keyGradient attentionBiasGradient)))
        (Unify
           (Layout LayoutType)
           ('Layout 'Dense)
           (Unify
              (Layout LayoutType)
              queryLayout
              (Unify (Layout LayoutType) keyLayout attentionBiasLayout)))
        generatorOutputDevice
        (Unify
           (DataType DType)
           dataType
           (Unify
              (DataType DType)
              queryDataType
              (Unify (DataType DType) keyDataType attentionBiasDataType)))
        mhaOutputShape,
      Generator generatorOutputDevice)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: Type -&gt; Type).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">GCrossAttention
  (MultiHeadAttention
     'BART
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     keyEmbedDim
     keyEmbedDim)
  (LayerNorm
     'WithBias gradient device dataType ('Shape '[queryEmbedDim]))
  Dropout
-&gt; MultiHeadAttention
     'BART
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     keyEmbedDim
     keyEmbedDim
forall mha layerNorm dropout.
GCrossAttention mha layerNorm dropout -&gt; mha
</span><a href="Torch.GraduallyTyped.NN.Transformer.CrossAttention.html#caMultiHeadAttention"><span class="hs-identifier hs-var hs-var">caMultiHeadAttention</span></a></span><span> </span><span class="annot"><span class="annottext">GCrossAttention
  (MultiHeadAttention
     'BART
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     keyEmbedDim
     keyEmbedDim)
  (LayerNorm
     'WithBias gradient device dataType ('Shape '[queryEmbedDim]))
  Dropout
GCrossAttention
  (CAMultiheadAttentionF
     'BART
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     keyEmbedDim)
  (CALayerNormF 'BART gradient device dataType queryEmbedDim)
  (CADropoutF 'BART)
</span><a href="#local-6989586621679804827"><span class="hs-identifier hs-var">ca</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">query
</span><a href="#local-6989586621679804823"><span class="hs-identifier hs-var">query'</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">key
</span><a href="#local-6989586621679804825"><span class="hs-identifier hs-var">key</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">key
</span><a href="#local-6989586621679804825"><span class="hs-identifier hs-var">key</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">attentionBias
</span><a href="#local-6989586621679804824"><span class="hs-identifier hs-var">attentionBias</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-500"></span><span>        </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorOutputDevice)
  (Tensor
     (Or
        (Gradient RequiresGradient)
        gradient
        (Or
           (Gradient RequiresGradient)
           queryGradient
           (Or
              (Gradient RequiresGradient) keyGradient attentionBiasGradient)))
     (Unify
        (Layout LayoutType)
        ('Layout 'Dense)
        (Unify
           (Layout LayoutType)
           queryLayout
           (Unify (Layout LayoutType) keyLayout attentionBiasLayout)))
     generatorOutputDevice
     (Unify
        (DataType DType)
        dataType
        (Unify
           (DataType DType)
           queryDataType
           (Unify (DataType DType) keyDataType attentionBiasDataType)))
     mhaOutputShape)
-&gt; (Tensor
      (Or
         (Gradient RequiresGradient)
         gradient
         (Or
            (Gradient RequiresGradient)
            queryGradient
            (Or
               (Gradient RequiresGradient) keyGradient attentionBiasGradient)))
      (Unify
         (Layout LayoutType)
         ('Layout 'Dense)
         (Unify
            (Layout LayoutType)
            queryLayout
            (Unify (Layout LayoutType) keyLayout attentionBiasLayout)))
      generatorOutputDevice
      (Unify
         (DataType DType)
         dataType
         (Unify
            (DataType DType)
            queryDataType
            (Unify (DataType DType) keyDataType attentionBiasDataType)))
      mhaOutputShape
    -&gt; IxStateT
         m
         (Generator generatorOutputDevice)
         (Generator generatorOutputDevice)
         (Tensor
            (Or
               (Gradient RequiresGradient)
               gradient
               (Or
                  (Gradient RequiresGradient)
                  queryGradient
                  (Or
                     (Gradient RequiresGradient) keyGradient attentionBiasGradient)))
            (Unify
               (Layout LayoutType)
               ('Layout 'Dense)
               (Unify
                  (Layout LayoutType)
                  queryLayout
                  (Unify (Layout LayoutType) keyLayout attentionBiasLayout)))
            generatorOutputDevice
            (Unify
               (DataType DType)
               dataType
               (Unify
                  (DataType DType)
                  queryDataType
                  (Unify (DataType DType) keyDataType attentionBiasDataType)))
            mhaOutputShape))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorOutputDevice)
     (Tensor
        (Or
           (Gradient RequiresGradient)
           gradient
           (Or
              (Gradient RequiresGradient)
              queryGradient
              (Or
                 (Gradient RequiresGradient) keyGradient attentionBiasGradient)))
        (Unify
           (Layout LayoutType)
           ('Layout 'Dense)
           (Unify
              (Layout LayoutType)
              queryLayout
              (Unify (Layout LayoutType) keyLayout attentionBiasLayout)))
        generatorOutputDevice
        (Unify
           (DataType DType)
           dataType
           (Unify
              (DataType DType)
              queryDataType
              (Unify (DataType DType) keyDataType attentionBiasDataType)))
        mhaOutputShape)
forall k1 (m :: k1 -&gt; k1 -&gt; Type -&gt; Type) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(Generator generatorOutputDevice
 -&gt; m (Tensor
         (Or
            (Gradient RequiresGradient)
            gradient
            (Or
               (Gradient RequiresGradient)
               queryGradient
               (Or
                  (Gradient RequiresGradient) keyGradient attentionBiasGradient)))
         (Unify
            (Layout LayoutType)
            ('Layout 'Dense)
            (Unify
               (Layout LayoutType)
               queryLayout
               (Unify (Layout LayoutType) keyLayout attentionBiasLayout)))
         generatorOutputDevice
         (Unify
            (DataType DType)
            dataType
            (Unify
               (DataType DType)
               queryDataType
               (Unify (DataType DType) keyDataType attentionBiasDataType)))
         mhaOutputShape,
       Generator generatorOutputDevice))
-&gt; IxStateT
     m
     (Generator generatorOutputDevice)
     (Generator generatorOutputDevice)
     (Tensor
        (Or
           (Gradient RequiresGradient)
           gradient
           (Or
              (Gradient RequiresGradient)
              queryGradient
              (Or
                 (Gradient RequiresGradient) keyGradient attentionBiasGradient)))
        (Unify
           (Layout LayoutType)
           ('Layout 'Dense)
           (Unify
              (Layout LayoutType)
              queryLayout
              (Unify (Layout LayoutType) keyLayout attentionBiasLayout)))
        generatorOutputDevice
        (Unify
           (DataType DType)
           dataType
           (Unify
              (DataType DType)
              queryDataType
              (Unify (DataType DType) keyDataType attentionBiasDataType)))
        mhaOutputShape)
forall (m :: Type -&gt; Type) i j a.
(i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator generatorOutputDevice
  -&gt; m (Tensor
          (Or
             (Gradient RequiresGradient)
             gradient
             (Or
                (Gradient RequiresGradient)
                queryGradient
                (Or
                   (Gradient RequiresGradient) keyGradient attentionBiasGradient)))
          (Unify
             (Layout LayoutType)
             ('Layout 'Dense)
             (Unify
                (Layout LayoutType)
                queryLayout
                (Unify (Layout LayoutType) keyLayout attentionBiasLayout)))
          generatorOutputDevice
          (Unify
             (DataType DType)
             dataType
             (Unify
                (DataType DType)
                queryDataType
                (Unify (DataType DType) keyDataType attentionBiasDataType)))
          mhaOutputShape,
        Generator generatorOutputDevice))
 -&gt; IxStateT
      m
      (Generator generatorOutputDevice)
      (Generator generatorOutputDevice)
      (Tensor
         (Or
            (Gradient RequiresGradient)
            gradient
            (Or
               (Gradient RequiresGradient)
               queryGradient
               (Or
                  (Gradient RequiresGradient) keyGradient attentionBiasGradient)))
         (Unify
            (Layout LayoutType)
            ('Layout 'Dense)
            (Unify
               (Layout LayoutType)
               queryLayout
               (Unify (Layout LayoutType) keyLayout attentionBiasLayout)))
         generatorOutputDevice
         (Unify
            (DataType DType)
            dataType
            (Unify
               (DataType DType)
               queryDataType
               (Unify (DataType DType) keyDataType attentionBiasDataType)))
         mhaOutputShape))
-&gt; (Tensor
      (Or
         (Gradient RequiresGradient)
         gradient
         (Or
            (Gradient RequiresGradient)
            queryGradient
            (Or
               (Gradient RequiresGradient) keyGradient attentionBiasGradient)))
      (Unify
         (Layout LayoutType)
         ('Layout 'Dense)
         (Unify
            (Layout LayoutType)
            queryLayout
            (Unify (Layout LayoutType) keyLayout attentionBiasLayout)))
      generatorOutputDevice
      (Unify
         (DataType DType)
         dataType
         (Unify
            (DataType DType)
            queryDataType
            (Unify (DataType DType) keyDataType attentionBiasDataType)))
      mhaOutputShape
    -&gt; Generator generatorOutputDevice
    -&gt; m (Tensor
            (Or
               (Gradient RequiresGradient)
               gradient
               (Or
                  (Gradient RequiresGradient)
                  queryGradient
                  (Or
                     (Gradient RequiresGradient) keyGradient attentionBiasGradient)))
            (Unify
               (Layout LayoutType)
               ('Layout 'Dense)
               (Unify
                  (Layout LayoutType)
                  queryLayout
                  (Unify (Layout LayoutType) keyLayout attentionBiasLayout)))
            generatorOutputDevice
            (Unify
               (DataType DType)
               dataType
               (Unify
                  (DataType DType)
                  queryDataType
                  (Unify (DataType DType) keyDataType attentionBiasDataType)))
            mhaOutputShape,
          Generator generatorOutputDevice))
-&gt; Tensor
     (Or
        (Gradient RequiresGradient)
        gradient
        (Or
           (Gradient RequiresGradient)
           queryGradient
           (Or
              (Gradient RequiresGradient) keyGradient attentionBiasGradient)))
     (Unify
        (Layout LayoutType)
        ('Layout 'Dense)
        (Unify
           (Layout LayoutType)
           queryLayout
           (Unify (Layout LayoutType) keyLayout attentionBiasLayout)))
     generatorOutputDevice
     (Unify
        (DataType DType)
        dataType
        (Unify
           (DataType DType)
           queryDataType
           (Unify (DataType DType) keyDataType attentionBiasDataType)))
     mhaOutputShape
-&gt; IxStateT
     m
     (Generator generatorOutputDevice)
     (Generator generatorOutputDevice)
     (Tensor
        (Or
           (Gradient RequiresGradient)
           gradient
           (Or
              (Gradient RequiresGradient)
              queryGradient
              (Or
                 (Gradient RequiresGradient) keyGradient attentionBiasGradient)))
        (Unify
           (Layout LayoutType)
           ('Layout 'Dense)
           (Unify
              (Layout LayoutType)
              queryLayout
              (Unify (Layout LayoutType) keyLayout attentionBiasLayout)))
        generatorOutputDevice
        (Unify
           (DataType DType)
           dataType
           (Unify
              (DataType DType)
              queryDataType
              (Unify (DataType DType) keyDataType attentionBiasDataType)))
        mhaOutputShape)
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Dropout
-&gt; Tensor
     (Or
        (Gradient RequiresGradient)
        gradient
        (Or
           (Gradient RequiresGradient)
           queryGradient
           (Or
              (Gradient RequiresGradient) keyGradient attentionBiasGradient)))
     (Unify
        (Layout LayoutType)
        ('Layout 'Dense)
        (Unify
           (Layout LayoutType)
           queryLayout
           (Unify (Layout LayoutType) keyLayout attentionBiasLayout)))
     generatorOutputDevice
     (Unify
        (DataType DType)
        dataType
        (Unify
           (DataType DType)
           queryDataType
           (Unify (DataType DType) keyDataType attentionBiasDataType)))
     mhaOutputShape
-&gt; Generator generatorOutputDevice
-&gt; m (Tensor
        (Or
           (Gradient RequiresGradient)
           gradient
           (Or
              (Gradient RequiresGradient)
              queryGradient
              (Or
                 (Gradient RequiresGradient) keyGradient attentionBiasGradient)))
        (Unify
           (Layout LayoutType)
           ('Layout 'Dense)
           (Unify
              (Layout LayoutType)
              queryLayout
              (Unify (Layout LayoutType) keyLayout attentionBiasLayout)))
        generatorOutputDevice
        (Unify
           (DataType DType)
           dataType
           (Unify
              (DataType DType)
              queryDataType
              (Unify (DataType DType) keyDataType attentionBiasDataType)))
        mhaOutputShape,
      Generator generatorOutputDevice)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: Type -&gt; Type).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">GCrossAttention
  (MultiHeadAttention
     'BART
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     keyEmbedDim
     keyEmbedDim)
  (LayerNorm
     'WithBias gradient device dataType ('Shape '[queryEmbedDim]))
  Dropout
-&gt; Dropout
forall mha layerNorm dropout.
GCrossAttention mha layerNorm dropout -&gt; dropout
</span><a href="Torch.GraduallyTyped.NN.Transformer.CrossAttention.html#caDropout"><span class="hs-identifier hs-var hs-var">caDropout</span></a></span><span> </span><span class="annot"><span class="annottext">GCrossAttention
  (MultiHeadAttention
     'BART
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     keyEmbedDim
     keyEmbedDim)
  (LayerNorm
     'WithBias gradient device dataType ('Shape '[queryEmbedDim]))
  Dropout
GCrossAttention
  (CAMultiheadAttentionF
     'BART
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     keyEmbedDim)
  (CALayerNormF 'BART gradient device dataType queryEmbedDim)
  (CADropoutF 'BART)
</span><a href="#local-6989586621679804827"><span class="hs-identifier hs-var">ca</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-501"></span><span>        </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorOutputDevice)
  (Tensor
     (Or
        (Gradient RequiresGradient)
        gradient
        (Or
           (Gradient RequiresGradient)
           queryGradient
           (Or
              (Gradient RequiresGradient) keyGradient attentionBiasGradient)))
     (Unify
        (Layout LayoutType)
        ('Layout 'Dense)
        (Unify
           (Layout LayoutType)
           queryLayout
           (Unify (Layout LayoutType) keyLayout attentionBiasLayout)))
     generatorOutputDevice
     (Unify
        (DataType DType)
        dataType
        (Unify
           (DataType DType)
           queryDataType
           (Unify (DataType DType) keyDataType attentionBiasDataType)))
     mhaOutputShape)
-&gt; (Tensor
      (Or
         (Gradient RequiresGradient)
         gradient
         (Or
            (Gradient RequiresGradient)
            queryGradient
            (Or
               (Gradient RequiresGradient) keyGradient attentionBiasGradient)))
      (Unify
         (Layout LayoutType)
         ('Layout 'Dense)
         (Unify
            (Layout LayoutType)
            queryLayout
            (Unify (Layout LayoutType) keyLayout attentionBiasLayout)))
      generatorOutputDevice
      (Unify
         (DataType DType)
         dataType
         (Unify
            (DataType DType)
            queryDataType
            (Unify (DataType DType) keyDataType attentionBiasDataType)))
      mhaOutputShape
    -&gt; IxStateT
         m
         (Generator generatorOutputDevice)
         (Generator generatorOutputDevice)
         (Tensor
            (Or
               (Gradient RequiresGradient)
               queryGradient
               (Or
                  (Gradient RequiresGradient)
                  gradient
                  (Or
                     (Gradient RequiresGradient)
                     queryGradient
                     (Or
                        (Gradient RequiresGradient) keyGradient attentionBiasGradient))))
            (Unify
               (Layout LayoutType)
               queryLayout
               (Unify
                  (Layout LayoutType)
                  ('Layout 'Dense)
                  (Unify
                     (Layout LayoutType)
                     queryLayout
                     (Unify (Layout LayoutType) keyLayout attentionBiasLayout))))
            (Unify (Device (DeviceType Nat)) queryDevice generatorOutputDevice)
            (Unify
               (DataType DType)
               queryDataType
               (Unify
                  (DataType DType)
                  dataType
                  (Unify
                     (DataType DType)
                     queryDataType
                     (Unify (DataType DType) keyDataType attentionBiasDataType))))
            (BroadcastShapesF queryShape mhaOutputShape)))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorOutputDevice)
     (Tensor
        (Or
           (Gradient RequiresGradient)
           queryGradient
           (Or
              (Gradient RequiresGradient)
              gradient
              (Or
                 (Gradient RequiresGradient)
                 queryGradient
                 (Or
                    (Gradient RequiresGradient) keyGradient attentionBiasGradient))))
        (Unify
           (Layout LayoutType)
           queryLayout
           (Unify
              (Layout LayoutType)
              ('Layout 'Dense)
              (Unify
                 (Layout LayoutType)
                 queryLayout
                 (Unify (Layout LayoutType) keyLayout attentionBiasLayout))))
        (Unify (Device (DeviceType Nat)) queryDevice generatorOutputDevice)
        (Unify
           (DataType DType)
           queryDataType
           (Unify
              (DataType DType)
              dataType
              (Unify
                 (DataType DType)
                 queryDataType
                 (Unify (DataType DType) keyDataType attentionBiasDataType))))
        (BroadcastShapesF queryShape mhaOutputShape))
forall k1 (m :: k1 -&gt; k1 -&gt; Type -&gt; Type) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  (Or
     (Gradient RequiresGradient)
     queryGradient
     (Or
        (Gradient RequiresGradient)
        gradient
        (Or
           (Gradient RequiresGradient)
           queryGradient
           (Or
              (Gradient RequiresGradient) keyGradient attentionBiasGradient))))
  (Unify
     (Layout LayoutType)
     queryLayout
     (Unify
        (Layout LayoutType)
        ('Layout 'Dense)
        (Unify
           (Layout LayoutType)
           queryLayout
           (Unify (Layout LayoutType) keyLayout attentionBiasLayout))))
  (Unify (Device (DeviceType Nat)) queryDevice generatorOutputDevice)
  (Unify
     (DataType DType)
     queryDataType
     (Unify
        (DataType DType)
        dataType
        (Unify
           (DataType DType)
           queryDataType
           (Unify (DataType DType) keyDataType attentionBiasDataType))))
  (BroadcastShapesF queryShape mhaOutputShape)
-&gt; IxStateT
     m
     (Generator generatorOutputDevice)
     (Generator generatorOutputDevice)
     (Tensor
        (Or
           (Gradient RequiresGradient)
           queryGradient
           (Or
              (Gradient RequiresGradient)
              gradient
              (Or
                 (Gradient RequiresGradient)
                 queryGradient
                 (Or
                    (Gradient RequiresGradient) keyGradient attentionBiasGradient))))
        (Unify
           (Layout LayoutType)
           queryLayout
           (Unify
              (Layout LayoutType)
              ('Layout 'Dense)
              (Unify
                 (Layout LayoutType)
                 queryLayout
                 (Unify (Layout LayoutType) keyLayout attentionBiasLayout))))
        (Unify (Device (DeviceType Nat)) queryDevice generatorOutputDevice)
        (Unify
           (DataType DType)
           queryDataType
           (Unify
              (DataType DType)
              dataType
              (Unify
                 (DataType DType)
                 queryDataType
                 (Unify (DataType DType) keyDataType attentionBiasDataType))))
        (BroadcastShapesF queryShape mhaOutputShape))
forall k (m :: k -&gt; k -&gt; Type -&gt; Type) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">(Tensor
   (Or
      (Gradient RequiresGradient)
      queryGradient
      (Or
         (Gradient RequiresGradient)
         gradient
         (Or
            (Gradient RequiresGradient)
            queryGradient
            (Or
               (Gradient RequiresGradient) keyGradient attentionBiasGradient))))
   (Unify
      (Layout LayoutType)
      queryLayout
      (Unify
         (Layout LayoutType)
         ('Layout 'Dense)
         (Unify
            (Layout LayoutType)
            queryLayout
            (Unify (Layout LayoutType) keyLayout attentionBiasLayout))))
   (Unify (Device (DeviceType Nat)) queryDevice generatorOutputDevice)
   (Unify
      (DataType DType)
      queryDataType
      (Unify
         (DataType DType)
         dataType
         (Unify
            (DataType DType)
            queryDataType
            (Unify (DataType DType) keyDataType attentionBiasDataType))))
   (BroadcastShapesF queryShape mhaOutputShape)
 -&gt; IxStateT
      m
      (Generator generatorOutputDevice)
      (Generator generatorOutputDevice)
      (Tensor
         (Or
            (Gradient RequiresGradient)
            queryGradient
            (Or
               (Gradient RequiresGradient)
               gradient
               (Or
                  (Gradient RequiresGradient)
                  queryGradient
                  (Or
                     (Gradient RequiresGradient) keyGradient attentionBiasGradient))))
         (Unify
            (Layout LayoutType)
            queryLayout
            (Unify
               (Layout LayoutType)
               ('Layout 'Dense)
               (Unify
                  (Layout LayoutType)
                  queryLayout
                  (Unify (Layout LayoutType) keyLayout attentionBiasLayout))))
         (Unify (Device (DeviceType Nat)) queryDevice generatorOutputDevice)
         (Unify
            (DataType DType)
            queryDataType
            (Unify
               (DataType DType)
               dataType
               (Unify
                  (DataType DType)
                  queryDataType
                  (Unify (DataType DType) keyDataType attentionBiasDataType))))
         (BroadcastShapesF queryShape mhaOutputShape)))
-&gt; (Tensor
      (Or
         (Gradient RequiresGradient)
         gradient
         (Or
            (Gradient RequiresGradient)
            queryGradient
            (Or
               (Gradient RequiresGradient) keyGradient attentionBiasGradient)))
      (Unify
         (Layout LayoutType)
         ('Layout 'Dense)
         (Unify
            (Layout LayoutType)
            queryLayout
            (Unify (Layout LayoutType) keyLayout attentionBiasLayout)))
      generatorOutputDevice
      (Unify
         (DataType DType)
         dataType
         (Unify
            (DataType DType)
            queryDataType
            (Unify (DataType DType) keyDataType attentionBiasDataType)))
      mhaOutputShape
    -&gt; Tensor
         (Or
            (Gradient RequiresGradient)
            queryGradient
            (Or
               (Gradient RequiresGradient)
               gradient
               (Or
                  (Gradient RequiresGradient)
                  queryGradient
                  (Or
                     (Gradient RequiresGradient) keyGradient attentionBiasGradient))))
         (Unify
            (Layout LayoutType)
            queryLayout
            (Unify
               (Layout LayoutType)
               ('Layout 'Dense)
               (Unify
                  (Layout LayoutType)
                  queryLayout
                  (Unify (Layout LayoutType) keyLayout attentionBiasLayout))))
         (Unify (Device (DeviceType Nat)) queryDevice generatorOutputDevice)
         (Unify
            (DataType DType)
            queryDataType
            (Unify
               (DataType DType)
               dataType
               (Unify
                  (DataType DType)
                  queryDataType
                  (Unify (DataType DType) keyDataType attentionBiasDataType))))
         (BroadcastShapesF queryShape mhaOutputShape))
-&gt; Tensor
     (Or
        (Gradient RequiresGradient)
        gradient
        (Or
           (Gradient RequiresGradient)
           queryGradient
           (Or
              (Gradient RequiresGradient) keyGradient attentionBiasGradient)))
     (Unify
        (Layout LayoutType)
        ('Layout 'Dense)
        (Unify
           (Layout LayoutType)
           queryLayout
           (Unify (Layout LayoutType) keyLayout attentionBiasLayout)))
     generatorOutputDevice
     (Unify
        (DataType DType)
        dataType
        (Unify
           (DataType DType)
           queryDataType
           (Unify (DataType DType) keyDataType attentionBiasDataType)))
     mhaOutputShape
-&gt; IxStateT
     m
     (Generator generatorOutputDevice)
     (Generator generatorOutputDevice)
     (Tensor
        (Or
           (Gradient RequiresGradient)
           queryGradient
           (Or
              (Gradient RequiresGradient)
              gradient
              (Or
                 (Gradient RequiresGradient)
                 queryGradient
                 (Or
                    (Gradient RequiresGradient) keyGradient attentionBiasGradient))))
        (Unify
           (Layout LayoutType)
           queryLayout
           (Unify
              (Layout LayoutType)
              ('Layout 'Dense)
              (Unify
                 (Layout LayoutType)
                 queryLayout
                 (Unify (Layout LayoutType) keyLayout attentionBiasLayout))))
        (Unify (Device (DeviceType Nat)) queryDevice generatorOutputDevice)
        (Unify
           (DataType DType)
           queryDataType
           (Unify
              (DataType DType)
              dataType
              (Unify
                 (DataType DType)
                 queryDataType
                 (Unify (DataType DType) keyDataType attentionBiasDataType))))
        (BroadcastShapesF queryShape mhaOutputShape))
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">query
Tensor
  queryGradient queryLayout queryDevice queryDataType queryShape
</span><a href="#local-6989586621679804826"><span class="hs-identifier hs-var">query</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  queryGradient queryLayout queryDevice queryDataType queryShape
-&gt; Tensor
     (Or
        (Gradient RequiresGradient)
        gradient
        (Or
           (Gradient RequiresGradient)
           queryGradient
           (Or
              (Gradient RequiresGradient) keyGradient attentionBiasGradient)))
     (Unify
        (Layout LayoutType)
        ('Layout 'Dense)
        (Unify
           (Layout LayoutType)
           queryLayout
           (Unify (Layout LayoutType) keyLayout attentionBiasLayout)))
     generatorOutputDevice
     (Unify
        (DataType DType)
        dataType
        (Unify
           (DataType DType)
           queryDataType
           (Unify (DataType DType) keyDataType attentionBiasDataType)))
     mhaOutputShape
-&gt; Tensor
     (queryGradient
      &lt;|&gt; Or
            (Gradient RequiresGradient)
            gradient
            (Or
               (Gradient RequiresGradient)
               queryGradient
               (Or
                  (Gradient RequiresGradient) keyGradient attentionBiasGradient)))
     (queryLayout
      &lt;+&gt; Unify
            (Layout LayoutType)
            ('Layout 'Dense)
            (Unify
               (Layout LayoutType)
               queryLayout
               (Unify (Layout LayoutType) keyLayout attentionBiasLayout)))
     (queryDevice &lt;+&gt; generatorOutputDevice)
     (queryDataType
      &lt;+&gt; Unify
            (DataType DType)
            dataType
            (Unify
               (DataType DType)
               queryDataType
               (Unify (DataType DType) keyDataType attentionBiasDataType)))
     (BroadcastShapesF queryShape mhaOutputShape)
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (gradient' :: Gradient RequiresGradient)
       (layout' :: Layout LayoutType) (device' :: Device (DeviceType Nat))
       (dataType' :: DataType DType)
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]).
Tensor gradient layout device dataType shape
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; Tensor
     (gradient &lt;|&gt; gradient')
     (layout &lt;+&gt; layout')
     (device &lt;+&gt; device')
     (dataType &lt;+&gt; dataType')
     (BroadcastShapesF shape shape')
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#add"><span class="hs-operator hs-var">`add`</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-502"></span><span>        </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorOutputDevice)
  (Tensor
     (Or
        (Gradient RequiresGradient)
        queryGradient
        (Or
           (Gradient RequiresGradient)
           gradient
           (Or
              (Gradient RequiresGradient)
              queryGradient
              (Or
                 (Gradient RequiresGradient) keyGradient attentionBiasGradient))))
     (Unify
        (Layout LayoutType)
        queryLayout
        (Unify
           (Layout LayoutType)
           ('Layout 'Dense)
           (Unify
              (Layout LayoutType)
              queryLayout
              (Unify (Layout LayoutType) keyLayout attentionBiasLayout))))
     (Unify (Device (DeviceType Nat)) queryDevice generatorOutputDevice)
     (Unify
        (DataType DType)
        queryDataType
        (Unify
           (DataType DType)
           dataType
           (Unify
              (DataType DType)
              queryDataType
              (Unify (DataType DType) keyDataType attentionBiasDataType))))
     (BroadcastShapesF queryShape mhaOutputShape))
-&gt; (Tensor
      (Or
         (Gradient RequiresGradient)
         queryGradient
         (Or
            (Gradient RequiresGradient)
            gradient
            (Or
               (Gradient RequiresGradient)
               queryGradient
               (Or
                  (Gradient RequiresGradient) keyGradient attentionBiasGradient))))
      (Unify
         (Layout LayoutType)
         queryLayout
         (Unify
            (Layout LayoutType)
            ('Layout 'Dense)
            (Unify
               (Layout LayoutType)
               queryLayout
               (Unify (Layout LayoutType) keyLayout attentionBiasLayout))))
      (Unify (Device (DeviceType Nat)) queryDevice generatorOutputDevice)
      (Unify
         (DataType DType)
         queryDataType
         (Unify
            (DataType DType)
            dataType
            (Unify
               (DataType DType)
               queryDataType
               (Unify (DataType DType) keyDataType attentionBiasDataType))))
      (BroadcastShapesF queryShape mhaOutputShape)
    -&gt; IxStateT
         m
         (Generator generatorOutputDevice)
         (Generator generatorOutputDevice)
         output)
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorOutputDevice)
     output
forall k1 (m :: k1 -&gt; k1 -&gt; Type -&gt; Type) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(Generator generatorOutputDevice
 -&gt; m (output, Generator generatorOutputDevice))
-&gt; IxStateT
     m
     (Generator generatorOutputDevice)
     (Generator generatorOutputDevice)
     output
forall (m :: Type -&gt; Type) i j a.
(i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator generatorOutputDevice
  -&gt; m (output, Generator generatorOutputDevice))
 -&gt; IxStateT
      m
      (Generator generatorOutputDevice)
      (Generator generatorOutputDevice)
      output)
-&gt; (Tensor
      (Or
         (Gradient RequiresGradient)
         queryGradient
         (Or
            (Gradient RequiresGradient)
            gradient
            (Or
               (Gradient RequiresGradient)
               queryGradient
               (Or
                  (Gradient RequiresGradient) keyGradient attentionBiasGradient))))
      (Unify
         (Layout LayoutType)
         queryLayout
         (Unify
            (Layout LayoutType)
            ('Layout 'Dense)
            (Unify
               (Layout LayoutType)
               queryLayout
               (Unify (Layout LayoutType) keyLayout attentionBiasLayout))))
      (Unify (Device (DeviceType Nat)) queryDevice generatorOutputDevice)
      (Unify
         (DataType DType)
         queryDataType
         (Unify
            (DataType DType)
            dataType
            (Unify
               (DataType DType)
               queryDataType
               (Unify (DataType DType) keyDataType attentionBiasDataType))))
      (BroadcastShapesF queryShape mhaOutputShape)
    -&gt; Generator generatorOutputDevice
    -&gt; m (output, Generator generatorOutputDevice))
-&gt; Tensor
     (Or
        (Gradient RequiresGradient)
        queryGradient
        (Or
           (Gradient RequiresGradient)
           gradient
           (Or
              (Gradient RequiresGradient)
              queryGradient
              (Or
                 (Gradient RequiresGradient) keyGradient attentionBiasGradient))))
     (Unify
        (Layout LayoutType)
        queryLayout
        (Unify
           (Layout LayoutType)
           ('Layout 'Dense)
           (Unify
              (Layout LayoutType)
              queryLayout
              (Unify (Layout LayoutType) keyLayout attentionBiasLayout))))
     (Unify (Device (DeviceType Nat)) queryDevice generatorOutputDevice)
     (Unify
        (DataType DType)
        queryDataType
        (Unify
           (DataType DType)
           dataType
           (Unify
              (DataType DType)
              queryDataType
              (Unify (DataType DType) keyDataType attentionBiasDataType))))
     (BroadcastShapesF queryShape mhaOutputShape)
-&gt; IxStateT
     m
     (Generator generatorOutputDevice)
     (Generator generatorOutputDevice)
     output
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">LayerNorm
  'WithBias gradient device dataType ('Shape '[queryEmbedDim])
-&gt; Tensor
     (Or
        (Gradient RequiresGradient)
        queryGradient
        (Or
           (Gradient RequiresGradient)
           gradient
           (Or
              (Gradient RequiresGradient)
              queryGradient
              (Or
                 (Gradient RequiresGradient) keyGradient attentionBiasGradient))))
     (Unify
        (Layout LayoutType)
        queryLayout
        (Unify
           (Layout LayoutType)
           ('Layout 'Dense)
           (Unify
              (Layout LayoutType)
              queryLayout
              (Unify (Layout LayoutType) keyLayout attentionBiasLayout))))
     (Unify (Device (DeviceType Nat)) queryDevice generatorOutputDevice)
     (Unify
        (DataType DType)
        queryDataType
        (Unify
           (DataType DType)
           dataType
           (Unify
              (DataType DType)
              queryDataType
              (Unify (DataType DType) keyDataType attentionBiasDataType))))
     (BroadcastShapesF queryShape mhaOutputShape)
-&gt; Generator generatorOutputDevice
-&gt; m (output, Generator generatorOutputDevice)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: Type -&gt; Type).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">GCrossAttention
  (MultiHeadAttention
     'BART
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     keyEmbedDim
     keyEmbedDim)
  (LayerNorm
     'WithBias gradient device dataType ('Shape '[queryEmbedDim]))
  Dropout
-&gt; LayerNorm
     'WithBias gradient device dataType ('Shape '[queryEmbedDim])
forall mha layerNorm dropout.
GCrossAttention mha layerNorm dropout -&gt; layerNorm
</span><a href="Torch.GraduallyTyped.NN.Transformer.CrossAttention.html#caLayerNorm"><span class="hs-identifier hs-var hs-var">caLayerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">GCrossAttention
  (MultiHeadAttention
     'BART
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     keyEmbedDim
     keyEmbedDim)
  (LayerNorm
     'WithBias gradient device dataType ('Shape '[queryEmbedDim]))
  Dropout
GCrossAttention
  (CAMultiheadAttentionF
     'BART
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     keyEmbedDim)
  (CALayerNormF 'BART gradient device dataType queryEmbedDim)
  (CADropoutF 'BART)
</span><a href="#local-6989586621679804827"><span class="hs-identifier hs-var">ca</span></a></span><span class="hs-special">)</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span>
</span><span id="line-503"></span><span>
</span><span id="line-504"></span><span class="hs-comment">-- | 'HasForward' instance for @CrossAttention 'Pegasus@.</span><span>
</span><span id="line-505"></span><span class="hs-comment">--</span><span>
</span><span id="line-506"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-507"></span><span class="hs-comment">--    &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;  &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;  &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;</span><span>
</span><span id="line-508"></span><span class="hs-comment">--    &#9474; query &#9474;  &#9474; key &#9474;  &#9474; attentionBias &#9474;</span><span>
</span><span id="line-509"></span><span class="hs-comment">--    &#9492;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9496;  &#9492;&#9472;&#9472;&#9516;&#9472;&#9472;&#9496;  &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-510"></span><span class="hs-comment">--        &#9474;         &#9474;             &#9474;</span><span>
</span><span id="line-511"></span><span class="hs-comment">-- &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9508;         &#9474;             &#9474;</span><span>
</span><span id="line-512"></span><span class="hs-comment">-- &#9474;      &#9474;         &#9474;             &#9474;</span><span>
</span><span id="line-513"></span><span class="hs-comment">-- &#9474;      &#9660;         &#9474;             &#9474;</span><span>
</span><span id="line-514"></span><span class="hs-comment">-- &#9474; caLayerNorm    &#9474;             &#9474;</span><span>
</span><span id="line-515"></span><span class="hs-comment">-- &#9474;      &#9474;         &#9474;             &#9474;</span><span>
</span><span id="line-516"></span><span class="hs-comment">-- &#9474;      &#9474;      &#9484;&#9472;&#9472;&#9524;&#9472;&#9472;&#9488;          &#9474;</span><span>
</span><span id="line-517"></span><span class="hs-comment">-- &#9474;      &#9474;      &#9474;     &#9474;          &#9474;</span><span>
</span><span id="line-518"></span><span class="hs-comment">-- &#9474;      &#9660;      &#9660;     &#9660;          &#9474;</span><span>
</span><span id="line-519"></span><span class="hs-comment">-- &#9474;   caMultiheadAttention&#9668;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-520"></span><span class="hs-comment">-- &#9474;             &#9474;</span><span>
</span><span id="line-521"></span><span class="hs-comment">-- &#9474;             &#9660;</span><span>
</span><span id="line-522"></span><span class="hs-comment">-- &#9474;         caDropout</span><span>
</span><span id="line-523"></span><span class="hs-comment">-- &#9474;             &#9474;</span><span>
</span><span id="line-524"></span><span class="hs-comment">-- &#9492;&#9472;&#9472;&#9472;&#9472;&#9658;add&#9668;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-525"></span><span class="hs-comment">--        &#9474;</span><span>
</span><span id="line-526"></span><span class="hs-comment">--        &#9660;</span><span>
</span><span id="line-527"></span><span class="hs-comment">--    &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;</span><span>
</span><span id="line-528"></span><span class="hs-comment">--    &#9474; query &#9474;</span><span>
</span><span id="line-529"></span><span class="hs-comment">--    &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;</span><span>
</span><span id="line-530"></span><span class="hs-comment">-- @</span><span>
</span><span id="line-531"></span><span id="local-6989586621679804787"><span id="local-6989586621679804788"><span id="local-6989586621679804789"><span id="local-6989586621679804790"><span id="local-6989586621679804791"><span id="local-6989586621679804792"><span id="local-6989586621679804793"><span id="local-6989586621679804794"><span id="local-6989586621679804795"><span id="local-6989586621679804796"><span id="local-6989586621679804797"><span id="local-6989586621679804798"><span id="local-6989586621679804799"><span id="local-6989586621679804800"><span id="local-6989586621679804801"><span id="local-6989586621679804802"><span id="local-6989586621679804803"><span id="local-6989586621679804804"><span id="local-6989586621679804805"><span id="local-6989586621679804806"><span id="local-6989586621679804807"><span id="local-6989586621679804808"><span id="local-6989586621679804809"><span id="local-6989586621679804810"><span id="local-6989586621679804811"><span id="local-6989586621679804812"><span id="local-6989586621679804813"><span id="local-6989586621679804814"><span id="local-6989586621679804815"><span id="local-6989586621679804816"><span id="local-6989586621679804817"><span id="local-6989586621679804818"><span id="local-6989586621679804819"><span id="local-6989586621679804820"><span id="local-6989586621679804821"><span id="local-6989586621679804822"><span class="hs-keyword">instance</span><span>
</span><span id="line-532"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetDim"><span class="hs-identifier hs-type">SGetDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804822"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-533"></span><span>    </span><span class="annot"><a href="#local-6989586621679804821"><span class="hs-identifier hs-type">query</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804820"><span class="hs-identifier hs-type">queryGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804819"><span class="hs-identifier hs-type">queryLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804818"><span class="hs-identifier hs-type">queryDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804817"><span class="hs-identifier hs-type">queryDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804816"><span class="hs-identifier hs-type">queryShape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-534"></span><span>    </span><span class="annot"><a href="#local-6989586621679804815"><span class="hs-identifier hs-type">key</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804814"><span class="hs-identifier hs-type">keyGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804813"><span class="hs-identifier hs-type">keyLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804812"><span class="hs-identifier hs-type">keyDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804811"><span class="hs-identifier hs-type">keyDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804810"><span class="hs-identifier hs-type">keyShape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-535"></span><span>    </span><span class="annot"><a href="#local-6989586621679804809"><span class="hs-identifier hs-type">attentionBias</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804808"><span class="hs-identifier hs-type">attentionBiasGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804807"><span class="hs-identifier hs-type">attentionBiasLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804806"><span class="hs-identifier hs-type">attentionBiasDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804805"><span class="hs-identifier hs-type">attentionBiasDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804804"><span class="hs-identifier hs-type">attentionBiasShape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-536"></span><span>    </span><span class="annot"><a href="#local-6989586621679804803"><span class="hs-identifier hs-type">normedQueryGradient</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679804802"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804820"><span class="hs-identifier hs-type">queryGradient</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-537"></span><span>    </span><span class="annot"><a href="#local-6989586621679804801"><span class="hs-identifier hs-type">normedQueryLayout</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Dense"><span class="hs-identifier hs-type">Dense</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804819"><span class="hs-identifier hs-type">queryLayout</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-538"></span><span>    </span><span class="annot"><a href="#local-6989586621679804800"><span class="hs-identifier hs-type">normedQueryDevice</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679804799"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804818"><span class="hs-identifier hs-type">queryDevice</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-539"></span><span>    </span><span class="annot"><a href="#local-6989586621679804798"><span class="hs-identifier hs-type">normedQueryDataType</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679804797"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804817"><span class="hs-identifier hs-type">queryDataType</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-540"></span><span>    </span><span class="annot"><a href="#local-6989586621679804796"><span class="hs-identifier hs-type">normedQueryShape</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Functional.Normalization.html#LayerNormWithBiasF"><span class="hs-identifier hs-type">LayerNormWithBiasF</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679804822"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679804822"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679804816"><span class="hs-identifier hs-type">queryShape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-541"></span><span>    </span><span class="annot"><a href="#local-6989586621679804795"><span class="hs-identifier hs-type">normedQuery</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804803"><span class="hs-identifier hs-type">normedQueryGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804801"><span class="hs-identifier hs-type">normedQueryLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804800"><span class="hs-identifier hs-type">normedQueryDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804798"><span class="hs-identifier hs-type">normedQueryDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804796"><span class="hs-identifier hs-type">normedQueryShape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-542"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-543"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.MultiHeadAttention.html#MultiHeadAttention"><span class="hs-identifier hs-type">MultiHeadAttention</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#Pegasus"><span class="hs-identifier hs-type">Pegasus</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804802"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804799"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804797"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804794"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804793"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804792"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804822"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804791"><span class="hs-identifier hs-type">keyEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804791"><span class="hs-identifier hs-type">keyEmbedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-544"></span><span>      </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="#local-6989586621679804795"><span class="hs-identifier hs-type">normedQuery</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-545"></span><span>        </span><span class="annot"><a href="#local-6989586621679804815"><span class="hs-identifier hs-type">key</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-546"></span><span>        </span><span class="annot"><a href="#local-6989586621679804815"><span class="hs-identifier hs-type">key</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-547"></span><span>        </span><span class="annot"><a href="#local-6989586621679804809"><span class="hs-identifier hs-type">attentionBias</span></a></span><span>
</span><span id="line-548"></span><span>      </span><span class="hs-special">)</span><span>
</span><span id="line-549"></span><span>      </span><span class="annot"><a href="#local-6989586621679804790"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-550"></span><span>      </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-551"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679804820"><span class="hs-identifier hs-type">queryGradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804802"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804814"><span class="hs-identifier hs-type">keyGradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804808"><span class="hs-identifier hs-type">attentionBiasGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-552"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679804819"><span class="hs-identifier hs-type">queryLayout</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Dense"><span class="hs-identifier hs-type">Dense</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804813"><span class="hs-identifier hs-type">keyLayout</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804807"><span class="hs-identifier hs-type">attentionBiasLayout</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-553"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679804818"><span class="hs-identifier hs-type">queryDevice</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804799"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804812"><span class="hs-identifier hs-type">keyDevice</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804806"><span class="hs-identifier hs-type">attentionBiasDevice</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804790"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-554"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679804817"><span class="hs-identifier hs-type">queryDataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804797"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804811"><span class="hs-identifier hs-type">keyDataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804805"><span class="hs-identifier hs-type">attentionBiasDataType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-555"></span><span>          </span><span class="annot"><a href="#local-6989586621679804789"><span class="hs-identifier hs-type">mhaOutputShape</span></a></span><span>
</span><span id="line-556"></span><span>      </span><span class="hs-special">)</span><span>
</span><span id="line-557"></span><span>      </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679804818"><span class="hs-identifier hs-type">queryDevice</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804799"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804812"><span class="hs-identifier hs-type">keyDevice</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804806"><span class="hs-identifier hs-type">attentionBiasDevice</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804790"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-558"></span><span>    </span><span class="annot"><a href="#local-6989586621679804788"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-559"></span><span>      </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-560"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679804820"><span class="hs-identifier hs-type">queryGradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804802"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804814"><span class="hs-identifier hs-type">keyGradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804808"><span class="hs-identifier hs-type">attentionBiasGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-561"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679804819"><span class="hs-identifier hs-type">queryLayout</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Dense"><span class="hs-identifier hs-type">Dense</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804813"><span class="hs-identifier hs-type">keyLayout</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804807"><span class="hs-identifier hs-type">attentionBiasLayout</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-562"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679804818"><span class="hs-identifier hs-type">queryDevice</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804799"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804812"><span class="hs-identifier hs-type">keyDevice</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804806"><span class="hs-identifier hs-type">attentionBiasDevice</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804790"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-563"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679804817"><span class="hs-identifier hs-type">queryDataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804797"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804811"><span class="hs-identifier hs-type">keyDataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804805"><span class="hs-identifier hs-type">attentionBiasDataType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-564"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#BroadcastShapesF"><span class="hs-identifier hs-type">BroadcastShapesF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804816"><span class="hs-identifier hs-type">queryShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804789"><span class="hs-identifier hs-type">mhaOutputShape</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-565"></span><span>    </span><span class="annot"><a href="#local-6989586621679804787"><span class="hs-identifier hs-type">generatorOutputDevice</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679804818"><span class="hs-identifier hs-type">queryDevice</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804799"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804812"><span class="hs-identifier hs-type">keyDevice</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804806"><span class="hs-identifier hs-type">attentionBiasDevice</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804790"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-566"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-567"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-568"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.CrossAttention.html#CrossAttention"><span class="hs-identifier hs-type">CrossAttention</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#Pegasus"><span class="hs-identifier hs-type">Pegasus</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804802"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804799"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804797"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804794"><span class="hs-identifier hs-type">headDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804793"><span class="hs-identifier hs-type">headEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804792"><span class="hs-identifier hs-type">embedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804822"><span class="hs-identifier hs-type">queryEmbedDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679804791"><span class="hs-identifier hs-type">keyEmbedDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-569"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679804821"><span class="hs-identifier hs-type">query</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679804815"><span class="hs-identifier hs-type">key</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679804809"><span class="hs-identifier hs-type">attentionBias</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-570"></span><span>    </span><span class="annot"><a href="#local-6989586621679804790"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-571"></span><span>    </span><span class="annot"><a href="#local-6989586621679804788"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-572"></span><span>    </span><span class="annot"><a href="#local-6989586621679804787"><span class="hs-identifier hs-type">generatorOutputDevice</span></a></span><span>
</span><span id="line-573"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-574"></span><span>  </span><span id="local-6989586621679804785"><span class="annot"><span class="annottext">forward :: CrossAttention
  'Pegasus
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  queryEmbedDim
  keyEmbedDim
-&gt; (query, key, attentionBias)
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="#local-6989586621679804785"><span class="hs-identifier hs-var hs-var hs-var hs-var">forward</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.CrossAttention.html#CrossAttention"><span class="hs-identifier hs-type">CrossAttention</span></a></span><span> </span><span id="local-6989586621679804784"><span class="annot"><span class="annottext">GCrossAttention
  (CAMultiheadAttentionF
     'Pegasus
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     keyEmbedDim)
  (CALayerNormF 'Pegasus gradient device dataType queryEmbedDim)
  (CADropoutF 'Pegasus)
</span><a href="#local-6989586621679804784"><span class="hs-identifier hs-var">ca</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679804783"><span class="annot"><span class="annottext">query
</span><a href="#local-6989586621679804783"><span class="hs-identifier hs-var">query</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679804782"><span class="annot"><span class="annottext">key
</span><a href="#local-6989586621679804782"><span class="hs-identifier hs-var">key</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679804781"><span class="annot"><span class="annottext">attentionBias
</span><a href="#local-6989586621679804781"><span class="hs-identifier hs-var">attentionBias</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-575"></span><span>    </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorOutputDevice)
  output
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
forall (m :: Type -&gt; Type) i j a. IxStateT m i j a -&gt; i -&gt; m (a, j)
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var hs-var">runIxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">(IxStateT
   m
   (Generator generatorDevice)
   (Generator generatorOutputDevice)
   output
 -&gt; Generator generatorDevice
 -&gt; m (output, Generator generatorOutputDevice))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorOutputDevice)
     output
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-576"></span><span>      </span><span class="annot"><span class="annottext">query
-&gt; IxStateT
     m (Generator generatorDevice) (Generator generatorDevice) query
forall k (m :: k -&gt; k -&gt; Type -&gt; Type) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">query
</span><a href="#local-6989586621679804783"><span class="hs-identifier hs-var">query</span></a></span><span>
</span><span id="line-577"></span><span>        </span><span class="annot"><span class="annottext">IxStateT
  m (Generator generatorDevice) (Generator generatorDevice) query
-&gt; (query
    -&gt; IxStateT
         m
         (Generator generatorDevice)
         (Generator generatorDevice)
         (Tensor
            normedQueryGradient
            normedQueryLayout
            normedQueryDevice
            normedQueryDataType
            normedQueryShape))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     (Tensor
        normedQueryGradient
        normedQueryLayout
        normedQueryDevice
        normedQueryDataType
        normedQueryShape)
forall k1 (m :: k1 -&gt; k1 -&gt; Type -&gt; Type) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(Generator generatorDevice
 -&gt; m (Tensor
         normedQueryGradient
         normedQueryLayout
         normedQueryDevice
         normedQueryDataType
         normedQueryShape,
       Generator generatorDevice))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     (Tensor
        normedQueryGradient
        normedQueryLayout
        normedQueryDevice
        normedQueryDataType
        normedQueryShape)
forall (m :: Type -&gt; Type) i j a.
(i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator generatorDevice
  -&gt; m (Tensor
          normedQueryGradient
          normedQueryLayout
          normedQueryDevice
          normedQueryDataType
          normedQueryShape,
        Generator generatorDevice))
 -&gt; IxStateT
      m
      (Generator generatorDevice)
      (Generator generatorDevice)
      (Tensor
         normedQueryGradient
         normedQueryLayout
         normedQueryDevice
         normedQueryDataType
         normedQueryShape))
-&gt; (query
    -&gt; Generator generatorDevice
    -&gt; m (Tensor
            normedQueryGradient
            normedQueryLayout
            normedQueryDevice
            normedQueryDataType
            normedQueryShape,
          Generator generatorDevice))
-&gt; query
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorDevice)
     (Tensor
        normedQueryGradient
        normedQueryLayout
        normedQueryDevice
        normedQueryDataType
        normedQueryShape)
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">LayerNorm
  'WithBias gradient device dataType ('Shape '[queryEmbedDim])
-&gt; query
-&gt; Generator generatorDevice
-&gt; m (Tensor
        normedQueryGradient
        normedQueryLayout
        normedQueryDevice
        normedQueryDataType
        normedQueryShape,
      Generator generatorDevice)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: Type -&gt; Type).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">GCrossAttention
  (MultiHeadAttention
     'Pegasus
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     keyEmbedDim
     keyEmbedDim)
  (LayerNorm
     'WithBias gradient device dataType ('Shape '[queryEmbedDim]))
  Dropout
-&gt; LayerNorm
     'WithBias gradient device dataType ('Shape '[queryEmbedDim])
forall mha layerNorm dropout.
GCrossAttention mha layerNorm dropout -&gt; layerNorm
</span><a href="Torch.GraduallyTyped.NN.Transformer.CrossAttention.html#caLayerNorm"><span class="hs-identifier hs-var hs-var">caLayerNorm</span></a></span><span> </span><span class="annot"><span class="annottext">GCrossAttention
  (MultiHeadAttention
     'Pegasus
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     keyEmbedDim
     keyEmbedDim)
  (LayerNorm
     'WithBias gradient device dataType ('Shape '[queryEmbedDim]))
  Dropout
GCrossAttention
  (CAMultiheadAttentionF
     'Pegasus
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     keyEmbedDim)
  (CALayerNormF 'Pegasus gradient device dataType queryEmbedDim)
  (CADropoutF 'Pegasus)
</span><a href="#local-6989586621679804784"><span class="hs-identifier hs-var">ca</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-578"></span><span>        </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorDevice)
  (Tensor
     normedQueryGradient
     normedQueryLayout
     normedQueryDevice
     normedQueryDataType
     normedQueryShape)
-&gt; (Tensor
      normedQueryGradient
      normedQueryLayout
      normedQueryDevice
      normedQueryDataType
      normedQueryShape
    -&gt; IxStateT
         m
         (Generator generatorDevice)
         (Generator generatorOutputDevice)
         (Tensor
            (Or
               (Gradient RequiresGradient)
               queryGradient
               (Or
                  (Gradient RequiresGradient)
                  gradient
                  (Or
                     (Gradient RequiresGradient) keyGradient attentionBiasGradient)))
            (Unify
               (Layout LayoutType)
               queryLayout
               (Unify
                  (Layout LayoutType)
                  ('Layout 'Dense)
                  (Unify (Layout LayoutType) keyLayout attentionBiasLayout)))
            generatorOutputDevice
            (Unify
               (DataType DType)
               queryDataType
               (Unify
                  (DataType DType)
                  dataType
                  (Unify (DataType DType) keyDataType attentionBiasDataType)))
            mhaOutputShape))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorOutputDevice)
     (Tensor
        (Or
           (Gradient RequiresGradient)
           queryGradient
           (Or
              (Gradient RequiresGradient)
              gradient
              (Or
                 (Gradient RequiresGradient) keyGradient attentionBiasGradient)))
        (Unify
           (Layout LayoutType)
           queryLayout
           (Unify
              (Layout LayoutType)
              ('Layout 'Dense)
              (Unify (Layout LayoutType) keyLayout attentionBiasLayout)))
        generatorOutputDevice
        (Unify
           (DataType DType)
           queryDataType
           (Unify
              (DataType DType)
              dataType
              (Unify (DataType DType) keyDataType attentionBiasDataType)))
        mhaOutputShape)
forall k1 (m :: k1 -&gt; k1 -&gt; Type -&gt; Type) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">\</span><span id="local-6989586621679804780"><span class="annot"><span class="annottext">Tensor
  normedQueryGradient
  normedQueryLayout
  normedQueryDevice
  normedQueryDataType
  normedQueryShape
</span><a href="#local-6989586621679804780"><span class="hs-identifier hs-var">query'</span></a></span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="annottext">(Generator generatorDevice
 -&gt; m (Tensor
         (Or
            (Gradient RequiresGradient)
            queryGradient
            (Or
               (Gradient RequiresGradient)
               gradient
               (Or
                  (Gradient RequiresGradient) keyGradient attentionBiasGradient)))
         (Unify
            (Layout LayoutType)
            queryLayout
            (Unify
               (Layout LayoutType)
               ('Layout 'Dense)
               (Unify (Layout LayoutType) keyLayout attentionBiasLayout)))
         generatorOutputDevice
         (Unify
            (DataType DType)
            queryDataType
            (Unify
               (DataType DType)
               dataType
               (Unify (DataType DType) keyDataType attentionBiasDataType)))
         mhaOutputShape,
       Generator generatorOutputDevice))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorOutputDevice)
     (Tensor
        (Or
           (Gradient RequiresGradient)
           queryGradient
           (Or
              (Gradient RequiresGradient)
              gradient
              (Or
                 (Gradient RequiresGradient) keyGradient attentionBiasGradient)))
        (Unify
           (Layout LayoutType)
           queryLayout
           (Unify
              (Layout LayoutType)
              ('Layout 'Dense)
              (Unify (Layout LayoutType) keyLayout attentionBiasLayout)))
        generatorOutputDevice
        (Unify
           (DataType DType)
           queryDataType
           (Unify
              (DataType DType)
              dataType
              (Unify (DataType DType) keyDataType attentionBiasDataType)))
        mhaOutputShape)
forall (m :: Type -&gt; Type) i j a.
(i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator generatorDevice
  -&gt; m (Tensor
          (Or
             (Gradient RequiresGradient)
             queryGradient
             (Or
                (Gradient RequiresGradient)
                gradient
                (Or
                   (Gradient RequiresGradient) keyGradient attentionBiasGradient)))
          (Unify
             (Layout LayoutType)
             queryLayout
             (Unify
                (Layout LayoutType)
                ('Layout 'Dense)
                (Unify (Layout LayoutType) keyLayout attentionBiasLayout)))
          generatorOutputDevice
          (Unify
             (DataType DType)
             queryDataType
             (Unify
                (DataType DType)
                dataType
                (Unify (DataType DType) keyDataType attentionBiasDataType)))
          mhaOutputShape,
        Generator generatorOutputDevice))
 -&gt; IxStateT
      m
      (Generator generatorDevice)
      (Generator generatorOutputDevice)
      (Tensor
         (Or
            (Gradient RequiresGradient)
            queryGradient
            (Or
               (Gradient RequiresGradient)
               gradient
               (Or
                  (Gradient RequiresGradient) keyGradient attentionBiasGradient)))
         (Unify
            (Layout LayoutType)
            queryLayout
            (Unify
               (Layout LayoutType)
               ('Layout 'Dense)
               (Unify (Layout LayoutType) keyLayout attentionBiasLayout)))
         generatorOutputDevice
         (Unify
            (DataType DType)
            queryDataType
            (Unify
               (DataType DType)
               dataType
               (Unify (DataType DType) keyDataType attentionBiasDataType)))
         mhaOutputShape))
-&gt; (Generator generatorDevice
    -&gt; m (Tensor
            (Or
               (Gradient RequiresGradient)
               queryGradient
               (Or
                  (Gradient RequiresGradient)
                  gradient
                  (Or
                     (Gradient RequiresGradient) keyGradient attentionBiasGradient)))
            (Unify
               (Layout LayoutType)
               queryLayout
               (Unify
                  (Layout LayoutType)
                  ('Layout 'Dense)
                  (Unify (Layout LayoutType) keyLayout attentionBiasLayout)))
            generatorOutputDevice
            (Unify
               (DataType DType)
               queryDataType
               (Unify
                  (DataType DType)
                  dataType
                  (Unify (DataType DType) keyDataType attentionBiasDataType)))
            mhaOutputShape,
          Generator generatorOutputDevice))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorOutputDevice)
     (Tensor
        (Or
           (Gradient RequiresGradient)
           queryGradient
           (Or
              (Gradient RequiresGradient)
              gradient
              (Or
                 (Gradient RequiresGradient) keyGradient attentionBiasGradient)))
        (Unify
           (Layout LayoutType)
           queryLayout
           (Unify
              (Layout LayoutType)
              ('Layout 'Dense)
              (Unify (Layout LayoutType) keyLayout attentionBiasLayout)))
        generatorOutputDevice
        (Unify
           (DataType DType)
           queryDataType
           (Unify
              (DataType DType)
              dataType
              (Unify (DataType DType) keyDataType attentionBiasDataType)))
        mhaOutputShape)
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">MultiHeadAttention
  'Pegasus
  gradient
  device
  dataType
  headDim
  headEmbedDim
  embedDim
  queryEmbedDim
  keyEmbedDim
  keyEmbedDim
-&gt; (Tensor
      normedQueryGradient
      normedQueryLayout
      normedQueryDevice
      normedQueryDataType
      normedQueryShape,
    key, key, attentionBias)
-&gt; Generator generatorDevice
-&gt; m (Tensor
        (Or
           (Gradient RequiresGradient)
           queryGradient
           (Or
              (Gradient RequiresGradient)
              gradient
              (Or
                 (Gradient RequiresGradient) keyGradient attentionBiasGradient)))
        (Unify
           (Layout LayoutType)
           queryLayout
           (Unify
              (Layout LayoutType)
              ('Layout 'Dense)
              (Unify (Layout LayoutType) keyLayout attentionBiasLayout)))
        generatorOutputDevice
        (Unify
           (DataType DType)
           queryDataType
           (Unify
              (DataType DType)
              dataType
              (Unify (DataType DType) keyDataType attentionBiasDataType)))
        mhaOutputShape,
      Generator generatorOutputDevice)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: Type -&gt; Type).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">GCrossAttention
  (MultiHeadAttention
     'Pegasus
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     keyEmbedDim
     keyEmbedDim)
  (LayerNorm
     'WithBias gradient device dataType ('Shape '[queryEmbedDim]))
  Dropout
-&gt; MultiHeadAttention
     'Pegasus
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     keyEmbedDim
     keyEmbedDim
forall mha layerNorm dropout.
GCrossAttention mha layerNorm dropout -&gt; mha
</span><a href="Torch.GraduallyTyped.NN.Transformer.CrossAttention.html#caMultiHeadAttention"><span class="hs-identifier hs-var hs-var">caMultiHeadAttention</span></a></span><span> </span><span class="annot"><span class="annottext">GCrossAttention
  (MultiHeadAttention
     'Pegasus
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     keyEmbedDim
     keyEmbedDim)
  (LayerNorm
     'WithBias gradient device dataType ('Shape '[queryEmbedDim]))
  Dropout
GCrossAttention
  (CAMultiheadAttentionF
     'Pegasus
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     keyEmbedDim)
  (CALayerNormF 'Pegasus gradient device dataType queryEmbedDim)
  (CADropoutF 'Pegasus)
</span><a href="#local-6989586621679804784"><span class="hs-identifier hs-var">ca</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Tensor
  normedQueryGradient
  normedQueryLayout
  normedQueryDevice
  normedQueryDataType
  normedQueryShape
</span><a href="#local-6989586621679804780"><span class="hs-identifier hs-var">query'</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">key
</span><a href="#local-6989586621679804782"><span class="hs-identifier hs-var">key</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">key
</span><a href="#local-6989586621679804782"><span class="hs-identifier hs-var">key</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">attentionBias
</span><a href="#local-6989586621679804781"><span class="hs-identifier hs-var">attentionBias</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-579"></span><span>        </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorOutputDevice)
  (Tensor
     (Or
        (Gradient RequiresGradient)
        queryGradient
        (Or
           (Gradient RequiresGradient)
           gradient
           (Or
              (Gradient RequiresGradient) keyGradient attentionBiasGradient)))
     (Unify
        (Layout LayoutType)
        queryLayout
        (Unify
           (Layout LayoutType)
           ('Layout 'Dense)
           (Unify (Layout LayoutType) keyLayout attentionBiasLayout)))
     generatorOutputDevice
     (Unify
        (DataType DType)
        queryDataType
        (Unify
           (DataType DType)
           dataType
           (Unify (DataType DType) keyDataType attentionBiasDataType)))
     mhaOutputShape)
-&gt; (Tensor
      (Or
         (Gradient RequiresGradient)
         queryGradient
         (Or
            (Gradient RequiresGradient)
            gradient
            (Or
               (Gradient RequiresGradient) keyGradient attentionBiasGradient)))
      (Unify
         (Layout LayoutType)
         queryLayout
         (Unify
            (Layout LayoutType)
            ('Layout 'Dense)
            (Unify (Layout LayoutType) keyLayout attentionBiasLayout)))
      generatorOutputDevice
      (Unify
         (DataType DType)
         queryDataType
         (Unify
            (DataType DType)
            dataType
            (Unify (DataType DType) keyDataType attentionBiasDataType)))
      mhaOutputShape
    -&gt; IxStateT
         m
         (Generator generatorOutputDevice)
         (Generator generatorOutputDevice)
         (Tensor
            (Or
               (Gradient RequiresGradient)
               queryGradient
               (Or
                  (Gradient RequiresGradient)
                  gradient
                  (Or
                     (Gradient RequiresGradient) keyGradient attentionBiasGradient)))
            (Unify
               (Layout LayoutType)
               queryLayout
               (Unify
                  (Layout LayoutType)
                  ('Layout 'Dense)
                  (Unify (Layout LayoutType) keyLayout attentionBiasLayout)))
            generatorOutputDevice
            (Unify
               (DataType DType)
               queryDataType
               (Unify
                  (DataType DType)
                  dataType
                  (Unify (DataType DType) keyDataType attentionBiasDataType)))
            mhaOutputShape))
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorOutputDevice)
     (Tensor
        (Or
           (Gradient RequiresGradient)
           queryGradient
           (Or
              (Gradient RequiresGradient)
              gradient
              (Or
                 (Gradient RequiresGradient) keyGradient attentionBiasGradient)))
        (Unify
           (Layout LayoutType)
           queryLayout
           (Unify
              (Layout LayoutType)
              ('Layout 'Dense)
              (Unify (Layout LayoutType) keyLayout attentionBiasLayout)))
        generatorOutputDevice
        (Unify
           (DataType DType)
           queryDataType
           (Unify
              (DataType DType)
              dataType
              (Unify (DataType DType) keyDataType attentionBiasDataType)))
        mhaOutputShape)
forall k1 (m :: k1 -&gt; k1 -&gt; Type -&gt; Type) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">(Generator generatorOutputDevice
 -&gt; m (Tensor
         (Or
            (Gradient RequiresGradient)
            queryGradient
            (Or
               (Gradient RequiresGradient)
               gradient
               (Or
                  (Gradient RequiresGradient) keyGradient attentionBiasGradient)))
         (Unify
            (Layout LayoutType)
            queryLayout
            (Unify
               (Layout LayoutType)
               ('Layout 'Dense)
               (Unify (Layout LayoutType) keyLayout attentionBiasLayout)))
         generatorOutputDevice
         (Unify
            (DataType DType)
            queryDataType
            (Unify
               (DataType DType)
               dataType
               (Unify (DataType DType) keyDataType attentionBiasDataType)))
         mhaOutputShape,
       Generator generatorOutputDevice))
-&gt; IxStateT
     m
     (Generator generatorOutputDevice)
     (Generator generatorOutputDevice)
     (Tensor
        (Or
           (Gradient RequiresGradient)
           queryGradient
           (Or
              (Gradient RequiresGradient)
              gradient
              (Or
                 (Gradient RequiresGradient) keyGradient attentionBiasGradient)))
        (Unify
           (Layout LayoutType)
           queryLayout
           (Unify
              (Layout LayoutType)
              ('Layout 'Dense)
              (Unify (Layout LayoutType) keyLayout attentionBiasLayout)))
        generatorOutputDevice
        (Unify
           (DataType DType)
           queryDataType
           (Unify
              (DataType DType)
              dataType
              (Unify (DataType DType) keyDataType attentionBiasDataType)))
        mhaOutputShape)
forall (m :: Type -&gt; Type) i j a.
(i -&gt; m (a, j)) -&gt; IxStateT m i j a
</span><a href="../file:///nix/store/8vjaffqxij7bih93d9mlzmc7ksanlw0i-indexed-extras-lib-indexed-extras-0.2-haddock-doc/share/doc/indexed-extras/html/src"><span class="hs-identifier hs-var">IxStateT</span></a></span><span> </span><span class="annot"><span class="annottext">((Generator generatorOutputDevice
  -&gt; m (Tensor
          (Or
             (Gradient RequiresGradient)
             queryGradient
             (Or
                (Gradient RequiresGradient)
                gradient
                (Or
                   (Gradient RequiresGradient) keyGradient attentionBiasGradient)))
          (Unify
             (Layout LayoutType)
             queryLayout
             (Unify
                (Layout LayoutType)
                ('Layout 'Dense)
                (Unify (Layout LayoutType) keyLayout attentionBiasLayout)))
          generatorOutputDevice
          (Unify
             (DataType DType)
             queryDataType
             (Unify
                (DataType DType)
                dataType
                (Unify (DataType DType) keyDataType attentionBiasDataType)))
          mhaOutputShape,
        Generator generatorOutputDevice))
 -&gt; IxStateT
      m
      (Generator generatorOutputDevice)
      (Generator generatorOutputDevice)
      (Tensor
         (Or
            (Gradient RequiresGradient)
            queryGradient
            (Or
               (Gradient RequiresGradient)
               gradient
               (Or
                  (Gradient RequiresGradient) keyGradient attentionBiasGradient)))
         (Unify
            (Layout LayoutType)
            queryLayout
            (Unify
               (Layout LayoutType)
               ('Layout 'Dense)
               (Unify (Layout LayoutType) keyLayout attentionBiasLayout)))
         generatorOutputDevice
         (Unify
            (DataType DType)
            queryDataType
            (Unify
               (DataType DType)
               dataType
               (Unify (DataType DType) keyDataType attentionBiasDataType)))
         mhaOutputShape))
-&gt; (Tensor
      (Or
         (Gradient RequiresGradient)
         queryGradient
         (Or
            (Gradient RequiresGradient)
            gradient
            (Or
               (Gradient RequiresGradient) keyGradient attentionBiasGradient)))
      (Unify
         (Layout LayoutType)
         queryLayout
         (Unify
            (Layout LayoutType)
            ('Layout 'Dense)
            (Unify (Layout LayoutType) keyLayout attentionBiasLayout)))
      generatorOutputDevice
      (Unify
         (DataType DType)
         queryDataType
         (Unify
            (DataType DType)
            dataType
            (Unify (DataType DType) keyDataType attentionBiasDataType)))
      mhaOutputShape
    -&gt; Generator generatorOutputDevice
    -&gt; m (Tensor
            (Or
               (Gradient RequiresGradient)
               queryGradient
               (Or
                  (Gradient RequiresGradient)
                  gradient
                  (Or
                     (Gradient RequiresGradient) keyGradient attentionBiasGradient)))
            (Unify
               (Layout LayoutType)
               queryLayout
               (Unify
                  (Layout LayoutType)
                  ('Layout 'Dense)
                  (Unify (Layout LayoutType) keyLayout attentionBiasLayout)))
            generatorOutputDevice
            (Unify
               (DataType DType)
               queryDataType
               (Unify
                  (DataType DType)
                  dataType
                  (Unify (DataType DType) keyDataType attentionBiasDataType)))
            mhaOutputShape,
          Generator generatorOutputDevice))
-&gt; Tensor
     (Or
        (Gradient RequiresGradient)
        queryGradient
        (Or
           (Gradient RequiresGradient)
           gradient
           (Or
              (Gradient RequiresGradient) keyGradient attentionBiasGradient)))
     (Unify
        (Layout LayoutType)
        queryLayout
        (Unify
           (Layout LayoutType)
           ('Layout 'Dense)
           (Unify (Layout LayoutType) keyLayout attentionBiasLayout)))
     generatorOutputDevice
     (Unify
        (DataType DType)
        queryDataType
        (Unify
           (DataType DType)
           dataType
           (Unify (DataType DType) keyDataType attentionBiasDataType)))
     mhaOutputShape
-&gt; IxStateT
     m
     (Generator generatorOutputDevice)
     (Generator generatorOutputDevice)
     (Tensor
        (Or
           (Gradient RequiresGradient)
           queryGradient
           (Or
              (Gradient RequiresGradient)
              gradient
              (Or
                 (Gradient RequiresGradient) keyGradient attentionBiasGradient)))
        (Unify
           (Layout LayoutType)
           queryLayout
           (Unify
              (Layout LayoutType)
              ('Layout 'Dense)
              (Unify (Layout LayoutType) keyLayout attentionBiasLayout)))
        generatorOutputDevice
        (Unify
           (DataType DType)
           queryDataType
           (Unify
              (DataType DType)
              dataType
              (Unify (DataType DType) keyDataType attentionBiasDataType)))
        mhaOutputShape)
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Dropout
-&gt; Tensor
     (Or
        (Gradient RequiresGradient)
        queryGradient
        (Or
           (Gradient RequiresGradient)
           gradient
           (Or
              (Gradient RequiresGradient) keyGradient attentionBiasGradient)))
     (Unify
        (Layout LayoutType)
        queryLayout
        (Unify
           (Layout LayoutType)
           ('Layout 'Dense)
           (Unify (Layout LayoutType) keyLayout attentionBiasLayout)))
     generatorOutputDevice
     (Unify
        (DataType DType)
        queryDataType
        (Unify
           (DataType DType)
           dataType
           (Unify (DataType DType) keyDataType attentionBiasDataType)))
     mhaOutputShape
-&gt; Generator generatorOutputDevice
-&gt; m (Tensor
        (Or
           (Gradient RequiresGradient)
           queryGradient
           (Or
              (Gradient RequiresGradient)
              gradient
              (Or
                 (Gradient RequiresGradient) keyGradient attentionBiasGradient)))
        (Unify
           (Layout LayoutType)
           queryLayout
           (Unify
              (Layout LayoutType)
              ('Layout 'Dense)
              (Unify (Layout LayoutType) keyLayout attentionBiasLayout)))
        generatorOutputDevice
        (Unify
           (DataType DType)
           queryDataType
           (Unify
              (DataType DType)
              dataType
              (Unify (DataType DType) keyDataType attentionBiasDataType)))
        mhaOutputShape,
      Generator generatorOutputDevice)
forall model input (generatorDevice :: Device (DeviceType Nat))
       output (generatorOutputDevice :: Device (DeviceType Nat))
       (m :: Type -&gt; Type).
(HasForward
   model input generatorDevice output generatorOutputDevice,
 MonadThrow m) =&gt;
model
-&gt; input
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorOutputDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">GCrossAttention
  (MultiHeadAttention
     'Pegasus
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     keyEmbedDim
     keyEmbedDim)
  (LayerNorm
     'WithBias gradient device dataType ('Shape '[queryEmbedDim]))
  Dropout
-&gt; Dropout
forall mha layerNorm dropout.
GCrossAttention mha layerNorm dropout -&gt; dropout
</span><a href="Torch.GraduallyTyped.NN.Transformer.CrossAttention.html#caDropout"><span class="hs-identifier hs-var hs-var">caDropout</span></a></span><span> </span><span class="annot"><span class="annottext">GCrossAttention
  (MultiHeadAttention
     'Pegasus
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     keyEmbedDim
     keyEmbedDim)
  (LayerNorm
     'WithBias gradient device dataType ('Shape '[queryEmbedDim]))
  Dropout
GCrossAttention
  (CAMultiheadAttentionF
     'Pegasus
     gradient
     device
     dataType
     headDim
     headEmbedDim
     embedDim
     queryEmbedDim
     keyEmbedDim)
  (CALayerNormF 'Pegasus gradient device dataType queryEmbedDim)
  (CADropoutF 'Pegasus)
</span><a href="#local-6989586621679804784"><span class="hs-identifier hs-var">ca</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-580"></span><span>        </span><span class="annot"><span class="annottext">IxStateT
  m
  (Generator generatorDevice)
  (Generator generatorOutputDevice)
  (Tensor
     (Or
        (Gradient RequiresGradient)
        queryGradient
        (Or
           (Gradient RequiresGradient)
           gradient
           (Or
              (Gradient RequiresGradient) keyGradient attentionBiasGradient)))
     (Unify
        (Layout LayoutType)
        queryLayout
        (Unify
           (Layout LayoutType)
           ('Layout 'Dense)
           (Unify (Layout LayoutType) keyLayout attentionBiasLayout)))
     generatorOutputDevice
     (Unify
        (DataType DType)
        queryDataType
        (Unify
           (DataType DType)
           dataType
           (Unify (DataType DType) keyDataType attentionBiasDataType)))
     mhaOutputShape)
-&gt; (Tensor
      (Or
         (Gradient RequiresGradient)
         queryGradient
         (Or
            (Gradient RequiresGradient)
            gradient
            (Or
               (Gradient RequiresGradient) keyGradient attentionBiasGradient)))
      (Unify
         (Layout LayoutType)
         queryLayout
         (Unify
            (Layout LayoutType)
            ('Layout 'Dense)
            (Unify (Layout LayoutType) keyLayout attentionBiasLayout)))
      generatorOutputDevice
      (Unify
         (DataType DType)
         queryDataType
         (Unify
            (DataType DType)
            dataType
            (Unify (DataType DType) keyDataType attentionBiasDataType)))
      mhaOutputShape
    -&gt; IxStateT
         m
         (Generator generatorOutputDevice)
         (Generator generatorOutputDevice)
         output)
-&gt; IxStateT
     m
     (Generator generatorDevice)
     (Generator generatorOutputDevice)
     output
forall k1 (m :: k1 -&gt; k1 -&gt; Type -&gt; Type) (i :: k1) (j :: k1) a
       (k2 :: k1) b.
IxMonad m =&gt;
m i j a -&gt; (a -&gt; m j k2 b) -&gt; m i k2 b
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-operator hs-var">&gt;&gt;&gt;=</span></a></span><span> </span><span class="annot"><span class="annottext">output
-&gt; IxStateT
     m
     (Generator generatorOutputDevice)
     (Generator generatorOutputDevice)
     output
forall k (m :: k -&gt; k -&gt; Type -&gt; Type) a (i :: k).
IxPointed m =&gt;
a -&gt; m i i a
</span><a href="../file:///nix/store/y93sl1ahi24xw24f0y8xsbhzkmpzqzqh-indexed-lib-indexed-0.1.3-haddock-doc/share/doc/indexed/html/src"><span class="hs-identifier hs-var">ireturn</span></a></span><span> </span><span class="annot"><span class="annottext">(output
 -&gt; IxStateT
      m
      (Generator generatorOutputDevice)
      (Generator generatorOutputDevice)
      output)
-&gt; (Tensor
      (Or
         (Gradient RequiresGradient)
         queryGradient
         (Or
            (Gradient RequiresGradient)
            gradient
            (Or
               (Gradient RequiresGradient) keyGradient attentionBiasGradient)))
      (Unify
         (Layout LayoutType)
         queryLayout
         (Unify
            (Layout LayoutType)
            ('Layout 'Dense)
            (Unify (Layout LayoutType) keyLayout attentionBiasLayout)))
      generatorOutputDevice
      (Unify
         (DataType DType)
         queryDataType
         (Unify
            (DataType DType)
            dataType
            (Unify (DataType DType) keyDataType attentionBiasDataType)))
      mhaOutputShape
    -&gt; output)
-&gt; Tensor
     (Or
        (Gradient RequiresGradient)
        queryGradient
        (Or
           (Gradient RequiresGradient)
           gradient
           (Or
              (Gradient RequiresGradient) keyGradient attentionBiasGradient)))
     (Unify
        (Layout LayoutType)
        queryLayout
        (Unify
           (Layout LayoutType)
           ('Layout 'Dense)
           (Unify (Layout LayoutType) keyLayout attentionBiasLayout)))
     generatorOutputDevice
     (Unify
        (DataType DType)
        queryDataType
        (Unify
           (DataType DType)
           dataType
           (Unify (DataType DType) keyDataType attentionBiasDataType)))
     mhaOutputShape
-&gt; IxStateT
     m
     (Generator generatorOutputDevice)
     (Generator generatorOutputDevice)
     output
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">query
Tensor
  queryGradient queryLayout queryDevice queryDataType queryShape
</span><a href="#local-6989586621679804783"><span class="hs-identifier hs-var">query</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  queryGradient queryLayout queryDevice queryDataType queryShape
-&gt; Tensor
     (Or
        (Gradient RequiresGradient)
        queryGradient
        (Or
           (Gradient RequiresGradient)
           gradient
           (Or
              (Gradient RequiresGradient) keyGradient attentionBiasGradient)))
     (Unify
        (Layout LayoutType)
        queryLayout
        (Unify
           (Layout LayoutType)
           ('Layout 'Dense)
           (Unify (Layout LayoutType) keyLayout attentionBiasLayout)))
     generatorOutputDevice
     (Unify
        (DataType DType)
        queryDataType
        (Unify
           (DataType DType)
           dataType
           (Unify (DataType DType) keyDataType attentionBiasDataType)))
     mhaOutputShape
-&gt; Tensor
     (queryGradient
      &lt;|&gt; Or
            (Gradient RequiresGradient)
            queryGradient
            (Or
               (Gradient RequiresGradient)
               gradient
               (Or
                  (Gradient RequiresGradient) keyGradient attentionBiasGradient)))
     (queryLayout
      &lt;+&gt; Unify
            (Layout LayoutType)
            queryLayout
            (Unify
               (Layout LayoutType)
               ('Layout 'Dense)
               (Unify (Layout LayoutType) keyLayout attentionBiasLayout)))
     (queryDevice &lt;+&gt; generatorOutputDevice)
     (queryDataType
      &lt;+&gt; Unify
            (DataType DType)
            queryDataType
            (Unify
               (DataType DType)
               dataType
               (Unify (DataType DType) keyDataType attentionBiasDataType)))
     (BroadcastShapesF queryShape mhaOutputShape)
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (gradient' :: Gradient RequiresGradient)
       (layout' :: Layout LayoutType) (device' :: Device (DeviceType Nat))
       (dataType' :: DataType DType)
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]).
Tensor gradient layout device dataType shape
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; Tensor
     (gradient &lt;|&gt; gradient')
     (layout &lt;+&gt; layout')
     (device &lt;+&gt; device')
     (dataType &lt;+&gt; dataType')
     (BroadcastShapesF shape shape')
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#add"><span class="hs-operator hs-var">`add`</span></a></span><span class="hs-special">)</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span>
</span><span id="line-581"></span></pre></body></html>