<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><link rel="stylesheet" type="text/css" href="style.css" /><script type="text/javascript" src="highlight.js"></script></head><body><pre><span id="%24con2tag_Hck9baxzUsC7hg0HrbQBTX"></span><span class="hs-pragma">{-# LANGUAGE ConstraintKinds #-}</span><span>
</span><span id="line-2"></span><span class="hs-pragma">{-# LANGUAGE DataKinds #-}</span><span>
</span><span id="line-3"></span><span class="hs-pragma">{-# LANGUAGE DeriveGeneric #-}</span><span>
</span><span id="line-4"></span><span class="hs-pragma">{-# LANGUAGE DerivingStrategies #-}</span><span>
</span><span id="line-5"></span><span class="hs-pragma">{-# LANGUAGE FlexibleInstances #-}</span><span>
</span><span id="line-6"></span><span class="hs-pragma">{-# LANGUAGE GADTs #-}</span><span>
</span><span id="line-7"></span><span class="hs-pragma">{-# LANGUAGE MultiParamTypeClasses #-}</span><span>
</span><span id="line-8"></span><span class="hs-pragma">{-# LANGUAGE PatternSynonyms #-}</span><span>
</span><span id="line-9"></span><span class="hs-pragma">{-# LANGUAGE RecordWildCards #-}</span><span>
</span><span id="line-10"></span><span class="hs-pragma">{-# LANGUAGE ScopedTypeVariables #-}</span><span>
</span><span id="line-11"></span><span class="hs-pragma">{-# LANGUAGE StandaloneKindSignatures #-}</span><span>
</span><span id="line-12"></span><span class="hs-pragma">{-# LANGUAGE TemplateHaskell #-}</span><span>
</span><span id="line-13"></span><span class="hs-pragma">{-# LANGUAGE TupleSections #-}</span><span>
</span><span id="line-14"></span><span class="hs-pragma">{-# LANGUAGE TypeApplications #-}</span><span>
</span><span id="line-15"></span><span class="hs-pragma">{-# LANGUAGE TypeFamilies #-}</span><span>
</span><span id="line-16"></span><span class="hs-pragma">{-# LANGUAGE TypeOperators #-}</span><span>
</span><span id="line-17"></span><span class="hs-pragma">{-# LANGUAGE UndecidableInstances #-}</span><span>
</span><span id="line-18"></span><span class="hs-pragma">{-# OPTIONS_GHC -fplugin TypeLevel.Rewrite
                -fplugin-opt=TypeLevel.Rewrite:Torch.GraduallyTyped.Unify.UnifyRightAssociativeL
                -fplugin-opt=TypeLevel.Rewrite:Torch.GraduallyTyped.Unify.UnifyIdempotenceL2 #-}</span><span>
</span><span id="line-21"></span><span>
</span><span id="line-22"></span><span class="hs-keyword">module</span><span> </span><span class="hs-identifier">Torch.GraduallyTyped.NN.Transformer.Type</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-23"></span><span>
</span><span id="line-24"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier">Control.Monad.Catch</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier">MonadThrow</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-25"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.List.html"><span class="hs-identifier">Torch.GraduallyTyped.Prelude.List</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">SList</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">SNil</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-26"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">Data.Singletons.TH</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">SingKind</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">fromSing</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">genSingletons</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-27"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">GHC.Float</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier">double2Int</span></span><span class="hs-special">)</span><span>
</span><span id="line-28"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">GHC.Generics</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier">Generic</span></span><span class="hs-special">)</span><span>
</span><span id="line-29"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">GHC.TypeLits</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier">Nat</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier">Symbol</span></span><span class="hs-special">)</span><span>
</span><span id="line-30"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html"><span class="hs-identifier">Torch.GraduallyTyped.DType</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier">DType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier">DataType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#SDType"><span class="hs-identifier">SDType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier">SDataType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-31"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html"><span class="hs-identifier">Torch.GraduallyTyped.Device</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#SDevice"><span class="hs-identifier">SDevice</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-32"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html"><span class="hs-identifier">Torch.GraduallyTyped.Layout</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier">Layout</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#LayoutType"><span class="hs-identifier">LayoutType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#SLayout"><span class="hs-identifier">SLayout</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#SLayoutType"><span class="hs-identifier">SLayoutType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-33"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html"><span class="hs-identifier">Torch.GraduallyTyped.NN.Class</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier">HasForward</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier">HasInitialize</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasStateDict"><span class="hs-identifier">HasStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier">ModelSpec</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-34"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html"><span class="hs-identifier">Torch.GraduallyTyped.Prelude</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Catch"><span class="hs-identifier">Catch</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#forgetIsChecked"><span class="hs-identifier">forgetIsChecked</span></a></span><span class="hs-special">,</span><span> </span><span class="hs-keyword">pattern</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#%3A%7C%3A"><span class="hs-operator">(:|:)</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-35"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html"><span class="hs-identifier">Torch.GraduallyTyped.RequiresGradient</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier">Gradient</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#RequiresGradient"><span class="hs-identifier">RequiresGradient</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier">SGradient</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#SRequiresGradient"><span class="hs-identifier">SRequiresGradient</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-36"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Scalar.html"><span class="hs-identifier">Torch.GraduallyTyped.Scalar</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Scalar.html#Scalar"><span class="hs-identifier">Scalar</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-37"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html"><span class="hs-identifier">Torch.GraduallyTyped.Shape.Class</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#AddDimF"><span class="hs-identifier">AddDimF</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#BroadcastShapesF"><span class="hs-identifier">BroadcastShapesF</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#ReplaceDimF"><span class="hs-identifier">ReplaceDimF</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#sGetDimFromShape"><span class="hs-identifier">sGetDimFromShape</span></a></span><span class="hs-special">,</span><span> </span><span class="hs-keyword">type</span><span> </span><span class="hs-special">(</span><span class="hs-glyph">!</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-38"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html"><span class="hs-identifier">Torch.GraduallyTyped.Shape.Type</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#By"><span class="hs-identifier">By</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier">Name</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SBy"><span class="hs-identifier">SBy</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier">SDim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#sDimSize"><span class="hs-identifier">sDimSize</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier">SName</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SSelectDim"><span class="hs-identifier">SSelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier">SShape</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier">SSize</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier">Shape</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier">Size</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="hs-keyword">pattern</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator">(:&amp;:)</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-39"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Creation.html"><span class="hs-identifier">Torch.GraduallyTyped.Tensor.Creation</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Creation.html#sArangeNaturals"><span class="hs-identifier">sArangeNaturals</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Creation.html#sFull"><span class="hs-identifier">sFull</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Creation.html#sOnes"><span class="hs-identifier">sOnes</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Creation.html#sZeros"><span class="hs-identifier">sZeros</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-40"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html"><span class="hs-identifier">Torch.GraduallyTyped.Tensor.IndexingSlicingJoining</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#UnsqueezeF"><span class="hs-identifier">UnsqueezeF</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#cat"><span class="hs-identifier">cat</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#unsqueeze"><span class="hs-identifier">unsqueeze</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-41"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Comparison.html"><span class="hs-identifier">Torch.GraduallyTyped.Tensor.MathOperations.Comparison</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Comparison.html#%3D%3D."><span class="hs-operator">(==.)</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-42"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html"><span class="hs-identifier">Torch.GraduallyTyped.Tensor.MathOperations.Pointwise</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#addScalar"><span class="hs-identifier">addScalar</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#logicalOr"><span class="hs-identifier">logicalOr</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-43"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Other.html"><span class="hs-identifier">Torch.GraduallyTyped.Tensor.Other</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Other.html#maskedFill"><span class="hs-identifier">maskedFill</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Other.html#triu"><span class="hs-identifier">triu</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-44"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html"><span class="hs-identifier">Torch.GraduallyTyped.Tensor.Type</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetDataType"><span class="hs-identifier">SGetDataType</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#sGetDataType"><span class="hs-identifier">sGetDataType</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetDevice"><span class="hs-identifier">SGetDevice</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetDim"><span class="hs-identifier">SGetDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetLayout"><span class="hs-identifier">SGetLayout</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetShape"><span class="hs-identifier">SGetShape</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier">Tensor</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorLike"><span class="hs-identifier">TensorLike</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#sToTensor"><span class="hs-identifier">sToTensor</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorSpec"><span class="hs-identifier">TensorSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#bool"><span class="hs-identifier">bool</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#sCheckedShape"><span class="hs-identifier">sCheckedShape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-45"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html"><span class="hs-identifier">Torch.GraduallyTyped.Unify</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-keyword">type</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator">(&lt;+&gt;)</span></a></span><span class="hs-special">,</span><span> </span><span class="hs-keyword">type</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator">(&lt;|&gt;)</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-46"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../../../../hasktorch/html/src"><span class="hs-identifier">Torch.HList</span></a></span><span>
</span><span id="line-47"></span><span>
</span><span id="line-48"></span><span class="hs-comment">-- | A data type representing the style of a transformer.</span><span>
</span><span id="line-49"></span><span class="hs-comment">-- Every supported transformer has a constructor of this type.</span><span>
</span><span id="line-50"></span><span class="hs-keyword">data</span><span> </span><span id="TransformerStyle"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerStyle"><span class="hs-identifier hs-var">TransformerStyle</span></a></span></span><span>
</span><span id="line-51"></span><span>  </span><span class="hs-glyph">=</span><span> </span><span class="hs-comment">-- | @T5@ transformer style, see https://ai.googleblog.com/2020/02/exploring-transfer-learning-with-t5.html</span><span>
</span><span id="line-52"></span><span>    </span><span id="T5"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#T5"><span class="hs-identifier hs-var">T5</span></a></span></span><span>
</span><span id="line-53"></span><span>  </span><span class="hs-glyph">|</span><span> </span><span class="hs-comment">-- | @ByT5@ transformer style, see https://arxiv.org/abs/2105.13626</span><span>
</span><span id="line-54"></span><span>    </span><span id="ByT5"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ByT5"><span class="hs-identifier hs-var">ByT5</span></a></span></span><span>
</span><span id="line-55"></span><span>  </span><span class="hs-glyph">|</span><span> </span><span class="hs-comment">-- | @BART@ transformer style, see https://arxiv.org/abs/1910.13461</span><span>
</span><span id="line-56"></span><span>    </span><span id="BART"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-var">BART</span></a></span></span><span>
</span><span id="line-57"></span><span>  </span><span class="hs-glyph">|</span><span> </span><span class="hs-comment">-- | @MBART@ transformer style, see https://arxiv.org/abs/2001.08210</span><span>
</span><span id="line-58"></span><span>    </span><span id="MBART"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MBART"><span class="hs-identifier hs-var">MBART</span></a></span></span><span>
</span><span id="line-59"></span><span>  </span><span class="hs-glyph">|</span><span> </span><span class="hs-comment">-- | @Pegasus@ transformer style, see https://ai.googleblog.com/2020/06/pegasus-state-of-art-model-for.html</span><span>
</span><span id="line-60"></span><span>    </span><span id="Pegasus"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#Pegasus"><span class="hs-identifier hs-var">Pegasus</span></a></span></span><span>
</span><span id="line-61"></span><span>  </span><span class="hs-glyph">|</span><span> </span><span class="hs-comment">-- | @BERT@ transformer style, see https://arxiv.org/abs/1810.04805</span><span>
</span><span id="line-62"></span><span>    </span><span id="BERT"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BERT"><span class="hs-identifier hs-var">BERT</span></a></span></span><span>
</span><span id="line-63"></span><span>  </span><span class="hs-glyph">|</span><span> </span><span class="hs-comment">-- | @RoBERTa@ transformer style, see https://arxiv.org/abs/1907.11692</span><span>
</span><span id="line-64"></span><span>    </span><span id="RoBERTa"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#RoBERTa"><span class="hs-identifier hs-var">RoBERTa</span></a></span></span><span>
</span><span id="line-65"></span><span>  </span><span class="hs-glyph">|</span><span> </span><span class="hs-comment">-- | @GPT2@ transformer style, see https://openai.com/blog/better-language-models/</span><span>
</span><span id="line-66"></span><span>    </span><span id="GPT2"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#GPT2"><span class="hs-identifier hs-var">GPT2</span></a></span></span><span>
</span><span id="line-67"></span><span>  </span><span class="hs-keyword">deriving</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679677617"><span id="local-6989586621679677619"><span id="local-6989586621679677621"><span class="annot"><span class="annottext">Int -&gt; TransformerStyle -&gt; ShowS
[TransformerStyle] -&gt; ShowS
TransformerStyle -&gt; String
(Int -&gt; TransformerStyle -&gt; ShowS)
-&gt; (TransformerStyle -&gt; String)
-&gt; ([TransformerStyle] -&gt; ShowS)
-&gt; Show TransformerStyle
forall a.
(Int -&gt; a -&gt; ShowS) -&gt; (a -&gt; String) -&gt; ([a] -&gt; ShowS) -&gt; Show a
showList :: [TransformerStyle] -&gt; ShowS
$cshowList :: [TransformerStyle] -&gt; ShowS
show :: TransformerStyle -&gt; String
$cshow :: TransformerStyle -&gt; String
showsPrec :: Int -&gt; TransformerStyle -&gt; ShowS
$cshowsPrec :: Int -&gt; TransformerStyle -&gt; ShowS
</span><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">Show</span></span></span></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679677612"><span id="local-6989586621679677614"><span class="annot"><span class="annottext">TransformerStyle -&gt; TransformerStyle -&gt; Bool
(TransformerStyle -&gt; TransformerStyle -&gt; Bool)
-&gt; (TransformerStyle -&gt; TransformerStyle -&gt; Bool)
-&gt; Eq TransformerStyle
forall a. (a -&gt; a -&gt; Bool) -&gt; (a -&gt; a -&gt; Bool) -&gt; Eq a
/= :: TransformerStyle -&gt; TransformerStyle -&gt; Bool
$c/= :: TransformerStyle -&gt; TransformerStyle -&gt; Bool
== :: TransformerStyle -&gt; TransformerStyle -&gt; Bool
$c== :: TransformerStyle -&gt; TransformerStyle -&gt; Bool
</span><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var">Eq</span></span></span></span><span class="hs-special">)</span><span>
</span><span id="line-68"></span><span>
</span><span id="line-69"></span><span id="T5Sym0"><span id="ByT5Sym0"><span id="BARTSym0"><span id="MBARTSym0"><span id="PegasusSym0"><span id="BERTSym0"><span id="RoBERTaSym0"><span id="GPT2Sym0"><span id="SGPT2"><span id="SRoBERTa"><span id="SBERT"><span id="SPegasus"><span id="SMBART"><span id="SBART"><span id="SByT5"><span id="ST5"><span id="STransformerStyle"><span id="local-6989586621679677590"><span id="local-6989586621679677592"><span id="local-6989586621679677594"><span id="local-6989586621679677596"><span id="local-6989586621679677598"><span id="local-6989586621679677600"><span id="local-6989586621679677602"><span id="local-6989586621679677604"><span id="local-6989586621679677606"><span id="local-6989586621679677608"><span id="local-6989586621679677610"><span id="Demote"><span id="Sing"><span class="hs-identifier">genSingletons</span><span> </span><span class="hs-special">[</span><span class="hs-special">''</span><span class="hs-identifier">TransformerStyle</span><span class="hs-special">]</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span>
</span><span id="line-70"></span><span>
</span><span id="line-71"></span><span class="hs-comment">-- | A data type representing the type of head used in a transformer.</span><span>
</span><span id="line-72"></span><span class="hs-keyword">data</span><span> </span><span id="TransformerHead"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerHead"><span class="hs-identifier hs-var">TransformerHead</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span id="WithoutHead"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#WithoutHead"><span class="hs-identifier hs-var">WithoutHead</span></a></span></span><span> </span><span class="hs-glyph">|</span><span> </span><span id="WithLMHead"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#WithLMHead"><span class="hs-identifier hs-var">WithLMHead</span></a></span></span><span>
</span><span id="line-73"></span><span>
</span><span id="line-74"></span><span id="WithoutHeadSym0"><span id="WithLMHeadSym0"><span id="SWithLMHead"><span id="SWithoutHead"><span id="STransformerHead"><span id="local-6989586621679677560"><span id="local-6989586621679677562"><span id="local-6989586621679677564"><span id="local-6989586621679677566"><span id="local-6989586621679677568"><span id="Demote"><span id="Sing"><span class="hs-identifier">genSingletons</span><span> </span><span class="hs-special">[</span><span class="hs-special">''</span><span class="hs-identifier">TransformerHead</span><span class="hs-special">]</span></span></span></span></span></span></span></span></span></span></span></span></span><span>
</span><span id="line-75"></span><span>
</span><span id="line-76"></span><span id="local-6989586621679678134"><span id="local-6989586621679678135"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#padded"><span class="hs-identifier hs-type">padded</span></a></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Integral</span></span><span> </span><span class="annot"><a href="#local-6989586621679678135"><span class="hs-identifier hs-type">n</span></a></span><span> </span><span class="hs-glyph">=&gt;</span><span> </span><span class="annot"><a href="#local-6989586621679678135"><span class="hs-identifier hs-type">n</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="#local-6989586621679678134"><span class="hs-identifier hs-type">a</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679678134"><span class="hs-identifier hs-type">a</span></a></span><span class="hs-special">]</span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679678134"><span class="hs-identifier hs-type">a</span></a></span><span class="hs-special">]</span></span></span><span>
</span><span id="line-77"></span><span id="padded"><span class="annot"><span class="annottext">padded :: n -&gt; a -&gt; [a] -&gt; [a]
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#padded"><span class="hs-identifier hs-var hs-var">padded</span></a></span></span><span> </span><span id="local-6989586621679677553"><span class="annot"><span class="annottext">n
</span><a href="#local-6989586621679677553"><span class="hs-identifier hs-var">n</span></a></span></span><span> </span><span id="local-6989586621679677552"><span class="annot"><span class="annottext">a
</span><a href="#local-6989586621679677552"><span class="hs-identifier hs-var">p</span></a></span></span><span> </span><span id="local-6989586621679677551"><span class="annot"><span class="annottext">[a]
</span><a href="#local-6989586621679677551"><span class="hs-identifier hs-var">xs</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-78"></span><span>  </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679677550"><span class="annot"><span class="annottext">n' :: Int
</span><a href="#local-6989586621679677550"><span class="hs-identifier hs-var hs-var">n'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">n -&gt; Int
forall a b. (Integral a, Num b) =&gt; a -&gt; b
</span><span class="hs-identifier hs-var">fromIntegral</span></span><span> </span><span class="annot"><span class="annottext">n
</span><a href="#local-6989586621679677553"><span class="hs-identifier hs-var">n</span></a></span><span>
</span><span id="line-79"></span><span>      </span><span id="local-6989586621679677549"><span class="annot"><span class="annottext">diff :: Int
</span><a href="#local-6989586621679677549"><span class="hs-identifier hs-var hs-var">diff</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679677550"><span class="hs-identifier hs-var">n'</span></a></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Int
forall a. Num a =&gt; a -&gt; a -&gt; a
</span><span class="hs-glyph hs-var">-</span></span><span> </span><span class="annot"><span class="annottext">[a] -&gt; Int
forall (t :: * -&gt; *) a. Foldable t =&gt; t a -&gt; Int
</span><span class="hs-identifier hs-var">length</span></span><span> </span><span class="annot"><span class="annottext">[a]
</span><a href="#local-6989586621679677551"><span class="hs-identifier hs-var">xs</span></a></span><span>
</span><span id="line-80"></span><span>   </span><span class="hs-keyword">in</span><span> </span><span class="annot"><span class="annottext">Int -&gt; [a] -&gt; [a]
forall a. Int -&gt; [a] -&gt; [a]
</span><span class="hs-identifier hs-var">take</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679677550"><span class="hs-identifier hs-var">n'</span></a></span><span> </span><span class="annot"><span class="annottext">[a]
</span><a href="#local-6989586621679677551"><span class="hs-identifier hs-var">xs</span></a></span><span> </span><span class="annot"><span class="annottext">[a] -&gt; [a] -&gt; [a]
forall a. [a] -&gt; [a] -&gt; [a]
</span><span class="hs-operator hs-var">++</span></span><span> </span><span class="annot"><span class="annottext">Int -&gt; a -&gt; [a]
forall a. Int -&gt; a -&gt; [a]
</span><span class="hs-identifier hs-var">replicate</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679677549"><span class="hs-identifier hs-var">diff</span></a></span><span> </span><span class="annot"><span class="annottext">a
</span><a href="#local-6989586621679677552"><span class="hs-identifier hs-var">p</span></a></span><span>
</span><span id="line-81"></span><span>
</span><span id="line-82"></span><span class="hs-comment">-- | Converts a doubly-nested list of input ids to a batched input tensor.</span><span>
</span><span id="line-83"></span><span class="hs-comment">-- The outer list is over batches, the inner list over sequences.</span><span>
</span><span id="line-84"></span><span class="hs-comment">-- The batch size is inferred from the length of the outer list.</span><span>
</span><span id="line-85"></span><span class="hs-comment">-- The sequence length is inferred from the length of the inner list.</span><span>
</span><span id="line-86"></span><span class="hs-comment">-- The input ids are padded to the maximum sequence length.</span><span>
</span><span id="line-87"></span><span class="hs-comment">-- The output tensor is truncated to the maximum sequence length.</span><span>
</span><span id="line-88"></span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#mkTransformerInput"><span class="hs-identifier hs-type">mkTransformerInput</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-89"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679677544"><span class="annot"><a href="#local-6989586621679677544"><span class="hs-identifier hs-type">batchDim</span></a></span></span><span> </span><span id="local-6989586621679677543"><span class="annot"><a href="#local-6989586621679677543"><span class="hs-identifier hs-type">seqDim</span></a></span></span><span> </span><span id="local-6989586621679677542"><span class="annot"><a href="#local-6989586621679677542"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679677541"><span class="annot"><a href="#local-6989586621679677541"><span class="hs-identifier hs-type">m</span></a></span></span><span> </span><span id="local-6989586621679677540"><span class="annot"><a href="#local-6989586621679677540"><span class="hs-identifier hs-type">output</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-90"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier hs-type">MonadThrow</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677541"><span class="hs-identifier hs-type">m</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-91"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetDim"><span class="hs-identifier hs-type">SGetDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677544"><span class="hs-identifier hs-type">batchDim</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-92"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetDim"><span class="hs-identifier hs-type">SGetDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677543"><span class="hs-identifier hs-type">seqDim</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-93"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Catch"><span class="hs-identifier hs-type">Catch</span></a></span><span>
</span><span id="line-94"></span><span>      </span><span class="hs-special">(</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span>
</span><span id="line-95"></span><span>          </span><span class="hs-special">'</span><span class="hs-special">[</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#UncheckedSize"><span class="hs-identifier hs-type">UncheckedSize</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-96"></span><span>             </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#UncheckedSize"><span class="hs-identifier hs-type">UncheckedSize</span></a></span><span>
</span><span id="line-97"></span><span>           </span><span class="hs-special">]</span><span>
</span><span id="line-98"></span><span>          </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679677544"><span class="hs-identifier hs-type">batchDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679677543"><span class="hs-identifier hs-type">seqDim</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-99"></span><span>      </span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-100"></span><span>    </span><span class="annot"><a href="#local-6989586621679677540"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-101"></span><span>      </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-102"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#WithoutGradient"><span class="hs-identifier hs-type">WithoutGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-103"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Dense"><span class="hs-identifier hs-type">Dense</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-104"></span><span>          </span><span class="annot"><a href="#local-6989586621679677542"><span class="hs-identifier hs-type">device</span></a></span><span>
</span><span id="line-105"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#Int64"><span class="hs-identifier hs-type">Int64</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-106"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679677544"><span class="hs-identifier hs-type">batchDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679677543"><span class="hs-identifier hs-type">seqDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-107"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-108"></span><span>  </span><span class="hs-comment">-- | padding token id</span><span>
</span><span id="line-109"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-110"></span><span>  </span><span class="hs-comment">-- | batch dimension singleton</span><span>
</span><span id="line-111"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677544"><span class="hs-identifier hs-type">batchDim</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-112"></span><span>  </span><span class="hs-comment">-- | sequence dimension singleton</span><span>
</span><span id="line-113"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677543"><span class="hs-identifier hs-type">seqDim</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-114"></span><span>  </span><span class="hs-comment">-- | device for the tensor</span><span>
</span><span id="line-115"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#SDevice"><span class="hs-identifier hs-type">SDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677542"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-116"></span><span>  </span><span class="hs-comment">-- | batch of input ids</span><span>
</span><span id="line-117"></span><span>  </span><span class="hs-special">[</span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">]</span><span class="hs-special">]</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-118"></span><span>  </span><span class="hs-comment">-- | input tensor</span><span>
</span><span id="line-119"></span><span>  </span><span class="annot"><a href="#local-6989586621679677541"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677540"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-120"></span><span id="mkTransformerInput"><span class="annot"><span class="annottext">mkTransformerInput :: Int
-&gt; SDim batchDim
-&gt; SDim seqDim
-&gt; SDevice device
-&gt; [[Int]]
-&gt; m output
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#mkTransformerInput"><span class="hs-identifier hs-var hs-var">mkTransformerInput</span></a></span></span><span> </span><span id="local-6989586621679677539"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679677539"><span class="hs-identifier hs-var">padTokenId</span></a></span></span><span> </span><span id="local-6989586621679677538"><span class="annot"><span class="annottext">SDim batchDim
</span><a href="#local-6989586621679677538"><span class="hs-identifier hs-var">batchDim</span></a></span></span><span> </span><span id="local-6989586621679677537"><span class="annot"><span class="annottext">SDim seqDim
</span><a href="#local-6989586621679677537"><span class="hs-identifier hs-var">seqDim</span></a></span></span><span> </span><span id="local-6989586621679677536"><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679677536"><span class="hs-identifier hs-var">device</span></a></span></span><span> </span><span id="local-6989586621679677535"><span class="annot"><span class="annottext">[[Int]]
</span><a href="#local-6989586621679677535"><span class="hs-identifier hs-var">xs</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-121"></span><span>  </span><span class="annot"><span class="annottext">SGradient ('Gradient 'WithoutGradient)
-&gt; SLayout ('Layout 'Dense)
-&gt; SDevice device
-&gt; [[Int]]
-&gt; m (Tensor
        ('Gradient 'WithoutGradient)
        ('Layout 'Dense)
        device
        ('DataType 'Int64)
        ('Shape
           '[ 'Dim ('Name &quot;*&quot;) 'UncheckedSize,
              'Dim ('Name &quot;*&quot;) 'UncheckedSize]))
forall a (dType :: DType) (dims :: [Dim (Name Symbol) (Size Nat)])
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (m :: * -&gt; *).
(TensorLike a dType dims, MonadThrow m) =&gt;
SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; a
-&gt; m (Tensor
        gradient layout device ('DataType dType) ('Shape dims))
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sToTensor"><span class="hs-identifier hs-var">sToTensor</span></a></span><span> </span><span class="annot"><span class="annottext">SGradient ('Gradient 'WithoutGradient)
</span><a href="#local-6989586621679677534"><span class="hs-identifier hs-var">gradient</span></a></span><span> </span><span class="annot"><span class="annottext">SLayout ('Layout 'Dense)
</span><a href="#local-6989586621679677533"><span class="hs-identifier hs-var">layout</span></a></span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679677536"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">[[Int]]
</span><a href="#local-6989586621679677532"><span class="hs-identifier hs-var">paddedXs</span></a></span><span>
</span><span id="line-122"></span><span>    </span><span class="annot"><span class="annottext">m (Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     device
     ('DataType 'Int64)
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) 'UncheckedSize,
           'Dim ('Name &quot;*&quot;) 'UncheckedSize]))
-&gt; (Tensor
      ('Gradient 'WithoutGradient)
      ('Layout 'Dense)
      device
      ('DataType 'Int64)
      ('Shape
         '[ 'Dim ('Name &quot;*&quot;) 'UncheckedSize,
            'Dim ('Name &quot;*&quot;) 'UncheckedSize])
    -&gt; m (Tensor
            ('Gradient 'WithoutGradient)
            ('Layout 'Dense)
            device
            ('DataType 'Int64)
            ('Shape '[batchDim, seqDim])))
-&gt; m (Tensor
        ('Gradient 'WithoutGradient)
        ('Layout 'Dense)
        device
        ('DataType 'Int64)
        ('Shape '[batchDim, seqDim]))
forall (m :: * -&gt; *) a b. Monad m =&gt; m a -&gt; (a -&gt; m b) -&gt; m b
</span><span class="hs-operator hs-var">&gt;&gt;=</span></span><span> </span><span class="annot"><span class="annottext">SShape ('Shape '[batchDim, seqDim])
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     device
     ('DataType 'Int64)
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) 'UncheckedSize,
           'Dim ('Name &quot;*&quot;) 'UncheckedSize])
-&gt; m (Tensor
        ('Gradient 'WithoutGradient)
        ('Layout 'Dense)
        device
        ('DataType 'Int64)
        ('Shape '[batchDim, seqDim]))
forall (shape' :: Shape [Dim (Name Symbol) (Size Nat)])
       (m :: * -&gt; *) (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
(SGetShape shape, MonadThrow m, Catch (shape &lt;+&gt; shape')) =&gt;
SShape shape'
-&gt; Tensor gradient layout device dataType shape
-&gt; m (Tensor gradient layout device dataType shape')
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sCheckedShape"><span class="hs-identifier hs-var">sCheckedShape</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SList '[batchDim, seqDim] -&gt; SShape ('Shape '[batchDim, seqDim])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList '[batchDim, seqDim] -&gt; SShape ('Shape '[batchDim, seqDim]))
-&gt; SList '[batchDim, seqDim] -&gt; SShape ('Shape '[batchDim, seqDim])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">Sing batchDim
SDim batchDim
</span><a href="#local-6989586621679677538"><span class="hs-identifier hs-var">batchDim</span></a></span><span> </span><span class="annot"><span class="annottext">Sing batchDim -&gt; SList '[seqDim] -&gt; SList '[batchDim, seqDim]
forall a1 (a2 :: a1) (as :: [a1]).
Sing a2 -&gt; SList as -&gt; SList (a2 : as)
</span><a href="Torch.GraduallyTyped.Prelude.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">Sing seqDim
SDim seqDim
</span><a href="#local-6989586621679677537"><span class="hs-identifier hs-var">seqDim</span></a></span><span> </span><span class="annot"><span class="annottext">Sing seqDim -&gt; SList '[] -&gt; SList '[seqDim]
forall a1 (a2 :: a1) (as :: [a1]).
Sing a2 -&gt; SList as -&gt; SList (a2 : as)
</span><a href="Torch.GraduallyTyped.Prelude.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-123"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-124"></span><span>    </span><span id="local-6989586621679677534"><span class="annot"><span class="annottext">gradient :: SGradient ('Gradient 'WithoutGradient)
</span><a href="#local-6989586621679677534"><span class="hs-identifier hs-var hs-var">gradient</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SRequiresGradient 'WithoutGradient
-&gt; SGradient ('Gradient 'WithoutGradient)
forall (requiresGradient :: RequiresGradient).
SRequiresGradient requiresGradient
-&gt; SGradient ('Gradient requiresGradient)
</span><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier hs-var">SGradient</span></a></span><span> </span><span class="annot"><span class="annottext">SRequiresGradient 'WithoutGradient
</span><a href="Torch.GraduallyTyped.RequiresGradient.html#SWithoutGradient"><span class="hs-identifier hs-var">SWithoutGradient</span></a></span><span>
</span><span id="line-125"></span><span>    </span><span id="local-6989586621679677533"><span class="annot"><span class="annottext">layout :: SLayout ('Layout 'Dense)
</span><a href="#local-6989586621679677533"><span class="hs-identifier hs-var hs-var">layout</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SLayoutType 'Dense -&gt; SLayout ('Layout 'Dense)
forall (layoutType :: LayoutType).
SLayoutType layoutType -&gt; SLayout ('Layout layoutType)
</span><a href="Torch.GraduallyTyped.Layout.html#SLayout"><span class="hs-identifier hs-var">SLayout</span></a></span><span> </span><span class="annot"><span class="annottext">SLayoutType 'Dense
</span><a href="Torch.GraduallyTyped.Layout.html#SDense"><span class="hs-identifier hs-var">SDense</span></a></span><span>
</span><span id="line-126"></span><span>    </span><span id="local-6989586621679677526"><span class="annot"><span class="annottext">batchSize :: Integer
</span><a href="#local-6989586621679677526"><span class="hs-identifier hs-var hs-var">batchSize</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IsChecked Integer -&gt; Integer
forall a. IsChecked a -&gt; a
</span><a href="Torch.GraduallyTyped.Prelude.html#forgetIsChecked"><span class="hs-identifier hs-var">forgetIsChecked</span></a></span><span> </span><span class="annot"><span class="annottext">(IsChecked Integer -&gt; Integer)
-&gt; (Dim (IsChecked String) (IsChecked Integer)
    -&gt; IsChecked Integer)
-&gt; Dim (IsChecked String) (IsChecked Integer)
-&gt; Integer
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Dim (IsChecked String) (IsChecked Integer) -&gt; IsChecked Integer
forall name size. Dim name size -&gt; size
</span><a href="Torch.GraduallyTyped.Shape.Type.html#dimSize"><span class="hs-identifier hs-var hs-var">dimSize</span></a></span><span> </span><span class="annot"><span class="annottext">(Dim (IsChecked String) (IsChecked Integer) -&gt; Integer)
-&gt; Dim (IsChecked String) (IsChecked Integer) -&gt; Integer
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">Sing batchDim -&gt; Demote (Dim (Name Symbol) (Size Nat))
forall k (a :: k). SingKind k =&gt; Sing a -&gt; Demote k
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">fromSing</span></a></span><span> </span><span class="annot"><span class="annottext">Sing batchDim
SDim batchDim
</span><a href="#local-6989586621679677538"><span class="hs-identifier hs-var">batchDim</span></a></span><span>
</span><span id="line-127"></span><span>    </span><span id="local-6989586621679677523"><span class="annot"><span class="annottext">seqSize :: Integer
</span><a href="#local-6989586621679677523"><span class="hs-identifier hs-var hs-var">seqSize</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IsChecked Integer -&gt; Integer
forall a. IsChecked a -&gt; a
</span><a href="Torch.GraduallyTyped.Prelude.html#forgetIsChecked"><span class="hs-identifier hs-var">forgetIsChecked</span></a></span><span> </span><span class="annot"><span class="annottext">(IsChecked Integer -&gt; Integer)
-&gt; (Dim (IsChecked String) (IsChecked Integer)
    -&gt; IsChecked Integer)
-&gt; Dim (IsChecked String) (IsChecked Integer)
-&gt; Integer
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Dim (IsChecked String) (IsChecked Integer) -&gt; IsChecked Integer
forall name size. Dim name size -&gt; size
</span><a href="Torch.GraduallyTyped.Shape.Type.html#dimSize"><span class="hs-identifier hs-var hs-var">dimSize</span></a></span><span> </span><span class="annot"><span class="annottext">(Dim (IsChecked String) (IsChecked Integer) -&gt; Integer)
-&gt; Dim (IsChecked String) (IsChecked Integer) -&gt; Integer
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">Sing seqDim -&gt; Demote (Dim (Name Symbol) (Size Nat))
forall k (a :: k). SingKind k =&gt; Sing a -&gt; Demote k
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">fromSing</span></a></span><span> </span><span class="annot"><span class="annottext">Sing seqDim
SDim seqDim
</span><a href="#local-6989586621679677537"><span class="hs-identifier hs-var">seqDim</span></a></span><span>
</span><span id="line-128"></span><span>    </span><span id="local-6989586621679677522"><span class="annot"><span class="annottext">emptySeq :: [Int]
</span><a href="#local-6989586621679677522"><span class="hs-identifier hs-var hs-var">emptySeq</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; [Int]
forall a. Int -&gt; a -&gt; [a]
</span><span class="hs-identifier hs-var">replicate</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Integer -&gt; Int
forall a b. (Integral a, Num b) =&gt; a -&gt; b
</span><span class="hs-identifier hs-var">fromIntegral</span></span><span> </span><span class="annot"><span class="annottext">Integer
</span><a href="#local-6989586621679677523"><span class="hs-identifier hs-var">seqSize</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679677539"><span class="hs-identifier hs-var">padTokenId</span></a></span><span>
</span><span id="line-129"></span><span>    </span><span id="local-6989586621679677532"><span class="annot"><span class="annottext">paddedXs :: [[Int]]
</span><a href="#local-6989586621679677532"><span class="hs-identifier hs-var hs-var">paddedXs</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Integer -&gt; [Int] -&gt; [[Int]] -&gt; [[Int]]
forall n a. Integral n =&gt; n -&gt; a -&gt; [a] -&gt; [a]
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#padded"><span class="hs-identifier hs-var">padded</span></a></span><span> </span><span class="annot"><span class="annottext">Integer
</span><a href="#local-6989586621679677526"><span class="hs-identifier hs-var">batchSize</span></a></span><span> </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679677522"><span class="hs-identifier hs-var">emptySeq</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Integer -&gt; Int -&gt; [Int] -&gt; [Int]
forall n a. Integral n =&gt; n -&gt; a -&gt; [a] -&gt; [a]
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#padded"><span class="hs-identifier hs-var">padded</span></a></span><span> </span><span class="annot"><span class="annottext">Integer
</span><a href="#local-6989586621679677523"><span class="hs-identifier hs-var">seqSize</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679677539"><span class="hs-identifier hs-var">padTokenId</span></a></span><span> </span><span class="annot"><span class="annottext">([Int] -&gt; [Int]) -&gt; [[Int]] -&gt; [[Int]]
forall (f :: * -&gt; *) a b. Functor f =&gt; (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;$&gt;</span></span><span> </span><span class="annot"><span class="annottext">[[Int]]
</span><a href="#local-6989586621679677535"><span class="hs-identifier hs-var">xs</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-130"></span><span>
</span><span id="line-131"></span><span class="hs-keyword">type</span><span> </span><span id="MkPosC"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkPosC"><span class="hs-identifier hs-var">MkPosC</span></a></span></span><span> </span><span id="local-6989586621679677520"><span class="annot"><a href="#local-6989586621679677520"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679677519"><span class="annot"><a href="#local-6989586621679677519"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679677518"><span class="annot"><a href="#local-6989586621679677518"><span class="hs-identifier hs-type">seqDim</span></a></span></span><span> </span><span id="local-6989586621679677517"><span class="annot"><a href="#local-6989586621679677517"><span class="hs-identifier hs-type">seqName</span></a></span></span><span> </span><span id="local-6989586621679677516"><span class="annot"><a href="#local-6989586621679677516"><span class="hs-identifier hs-type">seqSize</span></a></span></span><span> </span><span id="local-6989586621679677515"><span class="annot"><a href="#local-6989586621679677515"><span class="hs-identifier hs-type">output</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-132"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetDevice"><span class="hs-identifier hs-type">SGetDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677520"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-133"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetShape"><span class="hs-identifier hs-type">SGetShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677519"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-134"></span><span>    </span><span class="annot"><a href="#local-6989586621679677518"><span class="hs-identifier hs-type">seqDim</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679677519"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#%21"><span class="hs-glyph hs-type">!</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-135"></span><span>    </span><span class="annot"><a href="#local-6989586621679677518"><span class="hs-identifier hs-type">seqDim</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677517"><span class="hs-identifier hs-type">seqName</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677516"><span class="hs-identifier hs-type">seqSize</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-136"></span><span>    </span><span class="annot"><a href="#local-6989586621679677515"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-137"></span><span>      </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-138"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#WithoutGradient"><span class="hs-identifier hs-type">WithoutGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-139"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Dense"><span class="hs-identifier hs-type">Dense</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-140"></span><span>          </span><span class="annot"><a href="#local-6989586621679677520"><span class="hs-identifier hs-type">device</span></a></span><span>
</span><span id="line-141"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#Int64"><span class="hs-identifier hs-type">Int64</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-142"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679677516"><span class="hs-identifier hs-type">seqSize</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-143"></span><span>  </span><span class="hs-special">)</span><span>
</span><span id="line-144"></span><span>
</span><span id="line-145"></span><span class="hs-comment">-- | Computes absolute positions of the input tokens.</span><span>
</span><span id="line-146"></span><span class="hs-comment">-- Given an input tensor of shape @[batchDim, Dim seqName seqSize]@,</span><span>
</span><span id="line-147"></span><span class="hs-comment">-- returns a tensor of shape @[Dim &quot;*&quot; seqSize]@.</span><span>
</span><span id="line-148"></span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#mkPos"><span class="hs-identifier hs-type">mkPos</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-149"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679678037"><span class="annot"><a href="#local-6989586621679678037"><span class="hs-identifier hs-type">m</span></a></span></span><span> </span><span id="local-6989586621679678030"><span class="annot"><a href="#local-6989586621679678030"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679678029"><span class="annot"><a href="#local-6989586621679678029"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679678036"><span class="annot"><a href="#local-6989586621679678036"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679678028"><span class="annot"><a href="#local-6989586621679678028"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679678035"><span class="annot"><a href="#local-6989586621679678035"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679678034"><span class="annot"><a href="#local-6989586621679678034"><span class="hs-identifier hs-type">seqDim</span></a></span></span><span> </span><span id="local-6989586621679678033"><span class="annot"><a href="#local-6989586621679678033"><span class="hs-identifier hs-type">seqName</span></a></span></span><span> </span><span id="local-6989586621679678032"><span class="annot"><a href="#local-6989586621679678032"><span class="hs-identifier hs-type">seqSize</span></a></span></span><span> </span><span id="local-6989586621679678031"><span class="annot"><a href="#local-6989586621679678031"><span class="hs-identifier hs-type">output</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-150"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier hs-type">MonadThrow</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679678037"><span class="hs-identifier hs-type">m</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-151"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkPosC"><span class="hs-identifier hs-type">MkPosC</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679678036"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679678035"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679678034"><span class="hs-identifier hs-type">seqDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679678033"><span class="hs-identifier hs-type">seqName</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679678032"><span class="hs-identifier hs-type">seqSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679678031"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-152"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-153"></span><span>  </span><span class="hs-comment">-- | input tensor</span><span>
</span><span id="line-154"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679678030"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679678029"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679678036"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679678028"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679678035"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-155"></span><span>  </span><span class="hs-comment">-- | positions of the input tokens</span><span>
</span><span id="line-156"></span><span>  </span><span class="annot"><a href="#local-6989586621679678037"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679678031"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-157"></span><span id="mkPos"><span class="annot"><span class="annottext">mkPos :: Tensor gradient layout device dataType shape -&gt; m output
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#mkPos"><span class="hs-identifier hs-var hs-var">mkPos</span></a></span></span><span> </span><span id="local-6989586621679677513"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679677513"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-158"></span><span>  </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679677512"><span class="annot"><span class="annottext">device :: SDevice device
</span><a href="#local-6989586621679677512"><span class="hs-identifier hs-var hs-var">device</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape -&gt; SDevice device
forall (device :: Device (DeviceType Nat))
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SGetDevice device =&gt;
Tensor gradient layout device dataType shape -&gt; SDevice device
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sGetDevice"><span class="hs-identifier hs-var">sGetDevice</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679677513"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-159"></span><span>      </span><span id="local-6989586621679677510"><span class="annot"><span class="annottext">shape :: SShape shape
</span><a href="#local-6989586621679677510"><span class="hs-identifier hs-var hs-var">shape</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape -&gt; SShape shape
forall (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType).
SGetShape shape =&gt;
Tensor gradient layout device dataType shape -&gt; SShape shape
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sGetShape"><span class="hs-identifier hs-var">sGetShape</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679677513"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-160"></span><span>  </span><span id="local-6989586621679677508"><span class="annot"><span class="annottext">SDim ('Dim seqName seqSize)
</span><a href="#local-6989586621679677508"><span class="hs-identifier hs-var">seqDim</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">SSelectDim ('SelectDim ('ByIndex 1))
-&gt; SShape shape -&gt; m (SDim ('Dim seqName seqSize))
forall (selectDim :: SelectDim (By Symbol Nat))
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (dim :: Dim (Name Symbol) (Size Nat)) (m :: * -&gt; *).
(dim ~ GetDimF selectDim shape, MonadThrow m) =&gt;
SSelectDim selectDim -&gt; SShape shape -&gt; m (SDim dim)
</span><a href="Torch.GraduallyTyped.Shape.Class.html#sGetDimFromShape"><span class="hs-identifier hs-var">sGetDimFromShape</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SBy ('ByIndex 1) -&gt; SSelectDim ('SelectDim ('ByIndex 1))
forall (by :: By Symbol Nat). SBy by -&gt; SSelectDim ('SelectDim by)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSelectDim"><span class="hs-identifier hs-var">SSelectDim</span></a></span><span> </span><span class="annot"><span class="annottext">(SBy ('ByIndex 1) -&gt; SSelectDim ('SelectDim ('ByIndex 1)))
-&gt; SBy ('ByIndex 1) -&gt; SSelectDim ('SelectDim ('ByIndex 1))
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">KnownNat 1 =&gt; SBy ('ByIndex 1)
forall (index :: Nat). KnownNat index =&gt; SBy ('ByIndex index)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SByIndex"><span class="hs-identifier hs-var">SByIndex</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">SShape shape
</span><a href="#local-6989586621679677510"><span class="hs-identifier hs-var">shape</span></a></span><span>
</span><span id="line-161"></span><span>  </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679677505"><span class="annot"><span class="annottext">seqSize :: SSize seqSize
</span><a href="#local-6989586621679677505"><span class="hs-identifier hs-var hs-var">seqSize</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SDim ('Dim seqName seqSize) -&gt; SSize seqSize
forall (name :: Name Symbol) (size :: Size Nat).
SDim ('Dim name size) -&gt; SSize size
</span><a href="Torch.GraduallyTyped.Shape.Type.html#sDimSize"><span class="hs-identifier hs-var hs-var">sDimSize</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim seqName seqSize)
</span><a href="#local-6989586621679677508"><span class="hs-identifier hs-var">seqDim</span></a></span><span>
</span><span id="line-162"></span><span>  </span><span class="annot"><span class="annottext">SGradient ('Gradient 'WithoutGradient)
-&gt; SLayout ('Layout 'Dense)
-&gt; SDevice device
-&gt; SDataType ('DataType 'Int64)
-&gt; SSize seqSize
-&gt; m (Tensor
        ('Gradient 'WithoutGradient)
        ('Layout 'Dense)
        device
        ('DataType 'Int64)
        ('Shape '[ 'Dim ('Name &quot;*&quot;) seqSize]))
forall (m :: * -&gt; *) (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType) (size :: Size Nat)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
(MonadThrow m, shape ~ 'Shape '[ 'Dim ('Name &quot;*&quot;) size]) =&gt;
SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SSize size
-&gt; m (Tensor gradient layout device dataType shape)
</span><a href="Torch.GraduallyTyped.Tensor.Creation.html#sArangeNaturals"><span class="hs-identifier hs-var">sArangeNaturals</span></a></span><span>
</span><span id="line-163"></span><span>    </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SRequiresGradient 'WithoutGradient
-&gt; SGradient ('Gradient 'WithoutGradient)
forall (requiresGradient :: RequiresGradient).
SRequiresGradient requiresGradient
-&gt; SGradient ('Gradient requiresGradient)
</span><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier hs-var">SGradient</span></a></span><span> </span><span class="annot"><span class="annottext">SRequiresGradient 'WithoutGradient
</span><a href="Torch.GraduallyTyped.RequiresGradient.html#SWithoutGradient"><span class="hs-identifier hs-var">SWithoutGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-164"></span><span>    </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SLayoutType 'Dense -&gt; SLayout ('Layout 'Dense)
forall (layoutType :: LayoutType).
SLayoutType layoutType -&gt; SLayout ('Layout layoutType)
</span><a href="Torch.GraduallyTyped.Layout.html#SLayout"><span class="hs-identifier hs-var">SLayout</span></a></span><span> </span><span class="annot"><span class="annottext">SLayoutType 'Dense
</span><a href="Torch.GraduallyTyped.Layout.html#SDense"><span class="hs-identifier hs-var">SDense</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-165"></span><span>    </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679677512"><span class="hs-identifier hs-var">device</span></a></span><span>
</span><span id="line-166"></span><span>    </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SDType 'Int64 -&gt; SDataType ('DataType 'Int64)
forall (dType :: DType).
SDType dType -&gt; SDataType ('DataType dType)
</span><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier hs-var">SDataType</span></a></span><span> </span><span class="annot"><span class="annottext">SDType 'Int64
</span><a href="Torch.GraduallyTyped.DType.html#SInt64"><span class="hs-identifier hs-var">SInt64</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-167"></span><span>    </span><span class="annot"><span class="annottext">SSize seqSize
</span><a href="#local-6989586621679677505"><span class="hs-identifier hs-var">seqSize</span></a></span><span>
</span><span id="line-168"></span><span>
</span><span id="line-169"></span><span id="local-6989586621679677501"><span id="local-6989586621679677502"></span></span><span class="hs-keyword">data</span><span> </span><span id="MkAbsPos"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkAbsPos"><span class="hs-identifier hs-var">MkAbsPos</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span id="MkAbsPos"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkAbsPos"><span class="hs-identifier hs-var">MkAbsPos</span></a></span></span><span> </span><span class="hs-glyph">|</span><span> </span><span id="MkAbsPosWithOffset"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkAbsPosWithOffset"><span class="hs-identifier hs-var">MkAbsPosWithOffset</span></a></span></span><span> </span><span class="hs-special">{</span><span id="absPosOffset"><span class="annot"><span class="annottext">MkAbsPos -&gt; Int
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#absPosOffset"><span class="hs-identifier hs-var hs-var">absPosOffset</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">}</span><span>
</span><span id="line-170"></span><span>  </span><span class="hs-keyword">deriving</span><span> </span><span class="annot"><span class="hs-keyword">stock</span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679677494"><span id="local-6989586621679677496"><span class="annot"><span class="annottext">MkAbsPos -&gt; MkAbsPos -&gt; Bool
(MkAbsPos -&gt; MkAbsPos -&gt; Bool)
-&gt; (MkAbsPos -&gt; MkAbsPos -&gt; Bool) -&gt; Eq MkAbsPos
forall a. (a -&gt; a -&gt; Bool) -&gt; (a -&gt; a -&gt; Bool) -&gt; Eq a
/= :: MkAbsPos -&gt; MkAbsPos -&gt; Bool
$c/= :: MkAbsPos -&gt; MkAbsPos -&gt; Bool
== :: MkAbsPos -&gt; MkAbsPos -&gt; Bool
$c== :: MkAbsPos -&gt; MkAbsPos -&gt; Bool
</span><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var">Eq</span></span></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679677479"><span id="local-6989586621679677481"><span id="local-6989586621679677483"><span id="local-6989586621679677485"><span id="local-6989586621679677487"><span id="local-6989586621679677489"><span id="local-6989586621679677491"><span class="annot"><span class="annottext">Eq MkAbsPos
Eq MkAbsPos
-&gt; (MkAbsPos -&gt; MkAbsPos -&gt; Ordering)
-&gt; (MkAbsPos -&gt; MkAbsPos -&gt; Bool)
-&gt; (MkAbsPos -&gt; MkAbsPos -&gt; Bool)
-&gt; (MkAbsPos -&gt; MkAbsPos -&gt; Bool)
-&gt; (MkAbsPos -&gt; MkAbsPos -&gt; Bool)
-&gt; (MkAbsPos -&gt; MkAbsPos -&gt; MkAbsPos)
-&gt; (MkAbsPos -&gt; MkAbsPos -&gt; MkAbsPos)
-&gt; Ord MkAbsPos
MkAbsPos -&gt; MkAbsPos -&gt; Bool
MkAbsPos -&gt; MkAbsPos -&gt; Ordering
MkAbsPos -&gt; MkAbsPos -&gt; MkAbsPos
forall a.
Eq a
-&gt; (a -&gt; a -&gt; Ordering)
-&gt; (a -&gt; a -&gt; Bool)
-&gt; (a -&gt; a -&gt; Bool)
-&gt; (a -&gt; a -&gt; Bool)
-&gt; (a -&gt; a -&gt; Bool)
-&gt; (a -&gt; a -&gt; a)
-&gt; (a -&gt; a -&gt; a)
-&gt; Ord a
min :: MkAbsPos -&gt; MkAbsPos -&gt; MkAbsPos
$cmin :: MkAbsPos -&gt; MkAbsPos -&gt; MkAbsPos
max :: MkAbsPos -&gt; MkAbsPos -&gt; MkAbsPos
$cmax :: MkAbsPos -&gt; MkAbsPos -&gt; MkAbsPos
&gt;= :: MkAbsPos -&gt; MkAbsPos -&gt; Bool
$c&gt;= :: MkAbsPos -&gt; MkAbsPos -&gt; Bool
&gt; :: MkAbsPos -&gt; MkAbsPos -&gt; Bool
$c&gt; :: MkAbsPos -&gt; MkAbsPos -&gt; Bool
&lt;= :: MkAbsPos -&gt; MkAbsPos -&gt; Bool
$c&lt;= :: MkAbsPos -&gt; MkAbsPos -&gt; Bool
&lt; :: MkAbsPos -&gt; MkAbsPos -&gt; Bool
$c&lt; :: MkAbsPos -&gt; MkAbsPos -&gt; Bool
compare :: MkAbsPos -&gt; MkAbsPos -&gt; Ordering
$ccompare :: MkAbsPos -&gt; MkAbsPos -&gt; Ordering
$cp1Ord :: Eq MkAbsPos
</span><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">Ord</span></span></span></span></span></span></span></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679677472"><span id="local-6989586621679677474"><span id="local-6989586621679677476"><span class="annot"><span class="annottext">Int -&gt; MkAbsPos -&gt; ShowS
[MkAbsPos] -&gt; ShowS
MkAbsPos -&gt; String
(Int -&gt; MkAbsPos -&gt; ShowS)
-&gt; (MkAbsPos -&gt; String) -&gt; ([MkAbsPos] -&gt; ShowS) -&gt; Show MkAbsPos
forall a.
(Int -&gt; a -&gt; ShowS) -&gt; (a -&gt; String) -&gt; ([a] -&gt; ShowS) -&gt; Show a
showList :: [MkAbsPos] -&gt; ShowS
$cshowList :: [MkAbsPos] -&gt; ShowS
show :: MkAbsPos -&gt; String
$cshow :: MkAbsPos -&gt; String
showsPrec :: Int -&gt; MkAbsPos -&gt; ShowS
$cshowsPrec :: Int -&gt; MkAbsPos -&gt; ShowS
</span><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">Show</span></span></span></span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">(forall x. MkAbsPos -&gt; Rep MkAbsPos x)
-&gt; (forall x. Rep MkAbsPos x -&gt; MkAbsPos) -&gt; Generic MkAbsPos
forall x. Rep MkAbsPos x -&gt; MkAbsPos
forall x. MkAbsPos -&gt; Rep MkAbsPos x
forall a.
(forall x. a -&gt; Rep a x) -&gt; (forall x. Rep a x -&gt; a) -&gt; Generic a
$cto :: forall x. Rep MkAbsPos x -&gt; MkAbsPos
$cfrom :: forall x. MkAbsPos -&gt; Rep MkAbsPos x
</span><span class="hs-identifier hs-var hs-var hs-var hs-var">Generic</span></span><span class="hs-special">)</span><span>
</span><span id="line-171"></span><span>
</span><span id="line-172"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">instance</span><span> </span><span id="ModelSpec"><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier hs-var">ModelSpec</span></a></span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkAbsPos"><span class="hs-identifier hs-type">MkAbsPos</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkAbsPos"><span class="hs-identifier hs-type">MkAbsPos</span></a></span><span>
</span><span id="line-173"></span><span>
</span><span id="line-174"></span><span id="local-6989586621679677468"><span class="hs-keyword">instance</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkAbsPos"><span class="hs-identifier hs-type">MkAbsPos</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677468"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkAbsPos"><span class="hs-identifier hs-type">MkAbsPos</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677468"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-175"></span><span>  </span><span id="local-6989586621679677465"><span class="annot"><span class="annottext">initialize :: ModelSpec MkAbsPos
-&gt; Generator generatorDevice
-&gt; m (MkAbsPos, Generator generatorDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#initialize"><span class="hs-identifier hs-var hs-var hs-var hs-var">initialize</span></a></span></span><span> </span><span id="local-6989586621679677463"><span class="annot"><span class="annottext">ModelSpec MkAbsPos
</span><a href="#local-6989586621679677463"><span class="hs-identifier hs-var">spec</span></a></span></span><span> </span><span id="local-6989586621679677462"><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679677462"><span class="hs-identifier hs-var">g</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(MkAbsPos, Generator generatorDevice)
-&gt; m (MkAbsPos, Generator generatorDevice)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">ModelSpec MkAbsPos
MkAbsPos
</span><a href="#local-6989586621679677463"><span class="hs-identifier hs-var">spec</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679677462"><span class="hs-identifier hs-var">g</span></a></span><span class="hs-special">)</span></span><span>
</span><span id="line-176"></span><span>
</span><span id="line-177"></span><span class="hs-keyword">instance</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasStateDict"><span class="hs-identifier hs-type">HasStateDict</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkAbsPos"><span class="hs-identifier hs-type">MkAbsPos</span></a></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-178"></span><span>  </span><span id="local-6989586621679677458"><span class="annot"><span class="annottext">fromStateDict :: ModelSpec MkAbsPos -&gt; StateDictKey -&gt; m MkAbsPos
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var hs-var hs-var hs-var">fromStateDict</span></a></span></span><span> </span><span id="local-6989586621679677456"><span class="annot"><span class="annottext">ModelSpec MkAbsPos
</span><a href="#local-6989586621679677456"><span class="hs-identifier hs-var">spec</span></a></span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">MkAbsPos -&gt; m MkAbsPos
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">ModelSpec MkAbsPos
MkAbsPos
</span><a href="#local-6989586621679677456"><span class="hs-identifier hs-var">spec</span></a></span><span>
</span><span id="line-179"></span><span>  </span><span id="local-6989586621679677455"><span class="annot"><span class="annottext">toStateDict :: StateDictKey -&gt; MkAbsPos -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var hs-var hs-var hs-var">toStateDict</span></a></span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="annottext">MkAbsPos
</span><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">() -&gt; m ()
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-180"></span><span>
</span><span id="line-181"></span><span id="local-6989586621679677444"><span id="local-6989586621679677445"><span id="local-6989586621679677446"><span id="local-6989586621679677447"><span id="local-6989586621679677448"><span id="local-6989586621679677449"><span id="local-6989586621679677450"><span id="local-6989586621679677451"><span id="local-6989586621679677452"><span id="local-6989586621679677453"><span class="hs-keyword">instance</span><span>
</span><span id="line-182"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkPosC"><span class="hs-identifier hs-type">MkPosC</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677453"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677452"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677451"><span class="hs-identifier hs-type">seqDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677450"><span class="hs-identifier hs-type">seqName</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677449"><span class="hs-identifier hs-type">seqSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677448"><span class="hs-identifier hs-type">output</span></a></span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-183"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-184"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkAbsPos"><span class="hs-identifier hs-type">MkAbsPos</span></a></span><span>
</span><span id="line-185"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677447"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677446"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677453"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677445"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677452"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-186"></span><span>    </span><span class="annot"><a href="#local-6989586621679677444"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-187"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#WithoutGradient"><span class="hs-identifier hs-type">WithoutGradient</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Dense"><span class="hs-identifier hs-type">Dense</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679677453"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#Int64"><span class="hs-identifier hs-type">Int64</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679677449"><span class="hs-identifier hs-type">seqSize</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-188"></span><span>    </span><span class="annot"><a href="#local-6989586621679677444"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-189"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-190"></span><span>  </span><span id="local-6989586621679677441"><span class="annot"><span class="annottext">forward :: MkAbsPos
-&gt; Tensor gradient layout device dataType shape
-&gt; Generator generatorDevice
-&gt; m (Tensor
        ('Gradient 'WithoutGradient)
        ('Layout 'Dense)
        device
        ('DataType 'Int64)
        ('Shape '[ 'Dim ('Name &quot;*&quot;) seqSize]),
      Generator generatorDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var hs-var hs-var hs-var">forward</span></a></span></span><span> </span><span class="annot"><span class="annottext">MkAbsPos
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkAbsPos"><span class="hs-identifier hs-var">MkAbsPos</span></a></span><span> </span><span id="local-6989586621679677439"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679677439"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span id="local-6989586621679677438"><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679677438"><span class="hs-identifier hs-var">g</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-191"></span><span>    </span><span id="local-6989586621679677437"><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  device
  ('DataType 'Int64)
  ('Shape '[ 'Dim ('Name &quot;*&quot;) seqSize])
</span><a href="#local-6989586621679677437"><span class="hs-identifier hs-var">pos</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
-&gt; m (Tensor
        ('Gradient 'WithoutGradient)
        ('Layout 'Dense)
        device
        ('DataType 'Int64)
        ('Shape '[ 'Dim ('Name &quot;*&quot;) seqSize]))
forall (m :: * -&gt; *) (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (seqDim :: Dim (Name Symbol) (Size Nat)) (seqName :: Name Symbol)
       (seqSize :: Size Nat) output.
(MonadThrow m,
 MkPosC device shape seqDim seqName seqSize output) =&gt;
Tensor gradient layout device dataType shape -&gt; m output
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#mkPos"><span class="hs-identifier hs-var">mkPos</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679677439"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-192"></span><span>    </span><span class="annot"><span class="annottext">(Tensor
   ('Gradient 'WithoutGradient)
   ('Layout 'Dense)
   device
   ('DataType 'Int64)
   ('Shape '[ 'Dim ('Name &quot;*&quot;) seqSize]),
 Generator generatorDevice)
-&gt; m (Tensor
        ('Gradient 'WithoutGradient)
        ('Layout 'Dense)
        device
        ('DataType 'Int64)
        ('Shape '[ 'Dim ('Name &quot;*&quot;) seqSize]),
      Generator generatorDevice)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  device
  ('DataType 'Int64)
  ('Shape '[ 'Dim ('Name &quot;*&quot;) seqSize])
</span><a href="#local-6989586621679677437"><span class="hs-identifier hs-var">pos</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679677438"><span class="hs-identifier hs-var">g</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-193"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkAbsPosWithOffset"><span class="hs-identifier hs-type">MkAbsPosWithOffset</span></a></span><span> </span><span class="hs-special">{</span><span id="local-6989586621679677436"><span class="annot"><span class="annottext">Int
absPosOffset :: Int
absPosOffset :: MkAbsPos -&gt; Int
</span><a href="#local-6989586621679677436"><span class="hs-glyph hs-var hs-var">..</span></a></span></span><span class="hs-special">}</span><span> </span><span id="local-6989586621679677435"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679677435"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span id="local-6989586621679677434"><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679677434"><span class="hs-identifier hs-var">g</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-194"></span><span>    </span><span id="local-6989586621679677433"><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  device
  ('DataType 'Int64)
  ('Shape '[ 'Dim ('Name &quot;*&quot;) seqSize])
</span><a href="#local-6989586621679677433"><span class="hs-identifier hs-var">pos</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
-&gt; m (Tensor
        ('Gradient 'WithoutGradient)
        ('Layout 'Dense)
        device
        ('DataType 'Int64)
        ('Shape '[ 'Dim ('Name &quot;*&quot;) seqSize]))
forall (m :: * -&gt; *) (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (seqDim :: Dim (Name Symbol) (Size Nat)) (seqName :: Name Symbol)
       (seqSize :: Size Nat) output.
(MonadThrow m,
 MkPosC device shape seqDim seqName seqSize output) =&gt;
Tensor gradient layout device dataType shape -&gt; m output
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#mkPos"><span class="hs-identifier hs-var">mkPos</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679677435"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-195"></span><span>    </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679677432"><span class="annot"><span class="annottext">pos' :: Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  device
  ('DataType 'Int64)
  ('Shape '[ 'Dim ('Name &quot;*&quot;) seqSize])
</span><a href="#local-6989586621679677432"><span class="hs-identifier hs-var hs-var">pos'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  device
  ('DataType 'Int64)
  ('Shape '[ 'Dim ('Name &quot;*&quot;) seqSize])
-&gt; Int
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     device
     ('DataType 'Int64)
     ('Shape '[ 'Dim ('Name &quot;*&quot;) seqSize])
forall other (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
Scalar other =&gt;
Tensor gradient layout device dataType shape
-&gt; other -&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#addScalar"><span class="hs-identifier hs-var">addScalar</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  device
  ('DataType 'Int64)
  ('Shape '[ 'Dim ('Name &quot;*&quot;) seqSize])
</span><a href="#local-6989586621679677433"><span class="hs-identifier hs-var">pos</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679677436"><span class="hs-identifier hs-var">absPosOffset</span></a></span><span>
</span><span id="line-196"></span><span>    </span><span class="annot"><span class="annottext">(Tensor
   ('Gradient 'WithoutGradient)
   ('Layout 'Dense)
   device
   ('DataType 'Int64)
   ('Shape '[ 'Dim ('Name &quot;*&quot;) seqSize]),
 Generator generatorDevice)
-&gt; m (Tensor
        ('Gradient 'WithoutGradient)
        ('Layout 'Dense)
        device
        ('DataType 'Int64)
        ('Shape '[ 'Dim ('Name &quot;*&quot;) seqSize]),
      Generator generatorDevice)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  device
  ('DataType 'Int64)
  ('Shape '[ 'Dim ('Name &quot;*&quot;) seqSize])
</span><a href="#local-6989586621679677432"><span class="hs-identifier hs-var">pos'</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679677434"><span class="hs-identifier hs-var">g</span></a></span><span class="hs-special">)</span></span></span></span></span></span></span></span></span></span></span><span>
</span><span id="line-197"></span><span>
</span><span id="line-198"></span><span class="hs-comment">-- | Computes relative positions of the input tokens to the encoder.</span><span>
</span><span id="line-199"></span><span class="hs-comment">--</span><span>
</span><span id="line-200"></span><span class="hs-comment">-- &gt;&gt;&gt; mkRelPos' 32 128 21 17</span><span>
</span><span id="line-201"></span><span class="hs-comment">-- [[0,17,18,19,20,21,22,23,24,24,24,24,25,25,25,25,26],[1,0,17,18,19,20,21,22,23,24,24,24,24,25,25,25,25],[2,1,0,17,18,19,20,21,22,23,24,24,24,24,25,25,25],[3,2,1,0,17,18,19,20,21,22,23,24,24,24,24,25,25],[4,3,2,1,0,17,18,19,20,21,22,23,24,24,24,24,25],[5,4,3,2,1,0,17,18,19,20,21,22,23,24,24,24,24],[6,5,4,3,2,1,0,17,18,19,20,21,22,23,24,24,24],[7,6,5,4,3,2,1,0,17,18,19,20,21,22,23,24,24],[8,7,6,5,4,3,2,1,0,17,18,19,20,21,22,23,24],[8,8,7,6,5,4,3,2,1,0,17,18,19,20,21,22,23],[8,8,8,7,6,5,4,3,2,1,0,17,18,19,20,21,22],[8,8,8,8,7,6,5,4,3,2,1,0,17,18,19,20,21],[9,8,8,8,8,7,6,5,4,3,2,1,0,17,18,19,20],[9,9,8,8,8,8,7,6,5,4,3,2,1,0,17,18,19],[9,9,9,8,8,8,8,7,6,5,4,3,2,1,0,17,18],[9,9,9,9,8,8,8,8,7,6,5,4,3,2,1,0,17],[10,9,9,9,9,8,8,8,8,7,6,5,4,3,2,1,0],[10,10,9,9,9,9,8,8,8,8,7,6,5,4,3,2,1],[10,10,10,9,9,9,9,8,8,8,8,7,6,5,4,3,2],[10,10,10,10,9,9,9,9,8,8,8,8,7,6,5,4,3],[10,10,10,10,10,9,9,9,9,8,8,8,8,7,6,5,4]]</span><span>
</span><span id="line-202"></span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#mkRelPos%27"><span class="hs-identifier hs-type">mkRelPos'</span></a></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">[</span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">]</span><span class="hs-special">]</span><span>
</span><span id="line-203"></span><span id="mkRelPos%27"><span class="annot"><span class="annottext">mkRelPos' :: Int -&gt; Int -&gt; Int -&gt; Int -&gt; [[Int]]
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#mkRelPos%27"><span class="hs-identifier hs-var hs-var">mkRelPos'</span></a></span></span><span> </span><span id="local-6989586621679677430"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679677430"><span class="hs-identifier hs-var">numBuckets</span></a></span></span><span> </span><span id="local-6989586621679677429"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679677429"><span class="hs-identifier hs-var">maxDistance</span></a></span></span><span> </span><span id="local-6989586621679677428"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679677428"><span class="hs-identifier hs-var">querySize</span></a></span></span><span> </span><span id="local-6989586621679677427"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679677427"><span class="hs-identifier hs-var">keySize</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-204"></span><span>  </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679677426"><span class="annot"><span class="annottext">queryPos :: [Int]
</span><a href="#local-6989586621679677426"><span class="hs-identifier hs-var hs-var">queryPos</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">0</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">1</span></span><span> </span><span class="hs-glyph">..</span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679677428"><span class="hs-identifier hs-var">querySize</span></a></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Int
forall a. Num a =&gt; a -&gt; a -&gt; a
</span><span class="hs-glyph hs-var">-</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">1</span></span><span class="hs-special">]</span><span>
</span><span id="line-205"></span><span>      </span><span id="local-6989586621679677425"><span class="annot"><span class="annottext">keyPos :: [Int]
</span><a href="#local-6989586621679677425"><span class="hs-identifier hs-var hs-var">keyPos</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">0</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">1</span></span><span> </span><span class="hs-glyph">..</span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679677427"><span class="hs-identifier hs-var">keySize</span></a></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Int
forall a. Num a =&gt; a -&gt; a -&gt; a
</span><span class="hs-glyph hs-var">-</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">1</span></span><span class="hs-special">]</span><span>
</span><span id="line-206"></span><span>      </span><span id="local-6989586621679677424"><span class="annot"><span class="annottext">numBuckets' :: Int
</span><a href="#local-6989586621679677424"><span class="hs-identifier hs-var hs-var">numBuckets'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679677430"><span class="hs-identifier hs-var">numBuckets</span></a></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Int
forall a. Integral a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">`div`</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">2</span></span><span>
</span><span id="line-207"></span><span>      </span><span id="local-6989586621679677422"><span class="annot"><span class="annottext">maxExact :: Int
</span><a href="#local-6989586621679677422"><span class="hs-identifier hs-var hs-var">maxExact</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679677424"><span class="hs-identifier hs-var">numBuckets'</span></a></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Int
forall a. Integral a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">`div`</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">2</span></span><span>
</span><span id="line-208"></span><span>   </span><span class="hs-keyword">in</span><span> </span><span class="annot"><span class="annottext">(Int -&gt; [Int]) -&gt; [Int] -&gt; [[Int]]
forall (f :: * -&gt; *) a b. Functor f =&gt; (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-identifier hs-var">fmap</span></span><span>
</span><span id="line-209"></span><span>        </span><span class="hs-special">(</span><span> </span><span class="hs-glyph">\</span><span id="local-6989586621679677421"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679677421"><span class="hs-identifier hs-var">qp</span></a></span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-210"></span><span>            </span><span class="annot"><span class="annottext">(Int -&gt; Int) -&gt; [Int] -&gt; [Int]
forall (f :: * -&gt; *) a b. Functor f =&gt; (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-identifier hs-var">fmap</span></span><span>
</span><span id="line-211"></span><span>              </span><span class="hs-special">(</span><span> </span><span class="hs-glyph">\</span><span id="local-6989586621679677420"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679677420"><span class="hs-identifier hs-var">kp</span></a></span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-212"></span><span>                  </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679677419"><span class="annot"><span class="annottext">rawRelPos :: Int
</span><a href="#local-6989586621679677419"><span class="hs-identifier hs-var hs-var">rawRelPos</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679677420"><span class="hs-identifier hs-var">kp</span></a></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Int
forall a. Num a =&gt; a -&gt; a -&gt; a
</span><span class="hs-glyph hs-var">-</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679677421"><span class="hs-identifier hs-var">qp</span></a></span><span>
</span><span id="line-213"></span><span>                      </span><span id="local-6989586621679677418"><span class="annot"><span class="annottext">absRelPos :: Int
</span><a href="#local-6989586621679677418"><span class="hs-identifier hs-var hs-var">absRelPos</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int
forall a. Num a =&gt; a -&gt; a
</span><span class="hs-identifier hs-var">abs</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679677419"><span class="hs-identifier hs-var">rawRelPos</span></a></span><span>
</span><span id="line-214"></span><span>                      </span><span id="local-6989586621679677416"><span class="annot"><span class="annottext">relBucket :: Int
</span><a href="#local-6989586621679677416"><span class="hs-identifier hs-var hs-var">relBucket</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">if</span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679677419"><span class="hs-identifier hs-var">rawRelPos</span></a></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Bool
forall a. Ord a =&gt; a -&gt; a -&gt; Bool
</span><span class="hs-operator hs-var">&gt;</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">0</span></span><span> </span><span class="hs-keyword">then</span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679677424"><span class="hs-identifier hs-var">numBuckets'</span></a></span><span> </span><span class="hs-keyword">else</span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">0</span></span><span>
</span><span id="line-215"></span><span>                      </span><span id="local-6989586621679677414"><span class="annot"><span class="annottext">relBucket' :: Int
</span><a href="#local-6989586621679677414"><span class="hs-identifier hs-var hs-var">relBucket'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-216"></span><span>                        </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679677413"><span class="annot"><span class="annottext">isSmall :: Bool
</span><a href="#local-6989586621679677413"><span class="hs-identifier hs-var hs-var">isSmall</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679677418"><span class="hs-identifier hs-var">absRelPos</span></a></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Bool
forall a. Ord a =&gt; a -&gt; a -&gt; Bool
</span><span class="hs-operator hs-var">&lt;</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679677422"><span class="hs-identifier hs-var">maxExact</span></a></span><span>
</span><span id="line-217"></span><span>                            </span><span id="local-6989586621679677411"><span class="annot"><span class="annottext">relPosIfLarge :: Int
</span><a href="#local-6989586621679677411"><span class="hs-identifier hs-var hs-var">relPosIfLarge</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-218"></span><span>                              </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679677422"><span class="hs-identifier hs-var">maxExact</span></a></span><span>
</span><span id="line-219"></span><span>                                </span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Int
forall a. Num a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">+</span></span><span> </span><span class="annot"><span class="annottext">Double -&gt; Int
</span><span class="hs-identifier hs-var">double2Int</span></span><span>
</span><span id="line-220"></span><span>                                  </span><span class="hs-special">(</span><span> </span><span class="annot"><span class="annottext">Double -&gt; Double -&gt; Double
forall a. Floating a =&gt; a -&gt; a -&gt; a
</span><span class="hs-identifier hs-var">logBase</span></span><span>
</span><span id="line-221"></span><span>                                      </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Int -&gt; Double
forall a b. (Integral a, Num b) =&gt; a -&gt; b
</span><span class="hs-identifier hs-var">fromIntegral</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679677429"><span class="hs-identifier hs-var">maxDistance</span></a></span><span> </span><span class="annot"><span class="annottext">Double -&gt; Double -&gt; Double
forall a. Fractional a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">/</span></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Double
forall a b. (Integral a, Num b) =&gt; a -&gt; b
</span><span class="hs-identifier hs-var">fromIntegral</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679677422"><span class="hs-identifier hs-var">maxExact</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-222"></span><span>                                      </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Int -&gt; Double
forall a b. (Integral a, Num b) =&gt; a -&gt; b
</span><span class="hs-identifier hs-var">fromIntegral</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679677418"><span class="hs-identifier hs-var">absRelPos</span></a></span><span> </span><span class="annot"><span class="annottext">Double -&gt; Double -&gt; Double
forall a. Fractional a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">/</span></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Double
forall a b. (Integral a, Num b) =&gt; a -&gt; b
</span><span class="hs-identifier hs-var">fromIntegral</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679677422"><span class="hs-identifier hs-var">maxExact</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-223"></span><span>                                      </span><span class="annot"><span class="annottext">Double -&gt; Double -&gt; Double
forall a. Num a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">*</span></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Double
forall a b. (Integral a, Num b) =&gt; a -&gt; b
</span><span class="hs-identifier hs-var">fromIntegral</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679677424"><span class="hs-identifier hs-var">numBuckets'</span></a></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Int
forall a. Num a =&gt; a -&gt; a -&gt; a
</span><span class="hs-glyph hs-var">-</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679677422"><span class="hs-identifier hs-var">maxExact</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-224"></span><span>                                  </span><span class="hs-special">)</span><span>
</span><span id="line-225"></span><span>                            </span><span id="local-6989586621679677406"><span class="annot"><span class="annottext">relPosIfLarge' :: Int
</span><a href="#local-6989586621679677406"><span class="hs-identifier hs-var hs-var">relPosIfLarge'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Int
forall a. Ord a =&gt; a -&gt; a -&gt; a
</span><span class="hs-identifier hs-var">min</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679677411"><span class="hs-identifier hs-var">relPosIfLarge</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679677424"><span class="hs-identifier hs-var">numBuckets'</span></a></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Int
forall a. Num a =&gt; a -&gt; a -&gt; a
</span><span class="hs-glyph hs-var">-</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">1</span></span><span class="hs-special">)</span><span>
</span><span id="line-226"></span><span>                         </span><span class="hs-keyword">in</span><span> </span><span class="hs-keyword">if</span><span> </span><span class="annot"><span class="annottext">Bool
</span><a href="#local-6989586621679677413"><span class="hs-identifier hs-var">isSmall</span></a></span><span> </span><span class="hs-keyword">then</span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679677418"><span class="hs-identifier hs-var">absRelPos</span></a></span><span> </span><span class="hs-keyword">else</span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679677406"><span class="hs-identifier hs-var">relPosIfLarge'</span></a></span><span>
</span><span id="line-227"></span><span>                   </span><span class="hs-keyword">in</span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679677416"><span class="hs-identifier hs-var">relBucket</span></a></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Int
forall a. Num a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">+</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679677414"><span class="hs-identifier hs-var">relBucket'</span></a></span><span>
</span><span id="line-228"></span><span>              </span><span class="hs-special">)</span><span>
</span><span id="line-229"></span><span>              </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679677425"><span class="hs-identifier hs-var">keyPos</span></a></span><span>
</span><span id="line-230"></span><span>        </span><span class="hs-special">)</span><span>
</span><span id="line-231"></span><span>        </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679677426"><span class="hs-identifier hs-var">queryPos</span></a></span><span>
</span><span id="line-232"></span><span>
</span><span id="line-233"></span><span class="hs-keyword">type</span><span> </span><span id="MkRelPosC"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkRelPosC"><span class="hs-identifier hs-var">MkRelPosC</span></a></span></span><span> </span><span id="local-6989586621679677404"><span class="annot"><a href="#local-6989586621679677404"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679677403"><span class="annot"><a href="#local-6989586621679677403"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679677402"><span class="annot"><a href="#local-6989586621679677402"><span class="hs-identifier hs-type">seqDim</span></a></span></span><span> </span><span id="local-6989586621679677401"><span class="annot"><a href="#local-6989586621679677401"><span class="hs-identifier hs-type">seqName</span></a></span></span><span> </span><span id="local-6989586621679677400"><span class="annot"><a href="#local-6989586621679677400"><span class="hs-identifier hs-type">seqSize</span></a></span></span><span> </span><span id="local-6989586621679677399"><span class="annot"><a href="#local-6989586621679677399"><span class="hs-identifier hs-type">output</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-234"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetDevice"><span class="hs-identifier hs-type">SGetDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677404"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-235"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetShape"><span class="hs-identifier hs-type">SGetShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677403"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-236"></span><span>    </span><span class="annot"><a href="#local-6989586621679677402"><span class="hs-identifier hs-type">seqDim</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679677403"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#%21"><span class="hs-glyph hs-type">!</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-237"></span><span>    </span><span class="annot"><a href="#local-6989586621679677402"><span class="hs-identifier hs-type">seqDim</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677401"><span class="hs-identifier hs-type">seqName</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677400"><span class="hs-identifier hs-type">seqSize</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-238"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Catch"><span class="hs-identifier hs-type">Catch</span></a></span><span>
</span><span id="line-239"></span><span>      </span><span class="hs-special">(</span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#UncheckedSize"><span class="hs-identifier hs-type">UncheckedSize</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-240"></span><span>           </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#UncheckedSize"><span class="hs-identifier hs-type">UncheckedSize</span></a></span><span>
</span><span id="line-241"></span><span>         </span><span class="hs-special">]</span><span>
</span><span id="line-242"></span><span>          </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679677400"><span class="hs-identifier hs-type">seqSize</span></a></span><span class="hs-special">,</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679677400"><span class="hs-identifier hs-type">seqSize</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-243"></span><span>      </span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-244"></span><span>    </span><span class="annot"><a href="#local-6989586621679677399"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-245"></span><span>      </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-246"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#WithoutGradient"><span class="hs-identifier hs-type">WithoutGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-247"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Dense"><span class="hs-identifier hs-type">Dense</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-248"></span><span>          </span><span class="annot"><a href="#local-6989586621679677404"><span class="hs-identifier hs-type">device</span></a></span><span>
</span><span id="line-249"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#Int64"><span class="hs-identifier hs-type">Int64</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-250"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679677400"><span class="hs-identifier hs-type">seqSize</span></a></span><span class="hs-special">,</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679677400"><span class="hs-identifier hs-type">seqSize</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-251"></span><span>  </span><span class="hs-special">)</span><span>
</span><span id="line-252"></span><span>
</span><span id="line-253"></span><span class="hs-comment">-- | Computes relative positions of the input tokens to the encoder.</span><span>
</span><span id="line-254"></span><span class="hs-comment">-- Given an input tensor of shape @[batchDim, Dim seqName seqSize]@,</span><span>
</span><span id="line-255"></span><span class="hs-comment">-- returns a tensor of shape @[1, Dim &quot;*&quot; seqSize, Dim &quot;*&quot; seqSize]@.</span><span>
</span><span id="line-256"></span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#mkRelPos"><span class="hs-identifier hs-type">mkRelPos</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-257"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679677959"><span class="annot"><a href="#local-6989586621679677959"><span class="hs-identifier hs-type">m</span></a></span></span><span> </span><span id="local-6989586621679677951"><span class="annot"><a href="#local-6989586621679677951"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679677950"><span class="annot"><a href="#local-6989586621679677950"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679677958"><span class="annot"><a href="#local-6989586621679677958"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679677949"><span class="annot"><a href="#local-6989586621679677949"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679677957"><span class="annot"><a href="#local-6989586621679677957"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679677952"><span class="annot"><a href="#local-6989586621679677952"><span class="hs-identifier hs-type">relPosEncBucketDim</span></a></span></span><span> </span><span id="local-6989586621679677956"><span class="annot"><a href="#local-6989586621679677956"><span class="hs-identifier hs-type">seqDim</span></a></span></span><span> </span><span id="local-6989586621679677955"><span class="annot"><a href="#local-6989586621679677955"><span class="hs-identifier hs-type">seqName</span></a></span></span><span> </span><span id="local-6989586621679677954"><span class="annot"><a href="#local-6989586621679677954"><span class="hs-identifier hs-type">seqSize</span></a></span></span><span> </span><span id="local-6989586621679677953"><span class="annot"><a href="#local-6989586621679677953"><span class="hs-identifier hs-type">output</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-258"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier hs-type">MonadThrow</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677959"><span class="hs-identifier hs-type">m</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-259"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkRelPosC"><span class="hs-identifier hs-type">MkRelPosC</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677958"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677957"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677956"><span class="hs-identifier hs-type">seqDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677955"><span class="hs-identifier hs-type">seqName</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677954"><span class="hs-identifier hs-type">seqSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677953"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-260"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-261"></span><span>  </span><span class="hs-comment">-- | bucket dimension</span><span>
</span><span id="line-262"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677952"><span class="hs-identifier hs-type">relPosEncBucketDim</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-263"></span><span>  </span><span class="hs-comment">-- | maximum distance</span><span>
</span><span id="line-264"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-265"></span><span>  </span><span class="hs-comment">-- | input tensor</span><span>
</span><span id="line-266"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677951"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677950"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677958"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677949"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677957"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-267"></span><span>  </span><span class="hs-comment">-- | relative positions of the input tokens</span><span>
</span><span id="line-268"></span><span>  </span><span class="annot"><a href="#local-6989586621679677959"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677953"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-269"></span><span id="mkRelPos"><span class="annot"><span class="annottext">mkRelPos :: SDim relPosEncBucketDim
-&gt; Int -&gt; Tensor gradient layout device dataType shape -&gt; m output
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#mkRelPos"><span class="hs-identifier hs-var hs-var">mkRelPos</span></a></span></span><span> </span><span id="local-6989586621679677397"><span class="annot"><span class="annottext">SDim relPosEncBucketDim
</span><a href="#local-6989586621679677397"><span class="hs-identifier hs-var">relPosEncBucketDim</span></a></span></span><span> </span><span id="local-6989586621679677396"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679677396"><span class="hs-identifier hs-var">maxDistance</span></a></span></span><span> </span><span id="local-6989586621679677395"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679677395"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-270"></span><span>  </span><span id="local-6989586621679677394"><span class="annot"><span class="annottext">SDim ('Dim seqName seqSize)
</span><a href="#local-6989586621679677394"><span class="hs-identifier hs-var">seqDim</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">SSelectDim ('SelectDim ('ByIndex 1))
-&gt; SShape shape -&gt; m (SDim ('Dim seqName seqSize))
forall (selectDim :: SelectDim (By Symbol Nat))
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (dim :: Dim (Name Symbol) (Size Nat)) (m :: * -&gt; *).
(dim ~ GetDimF selectDim shape, MonadThrow m) =&gt;
SSelectDim selectDim -&gt; SShape shape -&gt; m (SDim dim)
</span><a href="Torch.GraduallyTyped.Shape.Class.html#sGetDimFromShape"><span class="hs-identifier hs-var">sGetDimFromShape</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SBy ('ByIndex 1) -&gt; SSelectDim ('SelectDim ('ByIndex 1))
forall (by :: By Symbol Nat). SBy by -&gt; SSelectDim ('SelectDim by)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSelectDim"><span class="hs-identifier hs-var">SSelectDim</span></a></span><span> </span><span class="annot"><span class="annottext">(SBy ('ByIndex 1) -&gt; SSelectDim ('SelectDim ('ByIndex 1)))
-&gt; SBy ('ByIndex 1) -&gt; SSelectDim ('SelectDim ('ByIndex 1))
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">KnownNat 1 =&gt; SBy ('ByIndex 1)
forall (index :: Nat). KnownNat index =&gt; SBy ('ByIndex index)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SByIndex"><span class="hs-identifier hs-var">SByIndex</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">(SShape shape -&gt; m (SDim ('Dim seqName seqSize)))
-&gt; SShape shape -&gt; m (SDim ('Dim seqName seqSize))
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape -&gt; SShape shape
forall (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType).
SGetShape shape =&gt;
Tensor gradient layout device dataType shape -&gt; SShape shape
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sGetShape"><span class="hs-identifier hs-var">sGetShape</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679677395"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-271"></span><span>  </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679677393"><span class="annot"><span class="annottext">seqSize :: Int
</span><a href="#local-6989586621679677393"><span class="hs-identifier hs-var hs-var">seqSize</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Integer -&gt; Int
forall a. Num a =&gt; Integer -&gt; a
</span><span class="hs-identifier hs-var">fromInteger</span></span><span> </span><span class="annot"><span class="annottext">(Integer -&gt; Int)
-&gt; (SSize seqSize -&gt; Integer) -&gt; SSize seqSize -&gt; Int
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">IsChecked Integer -&gt; Integer
forall a. IsChecked a -&gt; a
</span><a href="Torch.GraduallyTyped.Prelude.html#forgetIsChecked"><span class="hs-identifier hs-var">forgetIsChecked</span></a></span><span> </span><span class="annot"><span class="annottext">(IsChecked Integer -&gt; Integer)
-&gt; (SSize seqSize -&gt; IsChecked Integer) -&gt; SSize seqSize -&gt; Integer
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">SSize seqSize -&gt; IsChecked Integer
forall k (a :: k). SingKind k =&gt; Sing a -&gt; Demote k
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">fromSing</span></a></span><span> </span><span class="annot"><span class="annottext">(SSize seqSize -&gt; Int) -&gt; SSize seqSize -&gt; Int
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim seqName seqSize) -&gt; SSize seqSize
forall (name :: Name Symbol) (size :: Size Nat).
SDim ('Dim name size) -&gt; SSize size
</span><a href="Torch.GraduallyTyped.Shape.Type.html#sDimSize"><span class="hs-identifier hs-var hs-var">sDimSize</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim seqName seqSize)
</span><a href="#local-6989586621679677394"><span class="hs-identifier hs-var">seqDim</span></a></span><span>
</span><span id="line-272"></span><span>  </span><span class="annot"><span class="annottext">SGradient ('Gradient 'WithoutGradient)
-&gt; SLayout ('Layout 'Dense)
-&gt; SDevice device
-&gt; [[[Int]]]
-&gt; m (Tensor
        ('Gradient 'WithoutGradient)
        ('Layout 'Dense)
        device
        ('DataType 'Int64)
        ('Shape
           '[ 'Dim ('Name &quot;*&quot;) 'UncheckedSize,
              'Dim ('Name &quot;*&quot;) 'UncheckedSize, 'Dim ('Name &quot;*&quot;) 'UncheckedSize]))
forall a (dType :: DType) (dims :: [Dim (Name Symbol) (Size Nat)])
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (m :: * -&gt; *).
(TensorLike a dType dims, MonadThrow m) =&gt;
SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; a
-&gt; m (Tensor
        gradient layout device ('DataType dType) ('Shape dims))
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sToTensor"><span class="hs-identifier hs-var">sToTensor</span></a></span><span> </span><span class="annot"><span class="annottext">SGradient ('Gradient 'WithoutGradient)
</span><a href="#local-6989586621679677392"><span class="hs-identifier hs-var">gradient'</span></a></span><span> </span><span class="annot"><span class="annottext">SLayout ('Layout 'Dense)
</span><a href="#local-6989586621679677391"><span class="hs-identifier hs-var">layout'</span></a></span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679677390"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="hs-special">[</span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Int -&gt; Int -&gt; [[Int]]
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#mkRelPos%27"><span class="hs-identifier hs-var">mkRelPos'</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679677389"><span class="hs-identifier hs-var">relPosEncBucketSize</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679677396"><span class="hs-identifier hs-var">maxDistance</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679677393"><span class="hs-identifier hs-var">seqSize</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679677393"><span class="hs-identifier hs-var">seqSize</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-273"></span><span>    </span><span class="annot"><span class="annottext">m (Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     device
     ('DataType 'Int64)
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) 'UncheckedSize,
           'Dim ('Name &quot;*&quot;) 'UncheckedSize, 'Dim ('Name &quot;*&quot;) 'UncheckedSize]))
-&gt; (Tensor
      ('Gradient 'WithoutGradient)
      ('Layout 'Dense)
      device
      ('DataType 'Int64)
      ('Shape
         '[ 'Dim ('Name &quot;*&quot;) 'UncheckedSize,
            'Dim ('Name &quot;*&quot;) 'UncheckedSize, 'Dim ('Name &quot;*&quot;) 'UncheckedSize])
    -&gt; m (Tensor
            ('Gradient 'WithoutGradient)
            ('Layout 'Dense)
            device
            ('DataType 'Int64)
            ('Shape
               '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) seqSize,
                  'Dim ('Name &quot;*&quot;) seqSize])))
-&gt; m (Tensor
        ('Gradient 'WithoutGradient)
        ('Layout 'Dense)
        device
        ('DataType 'Int64)
        ('Shape
           '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) seqSize,
              'Dim ('Name &quot;*&quot;) seqSize]))
forall (m :: * -&gt; *) a b. Monad m =&gt; m a -&gt; (a -&gt; m b) -&gt; m b
</span><span class="hs-operator hs-var">&gt;&gt;=</span></span><span> </span><span class="annot"><span class="annottext">SShape
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) seqSize,
        'Dim ('Name &quot;*&quot;) seqSize])
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     device
     ('DataType 'Int64)
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) 'UncheckedSize,
           'Dim ('Name &quot;*&quot;) 'UncheckedSize, 'Dim ('Name &quot;*&quot;) 'UncheckedSize])
-&gt; m (Tensor
        ('Gradient 'WithoutGradient)
        ('Layout 'Dense)
        device
        ('DataType 'Int64)
        ('Shape
           '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) seqSize,
              'Dim ('Name &quot;*&quot;) seqSize]))
forall (shape' :: Shape [Dim (Name Symbol) (Size Nat)])
       (m :: * -&gt; *) (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
(SGetShape shape, MonadThrow m, Catch (shape &lt;+&gt; shape')) =&gt;
SShape shape'
-&gt; Tensor gradient layout device dataType shape
-&gt; m (Tensor gradient layout device dataType shape')
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sCheckedShape"><span class="hs-identifier hs-var">sCheckedShape</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SList
  '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) seqSize,
     'Dim ('Name &quot;*&quot;) seqSize]
-&gt; SShape
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) seqSize,
           'Dim ('Name &quot;*&quot;) seqSize])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList
   '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) seqSize,
      'Dim ('Name &quot;*&quot;) seqSize]
 -&gt; SShape
      ('Shape
         '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) seqSize,
            'Dim ('Name &quot;*&quot;) seqSize]))
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) seqSize,
        'Dim ('Name &quot;*&quot;) seqSize]
-&gt; SShape
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) seqSize,
           'Dim ('Name &quot;*&quot;) seqSize])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize ('Size 1) -&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 1))
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownNat 1 =&gt; SSize ('Size 1)
forall (size :: Nat). KnownNat size =&gt; SSize ('Size size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier hs-var">SSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">1</span></span><span> </span><span class="annot"><span class="annottext">Sing ('Dim ('Name &quot;*&quot;) ('Size 1))
-&gt; SList '[ 'Dim ('Name &quot;*&quot;) seqSize, 'Dim ('Name &quot;*&quot;) seqSize]
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) seqSize,
        'Dim ('Name &quot;*&quot;) seqSize]
forall a1 (a2 :: a1) (as :: [a1]).
Sing a2 -&gt; SList as -&gt; SList (a2 : as)
</span><a href="Torch.GraduallyTyped.Prelude.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize seqSize -&gt; SDim ('Dim ('Name &quot;*&quot;) seqSize)
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim seqName seqSize) -&gt; SSize seqSize
forall (name :: Name Symbol) (size :: Size Nat).
SDim ('Dim name size) -&gt; SSize size
</span><a href="Torch.GraduallyTyped.Shape.Type.html#sDimSize"><span class="hs-identifier hs-var hs-var">sDimSize</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim seqName seqSize)
</span><a href="#local-6989586621679677394"><span class="hs-identifier hs-var">seqDim</span></a></span><span> </span><span class="annot"><span class="annottext">Sing ('Dim ('Name &quot;*&quot;) seqSize)
-&gt; SList '[ 'Dim ('Name &quot;*&quot;) seqSize]
-&gt; SList '[ 'Dim ('Name &quot;*&quot;) seqSize, 'Dim ('Name &quot;*&quot;) seqSize]
forall a1 (a2 :: a1) (as :: [a1]).
Sing a2 -&gt; SList as -&gt; SList (a2 : as)
</span><a href="Torch.GraduallyTyped.Prelude.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize seqSize -&gt; SDim ('Dim ('Name &quot;*&quot;) seqSize)
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim seqName seqSize) -&gt; SSize seqSize
forall (name :: Name Symbol) (size :: Size Nat).
SDim ('Dim name size) -&gt; SSize size
</span><a href="Torch.GraduallyTyped.Shape.Type.html#sDimSize"><span class="hs-identifier hs-var hs-var">sDimSize</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim seqName seqSize)
</span><a href="#local-6989586621679677394"><span class="hs-identifier hs-var">seqDim</span></a></span><span> </span><span class="annot"><span class="annottext">Sing ('Dim ('Name &quot;*&quot;) seqSize)
-&gt; SList '[] -&gt; SList '[ 'Dim ('Name &quot;*&quot;) seqSize]
forall a1 (a2 :: a1) (as :: [a1]).
Sing a2 -&gt; SList as -&gt; SList (a2 : as)
</span><a href="Torch.GraduallyTyped.Prelude.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-274"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-275"></span><span>    </span><span id="local-6989586621679677392"><span class="annot"><span class="annottext">gradient' :: SGradient ('Gradient 'WithoutGradient)
</span><a href="#local-6989586621679677392"><span class="hs-identifier hs-var hs-var">gradient'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SRequiresGradient 'WithoutGradient
-&gt; SGradient ('Gradient 'WithoutGradient)
forall (requiresGradient :: RequiresGradient).
SRequiresGradient requiresGradient
-&gt; SGradient ('Gradient requiresGradient)
</span><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier hs-var">SGradient</span></a></span><span> </span><span class="annot"><span class="annottext">SRequiresGradient 'WithoutGradient
</span><a href="Torch.GraduallyTyped.RequiresGradient.html#SWithoutGradient"><span class="hs-identifier hs-var">SWithoutGradient</span></a></span><span>
</span><span id="line-276"></span><span>    </span><span id="local-6989586621679677391"><span class="annot"><span class="annottext">layout' :: SLayout ('Layout 'Dense)
</span><a href="#local-6989586621679677391"><span class="hs-identifier hs-var hs-var">layout'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SLayoutType 'Dense -&gt; SLayout ('Layout 'Dense)
forall (layoutType :: LayoutType).
SLayoutType layoutType -&gt; SLayout ('Layout layoutType)
</span><a href="Torch.GraduallyTyped.Layout.html#SLayout"><span class="hs-identifier hs-var">SLayout</span></a></span><span> </span><span class="annot"><span class="annottext">SLayoutType 'Dense
</span><a href="Torch.GraduallyTyped.Layout.html#SDense"><span class="hs-identifier hs-var">SDense</span></a></span><span>
</span><span id="line-277"></span><span>    </span><span id="local-6989586621679677390"><span class="annot"><span class="annottext">device :: SDevice device
</span><a href="#local-6989586621679677390"><span class="hs-identifier hs-var hs-var">device</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape -&gt; SDevice device
forall (device :: Device (DeviceType Nat))
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SGetDevice device =&gt;
Tensor gradient layout device dataType shape -&gt; SDevice device
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sGetDevice"><span class="hs-identifier hs-var">sGetDevice</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679677395"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-278"></span><span>    </span><span id="local-6989586621679677389"><span class="annot"><span class="annottext">relPosEncBucketSize :: Int
</span><a href="#local-6989586621679677389"><span class="hs-identifier hs-var hs-var">relPosEncBucketSize</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Integer -&gt; Int
forall a. Num a =&gt; Integer -&gt; a
</span><span class="hs-identifier hs-var">fromInteger</span></span><span> </span><span class="annot"><span class="annottext">(Integer -&gt; Int)
-&gt; (SDim relPosEncBucketDim -&gt; Integer)
-&gt; SDim relPosEncBucketDim
-&gt; Int
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">IsChecked Integer -&gt; Integer
forall a. IsChecked a -&gt; a
</span><a href="Torch.GraduallyTyped.Prelude.html#forgetIsChecked"><span class="hs-identifier hs-var">forgetIsChecked</span></a></span><span> </span><span class="annot"><span class="annottext">(IsChecked Integer -&gt; Integer)
-&gt; (SDim relPosEncBucketDim -&gt; IsChecked Integer)
-&gt; SDim relPosEncBucketDim
-&gt; Integer
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Dim (IsChecked String) (IsChecked Integer) -&gt; IsChecked Integer
forall name size. Dim name size -&gt; size
</span><a href="Torch.GraduallyTyped.Shape.Type.html#dimSize"><span class="hs-identifier hs-var hs-var">dimSize</span></a></span><span> </span><span class="annot"><span class="annottext">(Dim (IsChecked String) (IsChecked Integer) -&gt; IsChecked Integer)
-&gt; (SDim relPosEncBucketDim
    -&gt; Dim (IsChecked String) (IsChecked Integer))
-&gt; SDim relPosEncBucketDim
-&gt; IsChecked Integer
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">SDim relPosEncBucketDim
-&gt; Dim (IsChecked String) (IsChecked Integer)
forall k (a :: k). SingKind k =&gt; Sing a -&gt; Demote k
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">fromSing</span></a></span><span> </span><span class="annot"><span class="annottext">(SDim relPosEncBucketDim -&gt; Int) -&gt; SDim relPosEncBucketDim -&gt; Int
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SDim relPosEncBucketDim
</span><a href="#local-6989586621679677397"><span class="hs-identifier hs-var">relPosEncBucketDim</span></a></span><span>
</span><span id="line-279"></span><span>
</span><span id="line-280"></span><span class="hs-comment">-- | Computes relative positions of the input tokens to the decoder.</span><span>
</span><span id="line-281"></span><span class="hs-comment">--</span><span>
</span><span id="line-282"></span><span class="hs-comment">-- &gt;&gt;&gt; mkDecoderRelPos' 32 128 21 17</span><span>
</span><span id="line-283"></span><span class="hs-comment">-- [[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[2,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[3,2,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[4,3,2,1,0,0,0,0,0,0,0,0,0,0,0,0,0],[5,4,3,2,1,0,0,0,0,0,0,0,0,0,0,0,0],[6,5,4,3,2,1,0,0,0,0,0,0,0,0,0,0,0],[7,6,5,4,3,2,1,0,0,0,0,0,0,0,0,0,0],[8,7,6,5,4,3,2,1,0,0,0,0,0,0,0,0,0],[9,8,7,6,5,4,3,2,1,0,0,0,0,0,0,0,0],[10,9,8,7,6,5,4,3,2,1,0,0,0,0,0,0,0],[11,10,9,8,7,6,5,4,3,2,1,0,0,0,0,0,0],[12,11,10,9,8,7,6,5,4,3,2,1,0,0,0,0,0],[13,12,11,10,9,8,7,6,5,4,3,2,1,0,0,0,0],[14,13,12,11,10,9,8,7,6,5,4,3,2,1,0,0,0],[15,14,13,12,11,10,9,8,7,6,5,4,3,2,1,0,0],[16,15,14,13,12,11,10,9,8,7,6,5,4,3,2,1,0],[16,16,15,14,13,12,11,10,9,8,7,6,5,4,3,2,1],[16,16,16,15,14,13,12,11,10,9,8,7,6,5,4,3,2],[17,16,16,16,15,14,13,12,11,10,9,8,7,6,5,4,3],[17,17,16,16,16,15,14,13,12,11,10,9,8,7,6,5,4]]</span><span>
</span><span id="line-284"></span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#mkDecoderRelPos%27"><span class="hs-identifier hs-type">mkDecoderRelPos'</span></a></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">[</span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">]</span><span class="hs-special">]</span><span>
</span><span id="line-285"></span><span id="mkDecoderRelPos%27"><span class="annot"><span class="annottext">mkDecoderRelPos' :: Int -&gt; Int -&gt; Int -&gt; Int -&gt; [[Int]]
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#mkDecoderRelPos%27"><span class="hs-identifier hs-var hs-var">mkDecoderRelPos'</span></a></span></span><span> </span><span id="local-6989586621679677385"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679677385"><span class="hs-identifier hs-var">numBuckets</span></a></span></span><span> </span><span id="local-6989586621679677384"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679677384"><span class="hs-identifier hs-var">maxDistance</span></a></span></span><span> </span><span id="local-6989586621679677383"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679677383"><span class="hs-identifier hs-var">querySize</span></a></span></span><span> </span><span id="local-6989586621679677382"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679677382"><span class="hs-identifier hs-var">keySize</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-286"></span><span>  </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679677381"><span class="annot"><span class="annottext">queryPos :: [Int]
</span><a href="#local-6989586621679677381"><span class="hs-identifier hs-var hs-var">queryPos</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">0</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">1</span></span><span> </span><span class="hs-glyph">..</span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679677383"><span class="hs-identifier hs-var">querySize</span></a></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Int
forall a. Num a =&gt; a -&gt; a -&gt; a
</span><span class="hs-glyph hs-var">-</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">1</span></span><span class="hs-special">]</span><span>
</span><span id="line-287"></span><span>      </span><span id="local-6989586621679677380"><span class="annot"><span class="annottext">keyPos :: [Int]
</span><a href="#local-6989586621679677380"><span class="hs-identifier hs-var hs-var">keyPos</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">0</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">1</span></span><span> </span><span class="hs-glyph">..</span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679677382"><span class="hs-identifier hs-var">keySize</span></a></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Int
forall a. Num a =&gt; a -&gt; a -&gt; a
</span><span class="hs-glyph hs-var">-</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">1</span></span><span class="hs-special">]</span><span>
</span><span id="line-288"></span><span>      </span><span id="local-6989586621679677379"><span class="annot"><span class="annottext">maxExact :: Int
</span><a href="#local-6989586621679677379"><span class="hs-identifier hs-var hs-var">maxExact</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679677385"><span class="hs-identifier hs-var">numBuckets</span></a></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Int
forall a. Integral a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">`div`</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">2</span></span><span>
</span><span id="line-289"></span><span>   </span><span class="hs-keyword">in</span><span> </span><span class="annot"><span class="annottext">(Int -&gt; [Int]) -&gt; [Int] -&gt; [[Int]]
forall (f :: * -&gt; *) a b. Functor f =&gt; (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-identifier hs-var">fmap</span></span><span>
</span><span id="line-290"></span><span>        </span><span class="hs-special">(</span><span> </span><span class="hs-glyph">\</span><span id="local-6989586621679677378"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679677378"><span class="hs-identifier hs-var">qp</span></a></span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-291"></span><span>            </span><span class="annot"><span class="annottext">(Int -&gt; Int) -&gt; [Int] -&gt; [Int]
forall (f :: * -&gt; *) a b. Functor f =&gt; (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-identifier hs-var">fmap</span></span><span>
</span><span id="line-292"></span><span>              </span><span class="hs-special">(</span><span> </span><span class="hs-glyph">\</span><span id="local-6989586621679677377"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679677377"><span class="hs-identifier hs-var">kp</span></a></span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-293"></span><span>                  </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679677376"><span class="annot"><span class="annottext">rawRelPos :: Int
</span><a href="#local-6989586621679677376"><span class="hs-identifier hs-var hs-var">rawRelPos</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679677377"><span class="hs-identifier hs-var">kp</span></a></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Int
forall a. Num a =&gt; a -&gt; a -&gt; a
</span><span class="hs-glyph hs-var">-</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679677378"><span class="hs-identifier hs-var">qp</span></a></span><span>
</span><span id="line-294"></span><span>                      </span><span id="local-6989586621679677375"><span class="annot"><span class="annottext">absRelPos :: Int
</span><a href="#local-6989586621679677375"><span class="hs-identifier hs-var hs-var">absRelPos</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int
forall a. Num a =&gt; a -&gt; a
</span><span class="hs-identifier hs-var">negate</span></span><span> </span><span class="annot"><span class="annottext">(Int -&gt; Int) -&gt; (Int -&gt; Int) -&gt; Int -&gt; Int
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Int
forall a. Ord a =&gt; a -&gt; a -&gt; a
</span><span class="hs-identifier hs-var">min</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">0</span></span><span> </span><span class="annot"><span class="annottext">(Int -&gt; Int) -&gt; Int -&gt; Int
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679677376"><span class="hs-identifier hs-var">rawRelPos</span></a></span><span>
</span><span id="line-295"></span><span>                      </span><span id="local-6989586621679677374"><span class="annot"><span class="annottext">relBucket' :: Int
</span><a href="#local-6989586621679677374"><span class="hs-identifier hs-var hs-var">relBucket'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-296"></span><span>                        </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679677373"><span class="annot"><span class="annottext">isSmall :: Bool
</span><a href="#local-6989586621679677373"><span class="hs-identifier hs-var hs-var">isSmall</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679677375"><span class="hs-identifier hs-var">absRelPos</span></a></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Bool
forall a. Ord a =&gt; a -&gt; a -&gt; Bool
</span><span class="hs-operator hs-var">&lt;</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679677379"><span class="hs-identifier hs-var">maxExact</span></a></span><span>
</span><span id="line-297"></span><span>                            </span><span id="local-6989586621679677372"><span class="annot"><span class="annottext">relPosIfLarge :: Int
</span><a href="#local-6989586621679677372"><span class="hs-identifier hs-var hs-var">relPosIfLarge</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-298"></span><span>                              </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679677379"><span class="hs-identifier hs-var">maxExact</span></a></span><span>
</span><span id="line-299"></span><span>                                </span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Int
forall a. Num a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">+</span></span><span> </span><span class="annot"><span class="annottext">Double -&gt; Int
</span><span class="hs-identifier hs-var">double2Int</span></span><span>
</span><span id="line-300"></span><span>                                  </span><span class="hs-special">(</span><span> </span><span class="annot"><span class="annottext">Double -&gt; Double -&gt; Double
forall a. Floating a =&gt; a -&gt; a -&gt; a
</span><span class="hs-identifier hs-var">logBase</span></span><span>
</span><span id="line-301"></span><span>                                      </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Int -&gt; Double
forall a b. (Integral a, Num b) =&gt; a -&gt; b
</span><span class="hs-identifier hs-var">fromIntegral</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679677384"><span class="hs-identifier hs-var">maxDistance</span></a></span><span> </span><span class="annot"><span class="annottext">Double -&gt; Double -&gt; Double
forall a. Fractional a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">/</span></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Double
forall a b. (Integral a, Num b) =&gt; a -&gt; b
</span><span class="hs-identifier hs-var">fromIntegral</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679677379"><span class="hs-identifier hs-var">maxExact</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-302"></span><span>                                      </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Int -&gt; Double
forall a b. (Integral a, Num b) =&gt; a -&gt; b
</span><span class="hs-identifier hs-var">fromIntegral</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679677375"><span class="hs-identifier hs-var">absRelPos</span></a></span><span> </span><span class="annot"><span class="annottext">Double -&gt; Double -&gt; Double
forall a. Fractional a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">/</span></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Double
forall a b. (Integral a, Num b) =&gt; a -&gt; b
</span><span class="hs-identifier hs-var">fromIntegral</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679677379"><span class="hs-identifier hs-var">maxExact</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-303"></span><span>                                      </span><span class="annot"><span class="annottext">Double -&gt; Double -&gt; Double
forall a. Num a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">*</span></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Double
forall a b. (Integral a, Num b) =&gt; a -&gt; b
</span><span class="hs-identifier hs-var">fromIntegral</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679677385"><span class="hs-identifier hs-var">numBuckets</span></a></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Int
forall a. Num a =&gt; a -&gt; a -&gt; a
</span><span class="hs-glyph hs-var">-</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679677379"><span class="hs-identifier hs-var">maxExact</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-304"></span><span>                                  </span><span class="hs-special">)</span><span>
</span><span id="line-305"></span><span>                            </span><span id="local-6989586621679677371"><span class="annot"><span class="annottext">relPosIfLarge' :: Int
</span><a href="#local-6989586621679677371"><span class="hs-identifier hs-var hs-var">relPosIfLarge'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Int
forall a. Ord a =&gt; a -&gt; a -&gt; a
</span><span class="hs-identifier hs-var">min</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679677372"><span class="hs-identifier hs-var">relPosIfLarge</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679677385"><span class="hs-identifier hs-var">numBuckets</span></a></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Int
forall a. Num a =&gt; a -&gt; a -&gt; a
</span><span class="hs-glyph hs-var">-</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">1</span></span><span class="hs-special">)</span><span>
</span><span id="line-306"></span><span>                         </span><span class="hs-keyword">in</span><span> </span><span class="hs-keyword">if</span><span> </span><span class="annot"><span class="annottext">Bool
</span><a href="#local-6989586621679677373"><span class="hs-identifier hs-var">isSmall</span></a></span><span> </span><span class="hs-keyword">then</span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679677375"><span class="hs-identifier hs-var">absRelPos</span></a></span><span> </span><span class="hs-keyword">else</span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679677371"><span class="hs-identifier hs-var">relPosIfLarge'</span></a></span><span>
</span><span id="line-307"></span><span>                   </span><span class="hs-keyword">in</span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679677374"><span class="hs-identifier hs-var">relBucket'</span></a></span><span>
</span><span id="line-308"></span><span>              </span><span class="hs-special">)</span><span>
</span><span id="line-309"></span><span>              </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679677380"><span class="hs-identifier hs-var">keyPos</span></a></span><span>
</span><span id="line-310"></span><span>        </span><span class="hs-special">)</span><span>
</span><span id="line-311"></span><span>        </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679677381"><span class="hs-identifier hs-var">queryPos</span></a></span><span>
</span><span id="line-312"></span><span>
</span><span id="line-313"></span><span class="hs-comment">-- | Computes relative positions of the input tokens to the decoder.</span><span>
</span><span id="line-314"></span><span class="hs-comment">-- Given an input tensor of shape @[batchDim, Dim seqName seqSize]@,</span><span>
</span><span id="line-315"></span><span class="hs-comment">-- returns a tensor of shape @[1, Dim &quot;*&quot; seqSize, Dim &quot;*&quot; seqSize]@.</span><span>
</span><span id="line-316"></span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#mkDecoderRelPos"><span class="hs-identifier hs-type">mkDecoderRelPos</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-317"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679677369"><span class="annot"><a href="#local-6989586621679677369"><span class="hs-identifier hs-type">m</span></a></span></span><span> </span><span id="local-6989586621679677368"><span class="annot"><a href="#local-6989586621679677368"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679677367"><span class="annot"><a href="#local-6989586621679677367"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679677366"><span class="annot"><a href="#local-6989586621679677366"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679677365"><span class="annot"><a href="#local-6989586621679677365"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679677364"><span class="annot"><a href="#local-6989586621679677364"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679677363"><span class="annot"><a href="#local-6989586621679677363"><span class="hs-identifier hs-type">relPosEncBucketDim</span></a></span></span><span> </span><span id="local-6989586621679677362"><span class="annot"><a href="#local-6989586621679677362"><span class="hs-identifier hs-type">seqDim</span></a></span></span><span> </span><span id="local-6989586621679677361"><span class="annot"><a href="#local-6989586621679677361"><span class="hs-identifier hs-type">seqName</span></a></span></span><span> </span><span id="local-6989586621679677360"><span class="annot"><a href="#local-6989586621679677360"><span class="hs-identifier hs-type">seqSize</span></a></span></span><span> </span><span id="local-6989586621679677359"><span class="annot"><a href="#local-6989586621679677359"><span class="hs-identifier hs-type">output</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-318"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier hs-type">MonadThrow</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677369"><span class="hs-identifier hs-type">m</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-319"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkRelPosC"><span class="hs-identifier hs-type">MkRelPosC</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677366"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677364"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677362"><span class="hs-identifier hs-type">seqDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677361"><span class="hs-identifier hs-type">seqName</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677360"><span class="hs-identifier hs-type">seqSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677359"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-320"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-321"></span><span>  </span><span class="hs-comment">-- | bucket dimension</span><span>
</span><span id="line-322"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677363"><span class="hs-identifier hs-type">relPosEncBucketDim</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-323"></span><span>  </span><span class="hs-comment">-- | maximum distance</span><span>
</span><span id="line-324"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-325"></span><span>  </span><span class="hs-comment">-- | decoder input tensor</span><span>
</span><span id="line-326"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677368"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677367"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677366"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677365"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677364"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-327"></span><span>  </span><span class="hs-comment">-- | relative positions of the input tokens</span><span>
</span><span id="line-328"></span><span>  </span><span class="annot"><a href="#local-6989586621679677369"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677359"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-329"></span><span id="mkDecoderRelPos"><span class="annot"><span class="annottext">mkDecoderRelPos :: SDim relPosEncBucketDim
-&gt; Int -&gt; Tensor gradient layout device dataType shape -&gt; m output
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#mkDecoderRelPos"><span class="hs-identifier hs-var hs-var">mkDecoderRelPos</span></a></span></span><span> </span><span id="local-6989586621679677358"><span class="annot"><span class="annottext">SDim relPosEncBucketDim
</span><a href="#local-6989586621679677358"><span class="hs-identifier hs-var">relPosEncBucketDim</span></a></span></span><span> </span><span id="local-6989586621679677357"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679677357"><span class="hs-identifier hs-var">maxDistance</span></a></span></span><span> </span><span id="local-6989586621679677356"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679677356"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-330"></span><span>  </span><span id="local-6989586621679677355"><span class="annot"><span class="annottext">SDim ('Dim seqName seqSize)
</span><a href="#local-6989586621679677355"><span class="hs-identifier hs-var">seqDim</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">SSelectDim ('SelectDim ('ByIndex 1))
-&gt; SShape shape -&gt; m (SDim ('Dim seqName seqSize))
forall (selectDim :: SelectDim (By Symbol Nat))
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (dim :: Dim (Name Symbol) (Size Nat)) (m :: * -&gt; *).
(dim ~ GetDimF selectDim shape, MonadThrow m) =&gt;
SSelectDim selectDim -&gt; SShape shape -&gt; m (SDim dim)
</span><a href="Torch.GraduallyTyped.Shape.Class.html#sGetDimFromShape"><span class="hs-identifier hs-var">sGetDimFromShape</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SBy ('ByIndex 1) -&gt; SSelectDim ('SelectDim ('ByIndex 1))
forall (by :: By Symbol Nat). SBy by -&gt; SSelectDim ('SelectDim by)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSelectDim"><span class="hs-identifier hs-var">SSelectDim</span></a></span><span> </span><span class="annot"><span class="annottext">(SBy ('ByIndex 1) -&gt; SSelectDim ('SelectDim ('ByIndex 1)))
-&gt; SBy ('ByIndex 1) -&gt; SSelectDim ('SelectDim ('ByIndex 1))
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">KnownNat 1 =&gt; SBy ('ByIndex 1)
forall (index :: Nat). KnownNat index =&gt; SBy ('ByIndex index)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SByIndex"><span class="hs-identifier hs-var">SByIndex</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">(SShape shape -&gt; m (SDim ('Dim seqName seqSize)))
-&gt; SShape shape -&gt; m (SDim ('Dim seqName seqSize))
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape -&gt; SShape shape
forall (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType).
SGetShape shape =&gt;
Tensor gradient layout device dataType shape -&gt; SShape shape
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sGetShape"><span class="hs-identifier hs-var">sGetShape</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679677356"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-331"></span><span>  </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679677354"><span class="annot"><span class="annottext">seqSize :: Int
</span><a href="#local-6989586621679677354"><span class="hs-identifier hs-var hs-var">seqSize</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Integer -&gt; Int
forall a. Num a =&gt; Integer -&gt; a
</span><span class="hs-identifier hs-var">fromInteger</span></span><span> </span><span class="annot"><span class="annottext">(Integer -&gt; Int)
-&gt; (SSize seqSize -&gt; Integer) -&gt; SSize seqSize -&gt; Int
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">IsChecked Integer -&gt; Integer
forall a. IsChecked a -&gt; a
</span><a href="Torch.GraduallyTyped.Prelude.html#forgetIsChecked"><span class="hs-identifier hs-var">forgetIsChecked</span></a></span><span> </span><span class="annot"><span class="annottext">(IsChecked Integer -&gt; Integer)
-&gt; (SSize seqSize -&gt; IsChecked Integer) -&gt; SSize seqSize -&gt; Integer
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">SSize seqSize -&gt; IsChecked Integer
forall k (a :: k). SingKind k =&gt; Sing a -&gt; Demote k
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">fromSing</span></a></span><span> </span><span class="annot"><span class="annottext">(SSize seqSize -&gt; Int) -&gt; SSize seqSize -&gt; Int
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim seqName seqSize) -&gt; SSize seqSize
forall (name :: Name Symbol) (size :: Size Nat).
SDim ('Dim name size) -&gt; SSize size
</span><a href="Torch.GraduallyTyped.Shape.Type.html#sDimSize"><span class="hs-identifier hs-var hs-var">sDimSize</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim seqName seqSize)
</span><a href="#local-6989586621679677355"><span class="hs-identifier hs-var">seqDim</span></a></span><span>
</span><span id="line-332"></span><span>  </span><span class="annot"><span class="annottext">SGradient ('Gradient 'WithoutGradient)
-&gt; SLayout ('Layout 'Dense)
-&gt; SDevice device
-&gt; [[[Int]]]
-&gt; m (Tensor
        ('Gradient 'WithoutGradient)
        ('Layout 'Dense)
        device
        ('DataType 'Int64)
        ('Shape
           '[ 'Dim ('Name &quot;*&quot;) 'UncheckedSize,
              'Dim ('Name &quot;*&quot;) 'UncheckedSize, 'Dim ('Name &quot;*&quot;) 'UncheckedSize]))
forall a (dType :: DType) (dims :: [Dim (Name Symbol) (Size Nat)])
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (m :: * -&gt; *).
(TensorLike a dType dims, MonadThrow m) =&gt;
SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; a
-&gt; m (Tensor
        gradient layout device ('DataType dType) ('Shape dims))
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sToTensor"><span class="hs-identifier hs-var">sToTensor</span></a></span><span> </span><span class="annot"><span class="annottext">SGradient ('Gradient 'WithoutGradient)
</span><a href="#local-6989586621679677353"><span class="hs-identifier hs-var">gradient'</span></a></span><span> </span><span class="annot"><span class="annottext">SLayout ('Layout 'Dense)
</span><a href="#local-6989586621679677352"><span class="hs-identifier hs-var">layout'</span></a></span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679677351"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="hs-special">[</span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Int -&gt; Int -&gt; [[Int]]
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#mkDecoderRelPos%27"><span class="hs-identifier hs-var">mkDecoderRelPos'</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679677350"><span class="hs-identifier hs-var">relPosEncBucketSize</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679677357"><span class="hs-identifier hs-var">maxDistance</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679677354"><span class="hs-identifier hs-var">seqSize</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679677354"><span class="hs-identifier hs-var">seqSize</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-333"></span><span>    </span><span class="annot"><span class="annottext">m (Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     device
     ('DataType 'Int64)
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) 'UncheckedSize,
           'Dim ('Name &quot;*&quot;) 'UncheckedSize, 'Dim ('Name &quot;*&quot;) 'UncheckedSize]))
-&gt; (Tensor
      ('Gradient 'WithoutGradient)
      ('Layout 'Dense)
      device
      ('DataType 'Int64)
      ('Shape
         '[ 'Dim ('Name &quot;*&quot;) 'UncheckedSize,
            'Dim ('Name &quot;*&quot;) 'UncheckedSize, 'Dim ('Name &quot;*&quot;) 'UncheckedSize])
    -&gt; m (Tensor
            ('Gradient 'WithoutGradient)
            ('Layout 'Dense)
            device
            ('DataType 'Int64)
            ('Shape
               '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) seqSize,
                  'Dim ('Name &quot;*&quot;) seqSize])))
-&gt; m (Tensor
        ('Gradient 'WithoutGradient)
        ('Layout 'Dense)
        device
        ('DataType 'Int64)
        ('Shape
           '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) seqSize,
              'Dim ('Name &quot;*&quot;) seqSize]))
forall (m :: * -&gt; *) a b. Monad m =&gt; m a -&gt; (a -&gt; m b) -&gt; m b
</span><span class="hs-operator hs-var">&gt;&gt;=</span></span><span> </span><span class="annot"><span class="annottext">SShape
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) seqSize,
        'Dim ('Name &quot;*&quot;) seqSize])
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     device
     ('DataType 'Int64)
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) 'UncheckedSize,
           'Dim ('Name &quot;*&quot;) 'UncheckedSize, 'Dim ('Name &quot;*&quot;) 'UncheckedSize])
-&gt; m (Tensor
        ('Gradient 'WithoutGradient)
        ('Layout 'Dense)
        device
        ('DataType 'Int64)
        ('Shape
           '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) seqSize,
              'Dim ('Name &quot;*&quot;) seqSize]))
forall (shape' :: Shape [Dim (Name Symbol) (Size Nat)])
       (m :: * -&gt; *) (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
(SGetShape shape, MonadThrow m, Catch (shape &lt;+&gt; shape')) =&gt;
SShape shape'
-&gt; Tensor gradient layout device dataType shape
-&gt; m (Tensor gradient layout device dataType shape')
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sCheckedShape"><span class="hs-identifier hs-var">sCheckedShape</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SList
  '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) seqSize,
     'Dim ('Name &quot;*&quot;) seqSize]
-&gt; SShape
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) seqSize,
           'Dim ('Name &quot;*&quot;) seqSize])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList
   '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) seqSize,
      'Dim ('Name &quot;*&quot;) seqSize]
 -&gt; SShape
      ('Shape
         '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) seqSize,
            'Dim ('Name &quot;*&quot;) seqSize]))
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) seqSize,
        'Dim ('Name &quot;*&quot;) seqSize]
-&gt; SShape
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) seqSize,
           'Dim ('Name &quot;*&quot;) seqSize])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize ('Size 1) -&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 1))
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownNat 1 =&gt; SSize ('Size 1)
forall (size :: Nat). KnownNat size =&gt; SSize ('Size size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier hs-var">SSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">1</span></span><span> </span><span class="annot"><span class="annottext">Sing ('Dim ('Name &quot;*&quot;) ('Size 1))
-&gt; SList '[ 'Dim ('Name &quot;*&quot;) seqSize, 'Dim ('Name &quot;*&quot;) seqSize]
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) seqSize,
        'Dim ('Name &quot;*&quot;) seqSize]
forall a1 (a2 :: a1) (as :: [a1]).
Sing a2 -&gt; SList as -&gt; SList (a2 : as)
</span><a href="Torch.GraduallyTyped.Prelude.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize seqSize -&gt; SDim ('Dim ('Name &quot;*&quot;) seqSize)
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim seqName seqSize) -&gt; SSize seqSize
forall (name :: Name Symbol) (size :: Size Nat).
SDim ('Dim name size) -&gt; SSize size
</span><a href="Torch.GraduallyTyped.Shape.Type.html#sDimSize"><span class="hs-identifier hs-var hs-var">sDimSize</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim seqName seqSize)
</span><a href="#local-6989586621679677355"><span class="hs-identifier hs-var">seqDim</span></a></span><span> </span><span class="annot"><span class="annottext">Sing ('Dim ('Name &quot;*&quot;) seqSize)
-&gt; SList '[ 'Dim ('Name &quot;*&quot;) seqSize]
-&gt; SList '[ 'Dim ('Name &quot;*&quot;) seqSize, 'Dim ('Name &quot;*&quot;) seqSize]
forall a1 (a2 :: a1) (as :: [a1]).
Sing a2 -&gt; SList as -&gt; SList (a2 : as)
</span><a href="Torch.GraduallyTyped.Prelude.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize seqSize -&gt; SDim ('Dim ('Name &quot;*&quot;) seqSize)
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim seqName seqSize) -&gt; SSize seqSize
forall (name :: Name Symbol) (size :: Size Nat).
SDim ('Dim name size) -&gt; SSize size
</span><a href="Torch.GraduallyTyped.Shape.Type.html#sDimSize"><span class="hs-identifier hs-var hs-var">sDimSize</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim seqName seqSize)
</span><a href="#local-6989586621679677355"><span class="hs-identifier hs-var">seqDim</span></a></span><span> </span><span class="annot"><span class="annottext">Sing ('Dim ('Name &quot;*&quot;) seqSize)
-&gt; SList '[] -&gt; SList '[ 'Dim ('Name &quot;*&quot;) seqSize]
forall a1 (a2 :: a1) (as :: [a1]).
Sing a2 -&gt; SList as -&gt; SList (a2 : as)
</span><a href="Torch.GraduallyTyped.Prelude.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-334"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-335"></span><span>    </span><span id="local-6989586621679677353"><span class="annot"><span class="annottext">gradient' :: SGradient ('Gradient 'WithoutGradient)
</span><a href="#local-6989586621679677353"><span class="hs-identifier hs-var hs-var">gradient'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SRequiresGradient 'WithoutGradient
-&gt; SGradient ('Gradient 'WithoutGradient)
forall (requiresGradient :: RequiresGradient).
SRequiresGradient requiresGradient
-&gt; SGradient ('Gradient requiresGradient)
</span><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier hs-var">SGradient</span></a></span><span> </span><span class="annot"><span class="annottext">SRequiresGradient 'WithoutGradient
</span><a href="Torch.GraduallyTyped.RequiresGradient.html#SWithoutGradient"><span class="hs-identifier hs-var">SWithoutGradient</span></a></span><span>
</span><span id="line-336"></span><span>    </span><span id="local-6989586621679677352"><span class="annot"><span class="annottext">layout' :: SLayout ('Layout 'Dense)
</span><a href="#local-6989586621679677352"><span class="hs-identifier hs-var hs-var">layout'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SLayoutType 'Dense -&gt; SLayout ('Layout 'Dense)
forall (layoutType :: LayoutType).
SLayoutType layoutType -&gt; SLayout ('Layout layoutType)
</span><a href="Torch.GraduallyTyped.Layout.html#SLayout"><span class="hs-identifier hs-var">SLayout</span></a></span><span> </span><span class="annot"><span class="annottext">SLayoutType 'Dense
</span><a href="Torch.GraduallyTyped.Layout.html#SDense"><span class="hs-identifier hs-var">SDense</span></a></span><span>
</span><span id="line-337"></span><span>    </span><span id="local-6989586621679677351"><span class="annot"><span class="annottext">device :: SDevice device
</span><a href="#local-6989586621679677351"><span class="hs-identifier hs-var hs-var">device</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape -&gt; SDevice device
forall (device :: Device (DeviceType Nat))
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SGetDevice device =&gt;
Tensor gradient layout device dataType shape -&gt; SDevice device
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sGetDevice"><span class="hs-identifier hs-var">sGetDevice</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679677356"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-338"></span><span>    </span><span id="local-6989586621679677350"><span class="annot"><span class="annottext">relPosEncBucketSize :: Int
</span><a href="#local-6989586621679677350"><span class="hs-identifier hs-var hs-var">relPosEncBucketSize</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Integer -&gt; Int
forall a. Num a =&gt; Integer -&gt; a
</span><span class="hs-identifier hs-var">fromInteger</span></span><span> </span><span class="annot"><span class="annottext">(Integer -&gt; Int)
-&gt; (SDim relPosEncBucketDim -&gt; Integer)
-&gt; SDim relPosEncBucketDim
-&gt; Int
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">IsChecked Integer -&gt; Integer
forall a. IsChecked a -&gt; a
</span><a href="Torch.GraduallyTyped.Prelude.html#forgetIsChecked"><span class="hs-identifier hs-var">forgetIsChecked</span></a></span><span> </span><span class="annot"><span class="annottext">(IsChecked Integer -&gt; Integer)
-&gt; (SDim relPosEncBucketDim -&gt; IsChecked Integer)
-&gt; SDim relPosEncBucketDim
-&gt; Integer
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Dim (IsChecked String) (IsChecked Integer) -&gt; IsChecked Integer
forall name size. Dim name size -&gt; size
</span><a href="Torch.GraduallyTyped.Shape.Type.html#dimSize"><span class="hs-identifier hs-var hs-var">dimSize</span></a></span><span> </span><span class="annot"><span class="annottext">(Dim (IsChecked String) (IsChecked Integer) -&gt; IsChecked Integer)
-&gt; (SDim relPosEncBucketDim
    -&gt; Dim (IsChecked String) (IsChecked Integer))
-&gt; SDim relPosEncBucketDim
-&gt; IsChecked Integer
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">SDim relPosEncBucketDim
-&gt; Dim (IsChecked String) (IsChecked Integer)
forall k (a :: k). SingKind k =&gt; Sing a -&gt; Demote k
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">fromSing</span></a></span><span> </span><span class="annot"><span class="annottext">(SDim relPosEncBucketDim -&gt; Int) -&gt; SDim relPosEncBucketDim -&gt; Int
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SDim relPosEncBucketDim
</span><a href="#local-6989586621679677358"><span class="hs-identifier hs-var">relPosEncBucketDim</span></a></span><span>
</span><span id="line-339"></span><span>
</span><span id="line-340"></span><span id="local-6989586621679677348"><span id="local-6989586621679677349"></span></span><span class="hs-keyword">data</span><span> </span><span id="MkRelPos"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkRelPos"><span class="hs-identifier hs-var">MkRelPos</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679677347"><span class="annot"><a href="#local-6989586621679677347"><span class="hs-identifier hs-type">relPosEncBucketDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-341"></span><span>  </span><span id="MkRelPos"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkRelPos"><span class="hs-identifier hs-var">MkRelPos</span></a></span></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-342"></span><span>    </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679677960"><span class="annot"><a href="#local-6989586621679677960"><span class="hs-identifier hs-type">relPosEncBucketDim</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-343"></span><span>    </span><span class="hs-special">{</span><span> </span><span id="relPosEncBucketDim"><span class="annot"><span class="annottext">MkRelPos relPosEncBucketDim -&gt; SDim relPosEncBucketDim
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#relPosEncBucketDim"><span class="hs-identifier hs-var hs-var">relPosEncBucketDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677960"><span class="hs-identifier hs-type">relPosEncBucketDim</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-344"></span><span>      </span><span id="relPosMaxDistance"><span class="annot"><span class="annottext">MkRelPos relPosEncBucketDim -&gt; Int
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#relPosMaxDistance"><span class="hs-identifier hs-var hs-var">relPosMaxDistance</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span>
</span><span id="line-345"></span><span>    </span><span class="hs-special">}</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-346"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkRelPos"><span class="hs-identifier hs-type">MkRelPos</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677960"><span class="hs-identifier hs-type">relPosEncBucketDim</span></a></span><span>
</span><span id="line-347"></span><span>  </span><span id="MkDecoderRelPos"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkDecoderRelPos"><span class="hs-identifier hs-var">MkDecoderRelPos</span></a></span></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-348"></span><span>    </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679677342"><span class="annot"><a href="#local-6989586621679677342"><span class="hs-identifier hs-type">relPosEncBucketDim</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-349"></span><span>    </span><span class="hs-special">{</span><span> </span><span id="decoderRelPosEncBucketDim"><span class="annot"><span class="annottext">MkRelPos relPosEncBucketDim -&gt; SDim relPosEncBucketDim
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#decoderRelPosEncBucketDim"><span class="hs-identifier hs-var hs-var">decoderRelPosEncBucketDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677342"><span class="hs-identifier hs-type">relPosEncBucketDim</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-350"></span><span>      </span><span id="decoderRelPosMaxDistance"><span class="annot"><span class="annottext">MkRelPos relPosEncBucketDim -&gt; Int
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#decoderRelPosMaxDistance"><span class="hs-identifier hs-var hs-var">decoderRelPosMaxDistance</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span>
</span><span id="line-351"></span><span>    </span><span class="hs-special">}</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-352"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkRelPos"><span class="hs-identifier hs-type">MkRelPos</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677342"><span class="hs-identifier hs-type">relPosEncBucketDim</span></a></span><span>
</span><span id="line-353"></span><span>  </span><span class="hs-keyword">deriving</span><span> </span><span class="annot"><span class="hs-keyword">stock</span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679677334"><span id="local-6989586621679677336"><span id="local-6989586621679677338"><span class="annot"><span class="annottext">Int -&gt; MkRelPos relPosEncBucketDim -&gt; ShowS
[MkRelPos relPosEncBucketDim] -&gt; ShowS
MkRelPos relPosEncBucketDim -&gt; String
(Int -&gt; MkRelPos relPosEncBucketDim -&gt; ShowS)
-&gt; (MkRelPos relPosEncBucketDim -&gt; String)
-&gt; ([MkRelPos relPosEncBucketDim] -&gt; ShowS)
-&gt; Show (MkRelPos relPosEncBucketDim)
forall a.
(Int -&gt; a -&gt; ShowS) -&gt; (a -&gt; String) -&gt; ([a] -&gt; ShowS) -&gt; Show a
forall (relPosEncBucketDim :: Dim (Name Symbol) (Size Nat)).
Int -&gt; MkRelPos relPosEncBucketDim -&gt; ShowS
forall (relPosEncBucketDim :: Dim (Name Symbol) (Size Nat)).
[MkRelPos relPosEncBucketDim] -&gt; ShowS
forall (relPosEncBucketDim :: Dim (Name Symbol) (Size Nat)).
MkRelPos relPosEncBucketDim -&gt; String
showList :: [MkRelPos relPosEncBucketDim] -&gt; ShowS
$cshowList :: forall (relPosEncBucketDim :: Dim (Name Symbol) (Size Nat)).
[MkRelPos relPosEncBucketDim] -&gt; ShowS
show :: MkRelPos relPosEncBucketDim -&gt; String
$cshow :: forall (relPosEncBucketDim :: Dim (Name Symbol) (Size Nat)).
MkRelPos relPosEncBucketDim -&gt; String
showsPrec :: Int -&gt; MkRelPos relPosEncBucketDim -&gt; ShowS
$cshowsPrec :: forall (relPosEncBucketDim :: Dim (Name Symbol) (Size Nat)).
Int -&gt; MkRelPos relPosEncBucketDim -&gt; ShowS
</span><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">Show</span></span></span></span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">(forall x.
 MkRelPos relPosEncBucketDim -&gt; Rep (MkRelPos relPosEncBucketDim) x)
-&gt; (forall x.
    Rep (MkRelPos relPosEncBucketDim) x -&gt; MkRelPos relPosEncBucketDim)
-&gt; Generic (MkRelPos relPosEncBucketDim)
forall x.
Rep (MkRelPos relPosEncBucketDim) x -&gt; MkRelPos relPosEncBucketDim
forall x.
MkRelPos relPosEncBucketDim -&gt; Rep (MkRelPos relPosEncBucketDim) x
forall a.
(forall x. a -&gt; Rep a x) -&gt; (forall x. Rep a x -&gt; a) -&gt; Generic a
forall (relPosEncBucketDim :: Dim (Name Symbol) (Size Nat)) x.
Rep (MkRelPos relPosEncBucketDim) x -&gt; MkRelPos relPosEncBucketDim
forall (relPosEncBucketDim :: Dim (Name Symbol) (Size Nat)) x.
MkRelPos relPosEncBucketDim -&gt; Rep (MkRelPos relPosEncBucketDim) x
$cto :: forall (relPosEncBucketDim :: Dim (Name Symbol) (Size Nat)) x.
Rep (MkRelPos relPosEncBucketDim) x -&gt; MkRelPos relPosEncBucketDim
$cfrom :: forall (relPosEncBucketDim :: Dim (Name Symbol) (Size Nat)) x.
MkRelPos relPosEncBucketDim -&gt; Rep (MkRelPos relPosEncBucketDim) x
</span><span class="hs-identifier hs-var hs-var hs-var hs-var">Generic</span></span><span class="hs-special">)</span><span>
</span><span id="line-354"></span><span>
</span><span id="line-355"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">instance</span><span> </span><span id="ModelSpec"><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier hs-var">ModelSpec</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkRelPos"><span class="hs-identifier hs-type">MkRelPos</span></a></span><span> </span><span id="local-6989586621679677331"><span class="annot"><a href="#local-6989586621679677331"><span class="hs-identifier hs-type hs-type">relPosEncBucketDim</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkRelPos"><span class="hs-identifier hs-type">MkRelPos</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677331"><span class="hs-identifier hs-type">relPosEncBucketDim</span></a></span><span>
</span><span id="line-356"></span><span>
</span><span id="line-357"></span><span id="local-6989586621679677329"><span id="local-6989586621679677330"><span class="hs-keyword">instance</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkRelPos"><span class="hs-identifier hs-type">MkRelPos</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677330"><span class="hs-identifier hs-type">relPosEncBucketDim</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679677329"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkRelPos"><span class="hs-identifier hs-type">MkRelPos</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677330"><span class="hs-identifier hs-type">relPosEncBucketDim</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679677329"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-358"></span><span>  </span><span id="local-6989586621679677327"><span class="annot"><span class="annottext">initialize :: ModelSpec (MkRelPos relPosEncBucketDim)
-&gt; Generator generatorDevice
-&gt; m (MkRelPos relPosEncBucketDim, Generator generatorDevice)
</span><a href="#local-6989586621679677327"><span class="hs-identifier hs-var hs-var hs-var hs-var">initialize</span></a></span></span><span> </span><span id="local-6989586621679677326"><span class="annot"><span class="annottext">ModelSpec (MkRelPos relPosEncBucketDim)
</span><a href="#local-6989586621679677326"><span class="hs-identifier hs-var">spec</span></a></span></span><span> </span><span id="local-6989586621679677325"><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679677325"><span class="hs-identifier hs-var">g</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(MkRelPos relPosEncBucketDim, Generator generatorDevice)
-&gt; m (MkRelPos relPosEncBucketDim, Generator generatorDevice)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">ModelSpec (MkRelPos relPosEncBucketDim)
MkRelPos relPosEncBucketDim
</span><a href="#local-6989586621679677326"><span class="hs-identifier hs-var">spec</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679677325"><span class="hs-identifier hs-var">g</span></a></span><span class="hs-special">)</span></span></span><span>
</span><span id="line-359"></span><span>
</span><span id="line-360"></span><span id="local-6989586621679677324"><span class="hs-keyword">instance</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasStateDict"><span class="hs-identifier hs-type">HasStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkRelPos"><span class="hs-identifier hs-type">MkRelPos</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677324"><span class="hs-identifier hs-type">relPosEncBucketDim</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-361"></span><span>  </span><span id="local-6989586621679677321"><span class="annot"><span class="annottext">fromStateDict :: ModelSpec (MkRelPos relPosEncBucketDim)
-&gt; StateDictKey -&gt; m (MkRelPos relPosEncBucketDim)
</span><a href="#local-6989586621679677321"><span class="hs-identifier hs-var hs-var hs-var hs-var">fromStateDict</span></a></span></span><span> </span><span id="local-6989586621679677320"><span class="annot"><span class="annottext">ModelSpec (MkRelPos relPosEncBucketDim)
</span><a href="#local-6989586621679677320"><span class="hs-identifier hs-var">spec</span></a></span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">MkRelPos relPosEncBucketDim -&gt; m (MkRelPos relPosEncBucketDim)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">ModelSpec (MkRelPos relPosEncBucketDim)
MkRelPos relPosEncBucketDim
</span><a href="#local-6989586621679677320"><span class="hs-identifier hs-var">spec</span></a></span><span>
</span><span id="line-362"></span><span>  </span><span id="local-6989586621679677319"><span class="annot"><span class="annottext">toStateDict :: StateDictKey -&gt; MkRelPos relPosEncBucketDim -&gt; m ()
</span><a href="#local-6989586621679677319"><span class="hs-identifier hs-var hs-var hs-var hs-var">toStateDict</span></a></span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="annottext">MkRelPos relPosEncBucketDim
</span><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">() -&gt; m ()
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span></span><span>
</span><span id="line-363"></span><span>
</span><span id="line-364"></span><span id="local-6989586621679677308"><span id="local-6989586621679677309"><span id="local-6989586621679677310"><span id="local-6989586621679677311"><span id="local-6989586621679677312"><span id="local-6989586621679677313"><span id="local-6989586621679677314"><span id="local-6989586621679677315"><span id="local-6989586621679677316"><span id="local-6989586621679677317"><span id="local-6989586621679677318"><span class="hs-keyword">instance</span><span>
</span><span id="line-365"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkRelPosC"><span class="hs-identifier hs-type">MkRelPosC</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677318"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677317"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677316"><span class="hs-identifier hs-type">seqDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677315"><span class="hs-identifier hs-type">seqName</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677314"><span class="hs-identifier hs-type">seqSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677313"><span class="hs-identifier hs-type">output</span></a></span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-366"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-367"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkRelPos"><span class="hs-identifier hs-type">MkRelPos</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677312"><span class="hs-identifier hs-type">relPosEncBucketDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-368"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677311"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677310"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677318"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677309"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677317"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-369"></span><span>    </span><span class="annot"><a href="#local-6989586621679677308"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-370"></span><span>    </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-371"></span><span>        </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#WithoutGradient"><span class="hs-identifier hs-type">WithoutGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-372"></span><span>        </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Dense"><span class="hs-identifier hs-type">Dense</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-373"></span><span>        </span><span class="annot"><a href="#local-6989586621679677318"><span class="hs-identifier hs-type">device</span></a></span><span>
</span><span id="line-374"></span><span>        </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#Int64"><span class="hs-identifier hs-type">Int64</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-375"></span><span>        </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679677314"><span class="hs-identifier hs-type">seqSize</span></a></span><span class="hs-special">,</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679677314"><span class="hs-identifier hs-type">seqSize</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-376"></span><span>    </span><span class="hs-special">)</span><span>
</span><span id="line-377"></span><span>    </span><span class="annot"><a href="#local-6989586621679677308"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-378"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-379"></span><span>  </span><span id="local-6989586621679677306"><span class="annot"><span class="annottext">forward :: MkRelPos relPosEncBucketDim
-&gt; Tensor gradient layout device dataType shape
-&gt; Generator generatorDevice
-&gt; m (Tensor
        ('Gradient 'WithoutGradient)
        ('Layout 'Dense)
        device
        ('DataType 'Int64)
        ('Shape
           '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) seqSize,
              'Dim ('Name &quot;*&quot;) seqSize]),
      Generator generatorDevice)
</span><a href="#local-6989586621679677306"><span class="hs-identifier hs-var hs-var hs-var hs-var">forward</span></a></span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkRelPos"><span class="hs-identifier hs-type">MkRelPos</span></a></span><span> </span><span class="hs-special">{</span><span id="local-6989586621679677304"><span id="local-6989586621679677305"><span class="annot"><span class="annottext">Int
SDim relPosEncBucketDim
relPosMaxDistance :: Int
relPosEncBucketDim :: SDim relPosEncBucketDim
relPosMaxDistance :: forall (relPosEncBucketDim :: Dim (Name Symbol) (Size Nat)).
MkRelPos relPosEncBucketDim -&gt; Int
relPosEncBucketDim :: forall (relPosEncBucketDim :: Dim (Name Symbol) (Size Nat)).
MkRelPos relPosEncBucketDim -&gt; SDim relPosEncBucketDim
</span><a href="#local-6989586621679677304"><span class="hs-glyph hs-var hs-var hs-var hs-var">..</span></a></span></span></span><span class="hs-special">}</span><span> </span><span id="local-6989586621679677303"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679677303"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span id="local-6989586621679677302"><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679677302"><span class="hs-identifier hs-var">g</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-380"></span><span>    </span><span id="local-6989586621679677301"><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  device
  ('DataType 'Int64)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) seqSize,
        'Dim ('Name &quot;*&quot;) seqSize])
</span><a href="#local-6989586621679677301"><span class="hs-identifier hs-var">relPos</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">SDim relPosEncBucketDim
-&gt; Int
-&gt; Tensor gradient layout device dataType shape
-&gt; m (Tensor
        ('Gradient 'WithoutGradient)
        ('Layout 'Dense)
        device
        ('DataType 'Int64)
        ('Shape
           '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) seqSize,
              'Dim ('Name &quot;*&quot;) seqSize]))
forall (m :: * -&gt; *) (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (relPosEncBucketDim :: Dim (Name Symbol) (Size Nat))
       (seqDim :: Dim (Name Symbol) (Size Nat)) (seqName :: Name Symbol)
       (seqSize :: Size Nat) output.
(MonadThrow m,
 MkRelPosC device shape seqDim seqName seqSize output) =&gt;
SDim relPosEncBucketDim
-&gt; Int -&gt; Tensor gradient layout device dataType shape -&gt; m output
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#mkRelPos"><span class="hs-identifier hs-var">mkRelPos</span></a></span><span> </span><span class="annot"><span class="annottext">SDim relPosEncBucketDim
</span><a href="#local-6989586621679677305"><span class="hs-identifier hs-var">relPosEncBucketDim</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679677304"><span class="hs-identifier hs-var">relPosMaxDistance</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679677303"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-381"></span><span>    </span><span class="annot"><span class="annottext">(Tensor
   ('Gradient 'WithoutGradient)
   ('Layout 'Dense)
   device
   ('DataType 'Int64)
   ('Shape
      '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) seqSize,
         'Dim ('Name &quot;*&quot;) seqSize]),
 Generator generatorDevice)
-&gt; m (Tensor
        ('Gradient 'WithoutGradient)
        ('Layout 'Dense)
        device
        ('DataType 'Int64)
        ('Shape
           '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) seqSize,
              'Dim ('Name &quot;*&quot;) seqSize]),
      Generator generatorDevice)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  device
  ('DataType 'Int64)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) seqSize,
        'Dim ('Name &quot;*&quot;) seqSize])
</span><a href="#local-6989586621679677301"><span class="hs-identifier hs-var">relPos</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679677302"><span class="hs-identifier hs-var">g</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-382"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkDecoderRelPos"><span class="hs-identifier hs-type">MkDecoderRelPos</span></a></span><span> </span><span class="hs-special">{</span><span id="local-6989586621679677299"><span id="local-6989586621679677300"><span class="annot"><span class="annottext">Int
SDim relPosEncBucketDim
decoderRelPosMaxDistance :: Int
decoderRelPosEncBucketDim :: SDim relPosEncBucketDim
decoderRelPosMaxDistance :: forall (relPosEncBucketDim :: Dim (Name Symbol) (Size Nat)).
MkRelPos relPosEncBucketDim -&gt; Int
decoderRelPosEncBucketDim :: forall (relPosEncBucketDim :: Dim (Name Symbol) (Size Nat)).
MkRelPos relPosEncBucketDim -&gt; SDim relPosEncBucketDim
</span><a href="#local-6989586621679677299"><span class="hs-glyph hs-var hs-var hs-var hs-var">..</span></a></span></span></span><span class="hs-special">}</span><span> </span><span id="local-6989586621679677298"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679677298"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span id="local-6989586621679677297"><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679677297"><span class="hs-identifier hs-var">g</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-383"></span><span>    </span><span id="local-6989586621679677296"><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  device
  ('DataType 'Int64)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) seqSize,
        'Dim ('Name &quot;*&quot;) seqSize])
</span><a href="#local-6989586621679677296"><span class="hs-identifier hs-var">decoderRelPos</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">SDim relPosEncBucketDim
-&gt; Int
-&gt; Tensor gradient layout device dataType shape
-&gt; m (Tensor
        ('Gradient 'WithoutGradient)
        ('Layout 'Dense)
        device
        ('DataType 'Int64)
        ('Shape
           '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) seqSize,
              'Dim ('Name &quot;*&quot;) seqSize]))
forall (m :: * -&gt; *) (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (relPosEncBucketDim :: Dim (Name Symbol) (Size Nat))
       (seqDim :: Dim (Name Symbol) (Size Nat)) (seqName :: Name Symbol)
       (seqSize :: Size Nat) output.
(MonadThrow m,
 MkRelPosC device shape seqDim seqName seqSize output) =&gt;
SDim relPosEncBucketDim
-&gt; Int -&gt; Tensor gradient layout device dataType shape -&gt; m output
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#mkDecoderRelPos"><span class="hs-identifier hs-var">mkDecoderRelPos</span></a></span><span> </span><span class="annot"><span class="annottext">SDim relPosEncBucketDim
</span><a href="#local-6989586621679677300"><span class="hs-identifier hs-var">decoderRelPosEncBucketDim</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679677299"><span class="hs-identifier hs-var">decoderRelPosMaxDistance</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679677298"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-384"></span><span>    </span><span class="annot"><span class="annottext">(Tensor
   ('Gradient 'WithoutGradient)
   ('Layout 'Dense)
   device
   ('DataType 'Int64)
   ('Shape
      '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) seqSize,
         'Dim ('Name &quot;*&quot;) seqSize]),
 Generator generatorDevice)
-&gt; m (Tensor
        ('Gradient 'WithoutGradient)
        ('Layout 'Dense)
        device
        ('DataType 'Int64)
        ('Shape
           '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) seqSize,
              'Dim ('Name &quot;*&quot;) seqSize]),
      Generator generatorDevice)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  device
  ('DataType 'Int64)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) seqSize,
        'Dim ('Name &quot;*&quot;) seqSize])
</span><a href="#local-6989586621679677296"><span class="hs-identifier hs-var">decoderRelPos</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679677297"><span class="hs-identifier hs-var">g</span></a></span><span class="hs-special">)</span></span></span></span></span></span></span></span></span></span></span></span><span>
</span><span id="line-385"></span><span>
</span><span id="line-386"></span><span class="hs-keyword">type</span><span> </span><span id="MkTransformerPaddingMaskC"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerPaddingMaskC"><span class="hs-identifier hs-var">MkTransformerPaddingMaskC</span></a></span></span><span> </span><span id="local-6989586621679677295"><span class="annot"><a href="#local-6989586621679677295"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679677294"><span class="annot"><a href="#local-6989586621679677294"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679677293"><span class="annot"><a href="#local-6989586621679677293"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679677292"><span class="annot"><a href="#local-6989586621679677292"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679677291"><span class="annot"><a href="#local-6989586621679677291"><span class="hs-identifier hs-type">output</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-387"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetDevice"><span class="hs-identifier hs-type">SGetDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677294"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-388"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Catch"><span class="hs-identifier hs-type">Catch</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679677293"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#Int64"><span class="hs-identifier hs-type">Int64</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-389"></span><span>    </span><span class="annot"><a href="#local-6989586621679677291"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-390"></span><span>      </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-391"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#WithoutGradient"><span class="hs-identifier hs-type">WithoutGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-392"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679677295"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Dense"><span class="hs-identifier hs-type">Dense</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-393"></span><span>          </span><span class="annot"><a href="#local-6989586621679677294"><span class="hs-identifier hs-type">device</span></a></span><span>
</span><span id="line-394"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#Bool"><span class="hs-identifier hs-type">Bool</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-395"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#BroadcastShapesF"><span class="hs-identifier hs-type">BroadcastShapesF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677292"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">]</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-396"></span><span>  </span><span class="hs-special">)</span><span>
</span><span id="line-397"></span><span>
</span><span id="line-398"></span><span class="hs-comment">-- | Computes the padding mask for a transformer.</span><span>
</span><span id="line-399"></span><span class="hs-comment">-- Given an input tensor of shape @[batchDim, Dim seqName seqSize]@,</span><span>
</span><span id="line-400"></span><span class="hs-comment">-- returns a tensor of shape @[batchDim, Dim &quot;*&quot; seqSize]@.</span><span>
</span><span id="line-401"></span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#mkTransformerPaddingMask"><span class="hs-identifier hs-type">mkTransformerPaddingMask</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-402"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679677900"><span class="annot"><a href="#local-6989586621679677900"><span class="hs-identifier hs-type">m</span></a></span></span><span> </span><span id="local-6989586621679677894"><span class="annot"><a href="#local-6989586621679677894"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679677899"><span class="annot"><a href="#local-6989586621679677899"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679677898"><span class="annot"><a href="#local-6989586621679677898"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679677897"><span class="annot"><a href="#local-6989586621679677897"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679677896"><span class="annot"><a href="#local-6989586621679677896"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679677895"><span class="annot"><a href="#local-6989586621679677895"><span class="hs-identifier hs-type">output</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-403"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier hs-type">MonadThrow</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677900"><span class="hs-identifier hs-type">m</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-404"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerPaddingMaskC"><span class="hs-identifier hs-type">MkTransformerPaddingMaskC</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677899"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677898"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677897"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677896"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677895"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-405"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-406"></span><span>  </span><span class="hs-comment">-- | padding token id</span><span>
</span><span id="line-407"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-408"></span><span>  </span><span class="hs-comment">-- | input tensor</span><span>
</span><span id="line-409"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677894"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677899"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677898"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677897"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677896"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-410"></span><span>  </span><span class="hs-comment">-- | padding mask</span><span>
</span><span id="line-411"></span><span>  </span><span class="annot"><a href="#local-6989586621679677900"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677895"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-412"></span><span id="mkTransformerPaddingMask"><span class="annot"><span class="annottext">mkTransformerPaddingMask :: Int -&gt; Tensor gradient layout device dataType shape -&gt; m output
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#mkTransformerPaddingMask"><span class="hs-identifier hs-var hs-var">mkTransformerPaddingMask</span></a></span></span><span> </span><span id="local-6989586621679677289"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679677289"><span class="hs-identifier hs-var">padTokenId</span></a></span></span><span> </span><span id="local-6989586621679677288"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679677288"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-413"></span><span>  </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679677287"><span class="annot"><span class="annottext">device :: SDevice device
</span><a href="#local-6989586621679677287"><span class="hs-identifier hs-var hs-var">device</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape -&gt; SDevice device
forall (device :: Device (DeviceType Nat))
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SGetDevice device =&gt;
Tensor gradient layout device dataType shape -&gt; SDevice device
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sGetDevice"><span class="hs-identifier hs-var">sGetDevice</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679677288"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-414"></span><span>  </span><span id="local-6989586621679677286"><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  device
  ('DataType 'Int64)
  ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1)])
</span><a href="#local-6989586621679677286"><span class="hs-identifier hs-var">padToken</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span>
</span><span id="line-415"></span><span>    </span><span class="annot"><span class="annottext">TensorSpec
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  device
  ('DataType 'Int64)
  ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1)])
-&gt; Int
-&gt; m (Tensor
        ('Gradient 'WithoutGradient)
        ('Layout 'Dense)
        device
        ('DataType 'Int64)
        ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1)]))
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]) input
       (m :: * -&gt; *).
(MonadThrow m, Scalar input) =&gt;
TensorSpec gradient layout device dataType shape
-&gt; input -&gt; m (Tensor gradient layout device dataType shape)
</span><a href="Torch.GraduallyTyped.Tensor.Creation.html#sFull"><span class="hs-identifier hs-var">sFull</span></a></span><span>
</span><span id="line-416"></span><span>      </span><span class="hs-special">(</span><span> </span><span class="annot"><span class="annottext">SGradient ('Gradient 'WithoutGradient)
-&gt; SLayout ('Layout 'Dense)
-&gt; SDevice device
-&gt; SDataType ('DataType 'Int64)
-&gt; SShape ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1)])
-&gt; TensorSpec
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     device
     ('DataType 'Int64)
     ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1)])
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SShape shape
-&gt; TensorSpec gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorSpec"><span class="hs-identifier hs-var">TensorSpec</span></a></span><span>
</span><span id="line-417"></span><span>          </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SRequiresGradient 'WithoutGradient
-&gt; SGradient ('Gradient 'WithoutGradient)
forall (requiresGradient :: RequiresGradient).
SRequiresGradient requiresGradient
-&gt; SGradient ('Gradient requiresGradient)
</span><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier hs-var">SGradient</span></a></span><span> </span><span class="annot"><span class="annottext">SRequiresGradient 'WithoutGradient
</span><a href="Torch.GraduallyTyped.RequiresGradient.html#SWithoutGradient"><span class="hs-identifier hs-var">SWithoutGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-418"></span><span>          </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SLayoutType 'Dense -&gt; SLayout ('Layout 'Dense)
forall (layoutType :: LayoutType).
SLayoutType layoutType -&gt; SLayout ('Layout layoutType)
</span><a href="Torch.GraduallyTyped.Layout.html#SLayout"><span class="hs-identifier hs-var">SLayout</span></a></span><span> </span><span class="annot"><span class="annottext">SLayoutType 'Dense
</span><a href="Torch.GraduallyTyped.Layout.html#SDense"><span class="hs-identifier hs-var">SDense</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-419"></span><span>          </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679677287"><span class="hs-identifier hs-var">device</span></a></span><span>
</span><span id="line-420"></span><span>          </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SDType 'Int64 -&gt; SDataType ('DataType 'Int64)
forall (dType :: DType).
SDType dType -&gt; SDataType ('DataType dType)
</span><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier hs-var">SDataType</span></a></span><span> </span><span class="annot"><span class="annottext">SDType 'Int64
</span><a href="Torch.GraduallyTyped.DType.html#SInt64"><span class="hs-identifier hs-var">SInt64</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-421"></span><span>          </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SList '[ 'Dim ('Name &quot;*&quot;) ('Size 1)]
-&gt; SShape ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1)])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList '[ 'Dim ('Name &quot;*&quot;) ('Size 1)]
 -&gt; SShape ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1)]))
-&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 1)]
-&gt; SShape ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1)])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize ('Size 1) -&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 1))
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownNat 1 =&gt; SSize ('Size 1)
forall (size :: Nat). KnownNat size =&gt; SSize ('Size size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier hs-var">SSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">1</span></span><span> </span><span class="annot"><span class="annottext">Sing ('Dim ('Name &quot;*&quot;) ('Size 1))
-&gt; SList '[] -&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 1)]
forall a1 (a2 :: a1) (as :: [a1]).
Sing a2 -&gt; SList as -&gt; SList (a2 : as)
</span><a href="Torch.GraduallyTyped.Prelude.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-422"></span><span>      </span><span class="hs-special">)</span><span>
</span><span id="line-423"></span><span>      </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679677289"><span class="hs-identifier hs-var">padTokenId</span></a></span><span>
</span><span id="line-424"></span><span>  </span><span class="annot"><span class="annottext">output -&gt; m output
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">(output -&gt; m output) -&gt; output -&gt; m output
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679677288"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     device
     ('DataType 'Int64)
     ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1)])
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     (layout &lt;+&gt; 'Layout 'Dense)
     (device &lt;+&gt; device)
     ('DataType 'Bool)
     (BroadcastShapesF shape ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1)]))
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (gradient' :: Gradient RequiresGradient)
       (layout' :: Layout LayoutType) (device' :: Device (DeviceType Nat))
       (dataType' :: DataType DType)
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]).
Catch (dataType &lt;+&gt; dataType') =&gt;
Tensor gradient layout device dataType shape
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     (layout &lt;+&gt; layout')
     (device &lt;+&gt; device')
     ('DataType 'Bool)
     (BroadcastShapesF shape shape')
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Comparison.html#%3D%3D."><span class="hs-operator hs-var">==.</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  device
  ('DataType 'Int64)
  ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1)])
</span><a href="#local-6989586621679677286"><span class="hs-identifier hs-var">padToken</span></a></span><span>
</span><span id="line-425"></span><span>
</span><span id="line-426"></span><span id="local-6989586621679677283"><span id="local-6989586621679677284"></span></span><span class="hs-keyword">newtype</span><span> </span><span id="MkTransformerPaddingMask"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerPaddingMask"><span class="hs-identifier hs-var">MkTransformerPaddingMask</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span id="MkTransformerPaddingMask"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerPaddingMask"><span class="hs-identifier hs-var">MkTransformerPaddingMask</span></a></span></span><span> </span><span class="hs-special">{</span><span id="padTokenId"><span class="annot"><span class="annottext">MkTransformerPaddingMask -&gt; Int
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#padTokenId"><span class="hs-identifier hs-var hs-var">padTokenId</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">}</span><span>
</span><span id="line-427"></span><span>  </span><span class="hs-keyword">deriving</span><span> </span><span class="annot"><span class="hs-keyword">stock</span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679677275"><span id="local-6989586621679677277"><span id="local-6989586621679677279"><span class="annot"><span class="annottext">Int -&gt; MkTransformerPaddingMask -&gt; ShowS
[MkTransformerPaddingMask] -&gt; ShowS
MkTransformerPaddingMask -&gt; String
(Int -&gt; MkTransformerPaddingMask -&gt; ShowS)
-&gt; (MkTransformerPaddingMask -&gt; String)
-&gt; ([MkTransformerPaddingMask] -&gt; ShowS)
-&gt; Show MkTransformerPaddingMask
forall a.
(Int -&gt; a -&gt; ShowS) -&gt; (a -&gt; String) -&gt; ([a] -&gt; ShowS) -&gt; Show a
showList :: [MkTransformerPaddingMask] -&gt; ShowS
$cshowList :: [MkTransformerPaddingMask] -&gt; ShowS
show :: MkTransformerPaddingMask -&gt; String
$cshow :: MkTransformerPaddingMask -&gt; String
showsPrec :: Int -&gt; MkTransformerPaddingMask -&gt; ShowS
$cshowsPrec :: Int -&gt; MkTransformerPaddingMask -&gt; ShowS
</span><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">Show</span></span></span></span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">(forall x.
 MkTransformerPaddingMask -&gt; Rep MkTransformerPaddingMask x)
-&gt; (forall x.
    Rep MkTransformerPaddingMask x -&gt; MkTransformerPaddingMask)
-&gt; Generic MkTransformerPaddingMask
forall x.
Rep MkTransformerPaddingMask x -&gt; MkTransformerPaddingMask
forall x.
MkTransformerPaddingMask -&gt; Rep MkTransformerPaddingMask x
forall a.
(forall x. a -&gt; Rep a x) -&gt; (forall x. Rep a x -&gt; a) -&gt; Generic a
$cto :: forall x.
Rep MkTransformerPaddingMask x -&gt; MkTransformerPaddingMask
$cfrom :: forall x.
MkTransformerPaddingMask -&gt; Rep MkTransformerPaddingMask x
</span><span class="hs-identifier hs-var hs-var hs-var hs-var">Generic</span></span><span class="hs-special">)</span><span>
</span><span id="line-428"></span><span>
</span><span id="line-429"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">instance</span><span>
</span><span id="line-430"></span><span>  </span><span id="ModelSpec"><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier hs-var">ModelSpec</span></a></span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerPaddingMask"><span class="hs-identifier hs-type">MkTransformerPaddingMask</span></a></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-431"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerPaddingMask"><span class="hs-identifier hs-type">MkTransformerPaddingMask</span></a></span><span>
</span><span id="line-432"></span><span>
</span><span id="line-433"></span><span id="local-6989586621679677272"><span class="hs-keyword">instance</span><span>
</span><span id="line-434"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span>
</span><span id="line-435"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerPaddingMask"><span class="hs-identifier hs-type">MkTransformerPaddingMask</span></a></span><span>
</span><span id="line-436"></span><span>    </span><span class="annot"><a href="#local-6989586621679677272"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-437"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerPaddingMask"><span class="hs-identifier hs-type">MkTransformerPaddingMask</span></a></span><span>
</span><span id="line-438"></span><span>    </span><span class="annot"><a href="#local-6989586621679677272"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-439"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-440"></span><span>  </span><span id="local-6989586621679677270"><span class="annot"><span class="annottext">initialize :: ModelSpec MkTransformerPaddingMask
-&gt; Generator generatorDevice
-&gt; m (MkTransformerPaddingMask, Generator generatorDevice)
</span><a href="#local-6989586621679677270"><span class="hs-identifier hs-var hs-var hs-var hs-var">initialize</span></a></span></span><span> </span><span id="local-6989586621679677269"><span class="annot"><span class="annottext">ModelSpec MkTransformerPaddingMask
</span><a href="#local-6989586621679677269"><span class="hs-identifier hs-var">spec</span></a></span></span><span> </span><span id="local-6989586621679677268"><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679677268"><span class="hs-identifier hs-var">g</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(MkTransformerPaddingMask, Generator generatorDevice)
-&gt; m (MkTransformerPaddingMask, Generator generatorDevice)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">ModelSpec MkTransformerPaddingMask
MkTransformerPaddingMask
</span><a href="#local-6989586621679677269"><span class="hs-identifier hs-var">spec</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679677268"><span class="hs-identifier hs-var">g</span></a></span><span class="hs-special">)</span></span><span>
</span><span id="line-441"></span><span>
</span><span id="line-442"></span><span class="hs-keyword">instance</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasStateDict"><span class="hs-identifier hs-type">HasStateDict</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerPaddingMask"><span class="hs-identifier hs-type">MkTransformerPaddingMask</span></a></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-443"></span><span>  </span><span id="local-6989586621679677265"><span class="annot"><span class="annottext">fromStateDict :: ModelSpec MkTransformerPaddingMask
-&gt; StateDictKey -&gt; m MkTransformerPaddingMask
</span><a href="#local-6989586621679677265"><span class="hs-identifier hs-var hs-var hs-var hs-var">fromStateDict</span></a></span></span><span> </span><span id="local-6989586621679677264"><span class="annot"><span class="annottext">ModelSpec MkTransformerPaddingMask
</span><a href="#local-6989586621679677264"><span class="hs-identifier hs-var">spec</span></a></span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">MkTransformerPaddingMask -&gt; m MkTransformerPaddingMask
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">ModelSpec MkTransformerPaddingMask
MkTransformerPaddingMask
</span><a href="#local-6989586621679677264"><span class="hs-identifier hs-var">spec</span></a></span><span>
</span><span id="line-444"></span><span>  </span><span id="local-6989586621679677263"><span class="annot"><span class="annottext">toStateDict :: StateDictKey -&gt; MkTransformerPaddingMask -&gt; m ()
</span><a href="#local-6989586621679677263"><span class="hs-identifier hs-var hs-var hs-var hs-var">toStateDict</span></a></span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="annottext">MkTransformerPaddingMask
</span><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">() -&gt; m ()
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-445"></span><span>
</span><span id="line-446"></span><span id="local-6989586621679677256"><span id="local-6989586621679677257"><span id="local-6989586621679677258"><span id="local-6989586621679677259"><span id="local-6989586621679677260"><span id="local-6989586621679677261"><span id="local-6989586621679677262"><span class="hs-keyword">instance</span><span>
</span><span id="line-447"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerPaddingMaskC"><span class="hs-identifier hs-type">MkTransformerPaddingMaskC</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677262"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677261"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677260"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677259"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677258"><span class="hs-identifier hs-type">output</span></a></span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-448"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-449"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerPaddingMask"><span class="hs-identifier hs-type">MkTransformerPaddingMask</span></a></span><span>
</span><span id="line-450"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677257"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677262"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677261"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677260"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677259"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-451"></span><span>    </span><span class="annot"><a href="#local-6989586621679677256"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-452"></span><span>    </span><span class="annot"><a href="#local-6989586621679677258"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-453"></span><span>    </span><span class="annot"><a href="#local-6989586621679677256"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-454"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-455"></span><span>  </span><span id="local-6989586621679677254"><span class="annot"><span class="annottext">forward :: MkTransformerPaddingMask
-&gt; Tensor gradient layout device dataType shape
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorDevice)
</span><a href="#local-6989586621679677254"><span class="hs-identifier hs-var hs-var hs-var hs-var">forward</span></a></span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerPaddingMask"><span class="hs-identifier hs-type">MkTransformerPaddingMask</span></a></span><span> </span><span class="hs-special">{</span><span id="local-6989586621679677253"><span class="annot"><span class="annottext">Int
padTokenId :: Int
padTokenId :: MkTransformerPaddingMask -&gt; Int
</span><a href="#local-6989586621679677253"><span class="hs-glyph hs-var hs-var">..</span></a></span></span><span class="hs-special">}</span><span> </span><span id="local-6989586621679677252"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679677252"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span id="local-6989586621679677251"><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679677251"><span class="hs-identifier hs-var">g</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-456"></span><span>    </span><span id="local-6989586621679677250"><span class="annot"><span class="annottext">output
</span><a href="#local-6989586621679677250"><span class="hs-identifier hs-var">paddingMask</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">Int -&gt; Tensor gradient layout device dataType shape -&gt; m output
forall (m :: * -&gt; *) (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]) output.
(MonadThrow m,
 MkTransformerPaddingMaskC layout device dataType shape output) =&gt;
Int -&gt; Tensor gradient layout device dataType shape -&gt; m output
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#mkTransformerPaddingMask"><span class="hs-identifier hs-var">mkTransformerPaddingMask</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679677253"><span class="hs-identifier hs-var">padTokenId</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679677252"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-457"></span><span>    </span><span class="annot"><span class="annottext">(output, Generator generatorDevice)
-&gt; m (output, Generator generatorDevice)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">output
</span><a href="#local-6989586621679677250"><span class="hs-identifier hs-var">paddingMask</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679677251"><span class="hs-identifier hs-var">g</span></a></span><span class="hs-special">)</span></span></span></span></span></span></span></span><span>
</span><span id="line-458"></span><span>
</span><span id="line-459"></span><span class="hs-keyword">type</span><span> </span><span id="MkTransformerAttentionMaskC"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerAttentionMaskC"><span class="hs-identifier hs-var">MkTransformerAttentionMaskC</span></a></span></span><span> </span><span id="local-6989586621679677249"><span class="annot"><a href="#local-6989586621679677249"><span class="hs-identifier hs-type">transformerDataType</span></a></span></span><span> </span><span id="local-6989586621679677248"><span class="annot"><a href="#local-6989586621679677248"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679677247"><span class="annot"><a href="#local-6989586621679677247"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679677246"><span class="annot"><a href="#local-6989586621679677246"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679677245"><span class="annot"><a href="#local-6989586621679677245"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679677244"><span class="annot"><a href="#local-6989586621679677244"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679677243"><span class="annot"><a href="#local-6989586621679677243"><span class="hs-identifier hs-type">seqDim</span></a></span></span><span> </span><span id="local-6989586621679677242"><span class="annot"><a href="#local-6989586621679677242"><span class="hs-identifier hs-type">output</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-460"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetLayout"><span class="hs-identifier hs-type">SGetLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677247"><span class="hs-identifier hs-type">layout</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-461"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetDevice"><span class="hs-identifier hs-type">SGetDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677246"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-462"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetShape"><span class="hs-identifier hs-type">SGetShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677244"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-463"></span><span>    </span><span class="annot"><a href="#local-6989586621679677243"><span class="hs-identifier hs-type">seqDim</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679677244"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#%21"><span class="hs-glyph hs-type">!</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-464"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Catch"><span class="hs-identifier hs-type">Catch</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679677248"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#WithoutGradient"><span class="hs-identifier hs-type">WithoutGradient</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-465"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Catch"><span class="hs-identifier hs-type">Catch</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679677245"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#Bool"><span class="hs-identifier hs-type">Bool</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-466"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Catch"><span class="hs-identifier hs-type">Catch</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#UnsqueezeF"><span class="hs-identifier hs-type">UnsqueezeF</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679677244"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-467"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Catch"><span class="hs-identifier hs-type">Catch</span></a></span><span>
</span><span id="line-468"></span><span>      </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#BroadcastShapesF"><span class="hs-identifier hs-type">BroadcastShapesF</span></a></span><span>
</span><span id="line-469"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#UnsqueezeF"><span class="hs-identifier hs-type">UnsqueezeF</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679677244"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-470"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679677243"><span class="hs-identifier hs-type">seqDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679677243"><span class="hs-identifier hs-type">seqDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-471"></span><span>      </span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-472"></span><span>    </span><span class="annot"><a href="#local-6989586621679677242"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-473"></span><span>      </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-474"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#WithoutGradient"><span class="hs-identifier hs-type">WithoutGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-475"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679677247"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Dense"><span class="hs-identifier hs-type">Dense</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-476"></span><span>          </span><span class="annot"><a href="#local-6989586621679677246"><span class="hs-identifier hs-type">device</span></a></span><span>
</span><span id="line-477"></span><span>          </span><span class="annot"><a href="#local-6989586621679677249"><span class="hs-identifier hs-type">transformerDataType</span></a></span><span>
</span><span id="line-478"></span><span>          </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#BroadcastShapesF"><span class="hs-identifier hs-type">BroadcastShapesF</span></a></span><span>
</span><span id="line-479"></span><span>              </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#UnsqueezeF"><span class="hs-identifier hs-type">UnsqueezeF</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679677244"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-480"></span><span>              </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679677243"><span class="hs-identifier hs-type">seqDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679677243"><span class="hs-identifier hs-type">seqDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-481"></span><span>          </span><span class="hs-special">)</span><span>
</span><span id="line-482"></span><span>  </span><span class="hs-special">)</span><span>
</span><span id="line-483"></span><span>
</span><span id="line-484"></span><span class="hs-comment">-- | Creates a bidirectional attention mask for a transformer.</span><span>
</span><span id="line-485"></span><span class="hs-comment">-- Given a padding mask of shape @[batchDim, seqDim]@,</span><span>
</span><span id="line-486"></span><span class="hs-comment">-- returns a tensor of shape @[batchDim, seqDim, seqDim]@.</span><span>
</span><span id="line-487"></span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#mkTransformerAttentionMask"><span class="hs-identifier hs-type">mkTransformerAttentionMask</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-488"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679677825"><span class="annot"><a href="#local-6989586621679677825"><span class="hs-identifier hs-type">m</span></a></span></span><span> </span><span id="local-6989586621679677824"><span class="annot"><a href="#local-6989586621679677824"><span class="hs-identifier hs-type">transformerDataType</span></a></span></span><span> </span><span id="local-6989586621679677823"><span class="annot"><a href="#local-6989586621679677823"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679677822"><span class="annot"><a href="#local-6989586621679677822"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679677821"><span class="annot"><a href="#local-6989586621679677821"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679677820"><span class="annot"><a href="#local-6989586621679677820"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679677819"><span class="annot"><a href="#local-6989586621679677819"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679677818"><span class="annot"><a href="#local-6989586621679677818"><span class="hs-identifier hs-type">seqDim</span></a></span></span><span> </span><span id="local-6989586621679677817"><span class="annot"><a href="#local-6989586621679677817"><span class="hs-identifier hs-type">output</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-489"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier hs-type">MonadThrow</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677825"><span class="hs-identifier hs-type">m</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-490"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerAttentionMaskC"><span class="hs-identifier hs-type">MkTransformerAttentionMaskC</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677824"><span class="hs-identifier hs-type">transformerDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677823"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677822"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677821"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677820"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677819"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677818"><span class="hs-identifier hs-type">seqDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677817"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-491"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-492"></span><span>  </span><span class="hs-comment">-- | data type singleton of the transformer</span><span>
</span><span id="line-493"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier hs-type">SDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677824"><span class="hs-identifier hs-type">transformerDataType</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-494"></span><span>  </span><span class="hs-comment">-- | attention mask bias (typically a large negative number)</span><span>
</span><span id="line-495"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-496"></span><span>  </span><span class="hs-comment">-- | encoder padding mask</span><span>
</span><span id="line-497"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677823"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677822"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677821"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677820"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677819"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-498"></span><span>  </span><span class="annot"><a href="#local-6989586621679677825"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677817"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-499"></span><span id="mkTransformerAttentionMask"><span class="annot"><span class="annottext">mkTransformerAttentionMask :: SDataType transformerDataType
-&gt; Double
-&gt; Tensor gradient layout device dataType shape
-&gt; m output
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#mkTransformerAttentionMask"><span class="hs-identifier hs-var hs-var">mkTransformerAttentionMask</span></a></span></span><span> </span><span id="local-6989586621679677240"><span class="annot"><span class="annottext">SDataType transformerDataType
</span><a href="#local-6989586621679677240"><span class="hs-identifier hs-var">transformerDataType</span></a></span></span><span> </span><span id="local-6989586621679677239"><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679677239"><span class="hs-identifier hs-var">attentionMaskBias</span></a></span></span><span> </span><span id="local-6989586621679677238"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679677238"><span class="hs-identifier hs-var">paddingMask</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-500"></span><span>  </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679677237"><span class="annot"><span class="annottext">pmLayout :: SLayout layout
</span><a href="#local-6989586621679677237"><span class="hs-identifier hs-var hs-var">pmLayout</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape -&gt; SLayout layout
forall (layout :: Layout LayoutType)
       (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SGetLayout layout =&gt;
Tensor gradient layout device dataType shape -&gt; SLayout layout
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sGetLayout"><span class="hs-identifier hs-var">sGetLayout</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679677238"><span class="hs-identifier hs-var">paddingMask</span></a></span><span>
</span><span id="line-501"></span><span>      </span><span id="local-6989586621679677235"><span class="annot"><span class="annottext">pmDevice :: SDevice device
</span><a href="#local-6989586621679677235"><span class="hs-identifier hs-var hs-var">pmDevice</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape -&gt; SDevice device
forall (device :: Device (DeviceType Nat))
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SGetDevice device =&gt;
Tensor gradient layout device dataType shape -&gt; SDevice device
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sGetDevice"><span class="hs-identifier hs-var">sGetDevice</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679677238"><span class="hs-identifier hs-var">paddingMask</span></a></span><span>
</span><span id="line-502"></span><span>      </span><span id="local-6989586621679677234"><span class="annot"><span class="annottext">pmShape :: SShape shape
</span><a href="#local-6989586621679677234"><span class="hs-identifier hs-var hs-var">pmShape</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape -&gt; SShape shape
forall (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType).
SGetShape shape =&gt;
Tensor gradient layout device dataType shape -&gt; SShape shape
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sGetShape"><span class="hs-identifier hs-var">sGetShape</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679677238"><span class="hs-identifier hs-var">paddingMask</span></a></span><span>
</span><span id="line-503"></span><span>  </span><span id="local-6989586621679677233"><span class="annot"><span class="annottext">SDim seqDim
</span><a href="#local-6989586621679677233"><span class="hs-identifier hs-var">pmSeqDim</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">SSelectDim ('SelectDim ('ByIndex 1))
-&gt; SShape shape -&gt; m (SDim seqDim)
forall (selectDim :: SelectDim (By Symbol Nat))
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (dim :: Dim (Name Symbol) (Size Nat)) (m :: * -&gt; *).
(dim ~ GetDimF selectDim shape, MonadThrow m) =&gt;
SSelectDim selectDim -&gt; SShape shape -&gt; m (SDim dim)
</span><a href="Torch.GraduallyTyped.Shape.Class.html#sGetDimFromShape"><span class="hs-identifier hs-var">sGetDimFromShape</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SBy ('ByIndex 1) -&gt; SSelectDim ('SelectDim ('ByIndex 1))
forall (by :: By Symbol Nat). SBy by -&gt; SSelectDim ('SelectDim by)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSelectDim"><span class="hs-identifier hs-var">SSelectDim</span></a></span><span> </span><span class="annot"><span class="annottext">(SBy ('ByIndex 1) -&gt; SSelectDim ('SelectDim ('ByIndex 1)))
-&gt; SBy ('ByIndex 1) -&gt; SSelectDim ('SelectDim ('ByIndex 1))
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">KnownNat 1 =&gt; SBy ('ByIndex 1)
forall (index :: Nat). KnownNat index =&gt; SBy ('ByIndex index)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SByIndex"><span class="hs-identifier hs-var">SByIndex</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">SShape shape
</span><a href="#local-6989586621679677234"><span class="hs-identifier hs-var">pmShape</span></a></span><span>
</span><span id="line-504"></span><span>  </span><span id="local-6989586621679677232"><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  layout
  device
  transformerDataType
  ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim])
</span><a href="#local-6989586621679677232"><span class="hs-identifier hs-var">emptyMask</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span>
</span><span id="line-505"></span><span>    </span><span class="annot"><span class="annottext">TensorSpec
  ('Gradient 'WithoutGradient)
  layout
  device
  transformerDataType
  ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim])
-&gt; m (Tensor
        ('Gradient 'WithoutGradient)
        layout
        device
        transformerDataType
        ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim]))
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]) (m :: * -&gt; *).
MonadThrow m =&gt;
TensorSpec gradient layout device dataType shape
-&gt; m (Tensor gradient layout device dataType shape)
</span><a href="Torch.GraduallyTyped.Tensor.Creation.html#sZeros"><span class="hs-identifier hs-var">sZeros</span></a></span><span> </span><span class="annot"><span class="annottext">(TensorSpec
   ('Gradient 'WithoutGradient)
   layout
   device
   transformerDataType
   ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim])
 -&gt; m (Tensor
         ('Gradient 'WithoutGradient)
         layout
         device
         transformerDataType
         ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim])))
-&gt; TensorSpec
     ('Gradient 'WithoutGradient)
     layout
     device
     transformerDataType
     ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim])
-&gt; m (Tensor
        ('Gradient 'WithoutGradient)
        layout
        device
        transformerDataType
        ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim]))
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-506"></span><span>      </span><span class="annot"><span class="annottext">SGradient ('Gradient 'WithoutGradient)
-&gt; SLayout layout
-&gt; SDevice device
-&gt; SDataType transformerDataType
-&gt; SShape ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim])
-&gt; TensorSpec
     ('Gradient 'WithoutGradient)
     layout
     device
     transformerDataType
     ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim])
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SShape shape
-&gt; TensorSpec gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorSpec"><span class="hs-identifier hs-var">TensorSpec</span></a></span><span>
</span><span id="line-507"></span><span>        </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SRequiresGradient 'WithoutGradient
-&gt; SGradient ('Gradient 'WithoutGradient)
forall (requiresGradient :: RequiresGradient).
SRequiresGradient requiresGradient
-&gt; SGradient ('Gradient requiresGradient)
</span><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier hs-var">SGradient</span></a></span><span> </span><span class="annot"><span class="annottext">SRequiresGradient 'WithoutGradient
</span><a href="Torch.GraduallyTyped.RequiresGradient.html#SWithoutGradient"><span class="hs-identifier hs-var">SWithoutGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-508"></span><span>        </span><span class="annot"><span class="annottext">SLayout layout
</span><a href="#local-6989586621679677237"><span class="hs-identifier hs-var">pmLayout</span></a></span><span>
</span><span id="line-509"></span><span>        </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679677235"><span class="hs-identifier hs-var">pmDevice</span></a></span><span>
</span><span id="line-510"></span><span>        </span><span class="annot"><span class="annottext">SDataType transformerDataType
</span><a href="#local-6989586621679677240"><span class="hs-identifier hs-var">transformerDataType</span></a></span><span>
</span><span id="line-511"></span><span>        </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SList '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim]
-&gt; SShape ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim]
 -&gt; SShape ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim]))
-&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim]
-&gt; SShape ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize ('Size 1) -&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 1))
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownNat 1 =&gt; SSize ('Size 1)
forall (size :: Nat). KnownNat size =&gt; SSize ('Size size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier hs-var">SSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">1</span></span><span> </span><span class="annot"><span class="annottext">Sing ('Dim ('Name &quot;*&quot;) ('Size 1))
-&gt; SList '[seqDim, seqDim]
-&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim]
forall a1 (a2 :: a1) (as :: [a1]).
Sing a2 -&gt; SList as -&gt; SList (a2 : as)
</span><a href="Torch.GraduallyTyped.Prelude.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">Sing seqDim
SDim seqDim
</span><a href="#local-6989586621679677233"><span class="hs-identifier hs-var">pmSeqDim</span></a></span><span> </span><span class="annot"><span class="annottext">Sing seqDim -&gt; SList '[seqDim] -&gt; SList '[seqDim, seqDim]
forall a1 (a2 :: a1) (as :: [a1]).
Sing a2 -&gt; SList as -&gt; SList (a2 : as)
</span><a href="Torch.GraduallyTyped.Prelude.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">Sing seqDim
SDim seqDim
</span><a href="#local-6989586621679677233"><span class="hs-identifier hs-var">pmSeqDim</span></a></span><span> </span><span class="annot"><span class="annottext">Sing seqDim -&gt; SList '[] -&gt; SList '[seqDim]
forall a1 (a2 :: a1) (as :: [a1]).
Sing a2 -&gt; SList as -&gt; SList (a2 : as)
</span><a href="Torch.GraduallyTyped.Prelude.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-512"></span><span>  </span><span id="local-6989586621679677231"><span class="annot"><span class="annottext">Tensor
  gradient
  layout
  device
  dataType
  (UnsqueezeF ('SelectDim ('ByIndex 1)) shape)
</span><a href="#local-6989586621679677231"><span class="hs-identifier hs-var">paddingMask'</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
-&gt; m (Tensor
        gradient
        layout
        device
        dataType
        (UnsqueezeF ('SelectDim ('ByIndex 1)) shape))
forall (selectDim :: SelectDim (By Symbol Nat))
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]) (m :: * -&gt; *).
(shape' ~ UnsqueezeF selectDim shape, Catch shape',
 SingI selectDim, MonadThrow m) =&gt;
Tensor gradient layout device dataType shape
-&gt; m (Tensor gradient layout device dataType shape')
</span><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#unsqueeze"><span class="hs-identifier hs-var">unsqueeze</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679677238"><span class="hs-identifier hs-var">paddingMask</span></a></span><span>
</span><span id="line-513"></span><span>  </span><span class="annot"><span class="annottext">Tensor
  gradient
  layout
  device
  dataType
  (UnsqueezeF ('SelectDim ('ByIndex 1)) shape)
-&gt; Double
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     layout
     device
     transformerDataType
     ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim])
-&gt; m (Tensor
        ('Gradient 'WithoutGradient)
        (layout &lt;+&gt; (layout &lt;+&gt; 'Layout 'Dense))
        (device &lt;+&gt; device)
        transformerDataType
        (BroadcastShapesF
           (UnsqueezeF ('SelectDim ('ByIndex 1)) shape)
           ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim])))
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]) value
       (gradient' :: Gradient RequiresGradient)
       (layout' :: Layout LayoutType) (device' :: Device (DeviceType Nat))
       (dataType' :: DataType DType)
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)])
       (shape'' :: Shape [Dim (Name Symbol) (Size Nat)]) (m :: * -&gt; *).
(Scalar value, MonadThrow m,
 Catch (gradient &lt;+&gt; 'Gradient 'WithoutGradient),
 Catch (dataType &lt;+&gt; 'DataType 'Bool),
 shape'' ~ BroadcastShapesF shape shape', Catch shape'') =&gt;
Tensor gradient layout device dataType shape
-&gt; value
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; m (Tensor
        gradient'
        (layout &lt;+&gt; (layout' &lt;+&gt; 'Layout 'Dense))
        (device &lt;+&gt; device')
        dataType'
        shape'')
</span><a href="Torch.GraduallyTyped.Tensor.Other.html#maskedFill"><span class="hs-identifier hs-var">maskedFill</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  gradient
  layout
  device
  dataType
  (UnsqueezeF ('SelectDim ('ByIndex 1)) shape)
</span><a href="#local-6989586621679677231"><span class="hs-identifier hs-var">paddingMask'</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679677239"><span class="hs-identifier hs-var">attentionMaskBias</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  layout
  device
  transformerDataType
  ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim])
</span><a href="#local-6989586621679677232"><span class="hs-identifier hs-var">emptyMask</span></a></span><span>
</span><span id="line-514"></span><span>
</span><span id="line-515"></span><span id="local-6989586621679677229"><span id="local-6989586621679677230"></span></span><span class="hs-keyword">data</span><span> </span><span id="MkTransformerAttentionMask"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerAttentionMask"><span class="hs-identifier hs-var">MkTransformerAttentionMask</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679677228"><span class="annot"><a href="#local-6989586621679677228"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier hs-type">DType</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-516"></span><span>  </span><span id="MkTransformerAttentionMask"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerAttentionMask"><span class="hs-identifier hs-var">MkTransformerAttentionMask</span></a></span></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-517"></span><span>    </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679677826"><span class="annot"><a href="#local-6989586621679677826"><span class="hs-identifier hs-type">dataType</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-518"></span><span>    </span><span class="hs-special">{</span><span> </span><span id="attentionMaskDataType"><span class="annot"><span class="annottext">MkTransformerAttentionMask dataType -&gt; SDataType dataType
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#attentionMaskDataType"><span class="hs-identifier hs-var hs-var">attentionMaskDataType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier hs-type">SDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677826"><span class="hs-identifier hs-type">dataType</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-519"></span><span>      </span><span id="attentionMaskBias"><span class="annot"><span class="annottext">MkTransformerAttentionMask dataType -&gt; Double
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#attentionMaskBias"><span class="hs-identifier hs-var hs-var">attentionMaskBias</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span>
</span><span id="line-520"></span><span>    </span><span class="hs-special">}</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-521"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerAttentionMask"><span class="hs-identifier hs-type">MkTransformerAttentionMask</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677826"><span class="hs-identifier hs-type">dataType</span></a></span><span>
</span><span id="line-522"></span><span>  </span><span class="hs-keyword">deriving</span><span> </span><span class="annot"><span class="hs-keyword">stock</span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679677219"><span id="local-6989586621679677221"><span id="local-6989586621679677223"><span class="annot"><span class="annottext">Int -&gt; MkTransformerAttentionMask dataType -&gt; ShowS
[MkTransformerAttentionMask dataType] -&gt; ShowS
MkTransformerAttentionMask dataType -&gt; String
(Int -&gt; MkTransformerAttentionMask dataType -&gt; ShowS)
-&gt; (MkTransformerAttentionMask dataType -&gt; String)
-&gt; ([MkTransformerAttentionMask dataType] -&gt; ShowS)
-&gt; Show (MkTransformerAttentionMask dataType)
forall a.
(Int -&gt; a -&gt; ShowS) -&gt; (a -&gt; String) -&gt; ([a] -&gt; ShowS) -&gt; Show a
forall (dataType :: DataType DType).
Int -&gt; MkTransformerAttentionMask dataType -&gt; ShowS
forall (dataType :: DataType DType).
[MkTransformerAttentionMask dataType] -&gt; ShowS
forall (dataType :: DataType DType).
MkTransformerAttentionMask dataType -&gt; String
showList :: [MkTransformerAttentionMask dataType] -&gt; ShowS
$cshowList :: forall (dataType :: DataType DType).
[MkTransformerAttentionMask dataType] -&gt; ShowS
show :: MkTransformerAttentionMask dataType -&gt; String
$cshow :: forall (dataType :: DataType DType).
MkTransformerAttentionMask dataType -&gt; String
showsPrec :: Int -&gt; MkTransformerAttentionMask dataType -&gt; ShowS
$cshowsPrec :: forall (dataType :: DataType DType).
Int -&gt; MkTransformerAttentionMask dataType -&gt; ShowS
</span><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">Show</span></span></span></span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">(forall x.
 MkTransformerAttentionMask dataType
 -&gt; Rep (MkTransformerAttentionMask dataType) x)
-&gt; (forall x.
    Rep (MkTransformerAttentionMask dataType) x
    -&gt; MkTransformerAttentionMask dataType)
-&gt; Generic (MkTransformerAttentionMask dataType)
forall x.
Rep (MkTransformerAttentionMask dataType) x
-&gt; MkTransformerAttentionMask dataType
forall x.
MkTransformerAttentionMask dataType
-&gt; Rep (MkTransformerAttentionMask dataType) x
forall a.
(forall x. a -&gt; Rep a x) -&gt; (forall x. Rep a x -&gt; a) -&gt; Generic a
forall (dataType :: DataType DType) x.
Rep (MkTransformerAttentionMask dataType) x
-&gt; MkTransformerAttentionMask dataType
forall (dataType :: DataType DType) x.
MkTransformerAttentionMask dataType
-&gt; Rep (MkTransformerAttentionMask dataType) x
$cto :: forall (dataType :: DataType DType) x.
Rep (MkTransformerAttentionMask dataType) x
-&gt; MkTransformerAttentionMask dataType
$cfrom :: forall (dataType :: DataType DType) x.
MkTransformerAttentionMask dataType
-&gt; Rep (MkTransformerAttentionMask dataType) x
</span><span class="hs-identifier hs-var hs-var hs-var hs-var">Generic</span></span><span class="hs-special">)</span><span>
</span><span id="line-523"></span><span>
</span><span id="line-524"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">instance</span><span>
</span><span id="line-525"></span><span>  </span><span id="ModelSpec"><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier hs-var">ModelSpec</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerAttentionMask"><span class="hs-identifier hs-type">MkTransformerAttentionMask</span></a></span><span> </span><span id="local-6989586621679677216"><span class="annot"><a href="#local-6989586621679677216"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-526"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerAttentionMask"><span class="hs-identifier hs-type">MkTransformerAttentionMask</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677216"><span class="hs-identifier hs-type">dataType</span></a></span><span>
</span><span id="line-527"></span><span>
</span><span id="line-528"></span><span id="local-6989586621679677214"><span id="local-6989586621679677215"><span class="hs-keyword">instance</span><span>
</span><span id="line-529"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span>
</span><span id="line-530"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerAttentionMask"><span class="hs-identifier hs-type">MkTransformerAttentionMask</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677215"><span class="hs-identifier hs-type">dataType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-531"></span><span>    </span><span class="annot"><a href="#local-6989586621679677214"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-532"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerAttentionMask"><span class="hs-identifier hs-type">MkTransformerAttentionMask</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677215"><span class="hs-identifier hs-type">dataType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-533"></span><span>    </span><span class="annot"><a href="#local-6989586621679677214"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-534"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-535"></span><span>  </span><span id="local-6989586621679677212"><span class="annot"><span class="annottext">initialize :: ModelSpec (MkTransformerAttentionMask dataType)
-&gt; Generator generatorDevice
-&gt; m (MkTransformerAttentionMask dataType,
      Generator generatorDevice)
</span><a href="#local-6989586621679677212"><span class="hs-identifier hs-var hs-var hs-var hs-var">initialize</span></a></span></span><span> </span><span id="local-6989586621679677211"><span class="annot"><span class="annottext">ModelSpec (MkTransformerAttentionMask dataType)
</span><a href="#local-6989586621679677211"><span class="hs-identifier hs-var">spec</span></a></span></span><span> </span><span id="local-6989586621679677210"><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679677210"><span class="hs-identifier hs-var">g</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(MkTransformerAttentionMask dataType, Generator generatorDevice)
-&gt; m (MkTransformerAttentionMask dataType,
      Generator generatorDevice)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">ModelSpec (MkTransformerAttentionMask dataType)
MkTransformerAttentionMask dataType
</span><a href="#local-6989586621679677211"><span class="hs-identifier hs-var">spec</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679677210"><span class="hs-identifier hs-var">g</span></a></span><span class="hs-special">)</span></span></span><span>
</span><span id="line-536"></span><span>
</span><span id="line-537"></span><span id="local-6989586621679677209"><span class="hs-keyword">instance</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasStateDict"><span class="hs-identifier hs-type">HasStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerAttentionMask"><span class="hs-identifier hs-type">MkTransformerAttentionMask</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677209"><span class="hs-identifier hs-type">dataType</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-538"></span><span>  </span><span id="local-6989586621679677206"><span class="annot"><span class="annottext">fromStateDict :: ModelSpec (MkTransformerAttentionMask dataType)
-&gt; StateDictKey -&gt; m (MkTransformerAttentionMask dataType)
</span><a href="#local-6989586621679677206"><span class="hs-identifier hs-var hs-var hs-var hs-var">fromStateDict</span></a></span></span><span> </span><span id="local-6989586621679677205"><span class="annot"><span class="annottext">ModelSpec (MkTransformerAttentionMask dataType)
</span><a href="#local-6989586621679677205"><span class="hs-identifier hs-var">spec</span></a></span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">MkTransformerAttentionMask dataType
-&gt; m (MkTransformerAttentionMask dataType)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">ModelSpec (MkTransformerAttentionMask dataType)
MkTransformerAttentionMask dataType
</span><a href="#local-6989586621679677205"><span class="hs-identifier hs-var">spec</span></a></span><span>
</span><span id="line-539"></span><span>  </span><span id="local-6989586621679677204"><span class="annot"><span class="annottext">toStateDict :: StateDictKey -&gt; MkTransformerAttentionMask dataType -&gt; m ()
</span><a href="#local-6989586621679677204"><span class="hs-identifier hs-var hs-var hs-var hs-var">toStateDict</span></a></span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="annottext">MkTransformerAttentionMask dataType
</span><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">() -&gt; m ()
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span></span><span>
</span><span id="line-540"></span><span>
</span><span id="line-541"></span><span id="local-6989586621679677195"><span id="local-6989586621679677196"><span id="local-6989586621679677197"><span id="local-6989586621679677198"><span id="local-6989586621679677199"><span id="local-6989586621679677200"><span id="local-6989586621679677201"><span id="local-6989586621679677202"><span id="local-6989586621679677203"><span class="hs-keyword">instance</span><span>
</span><span id="line-542"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerAttentionMaskC"><span class="hs-identifier hs-type">MkTransformerAttentionMaskC</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677203"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677202"><span class="hs-identifier hs-type">inputGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677201"><span class="hs-identifier hs-type">inputLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677200"><span class="hs-identifier hs-type">inputDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677199"><span class="hs-identifier hs-type">inputDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677198"><span class="hs-identifier hs-type">inputShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677197"><span class="hs-identifier hs-type">seqDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677196"><span class="hs-identifier hs-type">output</span></a></span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-543"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-544"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerAttentionMask"><span class="hs-identifier hs-type">MkTransformerAttentionMask</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677203"><span class="hs-identifier hs-type">dataType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-545"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677202"><span class="hs-identifier hs-type">inputGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677201"><span class="hs-identifier hs-type">inputLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677200"><span class="hs-identifier hs-type">inputDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677199"><span class="hs-identifier hs-type">inputDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677198"><span class="hs-identifier hs-type">inputShape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-546"></span><span>    </span><span class="annot"><a href="#local-6989586621679677195"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-547"></span><span>    </span><span class="annot"><a href="#local-6989586621679677196"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-548"></span><span>    </span><span class="annot"><a href="#local-6989586621679677195"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-549"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-550"></span><span>  </span><span id="local-6989586621679677193"><span class="annot"><span class="annottext">forward :: MkTransformerAttentionMask dataType
-&gt; Tensor
     inputGradient inputLayout inputDevice inputDataType inputShape
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorDevice)
</span><a href="#local-6989586621679677193"><span class="hs-identifier hs-var hs-var hs-var hs-var">forward</span></a></span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerAttentionMask"><span class="hs-identifier hs-type">MkTransformerAttentionMask</span></a></span><span> </span><span class="hs-special">{</span><span id="local-6989586621679677191"><span id="local-6989586621679677192"><span class="annot"><span class="annottext">Double
SDataType dataType
attentionMaskBias :: Double
attentionMaskDataType :: SDataType dataType
attentionMaskBias :: forall (dataType :: DataType DType).
MkTransformerAttentionMask dataType -&gt; Double
attentionMaskDataType :: forall (dataType :: DataType DType).
MkTransformerAttentionMask dataType -&gt; SDataType dataType
</span><a href="#local-6989586621679677191"><span class="hs-glyph hs-var hs-var hs-var hs-var">..</span></a></span></span></span><span class="hs-special">}</span><span> </span><span id="local-6989586621679677190"><span class="annot"><span class="annottext">Tensor
  inputGradient inputLayout inputDevice inputDataType inputShape
</span><a href="#local-6989586621679677190"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span id="local-6989586621679677189"><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679677189"><span class="hs-identifier hs-var">g</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-551"></span><span>    </span><span id="local-6989586621679677188"><span class="annot"><span class="annottext">output
</span><a href="#local-6989586621679677188"><span class="hs-identifier hs-var">attentionMask</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">SDataType dataType
-&gt; Double
-&gt; Tensor
     inputGradient inputLayout inputDevice inputDataType inputShape
-&gt; m output
forall (m :: * -&gt; *) (transformerDataType :: DataType DType)
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (seqDim :: Dim (Name Symbol) (Size Nat)) output.
(MonadThrow m,
 MkTransformerAttentionMaskC
   transformerDataType
   gradient
   layout
   device
   dataType
   shape
   seqDim
   output) =&gt;
SDataType transformerDataType
-&gt; Double
-&gt; Tensor gradient layout device dataType shape
-&gt; m output
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#mkTransformerAttentionMask"><span class="hs-identifier hs-var">mkTransformerAttentionMask</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679677192"><span class="hs-identifier hs-var">attentionMaskDataType</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679677191"><span class="hs-identifier hs-var">attentionMaskBias</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  inputGradient inputLayout inputDevice inputDataType inputShape
</span><a href="#local-6989586621679677190"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-552"></span><span>    </span><span class="annot"><span class="annottext">(output, Generator generatorDevice)
-&gt; m (output, Generator generatorDevice)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">output
</span><a href="#local-6989586621679677188"><span class="hs-identifier hs-var">attentionMask</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679677189"><span class="hs-identifier hs-var">g</span></a></span><span class="hs-special">)</span></span></span></span></span></span></span></span></span></span><span>
</span><span id="line-553"></span><span>
</span><span id="line-554"></span><span class="hs-keyword">type</span><span> </span><span id="MkTransformerDecoderAttentionMaskC"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerDecoderAttentionMaskC"><span class="hs-identifier hs-var">MkTransformerDecoderAttentionMaskC</span></a></span></span><span> </span><span id="local-6989586621679677187"><span class="annot"><a href="#local-6989586621679677187"><span class="hs-identifier hs-type">transformerDataType</span></a></span></span><span> </span><span id="local-6989586621679677186"><span class="annot"><a href="#local-6989586621679677186"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679677185"><span class="annot"><a href="#local-6989586621679677185"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679677184"><span class="annot"><a href="#local-6989586621679677184"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679677183"><span class="annot"><a href="#local-6989586621679677183"><span class="hs-identifier hs-type">seqDim</span></a></span></span><span> </span><span id="local-6989586621679677182"><span class="annot"><a href="#local-6989586621679677182"><span class="hs-identifier hs-type">output</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-555"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetLayout"><span class="hs-identifier hs-type">SGetLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677186"><span class="hs-identifier hs-type">layout</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-556"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetDevice"><span class="hs-identifier hs-type">SGetDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677185"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-557"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetShape"><span class="hs-identifier hs-type">SGetShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677184"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-558"></span><span>    </span><span class="annot"><a href="#local-6989586621679677183"><span class="hs-identifier hs-type">seqDim</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679677184"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#%21"><span class="hs-glyph hs-type">!</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-559"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Catch"><span class="hs-identifier hs-type">Catch</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677183"><span class="hs-identifier hs-type">seqDim</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-560"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Catch"><span class="hs-identifier hs-type">Catch</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#UnsqueezeF"><span class="hs-identifier hs-type">UnsqueezeF</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679677184"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-561"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Catch"><span class="hs-identifier hs-type">Catch</span></a></span><span>
</span><span id="line-562"></span><span>      </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#BroadcastShapesF"><span class="hs-identifier hs-type">BroadcastShapesF</span></a></span><span>
</span><span id="line-563"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679677183"><span class="hs-identifier hs-type">seqDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679677183"><span class="hs-identifier hs-type">seqDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-564"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#UnsqueezeF"><span class="hs-identifier hs-type">UnsqueezeF</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679677184"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-565"></span><span>      </span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-566"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Catch"><span class="hs-identifier hs-type">Catch</span></a></span><span>
</span><span id="line-567"></span><span>      </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#BroadcastShapesF"><span class="hs-identifier hs-type">BroadcastShapesF</span></a></span><span>
</span><span id="line-568"></span><span>          </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#BroadcastShapesF"><span class="hs-identifier hs-type">BroadcastShapesF</span></a></span><span>
</span><span id="line-569"></span><span>              </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679677183"><span class="hs-identifier hs-type">seqDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679677183"><span class="hs-identifier hs-type">seqDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-570"></span><span>              </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#UnsqueezeF"><span class="hs-identifier hs-type">UnsqueezeF</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679677184"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-571"></span><span>          </span><span class="hs-special">)</span><span>
</span><span id="line-572"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679677183"><span class="hs-identifier hs-type">seqDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679677183"><span class="hs-identifier hs-type">seqDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-573"></span><span>      </span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-574"></span><span>    </span><span class="annot"><a href="#local-6989586621679677182"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-575"></span><span>      </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-576"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#WithoutGradient"><span class="hs-identifier hs-type">WithoutGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-577"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679677186"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Dense"><span class="hs-identifier hs-type">Dense</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-578"></span><span>          </span><span class="annot"><a href="#local-6989586621679677185"><span class="hs-identifier hs-type">device</span></a></span><span>
</span><span id="line-579"></span><span>          </span><span class="annot"><a href="#local-6989586621679677187"><span class="hs-identifier hs-type">transformerDataType</span></a></span><span>
</span><span id="line-580"></span><span>          </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#BroadcastShapesF"><span class="hs-identifier hs-type">BroadcastShapesF</span></a></span><span>
</span><span id="line-581"></span><span>              </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#BroadcastShapesF"><span class="hs-identifier hs-type">BroadcastShapesF</span></a></span><span>
</span><span id="line-582"></span><span>                  </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679677183"><span class="hs-identifier hs-type">seqDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679677183"><span class="hs-identifier hs-type">seqDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-583"></span><span>                  </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#UnsqueezeF"><span class="hs-identifier hs-type">UnsqueezeF</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679677184"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-584"></span><span>              </span><span class="hs-special">)</span><span>
</span><span id="line-585"></span><span>              </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679677183"><span class="hs-identifier hs-type">seqDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679677183"><span class="hs-identifier hs-type">seqDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-586"></span><span>          </span><span class="hs-special">)</span><span>
</span><span id="line-587"></span><span>  </span><span class="hs-special">)</span><span>
</span><span id="line-588"></span><span>
</span><span id="line-589"></span><span class="hs-comment">-- | Creates a causal attention mask for a transformer decoder.</span><span>
</span><span id="line-590"></span><span class="hs-comment">-- Given a padding mask of shape @[batchDim, seqDim]@,</span><span>
</span><span id="line-591"></span><span class="hs-comment">-- returns a tensor of shape @[batchDim, seqDim, seqDim]@.</span><span>
</span><span id="line-592"></span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#mkTransformerDecoderAttentionMask"><span class="hs-identifier hs-type">mkTransformerDecoderAttentionMask</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-593"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679677756"><span class="annot"><a href="#local-6989586621679677756"><span class="hs-identifier hs-type">m</span></a></span></span><span> </span><span id="local-6989586621679677755"><span class="annot"><a href="#local-6989586621679677755"><span class="hs-identifier hs-type">transformerDataType</span></a></span></span><span> </span><span id="local-6989586621679677749"><span class="annot"><a href="#local-6989586621679677749"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679677754"><span class="annot"><a href="#local-6989586621679677754"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679677753"><span class="annot"><a href="#local-6989586621679677753"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679677748"><span class="annot"><a href="#local-6989586621679677748"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679677752"><span class="annot"><a href="#local-6989586621679677752"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679677751"><span class="annot"><a href="#local-6989586621679677751"><span class="hs-identifier hs-type">seqDim</span></a></span></span><span> </span><span id="local-6989586621679677750"><span class="annot"><a href="#local-6989586621679677750"><span class="hs-identifier hs-type">output</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-594"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier hs-type">MonadThrow</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677756"><span class="hs-identifier hs-type">m</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-595"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerDecoderAttentionMaskC"><span class="hs-identifier hs-type">MkTransformerDecoderAttentionMaskC</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677755"><span class="hs-identifier hs-type">transformerDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677754"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677753"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677752"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677751"><span class="hs-identifier hs-type">seqDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677750"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-596"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-597"></span><span>  </span><span class="hs-comment">-- | data type singleton of the transformer</span><span>
</span><span id="line-598"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier hs-type">SDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677755"><span class="hs-identifier hs-type">transformerDataType</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-599"></span><span>  </span><span class="hs-comment">-- | attention mask bias (typically a large negative number)</span><span>
</span><span id="line-600"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-601"></span><span>  </span><span class="hs-comment">-- | decoder padding mask</span><span>
</span><span id="line-602"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677749"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677754"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677753"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677748"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677752"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-603"></span><span>  </span><span class="annot"><a href="#local-6989586621679677756"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677750"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-604"></span><span id="mkTransformerDecoderAttentionMask"><span class="annot"><span class="annottext">mkTransformerDecoderAttentionMask :: SDataType transformerDataType
-&gt; Double
-&gt; Tensor gradient layout device dataType shape
-&gt; m output
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#mkTransformerDecoderAttentionMask"><span class="hs-identifier hs-var hs-var">mkTransformerDecoderAttentionMask</span></a></span></span><span> </span><span id="local-6989586621679677180"><span class="annot"><span class="annottext">SDataType transformerDataType
</span><a href="#local-6989586621679677180"><span class="hs-identifier hs-var">transformerDataType</span></a></span></span><span> </span><span id="local-6989586621679677179"><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679677179"><span class="hs-identifier hs-var">attentionMaskBias</span></a></span></span><span> </span><span id="local-6989586621679677178"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679677178"><span class="hs-identifier hs-var">paddingMask</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-605"></span><span>  </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679677177"><span class="annot"><span class="annottext">pmLayout :: SLayout layout
</span><a href="#local-6989586621679677177"><span class="hs-identifier hs-var hs-var">pmLayout</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape -&gt; SLayout layout
forall (layout :: Layout LayoutType)
       (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SGetLayout layout =&gt;
Tensor gradient layout device dataType shape -&gt; SLayout layout
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sGetLayout"><span class="hs-identifier hs-var">sGetLayout</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679677178"><span class="hs-identifier hs-var">paddingMask</span></a></span><span>
</span><span id="line-606"></span><span>      </span><span id="local-6989586621679677176"><span class="annot"><span class="annottext">pmDevice :: SDevice device
</span><a href="#local-6989586621679677176"><span class="hs-identifier hs-var hs-var">pmDevice</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape -&gt; SDevice device
forall (device :: Device (DeviceType Nat))
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SGetDevice device =&gt;
Tensor gradient layout device dataType shape -&gt; SDevice device
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sGetDevice"><span class="hs-identifier hs-var">sGetDevice</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679677178"><span class="hs-identifier hs-var">paddingMask</span></a></span><span>
</span><span id="line-607"></span><span>      </span><span id="local-6989586621679677175"><span class="annot"><span class="annottext">pmShape :: SShape shape
</span><a href="#local-6989586621679677175"><span class="hs-identifier hs-var hs-var">pmShape</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape -&gt; SShape shape
forall (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType).
SGetShape shape =&gt;
Tensor gradient layout device dataType shape -&gt; SShape shape
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sGetShape"><span class="hs-identifier hs-var">sGetShape</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679677178"><span class="hs-identifier hs-var">paddingMask</span></a></span><span>
</span><span id="line-608"></span><span>  </span><span id="local-6989586621679677174"><span class="annot"><span class="annottext">SDim seqDim
</span><a href="#local-6989586621679677174"><span class="hs-identifier hs-var">pmSeqDim</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">SSelectDim ('SelectDim ('ByIndex 1))
-&gt; SShape shape -&gt; m (SDim seqDim)
forall (selectDim :: SelectDim (By Symbol Nat))
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (dim :: Dim (Name Symbol) (Size Nat)) (m :: * -&gt; *).
(dim ~ GetDimF selectDim shape, MonadThrow m) =&gt;
SSelectDim selectDim -&gt; SShape shape -&gt; m (SDim dim)
</span><a href="Torch.GraduallyTyped.Shape.Class.html#sGetDimFromShape"><span class="hs-identifier hs-var">sGetDimFromShape</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SBy ('ByIndex 1) -&gt; SSelectDim ('SelectDim ('ByIndex 1))
forall (by :: By Symbol Nat). SBy by -&gt; SSelectDim ('SelectDim by)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSelectDim"><span class="hs-identifier hs-var">SSelectDim</span></a></span><span> </span><span class="annot"><span class="annottext">(SBy ('ByIndex 1) -&gt; SSelectDim ('SelectDim ('ByIndex 1)))
-&gt; SBy ('ByIndex 1) -&gt; SSelectDim ('SelectDim ('ByIndex 1))
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">KnownNat 1 =&gt; SBy ('ByIndex 1)
forall (index :: Nat). KnownNat index =&gt; SBy ('ByIndex index)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SByIndex"><span class="hs-identifier hs-var">SByIndex</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">SShape shape
</span><a href="#local-6989586621679677175"><span class="hs-identifier hs-var">pmShape</span></a></span><span>
</span><span id="line-609"></span><span>  </span><span id="local-6989586621679677173"><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  layout
  device
  ('DataType 'Bool)
  ('Shape '[seqDim, seqDim])
</span><a href="#local-6989586621679677173"><span class="hs-identifier hs-var">causalMask</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span>
</span><span id="line-610"></span><span>    </span><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  layout
  device
  transformerDataType
  ('Shape '[seqDim, seqDim])
-&gt; m (Tensor
        ('Gradient 'WithoutGradient)
        layout
        device
        ('DataType 'Bool)
        ('Shape '[seqDim, seqDim]))
forall (m :: * -&gt; *) (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
MonadThrow m =&gt;
Tensor gradient layout device dataType shape
-&gt; m (Tensor
        ('Gradient 'WithoutGradient) layout device ('DataType 'Bool) shape)
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#bool"><span class="hs-identifier hs-var">bool</span></a></span><span> </span><span class="annot"><span class="annottext">(Tensor
   ('Gradient 'WithoutGradient)
   layout
   device
   transformerDataType
   ('Shape '[seqDim, seqDim])
 -&gt; m (Tensor
         ('Gradient 'WithoutGradient)
         layout
         device
         ('DataType 'Bool)
         ('Shape '[seqDim, seqDim])))
-&gt; (Tensor
      ('Gradient 'WithoutGradient)
      layout
      device
      transformerDataType
      ('Shape '[seqDim, seqDim])
    -&gt; Tensor
         ('Gradient 'WithoutGradient)
         layout
         device
         transformerDataType
         ('Shape '[seqDim, seqDim]))
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     layout
     device
     transformerDataType
     ('Shape '[seqDim, seqDim])
-&gt; m (Tensor
        ('Gradient 'WithoutGradient)
        layout
        device
        ('DataType 'Bool)
        ('Shape '[seqDim, seqDim]))
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Int
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     layout
     device
     transformerDataType
     ('Shape '[seqDim, seqDim])
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     layout
     device
     transformerDataType
     ('Shape '[seqDim, seqDim])
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
Int
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.Other.html#triu"><span class="hs-identifier hs-var">triu</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">1</span></span><span>
</span><span id="line-611"></span><span>      </span><span class="annot"><span class="annottext">(Tensor
   ('Gradient 'WithoutGradient)
   layout
   device
   transformerDataType
   ('Shape '[seqDim, seqDim])
 -&gt; m (Tensor
         ('Gradient 'WithoutGradient)
         layout
         device
         ('DataType 'Bool)
         ('Shape '[seqDim, seqDim])))
-&gt; m (Tensor
        ('Gradient 'WithoutGradient)
        layout
        device
        transformerDataType
        ('Shape '[seqDim, seqDim]))
-&gt; m (Tensor
        ('Gradient 'WithoutGradient)
        layout
        device
        ('DataType 'Bool)
        ('Shape '[seqDim, seqDim]))
forall (m :: * -&gt; *) a b. Monad m =&gt; (a -&gt; m b) -&gt; m a -&gt; m b
</span><span class="hs-operator hs-var">=&lt;&lt;</span></span><span> </span><span class="annot"><span class="annottext">TensorSpec
  ('Gradient 'WithoutGradient)
  layout
  device
  transformerDataType
  ('Shape '[seqDim, seqDim])
-&gt; m (Tensor
        ('Gradient 'WithoutGradient)
        layout
        device
        transformerDataType
        ('Shape '[seqDim, seqDim]))
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]) (m :: * -&gt; *).
MonadThrow m =&gt;
TensorSpec gradient layout device dataType shape
-&gt; m (Tensor gradient layout device dataType shape)
</span><a href="Torch.GraduallyTyped.Tensor.Creation.html#sOnes"><span class="hs-identifier hs-var">sOnes</span></a></span><span>
</span><span id="line-612"></span><span>        </span><span class="hs-special">(</span><span> </span><span class="annot"><span class="annottext">SGradient ('Gradient 'WithoutGradient)
-&gt; SLayout layout
-&gt; SDevice device
-&gt; SDataType transformerDataType
-&gt; SShape ('Shape '[seqDim, seqDim])
-&gt; TensorSpec
     ('Gradient 'WithoutGradient)
     layout
     device
     transformerDataType
     ('Shape '[seqDim, seqDim])
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SShape shape
-&gt; TensorSpec gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorSpec"><span class="hs-identifier hs-var">TensorSpec</span></a></span><span>
</span><span id="line-613"></span><span>            </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SRequiresGradient 'WithoutGradient
-&gt; SGradient ('Gradient 'WithoutGradient)
forall (requiresGradient :: RequiresGradient).
SRequiresGradient requiresGradient
-&gt; SGradient ('Gradient requiresGradient)
</span><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier hs-var">SGradient</span></a></span><span> </span><span class="annot"><span class="annottext">SRequiresGradient 'WithoutGradient
</span><a href="Torch.GraduallyTyped.RequiresGradient.html#SWithoutGradient"><span class="hs-identifier hs-var">SWithoutGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-614"></span><span>            </span><span class="annot"><span class="annottext">SLayout layout
</span><a href="#local-6989586621679677177"><span class="hs-identifier hs-var">pmLayout</span></a></span><span>
</span><span id="line-615"></span><span>            </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679677176"><span class="hs-identifier hs-var">pmDevice</span></a></span><span>
</span><span id="line-616"></span><span>            </span><span class="annot"><span class="annottext">SDataType transformerDataType
</span><a href="#local-6989586621679677180"><span class="hs-identifier hs-var">transformerDataType</span></a></span><span>
</span><span id="line-617"></span><span>            </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SList '[seqDim, seqDim] -&gt; SShape ('Shape '[seqDim, seqDim])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList '[seqDim, seqDim] -&gt; SShape ('Shape '[seqDim, seqDim]))
-&gt; SList '[seqDim, seqDim] -&gt; SShape ('Shape '[seqDim, seqDim])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">Sing seqDim
SDim seqDim
</span><a href="#local-6989586621679677174"><span class="hs-identifier hs-var">pmSeqDim</span></a></span><span> </span><span class="annot"><span class="annottext">Sing seqDim -&gt; SList '[seqDim] -&gt; SList '[seqDim, seqDim]
forall a1 (a2 :: a1) (as :: [a1]).
Sing a2 -&gt; SList as -&gt; SList (a2 : as)
</span><a href="Torch.GraduallyTyped.Prelude.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">Sing seqDim
SDim seqDim
</span><a href="#local-6989586621679677174"><span class="hs-identifier hs-var">pmSeqDim</span></a></span><span> </span><span class="annot"><span class="annottext">Sing seqDim -&gt; SList '[] -&gt; SList '[seqDim]
forall a1 (a2 :: a1) (as :: [a1]).
Sing a2 -&gt; SList as -&gt; SList (a2 : as)
</span><a href="Torch.GraduallyTyped.Prelude.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-618"></span><span>        </span><span class="hs-special">)</span><span>
</span><span id="line-619"></span><span>  </span><span id="local-6989586621679677171"><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  layout
  device
  ('DataType 'Bool)
  ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim])
</span><a href="#local-6989586621679677171"><span class="hs-identifier hs-var">causalMask'</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  layout
  device
  ('DataType 'Bool)
  ('Shape '[seqDim, seqDim])
-&gt; m (Tensor
        ('Gradient 'WithoutGradient)
        layout
        device
        ('DataType 'Bool)
        ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim]))
forall (selectDim :: SelectDim (By Symbol Nat))
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]) (m :: * -&gt; *).
(shape' ~ UnsqueezeF selectDim shape, Catch shape',
 SingI selectDim, MonadThrow m) =&gt;
Tensor gradient layout device dataType shape
-&gt; m (Tensor gradient layout device dataType shape')
</span><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#unsqueeze"><span class="hs-identifier hs-var">unsqueeze</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">0</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  layout
  device
  ('DataType 'Bool)
  ('Shape '[seqDim, seqDim])
</span><a href="#local-6989586621679677173"><span class="hs-identifier hs-var">causalMask</span></a></span><span>
</span><span id="line-620"></span><span>  </span><span id="local-6989586621679677170"><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  layout
  device
  transformerDataType
  ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim])
</span><a href="#local-6989586621679677170"><span class="hs-identifier hs-var">emptyMask</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span>
</span><span id="line-621"></span><span>    </span><span class="annot"><span class="annottext">TensorSpec
  ('Gradient 'WithoutGradient)
  layout
  device
  transformerDataType
  ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim])
-&gt; m (Tensor
        ('Gradient 'WithoutGradient)
        layout
        device
        transformerDataType
        ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim]))
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]) (m :: * -&gt; *).
MonadThrow m =&gt;
TensorSpec gradient layout device dataType shape
-&gt; m (Tensor gradient layout device dataType shape)
</span><a href="Torch.GraduallyTyped.Tensor.Creation.html#sZeros"><span class="hs-identifier hs-var">sZeros</span></a></span><span> </span><span class="annot"><span class="annottext">(TensorSpec
   ('Gradient 'WithoutGradient)
   layout
   device
   transformerDataType
   ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim])
 -&gt; m (Tensor
         ('Gradient 'WithoutGradient)
         layout
         device
         transformerDataType
         ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim])))
-&gt; TensorSpec
     ('Gradient 'WithoutGradient)
     layout
     device
     transformerDataType
     ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim])
-&gt; m (Tensor
        ('Gradient 'WithoutGradient)
        layout
        device
        transformerDataType
        ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim]))
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-622"></span><span>      </span><span class="annot"><span class="annottext">SGradient ('Gradient 'WithoutGradient)
-&gt; SLayout layout
-&gt; SDevice device
-&gt; SDataType transformerDataType
-&gt; SShape ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim])
-&gt; TensorSpec
     ('Gradient 'WithoutGradient)
     layout
     device
     transformerDataType
     ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim])
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SShape shape
-&gt; TensorSpec gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorSpec"><span class="hs-identifier hs-var">TensorSpec</span></a></span><span>
</span><span id="line-623"></span><span>        </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SRequiresGradient 'WithoutGradient
-&gt; SGradient ('Gradient 'WithoutGradient)
forall (requiresGradient :: RequiresGradient).
SRequiresGradient requiresGradient
-&gt; SGradient ('Gradient requiresGradient)
</span><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier hs-var">SGradient</span></a></span><span> </span><span class="annot"><span class="annottext">SRequiresGradient 'WithoutGradient
</span><a href="Torch.GraduallyTyped.RequiresGradient.html#SWithoutGradient"><span class="hs-identifier hs-var">SWithoutGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-624"></span><span>        </span><span class="annot"><span class="annottext">SLayout layout
</span><a href="#local-6989586621679677177"><span class="hs-identifier hs-var">pmLayout</span></a></span><span>
</span><span id="line-625"></span><span>        </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679677176"><span class="hs-identifier hs-var">pmDevice</span></a></span><span>
</span><span id="line-626"></span><span>        </span><span class="annot"><span class="annottext">SDataType transformerDataType
</span><a href="#local-6989586621679677180"><span class="hs-identifier hs-var">transformerDataType</span></a></span><span>
</span><span id="line-627"></span><span>        </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SList '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim]
-&gt; SShape ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim]
 -&gt; SShape ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim]))
-&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim]
-&gt; SShape ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize ('Size 1) -&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 1))
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownNat 1 =&gt; SSize ('Size 1)
forall (size :: Nat). KnownNat size =&gt; SSize ('Size size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier hs-var">SSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">1</span></span><span> </span><span class="annot"><span class="annottext">Sing ('Dim ('Name &quot;*&quot;) ('Size 1))
-&gt; SList '[seqDim, seqDim]
-&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim]
forall a1 (a2 :: a1) (as :: [a1]).
Sing a2 -&gt; SList as -&gt; SList (a2 : as)
</span><a href="Torch.GraduallyTyped.Prelude.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">Sing seqDim
SDim seqDim
</span><a href="#local-6989586621679677174"><span class="hs-identifier hs-var">pmSeqDim</span></a></span><span> </span><span class="annot"><span class="annottext">Sing seqDim -&gt; SList '[seqDim] -&gt; SList '[seqDim, seqDim]
forall a1 (a2 :: a1) (as :: [a1]).
Sing a2 -&gt; SList as -&gt; SList (a2 : as)
</span><a href="Torch.GraduallyTyped.Prelude.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">Sing seqDim
SDim seqDim
</span><a href="#local-6989586621679677174"><span class="hs-identifier hs-var">pmSeqDim</span></a></span><span> </span><span class="annot"><span class="annottext">Sing seqDim -&gt; SList '[] -&gt; SList '[seqDim]
forall a1 (a2 :: a1) (as :: [a1]).
Sing a2 -&gt; SList as -&gt; SList (a2 : as)
</span><a href="Torch.GraduallyTyped.Prelude.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-628"></span><span>  </span><span id="local-6989586621679677169"><span class="annot"><span class="annottext">Tensor
  gradient
  layout
  device
  dataType
  (UnsqueezeF ('SelectDim ('ByIndex 1)) shape)
</span><a href="#local-6989586621679677169"><span class="hs-identifier hs-var">paddingMask'</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
-&gt; m (Tensor
        gradient
        layout
        device
        dataType
        (UnsqueezeF ('SelectDim ('ByIndex 1)) shape))
forall (selectDim :: SelectDim (By Symbol Nat))
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]) (m :: * -&gt; *).
(shape' ~ UnsqueezeF selectDim shape, Catch shape',
 SingI selectDim, MonadThrow m) =&gt;
Tensor gradient layout device dataType shape
-&gt; m (Tensor gradient layout device dataType shape')
</span><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#unsqueeze"><span class="hs-identifier hs-var">unsqueeze</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679677178"><span class="hs-identifier hs-var">paddingMask</span></a></span><span>
</span><span id="line-629"></span><span>  </span><span id="local-6989586621679677168"><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  layout
  device
  ('DataType 'Bool)
  (BroadcastShapesF
     ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim])
     (UnsqueezeF ('SelectDim ('ByIndex 1)) shape))
</span><a href="#local-6989586621679677168"><span class="hs-identifier hs-var">booleanMask</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  layout
  device
  ('DataType 'Bool)
  ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim])
</span><a href="#local-6989586621679677171"><span class="hs-identifier hs-var">causalMask'</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  layout
  device
  ('DataType 'Bool)
  ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim])
-&gt; Tensor
     gradient
     layout
     device
     dataType
     (UnsqueezeF ('SelectDim ('ByIndex 1)) shape)
-&gt; m (Tensor
        ('Gradient 'WithoutGradient)
        (layout &lt;+&gt; layout)
        (device &lt;+&gt; device)
        ('DataType 'Bool)
        (BroadcastShapesF
           ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim])
           (UnsqueezeF ('SelectDim ('ByIndex 1)) shape)))
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (gradient' :: Gradient RequiresGradient)
       (layout' :: Layout LayoutType) (device' :: Device (DeviceType Nat))
       (dataType' :: DataType DType)
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)])
       (shape'' :: Shape [Dim (Name Symbol) (Size Nat)]) (m :: * -&gt; *).
(MonadThrow m, shape'' ~ BroadcastShapesF shape shape',
 Catch shape'') =&gt;
Tensor gradient layout device dataType shape
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; m (Tensor
        ('Gradient 'WithoutGradient)
        (layout &lt;+&gt; layout')
        (device &lt;+&gt; device')
        ('DataType 'Bool)
        shape'')
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#logicalOr"><span class="hs-operator hs-var">`logicalOr`</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  gradient
  layout
  device
  dataType
  (UnsqueezeF ('SelectDim ('ByIndex 1)) shape)
</span><a href="#local-6989586621679677169"><span class="hs-identifier hs-var">paddingMask'</span></a></span><span>
</span><span id="line-630"></span><span>  </span><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  layout
  device
  ('DataType 'Bool)
  (BroadcastShapesF
     ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim])
     (UnsqueezeF ('SelectDim ('ByIndex 1)) shape))
-&gt; Double
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     layout
     device
     transformerDataType
     ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim])
-&gt; m (Tensor
        ('Gradient 'WithoutGradient)
        (layout &lt;+&gt; (layout &lt;+&gt; 'Layout 'Dense))
        (device &lt;+&gt; device)
        transformerDataType
        (BroadcastShapesF
           (BroadcastShapesF
              ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim])
              (UnsqueezeF ('SelectDim ('ByIndex 1)) shape))
           ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim])))
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]) value
       (gradient' :: Gradient RequiresGradient)
       (layout' :: Layout LayoutType) (device' :: Device (DeviceType Nat))
       (dataType' :: DataType DType)
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)])
       (shape'' :: Shape [Dim (Name Symbol) (Size Nat)]) (m :: * -&gt; *).
(Scalar value, MonadThrow m,
 Catch (gradient &lt;+&gt; 'Gradient 'WithoutGradient),
 Catch (dataType &lt;+&gt; 'DataType 'Bool),
 shape'' ~ BroadcastShapesF shape shape', Catch shape'') =&gt;
Tensor gradient layout device dataType shape
-&gt; value
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; m (Tensor
        gradient'
        (layout &lt;+&gt; (layout' &lt;+&gt; 'Layout 'Dense))
        (device &lt;+&gt; device')
        dataType'
        shape'')
</span><a href="Torch.GraduallyTyped.Tensor.Other.html#maskedFill"><span class="hs-identifier hs-var">maskedFill</span></a></span><span>
</span><span id="line-631"></span><span>    </span><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  layout
  device
  ('DataType 'Bool)
  (BroadcastShapesF
     ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim])
     (UnsqueezeF ('SelectDim ('ByIndex 1)) shape))
</span><a href="#local-6989586621679677168"><span class="hs-identifier hs-var">booleanMask</span></a></span><span>
</span><span id="line-632"></span><span>    </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679677179"><span class="hs-identifier hs-var">attentionMaskBias</span></a></span><span>
</span><span id="line-633"></span><span>    </span><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  layout
  device
  transformerDataType
  ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim])
</span><a href="#local-6989586621679677170"><span class="hs-identifier hs-var">emptyMask</span></a></span><span>
</span><span id="line-634"></span><span>
</span><span id="line-635"></span><span id="local-6989586621679677166"><span id="local-6989586621679677167"></span></span><span class="hs-keyword">data</span><span> </span><span id="MkTransformerDecoderAttentionMask"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerDecoderAttentionMask"><span class="hs-identifier hs-var">MkTransformerDecoderAttentionMask</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679677165"><span class="annot"><a href="#local-6989586621679677165"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier hs-type">DType</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-636"></span><span>  </span><span id="MkTransformerDecoderAttentionMask"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerDecoderAttentionMask"><span class="hs-identifier hs-var">MkTransformerDecoderAttentionMask</span></a></span></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-637"></span><span>    </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679677757"><span class="annot"><a href="#local-6989586621679677757"><span class="hs-identifier hs-type">dataType</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-638"></span><span>    </span><span class="hs-special">{</span><span> </span><span id="decoderAttentionMaskDataType"><span class="annot"><span class="annottext">MkTransformerDecoderAttentionMask dataType -&gt; SDataType dataType
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#decoderAttentionMaskDataType"><span class="hs-identifier hs-var hs-var">decoderAttentionMaskDataType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier hs-type">SDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677757"><span class="hs-identifier hs-type">dataType</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-639"></span><span>      </span><span id="decoderAttentionMaskBias"><span class="annot"><span class="annottext">MkTransformerDecoderAttentionMask dataType -&gt; Double
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#decoderAttentionMaskBias"><span class="hs-identifier hs-var hs-var">decoderAttentionMaskBias</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span>
</span><span id="line-640"></span><span>    </span><span class="hs-special">}</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-641"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerDecoderAttentionMask"><span class="hs-identifier hs-type">MkTransformerDecoderAttentionMask</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677757"><span class="hs-identifier hs-type">dataType</span></a></span><span>
</span><span id="line-642"></span><span>  </span><span class="hs-keyword">deriving</span><span> </span><span class="annot"><span class="hs-keyword">stock</span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679677156"><span id="local-6989586621679677158"><span id="local-6989586621679677160"><span class="annot"><span class="annottext">Int -&gt; MkTransformerDecoderAttentionMask dataType -&gt; ShowS
[MkTransformerDecoderAttentionMask dataType] -&gt; ShowS
MkTransformerDecoderAttentionMask dataType -&gt; String
(Int -&gt; MkTransformerDecoderAttentionMask dataType -&gt; ShowS)
-&gt; (MkTransformerDecoderAttentionMask dataType -&gt; String)
-&gt; ([MkTransformerDecoderAttentionMask dataType] -&gt; ShowS)
-&gt; Show (MkTransformerDecoderAttentionMask dataType)
forall a.
(Int -&gt; a -&gt; ShowS) -&gt; (a -&gt; String) -&gt; ([a] -&gt; ShowS) -&gt; Show a
forall (dataType :: DataType DType).
Int -&gt; MkTransformerDecoderAttentionMask dataType -&gt; ShowS
forall (dataType :: DataType DType).
[MkTransformerDecoderAttentionMask dataType] -&gt; ShowS
forall (dataType :: DataType DType).
MkTransformerDecoderAttentionMask dataType -&gt; String
showList :: [MkTransformerDecoderAttentionMask dataType] -&gt; ShowS
$cshowList :: forall (dataType :: DataType DType).
[MkTransformerDecoderAttentionMask dataType] -&gt; ShowS
show :: MkTransformerDecoderAttentionMask dataType -&gt; String
$cshow :: forall (dataType :: DataType DType).
MkTransformerDecoderAttentionMask dataType -&gt; String
showsPrec :: Int -&gt; MkTransformerDecoderAttentionMask dataType -&gt; ShowS
$cshowsPrec :: forall (dataType :: DataType DType).
Int -&gt; MkTransformerDecoderAttentionMask dataType -&gt; ShowS
</span><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">Show</span></span></span></span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">(forall x.
 MkTransformerDecoderAttentionMask dataType
 -&gt; Rep (MkTransformerDecoderAttentionMask dataType) x)
-&gt; (forall x.
    Rep (MkTransformerDecoderAttentionMask dataType) x
    -&gt; MkTransformerDecoderAttentionMask dataType)
-&gt; Generic (MkTransformerDecoderAttentionMask dataType)
forall x.
Rep (MkTransformerDecoderAttentionMask dataType) x
-&gt; MkTransformerDecoderAttentionMask dataType
forall x.
MkTransformerDecoderAttentionMask dataType
-&gt; Rep (MkTransformerDecoderAttentionMask dataType) x
forall a.
(forall x. a -&gt; Rep a x) -&gt; (forall x. Rep a x -&gt; a) -&gt; Generic a
forall (dataType :: DataType DType) x.
Rep (MkTransformerDecoderAttentionMask dataType) x
-&gt; MkTransformerDecoderAttentionMask dataType
forall (dataType :: DataType DType) x.
MkTransformerDecoderAttentionMask dataType
-&gt; Rep (MkTransformerDecoderAttentionMask dataType) x
$cto :: forall (dataType :: DataType DType) x.
Rep (MkTransformerDecoderAttentionMask dataType) x
-&gt; MkTransformerDecoderAttentionMask dataType
$cfrom :: forall (dataType :: DataType DType) x.
MkTransformerDecoderAttentionMask dataType
-&gt; Rep (MkTransformerDecoderAttentionMask dataType) x
</span><span class="hs-identifier hs-var hs-var hs-var hs-var">Generic</span></span><span class="hs-special">)</span><span>
</span><span id="line-643"></span><span>
</span><span id="line-644"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">instance</span><span>
</span><span id="line-645"></span><span>  </span><span id="ModelSpec"><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier hs-var">ModelSpec</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerDecoderAttentionMask"><span class="hs-identifier hs-type">MkTransformerDecoderAttentionMask</span></a></span><span> </span><span id="local-6989586621679677153"><span class="annot"><a href="#local-6989586621679677153"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-646"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerDecoderAttentionMask"><span class="hs-identifier hs-type">MkTransformerDecoderAttentionMask</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677153"><span class="hs-identifier hs-type">dataType</span></a></span><span>
</span><span id="line-647"></span><span>
</span><span id="line-648"></span><span id="local-6989586621679677151"><span id="local-6989586621679677152"><span class="hs-keyword">instance</span><span>
</span><span id="line-649"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span>
</span><span id="line-650"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerDecoderAttentionMask"><span class="hs-identifier hs-type">MkTransformerDecoderAttentionMask</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677152"><span class="hs-identifier hs-type">dataType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-651"></span><span>    </span><span class="annot"><a href="#local-6989586621679677151"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-652"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerDecoderAttentionMask"><span class="hs-identifier hs-type">MkTransformerDecoderAttentionMask</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677152"><span class="hs-identifier hs-type">dataType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-653"></span><span>    </span><span class="annot"><a href="#local-6989586621679677151"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-654"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-655"></span><span>  </span><span id="local-6989586621679677149"><span class="annot"><span class="annottext">initialize :: ModelSpec (MkTransformerDecoderAttentionMask dataType)
-&gt; Generator generatorDevice
-&gt; m (MkTransformerDecoderAttentionMask dataType,
      Generator generatorDevice)
</span><a href="#local-6989586621679677149"><span class="hs-identifier hs-var hs-var hs-var hs-var">initialize</span></a></span></span><span> </span><span id="local-6989586621679677148"><span class="annot"><span class="annottext">ModelSpec (MkTransformerDecoderAttentionMask dataType)
</span><a href="#local-6989586621679677148"><span class="hs-identifier hs-var">spec</span></a></span></span><span> </span><span id="local-6989586621679677147"><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679677147"><span class="hs-identifier hs-var">g</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(MkTransformerDecoderAttentionMask dataType,
 Generator generatorDevice)
-&gt; m (MkTransformerDecoderAttentionMask dataType,
      Generator generatorDevice)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">ModelSpec (MkTransformerDecoderAttentionMask dataType)
MkTransformerDecoderAttentionMask dataType
</span><a href="#local-6989586621679677148"><span class="hs-identifier hs-var">spec</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679677147"><span class="hs-identifier hs-var">g</span></a></span><span class="hs-special">)</span></span></span><span>
</span><span id="line-656"></span><span>
</span><span id="line-657"></span><span id="local-6989586621679677146"><span class="hs-keyword">instance</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasStateDict"><span class="hs-identifier hs-type">HasStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerDecoderAttentionMask"><span class="hs-identifier hs-type">MkTransformerDecoderAttentionMask</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677146"><span class="hs-identifier hs-type">dataType</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-658"></span><span>  </span><span id="local-6989586621679677143"><span class="annot"><span class="annottext">fromStateDict :: ModelSpec (MkTransformerDecoderAttentionMask dataType)
-&gt; StateDictKey -&gt; m (MkTransformerDecoderAttentionMask dataType)
</span><a href="#local-6989586621679677143"><span class="hs-identifier hs-var hs-var hs-var hs-var">fromStateDict</span></a></span></span><span> </span><span id="local-6989586621679677142"><span class="annot"><span class="annottext">ModelSpec (MkTransformerDecoderAttentionMask dataType)
</span><a href="#local-6989586621679677142"><span class="hs-identifier hs-var">spec</span></a></span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">MkTransformerDecoderAttentionMask dataType
-&gt; m (MkTransformerDecoderAttentionMask dataType)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">ModelSpec (MkTransformerDecoderAttentionMask dataType)
MkTransformerDecoderAttentionMask dataType
</span><a href="#local-6989586621679677142"><span class="hs-identifier hs-var">spec</span></a></span><span>
</span><span id="line-659"></span><span>  </span><span id="local-6989586621679677141"><span class="annot"><span class="annottext">toStateDict :: StateDictKey -&gt; MkTransformerDecoderAttentionMask dataType -&gt; m ()
</span><a href="#local-6989586621679677141"><span class="hs-identifier hs-var hs-var hs-var hs-var">toStateDict</span></a></span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="annottext">MkTransformerDecoderAttentionMask dataType
</span><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">() -&gt; m ()
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span></span><span>
</span><span id="line-660"></span><span>
</span><span id="line-661"></span><span id="local-6989586621679677132"><span id="local-6989586621679677133"><span id="local-6989586621679677134"><span id="local-6989586621679677135"><span id="local-6989586621679677136"><span id="local-6989586621679677137"><span id="local-6989586621679677138"><span id="local-6989586621679677139"><span id="local-6989586621679677140"><span class="hs-keyword">instance</span><span>
</span><span id="line-662"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerDecoderAttentionMaskC"><span class="hs-identifier hs-type">MkTransformerDecoderAttentionMaskC</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677140"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677139"><span class="hs-identifier hs-type">decoderInputLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677138"><span class="hs-identifier hs-type">decoderInputDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677137"><span class="hs-identifier hs-type">decoderInputShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677136"><span class="hs-identifier hs-type">seqDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677135"><span class="hs-identifier hs-type">output</span></a></span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-663"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-664"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerDecoderAttentionMask"><span class="hs-identifier hs-type">MkTransformerDecoderAttentionMask</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677140"><span class="hs-identifier hs-type">dataType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-665"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677134"><span class="hs-identifier hs-type">decoderInputGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677139"><span class="hs-identifier hs-type">decoderInputLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677138"><span class="hs-identifier hs-type">decoderInputDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677133"><span class="hs-identifier hs-type">decoderInputDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677137"><span class="hs-identifier hs-type">decoderInputShape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-666"></span><span>    </span><span class="annot"><a href="#local-6989586621679677132"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-667"></span><span>    </span><span class="annot"><a href="#local-6989586621679677135"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-668"></span><span>    </span><span class="annot"><a href="#local-6989586621679677132"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-669"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-670"></span><span>  </span><span id="local-6989586621679677130"><span class="annot"><span class="annottext">forward :: MkTransformerDecoderAttentionMask dataType
-&gt; Tensor
     decoderInputGradient
     decoderInputLayout
     decoderInputDevice
     decoderInputDataType
     decoderInputShape
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorDevice)
</span><a href="#local-6989586621679677130"><span class="hs-identifier hs-var hs-var hs-var hs-var">forward</span></a></span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerDecoderAttentionMask"><span class="hs-identifier hs-type">MkTransformerDecoderAttentionMask</span></a></span><span> </span><span class="hs-special">{</span><span id="local-6989586621679677128"><span id="local-6989586621679677129"><span class="annot"><span class="annottext">Double
SDataType dataType
decoderAttentionMaskBias :: Double
decoderAttentionMaskDataType :: SDataType dataType
decoderAttentionMaskBias :: forall (dataType :: DataType DType).
MkTransformerDecoderAttentionMask dataType -&gt; Double
decoderAttentionMaskDataType :: forall (dataType :: DataType DType).
MkTransformerDecoderAttentionMask dataType -&gt; SDataType dataType
</span><a href="#local-6989586621679677128"><span class="hs-glyph hs-var hs-var hs-var hs-var">..</span></a></span></span></span><span class="hs-special">}</span><span> </span><span id="local-6989586621679677127"><span class="annot"><span class="annottext">Tensor
  decoderInputGradient
  decoderInputLayout
  decoderInputDevice
  decoderInputDataType
  decoderInputShape
</span><a href="#local-6989586621679677127"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span id="local-6989586621679677126"><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679677126"><span class="hs-identifier hs-var">g</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-671"></span><span>    </span><span id="local-6989586621679677125"><span class="annot"><span class="annottext">output
</span><a href="#local-6989586621679677125"><span class="hs-identifier hs-var">decoderAttentionMask</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">SDataType dataType
-&gt; Double
-&gt; Tensor
     decoderInputGradient
     decoderInputLayout
     decoderInputDevice
     decoderInputDataType
     decoderInputShape
-&gt; m output
forall (m :: * -&gt; *) (transformerDataType :: DataType DType)
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (seqDim :: Dim (Name Symbol) (Size Nat)) output.
(MonadThrow m,
 MkTransformerDecoderAttentionMaskC
   transformerDataType layout device shape seqDim output) =&gt;
SDataType transformerDataType
-&gt; Double
-&gt; Tensor gradient layout device dataType shape
-&gt; m output
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#mkTransformerDecoderAttentionMask"><span class="hs-identifier hs-var">mkTransformerDecoderAttentionMask</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679677129"><span class="hs-identifier hs-var">decoderAttentionMaskDataType</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679677128"><span class="hs-identifier hs-var">decoderAttentionMaskBias</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  decoderInputGradient
  decoderInputLayout
  decoderInputDevice
  decoderInputDataType
  decoderInputShape
</span><a href="#local-6989586621679677127"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-672"></span><span>    </span><span class="annot"><span class="annottext">(output, Generator generatorDevice)
-&gt; m (output, Generator generatorDevice)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">output
</span><a href="#local-6989586621679677125"><span class="hs-identifier hs-var">decoderAttentionMask</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679677126"><span class="hs-identifier hs-var">g</span></a></span><span class="hs-special">)</span></span></span></span></span></span></span></span></span></span><span>
</span><span id="line-673"></span><span>
</span><span id="line-674"></span><span class="hs-keyword">type</span><span> </span><span id="MkTransformerCrossAttentionMaskC"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerCrossAttentionMaskC"><span class="hs-identifier hs-var">MkTransformerCrossAttentionMaskC</span></a></span></span><span> </span><span id="local-6989586621679677124"><span class="annot"><a href="#local-6989586621679677124"><span class="hs-identifier hs-type">transformerDataType</span></a></span></span><span> </span><span id="local-6989586621679677123"><span class="annot"><a href="#local-6989586621679677123"><span class="hs-identifier hs-type">decoderInputShape</span></a></span></span><span> </span><span id="local-6989586621679677122"><span class="annot"><a href="#local-6989586621679677122"><span class="hs-identifier hs-type">decoderInputSeqDim</span></a></span></span><span> </span><span id="local-6989586621679677121"><span class="annot"><a href="#local-6989586621679677121"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679677120"><span class="annot"><a href="#local-6989586621679677120"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679677119"><span class="annot"><a href="#local-6989586621679677119"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679677118"><span class="annot"><a href="#local-6989586621679677118"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679677117"><span class="annot"><a href="#local-6989586621679677117"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679677116"><span class="annot"><a href="#local-6989586621679677116"><span class="hs-identifier hs-type">seqDim</span></a></span></span><span> </span><span id="local-6989586621679677115"><span class="annot"><a href="#local-6989586621679677115"><span class="hs-identifier hs-type">output</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-675"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetLayout"><span class="hs-identifier hs-type">SGetLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677120"><span class="hs-identifier hs-type">layout</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-676"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetDevice"><span class="hs-identifier hs-type">SGetDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677119"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-677"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetShape"><span class="hs-identifier hs-type">SGetShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677117"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-678"></span><span>    </span><span class="annot"><a href="#local-6989586621679677116"><span class="hs-identifier hs-type">seqDim</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679677117"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#%21"><span class="hs-glyph hs-type">!</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-679"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetShape"><span class="hs-identifier hs-type">SGetShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677123"><span class="hs-identifier hs-type">decoderInputShape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-680"></span><span>    </span><span class="annot"><a href="#local-6989586621679677122"><span class="hs-identifier hs-type">decoderInputSeqDim</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679677123"><span class="hs-identifier hs-type">decoderInputShape</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#%21"><span class="hs-glyph hs-type">!</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-681"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Catch"><span class="hs-identifier hs-type">Catch</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679677121"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#WithoutGradient"><span class="hs-identifier hs-type">WithoutGradient</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-682"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Catch"><span class="hs-identifier hs-type">Catch</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679677118"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#Bool"><span class="hs-identifier hs-type">Bool</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-683"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Catch"><span class="hs-identifier hs-type">Catch</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#UnsqueezeF"><span class="hs-identifier hs-type">UnsqueezeF</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679677117"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-684"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Catch"><span class="hs-identifier hs-type">Catch</span></a></span><span>
</span><span id="line-685"></span><span>      </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#BroadcastShapesF"><span class="hs-identifier hs-type">BroadcastShapesF</span></a></span><span>
</span><span id="line-686"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#UnsqueezeF"><span class="hs-identifier hs-type">UnsqueezeF</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679677117"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-687"></span><span>          </span><span class="hs-special">(</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span>
</span><span id="line-688"></span><span>              </span><span class="hs-special">'</span><span class="hs-special">[</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679677122"><span class="hs-identifier hs-type">decoderInputSeqDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679677116"><span class="hs-identifier hs-type">seqDim</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-689"></span><span>          </span><span class="hs-special">)</span><span>
</span><span id="line-690"></span><span>      </span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-691"></span><span>    </span><span class="annot"><a href="#local-6989586621679677115"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-692"></span><span>      </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-693"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#WithoutGradient"><span class="hs-identifier hs-type">WithoutGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-694"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679677120"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Dense"><span class="hs-identifier hs-type">Dense</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-695"></span><span>          </span><span class="annot"><a href="#local-6989586621679677119"><span class="hs-identifier hs-type">device</span></a></span><span>
</span><span id="line-696"></span><span>          </span><span class="annot"><a href="#local-6989586621679677124"><span class="hs-identifier hs-type">transformerDataType</span></a></span><span>
</span><span id="line-697"></span><span>          </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#BroadcastShapesF"><span class="hs-identifier hs-type">BroadcastShapesF</span></a></span><span>
</span><span id="line-698"></span><span>              </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#UnsqueezeF"><span class="hs-identifier hs-type">UnsqueezeF</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679677117"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-699"></span><span>              </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679677122"><span class="hs-identifier hs-type">decoderInputSeqDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679677116"><span class="hs-identifier hs-type">seqDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-700"></span><span>          </span><span class="hs-special">)</span><span>
</span><span id="line-701"></span><span>  </span><span class="hs-special">)</span><span>
</span><span id="line-702"></span><span>
</span><span id="line-703"></span><span class="hs-comment">-- | Creates a cross-attention mask for an encoder-decoder transformer.</span><span>
</span><span id="line-704"></span><span class="hs-comment">-- Given an encoder padding mask of shape @[batchDim, seqDim]@,</span><span>
</span><span id="line-705"></span><span class="hs-comment">-- and the shape @[batchDim, decoderSeqDim]@ of the decoder's input,</span><span>
</span><span id="line-706"></span><span class="hs-comment">-- returns a tensor of shape @[batchDim, decoderSeqDim, seqDim]@.</span><span>
</span><span id="line-707"></span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#mkTransformerCrossAttentionMask"><span class="hs-identifier hs-type">mkTransformerCrossAttentionMask</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-708"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679677705"><span class="annot"><a href="#local-6989586621679677705"><span class="hs-identifier hs-type">m</span></a></span></span><span> </span><span id="local-6989586621679677704"><span class="annot"><a href="#local-6989586621679677704"><span class="hs-identifier hs-type">transformerDataType</span></a></span></span><span> </span><span id="local-6989586621679677703"><span class="annot"><a href="#local-6989586621679677703"><span class="hs-identifier hs-type">decoderInputShape</span></a></span></span><span> </span><span id="local-6989586621679677702"><span class="annot"><a href="#local-6989586621679677702"><span class="hs-identifier hs-type">decoderInputSeqDim</span></a></span></span><span> </span><span id="local-6989586621679677701"><span class="annot"><a href="#local-6989586621679677701"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679677700"><span class="annot"><a href="#local-6989586621679677700"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679677699"><span class="annot"><a href="#local-6989586621679677699"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679677698"><span class="annot"><a href="#local-6989586621679677698"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679677697"><span class="annot"><a href="#local-6989586621679677697"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679677696"><span class="annot"><a href="#local-6989586621679677696"><span class="hs-identifier hs-type">seqDim</span></a></span></span><span> </span><span id="local-6989586621679677695"><span class="annot"><a href="#local-6989586621679677695"><span class="hs-identifier hs-type">output</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-709"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier hs-type">MonadThrow</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677705"><span class="hs-identifier hs-type">m</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-710"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerCrossAttentionMaskC"><span class="hs-identifier hs-type">MkTransformerCrossAttentionMaskC</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677704"><span class="hs-identifier hs-type">transformerDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677703"><span class="hs-identifier hs-type">decoderInputShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677702"><span class="hs-identifier hs-type">decoderInputSeqDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677701"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677700"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677699"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677698"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677697"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677696"><span class="hs-identifier hs-type">seqDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677695"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-711"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-712"></span><span>  </span><span class="hs-comment">-- | data type singleton of the transformer</span><span>
</span><span id="line-713"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier hs-type">SDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677704"><span class="hs-identifier hs-type">transformerDataType</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-714"></span><span>  </span><span class="hs-comment">-- | decoder input shape</span><span>
</span><span id="line-715"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-type">SShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677703"><span class="hs-identifier hs-type">decoderInputShape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-716"></span><span>  </span><span class="hs-comment">-- | attention mask bias (typically a large negative number)</span><span>
</span><span id="line-717"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-718"></span><span>  </span><span class="hs-comment">-- | encoder padding mask</span><span>
</span><span id="line-719"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677701"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677700"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677699"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677698"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677697"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-720"></span><span>  </span><span class="annot"><a href="#local-6989586621679677705"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677695"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-721"></span><span id="mkTransformerCrossAttentionMask"><span class="annot"><span class="annottext">mkTransformerCrossAttentionMask :: SDataType transformerDataType
-&gt; SShape decoderInputShape
-&gt; Double
-&gt; Tensor gradient layout device dataType shape
-&gt; m output
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#mkTransformerCrossAttentionMask"><span class="hs-identifier hs-var hs-var">mkTransformerCrossAttentionMask</span></a></span></span><span> </span><span id="local-6989586621679677113"><span class="annot"><span class="annottext">SDataType transformerDataType
</span><a href="#local-6989586621679677113"><span class="hs-identifier hs-var">transformerDataType</span></a></span></span><span> </span><span id="local-6989586621679677112"><span class="annot"><span class="annottext">SShape decoderInputShape
</span><a href="#local-6989586621679677112"><span class="hs-identifier hs-var">decoderInputShape</span></a></span></span><span> </span><span id="local-6989586621679677111"><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679677111"><span class="hs-identifier hs-var">attentionMaskBias</span></a></span></span><span> </span><span id="local-6989586621679677110"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679677110"><span class="hs-identifier hs-var">paddingMask</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-722"></span><span>  </span><span id="local-6989586621679677109"><span class="annot"><span class="annottext">SDim decoderInputSeqDim
</span><a href="#local-6989586621679677109"><span class="hs-identifier hs-var">decoderInputSeqDim</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">SSelectDim ('SelectDim ('ByIndex 1))
-&gt; SShape decoderInputShape -&gt; m (SDim decoderInputSeqDim)
forall (selectDim :: SelectDim (By Symbol Nat))
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (dim :: Dim (Name Symbol) (Size Nat)) (m :: * -&gt; *).
(dim ~ GetDimF selectDim shape, MonadThrow m) =&gt;
SSelectDim selectDim -&gt; SShape shape -&gt; m (SDim dim)
</span><a href="Torch.GraduallyTyped.Shape.Class.html#sGetDimFromShape"><span class="hs-identifier hs-var">sGetDimFromShape</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SBy ('ByIndex 1) -&gt; SSelectDim ('SelectDim ('ByIndex 1))
forall (by :: By Symbol Nat). SBy by -&gt; SSelectDim ('SelectDim by)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSelectDim"><span class="hs-identifier hs-var">SSelectDim</span></a></span><span> </span><span class="annot"><span class="annottext">(SBy ('ByIndex 1) -&gt; SSelectDim ('SelectDim ('ByIndex 1)))
-&gt; SBy ('ByIndex 1) -&gt; SSelectDim ('SelectDim ('ByIndex 1))
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">KnownNat 1 =&gt; SBy ('ByIndex 1)
forall (index :: Nat). KnownNat index =&gt; SBy ('ByIndex index)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SByIndex"><span class="hs-identifier hs-var">SByIndex</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">SShape decoderInputShape
</span><a href="#local-6989586621679677112"><span class="hs-identifier hs-var">decoderInputShape</span></a></span><span>
</span><span id="line-723"></span><span>  </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679677108"><span class="annot"><span class="annottext">pmLayout :: SLayout layout
</span><a href="#local-6989586621679677108"><span class="hs-identifier hs-var hs-var">pmLayout</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape -&gt; SLayout layout
forall (layout :: Layout LayoutType)
       (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SGetLayout layout =&gt;
Tensor gradient layout device dataType shape -&gt; SLayout layout
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sGetLayout"><span class="hs-identifier hs-var">sGetLayout</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679677110"><span class="hs-identifier hs-var">paddingMask</span></a></span><span>
</span><span id="line-724"></span><span>      </span><span id="local-6989586621679677107"><span class="annot"><span class="annottext">pmDevice :: SDevice device
</span><a href="#local-6989586621679677107"><span class="hs-identifier hs-var hs-var">pmDevice</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape -&gt; SDevice device
forall (device :: Device (DeviceType Nat))
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SGetDevice device =&gt;
Tensor gradient layout device dataType shape -&gt; SDevice device
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sGetDevice"><span class="hs-identifier hs-var">sGetDevice</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679677110"><span class="hs-identifier hs-var">paddingMask</span></a></span><span>
</span><span id="line-725"></span><span>      </span><span id="local-6989586621679677106"><span class="annot"><span class="annottext">pmShape :: SShape shape
</span><a href="#local-6989586621679677106"><span class="hs-identifier hs-var hs-var">pmShape</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape -&gt; SShape shape
forall (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType).
SGetShape shape =&gt;
Tensor gradient layout device dataType shape -&gt; SShape shape
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sGetShape"><span class="hs-identifier hs-var">sGetShape</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679677110"><span class="hs-identifier hs-var">paddingMask</span></a></span><span>
</span><span id="line-726"></span><span>  </span><span id="local-6989586621679677105"><span class="annot"><span class="annottext">SDim seqDim
</span><a href="#local-6989586621679677105"><span class="hs-identifier hs-var">pmSeqDim</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">SSelectDim ('SelectDim ('ByIndex 1))
-&gt; SShape shape -&gt; m (SDim seqDim)
forall (selectDim :: SelectDim (By Symbol Nat))
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (dim :: Dim (Name Symbol) (Size Nat)) (m :: * -&gt; *).
(dim ~ GetDimF selectDim shape, MonadThrow m) =&gt;
SSelectDim selectDim -&gt; SShape shape -&gt; m (SDim dim)
</span><a href="Torch.GraduallyTyped.Shape.Class.html#sGetDimFromShape"><span class="hs-identifier hs-var">sGetDimFromShape</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SBy ('ByIndex 1) -&gt; SSelectDim ('SelectDim ('ByIndex 1))
forall (by :: By Symbol Nat). SBy by -&gt; SSelectDim ('SelectDim by)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSelectDim"><span class="hs-identifier hs-var">SSelectDim</span></a></span><span> </span><span class="annot"><span class="annottext">(SBy ('ByIndex 1) -&gt; SSelectDim ('SelectDim ('ByIndex 1)))
-&gt; SBy ('ByIndex 1) -&gt; SSelectDim ('SelectDim ('ByIndex 1))
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">KnownNat 1 =&gt; SBy ('ByIndex 1)
forall (index :: Nat). KnownNat index =&gt; SBy ('ByIndex index)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SByIndex"><span class="hs-identifier hs-var">SByIndex</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">SShape shape
</span><a href="#local-6989586621679677106"><span class="hs-identifier hs-var">pmShape</span></a></span><span>
</span><span id="line-727"></span><span>  </span><span id="local-6989586621679677104"><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  layout
  device
  transformerDataType
  ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), decoderInputSeqDim, seqDim])
</span><a href="#local-6989586621679677104"><span class="hs-identifier hs-var">emptyMask</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span>
</span><span id="line-728"></span><span>    </span><span class="annot"><span class="annottext">TensorSpec
  ('Gradient 'WithoutGradient)
  layout
  device
  transformerDataType
  ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), decoderInputSeqDim, seqDim])
-&gt; m (Tensor
        ('Gradient 'WithoutGradient)
        layout
        device
        transformerDataType
        ('Shape
           '[ 'Dim ('Name &quot;*&quot;) ('Size 1), decoderInputSeqDim, seqDim]))
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]) (m :: * -&gt; *).
MonadThrow m =&gt;
TensorSpec gradient layout device dataType shape
-&gt; m (Tensor gradient layout device dataType shape)
</span><a href="Torch.GraduallyTyped.Tensor.Creation.html#sZeros"><span class="hs-identifier hs-var">sZeros</span></a></span><span> </span><span class="annot"><span class="annottext">(TensorSpec
   ('Gradient 'WithoutGradient)
   layout
   device
   transformerDataType
   ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), decoderInputSeqDim, seqDim])
 -&gt; m (Tensor
         ('Gradient 'WithoutGradient)
         layout
         device
         transformerDataType
         ('Shape
            '[ 'Dim ('Name &quot;*&quot;) ('Size 1), decoderInputSeqDim, seqDim])))
-&gt; TensorSpec
     ('Gradient 'WithoutGradient)
     layout
     device
     transformerDataType
     ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), decoderInputSeqDim, seqDim])
-&gt; m (Tensor
        ('Gradient 'WithoutGradient)
        layout
        device
        transformerDataType
        ('Shape
           '[ 'Dim ('Name &quot;*&quot;) ('Size 1), decoderInputSeqDim, seqDim]))
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-729"></span><span>      </span><span class="annot"><span class="annottext">SGradient ('Gradient 'WithoutGradient)
-&gt; SLayout layout
-&gt; SDevice device
-&gt; SDataType transformerDataType
-&gt; SShape
     ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), decoderInputSeqDim, seqDim])
-&gt; TensorSpec
     ('Gradient 'WithoutGradient)
     layout
     device
     transformerDataType
     ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), decoderInputSeqDim, seqDim])
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SShape shape
-&gt; TensorSpec gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorSpec"><span class="hs-identifier hs-var">TensorSpec</span></a></span><span>
</span><span id="line-730"></span><span>        </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SRequiresGradient 'WithoutGradient
-&gt; SGradient ('Gradient 'WithoutGradient)
forall (requiresGradient :: RequiresGradient).
SRequiresGradient requiresGradient
-&gt; SGradient ('Gradient requiresGradient)
</span><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier hs-var">SGradient</span></a></span><span> </span><span class="annot"><span class="annottext">SRequiresGradient 'WithoutGradient
</span><a href="Torch.GraduallyTyped.RequiresGradient.html#SWithoutGradient"><span class="hs-identifier hs-var">SWithoutGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-731"></span><span>        </span><span class="annot"><span class="annottext">SLayout layout
</span><a href="#local-6989586621679677108"><span class="hs-identifier hs-var">pmLayout</span></a></span><span>
</span><span id="line-732"></span><span>        </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679677107"><span class="hs-identifier hs-var">pmDevice</span></a></span><span>
</span><span id="line-733"></span><span>        </span><span class="annot"><span class="annottext">SDataType transformerDataType
</span><a href="#local-6989586621679677113"><span class="hs-identifier hs-var">transformerDataType</span></a></span><span>
</span><span id="line-734"></span><span>        </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SList '[ 'Dim ('Name &quot;*&quot;) ('Size 1), decoderInputSeqDim, seqDim]
-&gt; SShape
     ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), decoderInputSeqDim, seqDim])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList '[ 'Dim ('Name &quot;*&quot;) ('Size 1), decoderInputSeqDim, seqDim]
 -&gt; SShape
      ('Shape
         '[ 'Dim ('Name &quot;*&quot;) ('Size 1), decoderInputSeqDim, seqDim]))
-&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 1), decoderInputSeqDim, seqDim]
-&gt; SShape
     ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), decoderInputSeqDim, seqDim])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize ('Size 1) -&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 1))
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownNat 1 =&gt; SSize ('Size 1)
forall (size :: Nat). KnownNat size =&gt; SSize ('Size size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier hs-var">SSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">1</span></span><span> </span><span class="annot"><span class="annottext">Sing ('Dim ('Name &quot;*&quot;) ('Size 1))
-&gt; SList '[decoderInputSeqDim, seqDim]
-&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 1), decoderInputSeqDim, seqDim]
forall a1 (a2 :: a1) (as :: [a1]).
Sing a2 -&gt; SList as -&gt; SList (a2 : as)
</span><a href="Torch.GraduallyTyped.Prelude.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">Sing decoderInputSeqDim
SDim decoderInputSeqDim
</span><a href="#local-6989586621679677109"><span class="hs-identifier hs-var">decoderInputSeqDim</span></a></span><span> </span><span class="annot"><span class="annottext">Sing decoderInputSeqDim
-&gt; SList '[seqDim] -&gt; SList '[decoderInputSeqDim, seqDim]
forall a1 (a2 :: a1) (as :: [a1]).
Sing a2 -&gt; SList as -&gt; SList (a2 : as)
</span><a href="Torch.GraduallyTyped.Prelude.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">Sing seqDim
SDim seqDim
</span><a href="#local-6989586621679677105"><span class="hs-identifier hs-var">pmSeqDim</span></a></span><span> </span><span class="annot"><span class="annottext">Sing seqDim -&gt; SList '[] -&gt; SList '[seqDim]
forall a1 (a2 :: a1) (as :: [a1]).
Sing a2 -&gt; SList as -&gt; SList (a2 : as)
</span><a href="Torch.GraduallyTyped.Prelude.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-735"></span><span>  </span><span id="local-6989586621679677103"><span class="annot"><span class="annottext">Tensor
  gradient
  layout
  device
  dataType
  (UnsqueezeF ('SelectDim ('ByIndex 1)) shape)
</span><a href="#local-6989586621679677103"><span class="hs-identifier hs-var">paddingMask'</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
-&gt; m (Tensor
        gradient
        layout
        device
        dataType
        (UnsqueezeF ('SelectDim ('ByIndex 1)) shape))
forall (selectDim :: SelectDim (By Symbol Nat))
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]) (m :: * -&gt; *).
(shape' ~ UnsqueezeF selectDim shape, Catch shape',
 SingI selectDim, MonadThrow m) =&gt;
Tensor gradient layout device dataType shape
-&gt; m (Tensor gradient layout device dataType shape')
</span><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#unsqueeze"><span class="hs-identifier hs-var">unsqueeze</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679677110"><span class="hs-identifier hs-var">paddingMask</span></a></span><span>
</span><span id="line-736"></span><span>  </span><span class="annot"><span class="annottext">Tensor
  gradient
  layout
  device
  dataType
  (UnsqueezeF ('SelectDim ('ByIndex 1)) shape)
-&gt; Double
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     layout
     device
     transformerDataType
     ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), decoderInputSeqDim, seqDim])
-&gt; m (Tensor
        ('Gradient 'WithoutGradient)
        (layout &lt;+&gt; (layout &lt;+&gt; 'Layout 'Dense))
        (device &lt;+&gt; device)
        transformerDataType
        (BroadcastShapesF
           (UnsqueezeF ('SelectDim ('ByIndex 1)) shape)
           ('Shape
              '[ 'Dim ('Name &quot;*&quot;) ('Size 1), decoderInputSeqDim, seqDim])))
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]) value
       (gradient' :: Gradient RequiresGradient)
       (layout' :: Layout LayoutType) (device' :: Device (DeviceType Nat))
       (dataType' :: DataType DType)
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)])
       (shape'' :: Shape [Dim (Name Symbol) (Size Nat)]) (m :: * -&gt; *).
(Scalar value, MonadThrow m,
 Catch (gradient &lt;+&gt; 'Gradient 'WithoutGradient),
 Catch (dataType &lt;+&gt; 'DataType 'Bool),
 shape'' ~ BroadcastShapesF shape shape', Catch shape'') =&gt;
Tensor gradient layout device dataType shape
-&gt; value
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; m (Tensor
        gradient'
        (layout &lt;+&gt; (layout' &lt;+&gt; 'Layout 'Dense))
        (device &lt;+&gt; device')
        dataType'
        shape'')
</span><a href="Torch.GraduallyTyped.Tensor.Other.html#maskedFill"><span class="hs-identifier hs-var">maskedFill</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  gradient
  layout
  device
  dataType
  (UnsqueezeF ('SelectDim ('ByIndex 1)) shape)
</span><a href="#local-6989586621679677103"><span class="hs-identifier hs-var">paddingMask'</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679677111"><span class="hs-identifier hs-var">attentionMaskBias</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  layout
  device
  transformerDataType
  ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), decoderInputSeqDim, seqDim])
</span><a href="#local-6989586621679677104"><span class="hs-identifier hs-var">emptyMask</span></a></span><span>
</span><span id="line-737"></span><span>
</span><span id="line-738"></span><span id="local-6989586621679677101"><span id="local-6989586621679677102"></span></span><span class="hs-keyword">data</span><span> </span><span id="MkTransformerCrossAttentionMask"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerCrossAttentionMask"><span class="hs-identifier hs-var">MkTransformerCrossAttentionMask</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679677100"><span class="annot"><a href="#local-6989586621679677100"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier hs-type">DType</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-739"></span><span>  </span><span id="MkTransformerCrossAttentionMask"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerCrossAttentionMask"><span class="hs-identifier hs-var">MkTransformerCrossAttentionMask</span></a></span></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-740"></span><span>    </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679677706"><span class="annot"><a href="#local-6989586621679677706"><span class="hs-identifier hs-type">dataType</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-741"></span><span>    </span><span class="hs-special">{</span><span> </span><span id="crossAttentionMaskDataType"><span class="annot"><span class="annottext">MkTransformerCrossAttentionMask dataType -&gt; SDataType dataType
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#crossAttentionMaskDataType"><span class="hs-identifier hs-var hs-var">crossAttentionMaskDataType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier hs-type">SDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677706"><span class="hs-identifier hs-type">dataType</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-742"></span><span>      </span><span id="crossAttentionMaskBias"><span class="annot"><span class="annottext">MkTransformerCrossAttentionMask dataType -&gt; Double
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#crossAttentionMaskBias"><span class="hs-identifier hs-var hs-var">crossAttentionMaskBias</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span>
</span><span id="line-743"></span><span>    </span><span class="hs-special">}</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-744"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerCrossAttentionMask"><span class="hs-identifier hs-type">MkTransformerCrossAttentionMask</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677706"><span class="hs-identifier hs-type">dataType</span></a></span><span>
</span><span id="line-745"></span><span>  </span><span class="hs-keyword">deriving</span><span> </span><span class="annot"><span class="hs-keyword">stock</span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679677091"><span id="local-6989586621679677093"><span id="local-6989586621679677095"><span class="annot"><span class="annottext">Int -&gt; MkTransformerCrossAttentionMask dataType -&gt; ShowS
[MkTransformerCrossAttentionMask dataType] -&gt; ShowS
MkTransformerCrossAttentionMask dataType -&gt; String
(Int -&gt; MkTransformerCrossAttentionMask dataType -&gt; ShowS)
-&gt; (MkTransformerCrossAttentionMask dataType -&gt; String)
-&gt; ([MkTransformerCrossAttentionMask dataType] -&gt; ShowS)
-&gt; Show (MkTransformerCrossAttentionMask dataType)
forall a.
(Int -&gt; a -&gt; ShowS) -&gt; (a -&gt; String) -&gt; ([a] -&gt; ShowS) -&gt; Show a
forall (dataType :: DataType DType).
Int -&gt; MkTransformerCrossAttentionMask dataType -&gt; ShowS
forall (dataType :: DataType DType).
[MkTransformerCrossAttentionMask dataType] -&gt; ShowS
forall (dataType :: DataType DType).
MkTransformerCrossAttentionMask dataType -&gt; String
showList :: [MkTransformerCrossAttentionMask dataType] -&gt; ShowS
$cshowList :: forall (dataType :: DataType DType).
[MkTransformerCrossAttentionMask dataType] -&gt; ShowS
show :: MkTransformerCrossAttentionMask dataType -&gt; String
$cshow :: forall (dataType :: DataType DType).
MkTransformerCrossAttentionMask dataType -&gt; String
showsPrec :: Int -&gt; MkTransformerCrossAttentionMask dataType -&gt; ShowS
$cshowsPrec :: forall (dataType :: DataType DType).
Int -&gt; MkTransformerCrossAttentionMask dataType -&gt; ShowS
</span><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">Show</span></span></span></span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">(forall x.
 MkTransformerCrossAttentionMask dataType
 -&gt; Rep (MkTransformerCrossAttentionMask dataType) x)
-&gt; (forall x.
    Rep (MkTransformerCrossAttentionMask dataType) x
    -&gt; MkTransformerCrossAttentionMask dataType)
-&gt; Generic (MkTransformerCrossAttentionMask dataType)
forall x.
Rep (MkTransformerCrossAttentionMask dataType) x
-&gt; MkTransformerCrossAttentionMask dataType
forall x.
MkTransformerCrossAttentionMask dataType
-&gt; Rep (MkTransformerCrossAttentionMask dataType) x
forall a.
(forall x. a -&gt; Rep a x) -&gt; (forall x. Rep a x -&gt; a) -&gt; Generic a
forall (dataType :: DataType DType) x.
Rep (MkTransformerCrossAttentionMask dataType) x
-&gt; MkTransformerCrossAttentionMask dataType
forall (dataType :: DataType DType) x.
MkTransformerCrossAttentionMask dataType
-&gt; Rep (MkTransformerCrossAttentionMask dataType) x
$cto :: forall (dataType :: DataType DType) x.
Rep (MkTransformerCrossAttentionMask dataType) x
-&gt; MkTransformerCrossAttentionMask dataType
$cfrom :: forall (dataType :: DataType DType) x.
MkTransformerCrossAttentionMask dataType
-&gt; Rep (MkTransformerCrossAttentionMask dataType) x
</span><span class="hs-identifier hs-var hs-var hs-var hs-var">Generic</span></span><span class="hs-special">)</span><span>
</span><span id="line-746"></span><span>
</span><span id="line-747"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">instance</span><span>
</span><span id="line-748"></span><span>  </span><span id="ModelSpec"><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier hs-var">ModelSpec</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerCrossAttentionMask"><span class="hs-identifier hs-type">MkTransformerCrossAttentionMask</span></a></span><span> </span><span id="local-6989586621679677088"><span class="annot"><a href="#local-6989586621679677088"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-749"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerCrossAttentionMask"><span class="hs-identifier hs-type">MkTransformerCrossAttentionMask</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677088"><span class="hs-identifier hs-type">dataType</span></a></span><span>
</span><span id="line-750"></span><span>
</span><span id="line-751"></span><span id="local-6989586621679677086"><span id="local-6989586621679677087"><span class="hs-keyword">instance</span><span>
</span><span id="line-752"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span>
</span><span id="line-753"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerCrossAttentionMask"><span class="hs-identifier hs-type">MkTransformerCrossAttentionMask</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677087"><span class="hs-identifier hs-type">dataType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-754"></span><span>    </span><span class="annot"><a href="#local-6989586621679677086"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-755"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerCrossAttentionMask"><span class="hs-identifier hs-type">MkTransformerCrossAttentionMask</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677087"><span class="hs-identifier hs-type">dataType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-756"></span><span>    </span><span class="annot"><a href="#local-6989586621679677086"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-757"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-758"></span><span>  </span><span id="local-6989586621679677084"><span class="annot"><span class="annottext">initialize :: ModelSpec (MkTransformerCrossAttentionMask dataType)
-&gt; Generator generatorDevice
-&gt; m (MkTransformerCrossAttentionMask dataType,
      Generator generatorDevice)
</span><a href="#local-6989586621679677084"><span class="hs-identifier hs-var hs-var hs-var hs-var">initialize</span></a></span></span><span> </span><span id="local-6989586621679677083"><span class="annot"><span class="annottext">ModelSpec (MkTransformerCrossAttentionMask dataType)
</span><a href="#local-6989586621679677083"><span class="hs-identifier hs-var">spec</span></a></span></span><span> </span><span id="local-6989586621679677082"><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679677082"><span class="hs-identifier hs-var">g</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(MkTransformerCrossAttentionMask dataType,
 Generator generatorDevice)
-&gt; m (MkTransformerCrossAttentionMask dataType,
      Generator generatorDevice)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">ModelSpec (MkTransformerCrossAttentionMask dataType)
MkTransformerCrossAttentionMask dataType
</span><a href="#local-6989586621679677083"><span class="hs-identifier hs-var">spec</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679677082"><span class="hs-identifier hs-var">g</span></a></span><span class="hs-special">)</span></span></span><span>
</span><span id="line-759"></span><span>
</span><span id="line-760"></span><span id="local-6989586621679677081"><span class="hs-keyword">instance</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasStateDict"><span class="hs-identifier hs-type">HasStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerCrossAttentionMask"><span class="hs-identifier hs-type">MkTransformerCrossAttentionMask</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677081"><span class="hs-identifier hs-type">dataType</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-761"></span><span>  </span><span id="local-6989586621679677078"><span class="annot"><span class="annottext">fromStateDict :: ModelSpec (MkTransformerCrossAttentionMask dataType)
-&gt; StateDictKey -&gt; m (MkTransformerCrossAttentionMask dataType)
</span><a href="#local-6989586621679677078"><span class="hs-identifier hs-var hs-var hs-var hs-var">fromStateDict</span></a></span></span><span> </span><span id="local-6989586621679677077"><span class="annot"><span class="annottext">ModelSpec (MkTransformerCrossAttentionMask dataType)
</span><a href="#local-6989586621679677077"><span class="hs-identifier hs-var">spec</span></a></span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">MkTransformerCrossAttentionMask dataType
-&gt; m (MkTransformerCrossAttentionMask dataType)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">ModelSpec (MkTransformerCrossAttentionMask dataType)
MkTransformerCrossAttentionMask dataType
</span><a href="#local-6989586621679677077"><span class="hs-identifier hs-var">spec</span></a></span><span>
</span><span id="line-762"></span><span>  </span><span id="local-6989586621679677076"><span class="annot"><span class="annottext">toStateDict :: StateDictKey -&gt; MkTransformerCrossAttentionMask dataType -&gt; m ()
</span><a href="#local-6989586621679677076"><span class="hs-identifier hs-var hs-var hs-var hs-var">toStateDict</span></a></span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="annottext">MkTransformerCrossAttentionMask dataType
</span><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">() -&gt; m ()
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span></span><span>
</span><span id="line-763"></span><span>
</span><span id="line-764"></span><span id="local-6989586621679677061"><span id="local-6989586621679677062"><span id="local-6989586621679677063"><span id="local-6989586621679677064"><span id="local-6989586621679677065"><span id="local-6989586621679677066"><span id="local-6989586621679677067"><span id="local-6989586621679677068"><span id="local-6989586621679677069"><span id="local-6989586621679677070"><span id="local-6989586621679677071"><span id="local-6989586621679677072"><span id="local-6989586621679677073"><span id="local-6989586621679677074"><span id="local-6989586621679677075"><span class="hs-keyword">instance</span><span>
</span><span id="line-765"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerCrossAttentionMaskC"><span class="hs-identifier hs-type">MkTransformerCrossAttentionMaskC</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677075"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677074"><span class="hs-identifier hs-type">decoderInputShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677073"><span class="hs-identifier hs-type">decoderInputSeqDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677072"><span class="hs-identifier hs-type">inputPaddingMaskGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677071"><span class="hs-identifier hs-type">inputPaddingMaskLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677070"><span class="hs-identifier hs-type">inputPaddingMaskDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677069"><span class="hs-identifier hs-type">inputPaddingMaksDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677068"><span class="hs-identifier hs-type">inputPaddingMaskShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677067"><span class="hs-identifier hs-type">seqDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677066"><span class="hs-identifier hs-type">output</span></a></span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-766"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-767"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerCrossAttentionMask"><span class="hs-identifier hs-type">MkTransformerCrossAttentionMask</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677075"><span class="hs-identifier hs-type">dataType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-768"></span><span>    </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677065"><span class="hs-identifier hs-type">decoderInputGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677064"><span class="hs-identifier hs-type">decoderInputLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677063"><span class="hs-identifier hs-type">decoderInputDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677062"><span class="hs-identifier hs-type">decoderInputDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677074"><span class="hs-identifier hs-type">decoderInputShape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-769"></span><span>      </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677072"><span class="hs-identifier hs-type">inputPaddingMaskGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677071"><span class="hs-identifier hs-type">inputPaddingMaskLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677070"><span class="hs-identifier hs-type">inputPaddingMaskDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677069"><span class="hs-identifier hs-type">inputPaddingMaksDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677068"><span class="hs-identifier hs-type">inputPaddingMaskShape</span></a></span><span>
</span><span id="line-770"></span><span>    </span><span class="hs-special">)</span><span>
</span><span id="line-771"></span><span>    </span><span class="annot"><a href="#local-6989586621679677061"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-772"></span><span>    </span><span class="annot"><a href="#local-6989586621679677066"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-773"></span><span>    </span><span class="annot"><a href="#local-6989586621679677061"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-774"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-775"></span><span>  </span><span id="local-6989586621679677059"><span class="annot"><span class="annottext">forward :: MkTransformerCrossAttentionMask dataType
-&gt; (Tensor
      decoderInputGradient
      decoderInputLayout
      decoderInputDevice
      decoderInputDataType
      decoderInputShape,
    Tensor
      inputPaddingMaskGradient
      inputPaddingMaskLayout
      inputPaddingMaskDevice
      inputPaddingMaksDataType
      inputPaddingMaskShape)
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorDevice)
</span><a href="#local-6989586621679677059"><span class="hs-identifier hs-var hs-var hs-var hs-var">forward</span></a></span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerCrossAttentionMask"><span class="hs-identifier hs-type">MkTransformerCrossAttentionMask</span></a></span><span> </span><span class="hs-special">{</span><span id="local-6989586621679677057"><span id="local-6989586621679677058"><span class="annot"><span class="annottext">Double
SDataType dataType
crossAttentionMaskBias :: Double
crossAttentionMaskDataType :: SDataType dataType
crossAttentionMaskBias :: forall (dataType :: DataType DType).
MkTransformerCrossAttentionMask dataType -&gt; Double
crossAttentionMaskDataType :: forall (dataType :: DataType DType).
MkTransformerCrossAttentionMask dataType -&gt; SDataType dataType
</span><a href="#local-6989586621679677057"><span class="hs-glyph hs-var hs-var hs-var hs-var">..</span></a></span></span></span><span class="hs-special">}</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679677056"><span class="annot"><span class="annottext">Tensor
  decoderInputGradient
  decoderInputLayout
  decoderInputDevice
  decoderInputDataType
  decoderInputShape
</span><a href="#local-6989586621679677056"><span class="hs-identifier hs-var">decoderInput</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679677055"><span class="annot"><span class="annottext">Tensor
  inputPaddingMaskGradient
  inputPaddingMaskLayout
  inputPaddingMaskDevice
  inputPaddingMaksDataType
  inputPaddingMaskShape
</span><a href="#local-6989586621679677055"><span class="hs-identifier hs-var">inputPaddingMask</span></a></span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679677054"><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679677054"><span class="hs-identifier hs-var">g</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-776"></span><span>    </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679677053"><span class="annot"><span class="annottext">decoderInputShape :: SShape decoderInputShape
</span><a href="#local-6989586621679677053"><span class="hs-identifier hs-var hs-var">decoderInputShape</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor
  decoderInputGradient
  decoderInputLayout
  decoderInputDevice
  decoderInputDataType
  decoderInputShape
-&gt; SShape decoderInputShape
forall (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType).
SGetShape shape =&gt;
Tensor gradient layout device dataType shape -&gt; SShape shape
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sGetShape"><span class="hs-identifier hs-var">sGetShape</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  decoderInputGradient
  decoderInputLayout
  decoderInputDevice
  decoderInputDataType
  decoderInputShape
</span><a href="#local-6989586621679677056"><span class="hs-identifier hs-var">decoderInput</span></a></span><span>
</span><span id="line-777"></span><span>    </span><span id="local-6989586621679677052"><span class="annot"><span class="annottext">output
</span><a href="#local-6989586621679677052"><span class="hs-identifier hs-var">crossAttentionMask</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">SDataType dataType
-&gt; SShape decoderInputShape
-&gt; Double
-&gt; Tensor
     inputPaddingMaskGradient
     inputPaddingMaskLayout
     inputPaddingMaskDevice
     inputPaddingMaksDataType
     inputPaddingMaskShape
-&gt; m output
forall (m :: * -&gt; *) (transformerDataType :: DataType DType)
       (decoderInputShape :: Shape [Dim (Name Symbol) (Size Nat)])
       (decoderInputSeqDim :: Dim (Name Symbol) (Size Nat))
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (seqDim :: Dim (Name Symbol) (Size Nat)) output.
(MonadThrow m,
 MkTransformerCrossAttentionMaskC
   transformerDataType
   decoderInputShape
   decoderInputSeqDim
   gradient
   layout
   device
   dataType
   shape
   seqDim
   output) =&gt;
SDataType transformerDataType
-&gt; SShape decoderInputShape
-&gt; Double
-&gt; Tensor gradient layout device dataType shape
-&gt; m output
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#mkTransformerCrossAttentionMask"><span class="hs-identifier hs-var">mkTransformerCrossAttentionMask</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679677058"><span class="hs-identifier hs-var">crossAttentionMaskDataType</span></a></span><span> </span><span class="annot"><span class="annottext">SShape decoderInputShape
</span><a href="#local-6989586621679677053"><span class="hs-identifier hs-var">decoderInputShape</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679677057"><span class="hs-identifier hs-var">crossAttentionMaskBias</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  inputPaddingMaskGradient
  inputPaddingMaskLayout
  inputPaddingMaskDevice
  inputPaddingMaksDataType
  inputPaddingMaskShape
</span><a href="#local-6989586621679677055"><span class="hs-identifier hs-var">inputPaddingMask</span></a></span><span>
</span><span id="line-778"></span><span>    </span><span class="annot"><span class="annottext">(output, Generator generatorDevice)
-&gt; m (output, Generator generatorDevice)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">output
</span><a href="#local-6989586621679677052"><span class="hs-identifier hs-var">crossAttentionMask</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679677054"><span class="hs-identifier hs-var">g</span></a></span><span class="hs-special">)</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span>
</span><span id="line-779"></span><span>
</span><span id="line-780"></span><span id="local-6989586621679677050"><span id="local-6989586621679677051"></span></span><span class="hs-keyword">data</span><span> </span><span id="ShiftRight"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ShiftRight"><span class="hs-identifier hs-var">ShiftRight</span></a></span></span><span> </span><span id="local-6989586621679677049"><span class="annot"><a href="#local-6989586621679677049"><span class="hs-identifier hs-type">fillValue</span></a></span></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-781"></span><span>  </span><span id="ShiftRight"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ShiftRight"><span class="hs-identifier hs-var">ShiftRight</span></a></span></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-782"></span><span>    </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679677047"><span class="annot"><a href="#local-6989586621679677047"><span class="hs-identifier hs-type">fillValue</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-783"></span><span>    </span><span class="hs-comment">-- | fill value for shift right</span><span>
</span><span id="line-784"></span><span>    </span><span class="annot"><a href="#local-6989586621679677047"><span class="hs-identifier hs-type">fillValue</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-785"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ShiftRight"><span class="hs-identifier hs-type">ShiftRight</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677047"><span class="hs-identifier hs-type">fillValue</span></a></span><span>
</span><span id="line-786"></span><span>  </span><span class="hs-keyword">deriving</span><span> </span><span class="annot"><span class="hs-keyword">stock</span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679677043"><span id="local-6989586621679677045"><span class="annot"><span class="annottext">ShiftRight fillValue -&gt; ShiftRight fillValue -&gt; Bool
(ShiftRight fillValue -&gt; ShiftRight fillValue -&gt; Bool)
-&gt; (ShiftRight fillValue -&gt; ShiftRight fillValue -&gt; Bool)
-&gt; Eq (ShiftRight fillValue)
forall fillValue.
Eq fillValue =&gt;
ShiftRight fillValue -&gt; ShiftRight fillValue -&gt; Bool
forall a. (a -&gt; a -&gt; Bool) -&gt; (a -&gt; a -&gt; Bool) -&gt; Eq a
/= :: ShiftRight fillValue -&gt; ShiftRight fillValue -&gt; Bool
$c/= :: forall fillValue.
Eq fillValue =&gt;
ShiftRight fillValue -&gt; ShiftRight fillValue -&gt; Bool
== :: ShiftRight fillValue -&gt; ShiftRight fillValue -&gt; Bool
$c== :: forall fillValue.
Eq fillValue =&gt;
ShiftRight fillValue -&gt; ShiftRight fillValue -&gt; Bool
</span><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var">Eq</span></span></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679677028"><span id="local-6989586621679677030"><span id="local-6989586621679677032"><span id="local-6989586621679677034"><span id="local-6989586621679677036"><span id="local-6989586621679677038"><span id="local-6989586621679677040"><span class="annot"><span class="annottext">Eq (ShiftRight fillValue)
Eq (ShiftRight fillValue)
-&gt; (ShiftRight fillValue -&gt; ShiftRight fillValue -&gt; Ordering)
-&gt; (ShiftRight fillValue -&gt; ShiftRight fillValue -&gt; Bool)
-&gt; (ShiftRight fillValue -&gt; ShiftRight fillValue -&gt; Bool)
-&gt; (ShiftRight fillValue -&gt; ShiftRight fillValue -&gt; Bool)
-&gt; (ShiftRight fillValue -&gt; ShiftRight fillValue -&gt; Bool)
-&gt; (ShiftRight fillValue
    -&gt; ShiftRight fillValue -&gt; ShiftRight fillValue)
-&gt; (ShiftRight fillValue
    -&gt; ShiftRight fillValue -&gt; ShiftRight fillValue)
-&gt; Ord (ShiftRight fillValue)
ShiftRight fillValue -&gt; ShiftRight fillValue -&gt; Bool
ShiftRight fillValue -&gt; ShiftRight fillValue -&gt; Ordering
ShiftRight fillValue
-&gt; ShiftRight fillValue -&gt; ShiftRight fillValue
forall a.
Eq a
-&gt; (a -&gt; a -&gt; Ordering)
-&gt; (a -&gt; a -&gt; Bool)
-&gt; (a -&gt; a -&gt; Bool)
-&gt; (a -&gt; a -&gt; Bool)
-&gt; (a -&gt; a -&gt; Bool)
-&gt; (a -&gt; a -&gt; a)
-&gt; (a -&gt; a -&gt; a)
-&gt; Ord a
forall fillValue. Ord fillValue =&gt; Eq (ShiftRight fillValue)
forall fillValue.
Ord fillValue =&gt;
ShiftRight fillValue -&gt; ShiftRight fillValue -&gt; Bool
forall fillValue.
Ord fillValue =&gt;
ShiftRight fillValue -&gt; ShiftRight fillValue -&gt; Ordering
forall fillValue.
Ord fillValue =&gt;
ShiftRight fillValue
-&gt; ShiftRight fillValue -&gt; ShiftRight fillValue
min :: ShiftRight fillValue
-&gt; ShiftRight fillValue -&gt; ShiftRight fillValue
$cmin :: forall fillValue.
Ord fillValue =&gt;
ShiftRight fillValue
-&gt; ShiftRight fillValue -&gt; ShiftRight fillValue
max :: ShiftRight fillValue
-&gt; ShiftRight fillValue -&gt; ShiftRight fillValue
$cmax :: forall fillValue.
Ord fillValue =&gt;
ShiftRight fillValue
-&gt; ShiftRight fillValue -&gt; ShiftRight fillValue
&gt;= :: ShiftRight fillValue -&gt; ShiftRight fillValue -&gt; Bool
$c&gt;= :: forall fillValue.
Ord fillValue =&gt;
ShiftRight fillValue -&gt; ShiftRight fillValue -&gt; Bool
&gt; :: ShiftRight fillValue -&gt; ShiftRight fillValue -&gt; Bool
$c&gt; :: forall fillValue.
Ord fillValue =&gt;
ShiftRight fillValue -&gt; ShiftRight fillValue -&gt; Bool
&lt;= :: ShiftRight fillValue -&gt; ShiftRight fillValue -&gt; Bool
$c&lt;= :: forall fillValue.
Ord fillValue =&gt;
ShiftRight fillValue -&gt; ShiftRight fillValue -&gt; Bool
&lt; :: ShiftRight fillValue -&gt; ShiftRight fillValue -&gt; Bool
$c&lt; :: forall fillValue.
Ord fillValue =&gt;
ShiftRight fillValue -&gt; ShiftRight fillValue -&gt; Bool
compare :: ShiftRight fillValue -&gt; ShiftRight fillValue -&gt; Ordering
$ccompare :: forall fillValue.
Ord fillValue =&gt;
ShiftRight fillValue -&gt; ShiftRight fillValue -&gt; Ordering
$cp1Ord :: forall fillValue. Ord fillValue =&gt; Eq (ShiftRight fillValue)
</span><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">Ord</span></span></span></span></span></span></span></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679677022"><span id="local-6989586621679677024"><span id="local-6989586621679677026"><span class="annot"><span class="annottext">Int -&gt; ShiftRight fillValue -&gt; ShowS
[ShiftRight fillValue] -&gt; ShowS
ShiftRight fillValue -&gt; String
(Int -&gt; ShiftRight fillValue -&gt; ShowS)
-&gt; (ShiftRight fillValue -&gt; String)
-&gt; ([ShiftRight fillValue] -&gt; ShowS)
-&gt; Show (ShiftRight fillValue)
forall fillValue.
Show fillValue =&gt;
Int -&gt; ShiftRight fillValue -&gt; ShowS
forall fillValue. Show fillValue =&gt; [ShiftRight fillValue] -&gt; ShowS
forall fillValue. Show fillValue =&gt; ShiftRight fillValue -&gt; String
forall a.
(Int -&gt; a -&gt; ShowS) -&gt; (a -&gt; String) -&gt; ([a] -&gt; ShowS) -&gt; Show a
showList :: [ShiftRight fillValue] -&gt; ShowS
$cshowList :: forall fillValue. Show fillValue =&gt; [ShiftRight fillValue] -&gt; ShowS
show :: ShiftRight fillValue -&gt; String
$cshow :: forall fillValue. Show fillValue =&gt; ShiftRight fillValue -&gt; String
showsPrec :: Int -&gt; ShiftRight fillValue -&gt; ShowS
$cshowsPrec :: forall fillValue.
Show fillValue =&gt;
Int -&gt; ShiftRight fillValue -&gt; ShowS
</span><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">Show</span></span></span></span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">(forall x. ShiftRight fillValue -&gt; Rep (ShiftRight fillValue) x)
-&gt; (forall x. Rep (ShiftRight fillValue) x -&gt; ShiftRight fillValue)
-&gt; Generic (ShiftRight fillValue)
forall x. Rep (ShiftRight fillValue) x -&gt; ShiftRight fillValue
forall x. ShiftRight fillValue -&gt; Rep (ShiftRight fillValue) x
forall a.
(forall x. a -&gt; Rep a x) -&gt; (forall x. Rep a x -&gt; a) -&gt; Generic a
forall fillValue x.
Rep (ShiftRight fillValue) x -&gt; ShiftRight fillValue
forall fillValue x.
ShiftRight fillValue -&gt; Rep (ShiftRight fillValue) x
$cto :: forall fillValue x.
Rep (ShiftRight fillValue) x -&gt; ShiftRight fillValue
$cfrom :: forall fillValue x.
ShiftRight fillValue -&gt; Rep (ShiftRight fillValue) x
</span><span class="hs-identifier hs-var hs-var hs-var hs-var">Generic</span></span><span class="hs-special">)</span><span>
</span><span id="line-787"></span><span>
</span><span id="line-788"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">instance</span><span> </span><span id="ModelSpec"><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier hs-var">ModelSpec</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ShiftRight"><span class="hs-identifier hs-type">ShiftRight</span></a></span><span> </span><span id="local-6989586621679677019"><span class="annot"><a href="#local-6989586621679677019"><span class="hs-identifier hs-type hs-type">fillValue</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ShiftRight"><span class="hs-identifier hs-type">ShiftRight</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677019"><span class="hs-identifier hs-type">fillValue</span></a></span><span>
</span><span id="line-789"></span><span>
</span><span id="line-790"></span><span id="local-6989586621679677017"><span id="local-6989586621679677018"><span class="hs-keyword">instance</span><span>
</span><span id="line-791"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span>
</span><span id="line-792"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ShiftRight"><span class="hs-identifier hs-type">ShiftRight</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677018"><span class="hs-identifier hs-type">fillValue</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-793"></span><span>    </span><span class="annot"><a href="#local-6989586621679677017"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-794"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ShiftRight"><span class="hs-identifier hs-type">ShiftRight</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677018"><span class="hs-identifier hs-type">fillValue</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-795"></span><span>    </span><span class="annot"><a href="#local-6989586621679677017"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-796"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-797"></span><span>  </span><span id="local-6989586621679677015"><span class="annot"><span class="annottext">initialize :: ModelSpec (ShiftRight fillValue)
-&gt; Generator generatorDevice
-&gt; m (ShiftRight fillValue, Generator generatorDevice)
</span><a href="#local-6989586621679677015"><span class="hs-identifier hs-var hs-var hs-var hs-var">initialize</span></a></span></span><span> </span><span id="local-6989586621679677014"><span class="annot"><span class="annottext">ModelSpec (ShiftRight fillValue)
</span><a href="#local-6989586621679677014"><span class="hs-identifier hs-var">spec</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(ShiftRight fillValue, Generator generatorDevice)
-&gt; m (ShiftRight fillValue, Generator generatorDevice)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">((ShiftRight fillValue, Generator generatorDevice)
 -&gt; m (ShiftRight fillValue, Generator generatorDevice))
-&gt; (Generator generatorDevice
    -&gt; (ShiftRight fillValue, Generator generatorDevice))
-&gt; Generator generatorDevice
-&gt; m (ShiftRight fillValue, Generator generatorDevice)
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">ModelSpec (ShiftRight fillValue)
ShiftRight fillValue
</span><a href="#local-6989586621679677014"><span class="hs-identifier hs-var">spec</span></a></span><span class="hs-special">,</span><span class="hs-special">)</span></span></span><span>
</span><span id="line-798"></span><span>
</span><span id="line-799"></span><span id="local-6989586621679677013"><span class="hs-keyword">instance</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasStateDict"><span class="hs-identifier hs-type">HasStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ShiftRight"><span class="hs-identifier hs-type">ShiftRight</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677013"><span class="hs-identifier hs-type">fillValue</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-800"></span><span>  </span><span id="local-6989586621679677010"><span class="annot"><span class="annottext">fromStateDict :: ModelSpec (ShiftRight fillValue)
-&gt; StateDictKey -&gt; m (ShiftRight fillValue)
</span><a href="#local-6989586621679677010"><span class="hs-identifier hs-var hs-var hs-var hs-var">fromStateDict</span></a></span></span><span> </span><span id="local-6989586621679677009"><span class="annot"><span class="annottext">ModelSpec (ShiftRight fillValue)
</span><a href="#local-6989586621679677009"><span class="hs-identifier hs-var">spec</span></a></span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ShiftRight fillValue -&gt; m (ShiftRight fillValue)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">ModelSpec (ShiftRight fillValue)
ShiftRight fillValue
</span><a href="#local-6989586621679677009"><span class="hs-identifier hs-var">spec</span></a></span><span>
</span><span id="line-801"></span><span>  </span><span id="local-6989586621679677008"><span class="annot"><span class="annottext">toStateDict :: StateDictKey -&gt; ShiftRight fillValue -&gt; m ()
</span><a href="#local-6989586621679677008"><span class="hs-identifier hs-var hs-var hs-var hs-var">toStateDict</span></a></span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="annottext">ShiftRight fillValue
</span><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">() -&gt; m ()
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span></span><span>
</span><span id="line-802"></span><span>
</span><span id="line-803"></span><span id="local-6989586621679676997"><span id="local-6989586621679676998"><span id="local-6989586621679676999"><span id="local-6989586621679677000"><span id="local-6989586621679677001"><span id="local-6989586621679677002"><span id="local-6989586621679677003"><span id="local-6989586621679677004"><span id="local-6989586621679677005"><span id="local-6989586621679677006"><span id="local-6989586621679677007"><span class="hs-keyword">instance</span><span>
</span><span id="line-804"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="#local-6989586621679677007"><span class="hs-identifier hs-type">input</span></a></span><span>
</span><span id="line-805"></span><span>      </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-806"></span><span>          </span><span class="annot"><a href="#local-6989586621679677006"><span class="hs-identifier hs-type">inputGradient</span></a></span><span>
</span><span id="line-807"></span><span>          </span><span class="annot"><a href="#local-6989586621679677005"><span class="hs-identifier hs-type">inputLayout</span></a></span><span>
</span><span id="line-808"></span><span>          </span><span class="annot"><a href="#local-6989586621679677004"><span class="hs-identifier hs-type">inputDevice</span></a></span><span>
</span><span id="line-809"></span><span>          </span><span class="annot"><a href="#local-6989586621679677003"><span class="hs-identifier hs-type">inputDataType</span></a></span><span>
</span><span id="line-810"></span><span>          </span><span class="annot"><a href="#local-6989586621679677002"><span class="hs-identifier hs-type">inputShape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-811"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetLayout"><span class="hs-identifier hs-type">SGetLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677005"><span class="hs-identifier hs-type">inputLayout</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-812"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetDevice"><span class="hs-identifier hs-type">SGetDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677004"><span class="hs-identifier hs-type">inputDevice</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-813"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetDataType"><span class="hs-identifier hs-type">SGetDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677003"><span class="hs-identifier hs-type">inputDataType</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-814"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetShape"><span class="hs-identifier hs-type">SGetShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677002"><span class="hs-identifier hs-type">inputShape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-815"></span><span>    </span><span class="annot"><a href="#local-6989586621679677001"><span class="hs-identifier hs-type">inputBatchDim</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679677002"><span class="hs-identifier hs-type">inputShape</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#%21"><span class="hs-glyph hs-type">!</span></a></span><span> </span><span class="annot"><span class="hs-number">0</span></span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-816"></span><span>    </span><span class="annot"><a href="#local-6989586621679677000"><span class="hs-identifier hs-type">inputSeqDim</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679677002"><span class="hs-identifier hs-type">inputShape</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#%21"><span class="hs-glyph hs-type">!</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-817"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Scalar.html#Scalar"><span class="hs-identifier hs-type">Scalar</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679676999"><span class="hs-identifier hs-type">fillValue</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-818"></span><span>    </span><span class="annot"><a href="#local-6989586621679676998"><span class="hs-identifier hs-type">rightShiftedInput</span></a></span><span>
</span><span id="line-819"></span><span>      </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-820"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679677006"><span class="hs-identifier hs-type">inputGradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#WithoutGradient"><span class="hs-identifier hs-type">WithoutGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-821"></span><span>          </span><span class="annot"><a href="#local-6989586621679677005"><span class="hs-identifier hs-type">inputLayout</span></a></span><span>
</span><span id="line-822"></span><span>          </span><span class="annot"><a href="#local-6989586621679677004"><span class="hs-identifier hs-type">inputDevice</span></a></span><span>
</span><span id="line-823"></span><span>          </span><span class="annot"><a href="#local-6989586621679677003"><span class="hs-identifier hs-type">inputDataType</span></a></span><span>
</span><span id="line-824"></span><span>          </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#ReplaceDimF"><span class="hs-identifier hs-type">ReplaceDimF</span></a></span><span>
</span><span id="line-825"></span><span>              </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-826"></span><span>              </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679677002"><span class="hs-identifier hs-type">inputShape</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679677001"><span class="hs-identifier hs-type">inputBatchDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679677000"><span class="hs-identifier hs-type">inputSeqDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-827"></span><span>              </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#AddDimF"><span class="hs-identifier hs-type">AddDimF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679677000"><span class="hs-identifier hs-type">inputSeqDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-828"></span><span>          </span><span class="hs-special">)</span><span>
</span><span id="line-829"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-830"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ShiftRight"><span class="hs-identifier hs-type">ShiftRight</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679676999"><span class="hs-identifier hs-type">fillValue</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679677007"><span class="hs-identifier hs-type">input</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679676997"><span class="hs-identifier hs-type">generator</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679676998"><span class="hs-identifier hs-type">rightShiftedInput</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679676997"><span class="hs-identifier hs-type">generator</span></a></span><span>
</span><span id="line-831"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-832"></span><span>  </span><span id="local-6989586621679676995"><span class="annot"><span class="annottext">forward :: ShiftRight fillValue
-&gt; input
-&gt; Generator generator
-&gt; m (rightShiftedInput, Generator generator)
</span><a href="#local-6989586621679676995"><span class="hs-identifier hs-var hs-var hs-var hs-var">forward</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ShiftRight"><span class="hs-identifier hs-type">ShiftRight</span></a></span><span> </span><span id="local-6989586621679676994"><span class="annot"><span class="annottext">fillValue
</span><a href="#local-6989586621679676994"><span class="hs-identifier hs-var">fillValue</span></a></span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679676993"><span class="annot"><span class="annottext">input
</span><a href="#local-6989586621679676993"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span id="local-6989586621679676992"><span class="annot"><span class="annottext">Generator generator
</span><a href="#local-6989586621679676992"><span class="hs-identifier hs-var">g</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-833"></span><span>    </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679676991"><span class="annot"><span class="annottext">inputLayout :: SLayout inputLayout
</span><a href="#local-6989586621679676991"><span class="hs-identifier hs-var hs-var">inputLayout</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor
  inputGradient inputLayout inputDevice inputDataType inputShape
-&gt; SLayout inputLayout
forall (layout :: Layout LayoutType)
       (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SGetLayout layout =&gt;
Tensor gradient layout device dataType shape -&gt; SLayout layout
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sGetLayout"><span class="hs-identifier hs-var">sGetLayout</span></a></span><span> </span><span class="annot"><span class="annottext">input
Tensor
  inputGradient inputLayout inputDevice inputDataType inputShape
</span><a href="#local-6989586621679676993"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-834"></span><span>        </span><span id="local-6989586621679676990"><span class="annot"><span class="annottext">inputDevice :: SDevice inputDevice
</span><a href="#local-6989586621679676990"><span class="hs-identifier hs-var hs-var">inputDevice</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor
  inputGradient inputLayout inputDevice inputDataType inputShape
-&gt; SDevice inputDevice
forall (device :: Device (DeviceType Nat))
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SGetDevice device =&gt;
Tensor gradient layout device dataType shape -&gt; SDevice device
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sGetDevice"><span class="hs-identifier hs-var">sGetDevice</span></a></span><span> </span><span class="annot"><span class="annottext">input
Tensor
  inputGradient inputLayout inputDevice inputDataType inputShape
</span><a href="#local-6989586621679676993"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-835"></span><span>        </span><span id="local-6989586621679676989"><span class="annot"><span class="annottext">inputDataType :: SDataType inputDataType
</span><a href="#local-6989586621679676989"><span class="hs-identifier hs-var hs-var">inputDataType</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor
  inputGradient inputLayout inputDevice inputDataType inputShape
-&gt; SDataType inputDataType
forall (dataType :: DataType DType)
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SGetDataType dataType =&gt;
Tensor gradient layout device dataType shape -&gt; SDataType dataType
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sGetDataType"><span class="hs-identifier hs-var">sGetDataType</span></a></span><span> </span><span class="annot"><span class="annottext">input
Tensor
  inputGradient inputLayout inputDevice inputDataType inputShape
</span><a href="#local-6989586621679676993"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-836"></span><span>        </span><span id="local-6989586621679676988"><span class="annot"><span class="annottext">inputShape :: SShape inputShape
</span><a href="#local-6989586621679676988"><span class="hs-identifier hs-var hs-var">inputShape</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor
  inputGradient inputLayout inputDevice inputDataType inputShape
-&gt; SShape inputShape
forall (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType).
SGetShape shape =&gt;
Tensor gradient layout device dataType shape -&gt; SShape shape
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sGetShape"><span class="hs-identifier hs-var">sGetShape</span></a></span><span> </span><span class="annot"><span class="annottext">input
Tensor
  inputGradient inputLayout inputDevice inputDataType inputShape
</span><a href="#local-6989586621679676993"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-837"></span><span>    </span><span id="local-6989586621679676987"><span class="annot"><span class="annottext">SDim inputBatchDim
</span><a href="#local-6989586621679676987"><span class="hs-identifier hs-var">inputBatchDim</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">SSelectDim ('SelectDim ('ByIndex 0))
-&gt; SShape inputShape -&gt; m (SDim inputBatchDim)
forall (selectDim :: SelectDim (By Symbol Nat))
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (dim :: Dim (Name Symbol) (Size Nat)) (m :: * -&gt; *).
(dim ~ GetDimF selectDim shape, MonadThrow m) =&gt;
SSelectDim selectDim -&gt; SShape shape -&gt; m (SDim dim)
</span><a href="Torch.GraduallyTyped.Shape.Class.html#sGetDimFromShape"><span class="hs-identifier hs-var">sGetDimFromShape</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SBy ('ByIndex 0) -&gt; SSelectDim ('SelectDim ('ByIndex 0))
forall (by :: By Symbol Nat). SBy by -&gt; SSelectDim ('SelectDim by)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSelectDim"><span class="hs-identifier hs-var">SSelectDim</span></a></span><span> </span><span class="annot"><span class="annottext">(SBy ('ByIndex 0) -&gt; SSelectDim ('SelectDim ('ByIndex 0)))
-&gt; SBy ('ByIndex 0) -&gt; SSelectDim ('SelectDim ('ByIndex 0))
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">KnownNat 0 =&gt; SBy ('ByIndex 0)
forall (index :: Nat). KnownNat index =&gt; SBy ('ByIndex index)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SByIndex"><span class="hs-identifier hs-var">SByIndex</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">0</span></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">SShape inputShape
</span><a href="#local-6989586621679676988"><span class="hs-identifier hs-var">inputShape</span></a></span><span>
</span><span id="line-838"></span><span>    </span><span id="local-6989586621679676986"><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  inputLayout
  inputDevice
  inputDataType
  ('Shape '[inputBatchDim, 'Dim ('Name &quot;*&quot;) ('Size 1)])
</span><a href="#local-6989586621679676986"><span class="hs-identifier hs-var">filler</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span>
</span><span id="line-839"></span><span>      </span><span class="annot"><span class="annottext">TensorSpec
  ('Gradient 'WithoutGradient)
  inputLayout
  inputDevice
  inputDataType
  ('Shape '[inputBatchDim, 'Dim ('Name &quot;*&quot;) ('Size 1)])
-&gt; fillValue
-&gt; m (Tensor
        ('Gradient 'WithoutGradient)
        inputLayout
        inputDevice
        inputDataType
        ('Shape '[inputBatchDim, 'Dim ('Name &quot;*&quot;) ('Size 1)]))
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]) input
       (m :: * -&gt; *).
(MonadThrow m, Scalar input) =&gt;
TensorSpec gradient layout device dataType shape
-&gt; input -&gt; m (Tensor gradient layout device dataType shape)
</span><a href="Torch.GraduallyTyped.Tensor.Creation.html#sFull"><span class="hs-identifier hs-var">sFull</span></a></span><span>
</span><span id="line-840"></span><span>        </span><span class="hs-special">(</span><span> </span><span class="annot"><span class="annottext">SGradient ('Gradient 'WithoutGradient)
-&gt; SLayout inputLayout
-&gt; SDevice inputDevice
-&gt; SDataType inputDataType
-&gt; SShape ('Shape '[inputBatchDim, 'Dim ('Name &quot;*&quot;) ('Size 1)])
-&gt; TensorSpec
     ('Gradient 'WithoutGradient)
     inputLayout
     inputDevice
     inputDataType
     ('Shape '[inputBatchDim, 'Dim ('Name &quot;*&quot;) ('Size 1)])
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SShape shape
-&gt; TensorSpec gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorSpec"><span class="hs-identifier hs-var">TensorSpec</span></a></span><span>
</span><span id="line-841"></span><span>            </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SRequiresGradient 'WithoutGradient
-&gt; SGradient ('Gradient 'WithoutGradient)
forall (requiresGradient :: RequiresGradient).
SRequiresGradient requiresGradient
-&gt; SGradient ('Gradient requiresGradient)
</span><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier hs-var">SGradient</span></a></span><span> </span><span class="annot"><span class="annottext">SRequiresGradient 'WithoutGradient
</span><a href="Torch.GraduallyTyped.RequiresGradient.html#SWithoutGradient"><span class="hs-identifier hs-var">SWithoutGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-842"></span><span>            </span><span class="annot"><span class="annottext">SLayout inputLayout
</span><a href="#local-6989586621679676991"><span class="hs-identifier hs-var">inputLayout</span></a></span><span>
</span><span id="line-843"></span><span>            </span><span class="annot"><span class="annottext">SDevice inputDevice
</span><a href="#local-6989586621679676990"><span class="hs-identifier hs-var">inputDevice</span></a></span><span>
</span><span id="line-844"></span><span>            </span><span class="annot"><span class="annottext">SDataType inputDataType
</span><a href="#local-6989586621679676989"><span class="hs-identifier hs-var">inputDataType</span></a></span><span>
</span><span id="line-845"></span><span>            </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SList '[inputBatchDim, 'Dim ('Name &quot;*&quot;) ('Size 1)]
-&gt; SShape ('Shape '[inputBatchDim, 'Dim ('Name &quot;*&quot;) ('Size 1)])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList '[inputBatchDim, 'Dim ('Name &quot;*&quot;) ('Size 1)]
 -&gt; SShape ('Shape '[inputBatchDim, 'Dim ('Name &quot;*&quot;) ('Size 1)]))
-&gt; SList '[inputBatchDim, 'Dim ('Name &quot;*&quot;) ('Size 1)]
-&gt; SShape ('Shape '[inputBatchDim, 'Dim ('Name &quot;*&quot;) ('Size 1)])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">Sing inputBatchDim
SDim inputBatchDim
</span><a href="#local-6989586621679676987"><span class="hs-identifier hs-var">inputBatchDim</span></a></span><span> </span><span class="annot"><span class="annottext">Sing inputBatchDim
-&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 1)]
-&gt; SList '[inputBatchDim, 'Dim ('Name &quot;*&quot;) ('Size 1)]
forall a1 (a2 :: a1) (as :: [a1]).
Sing a2 -&gt; SList as -&gt; SList (a2 : as)
</span><a href="Torch.GraduallyTyped.Prelude.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize ('Size 1) -&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 1))
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownNat 1 =&gt; SSize ('Size 1)
forall (size :: Nat). KnownNat size =&gt; SSize ('Size size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier hs-var">SSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">1</span></span><span> </span><span class="annot"><span class="annottext">Sing ('Dim ('Name &quot;*&quot;) ('Size 1))
-&gt; SList '[] -&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 1)]
forall a1 (a2 :: a1) (as :: [a1]).
Sing a2 -&gt; SList as -&gt; SList (a2 : as)
</span><a href="Torch.GraduallyTyped.Prelude.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-846"></span><span>        </span><span class="hs-special">)</span><span>
</span><span id="line-847"></span><span>        </span><span class="annot"><span class="annottext">fillValue
</span><a href="#local-6989586621679676994"><span class="hs-identifier hs-var">fillValue</span></a></span><span>
</span><span id="line-848"></span><span>    </span><span id="local-6989586621679676985"><span class="annot"><span class="annottext">rightShiftedInput
</span><a href="#local-6989586621679676985"><span class="hs-identifier hs-var">shifted</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">HList
  '[Tensor
      ('Gradient 'WithoutGradient)
      inputLayout
      inputDevice
      inputDataType
      ('Shape '[inputBatchDim, 'Dim ('Name &quot;*&quot;) ('Size 1)]),
    input]
-&gt; m (CatF
        ('SelectDim ('ByIndex 1))
        '[Tensor
            ('Gradient 'WithoutGradient)
            inputLayout
            inputDevice
            inputDataType
            ('Shape '[inputBatchDim, 'Dim ('Name &quot;*&quot;) ('Size 1)]),
          input]
        HList)
forall (selectDim :: SelectDim (By Symbol Nat)) k (c :: k -&gt; *)
       (a :: k) (m :: * -&gt; *).
(HasCat selectDim k c a, SingI selectDim, MonadThrow m) =&gt;
c a -&gt; m (CatF selectDim a c)
</span><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#cat"><span class="hs-identifier hs-var">cat</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  inputLayout
  inputDevice
  inputDataType
  ('Shape '[inputBatchDim, 'Dim ('Name &quot;*&quot;) ('Size 1)])
</span><a href="#local-6989586621679676986"><span class="hs-identifier hs-var">filler</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  inputLayout
  inputDevice
  inputDataType
  ('Shape '[inputBatchDim, 'Dim ('Name &quot;*&quot;) ('Size 1)])
-&gt; HList '[input]
-&gt; HList
     '[Tensor
         ('Gradient 'WithoutGradient)
         inputLayout
         inputDevice
         inputDataType
         ('Shape '[inputBatchDim, 'Dim ('Name &quot;*&quot;) ('Size 1)]),
       input]
forall x (xs :: [*]). x -&gt; HList xs -&gt; HList (x : xs)
</span><a href="../../../../hasktorch/html/src"><span class="hs-operator hs-var">:.</span></a></span><span> </span><span class="annot"><span class="annottext">input
</span><a href="#local-6989586621679676993"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">input -&gt; HList '[] -&gt; HList '[input]
forall x (xs :: [*]). x -&gt; HList xs -&gt; HList (x : xs)
</span><a href="../../../../hasktorch/html/src"><span class="hs-operator hs-var">:.</span></a></span><span> </span><span class="annot"><span class="annottext">HList '[]
forall k. HList '[]
</span><a href="../../../../hasktorch/html/src"><span class="hs-identifier hs-var">HNil</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-849"></span><span>    </span><span class="annot"><span class="annottext">(rightShiftedInput, Generator generator)
-&gt; m (rightShiftedInput, Generator generator)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">rightShiftedInput
</span><a href="#local-6989586621679676985"><span class="hs-identifier hs-var">shifted</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Generator generator
</span><a href="#local-6989586621679676992"><span class="hs-identifier hs-var">g</span></a></span><span class="hs-special">)</span></span></span></span></span></span></span></span></span></span></span></span><span>
</span><span id="line-850"></span></pre></body></html>