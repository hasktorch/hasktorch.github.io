<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><link rel="stylesheet" type="text/css" href="style.css" /><script type="text/javascript" src="highlight.js"></script></head><body><pre><span class="hs-pragma">{-# LANGUAGE AllowAmbiguousTypes #-}</span><span>
</span><span id="line-2"></span><span class="hs-pragma">{-# LANGUAGE ConstraintKinds #-}</span><span>
</span><span id="line-3"></span><span class="hs-pragma">{-# LANGUAGE DataKinds #-}</span><span>
</span><span id="line-4"></span><span class="hs-pragma">{-# LANGUAGE EmptyCase #-}</span><span>
</span><span id="line-5"></span><span class="hs-pragma">{-# LANGUAGE FlexibleContexts #-}</span><span>
</span><span id="line-6"></span><span class="hs-pragma">{-# LANGUAGE FlexibleInstances #-}</span><span>
</span><span id="line-7"></span><span class="hs-pragma">{-# LANGUAGE GADTs #-}</span><span>
</span><span id="line-8"></span><span class="hs-pragma">{-# LANGUAGE InstanceSigs #-}</span><span>
</span><span id="line-9"></span><span class="hs-pragma">{-# LANGUAGE KindSignatures #-}</span><span>
</span><span id="line-10"></span><span class="hs-pragma">{-# LANGUAGE MultiParamTypeClasses #-}</span><span>
</span><span id="line-11"></span><span class="hs-pragma">{-# LANGUAGE PatternSynonyms #-}</span><span>
</span><span id="line-12"></span><span class="hs-pragma">{-# LANGUAGE RecordWildCards #-}</span><span>
</span><span id="line-13"></span><span class="hs-pragma">{-# LANGUAGE ScopedTypeVariables #-}</span><span>
</span><span id="line-14"></span><span class="hs-pragma">{-# LANGUAGE StandaloneDeriving #-}</span><span>
</span><span id="line-15"></span><span class="hs-pragma">{-# LANGUAGE StandaloneKindSignatures #-}</span><span>
</span><span id="line-16"></span><span class="hs-pragma">{-# LANGUAGE TemplateHaskell #-}</span><span>
</span><span id="line-17"></span><span class="hs-pragma">{-# LANGUAGE TupleSections #-}</span><span>
</span><span id="line-18"></span><span class="hs-pragma">{-# LANGUAGE TypeApplications #-}</span><span>
</span><span id="line-19"></span><span class="hs-pragma">{-# LANGUAGE TypeFamilies #-}</span><span>
</span><span id="line-20"></span><span class="hs-pragma">{-# LANGUAGE TypeOperators #-}</span><span>
</span><span id="line-21"></span><span class="hs-pragma">{-# LANGUAGE UndecidableInstances #-}</span><span>
</span><span id="line-22"></span><span class="hs-pragma">{-# OPTIONS_GHC -fplugin TypeLevel.Rewrite
                -fplugin-opt=TypeLevel.Rewrite:Torch.GraduallyTyped.Unify.UnifyRightAssociativeL
                -fplugin-opt=TypeLevel.Rewrite:Torch.GraduallyTyped.Unify.UnifyIdempotenceL2
                -fplugin-opt=TypeLevel.Rewrite:Torch.GraduallyTyped.Unify.UnifyIdempotenceL2C
                -fplugin-opt=TypeLevel.Rewrite:Torch.GraduallyTyped.Unify.UnifyIdempotenceL3
                -fplugin-opt=TypeLevel.Rewrite:Torch.GraduallyTyped.Unify.UnifyIdempotenceL3C
                -fplugin-opt=TypeLevel.Rewrite:Torch.GraduallyTyped.Unify.UnifyIdempotenceL4
                -fplugin-opt=TypeLevel.Rewrite:Torch.GraduallyTyped.Unify.UnifyIdempotenceL4C
                -fplugin-opt=TypeLevel.Rewrite:Torch.GraduallyTyped.Unify.UnifyIdempotenceL5
                -fplugin-opt=TypeLevel.Rewrite:Torch.GraduallyTyped.Unify.UnifyIdempotenceL5C
                -fplugin-opt=TypeLevel.Rewrite:Torch.GraduallyTyped.Unify.UnifyIdempotenceL6
                -fplugin-opt=TypeLevel.Rewrite:Torch.GraduallyTyped.Unify.UnifyIdempotenceL6C
                -fplugin-opt=TypeLevel.Rewrite:Torch.GraduallyTyped.Unify.UnifyIdempotenceL7
                -fplugin-opt=TypeLevel.Rewrite:Torch.GraduallyTyped.Unify.UnifyIdempotenceL7C
                -fplugin-opt=TypeLevel.Rewrite:Torch.GraduallyTyped.Unify.UnifyIdempotenceL8
                -fplugin-opt=TypeLevel.Rewrite:Torch.GraduallyTyped.Unify.UnifyIdempotenceL8C #-}</span><span>
</span><span id="line-38"></span><span class="hs-pragma">{-# OPTIONS_GHC -v2 #-}</span><span>
</span><span id="line-39"></span><span>
</span><span id="line-40"></span><span class="hs-keyword">module</span><span> </span><span class="hs-identifier">Torch.GraduallyTyped.NN.Transformer.Type</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-41"></span><span>
</span><span id="line-42"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier">Control.Monad.Catch</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier">MonadThrow</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-43"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">Data.Singletons.Prelude.List</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">SList</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">SNil</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-44"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">Data.Singletons.TH</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">SingKind</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">fromSing</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">genSingletons</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-45"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">GHC.Float</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier">double2Int</span></span><span class="hs-special">)</span><span>
</span><span id="line-46"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">GHC.TypeLits</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier">Nat</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier">Symbol</span></span><span class="hs-special">)</span><span>
</span><span id="line-47"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html"><span class="hs-identifier">Torch.GraduallyTyped.DType</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier">DType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier">DataType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#SDType"><span class="hs-identifier">SDType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier">SDataType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-48"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html"><span class="hs-identifier">Torch.GraduallyTyped.Device</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#Device"><span class="hs-identifier">Device</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#DeviceType"><span class="hs-identifier">DeviceType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#SDevice"><span class="hs-identifier">SDevice</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#SDeviceType"><span class="hs-identifier">SDeviceType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-49"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html"><span class="hs-identifier">Torch.GraduallyTyped.Layout</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier">Layout</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#LayoutType"><span class="hs-identifier">LayoutType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#SLayout"><span class="hs-identifier">SLayout</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#SLayoutType"><span class="hs-identifier">SLayoutType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-50"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html"><span class="hs-identifier">Torch.GraduallyTyped.NN.Class</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier">HasForward</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier">HasInitialize</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasStateDict"><span class="hs-identifier">HasStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier">ModelSpec</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-51"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html"><span class="hs-identifier">Torch.GraduallyTyped.Prelude</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Seq"><span class="hs-identifier">Seq</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#forgetIsChecked"><span class="hs-identifier">forgetIsChecked</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-52"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html"><span class="hs-identifier">Torch.GraduallyTyped.RequiresGradient</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier">Gradient</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#RequiresGradient"><span class="hs-identifier">RequiresGradient</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier">SGradient</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#SRequiresGradient"><span class="hs-identifier">SRequiresGradient</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-53"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Scalar.html"><span class="hs-identifier">Torch.GraduallyTyped.Scalar</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Scalar.html#Scalar"><span class="hs-identifier">Scalar</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-54"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html"><span class="hs-identifier">Torch.GraduallyTyped.Shape.Class</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#AddDimF"><span class="hs-identifier">AddDimF</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#BroadcastShapesF"><span class="hs-identifier">BroadcastShapesF</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#ReplaceDimF"><span class="hs-identifier">ReplaceDimF</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#sGetDimFromShape"><span class="hs-identifier">sGetDimFromShape</span></a></span><span class="hs-special">,</span><span> </span><span class="hs-keyword">type</span><span> </span><span class="hs-special">(</span><span class="hs-glyph">!</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-55"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html"><span class="hs-identifier">Torch.GraduallyTyped.Shape.Type</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#By"><span class="hs-identifier">By</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier">Name</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SBy"><span class="hs-identifier">SBy</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier">SDim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#sDimSize"><span class="hs-identifier">sDimSize</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier">SName</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SSelectDim"><span class="hs-identifier">SSelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier">SShape</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier">SSize</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier">Shape</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier">Size</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="hs-keyword">pattern</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator">(:&amp;:)</span></a></span><span class="hs-special">,</span><span> </span><span class="hs-keyword">pattern</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator">(:|:)</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-56"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Creation.html"><span class="hs-identifier">Torch.GraduallyTyped.Tensor.Creation</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Creation.html#sArangeNaturals"><span class="hs-identifier">sArangeNaturals</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Creation.html#sFull"><span class="hs-identifier">sFull</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Creation.html#sOnes"><span class="hs-identifier">sOnes</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Creation.html#sZeros"><span class="hs-identifier">sZeros</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-57"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html"><span class="hs-identifier">Torch.GraduallyTyped.Tensor.IndexingSlicingJoining</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#UnsqueezeF"><span class="hs-identifier">UnsqueezeF</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#cat"><span class="hs-identifier">cat</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#unsqueeze"><span class="hs-identifier">unsqueeze</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-58"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Comparison.html"><span class="hs-identifier">Torch.GraduallyTyped.Tensor.MathOperations.Comparison</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Comparison.html#%3D%3D."><span class="hs-operator">(==.)</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-59"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html"><span class="hs-identifier">Torch.GraduallyTyped.Tensor.MathOperations.Pointwise</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#addScalar"><span class="hs-identifier">addScalar</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#logicalOr"><span class="hs-identifier">logicalOr</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-60"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Other.html"><span class="hs-identifier">Torch.GraduallyTyped.Tensor.Other</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Other.html#maskedFill"><span class="hs-identifier">maskedFill</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Other.html#triu"><span class="hs-identifier">triu</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-61"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html"><span class="hs-identifier">Torch.GraduallyTyped.Tensor.Type</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetDataType"><span class="hs-identifier">SGetDataType</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#sGetDataType"><span class="hs-identifier">sGetDataType</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetDevice"><span class="hs-identifier">SGetDevice</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetDim"><span class="hs-identifier">SGetDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetLayout"><span class="hs-identifier">SGetLayout</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetShape"><span class="hs-identifier">SGetShape</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier">Tensor</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorLike"><span class="hs-identifier">TensorLike</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#sToTensor"><span class="hs-identifier">sToTensor</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorSpec"><span class="hs-identifier">TensorSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#bool"><span class="hs-identifier">bool</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#sCheckedShape"><span class="hs-identifier">sCheckedShape</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#toTensor"><span class="hs-identifier">toTensor</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-62"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html"><span class="hs-identifier">Torch.GraduallyTyped.Unify</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-keyword">type</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator">(&lt;+&gt;)</span></a></span><span class="hs-special">,</span><span> </span><span class="hs-keyword">type</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator">(&lt;|&gt;)</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-63"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../../../../hasktorch/html/src"><span class="hs-identifier">Torch.HList</span></a></span><span>
</span><span id="line-64"></span><span>
</span><span id="line-65"></span><span class="hs-keyword">data</span><span> </span><span id="TransformerStyle"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerStyle"><span class="hs-identifier hs-var">TransformerStyle</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span id="T5"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#T5"><span class="hs-identifier hs-var">T5</span></a></span></span><span> </span><span class="hs-glyph">|</span><span> </span><span id="ByT5"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ByT5"><span class="hs-identifier hs-var">ByT5</span></a></span></span><span> </span><span class="hs-glyph">|</span><span> </span><span id="BART"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-var">BART</span></a></span></span><span> </span><span class="hs-glyph">|</span><span> </span><span id="MBART"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MBART"><span class="hs-identifier hs-var">MBART</span></a></span></span><span> </span><span class="hs-glyph">|</span><span> </span><span id="Pegasus"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#Pegasus"><span class="hs-identifier hs-var">Pegasus</span></a></span></span><span> </span><span class="hs-glyph">|</span><span> </span><span id="BERT"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BERT"><span class="hs-identifier hs-var">BERT</span></a></span></span><span> </span><span class="hs-glyph">|</span><span> </span><span id="RoBERTa"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#RoBERTa"><span class="hs-identifier hs-var">RoBERTa</span></a></span></span><span> </span><span class="hs-glyph">|</span><span> </span><span id="GPT2"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#GPT2"><span class="hs-identifier hs-var">GPT2</span></a></span></span><span>
</span><span id="line-66"></span><span>  </span><span class="hs-keyword">deriving</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679572032"><span id="local-6989586621679572034"><span id="local-6989586621679572036"><span class="annot"><span class="annottext">Int -&gt; TransformerStyle -&gt; ShowS
[TransformerStyle] -&gt; ShowS
TransformerStyle -&gt; String
(Int -&gt; TransformerStyle -&gt; ShowS)
-&gt; (TransformerStyle -&gt; String)
-&gt; ([TransformerStyle] -&gt; ShowS)
-&gt; Show TransformerStyle
forall a.
(Int -&gt; a -&gt; ShowS) -&gt; (a -&gt; String) -&gt; ([a] -&gt; ShowS) -&gt; Show a
showList :: [TransformerStyle] -&gt; ShowS
$cshowList :: [TransformerStyle] -&gt; ShowS
show :: TransformerStyle -&gt; String
$cshow :: TransformerStyle -&gt; String
showsPrec :: Int -&gt; TransformerStyle -&gt; ShowS
$cshowsPrec :: Int -&gt; TransformerStyle -&gt; ShowS
</span><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">Show</span></span></span></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679572027"><span id="local-6989586621679572029"><span class="annot"><span class="annottext">TransformerStyle -&gt; TransformerStyle -&gt; Bool
(TransformerStyle -&gt; TransformerStyle -&gt; Bool)
-&gt; (TransformerStyle -&gt; TransformerStyle -&gt; Bool)
-&gt; Eq TransformerStyle
forall a. (a -&gt; a -&gt; Bool) -&gt; (a -&gt; a -&gt; Bool) -&gt; Eq a
/= :: TransformerStyle -&gt; TransformerStyle -&gt; Bool
$c/= :: TransformerStyle -&gt; TransformerStyle -&gt; Bool
== :: TransformerStyle -&gt; TransformerStyle -&gt; Bool
$c== :: TransformerStyle -&gt; TransformerStyle -&gt; Bool
</span><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var">Eq</span></span></span></span><span class="hs-special">)</span><span>
</span><span id="line-67"></span><span>
</span><span id="line-68"></span><span id="T5Sym0"><span id="ByT5Sym0"><span id="BARTSym0"><span id="MBARTSym0"><span id="PegasusSym0"><span id="BERTSym0"><span id="RoBERTaSym0"><span id="GPT2Sym0"><span id="SGPT2"><span id="SRoBERTa"><span id="SBERT"><span id="SPegasus"><span id="SMBART"><span id="SBART"><span id="SByT5"><span id="ST5"><span id="STransformerStyle"><span id="local-6989586621679572005"><span id="local-6989586621679572007"><span id="local-6989586621679572009"><span id="local-6989586621679572011"><span id="local-6989586621679572013"><span id="local-6989586621679572015"><span id="local-6989586621679572017"><span id="local-6989586621679572019"><span id="local-6989586621679572021"><span id="local-6989586621679572023"><span id="local-6989586621679572025"><span id="Demote"><span id="Sing"><span class="hs-identifier">genSingletons</span><span> </span><span class="hs-special">[</span><span class="hs-special">''</span><span class="hs-identifier">TransformerStyle</span><span class="hs-special">]</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span>
</span><span id="line-69"></span><span>
</span><span id="line-70"></span><span class="hs-keyword">data</span><span> </span><span id="TransformerHead"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerHead"><span class="hs-identifier hs-var">TransformerHead</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span id="WithoutHead"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#WithoutHead"><span class="hs-identifier hs-var">WithoutHead</span></a></span></span><span> </span><span class="hs-glyph">|</span><span> </span><span id="WithLMHead"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#WithLMHead"><span class="hs-identifier hs-var">WithLMHead</span></a></span></span><span>
</span><span id="line-71"></span><span>
</span><span id="line-72"></span><span id="WithoutHeadSym0"><span id="WithLMHeadSym0"><span id="SWithLMHead"><span id="SWithoutHead"><span id="STransformerHead"><span id="local-6989586621679571975"><span id="local-6989586621679571977"><span id="local-6989586621679571979"><span id="local-6989586621679571981"><span id="local-6989586621679571983"><span id="Demote"><span id="Sing"><span class="hs-identifier">genSingletons</span><span> </span><span class="hs-special">[</span><span class="hs-special">''</span><span class="hs-identifier">TransformerHead</span><span class="hs-special">]</span></span></span></span></span></span></span></span></span></span></span></span></span><span>
</span><span id="line-73"></span><span>
</span><span id="line-74"></span><span id="local-6989586621679572508"><span id="local-6989586621679572509"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#padded"><span class="hs-identifier hs-type">padded</span></a></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Integral</span></span><span> </span><span class="annot"><a href="#local-6989586621679572509"><span class="hs-identifier hs-type">n</span></a></span><span> </span><span class="hs-glyph">=&gt;</span><span> </span><span class="annot"><a href="#local-6989586621679572509"><span class="hs-identifier hs-type">n</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="#local-6989586621679572508"><span class="hs-identifier hs-type">a</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679572508"><span class="hs-identifier hs-type">a</span></a></span><span class="hs-special">]</span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679572508"><span class="hs-identifier hs-type">a</span></a></span><span class="hs-special">]</span></span></span><span>
</span><span id="line-75"></span><span id="padded"><span class="annot"><span class="annottext">padded :: n -&gt; a -&gt; [a] -&gt; [a]
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#padded"><span class="hs-identifier hs-var hs-var">padded</span></a></span></span><span> </span><span id="local-6989586621679571968"><span class="annot"><span class="annottext">n
</span><a href="#local-6989586621679571968"><span class="hs-identifier hs-var">n</span></a></span></span><span> </span><span id="local-6989586621679571967"><span class="annot"><span class="annottext">a
</span><a href="#local-6989586621679571967"><span class="hs-identifier hs-var">p</span></a></span></span><span> </span><span id="local-6989586621679571966"><span class="annot"><span class="annottext">[a]
</span><a href="#local-6989586621679571966"><span class="hs-identifier hs-var">xs</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-76"></span><span>  </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679571965"><span class="annot"><span class="annottext">n' :: Int
</span><a href="#local-6989586621679571965"><span class="hs-identifier hs-var hs-var">n'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">n -&gt; Int
forall a b. (Integral a, Num b) =&gt; a -&gt; b
</span><span class="hs-identifier hs-var">fromIntegral</span></span><span> </span><span class="annot"><span class="annottext">n
</span><a href="#local-6989586621679571968"><span class="hs-identifier hs-var">n</span></a></span><span>
</span><span id="line-77"></span><span>      </span><span id="local-6989586621679571964"><span class="annot"><span class="annottext">diff :: Int
</span><a href="#local-6989586621679571964"><span class="hs-identifier hs-var hs-var">diff</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679571965"><span class="hs-identifier hs-var">n'</span></a></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Int
forall a. Num a =&gt; a -&gt; a -&gt; a
</span><span class="hs-glyph hs-var">-</span></span><span> </span><span class="annot"><span class="annottext">[a] -&gt; Int
forall (t :: * -&gt; *) a. Foldable t =&gt; t a -&gt; Int
</span><span class="hs-identifier hs-var">length</span></span><span> </span><span class="annot"><span class="annottext">[a]
</span><a href="#local-6989586621679571966"><span class="hs-identifier hs-var">xs</span></a></span><span>
</span><span id="line-78"></span><span>   </span><span class="hs-keyword">in</span><span> </span><span class="annot"><span class="annottext">Int -&gt; [a] -&gt; [a]
forall a. Int -&gt; [a] -&gt; [a]
</span><span class="hs-identifier hs-var">take</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679571965"><span class="hs-identifier hs-var">n'</span></a></span><span> </span><span class="annot"><span class="annottext">[a]
</span><a href="#local-6989586621679571966"><span class="hs-identifier hs-var">xs</span></a></span><span> </span><span class="annot"><span class="annottext">[a] -&gt; [a] -&gt; [a]
forall a. [a] -&gt; [a] -&gt; [a]
</span><span class="hs-operator hs-var">++</span></span><span> </span><span class="annot"><span class="annottext">Int -&gt; a -&gt; [a]
forall a. Int -&gt; a -&gt; [a]
</span><span class="hs-identifier hs-var">replicate</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679571964"><span class="hs-identifier hs-var">diff</span></a></span><span> </span><span class="annot"><span class="annottext">a
</span><a href="#local-6989586621679571967"><span class="hs-identifier hs-var">p</span></a></span><span>
</span><span id="line-79"></span><span>
</span><span id="line-80"></span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#mkTransformerInput"><span class="hs-identifier hs-type">mkTransformerInput</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-81"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679571959"><span class="annot"><a href="#local-6989586621679571959"><span class="hs-identifier hs-type">batchDim</span></a></span></span><span> </span><span id="local-6989586621679571958"><span class="annot"><a href="#local-6989586621679571958"><span class="hs-identifier hs-type">seqDim</span></a></span></span><span> </span><span id="local-6989586621679571957"><span class="annot"><a href="#local-6989586621679571957"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679571956"><span class="annot"><a href="#local-6989586621679571956"><span class="hs-identifier hs-type">m</span></a></span></span><span> </span><span id="local-6989586621679571955"><span class="annot"><a href="#local-6989586621679571955"><span class="hs-identifier hs-type">output</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-82"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier hs-type">MonadThrow</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571956"><span class="hs-identifier hs-type">m</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-83"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetDim"><span class="hs-identifier hs-type">SGetDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571959"><span class="hs-identifier hs-type">batchDim</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-84"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetDim"><span class="hs-identifier hs-type">SGetDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571958"><span class="hs-identifier hs-type">seqDim</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-85"></span><span>    </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679571959"><span class="hs-identifier hs-type">batchDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679571958"><span class="hs-identifier hs-type">seqDim</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-86"></span><span>      </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Seq"><span class="hs-identifier hs-type">Seq</span></a></span><span>
</span><span id="line-87"></span><span>          </span><span class="hs-special">(</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span>
</span><span id="line-88"></span><span>              </span><span class="hs-special">'</span><span class="hs-special">[</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#UncheckedSize"><span class="hs-identifier hs-type">UncheckedSize</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-89"></span><span>                 </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#UncheckedSize"><span class="hs-identifier hs-type">UncheckedSize</span></a></span><span>
</span><span id="line-90"></span><span>               </span><span class="hs-special">]</span><span>
</span><span id="line-91"></span><span>              </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679571959"><span class="hs-identifier hs-type">batchDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679571958"><span class="hs-identifier hs-type">seqDim</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-92"></span><span>          </span><span class="hs-special">)</span><span>
</span><span id="line-93"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679571959"><span class="hs-identifier hs-type">batchDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679571958"><span class="hs-identifier hs-type">seqDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-94"></span><span>    </span><span class="annot"><a href="#local-6989586621679571955"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-95"></span><span>      </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-96"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#WithoutGradient"><span class="hs-identifier hs-type">WithoutGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-97"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Dense"><span class="hs-identifier hs-type">Dense</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-98"></span><span>          </span><span class="annot"><a href="#local-6989586621679571957"><span class="hs-identifier hs-type">device</span></a></span><span>
</span><span id="line-99"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#Int64"><span class="hs-identifier hs-type">Int64</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-100"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679571959"><span class="hs-identifier hs-type">batchDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679571958"><span class="hs-identifier hs-type">seqDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-101"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-102"></span><span>  </span><span class="hs-comment">-- | padding token id</span><span>
</span><span id="line-103"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-104"></span><span>  </span><span class="hs-comment">-- | batch dimension singleton</span><span>
</span><span id="line-105"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571959"><span class="hs-identifier hs-type">batchDim</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-106"></span><span>  </span><span class="hs-comment">-- | sequence dimension singleton</span><span>
</span><span id="line-107"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571958"><span class="hs-identifier hs-type">seqDim</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-108"></span><span>  </span><span class="hs-comment">-- | device for the tensor</span><span>
</span><span id="line-109"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#SDevice"><span class="hs-identifier hs-type">SDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571957"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-110"></span><span>  </span><span class="hs-comment">-- | batch of input ids</span><span>
</span><span id="line-111"></span><span>  </span><span class="hs-special">[</span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">]</span><span class="hs-special">]</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-112"></span><span>  </span><span class="hs-comment">-- | input tensor</span><span>
</span><span id="line-113"></span><span>  </span><span class="annot"><a href="#local-6989586621679571956"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571955"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-114"></span><span id="mkTransformerInput"><span class="annot"><span class="annottext">mkTransformerInput :: Int
-&gt; SDim batchDim
-&gt; SDim seqDim
-&gt; SDevice device
-&gt; [[Int]]
-&gt; m output
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#mkTransformerInput"><span class="hs-identifier hs-var hs-var">mkTransformerInput</span></a></span></span><span> </span><span id="local-6989586621679571954"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679571954"><span class="hs-identifier hs-var">padTokenId</span></a></span></span><span> </span><span id="local-6989586621679571953"><span class="annot"><span class="annottext">SDim batchDim
</span><a href="#local-6989586621679571953"><span class="hs-identifier hs-var">batchDim</span></a></span></span><span> </span><span id="local-6989586621679571952"><span class="annot"><span class="annottext">SDim seqDim
</span><a href="#local-6989586621679571952"><span class="hs-identifier hs-var">seqDim</span></a></span></span><span> </span><span id="local-6989586621679571951"><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679571951"><span class="hs-identifier hs-var">device</span></a></span></span><span> </span><span id="local-6989586621679571950"><span class="annot"><span class="annottext">[[Int]]
</span><a href="#local-6989586621679571950"><span class="hs-identifier hs-var">xs</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-115"></span><span>  </span><span class="annot"><span class="annottext">SGradient ('Gradient 'WithoutGradient)
-&gt; SLayout ('Layout 'Dense)
-&gt; SDevice device
-&gt; [[Int]]
-&gt; m (Tensor
        ('Gradient 'WithoutGradient)
        ('Layout 'Dense)
        device
        ('DataType 'Int64)
        ('Shape
           '[ 'Dim ('Name &quot;*&quot;) 'UncheckedSize,
              'Dim ('Name &quot;*&quot;) 'UncheckedSize]))
forall a (dType :: DType) (dims :: [Dim (Name Symbol) (Size Nat)])
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (m :: * -&gt; *).
(TensorLike a dType dims, MonadThrow m) =&gt;
SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; a
-&gt; m (Tensor
        gradient layout device ('DataType dType) ('Shape dims))
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sToTensor"><span class="hs-identifier hs-var">sToTensor</span></a></span><span> </span><span class="annot"><span class="annottext">SGradient ('Gradient 'WithoutGradient)
</span><a href="#local-6989586621679571949"><span class="hs-identifier hs-var">gradient</span></a></span><span> </span><span class="annot"><span class="annottext">SLayout ('Layout 'Dense)
</span><a href="#local-6989586621679571948"><span class="hs-identifier hs-var">layout</span></a></span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679571951"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">[[Int]]
</span><a href="#local-6989586621679571947"><span class="hs-identifier hs-var">paddedXs</span></a></span><span>
</span><span id="line-116"></span><span>    </span><span class="annot"><span class="annottext">m (Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     device
     ('DataType 'Int64)
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) 'UncheckedSize,
           'Dim ('Name &quot;*&quot;) 'UncheckedSize]))
-&gt; (Tensor
      ('Gradient 'WithoutGradient)
      ('Layout 'Dense)
      device
      ('DataType 'Int64)
      ('Shape
         '[ 'Dim ('Name &quot;*&quot;) 'UncheckedSize,
            'Dim ('Name &quot;*&quot;) 'UncheckedSize])
    -&gt; m output)
-&gt; m output
forall (m :: * -&gt; *) a b. Monad m =&gt; m a -&gt; (a -&gt; m b) -&gt; m b
</span><span class="hs-operator hs-var">&gt;&gt;=</span></span><span> </span><span class="annot"><span class="annottext">SShape ('Shape '[batchDim, seqDim])
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     device
     ('DataType 'Int64)
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) 'UncheckedSize,
           'Dim ('Name &quot;*&quot;) 'UncheckedSize])
-&gt; m (Tensor
        ('Gradient 'WithoutGradient)
        ('Layout 'Dense)
        device
        ('DataType 'Int64)
        (Seq
           ('Shape
              '[ 'Dim ('Name &quot;*&quot;) 'UncheckedSize,
                 'Dim ('Name &quot;*&quot;) 'UncheckedSize]
            &lt;+&gt; 'Shape '[batchDim, seqDim])
           ('Shape '[batchDim, seqDim])))
forall (shape' :: Shape [Dim (Name Symbol) (Size Nat)])
       (m :: * -&gt; *) (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
(SGetShape shape, MonadThrow m) =&gt;
SShape shape'
-&gt; Tensor gradient layout device dataType shape
-&gt; m (Tensor
        gradient layout device dataType (Seq (shape &lt;+&gt; shape') shape'))
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sCheckedShape"><span class="hs-identifier hs-var">sCheckedShape</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SList '[batchDim, seqDim] -&gt; SShape ('Shape '[batchDim, seqDim])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList '[batchDim, seqDim] -&gt; SShape ('Shape '[batchDim, seqDim]))
-&gt; SList '[batchDim, seqDim] -&gt; SShape ('Shape '[batchDim, seqDim])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SDim batchDim
</span><a href="#local-6989586621679571953"><span class="hs-identifier hs-var">batchDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim batchDim -&gt; SList '[seqDim] -&gt; SList '[batchDim, seqDim]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SDim seqDim
</span><a href="#local-6989586621679571952"><span class="hs-identifier hs-var">seqDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim seqDim -&gt; SList '[] -&gt; SList '[seqDim]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-117"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-118"></span><span>    </span><span id="local-6989586621679571949"><span class="annot"><span class="annottext">gradient :: SGradient ('Gradient 'WithoutGradient)
</span><a href="#local-6989586621679571949"><span class="hs-identifier hs-var hs-var">gradient</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SRequiresGradient 'WithoutGradient
-&gt; SGradient ('Gradient 'WithoutGradient)
forall (requiresGradient :: RequiresGradient).
SRequiresGradient requiresGradient
-&gt; SGradient ('Gradient requiresGradient)
</span><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier hs-var">SGradient</span></a></span><span> </span><span class="annot"><span class="annottext">SRequiresGradient 'WithoutGradient
</span><a href="Torch.GraduallyTyped.RequiresGradient.html#SWithoutGradient"><span class="hs-identifier hs-var">SWithoutGradient</span></a></span><span>
</span><span id="line-119"></span><span>    </span><span id="local-6989586621679571948"><span class="annot"><span class="annottext">layout :: SLayout ('Layout 'Dense)
</span><a href="#local-6989586621679571948"><span class="hs-identifier hs-var hs-var">layout</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SLayoutType 'Dense -&gt; SLayout ('Layout 'Dense)
forall (layoutType :: LayoutType).
SLayoutType layoutType -&gt; SLayout ('Layout layoutType)
</span><a href="Torch.GraduallyTyped.Layout.html#SLayout"><span class="hs-identifier hs-var">SLayout</span></a></span><span> </span><span class="annot"><span class="annottext">SLayoutType 'Dense
</span><a href="Torch.GraduallyTyped.Layout.html#SDense"><span class="hs-identifier hs-var">SDense</span></a></span><span>
</span><span id="line-120"></span><span>    </span><span id="local-6989586621679571941"><span class="annot"><span class="annottext">batchSize :: Integer
</span><a href="#local-6989586621679571941"><span class="hs-identifier hs-var hs-var">batchSize</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IsChecked Integer -&gt; Integer
forall a. IsChecked a -&gt; a
</span><a href="Torch.GraduallyTyped.Prelude.html#forgetIsChecked"><span class="hs-identifier hs-var">forgetIsChecked</span></a></span><span> </span><span class="annot"><span class="annottext">(IsChecked Integer -&gt; Integer)
-&gt; (Dim (IsChecked String) (IsChecked Integer)
    -&gt; IsChecked Integer)
-&gt; Dim (IsChecked String) (IsChecked Integer)
-&gt; Integer
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Dim (IsChecked String) (IsChecked Integer) -&gt; IsChecked Integer
forall name size. Dim name size -&gt; size
</span><a href="Torch.GraduallyTyped.Shape.Type.html#dimSize"><span class="hs-identifier hs-var hs-var">dimSize</span></a></span><span> </span><span class="annot"><span class="annottext">(Dim (IsChecked String) (IsChecked Integer) -&gt; Integer)
-&gt; Dim (IsChecked String) (IsChecked Integer) -&gt; Integer
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">Sing batchDim -&gt; Demote (Dim (Name Symbol) (Size Nat))
forall k (a :: k). SingKind k =&gt; Sing a -&gt; Demote k
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">fromSing</span></a></span><span> </span><span class="annot"><span class="annottext">Sing batchDim
SDim batchDim
</span><a href="#local-6989586621679571953"><span class="hs-identifier hs-var">batchDim</span></a></span><span>
</span><span id="line-121"></span><span>    </span><span id="local-6989586621679571938"><span class="annot"><span class="annottext">seqSize :: Integer
</span><a href="#local-6989586621679571938"><span class="hs-identifier hs-var hs-var">seqSize</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IsChecked Integer -&gt; Integer
forall a. IsChecked a -&gt; a
</span><a href="Torch.GraduallyTyped.Prelude.html#forgetIsChecked"><span class="hs-identifier hs-var">forgetIsChecked</span></a></span><span> </span><span class="annot"><span class="annottext">(IsChecked Integer -&gt; Integer)
-&gt; (Dim (IsChecked String) (IsChecked Integer)
    -&gt; IsChecked Integer)
-&gt; Dim (IsChecked String) (IsChecked Integer)
-&gt; Integer
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Dim (IsChecked String) (IsChecked Integer) -&gt; IsChecked Integer
forall name size. Dim name size -&gt; size
</span><a href="Torch.GraduallyTyped.Shape.Type.html#dimSize"><span class="hs-identifier hs-var hs-var">dimSize</span></a></span><span> </span><span class="annot"><span class="annottext">(Dim (IsChecked String) (IsChecked Integer) -&gt; Integer)
-&gt; Dim (IsChecked String) (IsChecked Integer) -&gt; Integer
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">Sing seqDim -&gt; Demote (Dim (Name Symbol) (Size Nat))
forall k (a :: k). SingKind k =&gt; Sing a -&gt; Demote k
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">fromSing</span></a></span><span> </span><span class="annot"><span class="annottext">Sing seqDim
SDim seqDim
</span><a href="#local-6989586621679571952"><span class="hs-identifier hs-var">seqDim</span></a></span><span>
</span><span id="line-122"></span><span>    </span><span id="local-6989586621679571937"><span class="annot"><span class="annottext">emptySeq :: [Int]
</span><a href="#local-6989586621679571937"><span class="hs-identifier hs-var hs-var">emptySeq</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; [Int]
forall a. Int -&gt; a -&gt; [a]
</span><span class="hs-identifier hs-var">replicate</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Integer -&gt; Int
forall a b. (Integral a, Num b) =&gt; a -&gt; b
</span><span class="hs-identifier hs-var">fromIntegral</span></span><span> </span><span class="annot"><span class="annottext">Integer
</span><a href="#local-6989586621679571938"><span class="hs-identifier hs-var">seqSize</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679571954"><span class="hs-identifier hs-var">padTokenId</span></a></span><span>
</span><span id="line-123"></span><span>    </span><span id="local-6989586621679571947"><span class="annot"><span class="annottext">paddedXs :: [[Int]]
</span><a href="#local-6989586621679571947"><span class="hs-identifier hs-var hs-var">paddedXs</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Integer -&gt; [Int] -&gt; [[Int]] -&gt; [[Int]]
forall n a. Integral n =&gt; n -&gt; a -&gt; [a] -&gt; [a]
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#padded"><span class="hs-identifier hs-var">padded</span></a></span><span> </span><span class="annot"><span class="annottext">Integer
</span><a href="#local-6989586621679571941"><span class="hs-identifier hs-var">batchSize</span></a></span><span> </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679571937"><span class="hs-identifier hs-var">emptySeq</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Integer -&gt; Int -&gt; [Int] -&gt; [Int]
forall n a. Integral n =&gt; n -&gt; a -&gt; [a] -&gt; [a]
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#padded"><span class="hs-identifier hs-var">padded</span></a></span><span> </span><span class="annot"><span class="annottext">Integer
</span><a href="#local-6989586621679571938"><span class="hs-identifier hs-var">seqSize</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679571954"><span class="hs-identifier hs-var">padTokenId</span></a></span><span> </span><span class="annot"><span class="annottext">([Int] -&gt; [Int]) -&gt; [[Int]] -&gt; [[Int]]
forall (f :: * -&gt; *) a b. Functor f =&gt; (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;$&gt;</span></span><span> </span><span class="annot"><span class="annottext">[[Int]]
</span><a href="#local-6989586621679571950"><span class="hs-identifier hs-var">xs</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-124"></span><span>
</span><span id="line-125"></span><span class="hs-keyword">type</span><span> </span><span id="MkPosC"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkPosC"><span class="hs-identifier hs-var">MkPosC</span></a></span></span><span> </span><span id="local-6989586621679571935"><span class="annot"><a href="#local-6989586621679571935"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679571934"><span class="annot"><a href="#local-6989586621679571934"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679571933"><span class="annot"><a href="#local-6989586621679571933"><span class="hs-identifier hs-type">seqDim</span></a></span></span><span> </span><span id="local-6989586621679571932"><span class="annot"><a href="#local-6989586621679571932"><span class="hs-identifier hs-type">seqName</span></a></span></span><span> </span><span id="local-6989586621679571931"><span class="annot"><a href="#local-6989586621679571931"><span class="hs-identifier hs-type">seqSize</span></a></span></span><span> </span><span id="local-6989586621679571930"><span class="annot"><a href="#local-6989586621679571930"><span class="hs-identifier hs-type">output</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-126"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetDevice"><span class="hs-identifier hs-type">SGetDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571935"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-127"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetShape"><span class="hs-identifier hs-type">SGetShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571934"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-128"></span><span>    </span><span class="annot"><a href="#local-6989586621679571933"><span class="hs-identifier hs-type">seqDim</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679571934"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#%21"><span class="hs-glyph hs-type">!</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-129"></span><span>    </span><span class="annot"><a href="#local-6989586621679571933"><span class="hs-identifier hs-type">seqDim</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571932"><span class="hs-identifier hs-type">seqName</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571931"><span class="hs-identifier hs-type">seqSize</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-130"></span><span>    </span><span class="annot"><a href="#local-6989586621679571930"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-131"></span><span>      </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-132"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#WithoutGradient"><span class="hs-identifier hs-type">WithoutGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-133"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Dense"><span class="hs-identifier hs-type">Dense</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-134"></span><span>          </span><span class="annot"><a href="#local-6989586621679571935"><span class="hs-identifier hs-type">device</span></a></span><span>
</span><span id="line-135"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#Int64"><span class="hs-identifier hs-type">Int64</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-136"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679571931"><span class="hs-identifier hs-type">seqSize</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-137"></span><span>  </span><span class="hs-special">)</span><span>
</span><span id="line-138"></span><span>
</span><span id="line-139"></span><span class="hs-comment">-- | Computes absolute positions of the input tokens.</span><span>
</span><span id="line-140"></span><span class="hs-comment">-- Given an input tensor of shape @[batchDim, Dim seqName seqSize]@,</span><span>
</span><span id="line-141"></span><span class="hs-comment">-- returns a tensor of shape @[Dim &quot;*&quot; seqSize]@.</span><span>
</span><span id="line-142"></span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#mkPos"><span class="hs-identifier hs-type">mkPos</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-143"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679572417"><span class="annot"><a href="#local-6989586621679572417"><span class="hs-identifier hs-type">m</span></a></span></span><span> </span><span id="local-6989586621679572410"><span class="annot"><a href="#local-6989586621679572410"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679572409"><span class="annot"><a href="#local-6989586621679572409"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679572416"><span class="annot"><a href="#local-6989586621679572416"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679572408"><span class="annot"><a href="#local-6989586621679572408"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679572415"><span class="annot"><a href="#local-6989586621679572415"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679572414"><span class="annot"><a href="#local-6989586621679572414"><span class="hs-identifier hs-type">seqDim</span></a></span></span><span> </span><span id="local-6989586621679572413"><span class="annot"><a href="#local-6989586621679572413"><span class="hs-identifier hs-type">seqName</span></a></span></span><span> </span><span id="local-6989586621679572412"><span class="annot"><a href="#local-6989586621679572412"><span class="hs-identifier hs-type">seqSize</span></a></span></span><span> </span><span id="local-6989586621679572411"><span class="annot"><a href="#local-6989586621679572411"><span class="hs-identifier hs-type">output</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-144"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier hs-type">MonadThrow</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679572417"><span class="hs-identifier hs-type">m</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-145"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkPosC"><span class="hs-identifier hs-type">MkPosC</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679572416"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679572415"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679572414"><span class="hs-identifier hs-type">seqDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679572413"><span class="hs-identifier hs-type">seqName</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679572412"><span class="hs-identifier hs-type">seqSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679572411"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-146"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-147"></span><span>  </span><span class="hs-comment">-- | input tensor</span><span>
</span><span id="line-148"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679572410"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679572409"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679572416"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679572408"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679572415"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-149"></span><span>  </span><span class="hs-comment">-- | positions of the input tokens</span><span>
</span><span id="line-150"></span><span>  </span><span class="annot"><a href="#local-6989586621679572417"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679572411"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-151"></span><span id="mkPos"><span class="annot"><span class="annottext">mkPos :: Tensor gradient layout device dataType shape -&gt; m output
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#mkPos"><span class="hs-identifier hs-var hs-var">mkPos</span></a></span></span><span> </span><span id="local-6989586621679571928"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679571928"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-152"></span><span>  </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679571927"><span class="annot"><span class="annottext">device :: SDevice device
</span><a href="#local-6989586621679571927"><span class="hs-identifier hs-var hs-var">device</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape -&gt; SDevice device
forall (device :: Device (DeviceType Nat))
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SGetDevice device =&gt;
Tensor gradient layout device dataType shape -&gt; SDevice device
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sGetDevice"><span class="hs-identifier hs-var">sGetDevice</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679571928"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-153"></span><span>      </span><span id="local-6989586621679571925"><span class="annot"><span class="annottext">shape :: SShape shape
</span><a href="#local-6989586621679571925"><span class="hs-identifier hs-var hs-var">shape</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape -&gt; SShape shape
forall (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType).
SGetShape shape =&gt;
Tensor gradient layout device dataType shape -&gt; SShape shape
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sGetShape"><span class="hs-identifier hs-var">sGetShape</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679571928"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-154"></span><span>  </span><span id="local-6989586621679571923"><span class="annot"><span class="annottext">SDim ('Dim seqName seqSize)
</span><a href="#local-6989586621679571923"><span class="hs-identifier hs-var">seqDim</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">SSelectDim ('SelectDim ('ByIndex 1))
-&gt; SShape shape -&gt; m (SDim ('Dim seqName seqSize))
forall (selectDim :: SelectDim (By Symbol Nat))
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (dim :: Dim (Name Symbol) (Size Nat)) (m :: * -&gt; *).
(dim ~ GetDimF selectDim shape, MonadThrow m) =&gt;
SSelectDim selectDim -&gt; SShape shape -&gt; m (SDim dim)
</span><a href="Torch.GraduallyTyped.Shape.Class.html#sGetDimFromShape"><span class="hs-identifier hs-var">sGetDimFromShape</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SBy ('ByIndex 1) -&gt; SSelectDim ('SelectDim ('ByIndex 1))
forall (by :: By Symbol Nat). SBy by -&gt; SSelectDim ('SelectDim by)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSelectDim"><span class="hs-identifier hs-var">SSelectDim</span></a></span><span> </span><span class="annot"><span class="annottext">(SBy ('ByIndex 1) -&gt; SSelectDim ('SelectDim ('ByIndex 1)))
-&gt; SBy ('ByIndex 1) -&gt; SSelectDim ('SelectDim ('ByIndex 1))
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">KnownNat 1 =&gt; SBy ('ByIndex 1)
forall (index :: Nat). KnownNat index =&gt; SBy ('ByIndex index)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SByIndex"><span class="hs-identifier hs-var">SByIndex</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">SShape shape
</span><a href="#local-6989586621679571925"><span class="hs-identifier hs-var">shape</span></a></span><span>
</span><span id="line-155"></span><span>  </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679571920"><span class="annot"><span class="annottext">seqSize :: SSize seqSize
</span><a href="#local-6989586621679571920"><span class="hs-identifier hs-var hs-var">seqSize</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SDim ('Dim seqName seqSize) -&gt; SSize seqSize
forall (name :: Name Symbol) (size :: Size Nat).
SDim ('Dim name size) -&gt; SSize size
</span><a href="Torch.GraduallyTyped.Shape.Type.html#sDimSize"><span class="hs-identifier hs-var hs-var">sDimSize</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim seqName seqSize)
</span><a href="#local-6989586621679571923"><span class="hs-identifier hs-var">seqDim</span></a></span><span>
</span><span id="line-156"></span><span>      </span><span id="local-6989586621679571919"><span class="annot"><span class="annottext">pos :: Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  device
  ('DataType 'Int64)
  ('Shape '[ 'Dim ('Name &quot;*&quot;) seqSize])
</span><a href="#local-6989586621679571919"><span class="hs-identifier hs-var hs-var">pos</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-157"></span><span>        </span><span class="annot"><span class="annottext">SGradient ('Gradient 'WithoutGradient)
-&gt; SLayout ('Layout 'Dense)
-&gt; SDevice device
-&gt; SDataType ('DataType 'Int64)
-&gt; SSize seqSize
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     device
     ('DataType 'Int64)
     ('Shape '[ 'Dim ('Name &quot;*&quot;) seqSize])
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType) (size :: Size Nat)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
(shape ~ 'Shape '[ 'Dim ('Name &quot;*&quot;) size]) =&gt;
SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SSize size
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.Creation.html#sArangeNaturals"><span class="hs-identifier hs-var">sArangeNaturals</span></a></span><span>
</span><span id="line-158"></span><span>          </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SRequiresGradient 'WithoutGradient
-&gt; SGradient ('Gradient 'WithoutGradient)
forall (requiresGradient :: RequiresGradient).
SRequiresGradient requiresGradient
-&gt; SGradient ('Gradient requiresGradient)
</span><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier hs-var">SGradient</span></a></span><span> </span><span class="annot"><span class="annottext">SRequiresGradient 'WithoutGradient
</span><a href="Torch.GraduallyTyped.RequiresGradient.html#SWithoutGradient"><span class="hs-identifier hs-var">SWithoutGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-159"></span><span>          </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SLayoutType 'Dense -&gt; SLayout ('Layout 'Dense)
forall (layoutType :: LayoutType).
SLayoutType layoutType -&gt; SLayout ('Layout layoutType)
</span><a href="Torch.GraduallyTyped.Layout.html#SLayout"><span class="hs-identifier hs-var">SLayout</span></a></span><span> </span><span class="annot"><span class="annottext">SLayoutType 'Dense
</span><a href="Torch.GraduallyTyped.Layout.html#SDense"><span class="hs-identifier hs-var">SDense</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-160"></span><span>          </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679571927"><span class="hs-identifier hs-var">device</span></a></span><span>
</span><span id="line-161"></span><span>          </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SDType 'Int64 -&gt; SDataType ('DataType 'Int64)
forall (dType :: DType).
SDType dType -&gt; SDataType ('DataType dType)
</span><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier hs-var">SDataType</span></a></span><span> </span><span class="annot"><span class="annottext">SDType 'Int64
</span><a href="Torch.GraduallyTyped.DType.html#SInt64"><span class="hs-identifier hs-var">SInt64</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-162"></span><span>          </span><span class="annot"><span class="annottext">SSize seqSize
</span><a href="#local-6989586621679571920"><span class="hs-identifier hs-var">seqSize</span></a></span><span>
</span><span id="line-163"></span><span>  </span><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  device
  ('DataType 'Int64)
  ('Shape '[ 'Dim ('Name &quot;*&quot;) seqSize])
-&gt; m (Tensor
        ('Gradient 'WithoutGradient)
        ('Layout 'Dense)
        device
        ('DataType 'Int64)
        ('Shape '[ 'Dim ('Name &quot;*&quot;) seqSize]))
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  device
  ('DataType 'Int64)
  ('Shape '[ 'Dim ('Name &quot;*&quot;) seqSize])
</span><a href="#local-6989586621679571919"><span class="hs-identifier hs-var">pos</span></a></span><span>
</span><span id="line-164"></span><span>
</span><span id="line-165"></span><span class="hs-keyword">data</span><span> </span><span id="MkAbsPos"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkAbsPos"><span class="hs-identifier hs-var">MkAbsPos</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span id="MkAbsPos"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkAbsPos"><span class="hs-identifier hs-var">MkAbsPos</span></a></span></span><span> </span><span class="hs-glyph">|</span><span> </span><span id="MkAbsPosWithOffset"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkAbsPosWithOffset"><span class="hs-identifier hs-var">MkAbsPosWithOffset</span></a></span></span><span> </span><span class="hs-special">{</span><span id="absPosOffset"><span class="annot"><span class="annottext">MkAbsPos -&gt; Int
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#absPosOffset"><span class="hs-identifier hs-var hs-var">absPosOffset</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">}</span><span>
</span><span id="line-166"></span><span>
</span><span id="line-167"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">instance</span><span> </span><span id="ModelSpec"><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier hs-var">ModelSpec</span></a></span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkAbsPos"><span class="hs-identifier hs-type">MkAbsPos</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkAbsPos"><span class="hs-identifier hs-type">MkAbsPos</span></a></span><span>
</span><span id="line-168"></span><span>
</span><span id="line-169"></span><span id="local-6989586621679571913"><span class="hs-keyword">instance</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkAbsPos"><span class="hs-identifier hs-type">MkAbsPos</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571913"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkAbsPos"><span class="hs-identifier hs-type">MkAbsPos</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571913"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-170"></span><span>  </span><span id="local-6989586621679571910"><span class="annot"><span class="annottext">initialize :: ModelSpec MkAbsPos
-&gt; Generator generatorDevice
-&gt; m (MkAbsPos, Generator generatorDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#initialize"><span class="hs-identifier hs-var hs-var hs-var hs-var">initialize</span></a></span></span><span> </span><span id="local-6989586621679571908"><span class="annot"><span class="annottext">ModelSpec MkAbsPos
</span><a href="#local-6989586621679571908"><span class="hs-identifier hs-var">spec</span></a></span></span><span> </span><span id="local-6989586621679571907"><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679571907"><span class="hs-identifier hs-var">g</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(MkAbsPos, Generator generatorDevice)
-&gt; m (MkAbsPos, Generator generatorDevice)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">ModelSpec MkAbsPos
MkAbsPos
</span><a href="#local-6989586621679571908"><span class="hs-identifier hs-var">spec</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679571907"><span class="hs-identifier hs-var">g</span></a></span><span class="hs-special">)</span></span><span>
</span><span id="line-171"></span><span>
</span><span id="line-172"></span><span class="hs-keyword">instance</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasStateDict"><span class="hs-identifier hs-type">HasStateDict</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkAbsPos"><span class="hs-identifier hs-type">MkAbsPos</span></a></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-173"></span><span>  </span><span id="local-6989586621679571903"><span class="annot"><span class="annottext">fromStateDict :: ModelSpec MkAbsPos -&gt; StateDictKey -&gt; m MkAbsPos
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var hs-var hs-var hs-var">fromStateDict</span></a></span></span><span> </span><span id="local-6989586621679571901"><span class="annot"><span class="annottext">ModelSpec MkAbsPos
</span><a href="#local-6989586621679571901"><span class="hs-identifier hs-var">spec</span></a></span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">MkAbsPos -&gt; m MkAbsPos
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">ModelSpec MkAbsPos
MkAbsPos
</span><a href="#local-6989586621679571901"><span class="hs-identifier hs-var">spec</span></a></span><span>
</span><span id="line-174"></span><span>  </span><span id="local-6989586621679571900"><span class="annot"><span class="annottext">toStateDict :: StateDictKey -&gt; MkAbsPos -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var hs-var hs-var hs-var">toStateDict</span></a></span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="annottext">MkAbsPos
</span><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">() -&gt; m ()
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-175"></span><span>
</span><span id="line-176"></span><span id="local-6989586621679571889"><span id="local-6989586621679571890"><span id="local-6989586621679571891"><span id="local-6989586621679571892"><span id="local-6989586621679571893"><span id="local-6989586621679571894"><span id="local-6989586621679571895"><span id="local-6989586621679571896"><span id="local-6989586621679571897"><span id="local-6989586621679571898"><span class="hs-keyword">instance</span><span>
</span><span id="line-177"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkPosC"><span class="hs-identifier hs-type">MkPosC</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571898"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571897"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571896"><span class="hs-identifier hs-type">seqDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571895"><span class="hs-identifier hs-type">seqName</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571894"><span class="hs-identifier hs-type">seqSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571893"><span class="hs-identifier hs-type">output</span></a></span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-178"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-179"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkAbsPos"><span class="hs-identifier hs-type">MkAbsPos</span></a></span><span>
</span><span id="line-180"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571892"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571891"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571898"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571890"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571897"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-181"></span><span>    </span><span class="annot"><a href="#local-6989586621679571889"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-182"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#WithoutGradient"><span class="hs-identifier hs-type">WithoutGradient</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Dense"><span class="hs-identifier hs-type">Dense</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679571898"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#Int64"><span class="hs-identifier hs-type">Int64</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679571894"><span class="hs-identifier hs-type">seqSize</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-183"></span><span>    </span><span class="annot"><a href="#local-6989586621679571889"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-184"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-185"></span><span>  </span><span id="local-6989586621679571886"><span class="annot"><span class="annottext">forward :: MkAbsPos
-&gt; Tensor gradient layout device dataType shape
-&gt; Generator generatorDevice
-&gt; m (Tensor
        ('Gradient 'WithoutGradient)
        ('Layout 'Dense)
        device
        ('DataType 'Int64)
        ('Shape '[ 'Dim ('Name &quot;*&quot;) seqSize]),
      Generator generatorDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var hs-var hs-var hs-var">forward</span></a></span></span><span> </span><span class="annot"><span class="annottext">MkAbsPos
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkAbsPos"><span class="hs-identifier hs-var">MkAbsPos</span></a></span><span> </span><span id="local-6989586621679571884"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679571884"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span id="local-6989586621679571883"><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679571883"><span class="hs-identifier hs-var">g</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-186"></span><span>    </span><span id="local-6989586621679571882"><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  device
  ('DataType 'Int64)
  ('Shape '[ 'Dim ('Name &quot;*&quot;) seqSize])
</span><a href="#local-6989586621679571882"><span class="hs-identifier hs-var">pos</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
-&gt; m (Tensor
        ('Gradient 'WithoutGradient)
        ('Layout 'Dense)
        device
        ('DataType 'Int64)
        ('Shape '[ 'Dim ('Name &quot;*&quot;) seqSize]))
forall (m :: * -&gt; *) (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (seqDim :: Dim (Name Symbol) (Size Nat)) (seqName :: Name Symbol)
       (seqSize :: Size Nat) output.
(MonadThrow m,
 MkPosC device shape seqDim seqName seqSize output) =&gt;
Tensor gradient layout device dataType shape -&gt; m output
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#mkPos"><span class="hs-identifier hs-var">mkPos</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679571884"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-187"></span><span>    </span><span class="annot"><span class="annottext">(Tensor
   ('Gradient 'WithoutGradient)
   ('Layout 'Dense)
   device
   ('DataType 'Int64)
   ('Shape '[ 'Dim ('Name &quot;*&quot;) seqSize]),
 Generator generatorDevice)
-&gt; m (Tensor
        ('Gradient 'WithoutGradient)
        ('Layout 'Dense)
        device
        ('DataType 'Int64)
        ('Shape '[ 'Dim ('Name &quot;*&quot;) seqSize]),
      Generator generatorDevice)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  device
  ('DataType 'Int64)
  ('Shape '[ 'Dim ('Name &quot;*&quot;) seqSize])
</span><a href="#local-6989586621679571882"><span class="hs-identifier hs-var">pos</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679571883"><span class="hs-identifier hs-var">g</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-188"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkAbsPosWithOffset"><span class="hs-identifier hs-type">MkAbsPosWithOffset</span></a></span><span> </span><span class="hs-special">{</span><span id="local-6989586621679571881"><span class="annot"><span class="annottext">Int
absPosOffset :: Int
absPosOffset :: MkAbsPos -&gt; Int
</span><a href="#local-6989586621679571881"><span class="hs-glyph hs-var hs-var">..</span></a></span></span><span class="hs-special">}</span><span> </span><span id="local-6989586621679571880"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679571880"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span id="local-6989586621679571879"><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679571879"><span class="hs-identifier hs-var">g</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-189"></span><span>    </span><span id="local-6989586621679571878"><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  device
  ('DataType 'Int64)
  ('Shape '[ 'Dim ('Name &quot;*&quot;) seqSize])
</span><a href="#local-6989586621679571878"><span class="hs-identifier hs-var">pos</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
-&gt; m (Tensor
        ('Gradient 'WithoutGradient)
        ('Layout 'Dense)
        device
        ('DataType 'Int64)
        ('Shape '[ 'Dim ('Name &quot;*&quot;) seqSize]))
forall (m :: * -&gt; *) (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (seqDim :: Dim (Name Symbol) (Size Nat)) (seqName :: Name Symbol)
       (seqSize :: Size Nat) output.
(MonadThrow m,
 MkPosC device shape seqDim seqName seqSize output) =&gt;
Tensor gradient layout device dataType shape -&gt; m output
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#mkPos"><span class="hs-identifier hs-var">mkPos</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679571880"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-190"></span><span>    </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679571877"><span class="annot"><span class="annottext">pos' :: Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  device
  ('DataType 'Int64)
  ('Shape '[ 'Dim ('Name &quot;*&quot;) seqSize])
</span><a href="#local-6989586621679571877"><span class="hs-identifier hs-var hs-var">pos'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  device
  ('DataType 'Int64)
  ('Shape '[ 'Dim ('Name &quot;*&quot;) seqSize])
-&gt; Int
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     device
     ('DataType 'Int64)
     ('Shape '[ 'Dim ('Name &quot;*&quot;) seqSize])
forall other (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
Scalar other =&gt;
Tensor gradient layout device dataType shape
-&gt; other -&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#addScalar"><span class="hs-identifier hs-var">addScalar</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  device
  ('DataType 'Int64)
  ('Shape '[ 'Dim ('Name &quot;*&quot;) seqSize])
</span><a href="#local-6989586621679571878"><span class="hs-identifier hs-var">pos</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679571881"><span class="hs-identifier hs-var">absPosOffset</span></a></span><span>
</span><span id="line-191"></span><span>    </span><span class="annot"><span class="annottext">(Tensor
   ('Gradient 'WithoutGradient)
   ('Layout 'Dense)
   device
   ('DataType 'Int64)
   ('Shape '[ 'Dim ('Name &quot;*&quot;) seqSize]),
 Generator generatorDevice)
-&gt; m (Tensor
        ('Gradient 'WithoutGradient)
        ('Layout 'Dense)
        device
        ('DataType 'Int64)
        ('Shape '[ 'Dim ('Name &quot;*&quot;) seqSize]),
      Generator generatorDevice)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  device
  ('DataType 'Int64)
  ('Shape '[ 'Dim ('Name &quot;*&quot;) seqSize])
</span><a href="#local-6989586621679571877"><span class="hs-identifier hs-var">pos'</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679571879"><span class="hs-identifier hs-var">g</span></a></span><span class="hs-special">)</span></span></span></span></span></span></span></span></span></span></span><span>
</span><span id="line-192"></span><span>
</span><span id="line-193"></span><span class="hs-comment">-- | Computes relative positions of the input tokens to the encoder.</span><span>
</span><span id="line-194"></span><span class="hs-comment">--</span><span>
</span><span id="line-195"></span><span class="hs-comment">-- &gt;&gt;&gt; mkRelPos' 32 128 21 17</span><span>
</span><span id="line-196"></span><span class="hs-comment">-- [[0,17,18,19,20,21,22,23,24,24,24,24,25,25,25,25,26],[1,0,17,18,19,20,21,22,23,24,24,24,24,25,25,25,25],[2,1,0,17,18,19,20,21,22,23,24,24,24,24,25,25,25],[3,2,1,0,17,18,19,20,21,22,23,24,24,24,24,25,25],[4,3,2,1,0,17,18,19,20,21,22,23,24,24,24,24,25],[5,4,3,2,1,0,17,18,19,20,21,22,23,24,24,24,24],[6,5,4,3,2,1,0,17,18,19,20,21,22,23,24,24,24],[7,6,5,4,3,2,1,0,17,18,19,20,21,22,23,24,24],[8,7,6,5,4,3,2,1,0,17,18,19,20,21,22,23,24],[8,8,7,6,5,4,3,2,1,0,17,18,19,20,21,22,23],[8,8,8,7,6,5,4,3,2,1,0,17,18,19,20,21,22],[8,8,8,8,7,6,5,4,3,2,1,0,17,18,19,20,21],[9,8,8,8,8,7,6,5,4,3,2,1,0,17,18,19,20],[9,9,8,8,8,8,7,6,5,4,3,2,1,0,17,18,19],[9,9,9,8,8,8,8,7,6,5,4,3,2,1,0,17,18],[9,9,9,9,8,8,8,8,7,6,5,4,3,2,1,0,17],[10,9,9,9,9,8,8,8,8,7,6,5,4,3,2,1,0],[10,10,9,9,9,9,8,8,8,8,7,6,5,4,3,2,1],[10,10,10,9,9,9,9,8,8,8,8,7,6,5,4,3,2],[10,10,10,10,9,9,9,9,8,8,8,8,7,6,5,4,3],[10,10,10,10,10,9,9,9,9,8,8,8,8,7,6,5,4]]</span><span>
</span><span id="line-197"></span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#mkRelPos%27"><span class="hs-identifier hs-type">mkRelPos'</span></a></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">[</span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">]</span><span class="hs-special">]</span><span>
</span><span id="line-198"></span><span id="mkRelPos%27"><span class="annot"><span class="annottext">mkRelPos' :: Int -&gt; Int -&gt; Int -&gt; Int -&gt; [[Int]]
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#mkRelPos%27"><span class="hs-identifier hs-var hs-var">mkRelPos'</span></a></span></span><span> </span><span id="local-6989586621679571875"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679571875"><span class="hs-identifier hs-var">numBuckets</span></a></span></span><span> </span><span id="local-6989586621679571874"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679571874"><span class="hs-identifier hs-var">maxDistance</span></a></span></span><span> </span><span id="local-6989586621679571873"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679571873"><span class="hs-identifier hs-var">querySize</span></a></span></span><span> </span><span id="local-6989586621679571872"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679571872"><span class="hs-identifier hs-var">keySize</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-199"></span><span>  </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679571871"><span class="annot"><span class="annottext">queryPos :: [Int]
</span><a href="#local-6989586621679571871"><span class="hs-identifier hs-var hs-var">queryPos</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">0</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">1</span></span><span> </span><span class="hs-glyph">..</span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679571873"><span class="hs-identifier hs-var">querySize</span></a></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Int
forall a. Num a =&gt; a -&gt; a -&gt; a
</span><span class="hs-glyph hs-var">-</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">1</span></span><span class="hs-special">]</span><span>
</span><span id="line-200"></span><span>      </span><span id="local-6989586621679571870"><span class="annot"><span class="annottext">keyPos :: [Int]
</span><a href="#local-6989586621679571870"><span class="hs-identifier hs-var hs-var">keyPos</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">0</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">1</span></span><span> </span><span class="hs-glyph">..</span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679571872"><span class="hs-identifier hs-var">keySize</span></a></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Int
forall a. Num a =&gt; a -&gt; a -&gt; a
</span><span class="hs-glyph hs-var">-</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">1</span></span><span class="hs-special">]</span><span>
</span><span id="line-201"></span><span>      </span><span id="local-6989586621679571869"><span class="annot"><span class="annottext">numBuckets' :: Int
</span><a href="#local-6989586621679571869"><span class="hs-identifier hs-var hs-var">numBuckets'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679571875"><span class="hs-identifier hs-var">numBuckets</span></a></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Int
forall a. Integral a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">`div`</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">2</span></span><span>
</span><span id="line-202"></span><span>      </span><span id="local-6989586621679571867"><span class="annot"><span class="annottext">maxExact :: Int
</span><a href="#local-6989586621679571867"><span class="hs-identifier hs-var hs-var">maxExact</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679571869"><span class="hs-identifier hs-var">numBuckets'</span></a></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Int
forall a. Integral a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">`div`</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">2</span></span><span>
</span><span id="line-203"></span><span>   </span><span class="hs-keyword">in</span><span> </span><span class="annot"><span class="annottext">(Int -&gt; [Int]) -&gt; [Int] -&gt; [[Int]]
forall (f :: * -&gt; *) a b. Functor f =&gt; (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-identifier hs-var">fmap</span></span><span>
</span><span id="line-204"></span><span>        </span><span class="hs-special">(</span><span> </span><span class="hs-glyph">\</span><span id="local-6989586621679571866"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679571866"><span class="hs-identifier hs-var">qp</span></a></span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-205"></span><span>            </span><span class="annot"><span class="annottext">(Int -&gt; Int) -&gt; [Int] -&gt; [Int]
forall (f :: * -&gt; *) a b. Functor f =&gt; (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-identifier hs-var">fmap</span></span><span>
</span><span id="line-206"></span><span>              </span><span class="hs-special">(</span><span> </span><span class="hs-glyph">\</span><span id="local-6989586621679571865"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679571865"><span class="hs-identifier hs-var">kp</span></a></span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-207"></span><span>                  </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679571864"><span class="annot"><span class="annottext">rawRelPos :: Int
</span><a href="#local-6989586621679571864"><span class="hs-identifier hs-var hs-var">rawRelPos</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679571865"><span class="hs-identifier hs-var">kp</span></a></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Int
forall a. Num a =&gt; a -&gt; a -&gt; a
</span><span class="hs-glyph hs-var">-</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679571866"><span class="hs-identifier hs-var">qp</span></a></span><span>
</span><span id="line-208"></span><span>                      </span><span id="local-6989586621679571863"><span class="annot"><span class="annottext">absRelPos :: Int
</span><a href="#local-6989586621679571863"><span class="hs-identifier hs-var hs-var">absRelPos</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int
forall a. Num a =&gt; a -&gt; a
</span><span class="hs-identifier hs-var">abs</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679571864"><span class="hs-identifier hs-var">rawRelPos</span></a></span><span>
</span><span id="line-209"></span><span>                      </span><span id="local-6989586621679571861"><span class="annot"><span class="annottext">relBucket :: Int
</span><a href="#local-6989586621679571861"><span class="hs-identifier hs-var hs-var">relBucket</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">if</span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679571864"><span class="hs-identifier hs-var">rawRelPos</span></a></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Bool
forall a. Ord a =&gt; a -&gt; a -&gt; Bool
</span><span class="hs-operator hs-var">&gt;</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">0</span></span><span> </span><span class="hs-keyword">then</span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679571869"><span class="hs-identifier hs-var">numBuckets'</span></a></span><span> </span><span class="hs-keyword">else</span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">0</span></span><span>
</span><span id="line-210"></span><span>                      </span><span id="local-6989586621679571859"><span class="annot"><span class="annottext">relBucket' :: Int
</span><a href="#local-6989586621679571859"><span class="hs-identifier hs-var hs-var">relBucket'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-211"></span><span>                        </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679571858"><span class="annot"><span class="annottext">isSmall :: Bool
</span><a href="#local-6989586621679571858"><span class="hs-identifier hs-var hs-var">isSmall</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679571863"><span class="hs-identifier hs-var">absRelPos</span></a></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Bool
forall a. Ord a =&gt; a -&gt; a -&gt; Bool
</span><span class="hs-operator hs-var">&lt;</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679571867"><span class="hs-identifier hs-var">maxExact</span></a></span><span>
</span><span id="line-212"></span><span>                            </span><span id="local-6989586621679571856"><span class="annot"><span class="annottext">relPosIfLarge :: Int
</span><a href="#local-6989586621679571856"><span class="hs-identifier hs-var hs-var">relPosIfLarge</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-213"></span><span>                              </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679571867"><span class="hs-identifier hs-var">maxExact</span></a></span><span>
</span><span id="line-214"></span><span>                                </span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Int
forall a. Num a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">+</span></span><span> </span><span class="annot"><span class="annottext">Double -&gt; Int
</span><span class="hs-identifier hs-var">double2Int</span></span><span>
</span><span id="line-215"></span><span>                                  </span><span class="hs-special">(</span><span> </span><span class="annot"><span class="annottext">Double -&gt; Double -&gt; Double
forall a. Floating a =&gt; a -&gt; a -&gt; a
</span><span class="hs-identifier hs-var">logBase</span></span><span>
</span><span id="line-216"></span><span>                                      </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Int -&gt; Double
forall a b. (Integral a, Num b) =&gt; a -&gt; b
</span><span class="hs-identifier hs-var">fromIntegral</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679571874"><span class="hs-identifier hs-var">maxDistance</span></a></span><span> </span><span class="annot"><span class="annottext">Double -&gt; Double -&gt; Double
forall a. Fractional a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">/</span></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Double
forall a b. (Integral a, Num b) =&gt; a -&gt; b
</span><span class="hs-identifier hs-var">fromIntegral</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679571867"><span class="hs-identifier hs-var">maxExact</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-217"></span><span>                                      </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Int -&gt; Double
forall a b. (Integral a, Num b) =&gt; a -&gt; b
</span><span class="hs-identifier hs-var">fromIntegral</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679571863"><span class="hs-identifier hs-var">absRelPos</span></a></span><span> </span><span class="annot"><span class="annottext">Double -&gt; Double -&gt; Double
forall a. Fractional a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">/</span></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Double
forall a b. (Integral a, Num b) =&gt; a -&gt; b
</span><span class="hs-identifier hs-var">fromIntegral</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679571867"><span class="hs-identifier hs-var">maxExact</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-218"></span><span>                                      </span><span class="annot"><span class="annottext">Double -&gt; Double -&gt; Double
forall a. Num a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">*</span></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Double
forall a b. (Integral a, Num b) =&gt; a -&gt; b
</span><span class="hs-identifier hs-var">fromIntegral</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679571869"><span class="hs-identifier hs-var">numBuckets'</span></a></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Int
forall a. Num a =&gt; a -&gt; a -&gt; a
</span><span class="hs-glyph hs-var">-</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679571867"><span class="hs-identifier hs-var">maxExact</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-219"></span><span>                                  </span><span class="hs-special">)</span><span>
</span><span id="line-220"></span><span>                            </span><span id="local-6989586621679571851"><span class="annot"><span class="annottext">relPosIfLarge' :: Int
</span><a href="#local-6989586621679571851"><span class="hs-identifier hs-var hs-var">relPosIfLarge'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Int
forall a. Ord a =&gt; a -&gt; a -&gt; a
</span><span class="hs-identifier hs-var">min</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679571856"><span class="hs-identifier hs-var">relPosIfLarge</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679571869"><span class="hs-identifier hs-var">numBuckets'</span></a></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Int
forall a. Num a =&gt; a -&gt; a -&gt; a
</span><span class="hs-glyph hs-var">-</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">1</span></span><span class="hs-special">)</span><span>
</span><span id="line-221"></span><span>                         </span><span class="hs-keyword">in</span><span> </span><span class="hs-keyword">if</span><span> </span><span class="annot"><span class="annottext">Bool
</span><a href="#local-6989586621679571858"><span class="hs-identifier hs-var">isSmall</span></a></span><span> </span><span class="hs-keyword">then</span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679571863"><span class="hs-identifier hs-var">absRelPos</span></a></span><span> </span><span class="hs-keyword">else</span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679571851"><span class="hs-identifier hs-var">relPosIfLarge'</span></a></span><span>
</span><span id="line-222"></span><span>                   </span><span class="hs-keyword">in</span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679571861"><span class="hs-identifier hs-var">relBucket</span></a></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Int
forall a. Num a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">+</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679571859"><span class="hs-identifier hs-var">relBucket'</span></a></span><span>
</span><span id="line-223"></span><span>              </span><span class="hs-special">)</span><span>
</span><span id="line-224"></span><span>              </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679571870"><span class="hs-identifier hs-var">keyPos</span></a></span><span>
</span><span id="line-225"></span><span>        </span><span class="hs-special">)</span><span>
</span><span id="line-226"></span><span>        </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679571871"><span class="hs-identifier hs-var">queryPos</span></a></span><span>
</span><span id="line-227"></span><span>
</span><span id="line-228"></span><span class="hs-keyword">type</span><span> </span><span id="MkRelPosC"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkRelPosC"><span class="hs-identifier hs-var">MkRelPosC</span></a></span></span><span> </span><span id="local-6989586621679571849"><span class="annot"><a href="#local-6989586621679571849"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679571848"><span class="annot"><a href="#local-6989586621679571848"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679571847"><span class="annot"><a href="#local-6989586621679571847"><span class="hs-identifier hs-type">seqDim</span></a></span></span><span> </span><span id="local-6989586621679571846"><span class="annot"><a href="#local-6989586621679571846"><span class="hs-identifier hs-type">seqName</span></a></span></span><span> </span><span id="local-6989586621679571845"><span class="annot"><a href="#local-6989586621679571845"><span class="hs-identifier hs-type">seqSize</span></a></span></span><span> </span><span id="local-6989586621679571844"><span class="annot"><a href="#local-6989586621679571844"><span class="hs-identifier hs-type">output</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-229"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetDevice"><span class="hs-identifier hs-type">SGetDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571849"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-230"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetShape"><span class="hs-identifier hs-type">SGetShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571848"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-231"></span><span>    </span><span class="annot"><a href="#local-6989586621679571847"><span class="hs-identifier hs-type">seqDim</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679571848"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#%21"><span class="hs-glyph hs-type">!</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-232"></span><span>    </span><span class="annot"><a href="#local-6989586621679571847"><span class="hs-identifier hs-type">seqDim</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571846"><span class="hs-identifier hs-type">seqName</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571845"><span class="hs-identifier hs-type">seqSize</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-233"></span><span>    </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span>
</span><span id="line-234"></span><span>      </span><span class="hs-special">'</span><span class="hs-special">[</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-235"></span><span>         </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679571845"><span class="hs-identifier hs-type">seqSize</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-236"></span><span>         </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679571845"><span class="hs-identifier hs-type">seqSize</span></a></span><span>
</span><span id="line-237"></span><span>       </span><span class="hs-special">]</span><span>
</span><span id="line-238"></span><span>      </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Seq"><span class="hs-identifier hs-type">Seq</span></a></span><span>
</span><span id="line-239"></span><span>          </span><span class="hs-special">(</span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#UncheckedSize"><span class="hs-identifier hs-type">UncheckedSize</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-240"></span><span>               </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#UncheckedSize"><span class="hs-identifier hs-type">UncheckedSize</span></a></span><span>
</span><span id="line-241"></span><span>             </span><span class="hs-special">]</span><span>
</span><span id="line-242"></span><span>              </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679571845"><span class="hs-identifier hs-type">seqSize</span></a></span><span class="hs-special">,</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679571845"><span class="hs-identifier hs-type">seqSize</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-243"></span><span>          </span><span class="hs-special">)</span><span>
</span><span id="line-244"></span><span>          </span><span class="hs-special">(</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span>
</span><span id="line-245"></span><span>              </span><span class="hs-special">'</span><span class="hs-special">[</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-246"></span><span>                 </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679571845"><span class="hs-identifier hs-type">seqSize</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-247"></span><span>                 </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679571845"><span class="hs-identifier hs-type">seqSize</span></a></span><span>
</span><span id="line-248"></span><span>               </span><span class="hs-special">]</span><span>
</span><span id="line-249"></span><span>          </span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-250"></span><span>    </span><span class="annot"><a href="#local-6989586621679571844"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-251"></span><span>      </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-252"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#WithoutGradient"><span class="hs-identifier hs-type">WithoutGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-253"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Dense"><span class="hs-identifier hs-type">Dense</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-254"></span><span>          </span><span class="annot"><a href="#local-6989586621679571849"><span class="hs-identifier hs-type">device</span></a></span><span>
</span><span id="line-255"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#Int64"><span class="hs-identifier hs-type">Int64</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-256"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679571845"><span class="hs-identifier hs-type">seqSize</span></a></span><span class="hs-special">,</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679571845"><span class="hs-identifier hs-type">seqSize</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-257"></span><span>  </span><span class="hs-special">)</span><span>
</span><span id="line-258"></span><span>
</span><span id="line-259"></span><span class="hs-comment">-- | Computes relative positions of the input tokens to the encoder.</span><span>
</span><span id="line-260"></span><span class="hs-comment">-- Given an input tensor of shape @[batchDim, Dim seqName seqSize]@,</span><span>
</span><span id="line-261"></span><span class="hs-comment">-- returns a tensor of shape @[1, Dim &quot;*&quot; seqSize, Dim &quot;*&quot; seqSize]@.</span><span>
</span><span id="line-262"></span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#mkRelPos"><span class="hs-identifier hs-type">mkRelPos</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-263"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679572342"><span class="annot"><a href="#local-6989586621679572342"><span class="hs-identifier hs-type">m</span></a></span></span><span> </span><span id="local-6989586621679572334"><span class="annot"><a href="#local-6989586621679572334"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679572333"><span class="annot"><a href="#local-6989586621679572333"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679572341"><span class="annot"><a href="#local-6989586621679572341"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679572332"><span class="annot"><a href="#local-6989586621679572332"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679572340"><span class="annot"><a href="#local-6989586621679572340"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679572335"><span class="annot"><a href="#local-6989586621679572335"><span class="hs-identifier hs-type">relPosEncBucketDim</span></a></span></span><span> </span><span id="local-6989586621679572339"><span class="annot"><a href="#local-6989586621679572339"><span class="hs-identifier hs-type">seqDim</span></a></span></span><span> </span><span id="local-6989586621679572338"><span class="annot"><a href="#local-6989586621679572338"><span class="hs-identifier hs-type">seqName</span></a></span></span><span> </span><span id="local-6989586621679572337"><span class="annot"><a href="#local-6989586621679572337"><span class="hs-identifier hs-type">seqSize</span></a></span></span><span> </span><span id="local-6989586621679572336"><span class="annot"><a href="#local-6989586621679572336"><span class="hs-identifier hs-type">output</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-264"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier hs-type">MonadThrow</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679572342"><span class="hs-identifier hs-type">m</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-265"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkRelPosC"><span class="hs-identifier hs-type">MkRelPosC</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679572341"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679572340"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679572339"><span class="hs-identifier hs-type">seqDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679572338"><span class="hs-identifier hs-type">seqName</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679572337"><span class="hs-identifier hs-type">seqSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679572336"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-266"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-267"></span><span>  </span><span class="hs-comment">-- | bucket dimension</span><span>
</span><span id="line-268"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679572335"><span class="hs-identifier hs-type">relPosEncBucketDim</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-269"></span><span>  </span><span class="hs-comment">-- | maximum distance</span><span>
</span><span id="line-270"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-271"></span><span>  </span><span class="hs-comment">-- | input tensor</span><span>
</span><span id="line-272"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679572334"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679572333"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679572341"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679572332"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679572340"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-273"></span><span>  </span><span class="hs-comment">-- | relative positions of the input tokens</span><span>
</span><span id="line-274"></span><span>  </span><span class="annot"><a href="#local-6989586621679572342"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679572336"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-275"></span><span id="mkRelPos"><span class="annot"><span class="annottext">mkRelPos :: SDim relPosEncBucketDim
-&gt; Int -&gt; Tensor gradient layout device dataType shape -&gt; m output
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#mkRelPos"><span class="hs-identifier hs-var hs-var">mkRelPos</span></a></span></span><span> </span><span id="local-6989586621679571842"><span class="annot"><span class="annottext">SDim relPosEncBucketDim
</span><a href="#local-6989586621679571842"><span class="hs-identifier hs-var">relPosEncBucketDim</span></a></span></span><span> </span><span id="local-6989586621679571841"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679571841"><span class="hs-identifier hs-var">maxDistance</span></a></span></span><span> </span><span id="local-6989586621679571840"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679571840"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-276"></span><span>  </span><span id="local-6989586621679571839"><span class="annot"><span class="annottext">SDim ('Dim seqName seqSize)
</span><a href="#local-6989586621679571839"><span class="hs-identifier hs-var">seqDim</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">SSelectDim ('SelectDim ('ByIndex 1))
-&gt; SShape shape -&gt; m (SDim ('Dim seqName seqSize))
forall (selectDim :: SelectDim (By Symbol Nat))
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (dim :: Dim (Name Symbol) (Size Nat)) (m :: * -&gt; *).
(dim ~ GetDimF selectDim shape, MonadThrow m) =&gt;
SSelectDim selectDim -&gt; SShape shape -&gt; m (SDim dim)
</span><a href="Torch.GraduallyTyped.Shape.Class.html#sGetDimFromShape"><span class="hs-identifier hs-var">sGetDimFromShape</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SBy ('ByIndex 1) -&gt; SSelectDim ('SelectDim ('ByIndex 1))
forall (by :: By Symbol Nat). SBy by -&gt; SSelectDim ('SelectDim by)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSelectDim"><span class="hs-identifier hs-var">SSelectDim</span></a></span><span> </span><span class="annot"><span class="annottext">(SBy ('ByIndex 1) -&gt; SSelectDim ('SelectDim ('ByIndex 1)))
-&gt; SBy ('ByIndex 1) -&gt; SSelectDim ('SelectDim ('ByIndex 1))
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">KnownNat 1 =&gt; SBy ('ByIndex 1)
forall (index :: Nat). KnownNat index =&gt; SBy ('ByIndex index)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SByIndex"><span class="hs-identifier hs-var">SByIndex</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">(SShape shape -&gt; m (SDim ('Dim seqName seqSize)))
-&gt; SShape shape -&gt; m (SDim ('Dim seqName seqSize))
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape -&gt; SShape shape
forall (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType).
SGetShape shape =&gt;
Tensor gradient layout device dataType shape -&gt; SShape shape
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sGetShape"><span class="hs-identifier hs-var">sGetShape</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679571840"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-277"></span><span>  </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679571838"><span class="annot"><span class="annottext">seqSize :: Int
</span><a href="#local-6989586621679571838"><span class="hs-identifier hs-var hs-var">seqSize</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Integer -&gt; Int
forall a. Num a =&gt; Integer -&gt; a
</span><span class="hs-identifier hs-var">fromInteger</span></span><span> </span><span class="annot"><span class="annottext">(Integer -&gt; Int)
-&gt; (SSize seqSize -&gt; Integer) -&gt; SSize seqSize -&gt; Int
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">IsChecked Integer -&gt; Integer
forall a. IsChecked a -&gt; a
</span><a href="Torch.GraduallyTyped.Prelude.html#forgetIsChecked"><span class="hs-identifier hs-var">forgetIsChecked</span></a></span><span> </span><span class="annot"><span class="annottext">(IsChecked Integer -&gt; Integer)
-&gt; (SSize seqSize -&gt; IsChecked Integer) -&gt; SSize seqSize -&gt; Integer
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">SSize seqSize -&gt; IsChecked Integer
forall k (a :: k). SingKind k =&gt; Sing a -&gt; Demote k
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">fromSing</span></a></span><span> </span><span class="annot"><span class="annottext">(SSize seqSize -&gt; Int) -&gt; SSize seqSize -&gt; Int
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim seqName seqSize) -&gt; SSize seqSize
forall (name :: Name Symbol) (size :: Size Nat).
SDim ('Dim name size) -&gt; SSize size
</span><a href="Torch.GraduallyTyped.Shape.Type.html#sDimSize"><span class="hs-identifier hs-var hs-var">sDimSize</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim seqName seqSize)
</span><a href="#local-6989586621679571839"><span class="hs-identifier hs-var">seqDim</span></a></span><span>
</span><span id="line-278"></span><span>  </span><span class="annot"><span class="annottext">SGradient ('Gradient 'WithoutGradient)
-&gt; SLayout ('Layout 'Dense)
-&gt; SDevice device
-&gt; [[[Int]]]
-&gt; m (Tensor
        ('Gradient 'WithoutGradient)
        ('Layout 'Dense)
        device
        ('DataType 'Int64)
        ('Shape
           '[ 'Dim ('Name &quot;*&quot;) 'UncheckedSize,
              'Dim ('Name &quot;*&quot;) 'UncheckedSize, 'Dim ('Name &quot;*&quot;) 'UncheckedSize]))
forall a (dType :: DType) (dims :: [Dim (Name Symbol) (Size Nat)])
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (m :: * -&gt; *).
(TensorLike a dType dims, MonadThrow m) =&gt;
SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; a
-&gt; m (Tensor
        gradient layout device ('DataType dType) ('Shape dims))
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sToTensor"><span class="hs-identifier hs-var">sToTensor</span></a></span><span> </span><span class="annot"><span class="annottext">SGradient ('Gradient 'WithoutGradient)
</span><a href="#local-6989586621679571837"><span class="hs-identifier hs-var">gradient'</span></a></span><span> </span><span class="annot"><span class="annottext">SLayout ('Layout 'Dense)
</span><a href="#local-6989586621679571836"><span class="hs-identifier hs-var">layout'</span></a></span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679571835"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="hs-special">[</span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Int -&gt; Int -&gt; [[Int]]
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#mkRelPos%27"><span class="hs-identifier hs-var">mkRelPos'</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679571834"><span class="hs-identifier hs-var">relPosEncBucketSize</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679571841"><span class="hs-identifier hs-var">maxDistance</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679571838"><span class="hs-identifier hs-var">seqSize</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679571838"><span class="hs-identifier hs-var">seqSize</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-279"></span><span>    </span><span class="annot"><span class="annottext">m (Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     device
     ('DataType 'Int64)
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) 'UncheckedSize,
           'Dim ('Name &quot;*&quot;) 'UncheckedSize, 'Dim ('Name &quot;*&quot;) 'UncheckedSize]))
-&gt; (Tensor
      ('Gradient 'WithoutGradient)
      ('Layout 'Dense)
      device
      ('DataType 'Int64)
      ('Shape
         '[ 'Dim ('Name &quot;*&quot;) 'UncheckedSize,
            'Dim ('Name &quot;*&quot;) 'UncheckedSize, 'Dim ('Name &quot;*&quot;) 'UncheckedSize])
    -&gt; m output)
-&gt; m output
forall (m :: * -&gt; *) a b. Monad m =&gt; m a -&gt; (a -&gt; m b) -&gt; m b
</span><span class="hs-operator hs-var">&gt;&gt;=</span></span><span> </span><span class="annot"><span class="annottext">SShape
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) seqSize,
        'Dim ('Name &quot;*&quot;) seqSize])
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     device
     ('DataType 'Int64)
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) 'UncheckedSize,
           'Dim ('Name &quot;*&quot;) 'UncheckedSize, 'Dim ('Name &quot;*&quot;) 'UncheckedSize])
-&gt; m (Tensor
        ('Gradient 'WithoutGradient)
        ('Layout 'Dense)
        device
        ('DataType 'Int64)
        (Seq
           ('Shape
              '[ 'Dim ('Name &quot;*&quot;) 'UncheckedSize,
                 'Dim ('Name &quot;*&quot;) 'UncheckedSize, 'Dim ('Name &quot;*&quot;) 'UncheckedSize]
            &lt;+&gt; 'Shape
                  '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) seqSize,
                     'Dim ('Name &quot;*&quot;) seqSize])
           ('Shape
              '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) seqSize,
                 'Dim ('Name &quot;*&quot;) seqSize])))
forall (shape' :: Shape [Dim (Name Symbol) (Size Nat)])
       (m :: * -&gt; *) (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
(SGetShape shape, MonadThrow m) =&gt;
SShape shape'
-&gt; Tensor gradient layout device dataType shape
-&gt; m (Tensor
        gradient layout device dataType (Seq (shape &lt;+&gt; shape') shape'))
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sCheckedShape"><span class="hs-identifier hs-var">sCheckedShape</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SList
  '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) seqSize,
     'Dim ('Name &quot;*&quot;) seqSize]
-&gt; SShape
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) seqSize,
           'Dim ('Name &quot;*&quot;) seqSize])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList
   '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) seqSize,
      'Dim ('Name &quot;*&quot;) seqSize]
 -&gt; SShape
      ('Shape
         '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) seqSize,
            'Dim ('Name &quot;*&quot;) seqSize]))
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) seqSize,
        'Dim ('Name &quot;*&quot;) seqSize]
-&gt; SShape
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) seqSize,
           'Dim ('Name &quot;*&quot;) seqSize])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize ('Size 1) -&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 1))
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownNat 1 =&gt; SSize ('Size 1)
forall (size :: Nat). KnownNat size =&gt; SSize ('Size size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier hs-var">SSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">1</span></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 1))
-&gt; SList '[ 'Dim ('Name &quot;*&quot;) seqSize, 'Dim ('Name &quot;*&quot;) seqSize]
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) seqSize,
        'Dim ('Name &quot;*&quot;) seqSize]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize seqSize -&gt; SDim ('Dim ('Name &quot;*&quot;) seqSize)
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim seqName seqSize) -&gt; SSize seqSize
forall (name :: Name Symbol) (size :: Size Nat).
SDim ('Dim name size) -&gt; SSize size
</span><a href="Torch.GraduallyTyped.Shape.Type.html#sDimSize"><span class="hs-identifier hs-var hs-var">sDimSize</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim seqName seqSize)
</span><a href="#local-6989586621679571839"><span class="hs-identifier hs-var">seqDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) seqSize)
-&gt; SList '[ 'Dim ('Name &quot;*&quot;) seqSize]
-&gt; SList '[ 'Dim ('Name &quot;*&quot;) seqSize, 'Dim ('Name &quot;*&quot;) seqSize]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize seqSize -&gt; SDim ('Dim ('Name &quot;*&quot;) seqSize)
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim seqName seqSize) -&gt; SSize seqSize
forall (name :: Name Symbol) (size :: Size Nat).
SDim ('Dim name size) -&gt; SSize size
</span><a href="Torch.GraduallyTyped.Shape.Type.html#sDimSize"><span class="hs-identifier hs-var hs-var">sDimSize</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim seqName seqSize)
</span><a href="#local-6989586621679571839"><span class="hs-identifier hs-var">seqDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) seqSize)
-&gt; SList '[] -&gt; SList '[ 'Dim ('Name &quot;*&quot;) seqSize]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-280"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-281"></span><span>    </span><span id="local-6989586621679571837"><span class="annot"><span class="annottext">gradient' :: SGradient ('Gradient 'WithoutGradient)
</span><a href="#local-6989586621679571837"><span class="hs-identifier hs-var hs-var">gradient'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SRequiresGradient 'WithoutGradient
-&gt; SGradient ('Gradient 'WithoutGradient)
forall (requiresGradient :: RequiresGradient).
SRequiresGradient requiresGradient
-&gt; SGradient ('Gradient requiresGradient)
</span><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier hs-var">SGradient</span></a></span><span> </span><span class="annot"><span class="annottext">SRequiresGradient 'WithoutGradient
</span><a href="Torch.GraduallyTyped.RequiresGradient.html#SWithoutGradient"><span class="hs-identifier hs-var">SWithoutGradient</span></a></span><span>
</span><span id="line-282"></span><span>    </span><span id="local-6989586621679571836"><span class="annot"><span class="annottext">layout' :: SLayout ('Layout 'Dense)
</span><a href="#local-6989586621679571836"><span class="hs-identifier hs-var hs-var">layout'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SLayoutType 'Dense -&gt; SLayout ('Layout 'Dense)
forall (layoutType :: LayoutType).
SLayoutType layoutType -&gt; SLayout ('Layout layoutType)
</span><a href="Torch.GraduallyTyped.Layout.html#SLayout"><span class="hs-identifier hs-var">SLayout</span></a></span><span> </span><span class="annot"><span class="annottext">SLayoutType 'Dense
</span><a href="Torch.GraduallyTyped.Layout.html#SDense"><span class="hs-identifier hs-var">SDense</span></a></span><span>
</span><span id="line-283"></span><span>    </span><span id="local-6989586621679571835"><span class="annot"><span class="annottext">device :: SDevice device
</span><a href="#local-6989586621679571835"><span class="hs-identifier hs-var hs-var">device</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape -&gt; SDevice device
forall (device :: Device (DeviceType Nat))
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SGetDevice device =&gt;
Tensor gradient layout device dataType shape -&gt; SDevice device
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sGetDevice"><span class="hs-identifier hs-var">sGetDevice</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679571840"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-284"></span><span>    </span><span id="local-6989586621679571834"><span class="annot"><span class="annottext">relPosEncBucketSize :: Int
</span><a href="#local-6989586621679571834"><span class="hs-identifier hs-var hs-var">relPosEncBucketSize</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Integer -&gt; Int
forall a. Num a =&gt; Integer -&gt; a
</span><span class="hs-identifier hs-var">fromInteger</span></span><span> </span><span class="annot"><span class="annottext">(Integer -&gt; Int)
-&gt; (SDim relPosEncBucketDim -&gt; Integer)
-&gt; SDim relPosEncBucketDim
-&gt; Int
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">IsChecked Integer -&gt; Integer
forall a. IsChecked a -&gt; a
</span><a href="Torch.GraduallyTyped.Prelude.html#forgetIsChecked"><span class="hs-identifier hs-var">forgetIsChecked</span></a></span><span> </span><span class="annot"><span class="annottext">(IsChecked Integer -&gt; Integer)
-&gt; (SDim relPosEncBucketDim -&gt; IsChecked Integer)
-&gt; SDim relPosEncBucketDim
-&gt; Integer
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Dim (IsChecked String) (IsChecked Integer) -&gt; IsChecked Integer
forall name size. Dim name size -&gt; size
</span><a href="Torch.GraduallyTyped.Shape.Type.html#dimSize"><span class="hs-identifier hs-var hs-var">dimSize</span></a></span><span> </span><span class="annot"><span class="annottext">(Dim (IsChecked String) (IsChecked Integer) -&gt; IsChecked Integer)
-&gt; (SDim relPosEncBucketDim
    -&gt; Dim (IsChecked String) (IsChecked Integer))
-&gt; SDim relPosEncBucketDim
-&gt; IsChecked Integer
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">SDim relPosEncBucketDim
-&gt; Dim (IsChecked String) (IsChecked Integer)
forall k (a :: k). SingKind k =&gt; Sing a -&gt; Demote k
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">fromSing</span></a></span><span> </span><span class="annot"><span class="annottext">(SDim relPosEncBucketDim -&gt; Int) -&gt; SDim relPosEncBucketDim -&gt; Int
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SDim relPosEncBucketDim
</span><a href="#local-6989586621679571842"><span class="hs-identifier hs-var">relPosEncBucketDim</span></a></span><span>
</span><span id="line-285"></span><span>
</span><span id="line-286"></span><span class="hs-comment">-- | Computes relative positions of the input tokens to the decoder.</span><span>
</span><span id="line-287"></span><span class="hs-comment">--</span><span>
</span><span id="line-288"></span><span class="hs-comment">-- &gt;&gt;&gt; mkDecoderRelPos' 32 128 21 17</span><span>
</span><span id="line-289"></span><span class="hs-comment">-- [[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[2,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[3,2,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[4,3,2,1,0,0,0,0,0,0,0,0,0,0,0,0,0],[5,4,3,2,1,0,0,0,0,0,0,0,0,0,0,0,0],[6,5,4,3,2,1,0,0,0,0,0,0,0,0,0,0,0],[7,6,5,4,3,2,1,0,0,0,0,0,0,0,0,0,0],[8,7,6,5,4,3,2,1,0,0,0,0,0,0,0,0,0],[9,8,7,6,5,4,3,2,1,0,0,0,0,0,0,0,0],[10,9,8,7,6,5,4,3,2,1,0,0,0,0,0,0,0],[11,10,9,8,7,6,5,4,3,2,1,0,0,0,0,0,0],[12,11,10,9,8,7,6,5,4,3,2,1,0,0,0,0,0],[13,12,11,10,9,8,7,6,5,4,3,2,1,0,0,0,0],[14,13,12,11,10,9,8,7,6,5,4,3,2,1,0,0,0],[15,14,13,12,11,10,9,8,7,6,5,4,3,2,1,0,0],[16,15,14,13,12,11,10,9,8,7,6,5,4,3,2,1,0],[16,16,15,14,13,12,11,10,9,8,7,6,5,4,3,2,1],[16,16,16,15,14,13,12,11,10,9,8,7,6,5,4,3,2],[17,16,16,16,15,14,13,12,11,10,9,8,7,6,5,4,3],[17,17,16,16,16,15,14,13,12,11,10,9,8,7,6,5,4]]</span><span>
</span><span id="line-290"></span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#mkDecoderRelPos%27"><span class="hs-identifier hs-type">mkDecoderRelPos'</span></a></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">[</span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">]</span><span class="hs-special">]</span><span>
</span><span id="line-291"></span><span id="mkDecoderRelPos%27"><span class="annot"><span class="annottext">mkDecoderRelPos' :: Int -&gt; Int -&gt; Int -&gt; Int -&gt; [[Int]]
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#mkDecoderRelPos%27"><span class="hs-identifier hs-var hs-var">mkDecoderRelPos'</span></a></span></span><span> </span><span id="local-6989586621679571830"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679571830"><span class="hs-identifier hs-var">numBuckets</span></a></span></span><span> </span><span id="local-6989586621679571829"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679571829"><span class="hs-identifier hs-var">maxDistance</span></a></span></span><span> </span><span id="local-6989586621679571828"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679571828"><span class="hs-identifier hs-var">querySize</span></a></span></span><span> </span><span id="local-6989586621679571827"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679571827"><span class="hs-identifier hs-var">keySize</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-292"></span><span>  </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679571826"><span class="annot"><span class="annottext">queryPos :: [Int]
</span><a href="#local-6989586621679571826"><span class="hs-identifier hs-var hs-var">queryPos</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">0</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">1</span></span><span> </span><span class="hs-glyph">..</span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679571828"><span class="hs-identifier hs-var">querySize</span></a></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Int
forall a. Num a =&gt; a -&gt; a -&gt; a
</span><span class="hs-glyph hs-var">-</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">1</span></span><span class="hs-special">]</span><span>
</span><span id="line-293"></span><span>      </span><span id="local-6989586621679571825"><span class="annot"><span class="annottext">keyPos :: [Int]
</span><a href="#local-6989586621679571825"><span class="hs-identifier hs-var hs-var">keyPos</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">0</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">1</span></span><span> </span><span class="hs-glyph">..</span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679571827"><span class="hs-identifier hs-var">keySize</span></a></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Int
forall a. Num a =&gt; a -&gt; a -&gt; a
</span><span class="hs-glyph hs-var">-</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">1</span></span><span class="hs-special">]</span><span>
</span><span id="line-294"></span><span>      </span><span id="local-6989586621679571824"><span class="annot"><span class="annottext">maxExact :: Int
</span><a href="#local-6989586621679571824"><span class="hs-identifier hs-var hs-var">maxExact</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679571830"><span class="hs-identifier hs-var">numBuckets</span></a></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Int
forall a. Integral a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">`div`</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">2</span></span><span>
</span><span id="line-295"></span><span>   </span><span class="hs-keyword">in</span><span> </span><span class="annot"><span class="annottext">(Int -&gt; [Int]) -&gt; [Int] -&gt; [[Int]]
forall (f :: * -&gt; *) a b. Functor f =&gt; (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-identifier hs-var">fmap</span></span><span>
</span><span id="line-296"></span><span>        </span><span class="hs-special">(</span><span> </span><span class="hs-glyph">\</span><span id="local-6989586621679571823"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679571823"><span class="hs-identifier hs-var">qp</span></a></span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-297"></span><span>            </span><span class="annot"><span class="annottext">(Int -&gt; Int) -&gt; [Int] -&gt; [Int]
forall (f :: * -&gt; *) a b. Functor f =&gt; (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-identifier hs-var">fmap</span></span><span>
</span><span id="line-298"></span><span>              </span><span class="hs-special">(</span><span> </span><span class="hs-glyph">\</span><span id="local-6989586621679571822"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679571822"><span class="hs-identifier hs-var">kp</span></a></span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-299"></span><span>                  </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679571821"><span class="annot"><span class="annottext">rawRelPos :: Int
</span><a href="#local-6989586621679571821"><span class="hs-identifier hs-var hs-var">rawRelPos</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679571822"><span class="hs-identifier hs-var">kp</span></a></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Int
forall a. Num a =&gt; a -&gt; a -&gt; a
</span><span class="hs-glyph hs-var">-</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679571823"><span class="hs-identifier hs-var">qp</span></a></span><span>
</span><span id="line-300"></span><span>                      </span><span id="local-6989586621679571820"><span class="annot"><span class="annottext">absRelPos :: Int
</span><a href="#local-6989586621679571820"><span class="hs-identifier hs-var hs-var">absRelPos</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int
forall a. Num a =&gt; a -&gt; a
</span><span class="hs-identifier hs-var">negate</span></span><span> </span><span class="annot"><span class="annottext">(Int -&gt; Int) -&gt; (Int -&gt; Int) -&gt; Int -&gt; Int
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Int
forall a. Ord a =&gt; a -&gt; a -&gt; a
</span><span class="hs-identifier hs-var">min</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">0</span></span><span> </span><span class="annot"><span class="annottext">(Int -&gt; Int) -&gt; Int -&gt; Int
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679571821"><span class="hs-identifier hs-var">rawRelPos</span></a></span><span>
</span><span id="line-301"></span><span>                      </span><span id="local-6989586621679571819"><span class="annot"><span class="annottext">relBucket' :: Int
</span><a href="#local-6989586621679571819"><span class="hs-identifier hs-var hs-var">relBucket'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-302"></span><span>                        </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679571818"><span class="annot"><span class="annottext">isSmall :: Bool
</span><a href="#local-6989586621679571818"><span class="hs-identifier hs-var hs-var">isSmall</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679571820"><span class="hs-identifier hs-var">absRelPos</span></a></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Bool
forall a. Ord a =&gt; a -&gt; a -&gt; Bool
</span><span class="hs-operator hs-var">&lt;</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679571824"><span class="hs-identifier hs-var">maxExact</span></a></span><span>
</span><span id="line-303"></span><span>                            </span><span id="local-6989586621679571817"><span class="annot"><span class="annottext">relPosIfLarge :: Int
</span><a href="#local-6989586621679571817"><span class="hs-identifier hs-var hs-var">relPosIfLarge</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-304"></span><span>                              </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679571824"><span class="hs-identifier hs-var">maxExact</span></a></span><span>
</span><span id="line-305"></span><span>                                </span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Int
forall a. Num a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">+</span></span><span> </span><span class="annot"><span class="annottext">Double -&gt; Int
</span><span class="hs-identifier hs-var">double2Int</span></span><span>
</span><span id="line-306"></span><span>                                  </span><span class="hs-special">(</span><span> </span><span class="annot"><span class="annottext">Double -&gt; Double -&gt; Double
forall a. Floating a =&gt; a -&gt; a -&gt; a
</span><span class="hs-identifier hs-var">logBase</span></span><span>
</span><span id="line-307"></span><span>                                      </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Int -&gt; Double
forall a b. (Integral a, Num b) =&gt; a -&gt; b
</span><span class="hs-identifier hs-var">fromIntegral</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679571829"><span class="hs-identifier hs-var">maxDistance</span></a></span><span> </span><span class="annot"><span class="annottext">Double -&gt; Double -&gt; Double
forall a. Fractional a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">/</span></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Double
forall a b. (Integral a, Num b) =&gt; a -&gt; b
</span><span class="hs-identifier hs-var">fromIntegral</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679571824"><span class="hs-identifier hs-var">maxExact</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-308"></span><span>                                      </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Int -&gt; Double
forall a b. (Integral a, Num b) =&gt; a -&gt; b
</span><span class="hs-identifier hs-var">fromIntegral</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679571820"><span class="hs-identifier hs-var">absRelPos</span></a></span><span> </span><span class="annot"><span class="annottext">Double -&gt; Double -&gt; Double
forall a. Fractional a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">/</span></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Double
forall a b. (Integral a, Num b) =&gt; a -&gt; b
</span><span class="hs-identifier hs-var">fromIntegral</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679571824"><span class="hs-identifier hs-var">maxExact</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-309"></span><span>                                      </span><span class="annot"><span class="annottext">Double -&gt; Double -&gt; Double
forall a. Num a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">*</span></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Double
forall a b. (Integral a, Num b) =&gt; a -&gt; b
</span><span class="hs-identifier hs-var">fromIntegral</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679571830"><span class="hs-identifier hs-var">numBuckets</span></a></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Int
forall a. Num a =&gt; a -&gt; a -&gt; a
</span><span class="hs-glyph hs-var">-</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679571824"><span class="hs-identifier hs-var">maxExact</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-310"></span><span>                                  </span><span class="hs-special">)</span><span>
</span><span id="line-311"></span><span>                            </span><span id="local-6989586621679571816"><span class="annot"><span class="annottext">relPosIfLarge' :: Int
</span><a href="#local-6989586621679571816"><span class="hs-identifier hs-var hs-var">relPosIfLarge'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Int
forall a. Ord a =&gt; a -&gt; a -&gt; a
</span><span class="hs-identifier hs-var">min</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679571817"><span class="hs-identifier hs-var">relPosIfLarge</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679571830"><span class="hs-identifier hs-var">numBuckets</span></a></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Int
forall a. Num a =&gt; a -&gt; a -&gt; a
</span><span class="hs-glyph hs-var">-</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">1</span></span><span class="hs-special">)</span><span>
</span><span id="line-312"></span><span>                         </span><span class="hs-keyword">in</span><span> </span><span class="hs-keyword">if</span><span> </span><span class="annot"><span class="annottext">Bool
</span><a href="#local-6989586621679571818"><span class="hs-identifier hs-var">isSmall</span></a></span><span> </span><span class="hs-keyword">then</span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679571820"><span class="hs-identifier hs-var">absRelPos</span></a></span><span> </span><span class="hs-keyword">else</span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679571816"><span class="hs-identifier hs-var">relPosIfLarge'</span></a></span><span>
</span><span id="line-313"></span><span>                   </span><span class="hs-keyword">in</span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679571819"><span class="hs-identifier hs-var">relBucket'</span></a></span><span>
</span><span id="line-314"></span><span>              </span><span class="hs-special">)</span><span>
</span><span id="line-315"></span><span>              </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679571825"><span class="hs-identifier hs-var">keyPos</span></a></span><span>
</span><span id="line-316"></span><span>        </span><span class="hs-special">)</span><span>
</span><span id="line-317"></span><span>        </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679571826"><span class="hs-identifier hs-var">queryPos</span></a></span><span>
</span><span id="line-318"></span><span>
</span><span id="line-319"></span><span class="hs-comment">-- | Computes relative positions of the input tokens to the decoder.</span><span>
</span><span id="line-320"></span><span class="hs-comment">-- Given an input tensor of shape @[batchDim, Dim seqName seqSize]@,</span><span>
</span><span id="line-321"></span><span class="hs-comment">-- returns a tensor of shape @[1, Dim &quot;*&quot; seqSize, Dim &quot;*&quot; seqSize]@.</span><span>
</span><span id="line-322"></span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#mkDecoderRelPos"><span class="hs-identifier hs-type">mkDecoderRelPos</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-323"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679571814"><span class="annot"><a href="#local-6989586621679571814"><span class="hs-identifier hs-type">m</span></a></span></span><span> </span><span id="local-6989586621679571813"><span class="annot"><a href="#local-6989586621679571813"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679571812"><span class="annot"><a href="#local-6989586621679571812"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679571811"><span class="annot"><a href="#local-6989586621679571811"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679571810"><span class="annot"><a href="#local-6989586621679571810"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679571809"><span class="annot"><a href="#local-6989586621679571809"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679571808"><span class="annot"><a href="#local-6989586621679571808"><span class="hs-identifier hs-type">relPosEncBucketDim</span></a></span></span><span> </span><span id="local-6989586621679571807"><span class="annot"><a href="#local-6989586621679571807"><span class="hs-identifier hs-type">seqDim</span></a></span></span><span> </span><span id="local-6989586621679571806"><span class="annot"><a href="#local-6989586621679571806"><span class="hs-identifier hs-type">seqName</span></a></span></span><span> </span><span id="local-6989586621679571805"><span class="annot"><a href="#local-6989586621679571805"><span class="hs-identifier hs-type">seqSize</span></a></span></span><span> </span><span id="local-6989586621679571804"><span class="annot"><a href="#local-6989586621679571804"><span class="hs-identifier hs-type">output</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-324"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier hs-type">MonadThrow</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571814"><span class="hs-identifier hs-type">m</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-325"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkRelPosC"><span class="hs-identifier hs-type">MkRelPosC</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571811"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571809"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571807"><span class="hs-identifier hs-type">seqDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571806"><span class="hs-identifier hs-type">seqName</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571805"><span class="hs-identifier hs-type">seqSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571804"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-326"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-327"></span><span>  </span><span class="hs-comment">-- | bucket dimension</span><span>
</span><span id="line-328"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571808"><span class="hs-identifier hs-type">relPosEncBucketDim</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-329"></span><span>  </span><span class="hs-comment">-- | maximum distance</span><span>
</span><span id="line-330"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-331"></span><span>  </span><span class="hs-comment">-- | decoder input tensor</span><span>
</span><span id="line-332"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571813"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571812"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571811"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571810"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571809"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-333"></span><span>  </span><span class="hs-comment">-- | relative positions of the input tokens</span><span>
</span><span id="line-334"></span><span>  </span><span class="annot"><a href="#local-6989586621679571814"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571804"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-335"></span><span id="mkDecoderRelPos"><span class="annot"><span class="annottext">mkDecoderRelPos :: SDim relPosEncBucketDim
-&gt; Int -&gt; Tensor gradient layout device dataType shape -&gt; m output
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#mkDecoderRelPos"><span class="hs-identifier hs-var hs-var">mkDecoderRelPos</span></a></span></span><span> </span><span id="local-6989586621679571803"><span class="annot"><span class="annottext">SDim relPosEncBucketDim
</span><a href="#local-6989586621679571803"><span class="hs-identifier hs-var">relPosEncBucketDim</span></a></span></span><span> </span><span id="local-6989586621679571802"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679571802"><span class="hs-identifier hs-var">maxDistance</span></a></span></span><span> </span><span id="local-6989586621679571801"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679571801"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-336"></span><span>  </span><span id="local-6989586621679571800"><span class="annot"><span class="annottext">SDim ('Dim seqName seqSize)
</span><a href="#local-6989586621679571800"><span class="hs-identifier hs-var">seqDim</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">SSelectDim ('SelectDim ('ByIndex 1))
-&gt; SShape shape -&gt; m (SDim ('Dim seqName seqSize))
forall (selectDim :: SelectDim (By Symbol Nat))
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (dim :: Dim (Name Symbol) (Size Nat)) (m :: * -&gt; *).
(dim ~ GetDimF selectDim shape, MonadThrow m) =&gt;
SSelectDim selectDim -&gt; SShape shape -&gt; m (SDim dim)
</span><a href="Torch.GraduallyTyped.Shape.Class.html#sGetDimFromShape"><span class="hs-identifier hs-var">sGetDimFromShape</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SBy ('ByIndex 1) -&gt; SSelectDim ('SelectDim ('ByIndex 1))
forall (by :: By Symbol Nat). SBy by -&gt; SSelectDim ('SelectDim by)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSelectDim"><span class="hs-identifier hs-var">SSelectDim</span></a></span><span> </span><span class="annot"><span class="annottext">(SBy ('ByIndex 1) -&gt; SSelectDim ('SelectDim ('ByIndex 1)))
-&gt; SBy ('ByIndex 1) -&gt; SSelectDim ('SelectDim ('ByIndex 1))
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">KnownNat 1 =&gt; SBy ('ByIndex 1)
forall (index :: Nat). KnownNat index =&gt; SBy ('ByIndex index)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SByIndex"><span class="hs-identifier hs-var">SByIndex</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">(SShape shape -&gt; m (SDim ('Dim seqName seqSize)))
-&gt; SShape shape -&gt; m (SDim ('Dim seqName seqSize))
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape -&gt; SShape shape
forall (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType).
SGetShape shape =&gt;
Tensor gradient layout device dataType shape -&gt; SShape shape
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sGetShape"><span class="hs-identifier hs-var">sGetShape</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679571801"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-337"></span><span>  </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679571799"><span class="annot"><span class="annottext">seqSize :: Int
</span><a href="#local-6989586621679571799"><span class="hs-identifier hs-var hs-var">seqSize</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Integer -&gt; Int
forall a. Num a =&gt; Integer -&gt; a
</span><span class="hs-identifier hs-var">fromInteger</span></span><span> </span><span class="annot"><span class="annottext">(Integer -&gt; Int)
-&gt; (SSize seqSize -&gt; Integer) -&gt; SSize seqSize -&gt; Int
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">IsChecked Integer -&gt; Integer
forall a. IsChecked a -&gt; a
</span><a href="Torch.GraduallyTyped.Prelude.html#forgetIsChecked"><span class="hs-identifier hs-var">forgetIsChecked</span></a></span><span> </span><span class="annot"><span class="annottext">(IsChecked Integer -&gt; Integer)
-&gt; (SSize seqSize -&gt; IsChecked Integer) -&gt; SSize seqSize -&gt; Integer
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">SSize seqSize -&gt; IsChecked Integer
forall k (a :: k). SingKind k =&gt; Sing a -&gt; Demote k
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">fromSing</span></a></span><span> </span><span class="annot"><span class="annottext">(SSize seqSize -&gt; Int) -&gt; SSize seqSize -&gt; Int
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim seqName seqSize) -&gt; SSize seqSize
forall (name :: Name Symbol) (size :: Size Nat).
SDim ('Dim name size) -&gt; SSize size
</span><a href="Torch.GraduallyTyped.Shape.Type.html#sDimSize"><span class="hs-identifier hs-var hs-var">sDimSize</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim seqName seqSize)
</span><a href="#local-6989586621679571800"><span class="hs-identifier hs-var">seqDim</span></a></span><span>
</span><span id="line-338"></span><span>  </span><span class="annot"><span class="annottext">SGradient ('Gradient 'WithoutGradient)
-&gt; SLayout ('Layout 'Dense)
-&gt; SDevice device
-&gt; [[[Int]]]
-&gt; m (Tensor
        ('Gradient 'WithoutGradient)
        ('Layout 'Dense)
        device
        ('DataType 'Int64)
        ('Shape
           '[ 'Dim ('Name &quot;*&quot;) 'UncheckedSize,
              'Dim ('Name &quot;*&quot;) 'UncheckedSize, 'Dim ('Name &quot;*&quot;) 'UncheckedSize]))
forall a (dType :: DType) (dims :: [Dim (Name Symbol) (Size Nat)])
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (m :: * -&gt; *).
(TensorLike a dType dims, MonadThrow m) =&gt;
SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; a
-&gt; m (Tensor
        gradient layout device ('DataType dType) ('Shape dims))
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sToTensor"><span class="hs-identifier hs-var">sToTensor</span></a></span><span> </span><span class="annot"><span class="annottext">SGradient ('Gradient 'WithoutGradient)
</span><a href="#local-6989586621679571798"><span class="hs-identifier hs-var">gradient'</span></a></span><span> </span><span class="annot"><span class="annottext">SLayout ('Layout 'Dense)
</span><a href="#local-6989586621679571797"><span class="hs-identifier hs-var">layout'</span></a></span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679571796"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="hs-special">[</span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Int -&gt; Int -&gt; [[Int]]
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#mkDecoderRelPos%27"><span class="hs-identifier hs-var">mkDecoderRelPos'</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679571795"><span class="hs-identifier hs-var">relPosEncBucketSize</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679571802"><span class="hs-identifier hs-var">maxDistance</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679571799"><span class="hs-identifier hs-var">seqSize</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679571799"><span class="hs-identifier hs-var">seqSize</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-339"></span><span>    </span><span class="annot"><span class="annottext">m (Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     device
     ('DataType 'Int64)
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) 'UncheckedSize,
           'Dim ('Name &quot;*&quot;) 'UncheckedSize, 'Dim ('Name &quot;*&quot;) 'UncheckedSize]))
-&gt; (Tensor
      ('Gradient 'WithoutGradient)
      ('Layout 'Dense)
      device
      ('DataType 'Int64)
      ('Shape
         '[ 'Dim ('Name &quot;*&quot;) 'UncheckedSize,
            'Dim ('Name &quot;*&quot;) 'UncheckedSize, 'Dim ('Name &quot;*&quot;) 'UncheckedSize])
    -&gt; m output)
-&gt; m output
forall (m :: * -&gt; *) a b. Monad m =&gt; m a -&gt; (a -&gt; m b) -&gt; m b
</span><span class="hs-operator hs-var">&gt;&gt;=</span></span><span> </span><span class="annot"><span class="annottext">SShape
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) seqSize,
        'Dim ('Name &quot;*&quot;) seqSize])
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     device
     ('DataType 'Int64)
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) 'UncheckedSize,
           'Dim ('Name &quot;*&quot;) 'UncheckedSize, 'Dim ('Name &quot;*&quot;) 'UncheckedSize])
-&gt; m (Tensor
        ('Gradient 'WithoutGradient)
        ('Layout 'Dense)
        device
        ('DataType 'Int64)
        (Seq
           ('Shape
              '[ 'Dim ('Name &quot;*&quot;) 'UncheckedSize,
                 'Dim ('Name &quot;*&quot;) 'UncheckedSize, 'Dim ('Name &quot;*&quot;) 'UncheckedSize]
            &lt;+&gt; 'Shape
                  '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) seqSize,
                     'Dim ('Name &quot;*&quot;) seqSize])
           ('Shape
              '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) seqSize,
                 'Dim ('Name &quot;*&quot;) seqSize])))
forall (shape' :: Shape [Dim (Name Symbol) (Size Nat)])
       (m :: * -&gt; *) (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
(SGetShape shape, MonadThrow m) =&gt;
SShape shape'
-&gt; Tensor gradient layout device dataType shape
-&gt; m (Tensor
        gradient layout device dataType (Seq (shape &lt;+&gt; shape') shape'))
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sCheckedShape"><span class="hs-identifier hs-var">sCheckedShape</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SList
  '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) seqSize,
     'Dim ('Name &quot;*&quot;) seqSize]
-&gt; SShape
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) seqSize,
           'Dim ('Name &quot;*&quot;) seqSize])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList
   '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) seqSize,
      'Dim ('Name &quot;*&quot;) seqSize]
 -&gt; SShape
      ('Shape
         '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) seqSize,
            'Dim ('Name &quot;*&quot;) seqSize]))
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) seqSize,
        'Dim ('Name &quot;*&quot;) seqSize]
-&gt; SShape
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) seqSize,
           'Dim ('Name &quot;*&quot;) seqSize])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize ('Size 1) -&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 1))
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownNat 1 =&gt; SSize ('Size 1)
forall (size :: Nat). KnownNat size =&gt; SSize ('Size size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier hs-var">SSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">1</span></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 1))
-&gt; SList '[ 'Dim ('Name &quot;*&quot;) seqSize, 'Dim ('Name &quot;*&quot;) seqSize]
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) seqSize,
        'Dim ('Name &quot;*&quot;) seqSize]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize seqSize -&gt; SDim ('Dim ('Name &quot;*&quot;) seqSize)
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim seqName seqSize) -&gt; SSize seqSize
forall (name :: Name Symbol) (size :: Size Nat).
SDim ('Dim name size) -&gt; SSize size
</span><a href="Torch.GraduallyTyped.Shape.Type.html#sDimSize"><span class="hs-identifier hs-var hs-var">sDimSize</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim seqName seqSize)
</span><a href="#local-6989586621679571800"><span class="hs-identifier hs-var">seqDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) seqSize)
-&gt; SList '[ 'Dim ('Name &quot;*&quot;) seqSize]
-&gt; SList '[ 'Dim ('Name &quot;*&quot;) seqSize, 'Dim ('Name &quot;*&quot;) seqSize]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize seqSize -&gt; SDim ('Dim ('Name &quot;*&quot;) seqSize)
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim seqName seqSize) -&gt; SSize seqSize
forall (name :: Name Symbol) (size :: Size Nat).
SDim ('Dim name size) -&gt; SSize size
</span><a href="Torch.GraduallyTyped.Shape.Type.html#sDimSize"><span class="hs-identifier hs-var hs-var">sDimSize</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim seqName seqSize)
</span><a href="#local-6989586621679571800"><span class="hs-identifier hs-var">seqDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) seqSize)
-&gt; SList '[] -&gt; SList '[ 'Dim ('Name &quot;*&quot;) seqSize]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-340"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-341"></span><span>    </span><span id="local-6989586621679571798"><span class="annot"><span class="annottext">gradient' :: SGradient ('Gradient 'WithoutGradient)
</span><a href="#local-6989586621679571798"><span class="hs-identifier hs-var hs-var">gradient'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SRequiresGradient 'WithoutGradient
-&gt; SGradient ('Gradient 'WithoutGradient)
forall (requiresGradient :: RequiresGradient).
SRequiresGradient requiresGradient
-&gt; SGradient ('Gradient requiresGradient)
</span><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier hs-var">SGradient</span></a></span><span> </span><span class="annot"><span class="annottext">SRequiresGradient 'WithoutGradient
</span><a href="Torch.GraduallyTyped.RequiresGradient.html#SWithoutGradient"><span class="hs-identifier hs-var">SWithoutGradient</span></a></span><span>
</span><span id="line-342"></span><span>    </span><span id="local-6989586621679571797"><span class="annot"><span class="annottext">layout' :: SLayout ('Layout 'Dense)
</span><a href="#local-6989586621679571797"><span class="hs-identifier hs-var hs-var">layout'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SLayoutType 'Dense -&gt; SLayout ('Layout 'Dense)
forall (layoutType :: LayoutType).
SLayoutType layoutType -&gt; SLayout ('Layout layoutType)
</span><a href="Torch.GraduallyTyped.Layout.html#SLayout"><span class="hs-identifier hs-var">SLayout</span></a></span><span> </span><span class="annot"><span class="annottext">SLayoutType 'Dense
</span><a href="Torch.GraduallyTyped.Layout.html#SDense"><span class="hs-identifier hs-var">SDense</span></a></span><span>
</span><span id="line-343"></span><span>    </span><span id="local-6989586621679571796"><span class="annot"><span class="annottext">device :: SDevice device
</span><a href="#local-6989586621679571796"><span class="hs-identifier hs-var hs-var">device</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape -&gt; SDevice device
forall (device :: Device (DeviceType Nat))
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SGetDevice device =&gt;
Tensor gradient layout device dataType shape -&gt; SDevice device
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sGetDevice"><span class="hs-identifier hs-var">sGetDevice</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679571801"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-344"></span><span>    </span><span id="local-6989586621679571795"><span class="annot"><span class="annottext">relPosEncBucketSize :: Int
</span><a href="#local-6989586621679571795"><span class="hs-identifier hs-var hs-var">relPosEncBucketSize</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Integer -&gt; Int
forall a. Num a =&gt; Integer -&gt; a
</span><span class="hs-identifier hs-var">fromInteger</span></span><span> </span><span class="annot"><span class="annottext">(Integer -&gt; Int)
-&gt; (SDim relPosEncBucketDim -&gt; Integer)
-&gt; SDim relPosEncBucketDim
-&gt; Int
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">IsChecked Integer -&gt; Integer
forall a. IsChecked a -&gt; a
</span><a href="Torch.GraduallyTyped.Prelude.html#forgetIsChecked"><span class="hs-identifier hs-var">forgetIsChecked</span></a></span><span> </span><span class="annot"><span class="annottext">(IsChecked Integer -&gt; Integer)
-&gt; (SDim relPosEncBucketDim -&gt; IsChecked Integer)
-&gt; SDim relPosEncBucketDim
-&gt; Integer
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Dim (IsChecked String) (IsChecked Integer) -&gt; IsChecked Integer
forall name size. Dim name size -&gt; size
</span><a href="Torch.GraduallyTyped.Shape.Type.html#dimSize"><span class="hs-identifier hs-var hs-var">dimSize</span></a></span><span> </span><span class="annot"><span class="annottext">(Dim (IsChecked String) (IsChecked Integer) -&gt; IsChecked Integer)
-&gt; (SDim relPosEncBucketDim
    -&gt; Dim (IsChecked String) (IsChecked Integer))
-&gt; SDim relPosEncBucketDim
-&gt; IsChecked Integer
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">SDim relPosEncBucketDim
-&gt; Dim (IsChecked String) (IsChecked Integer)
forall k (a :: k). SingKind k =&gt; Sing a -&gt; Demote k
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">fromSing</span></a></span><span> </span><span class="annot"><span class="annottext">(SDim relPosEncBucketDim -&gt; Int) -&gt; SDim relPosEncBucketDim -&gt; Int
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SDim relPosEncBucketDim
</span><a href="#local-6989586621679571803"><span class="hs-identifier hs-var">relPosEncBucketDim</span></a></span><span>
</span><span id="line-345"></span><span>
</span><span id="line-346"></span><span class="hs-keyword">data</span><span> </span><span id="MkRelPos"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkRelPos"><span class="hs-identifier hs-var">MkRelPos</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679571794"><span class="annot"><a href="#local-6989586621679571794"><span class="hs-identifier hs-type">relPosEncBucketDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-347"></span><span>  </span><span id="MkRelPos"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkRelPos"><span class="hs-identifier hs-var">MkRelPos</span></a></span></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-348"></span><span>    </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679572343"><span class="annot"><a href="#local-6989586621679572343"><span class="hs-identifier hs-type">relPosEncBucketDim</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-349"></span><span>    </span><span class="hs-special">{</span><span> </span><span id="relPosEncBucketDim"><span class="annot"><span class="annottext">MkRelPos relPosEncBucketDim -&gt; SDim relPosEncBucketDim
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#relPosEncBucketDim"><span class="hs-identifier hs-var hs-var">relPosEncBucketDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679572343"><span class="hs-identifier hs-type">relPosEncBucketDim</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-350"></span><span>      </span><span id="relPosMaxDistance"><span class="annot"><span class="annottext">MkRelPos relPosEncBucketDim -&gt; Int
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#relPosMaxDistance"><span class="hs-identifier hs-var hs-var">relPosMaxDistance</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span>
</span><span id="line-351"></span><span>    </span><span class="hs-special">}</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-352"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkRelPos"><span class="hs-identifier hs-type">MkRelPos</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679572343"><span class="hs-identifier hs-type">relPosEncBucketDim</span></a></span><span>
</span><span id="line-353"></span><span>  </span><span id="MkDecoderRelPos"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkDecoderRelPos"><span class="hs-identifier hs-var">MkDecoderRelPos</span></a></span></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-354"></span><span>    </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679571789"><span class="annot"><a href="#local-6989586621679571789"><span class="hs-identifier hs-type">relPosEncBucketDim</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-355"></span><span>    </span><span class="hs-special">{</span><span> </span><span id="decoderRelPosEncBucketDim"><span class="annot"><span class="annottext">MkRelPos relPosEncBucketDim -&gt; SDim relPosEncBucketDim
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#decoderRelPosEncBucketDim"><span class="hs-identifier hs-var hs-var">decoderRelPosEncBucketDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571789"><span class="hs-identifier hs-type">relPosEncBucketDim</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-356"></span><span>      </span><span id="decoderRelPosMaxDistance"><span class="annot"><span class="annottext">MkRelPos relPosEncBucketDim -&gt; Int
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#decoderRelPosMaxDistance"><span class="hs-identifier hs-var hs-var">decoderRelPosMaxDistance</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span>
</span><span id="line-357"></span><span>    </span><span class="hs-special">}</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-358"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkRelPos"><span class="hs-identifier hs-type">MkRelPos</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571789"><span class="hs-identifier hs-type">relPosEncBucketDim</span></a></span><span>
</span><span id="line-359"></span><span>
</span><span id="line-360"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">instance</span><span> </span><span id="ModelSpec"><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier hs-var">ModelSpec</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkRelPos"><span class="hs-identifier hs-type">MkRelPos</span></a></span><span> </span><span id="local-6989586621679571786"><span class="annot"><a href="#local-6989586621679571786"><span class="hs-identifier hs-type hs-type">relPosEncBucketDim</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkRelPos"><span class="hs-identifier hs-type">MkRelPos</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571786"><span class="hs-identifier hs-type">relPosEncBucketDim</span></a></span><span>
</span><span id="line-361"></span><span>
</span><span id="line-362"></span><span id="local-6989586621679571784"><span id="local-6989586621679571785"><span class="hs-keyword">instance</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkRelPos"><span class="hs-identifier hs-type">MkRelPos</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571785"><span class="hs-identifier hs-type">relPosEncBucketDim</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679571784"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkRelPos"><span class="hs-identifier hs-type">MkRelPos</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571785"><span class="hs-identifier hs-type">relPosEncBucketDim</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679571784"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-363"></span><span>  </span><span id="local-6989586621679571782"><span class="annot"><span class="annottext">initialize :: ModelSpec (MkRelPos relPosEncBucketDim)
-&gt; Generator generatorDevice
-&gt; m (MkRelPos relPosEncBucketDim, Generator generatorDevice)
</span><a href="#local-6989586621679571782"><span class="hs-identifier hs-var hs-var hs-var hs-var">initialize</span></a></span></span><span> </span><span id="local-6989586621679571781"><span class="annot"><span class="annottext">ModelSpec (MkRelPos relPosEncBucketDim)
</span><a href="#local-6989586621679571781"><span class="hs-identifier hs-var">spec</span></a></span></span><span> </span><span id="local-6989586621679571780"><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679571780"><span class="hs-identifier hs-var">g</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(MkRelPos relPosEncBucketDim, Generator generatorDevice)
-&gt; m (MkRelPos relPosEncBucketDim, Generator generatorDevice)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">ModelSpec (MkRelPos relPosEncBucketDim)
MkRelPos relPosEncBucketDim
</span><a href="#local-6989586621679571781"><span class="hs-identifier hs-var">spec</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679571780"><span class="hs-identifier hs-var">g</span></a></span><span class="hs-special">)</span></span></span><span>
</span><span id="line-364"></span><span>
</span><span id="line-365"></span><span id="local-6989586621679571779"><span class="hs-keyword">instance</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasStateDict"><span class="hs-identifier hs-type">HasStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkRelPos"><span class="hs-identifier hs-type">MkRelPos</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571779"><span class="hs-identifier hs-type">relPosEncBucketDim</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-366"></span><span>  </span><span id="local-6989586621679571776"><span class="annot"><span class="annottext">fromStateDict :: ModelSpec (MkRelPos relPosEncBucketDim)
-&gt; StateDictKey -&gt; m (MkRelPos relPosEncBucketDim)
</span><a href="#local-6989586621679571776"><span class="hs-identifier hs-var hs-var hs-var hs-var">fromStateDict</span></a></span></span><span> </span><span id="local-6989586621679571775"><span class="annot"><span class="annottext">ModelSpec (MkRelPos relPosEncBucketDim)
</span><a href="#local-6989586621679571775"><span class="hs-identifier hs-var">spec</span></a></span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">MkRelPos relPosEncBucketDim -&gt; m (MkRelPos relPosEncBucketDim)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">ModelSpec (MkRelPos relPosEncBucketDim)
MkRelPos relPosEncBucketDim
</span><a href="#local-6989586621679571775"><span class="hs-identifier hs-var">spec</span></a></span><span>
</span><span id="line-367"></span><span>  </span><span id="local-6989586621679571774"><span class="annot"><span class="annottext">toStateDict :: StateDictKey -&gt; MkRelPos relPosEncBucketDim -&gt; m ()
</span><a href="#local-6989586621679571774"><span class="hs-identifier hs-var hs-var hs-var hs-var">toStateDict</span></a></span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="annottext">MkRelPos relPosEncBucketDim
</span><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">() -&gt; m ()
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span></span><span>
</span><span id="line-368"></span><span>
</span><span id="line-369"></span><span id="local-6989586621679571763"><span id="local-6989586621679571764"><span id="local-6989586621679571765"><span id="local-6989586621679571766"><span id="local-6989586621679571767"><span id="local-6989586621679571768"><span id="local-6989586621679571769"><span id="local-6989586621679571770"><span id="local-6989586621679571771"><span id="local-6989586621679571772"><span id="local-6989586621679571773"><span class="hs-keyword">instance</span><span>
</span><span id="line-370"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkRelPosC"><span class="hs-identifier hs-type">MkRelPosC</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571773"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571772"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571771"><span class="hs-identifier hs-type">seqDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571770"><span class="hs-identifier hs-type">seqName</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571769"><span class="hs-identifier hs-type">seqSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571768"><span class="hs-identifier hs-type">output</span></a></span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-371"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-372"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkRelPos"><span class="hs-identifier hs-type">MkRelPos</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571767"><span class="hs-identifier hs-type">relPosEncBucketDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-373"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571766"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571765"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571773"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571764"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571772"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-374"></span><span>    </span><span class="annot"><a href="#local-6989586621679571763"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-375"></span><span>    </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-376"></span><span>        </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#WithoutGradient"><span class="hs-identifier hs-type">WithoutGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-377"></span><span>        </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Dense"><span class="hs-identifier hs-type">Dense</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-378"></span><span>        </span><span class="annot"><a href="#local-6989586621679571773"><span class="hs-identifier hs-type">device</span></a></span><span>
</span><span id="line-379"></span><span>        </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#Int64"><span class="hs-identifier hs-type">Int64</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-380"></span><span>        </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679571769"><span class="hs-identifier hs-type">seqSize</span></a></span><span class="hs-special">,</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679571769"><span class="hs-identifier hs-type">seqSize</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-381"></span><span>    </span><span class="hs-special">)</span><span>
</span><span id="line-382"></span><span>    </span><span class="annot"><a href="#local-6989586621679571763"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-383"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-384"></span><span>  </span><span id="local-6989586621679571761"><span class="annot"><span class="annottext">forward :: MkRelPos relPosEncBucketDim
-&gt; Tensor gradient layout device dataType shape
-&gt; Generator generatorDevice
-&gt; m (Tensor
        ('Gradient 'WithoutGradient)
        ('Layout 'Dense)
        device
        ('DataType 'Int64)
        ('Shape
           '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) seqSize,
              'Dim ('Name &quot;*&quot;) seqSize]),
      Generator generatorDevice)
</span><a href="#local-6989586621679571761"><span class="hs-identifier hs-var hs-var hs-var hs-var">forward</span></a></span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkRelPos"><span class="hs-identifier hs-type">MkRelPos</span></a></span><span> </span><span class="hs-special">{</span><span id="local-6989586621679571759"><span id="local-6989586621679571760"><span class="annot"><span class="annottext">Int
SDim relPosEncBucketDim
relPosMaxDistance :: Int
relPosEncBucketDim :: SDim relPosEncBucketDim
relPosMaxDistance :: forall (relPosEncBucketDim :: Dim (Name Symbol) (Size Nat)).
MkRelPos relPosEncBucketDim -&gt; Int
relPosEncBucketDim :: forall (relPosEncBucketDim :: Dim (Name Symbol) (Size Nat)).
MkRelPos relPosEncBucketDim -&gt; SDim relPosEncBucketDim
</span><a href="#local-6989586621679571759"><span class="hs-glyph hs-var hs-var hs-var hs-var">..</span></a></span></span></span><span class="hs-special">}</span><span> </span><span id="local-6989586621679571758"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679571758"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span id="local-6989586621679571757"><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679571757"><span class="hs-identifier hs-var">g</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-385"></span><span>    </span><span id="local-6989586621679571756"><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  device
  ('DataType 'Int64)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) seqSize,
        'Dim ('Name &quot;*&quot;) seqSize])
</span><a href="#local-6989586621679571756"><span class="hs-identifier hs-var">relPos</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">SDim relPosEncBucketDim
-&gt; Int
-&gt; Tensor gradient layout device dataType shape
-&gt; m (Tensor
        ('Gradient 'WithoutGradient)
        ('Layout 'Dense)
        device
        ('DataType 'Int64)
        ('Shape
           '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) seqSize,
              'Dim ('Name &quot;*&quot;) seqSize]))
forall (m :: * -&gt; *) (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (relPosEncBucketDim :: Dim (Name Symbol) (Size Nat))
       (seqDim :: Dim (Name Symbol) (Size Nat)) (seqName :: Name Symbol)
       (seqSize :: Size Nat) output.
(MonadThrow m,
 MkRelPosC device shape seqDim seqName seqSize output) =&gt;
SDim relPosEncBucketDim
-&gt; Int -&gt; Tensor gradient layout device dataType shape -&gt; m output
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#mkRelPos"><span class="hs-identifier hs-var">mkRelPos</span></a></span><span> </span><span class="annot"><span class="annottext">SDim relPosEncBucketDim
</span><a href="#local-6989586621679571760"><span class="hs-identifier hs-var">relPosEncBucketDim</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679571759"><span class="hs-identifier hs-var">relPosMaxDistance</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679571758"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-386"></span><span>    </span><span class="annot"><span class="annottext">(Tensor
   ('Gradient 'WithoutGradient)
   ('Layout 'Dense)
   device
   ('DataType 'Int64)
   ('Shape
      '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) seqSize,
         'Dim ('Name &quot;*&quot;) seqSize]),
 Generator generatorDevice)
-&gt; m (Tensor
        ('Gradient 'WithoutGradient)
        ('Layout 'Dense)
        device
        ('DataType 'Int64)
        ('Shape
           '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) seqSize,
              'Dim ('Name &quot;*&quot;) seqSize]),
      Generator generatorDevice)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  device
  ('DataType 'Int64)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) seqSize,
        'Dim ('Name &quot;*&quot;) seqSize])
</span><a href="#local-6989586621679571756"><span class="hs-identifier hs-var">relPos</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679571757"><span class="hs-identifier hs-var">g</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-387"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkDecoderRelPos"><span class="hs-identifier hs-type">MkDecoderRelPos</span></a></span><span> </span><span class="hs-special">{</span><span id="local-6989586621679571754"><span id="local-6989586621679571755"><span class="annot"><span class="annottext">Int
SDim relPosEncBucketDim
decoderRelPosMaxDistance :: Int
decoderRelPosEncBucketDim :: SDim relPosEncBucketDim
decoderRelPosMaxDistance :: forall (relPosEncBucketDim :: Dim (Name Symbol) (Size Nat)).
MkRelPos relPosEncBucketDim -&gt; Int
decoderRelPosEncBucketDim :: forall (relPosEncBucketDim :: Dim (Name Symbol) (Size Nat)).
MkRelPos relPosEncBucketDim -&gt; SDim relPosEncBucketDim
</span><a href="#local-6989586621679571754"><span class="hs-glyph hs-var hs-var hs-var hs-var">..</span></a></span></span></span><span class="hs-special">}</span><span> </span><span id="local-6989586621679571753"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679571753"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span id="local-6989586621679571752"><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679571752"><span class="hs-identifier hs-var">g</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-388"></span><span>    </span><span id="local-6989586621679571751"><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  device
  ('DataType 'Int64)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) seqSize,
        'Dim ('Name &quot;*&quot;) seqSize])
</span><a href="#local-6989586621679571751"><span class="hs-identifier hs-var">decoderRelPos</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">SDim relPosEncBucketDim
-&gt; Int
-&gt; Tensor gradient layout device dataType shape
-&gt; m (Tensor
        ('Gradient 'WithoutGradient)
        ('Layout 'Dense)
        device
        ('DataType 'Int64)
        ('Shape
           '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) seqSize,
              'Dim ('Name &quot;*&quot;) seqSize]))
forall (m :: * -&gt; *) (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (relPosEncBucketDim :: Dim (Name Symbol) (Size Nat))
       (seqDim :: Dim (Name Symbol) (Size Nat)) (seqName :: Name Symbol)
       (seqSize :: Size Nat) output.
(MonadThrow m,
 MkRelPosC device shape seqDim seqName seqSize output) =&gt;
SDim relPosEncBucketDim
-&gt; Int -&gt; Tensor gradient layout device dataType shape -&gt; m output
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#mkDecoderRelPos"><span class="hs-identifier hs-var">mkDecoderRelPos</span></a></span><span> </span><span class="annot"><span class="annottext">SDim relPosEncBucketDim
</span><a href="#local-6989586621679571755"><span class="hs-identifier hs-var">decoderRelPosEncBucketDim</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679571754"><span class="hs-identifier hs-var">decoderRelPosMaxDistance</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679571753"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-389"></span><span>    </span><span class="annot"><span class="annottext">(Tensor
   ('Gradient 'WithoutGradient)
   ('Layout 'Dense)
   device
   ('DataType 'Int64)
   ('Shape
      '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) seqSize,
         'Dim ('Name &quot;*&quot;) seqSize]),
 Generator generatorDevice)
-&gt; m (Tensor
        ('Gradient 'WithoutGradient)
        ('Layout 'Dense)
        device
        ('DataType 'Int64)
        ('Shape
           '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) seqSize,
              'Dim ('Name &quot;*&quot;) seqSize]),
      Generator generatorDevice)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  device
  ('DataType 'Int64)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) seqSize,
        'Dim ('Name &quot;*&quot;) seqSize])
</span><a href="#local-6989586621679571751"><span class="hs-identifier hs-var">decoderRelPos</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679571752"><span class="hs-identifier hs-var">g</span></a></span><span class="hs-special">)</span></span></span></span></span></span></span></span></span></span></span></span><span>
</span><span id="line-390"></span><span>
</span><span id="line-391"></span><span class="hs-keyword">type</span><span> </span><span id="MkTransformerPaddingMaskC"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerPaddingMaskC"><span class="hs-identifier hs-var">MkTransformerPaddingMaskC</span></a></span></span><span> </span><span id="local-6989586621679571750"><span class="annot"><a href="#local-6989586621679571750"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679571749"><span class="annot"><a href="#local-6989586621679571749"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679571748"><span class="annot"><a href="#local-6989586621679571748"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679571747"><span class="annot"><a href="#local-6989586621679571747"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679571746"><span class="annot"><a href="#local-6989586621679571746"><span class="hs-identifier hs-type">output</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-392"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetDevice"><span class="hs-identifier hs-type">SGetDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571749"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-393"></span><span>    </span><span class="annot"><a href="#local-6989586621679571746"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-394"></span><span>      </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-395"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#WithoutGradient"><span class="hs-identifier hs-type">WithoutGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-396"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679571750"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Dense"><span class="hs-identifier hs-type">Dense</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-397"></span><span>          </span><span class="annot"><a href="#local-6989586621679571749"><span class="hs-identifier hs-type">device</span></a></span><span>
</span><span id="line-398"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Seq"><span class="hs-identifier hs-type">Seq</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679571748"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#Int64"><span class="hs-identifier hs-type">Int64</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#Bool"><span class="hs-identifier hs-type">Bool</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-399"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#BroadcastShapesF"><span class="hs-identifier hs-type">BroadcastShapesF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571747"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">]</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-400"></span><span>  </span><span class="hs-special">)</span><span>
</span><span id="line-401"></span><span>
</span><span id="line-402"></span><span class="hs-comment">-- | Computes the padding mask for a transformer.</span><span>
</span><span id="line-403"></span><span class="hs-comment">-- Given an input tensor of shape @[batchDim, Dim seqName seqSize]@,</span><span>
</span><span id="line-404"></span><span class="hs-comment">-- returns a tensor of shape @[batchDim, Dim &quot;*&quot; seqSize]@.</span><span>
</span><span id="line-405"></span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#mkTransformerPaddingMask"><span class="hs-identifier hs-type">mkTransformerPaddingMask</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-406"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679572282"><span class="annot"><a href="#local-6989586621679572282"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679572287"><span class="annot"><a href="#local-6989586621679572287"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679572286"><span class="annot"><a href="#local-6989586621679572286"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679572285"><span class="annot"><a href="#local-6989586621679572285"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679572284"><span class="annot"><a href="#local-6989586621679572284"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679572283"><span class="annot"><a href="#local-6989586621679572283"><span class="hs-identifier hs-type">output</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-407"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerPaddingMaskC"><span class="hs-identifier hs-type">MkTransformerPaddingMaskC</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679572287"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679572286"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679572285"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679572284"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679572283"><span class="hs-identifier hs-type">output</span></a></span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-408"></span><span>  </span><span class="hs-comment">-- | padding token id</span><span>
</span><span id="line-409"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-410"></span><span>  </span><span class="hs-comment">-- | input tensor</span><span>
</span><span id="line-411"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679572282"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679572287"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679572286"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679572285"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679572284"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-412"></span><span>  </span><span class="hs-comment">-- | padding mask</span><span>
</span><span id="line-413"></span><span>  </span><span class="annot"><a href="#local-6989586621679572283"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-414"></span><span id="mkTransformerPaddingMask"><span class="annot"><span class="annottext">mkTransformerPaddingMask :: Int -&gt; Tensor gradient layout device dataType shape -&gt; output
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#mkTransformerPaddingMask"><span class="hs-identifier hs-var hs-var">mkTransformerPaddingMask</span></a></span></span><span> </span><span id="local-6989586621679571744"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679571744"><span class="hs-identifier hs-var">padTokenId</span></a></span></span><span> </span><span id="local-6989586621679571743"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679571743"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-415"></span><span>  </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679571742"><span class="annot"><span class="annottext">device :: SDevice device
</span><a href="#local-6989586621679571742"><span class="hs-identifier hs-var hs-var">device</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape -&gt; SDevice device
forall (device :: Device (DeviceType Nat))
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SGetDevice device =&gt;
Tensor gradient layout device dataType shape -&gt; SDevice device
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sGetDevice"><span class="hs-identifier hs-var">sGetDevice</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679571743"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-416"></span><span>      </span><span id="local-6989586621679571741"><span class="annot"><span class="annottext">padToken :: Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  device
  ('DataType 'Int64)
  ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1)])
</span><a href="#local-6989586621679571741"><span class="hs-identifier hs-var hs-var">padToken</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-417"></span><span>        </span><span class="annot"><span class="annottext">TensorSpec
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  device
  ('DataType 'Int64)
  ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1)])
-&gt; Int
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     device
     ('DataType 'Int64)
     ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1)])
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]) input.
Scalar input =&gt;
TensorSpec gradient layout device dataType shape
-&gt; input -&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.Creation.html#sFull"><span class="hs-identifier hs-var">sFull</span></a></span><span>
</span><span id="line-418"></span><span>          </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SGradient ('Gradient 'WithoutGradient)
-&gt; SLayout ('Layout 'Dense)
-&gt; SDevice device
-&gt; SDataType ('DataType 'Int64)
-&gt; SShape ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1)])
-&gt; TensorSpec
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     device
     ('DataType 'Int64)
     ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1)])
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SShape shape
-&gt; TensorSpec gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorSpec"><span class="hs-identifier hs-var">TensorSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SRequiresGradient 'WithoutGradient
-&gt; SGradient ('Gradient 'WithoutGradient)
forall (requiresGradient :: RequiresGradient).
SRequiresGradient requiresGradient
-&gt; SGradient ('Gradient requiresGradient)
</span><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier hs-var">SGradient</span></a></span><span> </span><span class="annot"><span class="annottext">SRequiresGradient 'WithoutGradient
</span><a href="Torch.GraduallyTyped.RequiresGradient.html#SWithoutGradient"><span class="hs-identifier hs-var">SWithoutGradient</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SLayoutType 'Dense -&gt; SLayout ('Layout 'Dense)
forall (layoutType :: LayoutType).
SLayoutType layoutType -&gt; SLayout ('Layout layoutType)
</span><a href="Torch.GraduallyTyped.Layout.html#SLayout"><span class="hs-identifier hs-var">SLayout</span></a></span><span> </span><span class="annot"><span class="annottext">SLayoutType 'Dense
</span><a href="Torch.GraduallyTyped.Layout.html#SDense"><span class="hs-identifier hs-var">SDense</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679571742"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SDType 'Int64 -&gt; SDataType ('DataType 'Int64)
forall (dType :: DType).
SDType dType -&gt; SDataType ('DataType dType)
</span><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier hs-var">SDataType</span></a></span><span> </span><span class="annot"><span class="annottext">SDType 'Int64
</span><a href="Torch.GraduallyTyped.DType.html#SInt64"><span class="hs-identifier hs-var">SInt64</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SList '[ 'Dim ('Name &quot;*&quot;) ('Size 1)]
-&gt; SShape ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1)])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList '[ 'Dim ('Name &quot;*&quot;) ('Size 1)]
 -&gt; SShape ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1)]))
-&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 1)]
-&gt; SShape ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1)])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize ('Size 1) -&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 1))
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownNat 1 =&gt; SSize ('Size 1)
forall (size :: Nat). KnownNat size =&gt; SSize ('Size size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier hs-var">SSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">1</span></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 1))
-&gt; SList '[] -&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 1)]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-419"></span><span>          </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679571744"><span class="hs-identifier hs-var">padTokenId</span></a></span><span>
</span><span id="line-420"></span><span>   </span><span class="hs-keyword">in</span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679571743"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     device
     ('DataType 'Int64)
     ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1)])
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     (layout &lt;+&gt; 'Layout 'Dense)
     (device &lt;+&gt; device)
     (Seq (dataType &lt;+&gt; 'DataType 'Int64) ('DataType 'Bool))
     (BroadcastShapesF shape ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1)]))
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (gradient' :: Gradient RequiresGradient)
       (layout' :: Layout LayoutType) (device' :: Device (DeviceType Nat))
       (dataType' :: DataType DType)
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]).
Tensor gradient layout device dataType shape
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     (layout &lt;+&gt; layout')
     (device &lt;+&gt; device')
     (Seq (dataType &lt;+&gt; dataType') ('DataType 'Bool))
     (BroadcastShapesF shape shape')
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Comparison.html#%3D%3D."><span class="hs-operator hs-var">==.</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  device
  ('DataType 'Int64)
  ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1)])
</span><a href="#local-6989586621679571741"><span class="hs-identifier hs-var">padToken</span></a></span><span>
</span><span id="line-421"></span><span>
</span><span id="line-422"></span><span class="hs-keyword">newtype</span><span> </span><span id="MkTransformerPaddingMask"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerPaddingMask"><span class="hs-identifier hs-var">MkTransformerPaddingMask</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span id="MkTransformerPaddingMask"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerPaddingMask"><span class="hs-identifier hs-var">MkTransformerPaddingMask</span></a></span></span><span> </span><span class="hs-special">{</span><span id="padTokenId"><span class="annot"><span class="annottext">MkTransformerPaddingMask -&gt; Int
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#padTokenId"><span class="hs-identifier hs-var hs-var">padTokenId</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">}</span><span>
</span><span id="line-423"></span><span>
</span><span id="line-424"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">instance</span><span>
</span><span id="line-425"></span><span>  </span><span id="ModelSpec"><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier hs-var">ModelSpec</span></a></span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerPaddingMask"><span class="hs-identifier hs-type">MkTransformerPaddingMask</span></a></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-426"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerPaddingMask"><span class="hs-identifier hs-type">MkTransformerPaddingMask</span></a></span><span>
</span><span id="line-427"></span><span>
</span><span id="line-428"></span><span id="local-6989586621679571737"><span class="hs-keyword">instance</span><span>
</span><span id="line-429"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span>
</span><span id="line-430"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerPaddingMask"><span class="hs-identifier hs-type">MkTransformerPaddingMask</span></a></span><span>
</span><span id="line-431"></span><span>    </span><span class="annot"><a href="#local-6989586621679571737"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-432"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerPaddingMask"><span class="hs-identifier hs-type">MkTransformerPaddingMask</span></a></span><span>
</span><span id="line-433"></span><span>    </span><span class="annot"><a href="#local-6989586621679571737"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-434"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-435"></span><span>  </span><span id="local-6989586621679571735"><span class="annot"><span class="annottext">initialize :: ModelSpec MkTransformerPaddingMask
-&gt; Generator generatorDevice
-&gt; m (MkTransformerPaddingMask, Generator generatorDevice)
</span><a href="#local-6989586621679571735"><span class="hs-identifier hs-var hs-var hs-var hs-var">initialize</span></a></span></span><span> </span><span id="local-6989586621679571734"><span class="annot"><span class="annottext">ModelSpec MkTransformerPaddingMask
</span><a href="#local-6989586621679571734"><span class="hs-identifier hs-var">spec</span></a></span></span><span> </span><span id="local-6989586621679571733"><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679571733"><span class="hs-identifier hs-var">g</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(MkTransformerPaddingMask, Generator generatorDevice)
-&gt; m (MkTransformerPaddingMask, Generator generatorDevice)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">ModelSpec MkTransformerPaddingMask
MkTransformerPaddingMask
</span><a href="#local-6989586621679571734"><span class="hs-identifier hs-var">spec</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679571733"><span class="hs-identifier hs-var">g</span></a></span><span class="hs-special">)</span></span><span>
</span><span id="line-436"></span><span>
</span><span id="line-437"></span><span class="hs-keyword">instance</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasStateDict"><span class="hs-identifier hs-type">HasStateDict</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerPaddingMask"><span class="hs-identifier hs-type">MkTransformerPaddingMask</span></a></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-438"></span><span>  </span><span id="local-6989586621679571730"><span class="annot"><span class="annottext">fromStateDict :: ModelSpec MkTransformerPaddingMask
-&gt; StateDictKey -&gt; m MkTransformerPaddingMask
</span><a href="#local-6989586621679571730"><span class="hs-identifier hs-var hs-var hs-var hs-var">fromStateDict</span></a></span></span><span> </span><span id="local-6989586621679571729"><span class="annot"><span class="annottext">ModelSpec MkTransformerPaddingMask
</span><a href="#local-6989586621679571729"><span class="hs-identifier hs-var">spec</span></a></span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">MkTransformerPaddingMask -&gt; m MkTransformerPaddingMask
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">ModelSpec MkTransformerPaddingMask
MkTransformerPaddingMask
</span><a href="#local-6989586621679571729"><span class="hs-identifier hs-var">spec</span></a></span><span>
</span><span id="line-439"></span><span>  </span><span id="local-6989586621679571728"><span class="annot"><span class="annottext">toStateDict :: StateDictKey -&gt; MkTransformerPaddingMask -&gt; m ()
</span><a href="#local-6989586621679571728"><span class="hs-identifier hs-var hs-var hs-var hs-var">toStateDict</span></a></span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="annottext">MkTransformerPaddingMask
</span><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">() -&gt; m ()
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-440"></span><span>
</span><span id="line-441"></span><span id="local-6989586621679571721"><span id="local-6989586621679571722"><span id="local-6989586621679571723"><span id="local-6989586621679571724"><span id="local-6989586621679571725"><span id="local-6989586621679571726"><span id="local-6989586621679571727"><span class="hs-keyword">instance</span><span>
</span><span id="line-442"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerPaddingMaskC"><span class="hs-identifier hs-type">MkTransformerPaddingMaskC</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571727"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571726"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571725"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571724"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571723"><span class="hs-identifier hs-type">output</span></a></span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-443"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-444"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerPaddingMask"><span class="hs-identifier hs-type">MkTransformerPaddingMask</span></a></span><span>
</span><span id="line-445"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571722"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571727"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571726"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571725"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571724"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-446"></span><span>    </span><span class="annot"><a href="#local-6989586621679571721"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-447"></span><span>    </span><span class="annot"><a href="#local-6989586621679571723"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-448"></span><span>    </span><span class="annot"><a href="#local-6989586621679571721"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-449"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-450"></span><span>  </span><span id="local-6989586621679571719"><span class="annot"><span class="annottext">forward :: MkTransformerPaddingMask
-&gt; Tensor gradient layout device dataType shape
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorDevice)
</span><a href="#local-6989586621679571719"><span class="hs-identifier hs-var hs-var hs-var hs-var">forward</span></a></span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerPaddingMask"><span class="hs-identifier hs-type">MkTransformerPaddingMask</span></a></span><span> </span><span class="hs-special">{</span><span id="local-6989586621679571718"><span class="annot"><span class="annottext">Int
padTokenId :: Int
padTokenId :: MkTransformerPaddingMask -&gt; Int
</span><a href="#local-6989586621679571718"><span class="hs-glyph hs-var hs-var">..</span></a></span></span><span class="hs-special">}</span><span> </span><span id="local-6989586621679571717"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679571717"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span id="local-6989586621679571716"><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679571716"><span class="hs-identifier hs-var">g</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-451"></span><span>    </span><span class="annot"><span class="annottext">(output, Generator generatorDevice)
-&gt; m (output, Generator generatorDevice)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Int -&gt; Tensor gradient layout device dataType shape -&gt; output
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]) output.
MkTransformerPaddingMaskC layout device dataType shape output =&gt;
Int -&gt; Tensor gradient layout device dataType shape -&gt; output
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#mkTransformerPaddingMask"><span class="hs-identifier hs-var">mkTransformerPaddingMask</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679571718"><span class="hs-identifier hs-var">padTokenId</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679571717"><span class="hs-identifier hs-var">input</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679571716"><span class="hs-identifier hs-var">g</span></a></span><span class="hs-special">)</span></span></span></span></span></span></span></span><span>
</span><span id="line-452"></span><span>
</span><span id="line-453"></span><span class="hs-keyword">type</span><span> </span><span id="MkTransformerAttentionMaskC"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerAttentionMaskC"><span class="hs-identifier hs-var">MkTransformerAttentionMaskC</span></a></span></span><span> </span><span id="local-6989586621679571715"><span class="annot"><a href="#local-6989586621679571715"><span class="hs-identifier hs-type">transformerDataType</span></a></span></span><span> </span><span id="local-6989586621679571714"><span class="annot"><a href="#local-6989586621679571714"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679571713"><span class="annot"><a href="#local-6989586621679571713"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679571712"><span class="annot"><a href="#local-6989586621679571712"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679571711"><span class="annot"><a href="#local-6989586621679571711"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679571710"><span class="annot"><a href="#local-6989586621679571710"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679571709"><span class="annot"><a href="#local-6989586621679571709"><span class="hs-identifier hs-type">seqDim</span></a></span></span><span> </span><span id="local-6989586621679571708"><span class="annot"><a href="#local-6989586621679571708"><span class="hs-identifier hs-type">output</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-454"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetLayout"><span class="hs-identifier hs-type">SGetLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571713"><span class="hs-identifier hs-type">layout</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-455"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetDevice"><span class="hs-identifier hs-type">SGetDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571712"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-456"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetShape"><span class="hs-identifier hs-type">SGetShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571710"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-457"></span><span>    </span><span class="annot"><a href="#local-6989586621679571709"><span class="hs-identifier hs-type">seqDim</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679571710"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#%21"><span class="hs-glyph hs-type">!</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-458"></span><span>    </span><span class="annot"><a href="#local-6989586621679571708"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-459"></span><span>      </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-460"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Seq"><span class="hs-identifier hs-type">Seq</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679571714"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#WithoutGradient"><span class="hs-identifier hs-type">WithoutGradient</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#WithoutGradient"><span class="hs-identifier hs-type">WithoutGradient</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-461"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679571713"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Dense"><span class="hs-identifier hs-type">Dense</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-462"></span><span>          </span><span class="annot"><a href="#local-6989586621679571712"><span class="hs-identifier hs-type">device</span></a></span><span>
</span><span id="line-463"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Seq"><span class="hs-identifier hs-type">Seq</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679571711"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#Bool"><span class="hs-identifier hs-type">Bool</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679571715"><span class="hs-identifier hs-type">transformerDataType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-464"></span><span>          </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#BroadcastShapesF"><span class="hs-identifier hs-type">BroadcastShapesF</span></a></span><span>
</span><span id="line-465"></span><span>              </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#UnsqueezeF"><span class="hs-identifier hs-type">UnsqueezeF</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679571710"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-466"></span><span>              </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679571709"><span class="hs-identifier hs-type">seqDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679571709"><span class="hs-identifier hs-type">seqDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-467"></span><span>          </span><span class="hs-special">)</span><span>
</span><span id="line-468"></span><span>  </span><span class="hs-special">)</span><span>
</span><span id="line-469"></span><span>
</span><span id="line-470"></span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#mkTransformerAttentionMask"><span class="hs-identifier hs-type">mkTransformerAttentionMask</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-471"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679572221"><span class="annot"><a href="#local-6989586621679572221"><span class="hs-identifier hs-type">m</span></a></span></span><span> </span><span id="local-6989586621679572220"><span class="annot"><a href="#local-6989586621679572220"><span class="hs-identifier hs-type">transformerDataType</span></a></span></span><span> </span><span id="local-6989586621679572219"><span class="annot"><a href="#local-6989586621679572219"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679572218"><span class="annot"><a href="#local-6989586621679572218"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679572217"><span class="annot"><a href="#local-6989586621679572217"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679572216"><span class="annot"><a href="#local-6989586621679572216"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679572215"><span class="annot"><a href="#local-6989586621679572215"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679572214"><span class="annot"><a href="#local-6989586621679572214"><span class="hs-identifier hs-type">seqDim</span></a></span></span><span> </span><span id="local-6989586621679572213"><span class="annot"><a href="#local-6989586621679572213"><span class="hs-identifier hs-type">output</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-472"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier hs-type">MonadThrow</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679572221"><span class="hs-identifier hs-type">m</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-473"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerAttentionMaskC"><span class="hs-identifier hs-type">MkTransformerAttentionMaskC</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679572220"><span class="hs-identifier hs-type">transformerDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679572219"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679572218"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679572217"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679572216"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679572215"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679572214"><span class="hs-identifier hs-type">seqDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679572213"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-474"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-475"></span><span>  </span><span class="hs-comment">-- | data type singleton of the transformer</span><span>
</span><span id="line-476"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier hs-type">SDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679572220"><span class="hs-identifier hs-type">transformerDataType</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-477"></span><span>  </span><span class="hs-comment">-- | attention mask bias (typically a large negative number)</span><span>
</span><span id="line-478"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-479"></span><span>  </span><span class="hs-comment">-- | encoder padding mask</span><span>
</span><span id="line-480"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679572219"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679572218"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679572217"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679572216"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679572215"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-481"></span><span>  </span><span class="annot"><a href="#local-6989586621679572221"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679572213"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-482"></span><span id="mkTransformerAttentionMask"><span class="annot"><span class="annottext">mkTransformerAttentionMask :: SDataType transformerDataType
-&gt; Double
-&gt; Tensor gradient layout device dataType shape
-&gt; m output
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#mkTransformerAttentionMask"><span class="hs-identifier hs-var hs-var">mkTransformerAttentionMask</span></a></span></span><span> </span><span id="local-6989586621679571706"><span class="annot"><span class="annottext">SDataType transformerDataType
</span><a href="#local-6989586621679571706"><span class="hs-identifier hs-var">transformerDataType</span></a></span></span><span> </span><span id="local-6989586621679571705"><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679571705"><span class="hs-identifier hs-var">attentionMaskBias</span></a></span></span><span> </span><span id="local-6989586621679571704"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679571704"><span class="hs-identifier hs-var">paddingMask</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-483"></span><span>  </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679571703"><span class="annot"><span class="annottext">pmLayout :: SLayout layout
</span><a href="#local-6989586621679571703"><span class="hs-identifier hs-var hs-var">pmLayout</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape -&gt; SLayout layout
forall (layout :: Layout LayoutType)
       (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SGetLayout layout =&gt;
Tensor gradient layout device dataType shape -&gt; SLayout layout
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sGetLayout"><span class="hs-identifier hs-var">sGetLayout</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679571704"><span class="hs-identifier hs-var">paddingMask</span></a></span><span>
</span><span id="line-484"></span><span>      </span><span id="local-6989586621679571701"><span class="annot"><span class="annottext">pmDevice :: SDevice device
</span><a href="#local-6989586621679571701"><span class="hs-identifier hs-var hs-var">pmDevice</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape -&gt; SDevice device
forall (device :: Device (DeviceType Nat))
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SGetDevice device =&gt;
Tensor gradient layout device dataType shape -&gt; SDevice device
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sGetDevice"><span class="hs-identifier hs-var">sGetDevice</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679571704"><span class="hs-identifier hs-var">paddingMask</span></a></span><span>
</span><span id="line-485"></span><span>      </span><span id="local-6989586621679571700"><span class="annot"><span class="annottext">pmShape :: SShape shape
</span><a href="#local-6989586621679571700"><span class="hs-identifier hs-var hs-var">pmShape</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape -&gt; SShape shape
forall (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType).
SGetShape shape =&gt;
Tensor gradient layout device dataType shape -&gt; SShape shape
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sGetShape"><span class="hs-identifier hs-var">sGetShape</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679571704"><span class="hs-identifier hs-var">paddingMask</span></a></span><span>
</span><span id="line-486"></span><span>  </span><span id="local-6989586621679571699"><span class="annot"><span class="annottext">SDim seqDim
</span><a href="#local-6989586621679571699"><span class="hs-identifier hs-var">pmSeqDim</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">SSelectDim ('SelectDim ('ByIndex 1))
-&gt; SShape shape -&gt; m (SDim seqDim)
forall (selectDim :: SelectDim (By Symbol Nat))
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (dim :: Dim (Name Symbol) (Size Nat)) (m :: * -&gt; *).
(dim ~ GetDimF selectDim shape, MonadThrow m) =&gt;
SSelectDim selectDim -&gt; SShape shape -&gt; m (SDim dim)
</span><a href="Torch.GraduallyTyped.Shape.Class.html#sGetDimFromShape"><span class="hs-identifier hs-var">sGetDimFromShape</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SBy ('ByIndex 1) -&gt; SSelectDim ('SelectDim ('ByIndex 1))
forall (by :: By Symbol Nat). SBy by -&gt; SSelectDim ('SelectDim by)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSelectDim"><span class="hs-identifier hs-var">SSelectDim</span></a></span><span> </span><span class="annot"><span class="annottext">(SBy ('ByIndex 1) -&gt; SSelectDim ('SelectDim ('ByIndex 1)))
-&gt; SBy ('ByIndex 1) -&gt; SSelectDim ('SelectDim ('ByIndex 1))
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">KnownNat 1 =&gt; SBy ('ByIndex 1)
forall (index :: Nat). KnownNat index =&gt; SBy ('ByIndex index)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SByIndex"><span class="hs-identifier hs-var">SByIndex</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">SShape shape
</span><a href="#local-6989586621679571700"><span class="hs-identifier hs-var">pmShape</span></a></span><span>
</span><span id="line-487"></span><span>  </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679571698"><span class="annot"><span class="annottext">emptyMask :: Tensor
  ('Gradient 'WithoutGradient)
  layout
  device
  transformerDataType
  ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim])
</span><a href="#local-6989586621679571698"><span class="hs-identifier hs-var hs-var">emptyMask</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-488"></span><span>        </span><span class="annot"><span class="annottext">TensorSpec
  ('Gradient 'WithoutGradient)
  layout
  device
  transformerDataType
  ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim])
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     layout
     device
     transformerDataType
     ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim])
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
TensorSpec gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.Creation.html#sZeros"><span class="hs-identifier hs-var">sZeros</span></a></span><span> </span><span class="annot"><span class="annottext">(TensorSpec
   ('Gradient 'WithoutGradient)
   layout
   device
   transformerDataType
   ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim])
 -&gt; Tensor
      ('Gradient 'WithoutGradient)
      layout
      device
      transformerDataType
      ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim]))
-&gt; TensorSpec
     ('Gradient 'WithoutGradient)
     layout
     device
     transformerDataType
     ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim])
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     layout
     device
     transformerDataType
     ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-489"></span><span>          </span><span class="annot"><span class="annottext">SGradient ('Gradient 'WithoutGradient)
-&gt; SLayout layout
-&gt; SDevice device
-&gt; SDataType transformerDataType
-&gt; SShape ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim])
-&gt; TensorSpec
     ('Gradient 'WithoutGradient)
     layout
     device
     transformerDataType
     ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim])
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SShape shape
-&gt; TensorSpec gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorSpec"><span class="hs-identifier hs-var">TensorSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SRequiresGradient 'WithoutGradient
-&gt; SGradient ('Gradient 'WithoutGradient)
forall (requiresGradient :: RequiresGradient).
SRequiresGradient requiresGradient
-&gt; SGradient ('Gradient requiresGradient)
</span><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier hs-var">SGradient</span></a></span><span> </span><span class="annot"><span class="annottext">SRequiresGradient 'WithoutGradient
</span><a href="Torch.GraduallyTyped.RequiresGradient.html#SWithoutGradient"><span class="hs-identifier hs-var">SWithoutGradient</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">SLayout layout
</span><a href="#local-6989586621679571703"><span class="hs-identifier hs-var">pmLayout</span></a></span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679571701"><span class="hs-identifier hs-var">pmDevice</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType transformerDataType
</span><a href="#local-6989586621679571706"><span class="hs-identifier hs-var">transformerDataType</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SList '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim]
-&gt; SShape ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim]
 -&gt; SShape ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim]))
-&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim]
-&gt; SShape ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize ('Size 1) -&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 1))
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownNat 1 =&gt; SSize ('Size 1)
forall (size :: Nat). KnownNat size =&gt; SSize ('Size size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier hs-var">SSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">1</span></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 1))
-&gt; SList '[seqDim, seqDim]
-&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SDim seqDim
</span><a href="#local-6989586621679571699"><span class="hs-identifier hs-var">pmSeqDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim seqDim -&gt; SList '[seqDim] -&gt; SList '[seqDim, seqDim]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SDim seqDim
</span><a href="#local-6989586621679571699"><span class="hs-identifier hs-var">pmSeqDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim seqDim -&gt; SList '[] -&gt; SList '[seqDim]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-490"></span><span>  </span><span class="annot"><span class="annottext">output -&gt; m output
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">(output -&gt; m output) -&gt; output -&gt; m output
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">Tensor
  gradient
  layout
  device
  dataType
  (UnsqueezeF ('SelectDim ('ByIndex 1)) shape)
-&gt; Double
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     layout
     device
     transformerDataType
     ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim])
-&gt; Tensor
     (Seq
        (gradient &lt;+&gt; 'Gradient 'WithoutGradient)
        ('Gradient 'WithoutGradient))
     (layout &lt;+&gt; (layout &lt;+&gt; 'Layout 'Dense))
     (device &lt;+&gt; device)
     (Seq (dataType &lt;+&gt; 'DataType 'Bool) transformerDataType)
     (BroadcastShapesF
        (UnsqueezeF ('SelectDim ('ByIndex 1)) shape)
        ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim]))
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]) value
       (gradient' :: Gradient RequiresGradient)
       (layout' :: Layout LayoutType) (device' :: Device (DeviceType Nat))
       (dataType' :: DataType DType)
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]).
Scalar value =&gt;
Tensor gradient layout device dataType shape
-&gt; value
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; Tensor
     (Seq (gradient &lt;+&gt; 'Gradient 'WithoutGradient) gradient')
     (layout &lt;+&gt; (layout' &lt;+&gt; 'Layout 'Dense))
     (device &lt;+&gt; device')
     (Seq (dataType &lt;+&gt; 'DataType 'Bool) dataType')
     (BroadcastShapesF shape shape')
</span><a href="Torch.GraduallyTyped.Tensor.Other.html#maskedFill"><span class="hs-identifier hs-var">maskedFill</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
-&gt; Tensor
     gradient
     layout
     device
     dataType
     (UnsqueezeF ('SelectDim ('ByIndex 1)) shape)
forall (selectDim :: SelectDim (By Symbol Nat))
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]).
(shape' ~ UnsqueezeF selectDim shape, SingI selectDim) =&gt;
Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape'
</span><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#unsqueeze"><span class="hs-identifier hs-var">unsqueeze</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679571704"><span class="hs-identifier hs-var">paddingMask</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679571705"><span class="hs-identifier hs-var">attentionMaskBias</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  layout
  device
  transformerDataType
  ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim])
</span><a href="#local-6989586621679571698"><span class="hs-identifier hs-var">emptyMask</span></a></span><span>
</span><span id="line-491"></span><span>
</span><span id="line-492"></span><span class="hs-keyword">data</span><span> </span><span id="MkTransformerAttentionMask"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerAttentionMask"><span class="hs-identifier hs-var">MkTransformerAttentionMask</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679571697"><span class="annot"><a href="#local-6989586621679571697"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier hs-type">DType</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-493"></span><span>  </span><span id="MkTransformerAttentionMask"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerAttentionMask"><span class="hs-identifier hs-var">MkTransformerAttentionMask</span></a></span></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-494"></span><span>    </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679572222"><span class="annot"><a href="#local-6989586621679572222"><span class="hs-identifier hs-type">dataType</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-495"></span><span>    </span><span class="hs-special">{</span><span> </span><span id="attentionMaskDataType"><span class="annot"><span class="annottext">MkTransformerAttentionMask dataType -&gt; SDataType dataType
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#attentionMaskDataType"><span class="hs-identifier hs-var hs-var">attentionMaskDataType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier hs-type">SDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679572222"><span class="hs-identifier hs-type">dataType</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-496"></span><span>      </span><span id="attentionMaskBias"><span class="annot"><span class="annottext">MkTransformerAttentionMask dataType -&gt; Double
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#attentionMaskBias"><span class="hs-identifier hs-var hs-var">attentionMaskBias</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span>
</span><span id="line-497"></span><span>    </span><span class="hs-special">}</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-498"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerAttentionMask"><span class="hs-identifier hs-type">MkTransformerAttentionMask</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679572222"><span class="hs-identifier hs-type">dataType</span></a></span><span>
</span><span id="line-499"></span><span>
</span><span id="line-500"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">instance</span><span>
</span><span id="line-501"></span><span>  </span><span id="ModelSpec"><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier hs-var">ModelSpec</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerAttentionMask"><span class="hs-identifier hs-type">MkTransformerAttentionMask</span></a></span><span> </span><span id="local-6989586621679571693"><span class="annot"><a href="#local-6989586621679571693"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-502"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerAttentionMask"><span class="hs-identifier hs-type">MkTransformerAttentionMask</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571693"><span class="hs-identifier hs-type">dataType</span></a></span><span>
</span><span id="line-503"></span><span>
</span><span id="line-504"></span><span id="local-6989586621679571691"><span id="local-6989586621679571692"><span class="hs-keyword">instance</span><span>
</span><span id="line-505"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span>
</span><span id="line-506"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerAttentionMask"><span class="hs-identifier hs-type">MkTransformerAttentionMask</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571692"><span class="hs-identifier hs-type">dataType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-507"></span><span>    </span><span class="annot"><a href="#local-6989586621679571691"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-508"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerAttentionMask"><span class="hs-identifier hs-type">MkTransformerAttentionMask</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571692"><span class="hs-identifier hs-type">dataType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-509"></span><span>    </span><span class="annot"><a href="#local-6989586621679571691"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-510"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-511"></span><span>  </span><span id="local-6989586621679571689"><span class="annot"><span class="annottext">initialize :: ModelSpec (MkTransformerAttentionMask dataType)
-&gt; Generator generatorDevice
-&gt; m (MkTransformerAttentionMask dataType,
      Generator generatorDevice)
</span><a href="#local-6989586621679571689"><span class="hs-identifier hs-var hs-var hs-var hs-var">initialize</span></a></span></span><span> </span><span id="local-6989586621679571688"><span class="annot"><span class="annottext">ModelSpec (MkTransformerAttentionMask dataType)
</span><a href="#local-6989586621679571688"><span class="hs-identifier hs-var">spec</span></a></span></span><span> </span><span id="local-6989586621679571687"><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679571687"><span class="hs-identifier hs-var">g</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(MkTransformerAttentionMask dataType, Generator generatorDevice)
-&gt; m (MkTransformerAttentionMask dataType,
      Generator generatorDevice)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">ModelSpec (MkTransformerAttentionMask dataType)
MkTransformerAttentionMask dataType
</span><a href="#local-6989586621679571688"><span class="hs-identifier hs-var">spec</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679571687"><span class="hs-identifier hs-var">g</span></a></span><span class="hs-special">)</span></span></span><span>
</span><span id="line-512"></span><span>
</span><span id="line-513"></span><span id="local-6989586621679571686"><span class="hs-keyword">instance</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasStateDict"><span class="hs-identifier hs-type">HasStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerAttentionMask"><span class="hs-identifier hs-type">MkTransformerAttentionMask</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571686"><span class="hs-identifier hs-type">dataType</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-514"></span><span>  </span><span id="local-6989586621679571683"><span class="annot"><span class="annottext">fromStateDict :: ModelSpec (MkTransformerAttentionMask dataType)
-&gt; StateDictKey -&gt; m (MkTransformerAttentionMask dataType)
</span><a href="#local-6989586621679571683"><span class="hs-identifier hs-var hs-var hs-var hs-var">fromStateDict</span></a></span></span><span> </span><span id="local-6989586621679571682"><span class="annot"><span class="annottext">ModelSpec (MkTransformerAttentionMask dataType)
</span><a href="#local-6989586621679571682"><span class="hs-identifier hs-var">spec</span></a></span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">MkTransformerAttentionMask dataType
-&gt; m (MkTransformerAttentionMask dataType)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">ModelSpec (MkTransformerAttentionMask dataType)
MkTransformerAttentionMask dataType
</span><a href="#local-6989586621679571682"><span class="hs-identifier hs-var">spec</span></a></span><span>
</span><span id="line-515"></span><span>  </span><span id="local-6989586621679571681"><span class="annot"><span class="annottext">toStateDict :: StateDictKey -&gt; MkTransformerAttentionMask dataType -&gt; m ()
</span><a href="#local-6989586621679571681"><span class="hs-identifier hs-var hs-var hs-var hs-var">toStateDict</span></a></span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="annottext">MkTransformerAttentionMask dataType
</span><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">() -&gt; m ()
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span></span><span>
</span><span id="line-516"></span><span>
</span><span id="line-517"></span><span id="local-6989586621679571672"><span id="local-6989586621679571673"><span id="local-6989586621679571674"><span id="local-6989586621679571675"><span id="local-6989586621679571676"><span id="local-6989586621679571677"><span id="local-6989586621679571678"><span id="local-6989586621679571679"><span id="local-6989586621679571680"><span class="hs-keyword">instance</span><span>
</span><span id="line-518"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerAttentionMaskC"><span class="hs-identifier hs-type">MkTransformerAttentionMaskC</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571680"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571679"><span class="hs-identifier hs-type">inputGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571678"><span class="hs-identifier hs-type">inputLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571677"><span class="hs-identifier hs-type">inputDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571676"><span class="hs-identifier hs-type">inputDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571675"><span class="hs-identifier hs-type">inputShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571674"><span class="hs-identifier hs-type">seqDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571673"><span class="hs-identifier hs-type">output</span></a></span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-519"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-520"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerAttentionMask"><span class="hs-identifier hs-type">MkTransformerAttentionMask</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571680"><span class="hs-identifier hs-type">dataType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-521"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571679"><span class="hs-identifier hs-type">inputGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571678"><span class="hs-identifier hs-type">inputLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571677"><span class="hs-identifier hs-type">inputDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571676"><span class="hs-identifier hs-type">inputDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571675"><span class="hs-identifier hs-type">inputShape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-522"></span><span>    </span><span class="annot"><a href="#local-6989586621679571672"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-523"></span><span>    </span><span class="annot"><a href="#local-6989586621679571673"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-524"></span><span>    </span><span class="annot"><a href="#local-6989586621679571672"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-525"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-526"></span><span>  </span><span id="local-6989586621679571670"><span class="annot"><span class="annottext">forward :: MkTransformerAttentionMask dataType
-&gt; Tensor
     inputGradient inputLayout inputDevice inputDataType inputShape
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorDevice)
</span><a href="#local-6989586621679571670"><span class="hs-identifier hs-var hs-var hs-var hs-var">forward</span></a></span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerAttentionMask"><span class="hs-identifier hs-type">MkTransformerAttentionMask</span></a></span><span> </span><span class="hs-special">{</span><span id="local-6989586621679571668"><span id="local-6989586621679571669"><span class="annot"><span class="annottext">Double
SDataType dataType
attentionMaskBias :: Double
attentionMaskDataType :: SDataType dataType
attentionMaskBias :: forall (dataType :: DataType DType).
MkTransformerAttentionMask dataType -&gt; Double
attentionMaskDataType :: forall (dataType :: DataType DType).
MkTransformerAttentionMask dataType -&gt; SDataType dataType
</span><a href="#local-6989586621679571668"><span class="hs-glyph hs-var hs-var hs-var hs-var">..</span></a></span></span></span><span class="hs-special">}</span><span> </span><span id="local-6989586621679571667"><span class="annot"><span class="annottext">Tensor
  inputGradient inputLayout inputDevice inputDataType inputShape
</span><a href="#local-6989586621679571667"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span id="local-6989586621679571666"><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679571666"><span class="hs-identifier hs-var">g</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-527"></span><span>    </span><span id="local-6989586621679571665"><span class="annot"><span class="annottext">output
</span><a href="#local-6989586621679571665"><span class="hs-identifier hs-var">attentionMask</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">SDataType dataType
-&gt; Double
-&gt; Tensor
     inputGradient inputLayout inputDevice inputDataType inputShape
-&gt; m output
forall (m :: * -&gt; *) (transformerDataType :: DataType DType)
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (seqDim :: Dim (Name Symbol) (Size Nat)) output.
(MonadThrow m,
 MkTransformerAttentionMaskC
   transformerDataType
   gradient
   layout
   device
   dataType
   shape
   seqDim
   output) =&gt;
SDataType transformerDataType
-&gt; Double
-&gt; Tensor gradient layout device dataType shape
-&gt; m output
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#mkTransformerAttentionMask"><span class="hs-identifier hs-var">mkTransformerAttentionMask</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679571669"><span class="hs-identifier hs-var">attentionMaskDataType</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679571668"><span class="hs-identifier hs-var">attentionMaskBias</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  inputGradient inputLayout inputDevice inputDataType inputShape
</span><a href="#local-6989586621679571667"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-528"></span><span>    </span><span class="annot"><span class="annottext">(output, Generator generatorDevice)
-&gt; m (output, Generator generatorDevice)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">output
</span><a href="#local-6989586621679571665"><span class="hs-identifier hs-var">attentionMask</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679571666"><span class="hs-identifier hs-var">g</span></a></span><span class="hs-special">)</span></span></span></span></span></span></span></span></span></span><span>
</span><span id="line-529"></span><span>
</span><span id="line-530"></span><span class="hs-keyword">type</span><span> </span><span id="MkTransformerDecoderAttentionMaskC"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerDecoderAttentionMaskC"><span class="hs-identifier hs-var">MkTransformerDecoderAttentionMaskC</span></a></span></span><span> </span><span id="local-6989586621679571664"><span class="annot"><a href="#local-6989586621679571664"><span class="hs-identifier hs-type">transformerDataType</span></a></span></span><span> </span><span id="local-6989586621679571663"><span class="annot"><a href="#local-6989586621679571663"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679571662"><span class="annot"><a href="#local-6989586621679571662"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679571661"><span class="annot"><a href="#local-6989586621679571661"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679571660"><span class="annot"><a href="#local-6989586621679571660"><span class="hs-identifier hs-type">seqDim</span></a></span></span><span> </span><span id="local-6989586621679571659"><span class="annot"><a href="#local-6989586621679571659"><span class="hs-identifier hs-type">output</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-531"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetLayout"><span class="hs-identifier hs-type">SGetLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571663"><span class="hs-identifier hs-type">layout</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-532"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetDevice"><span class="hs-identifier hs-type">SGetDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571662"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-533"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetShape"><span class="hs-identifier hs-type">SGetShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571661"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-534"></span><span>    </span><span class="annot"><a href="#local-6989586621679571660"><span class="hs-identifier hs-type">seqDim</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679571661"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#%21"><span class="hs-glyph hs-type">!</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-535"></span><span>    </span><span class="annot"><a href="#local-6989586621679571659"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-536"></span><span>      </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-537"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#WithoutGradient"><span class="hs-identifier hs-type">WithoutGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-538"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679571663"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Dense"><span class="hs-identifier hs-type">Dense</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-539"></span><span>          </span><span class="annot"><a href="#local-6989586621679571662"><span class="hs-identifier hs-type">device</span></a></span><span>
</span><span id="line-540"></span><span>          </span><span class="annot"><a href="#local-6989586621679571664"><span class="hs-identifier hs-type">transformerDataType</span></a></span><span>
</span><span id="line-541"></span><span>          </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#BroadcastShapesF"><span class="hs-identifier hs-type">BroadcastShapesF</span></a></span><span>
</span><span id="line-542"></span><span>              </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#BroadcastShapesF"><span class="hs-identifier hs-type">BroadcastShapesF</span></a></span><span>
</span><span id="line-543"></span><span>                  </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679571660"><span class="hs-identifier hs-type">seqDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679571660"><span class="hs-identifier hs-type">seqDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-544"></span><span>                  </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#UnsqueezeF"><span class="hs-identifier hs-type">UnsqueezeF</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679571661"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-545"></span><span>              </span><span class="hs-special">)</span><span>
</span><span id="line-546"></span><span>              </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679571660"><span class="hs-identifier hs-type">seqDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679571660"><span class="hs-identifier hs-type">seqDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-547"></span><span>          </span><span class="hs-special">)</span><span>
</span><span id="line-548"></span><span>  </span><span class="hs-special">)</span><span>
</span><span id="line-549"></span><span>
</span><span id="line-550"></span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#mkTransformerDecoderAttentionMask"><span class="hs-identifier hs-type">mkTransformerDecoderAttentionMask</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-551"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679572161"><span class="annot"><a href="#local-6989586621679572161"><span class="hs-identifier hs-type">m</span></a></span></span><span> </span><span id="local-6989586621679572160"><span class="annot"><a href="#local-6989586621679572160"><span class="hs-identifier hs-type">transformerDataType</span></a></span></span><span> </span><span id="local-6989586621679572154"><span class="annot"><a href="#local-6989586621679572154"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679572159"><span class="annot"><a href="#local-6989586621679572159"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679572158"><span class="annot"><a href="#local-6989586621679572158"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679572153"><span class="annot"><a href="#local-6989586621679572153"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679572157"><span class="annot"><a href="#local-6989586621679572157"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679572156"><span class="annot"><a href="#local-6989586621679572156"><span class="hs-identifier hs-type">seqDim</span></a></span></span><span> </span><span id="local-6989586621679572155"><span class="annot"><a href="#local-6989586621679572155"><span class="hs-identifier hs-type">output</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-552"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier hs-type">MonadThrow</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679572161"><span class="hs-identifier hs-type">m</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-553"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerDecoderAttentionMaskC"><span class="hs-identifier hs-type">MkTransformerDecoderAttentionMaskC</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679572160"><span class="hs-identifier hs-type">transformerDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679572159"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679572158"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679572157"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679572156"><span class="hs-identifier hs-type">seqDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679572155"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-554"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-555"></span><span>  </span><span class="hs-comment">-- | data type singleton of the transformer</span><span>
</span><span id="line-556"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier hs-type">SDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679572160"><span class="hs-identifier hs-type">transformerDataType</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-557"></span><span>  </span><span class="hs-comment">-- | attention mask bias (typically a large negative number)</span><span>
</span><span id="line-558"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-559"></span><span>  </span><span class="hs-comment">-- | decoder padding mask</span><span>
</span><span id="line-560"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679572154"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679572159"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679572158"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679572153"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679572157"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-561"></span><span>  </span><span class="annot"><a href="#local-6989586621679572161"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679572155"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-562"></span><span id="mkTransformerDecoderAttentionMask"><span class="annot"><span class="annottext">mkTransformerDecoderAttentionMask :: SDataType transformerDataType
-&gt; Double
-&gt; Tensor gradient layout device dataType shape
-&gt; m output
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#mkTransformerDecoderAttentionMask"><span class="hs-identifier hs-var hs-var">mkTransformerDecoderAttentionMask</span></a></span></span><span> </span><span id="local-6989586621679571657"><span class="annot"><span class="annottext">SDataType transformerDataType
</span><a href="#local-6989586621679571657"><span class="hs-identifier hs-var">transformerDataType</span></a></span></span><span> </span><span id="local-6989586621679571656"><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679571656"><span class="hs-identifier hs-var">attentionMaskBias</span></a></span></span><span> </span><span id="local-6989586621679571655"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679571655"><span class="hs-identifier hs-var">paddingMask</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-563"></span><span>  </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679571654"><span class="annot"><span class="annottext">pmLayout :: SLayout layout
</span><a href="#local-6989586621679571654"><span class="hs-identifier hs-var hs-var">pmLayout</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape -&gt; SLayout layout
forall (layout :: Layout LayoutType)
       (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SGetLayout layout =&gt;
Tensor gradient layout device dataType shape -&gt; SLayout layout
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sGetLayout"><span class="hs-identifier hs-var">sGetLayout</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679571655"><span class="hs-identifier hs-var">paddingMask</span></a></span><span>
</span><span id="line-564"></span><span>      </span><span id="local-6989586621679571653"><span class="annot"><span class="annottext">pmDevice :: SDevice device
</span><a href="#local-6989586621679571653"><span class="hs-identifier hs-var hs-var">pmDevice</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape -&gt; SDevice device
forall (device :: Device (DeviceType Nat))
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SGetDevice device =&gt;
Tensor gradient layout device dataType shape -&gt; SDevice device
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sGetDevice"><span class="hs-identifier hs-var">sGetDevice</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679571655"><span class="hs-identifier hs-var">paddingMask</span></a></span><span>
</span><span id="line-565"></span><span>      </span><span id="local-6989586621679571652"><span class="annot"><span class="annottext">pmShape :: SShape shape
</span><a href="#local-6989586621679571652"><span class="hs-identifier hs-var hs-var">pmShape</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape -&gt; SShape shape
forall (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType).
SGetShape shape =&gt;
Tensor gradient layout device dataType shape -&gt; SShape shape
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sGetShape"><span class="hs-identifier hs-var">sGetShape</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679571655"><span class="hs-identifier hs-var">paddingMask</span></a></span><span>
</span><span id="line-566"></span><span>  </span><span id="local-6989586621679571651"><span class="annot"><span class="annottext">SDim seqDim
</span><a href="#local-6989586621679571651"><span class="hs-identifier hs-var">pmSeqDim</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">SSelectDim ('SelectDim ('ByIndex 1))
-&gt; SShape shape -&gt; m (SDim seqDim)
forall (selectDim :: SelectDim (By Symbol Nat))
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (dim :: Dim (Name Symbol) (Size Nat)) (m :: * -&gt; *).
(dim ~ GetDimF selectDim shape, MonadThrow m) =&gt;
SSelectDim selectDim -&gt; SShape shape -&gt; m (SDim dim)
</span><a href="Torch.GraduallyTyped.Shape.Class.html#sGetDimFromShape"><span class="hs-identifier hs-var">sGetDimFromShape</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SBy ('ByIndex 1) -&gt; SSelectDim ('SelectDim ('ByIndex 1))
forall (by :: By Symbol Nat). SBy by -&gt; SSelectDim ('SelectDim by)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSelectDim"><span class="hs-identifier hs-var">SSelectDim</span></a></span><span> </span><span class="annot"><span class="annottext">(SBy ('ByIndex 1) -&gt; SSelectDim ('SelectDim ('ByIndex 1)))
-&gt; SBy ('ByIndex 1) -&gt; SSelectDim ('SelectDim ('ByIndex 1))
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">KnownNat 1 =&gt; SBy ('ByIndex 1)
forall (index :: Nat). KnownNat index =&gt; SBy ('ByIndex index)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SByIndex"><span class="hs-identifier hs-var">SByIndex</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">SShape shape
</span><a href="#local-6989586621679571652"><span class="hs-identifier hs-var">pmShape</span></a></span><span>
</span><span id="line-567"></span><span>  </span><span id="local-6989586621679571650"><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  layout
  device
  ('DataType 'Bool)
  ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim])
</span><a href="#local-6989586621679571650"><span class="hs-identifier hs-var">causalMask</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span>
</span><span id="line-568"></span><span>    </span><span class="annot"><span class="annottext">forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]).
(shape' ~ UnsqueezeF ('SelectDim ('ByIndex 0)) shape,
 SingI ('SelectDim ('ByIndex 0))) =&gt;
Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape'
forall (selectDim :: SelectDim (By Symbol Nat))
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]).
(shape' ~ UnsqueezeF selectDim shape, SingI selectDim) =&gt;
Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape'
</span><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#unsqueeze"><span class="hs-identifier hs-var">unsqueeze</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">0</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-569"></span><span>      </span><span class="annot"><span class="annottext">(Tensor
   ('Gradient 'WithoutGradient)
   layout
   device
   ('DataType 'Bool)
   ('Shape '[seqDim, seqDim])
 -&gt; Tensor
      ('Gradient 'WithoutGradient)
      layout
      device
      ('DataType 'Bool)
      ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim]))
-&gt; m (Tensor
        ('Gradient 'WithoutGradient)
        layout
        device
        ('DataType 'Bool)
        ('Shape '[seqDim, seqDim]))
-&gt; m (Tensor
        ('Gradient 'WithoutGradient)
        layout
        device
        ('DataType 'Bool)
        ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim]))
forall (f :: * -&gt; *) a b. Functor f =&gt; (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;$&gt;</span></span><span> </span><span class="hs-special">(</span><span> </span><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  layout
  device
  transformerDataType
  ('Shape '[seqDim, seqDim])
-&gt; m (Tensor
        ('Gradient 'WithoutGradient)
        layout
        device
        ('DataType 'Bool)
        ('Shape '[seqDim, seqDim]))
forall (m :: * -&gt; *) (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
MonadThrow m =&gt;
Tensor gradient layout device dataType shape
-&gt; m (Tensor
        ('Gradient 'WithoutGradient) layout device ('DataType 'Bool) shape)
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#bool"><span class="hs-identifier hs-var">bool</span></a></span><span>
</span><span id="line-570"></span><span>              </span><span class="annot"><span class="annottext">(Tensor
   ('Gradient 'WithoutGradient)
   layout
   device
   transformerDataType
   ('Shape '[seqDim, seqDim])
 -&gt; m (Tensor
         ('Gradient 'WithoutGradient)
         layout
         device
         ('DataType 'Bool)
         ('Shape '[seqDim, seqDim])))
-&gt; (TensorSpec
      ('Gradient 'WithoutGradient)
      layout
      device
      transformerDataType
      ('Shape '[seqDim, seqDim])
    -&gt; Tensor
         ('Gradient 'WithoutGradient)
         layout
         device
         transformerDataType
         ('Shape '[seqDim, seqDim]))
-&gt; TensorSpec
     ('Gradient 'WithoutGradient)
     layout
     device
     transformerDataType
     ('Shape '[seqDim, seqDim])
-&gt; m (Tensor
        ('Gradient 'WithoutGradient)
        layout
        device
        ('DataType 'Bool)
        ('Shape '[seqDim, seqDim]))
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Int
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     layout
     device
     transformerDataType
     ('Shape '[seqDim, seqDim])
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     layout
     device
     transformerDataType
     ('Shape '[seqDim, seqDim])
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
Int
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.Other.html#triu"><span class="hs-identifier hs-var">triu</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">1</span></span><span>
</span><span id="line-571"></span><span>              </span><span class="annot"><span class="annottext">(Tensor
   ('Gradient 'WithoutGradient)
   layout
   device
   transformerDataType
   ('Shape '[seqDim, seqDim])
 -&gt; Tensor
      ('Gradient 'WithoutGradient)
      layout
      device
      transformerDataType
      ('Shape '[seqDim, seqDim]))
-&gt; (TensorSpec
      ('Gradient 'WithoutGradient)
      layout
      device
      transformerDataType
      ('Shape '[seqDim, seqDim])
    -&gt; Tensor
         ('Gradient 'WithoutGradient)
         layout
         device
         transformerDataType
         ('Shape '[seqDim, seqDim]))
-&gt; TensorSpec
     ('Gradient 'WithoutGradient)
     layout
     device
     transformerDataType
     ('Shape '[seqDim, seqDim])
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     layout
     device
     transformerDataType
     ('Shape '[seqDim, seqDim])
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">TensorSpec
  ('Gradient 'WithoutGradient)
  layout
  device
  transformerDataType
  ('Shape '[seqDim, seqDim])
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     layout
     device
     transformerDataType
     ('Shape '[seqDim, seqDim])
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
TensorSpec gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.Creation.html#sOnes"><span class="hs-identifier hs-var">sOnes</span></a></span><span>
</span><span id="line-572"></span><span>              </span><span class="annot"><span class="annottext">(TensorSpec
   ('Gradient 'WithoutGradient)
   layout
   device
   transformerDataType
   ('Shape '[seqDim, seqDim])
 -&gt; m (Tensor
         ('Gradient 'WithoutGradient)
         layout
         device
         ('DataType 'Bool)
         ('Shape '[seqDim, seqDim])))
-&gt; TensorSpec
     ('Gradient 'WithoutGradient)
     layout
     device
     transformerDataType
     ('Shape '[seqDim, seqDim])
-&gt; m (Tensor
        ('Gradient 'WithoutGradient)
        layout
        device
        ('DataType 'Bool)
        ('Shape '[seqDim, seqDim]))
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SGradient ('Gradient 'WithoutGradient)
-&gt; SLayout layout
-&gt; SDevice device
-&gt; SDataType transformerDataType
-&gt; SShape ('Shape '[seqDim, seqDim])
-&gt; TensorSpec
     ('Gradient 'WithoutGradient)
     layout
     device
     transformerDataType
     ('Shape '[seqDim, seqDim])
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SShape shape
-&gt; TensorSpec gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorSpec"><span class="hs-identifier hs-var">TensorSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SRequiresGradient 'WithoutGradient
-&gt; SGradient ('Gradient 'WithoutGradient)
forall (requiresGradient :: RequiresGradient).
SRequiresGradient requiresGradient
-&gt; SGradient ('Gradient requiresGradient)
</span><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier hs-var">SGradient</span></a></span><span> </span><span class="annot"><span class="annottext">SRequiresGradient 'WithoutGradient
</span><a href="Torch.GraduallyTyped.RequiresGradient.html#SWithoutGradient"><span class="hs-identifier hs-var">SWithoutGradient</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">SLayout layout
</span><a href="#local-6989586621679571654"><span class="hs-identifier hs-var">pmLayout</span></a></span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679571653"><span class="hs-identifier hs-var">pmDevice</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType transformerDataType
</span><a href="#local-6989586621679571657"><span class="hs-identifier hs-var">transformerDataType</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SList '[seqDim, seqDim] -&gt; SShape ('Shape '[seqDim, seqDim])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList '[seqDim, seqDim] -&gt; SShape ('Shape '[seqDim, seqDim]))
-&gt; SList '[seqDim, seqDim] -&gt; SShape ('Shape '[seqDim, seqDim])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SDim seqDim
</span><a href="#local-6989586621679571651"><span class="hs-identifier hs-var">pmSeqDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim seqDim -&gt; SList '[seqDim] -&gt; SList '[seqDim, seqDim]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SDim seqDim
</span><a href="#local-6989586621679571651"><span class="hs-identifier hs-var">pmSeqDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim seqDim -&gt; SList '[] -&gt; SList '[seqDim]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-573"></span><span>          </span><span class="hs-special">)</span><span>
</span><span id="line-574"></span><span>  </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679571649"><span class="annot"><span class="annottext">emptyMask :: Tensor
  ('Gradient 'WithoutGradient)
  layout
  device
  transformerDataType
  ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim])
</span><a href="#local-6989586621679571649"><span class="hs-identifier hs-var hs-var">emptyMask</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">TensorSpec
  ('Gradient 'WithoutGradient)
  layout
  device
  transformerDataType
  ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim])
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     layout
     device
     transformerDataType
     ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim])
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
TensorSpec gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.Creation.html#sZeros"><span class="hs-identifier hs-var">sZeros</span></a></span><span> </span><span class="annot"><span class="annottext">(TensorSpec
   ('Gradient 'WithoutGradient)
   layout
   device
   transformerDataType
   ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim])
 -&gt; Tensor
      ('Gradient 'WithoutGradient)
      layout
      device
      transformerDataType
      ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim]))
-&gt; TensorSpec
     ('Gradient 'WithoutGradient)
     layout
     device
     transformerDataType
     ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim])
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     layout
     device
     transformerDataType
     ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SGradient ('Gradient 'WithoutGradient)
-&gt; SLayout layout
-&gt; SDevice device
-&gt; SDataType transformerDataType
-&gt; SShape ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim])
-&gt; TensorSpec
     ('Gradient 'WithoutGradient)
     layout
     device
     transformerDataType
     ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim])
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SShape shape
-&gt; TensorSpec gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorSpec"><span class="hs-identifier hs-var">TensorSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SRequiresGradient 'WithoutGradient
-&gt; SGradient ('Gradient 'WithoutGradient)
forall (requiresGradient :: RequiresGradient).
SRequiresGradient requiresGradient
-&gt; SGradient ('Gradient requiresGradient)
</span><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier hs-var">SGradient</span></a></span><span> </span><span class="annot"><span class="annottext">SRequiresGradient 'WithoutGradient
</span><a href="Torch.GraduallyTyped.RequiresGradient.html#SWithoutGradient"><span class="hs-identifier hs-var">SWithoutGradient</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">SLayout layout
</span><a href="#local-6989586621679571654"><span class="hs-identifier hs-var">pmLayout</span></a></span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679571653"><span class="hs-identifier hs-var">pmDevice</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType transformerDataType
</span><a href="#local-6989586621679571657"><span class="hs-identifier hs-var">transformerDataType</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SList '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim]
-&gt; SShape ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim]
 -&gt; SShape ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim]))
-&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim]
-&gt; SShape ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize ('Size 1) -&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 1))
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownNat 1 =&gt; SSize ('Size 1)
forall (size :: Nat). KnownNat size =&gt; SSize ('Size size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier hs-var">SSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">1</span></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 1))
-&gt; SList '[seqDim, seqDim]
-&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SDim seqDim
</span><a href="#local-6989586621679571651"><span class="hs-identifier hs-var">pmSeqDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim seqDim -&gt; SList '[seqDim] -&gt; SList '[seqDim, seqDim]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SDim seqDim
</span><a href="#local-6989586621679571651"><span class="hs-identifier hs-var">pmSeqDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim seqDim -&gt; SList '[] -&gt; SList '[seqDim]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-575"></span><span>      </span><span id="local-6989586621679571648"><span class="annot"><span class="annottext">booleanMask :: Tensor
  ('Gradient 'WithoutGradient)
  (layout &lt;+&gt; layout)
  (device &lt;+&gt; device)
  ('DataType 'Bool)
  (BroadcastShapesF
     ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim])
     (UnsqueezeF ('SelectDim ('ByIndex 1)) shape))
</span><a href="#local-6989586621679571648"><span class="hs-identifier hs-var hs-var">booleanMask</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  layout
  device
  ('DataType 'Bool)
  ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim])
</span><a href="#local-6989586621679571650"><span class="hs-identifier hs-var">causalMask</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  layout
  device
  ('DataType 'Bool)
  ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim])
-&gt; Tensor
     gradient
     layout
     device
     dataType
     (UnsqueezeF ('SelectDim ('ByIndex 1)) shape)
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     (layout &lt;+&gt; layout)
     (device &lt;+&gt; device)
     ('DataType 'Bool)
     (BroadcastShapesF
        ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim])
        (UnsqueezeF ('SelectDim ('ByIndex 1)) shape))
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (gradient' :: Gradient RequiresGradient)
       (layout' :: Layout LayoutType) (device' :: Device (DeviceType Nat))
       (dataType' :: DataType DType)
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]).
Tensor gradient layout device dataType shape
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     (layout &lt;+&gt; layout')
     (device &lt;+&gt; device')
     ('DataType 'Bool)
     (BroadcastShapesF shape shape')
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#logicalOr"><span class="hs-operator hs-var">`logicalOr`</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
-&gt; Tensor
     gradient
     layout
     device
     dataType
     (UnsqueezeF ('SelectDim ('ByIndex 1)) shape)
forall (selectDim :: SelectDim (By Symbol Nat))
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]).
(shape' ~ UnsqueezeF selectDim shape, SingI selectDim) =&gt;
Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape'
</span><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#unsqueeze"><span class="hs-identifier hs-var">unsqueeze</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679571655"><span class="hs-identifier hs-var">paddingMask</span></a></span><span>
</span><span id="line-576"></span><span>  </span><span class="annot"><span class="annottext">output -&gt; m output
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">(output -&gt; m output) -&gt; output -&gt; m output
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-577"></span><span>    </span><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  layout
  device
  ('DataType 'Bool)
  (BroadcastShapesF
     ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim])
     (UnsqueezeF ('SelectDim ('ByIndex 1)) shape))
-&gt; Double
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     layout
     device
     transformerDataType
     ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim])
-&gt; Tensor
     (Seq
        ('Gradient 'WithoutGradient &lt;+&gt; 'Gradient 'WithoutGradient)
        ('Gradient 'WithoutGradient))
     (layout &lt;+&gt; (layout &lt;+&gt; 'Layout 'Dense))
     (device &lt;+&gt; device)
     (Seq ('DataType 'Bool &lt;+&gt; 'DataType 'Bool) transformerDataType)
     (BroadcastShapesF
        (BroadcastShapesF
           ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim])
           (UnsqueezeF ('SelectDim ('ByIndex 1)) shape))
        ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim]))
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]) value
       (gradient' :: Gradient RequiresGradient)
       (layout' :: Layout LayoutType) (device' :: Device (DeviceType Nat))
       (dataType' :: DataType DType)
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]).
Scalar value =&gt;
Tensor gradient layout device dataType shape
-&gt; value
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; Tensor
     (Seq (gradient &lt;+&gt; 'Gradient 'WithoutGradient) gradient')
     (layout &lt;+&gt; (layout' &lt;+&gt; 'Layout 'Dense))
     (device &lt;+&gt; device')
     (Seq (dataType &lt;+&gt; 'DataType 'Bool) dataType')
     (BroadcastShapesF shape shape')
</span><a href="Torch.GraduallyTyped.Tensor.Other.html#maskedFill"><span class="hs-identifier hs-var">maskedFill</span></a></span><span>
</span><span id="line-578"></span><span>      </span><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  layout
  device
  ('DataType 'Bool)
  (BroadcastShapesF
     ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim])
     (UnsqueezeF ('SelectDim ('ByIndex 1)) shape))
Tensor
  ('Gradient 'WithoutGradient)
  (layout &lt;+&gt; layout)
  (device &lt;+&gt; device)
  ('DataType 'Bool)
  (BroadcastShapesF
     ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim])
     (UnsqueezeF ('SelectDim ('ByIndex 1)) shape))
</span><a href="#local-6989586621679571648"><span class="hs-identifier hs-var">booleanMask</span></a></span><span>
</span><span id="line-579"></span><span>      </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679571656"><span class="hs-identifier hs-var">attentionMaskBias</span></a></span><span>
</span><span id="line-580"></span><span>      </span><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  layout
  device
  transformerDataType
  ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim])
</span><a href="#local-6989586621679571649"><span class="hs-identifier hs-var">emptyMask</span></a></span><span>
</span><span id="line-581"></span><span>
</span><span id="line-582"></span><span class="hs-keyword">data</span><span> </span><span id="MkTransformerDecoderAttentionMask"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerDecoderAttentionMask"><span class="hs-identifier hs-var">MkTransformerDecoderAttentionMask</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679571647"><span class="annot"><a href="#local-6989586621679571647"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier hs-type">DType</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-583"></span><span>  </span><span id="MkTransformerDecoderAttentionMask"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerDecoderAttentionMask"><span class="hs-identifier hs-var">MkTransformerDecoderAttentionMask</span></a></span></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-584"></span><span>    </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679572162"><span class="annot"><a href="#local-6989586621679572162"><span class="hs-identifier hs-type">dataType</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-585"></span><span>    </span><span class="hs-special">{</span><span> </span><span id="decoderAttentionMaskDataType"><span class="annot"><span class="annottext">MkTransformerDecoderAttentionMask dataType -&gt; SDataType dataType
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#decoderAttentionMaskDataType"><span class="hs-identifier hs-var hs-var">decoderAttentionMaskDataType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier hs-type">SDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679572162"><span class="hs-identifier hs-type">dataType</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-586"></span><span>      </span><span id="decoderAttentionMaskBias"><span class="annot"><span class="annottext">MkTransformerDecoderAttentionMask dataType -&gt; Double
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#decoderAttentionMaskBias"><span class="hs-identifier hs-var hs-var">decoderAttentionMaskBias</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span>
</span><span id="line-587"></span><span>    </span><span class="hs-special">}</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-588"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerDecoderAttentionMask"><span class="hs-identifier hs-type">MkTransformerDecoderAttentionMask</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679572162"><span class="hs-identifier hs-type">dataType</span></a></span><span>
</span><span id="line-589"></span><span>
</span><span id="line-590"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">instance</span><span>
</span><span id="line-591"></span><span>  </span><span id="ModelSpec"><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier hs-var">ModelSpec</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerDecoderAttentionMask"><span class="hs-identifier hs-type">MkTransformerDecoderAttentionMask</span></a></span><span> </span><span id="local-6989586621679571643"><span class="annot"><a href="#local-6989586621679571643"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-592"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerDecoderAttentionMask"><span class="hs-identifier hs-type">MkTransformerDecoderAttentionMask</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571643"><span class="hs-identifier hs-type">dataType</span></a></span><span>
</span><span id="line-593"></span><span>
</span><span id="line-594"></span><span id="local-6989586621679571641"><span id="local-6989586621679571642"><span class="hs-keyword">instance</span><span>
</span><span id="line-595"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span>
</span><span id="line-596"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerDecoderAttentionMask"><span class="hs-identifier hs-type">MkTransformerDecoderAttentionMask</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571642"><span class="hs-identifier hs-type">dataType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-597"></span><span>    </span><span class="annot"><a href="#local-6989586621679571641"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-598"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerDecoderAttentionMask"><span class="hs-identifier hs-type">MkTransformerDecoderAttentionMask</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571642"><span class="hs-identifier hs-type">dataType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-599"></span><span>    </span><span class="annot"><a href="#local-6989586621679571641"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-600"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-601"></span><span>  </span><span id="local-6989586621679571639"><span class="annot"><span class="annottext">initialize :: ModelSpec (MkTransformerDecoderAttentionMask dataType)
-&gt; Generator generatorDevice
-&gt; m (MkTransformerDecoderAttentionMask dataType,
      Generator generatorDevice)
</span><a href="#local-6989586621679571639"><span class="hs-identifier hs-var hs-var hs-var hs-var">initialize</span></a></span></span><span> </span><span id="local-6989586621679571638"><span class="annot"><span class="annottext">ModelSpec (MkTransformerDecoderAttentionMask dataType)
</span><a href="#local-6989586621679571638"><span class="hs-identifier hs-var">spec</span></a></span></span><span> </span><span id="local-6989586621679571637"><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679571637"><span class="hs-identifier hs-var">g</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(MkTransformerDecoderAttentionMask dataType,
 Generator generatorDevice)
-&gt; m (MkTransformerDecoderAttentionMask dataType,
      Generator generatorDevice)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">ModelSpec (MkTransformerDecoderAttentionMask dataType)
MkTransformerDecoderAttentionMask dataType
</span><a href="#local-6989586621679571638"><span class="hs-identifier hs-var">spec</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679571637"><span class="hs-identifier hs-var">g</span></a></span><span class="hs-special">)</span></span></span><span>
</span><span id="line-602"></span><span>
</span><span id="line-603"></span><span id="local-6989586621679571636"><span class="hs-keyword">instance</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasStateDict"><span class="hs-identifier hs-type">HasStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerDecoderAttentionMask"><span class="hs-identifier hs-type">MkTransformerDecoderAttentionMask</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571636"><span class="hs-identifier hs-type">dataType</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-604"></span><span>  </span><span id="local-6989586621679571633"><span class="annot"><span class="annottext">fromStateDict :: ModelSpec (MkTransformerDecoderAttentionMask dataType)
-&gt; StateDictKey -&gt; m (MkTransformerDecoderAttentionMask dataType)
</span><a href="#local-6989586621679571633"><span class="hs-identifier hs-var hs-var hs-var hs-var">fromStateDict</span></a></span></span><span> </span><span id="local-6989586621679571632"><span class="annot"><span class="annottext">ModelSpec (MkTransformerDecoderAttentionMask dataType)
</span><a href="#local-6989586621679571632"><span class="hs-identifier hs-var">spec</span></a></span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">MkTransformerDecoderAttentionMask dataType
-&gt; m (MkTransformerDecoderAttentionMask dataType)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">ModelSpec (MkTransformerDecoderAttentionMask dataType)
MkTransformerDecoderAttentionMask dataType
</span><a href="#local-6989586621679571632"><span class="hs-identifier hs-var">spec</span></a></span><span>
</span><span id="line-605"></span><span>  </span><span id="local-6989586621679571631"><span class="annot"><span class="annottext">toStateDict :: StateDictKey -&gt; MkTransformerDecoderAttentionMask dataType -&gt; m ()
</span><a href="#local-6989586621679571631"><span class="hs-identifier hs-var hs-var hs-var hs-var">toStateDict</span></a></span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="annottext">MkTransformerDecoderAttentionMask dataType
</span><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">() -&gt; m ()
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span></span><span>
</span><span id="line-606"></span><span>
</span><span id="line-607"></span><span id="local-6989586621679571622"><span id="local-6989586621679571623"><span id="local-6989586621679571624"><span id="local-6989586621679571625"><span id="local-6989586621679571626"><span id="local-6989586621679571627"><span id="local-6989586621679571628"><span id="local-6989586621679571629"><span id="local-6989586621679571630"><span class="hs-keyword">instance</span><span>
</span><span id="line-608"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerDecoderAttentionMaskC"><span class="hs-identifier hs-type">MkTransformerDecoderAttentionMaskC</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571630"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571629"><span class="hs-identifier hs-type">decoderInputLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571628"><span class="hs-identifier hs-type">decoderInputDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571627"><span class="hs-identifier hs-type">decoderInputShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571626"><span class="hs-identifier hs-type">seqDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571625"><span class="hs-identifier hs-type">output</span></a></span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-609"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-610"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerDecoderAttentionMask"><span class="hs-identifier hs-type">MkTransformerDecoderAttentionMask</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571630"><span class="hs-identifier hs-type">dataType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-611"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571624"><span class="hs-identifier hs-type">decoderInputGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571629"><span class="hs-identifier hs-type">decoderInputLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571628"><span class="hs-identifier hs-type">decoderInputDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571623"><span class="hs-identifier hs-type">decoderInputDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571627"><span class="hs-identifier hs-type">decoderInputShape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-612"></span><span>    </span><span class="annot"><a href="#local-6989586621679571622"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-613"></span><span>    </span><span class="annot"><a href="#local-6989586621679571625"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-614"></span><span>    </span><span class="annot"><a href="#local-6989586621679571622"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-615"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-616"></span><span>  </span><span id="local-6989586621679571620"><span class="annot"><span class="annottext">forward :: MkTransformerDecoderAttentionMask dataType
-&gt; Tensor
     decoderInputGradient
     decoderInputLayout
     decoderInputDevice
     decoderInputDataType
     decoderInputShape
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorDevice)
</span><a href="#local-6989586621679571620"><span class="hs-identifier hs-var hs-var hs-var hs-var">forward</span></a></span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerDecoderAttentionMask"><span class="hs-identifier hs-type">MkTransformerDecoderAttentionMask</span></a></span><span> </span><span class="hs-special">{</span><span id="local-6989586621679571618"><span id="local-6989586621679571619"><span class="annot"><span class="annottext">Double
SDataType dataType
decoderAttentionMaskBias :: Double
decoderAttentionMaskDataType :: SDataType dataType
decoderAttentionMaskBias :: forall (dataType :: DataType DType).
MkTransformerDecoderAttentionMask dataType -&gt; Double
decoderAttentionMaskDataType :: forall (dataType :: DataType DType).
MkTransformerDecoderAttentionMask dataType -&gt; SDataType dataType
</span><a href="#local-6989586621679571618"><span class="hs-glyph hs-var hs-var hs-var hs-var">..</span></a></span></span></span><span class="hs-special">}</span><span> </span><span id="local-6989586621679571617"><span class="annot"><span class="annottext">Tensor
  decoderInputGradient
  decoderInputLayout
  decoderInputDevice
  decoderInputDataType
  decoderInputShape
</span><a href="#local-6989586621679571617"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span id="local-6989586621679571616"><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679571616"><span class="hs-identifier hs-var">g</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-617"></span><span>    </span><span id="local-6989586621679571615"><span class="annot"><span class="annottext">output
</span><a href="#local-6989586621679571615"><span class="hs-identifier hs-var">decoderAttentionMask</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">SDataType dataType
-&gt; Double
-&gt; Tensor
     decoderInputGradient
     decoderInputLayout
     decoderInputDevice
     decoderInputDataType
     decoderInputShape
-&gt; m output
forall (m :: * -&gt; *) (transformerDataType :: DataType DType)
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (seqDim :: Dim (Name Symbol) (Size Nat)) output.
(MonadThrow m,
 MkTransformerDecoderAttentionMaskC
   transformerDataType layout device shape seqDim output) =&gt;
SDataType transformerDataType
-&gt; Double
-&gt; Tensor gradient layout device dataType shape
-&gt; m output
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#mkTransformerDecoderAttentionMask"><span class="hs-identifier hs-var">mkTransformerDecoderAttentionMask</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679571619"><span class="hs-identifier hs-var">decoderAttentionMaskDataType</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679571618"><span class="hs-identifier hs-var">decoderAttentionMaskBias</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  decoderInputGradient
  decoderInputLayout
  decoderInputDevice
  decoderInputDataType
  decoderInputShape
</span><a href="#local-6989586621679571617"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-618"></span><span>    </span><span class="annot"><span class="annottext">(output, Generator generatorDevice)
-&gt; m (output, Generator generatorDevice)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">output
</span><a href="#local-6989586621679571615"><span class="hs-identifier hs-var">decoderAttentionMask</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679571616"><span class="hs-identifier hs-var">g</span></a></span><span class="hs-special">)</span></span></span></span></span></span></span></span></span></span><span>
</span><span id="line-619"></span><span>
</span><span id="line-620"></span><span class="hs-keyword">type</span><span> </span><span id="MkTransformerCrossAttentionMaskC"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerCrossAttentionMaskC"><span class="hs-identifier hs-var">MkTransformerCrossAttentionMaskC</span></a></span></span><span> </span><span id="local-6989586621679571614"><span class="annot"><a href="#local-6989586621679571614"><span class="hs-identifier hs-type">transformerDataType</span></a></span></span><span> </span><span id="local-6989586621679571613"><span class="annot"><a href="#local-6989586621679571613"><span class="hs-identifier hs-type">decoderInputShape</span></a></span></span><span> </span><span id="local-6989586621679571612"><span class="annot"><a href="#local-6989586621679571612"><span class="hs-identifier hs-type">decoderInputSeqDim</span></a></span></span><span> </span><span id="local-6989586621679571611"><span class="annot"><a href="#local-6989586621679571611"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679571610"><span class="annot"><a href="#local-6989586621679571610"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679571609"><span class="annot"><a href="#local-6989586621679571609"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679571608"><span class="annot"><a href="#local-6989586621679571608"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679571607"><span class="annot"><a href="#local-6989586621679571607"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679571606"><span class="annot"><a href="#local-6989586621679571606"><span class="hs-identifier hs-type">seqDim</span></a></span></span><span> </span><span id="local-6989586621679571605"><span class="annot"><a href="#local-6989586621679571605"><span class="hs-identifier hs-type">output</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-621"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetLayout"><span class="hs-identifier hs-type">SGetLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571610"><span class="hs-identifier hs-type">layout</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-622"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetDevice"><span class="hs-identifier hs-type">SGetDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571609"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-623"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetShape"><span class="hs-identifier hs-type">SGetShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571607"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-624"></span><span>    </span><span class="annot"><a href="#local-6989586621679571606"><span class="hs-identifier hs-type">seqDim</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679571607"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#%21"><span class="hs-glyph hs-type">!</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-625"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetShape"><span class="hs-identifier hs-type">SGetShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571613"><span class="hs-identifier hs-type">decoderInputShape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-626"></span><span>    </span><span class="annot"><a href="#local-6989586621679571612"><span class="hs-identifier hs-type">decoderInputSeqDim</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679571613"><span class="hs-identifier hs-type">decoderInputShape</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#%21"><span class="hs-glyph hs-type">!</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-627"></span><span>    </span><span class="annot"><a href="#local-6989586621679571605"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-628"></span><span>      </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-629"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Seq"><span class="hs-identifier hs-type">Seq</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679571611"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#WithoutGradient"><span class="hs-identifier hs-type">WithoutGradient</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#WithoutGradient"><span class="hs-identifier hs-type">WithoutGradient</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-630"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679571610"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Dense"><span class="hs-identifier hs-type">Dense</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-631"></span><span>          </span><span class="annot"><a href="#local-6989586621679571609"><span class="hs-identifier hs-type">device</span></a></span><span>
</span><span id="line-632"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Seq"><span class="hs-identifier hs-type">Seq</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679571608"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#Bool"><span class="hs-identifier hs-type">Bool</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679571614"><span class="hs-identifier hs-type">transformerDataType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-633"></span><span>          </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#BroadcastShapesF"><span class="hs-identifier hs-type">BroadcastShapesF</span></a></span><span>
</span><span id="line-634"></span><span>              </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#UnsqueezeF"><span class="hs-identifier hs-type">UnsqueezeF</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679571607"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-635"></span><span>              </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679571612"><span class="hs-identifier hs-type">decoderInputSeqDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679571606"><span class="hs-identifier hs-type">seqDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-636"></span><span>          </span><span class="hs-special">)</span><span>
</span><span id="line-637"></span><span>  </span><span class="hs-special">)</span><span>
</span><span id="line-638"></span><span>
</span><span id="line-639"></span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#mkTransformerCrossAttentionMask"><span class="hs-identifier hs-type">mkTransformerCrossAttentionMask</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-640"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679572114"><span class="annot"><a href="#local-6989586621679572114"><span class="hs-identifier hs-type">m</span></a></span></span><span> </span><span id="local-6989586621679572113"><span class="annot"><a href="#local-6989586621679572113"><span class="hs-identifier hs-type">transformerDataType</span></a></span></span><span> </span><span id="local-6989586621679572112"><span class="annot"><a href="#local-6989586621679572112"><span class="hs-identifier hs-type">decoderInputShape</span></a></span></span><span> </span><span id="local-6989586621679572111"><span class="annot"><a href="#local-6989586621679572111"><span class="hs-identifier hs-type">decoderInputSeqDim</span></a></span></span><span> </span><span id="local-6989586621679572110"><span class="annot"><a href="#local-6989586621679572110"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679572109"><span class="annot"><a href="#local-6989586621679572109"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679572108"><span class="annot"><a href="#local-6989586621679572108"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679572107"><span class="annot"><a href="#local-6989586621679572107"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679572106"><span class="annot"><a href="#local-6989586621679572106"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679572105"><span class="annot"><a href="#local-6989586621679572105"><span class="hs-identifier hs-type">seqDim</span></a></span></span><span> </span><span id="local-6989586621679572104"><span class="annot"><a href="#local-6989586621679572104"><span class="hs-identifier hs-type">output</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-641"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier hs-type">MonadThrow</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679572114"><span class="hs-identifier hs-type">m</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-642"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerCrossAttentionMaskC"><span class="hs-identifier hs-type">MkTransformerCrossAttentionMaskC</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679572113"><span class="hs-identifier hs-type">transformerDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679572112"><span class="hs-identifier hs-type">decoderInputShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679572111"><span class="hs-identifier hs-type">decoderInputSeqDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679572110"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679572109"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679572108"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679572107"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679572106"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679572105"><span class="hs-identifier hs-type">seqDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679572104"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-643"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-644"></span><span>  </span><span class="hs-comment">-- | data type singleton of the transformer</span><span>
</span><span id="line-645"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier hs-type">SDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679572113"><span class="hs-identifier hs-type">transformerDataType</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-646"></span><span>  </span><span class="hs-comment">-- | decoder input shape</span><span>
</span><span id="line-647"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-type">SShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679572112"><span class="hs-identifier hs-type">decoderInputShape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-648"></span><span>  </span><span class="hs-comment">-- | attention mask bias (typically a large negative number)</span><span>
</span><span id="line-649"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-650"></span><span>  </span><span class="hs-comment">-- | encoder padding mask</span><span>
</span><span id="line-651"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679572110"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679572109"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679572108"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679572107"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679572106"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-652"></span><span>  </span><span class="annot"><a href="#local-6989586621679572114"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679572104"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-653"></span><span id="mkTransformerCrossAttentionMask"><span class="annot"><span class="annottext">mkTransformerCrossAttentionMask :: SDataType transformerDataType
-&gt; SShape decoderInputShape
-&gt; Double
-&gt; Tensor gradient layout device dataType shape
-&gt; m output
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#mkTransformerCrossAttentionMask"><span class="hs-identifier hs-var hs-var">mkTransformerCrossAttentionMask</span></a></span></span><span> </span><span id="local-6989586621679571603"><span class="annot"><span class="annottext">SDataType transformerDataType
</span><a href="#local-6989586621679571603"><span class="hs-identifier hs-var">transformerDataType</span></a></span></span><span> </span><span id="local-6989586621679571602"><span class="annot"><span class="annottext">SShape decoderInputShape
</span><a href="#local-6989586621679571602"><span class="hs-identifier hs-var">decoderInputShape</span></a></span></span><span> </span><span id="local-6989586621679571601"><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679571601"><span class="hs-identifier hs-var">attentionMaskBias</span></a></span></span><span> </span><span id="local-6989586621679571600"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679571600"><span class="hs-identifier hs-var">paddingMask</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-654"></span><span>  </span><span id="local-6989586621679571599"><span class="annot"><span class="annottext">SDim decoderInputSeqDim
</span><a href="#local-6989586621679571599"><span class="hs-identifier hs-var">decoderInputSeqDim</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">SSelectDim ('SelectDim ('ByIndex 1))
-&gt; SShape decoderInputShape -&gt; m (SDim decoderInputSeqDim)
forall (selectDim :: SelectDim (By Symbol Nat))
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (dim :: Dim (Name Symbol) (Size Nat)) (m :: * -&gt; *).
(dim ~ GetDimF selectDim shape, MonadThrow m) =&gt;
SSelectDim selectDim -&gt; SShape shape -&gt; m (SDim dim)
</span><a href="Torch.GraduallyTyped.Shape.Class.html#sGetDimFromShape"><span class="hs-identifier hs-var">sGetDimFromShape</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SBy ('ByIndex 1) -&gt; SSelectDim ('SelectDim ('ByIndex 1))
forall (by :: By Symbol Nat). SBy by -&gt; SSelectDim ('SelectDim by)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSelectDim"><span class="hs-identifier hs-var">SSelectDim</span></a></span><span> </span><span class="annot"><span class="annottext">(SBy ('ByIndex 1) -&gt; SSelectDim ('SelectDim ('ByIndex 1)))
-&gt; SBy ('ByIndex 1) -&gt; SSelectDim ('SelectDim ('ByIndex 1))
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">KnownNat 1 =&gt; SBy ('ByIndex 1)
forall (index :: Nat). KnownNat index =&gt; SBy ('ByIndex index)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SByIndex"><span class="hs-identifier hs-var">SByIndex</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">SShape decoderInputShape
</span><a href="#local-6989586621679571602"><span class="hs-identifier hs-var">decoderInputShape</span></a></span><span>
</span><span id="line-655"></span><span>  </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679571598"><span class="annot"><span class="annottext">pmLayout :: SLayout layout
</span><a href="#local-6989586621679571598"><span class="hs-identifier hs-var hs-var">pmLayout</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape -&gt; SLayout layout
forall (layout :: Layout LayoutType)
       (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SGetLayout layout =&gt;
Tensor gradient layout device dataType shape -&gt; SLayout layout
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sGetLayout"><span class="hs-identifier hs-var">sGetLayout</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679571600"><span class="hs-identifier hs-var">paddingMask</span></a></span><span>
</span><span id="line-656"></span><span>      </span><span id="local-6989586621679571597"><span class="annot"><span class="annottext">pmDevice :: SDevice device
</span><a href="#local-6989586621679571597"><span class="hs-identifier hs-var hs-var">pmDevice</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape -&gt; SDevice device
forall (device :: Device (DeviceType Nat))
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SGetDevice device =&gt;
Tensor gradient layout device dataType shape -&gt; SDevice device
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sGetDevice"><span class="hs-identifier hs-var">sGetDevice</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679571600"><span class="hs-identifier hs-var">paddingMask</span></a></span><span>
</span><span id="line-657"></span><span>      </span><span id="local-6989586621679571596"><span class="annot"><span class="annottext">pmShape :: SShape shape
</span><a href="#local-6989586621679571596"><span class="hs-identifier hs-var hs-var">pmShape</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape -&gt; SShape shape
forall (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType).
SGetShape shape =&gt;
Tensor gradient layout device dataType shape -&gt; SShape shape
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sGetShape"><span class="hs-identifier hs-var">sGetShape</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679571600"><span class="hs-identifier hs-var">paddingMask</span></a></span><span>
</span><span id="line-658"></span><span>  </span><span id="local-6989586621679571595"><span class="annot"><span class="annottext">SDim seqDim
</span><a href="#local-6989586621679571595"><span class="hs-identifier hs-var">pmSeqDim</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">SSelectDim ('SelectDim ('ByIndex 1))
-&gt; SShape shape -&gt; m (SDim seqDim)
forall (selectDim :: SelectDim (By Symbol Nat))
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (dim :: Dim (Name Symbol) (Size Nat)) (m :: * -&gt; *).
(dim ~ GetDimF selectDim shape, MonadThrow m) =&gt;
SSelectDim selectDim -&gt; SShape shape -&gt; m (SDim dim)
</span><a href="Torch.GraduallyTyped.Shape.Class.html#sGetDimFromShape"><span class="hs-identifier hs-var">sGetDimFromShape</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SBy ('ByIndex 1) -&gt; SSelectDim ('SelectDim ('ByIndex 1))
forall (by :: By Symbol Nat). SBy by -&gt; SSelectDim ('SelectDim by)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSelectDim"><span class="hs-identifier hs-var">SSelectDim</span></a></span><span> </span><span class="annot"><span class="annottext">(SBy ('ByIndex 1) -&gt; SSelectDim ('SelectDim ('ByIndex 1)))
-&gt; SBy ('ByIndex 1) -&gt; SSelectDim ('SelectDim ('ByIndex 1))
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">KnownNat 1 =&gt; SBy ('ByIndex 1)
forall (index :: Nat). KnownNat index =&gt; SBy ('ByIndex index)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SByIndex"><span class="hs-identifier hs-var">SByIndex</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">SShape shape
</span><a href="#local-6989586621679571596"><span class="hs-identifier hs-var">pmShape</span></a></span><span>
</span><span id="line-659"></span><span>  </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679571594"><span class="annot"><span class="annottext">emptyMask :: Tensor
  ('Gradient 'WithoutGradient)
  layout
  device
  transformerDataType
  ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), decoderInputSeqDim, seqDim])
</span><a href="#local-6989586621679571594"><span class="hs-identifier hs-var hs-var">emptyMask</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">TensorSpec
  ('Gradient 'WithoutGradient)
  layout
  device
  transformerDataType
  ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), decoderInputSeqDim, seqDim])
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     layout
     device
     transformerDataType
     ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), decoderInputSeqDim, seqDim])
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
TensorSpec gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.Creation.html#sZeros"><span class="hs-identifier hs-var">sZeros</span></a></span><span> </span><span class="annot"><span class="annottext">(TensorSpec
   ('Gradient 'WithoutGradient)
   layout
   device
   transformerDataType
   ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), decoderInputSeqDim, seqDim])
 -&gt; Tensor
      ('Gradient 'WithoutGradient)
      layout
      device
      transformerDataType
      ('Shape
         '[ 'Dim ('Name &quot;*&quot;) ('Size 1), decoderInputSeqDim, seqDim]))
-&gt; TensorSpec
     ('Gradient 'WithoutGradient)
     layout
     device
     transformerDataType
     ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), decoderInputSeqDim, seqDim])
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     layout
     device
     transformerDataType
     ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), decoderInputSeqDim, seqDim])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SGradient ('Gradient 'WithoutGradient)
-&gt; SLayout layout
-&gt; SDevice device
-&gt; SDataType transformerDataType
-&gt; SShape
     ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), decoderInputSeqDim, seqDim])
-&gt; TensorSpec
     ('Gradient 'WithoutGradient)
     layout
     device
     transformerDataType
     ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), decoderInputSeqDim, seqDim])
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SShape shape
-&gt; TensorSpec gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorSpec"><span class="hs-identifier hs-var">TensorSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SRequiresGradient 'WithoutGradient
-&gt; SGradient ('Gradient 'WithoutGradient)
forall (requiresGradient :: RequiresGradient).
SRequiresGradient requiresGradient
-&gt; SGradient ('Gradient requiresGradient)
</span><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier hs-var">SGradient</span></a></span><span> </span><span class="annot"><span class="annottext">SRequiresGradient 'WithoutGradient
</span><a href="Torch.GraduallyTyped.RequiresGradient.html#SWithoutGradient"><span class="hs-identifier hs-var">SWithoutGradient</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">SLayout layout
</span><a href="#local-6989586621679571598"><span class="hs-identifier hs-var">pmLayout</span></a></span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679571597"><span class="hs-identifier hs-var">pmDevice</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType transformerDataType
</span><a href="#local-6989586621679571603"><span class="hs-identifier hs-var">transformerDataType</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SList '[ 'Dim ('Name &quot;*&quot;) ('Size 1), decoderInputSeqDim, seqDim]
-&gt; SShape
     ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), decoderInputSeqDim, seqDim])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList '[ 'Dim ('Name &quot;*&quot;) ('Size 1), decoderInputSeqDim, seqDim]
 -&gt; SShape
      ('Shape
         '[ 'Dim ('Name &quot;*&quot;) ('Size 1), decoderInputSeqDim, seqDim]))
-&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 1), decoderInputSeqDim, seqDim]
-&gt; SShape
     ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), decoderInputSeqDim, seqDim])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize ('Size 1) -&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 1))
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownNat 1 =&gt; SSize ('Size 1)
forall (size :: Nat). KnownNat size =&gt; SSize ('Size size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier hs-var">SSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">1</span></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 1))
-&gt; SList '[decoderInputSeqDim, seqDim]
-&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 1), decoderInputSeqDim, seqDim]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SDim decoderInputSeqDim
</span><a href="#local-6989586621679571599"><span class="hs-identifier hs-var">decoderInputSeqDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim decoderInputSeqDim
-&gt; SList '[seqDim] -&gt; SList '[decoderInputSeqDim, seqDim]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SDim seqDim
</span><a href="#local-6989586621679571595"><span class="hs-identifier hs-var">pmSeqDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim seqDim -&gt; SList '[] -&gt; SList '[seqDim]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-660"></span><span>  </span><span class="annot"><span class="annottext">output -&gt; m output
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">(output -&gt; m output) -&gt; output -&gt; m output
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">Tensor
  gradient
  layout
  device
  dataType
  (UnsqueezeF ('SelectDim ('ByIndex 1)) shape)
-&gt; Double
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     layout
     device
     transformerDataType
     ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), decoderInputSeqDim, seqDim])
-&gt; Tensor
     (Seq
        (gradient &lt;+&gt; 'Gradient 'WithoutGradient)
        ('Gradient 'WithoutGradient))
     (layout &lt;+&gt; (layout &lt;+&gt; 'Layout 'Dense))
     (device &lt;+&gt; device)
     (Seq (dataType &lt;+&gt; 'DataType 'Bool) transformerDataType)
     (BroadcastShapesF
        (UnsqueezeF ('SelectDim ('ByIndex 1)) shape)
        ('Shape
           '[ 'Dim ('Name &quot;*&quot;) ('Size 1), decoderInputSeqDim, seqDim]))
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]) value
       (gradient' :: Gradient RequiresGradient)
       (layout' :: Layout LayoutType) (device' :: Device (DeviceType Nat))
       (dataType' :: DataType DType)
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]).
Scalar value =&gt;
Tensor gradient layout device dataType shape
-&gt; value
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; Tensor
     (Seq (gradient &lt;+&gt; 'Gradient 'WithoutGradient) gradient')
     (layout &lt;+&gt; (layout' &lt;+&gt; 'Layout 'Dense))
     (device &lt;+&gt; device')
     (Seq (dataType &lt;+&gt; 'DataType 'Bool) dataType')
     (BroadcastShapesF shape shape')
</span><a href="Torch.GraduallyTyped.Tensor.Other.html#maskedFill"><span class="hs-identifier hs-var">maskedFill</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
-&gt; Tensor
     gradient
     layout
     device
     dataType
     (UnsqueezeF ('SelectDim ('ByIndex 1)) shape)
forall (selectDim :: SelectDim (By Symbol Nat))
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]).
(shape' ~ UnsqueezeF selectDim shape, SingI selectDim) =&gt;
Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape'
</span><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#unsqueeze"><span class="hs-identifier hs-var">unsqueeze</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679571600"><span class="hs-identifier hs-var">paddingMask</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679571601"><span class="hs-identifier hs-var">attentionMaskBias</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  layout
  device
  transformerDataType
  ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), decoderInputSeqDim, seqDim])
</span><a href="#local-6989586621679571594"><span class="hs-identifier hs-var">emptyMask</span></a></span><span>
</span><span id="line-661"></span><span>
</span><span id="line-662"></span><span class="hs-keyword">data</span><span> </span><span id="MkTransformerCrossAttentionMask"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerCrossAttentionMask"><span class="hs-identifier hs-var">MkTransformerCrossAttentionMask</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679571593"><span class="annot"><a href="#local-6989586621679571593"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier hs-type">DType</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-663"></span><span>  </span><span id="MkTransformerCrossAttentionMask"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerCrossAttentionMask"><span class="hs-identifier hs-var">MkTransformerCrossAttentionMask</span></a></span></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-664"></span><span>    </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679572115"><span class="annot"><a href="#local-6989586621679572115"><span class="hs-identifier hs-type">dataType</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-665"></span><span>    </span><span class="hs-special">{</span><span> </span><span id="crossAttentionMaskDataType"><span class="annot"><span class="annottext">MkTransformerCrossAttentionMask dataType -&gt; SDataType dataType
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#crossAttentionMaskDataType"><span class="hs-identifier hs-var hs-var">crossAttentionMaskDataType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier hs-type">SDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679572115"><span class="hs-identifier hs-type">dataType</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-666"></span><span>      </span><span id="crossAttentionMaskBias"><span class="annot"><span class="annottext">MkTransformerCrossAttentionMask dataType -&gt; Double
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#crossAttentionMaskBias"><span class="hs-identifier hs-var hs-var">crossAttentionMaskBias</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span>
</span><span id="line-667"></span><span>    </span><span class="hs-special">}</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-668"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerCrossAttentionMask"><span class="hs-identifier hs-type">MkTransformerCrossAttentionMask</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679572115"><span class="hs-identifier hs-type">dataType</span></a></span><span>
</span><span id="line-669"></span><span>
</span><span id="line-670"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">instance</span><span>
</span><span id="line-671"></span><span>  </span><span id="ModelSpec"><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier hs-var">ModelSpec</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerCrossAttentionMask"><span class="hs-identifier hs-type">MkTransformerCrossAttentionMask</span></a></span><span> </span><span id="local-6989586621679571589"><span class="annot"><a href="#local-6989586621679571589"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-672"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerCrossAttentionMask"><span class="hs-identifier hs-type">MkTransformerCrossAttentionMask</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571589"><span class="hs-identifier hs-type">dataType</span></a></span><span>
</span><span id="line-673"></span><span>
</span><span id="line-674"></span><span id="local-6989586621679571587"><span id="local-6989586621679571588"><span class="hs-keyword">instance</span><span>
</span><span id="line-675"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span>
</span><span id="line-676"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerCrossAttentionMask"><span class="hs-identifier hs-type">MkTransformerCrossAttentionMask</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571588"><span class="hs-identifier hs-type">dataType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-677"></span><span>    </span><span class="annot"><a href="#local-6989586621679571587"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-678"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerCrossAttentionMask"><span class="hs-identifier hs-type">MkTransformerCrossAttentionMask</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571588"><span class="hs-identifier hs-type">dataType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-679"></span><span>    </span><span class="annot"><a href="#local-6989586621679571587"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-680"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-681"></span><span>  </span><span id="local-6989586621679571585"><span class="annot"><span class="annottext">initialize :: ModelSpec (MkTransformerCrossAttentionMask dataType)
-&gt; Generator generatorDevice
-&gt; m (MkTransformerCrossAttentionMask dataType,
      Generator generatorDevice)
</span><a href="#local-6989586621679571585"><span class="hs-identifier hs-var hs-var hs-var hs-var">initialize</span></a></span></span><span> </span><span id="local-6989586621679571584"><span class="annot"><span class="annottext">ModelSpec (MkTransformerCrossAttentionMask dataType)
</span><a href="#local-6989586621679571584"><span class="hs-identifier hs-var">spec</span></a></span></span><span> </span><span id="local-6989586621679571583"><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679571583"><span class="hs-identifier hs-var">g</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(MkTransformerCrossAttentionMask dataType,
 Generator generatorDevice)
-&gt; m (MkTransformerCrossAttentionMask dataType,
      Generator generatorDevice)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">ModelSpec (MkTransformerCrossAttentionMask dataType)
MkTransformerCrossAttentionMask dataType
</span><a href="#local-6989586621679571584"><span class="hs-identifier hs-var">spec</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679571583"><span class="hs-identifier hs-var">g</span></a></span><span class="hs-special">)</span></span></span><span>
</span><span id="line-682"></span><span>
</span><span id="line-683"></span><span id="local-6989586621679571582"><span class="hs-keyword">instance</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasStateDict"><span class="hs-identifier hs-type">HasStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerCrossAttentionMask"><span class="hs-identifier hs-type">MkTransformerCrossAttentionMask</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571582"><span class="hs-identifier hs-type">dataType</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-684"></span><span>  </span><span id="local-6989586621679571579"><span class="annot"><span class="annottext">fromStateDict :: ModelSpec (MkTransformerCrossAttentionMask dataType)
-&gt; StateDictKey -&gt; m (MkTransformerCrossAttentionMask dataType)
</span><a href="#local-6989586621679571579"><span class="hs-identifier hs-var hs-var hs-var hs-var">fromStateDict</span></a></span></span><span> </span><span id="local-6989586621679571578"><span class="annot"><span class="annottext">ModelSpec (MkTransformerCrossAttentionMask dataType)
</span><a href="#local-6989586621679571578"><span class="hs-identifier hs-var">spec</span></a></span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">MkTransformerCrossAttentionMask dataType
-&gt; m (MkTransformerCrossAttentionMask dataType)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">ModelSpec (MkTransformerCrossAttentionMask dataType)
MkTransformerCrossAttentionMask dataType
</span><a href="#local-6989586621679571578"><span class="hs-identifier hs-var">spec</span></a></span><span>
</span><span id="line-685"></span><span>  </span><span id="local-6989586621679571577"><span class="annot"><span class="annottext">toStateDict :: StateDictKey -&gt; MkTransformerCrossAttentionMask dataType -&gt; m ()
</span><a href="#local-6989586621679571577"><span class="hs-identifier hs-var hs-var hs-var hs-var">toStateDict</span></a></span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="annottext">MkTransformerCrossAttentionMask dataType
</span><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">() -&gt; m ()
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span></span><span>
</span><span id="line-686"></span><span>
</span><span id="line-687"></span><span id="local-6989586621679571562"><span id="local-6989586621679571563"><span id="local-6989586621679571564"><span id="local-6989586621679571565"><span id="local-6989586621679571566"><span id="local-6989586621679571567"><span id="local-6989586621679571568"><span id="local-6989586621679571569"><span id="local-6989586621679571570"><span id="local-6989586621679571571"><span id="local-6989586621679571572"><span id="local-6989586621679571573"><span id="local-6989586621679571574"><span id="local-6989586621679571575"><span id="local-6989586621679571576"><span class="hs-keyword">instance</span><span>
</span><span id="line-688"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerCrossAttentionMaskC"><span class="hs-identifier hs-type">MkTransformerCrossAttentionMaskC</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571576"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571575"><span class="hs-identifier hs-type">decoderInputShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571574"><span class="hs-identifier hs-type">decoderInputSeqDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571573"><span class="hs-identifier hs-type">inputPaddingMaskGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571572"><span class="hs-identifier hs-type">inputPaddingMaskLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571571"><span class="hs-identifier hs-type">inputPaddingMaskDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571570"><span class="hs-identifier hs-type">inputPaddingMaksDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571569"><span class="hs-identifier hs-type">inputPaddingMaskShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571568"><span class="hs-identifier hs-type">seqDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571567"><span class="hs-identifier hs-type">output</span></a></span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-689"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-690"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerCrossAttentionMask"><span class="hs-identifier hs-type">MkTransformerCrossAttentionMask</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571576"><span class="hs-identifier hs-type">dataType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-691"></span><span>    </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571566"><span class="hs-identifier hs-type">decoderInputGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571565"><span class="hs-identifier hs-type">decoderInputLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571564"><span class="hs-identifier hs-type">decoderInputDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571563"><span class="hs-identifier hs-type">decoderInputDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571575"><span class="hs-identifier hs-type">decoderInputShape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-692"></span><span>      </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571573"><span class="hs-identifier hs-type">inputPaddingMaskGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571572"><span class="hs-identifier hs-type">inputPaddingMaskLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571571"><span class="hs-identifier hs-type">inputPaddingMaskDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571570"><span class="hs-identifier hs-type">inputPaddingMaksDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571569"><span class="hs-identifier hs-type">inputPaddingMaskShape</span></a></span><span>
</span><span id="line-693"></span><span>    </span><span class="hs-special">)</span><span>
</span><span id="line-694"></span><span>    </span><span class="annot"><a href="#local-6989586621679571562"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-695"></span><span>    </span><span class="annot"><a href="#local-6989586621679571567"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-696"></span><span>    </span><span class="annot"><a href="#local-6989586621679571562"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-697"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-698"></span><span>  </span><span id="local-6989586621679571560"><span class="annot"><span class="annottext">forward :: MkTransformerCrossAttentionMask dataType
-&gt; (Tensor
      decoderInputGradient
      decoderInputLayout
      decoderInputDevice
      decoderInputDataType
      decoderInputShape,
    Tensor
      inputPaddingMaskGradient
      inputPaddingMaskLayout
      inputPaddingMaskDevice
      inputPaddingMaksDataType
      inputPaddingMaskShape)
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorDevice)
</span><a href="#local-6989586621679571560"><span class="hs-identifier hs-var hs-var hs-var hs-var">forward</span></a></span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerCrossAttentionMask"><span class="hs-identifier hs-type">MkTransformerCrossAttentionMask</span></a></span><span> </span><span class="hs-special">{</span><span id="local-6989586621679571558"><span id="local-6989586621679571559"><span class="annot"><span class="annottext">Double
SDataType dataType
crossAttentionMaskBias :: Double
crossAttentionMaskDataType :: SDataType dataType
crossAttentionMaskBias :: forall (dataType :: DataType DType).
MkTransformerCrossAttentionMask dataType -&gt; Double
crossAttentionMaskDataType :: forall (dataType :: DataType DType).
MkTransformerCrossAttentionMask dataType -&gt; SDataType dataType
</span><a href="#local-6989586621679571558"><span class="hs-glyph hs-var hs-var hs-var hs-var">..</span></a></span></span></span><span class="hs-special">}</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679571557"><span class="annot"><span class="annottext">Tensor
  decoderInputGradient
  decoderInputLayout
  decoderInputDevice
  decoderInputDataType
  decoderInputShape
</span><a href="#local-6989586621679571557"><span class="hs-identifier hs-var">decoderInput</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679571556"><span class="annot"><span class="annottext">Tensor
  inputPaddingMaskGradient
  inputPaddingMaskLayout
  inputPaddingMaskDevice
  inputPaddingMaksDataType
  inputPaddingMaskShape
</span><a href="#local-6989586621679571556"><span class="hs-identifier hs-var">inputPaddingMask</span></a></span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679571555"><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679571555"><span class="hs-identifier hs-var">g</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-699"></span><span>    </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679571554"><span class="annot"><span class="annottext">decoderInputShape :: SShape decoderInputShape
</span><a href="#local-6989586621679571554"><span class="hs-identifier hs-var hs-var">decoderInputShape</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor
  decoderInputGradient
  decoderInputLayout
  decoderInputDevice
  decoderInputDataType
  decoderInputShape
-&gt; SShape decoderInputShape
forall (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType).
SGetShape shape =&gt;
Tensor gradient layout device dataType shape -&gt; SShape shape
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sGetShape"><span class="hs-identifier hs-var">sGetShape</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  decoderInputGradient
  decoderInputLayout
  decoderInputDevice
  decoderInputDataType
  decoderInputShape
</span><a href="#local-6989586621679571557"><span class="hs-identifier hs-var">decoderInput</span></a></span><span>
</span><span id="line-700"></span><span>    </span><span id="local-6989586621679571553"><span class="annot"><span class="annottext">output
</span><a href="#local-6989586621679571553"><span class="hs-identifier hs-var">crossAttentionMask</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">SDataType dataType
-&gt; SShape decoderInputShape
-&gt; Double
-&gt; Tensor
     inputPaddingMaskGradient
     inputPaddingMaskLayout
     inputPaddingMaskDevice
     inputPaddingMaksDataType
     inputPaddingMaskShape
-&gt; m output
forall (m :: * -&gt; *) (transformerDataType :: DataType DType)
       (decoderInputShape :: Shape [Dim (Name Symbol) (Size Nat)])
       (decoderInputSeqDim :: Dim (Name Symbol) (Size Nat))
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (seqDim :: Dim (Name Symbol) (Size Nat)) output.
(MonadThrow m,
 MkTransformerCrossAttentionMaskC
   transformerDataType
   decoderInputShape
   decoderInputSeqDim
   gradient
   layout
   device
   dataType
   shape
   seqDim
   output) =&gt;
SDataType transformerDataType
-&gt; SShape decoderInputShape
-&gt; Double
-&gt; Tensor gradient layout device dataType shape
-&gt; m output
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#mkTransformerCrossAttentionMask"><span class="hs-identifier hs-var">mkTransformerCrossAttentionMask</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679571559"><span class="hs-identifier hs-var">crossAttentionMaskDataType</span></a></span><span> </span><span class="annot"><span class="annottext">SShape decoderInputShape
</span><a href="#local-6989586621679571554"><span class="hs-identifier hs-var">decoderInputShape</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679571558"><span class="hs-identifier hs-var">crossAttentionMaskBias</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  inputPaddingMaskGradient
  inputPaddingMaskLayout
  inputPaddingMaskDevice
  inputPaddingMaksDataType
  inputPaddingMaskShape
</span><a href="#local-6989586621679571556"><span class="hs-identifier hs-var">inputPaddingMask</span></a></span><span>
</span><span id="line-701"></span><span>    </span><span class="annot"><span class="annottext">(output, Generator generatorDevice)
-&gt; m (output, Generator generatorDevice)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">output
</span><a href="#local-6989586621679571553"><span class="hs-identifier hs-var">crossAttentionMask</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679571555"><span class="hs-identifier hs-var">g</span></a></span><span class="hs-special">)</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span>
</span><span id="line-702"></span><span>
</span><span id="line-703"></span><span class="hs-keyword">data</span><span> </span><span id="ShiftRight"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ShiftRight"><span class="hs-identifier hs-var">ShiftRight</span></a></span></span><span> </span><span id="local-6989586621679571552"><span class="annot"><a href="#local-6989586621679571552"><span class="hs-identifier hs-type">fillValue</span></a></span></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-704"></span><span>  </span><span id="ShiftRight"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ShiftRight"><span class="hs-identifier hs-var">ShiftRight</span></a></span></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-705"></span><span>    </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679571550"><span class="annot"><a href="#local-6989586621679571550"><span class="hs-identifier hs-type">fillValue</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-706"></span><span>    </span><span class="hs-comment">-- | fill value for shift right</span><span>
</span><span id="line-707"></span><span>    </span><span class="annot"><a href="#local-6989586621679571550"><span class="hs-identifier hs-type">fillValue</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-708"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ShiftRight"><span class="hs-identifier hs-type">ShiftRight</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571550"><span class="hs-identifier hs-type">fillValue</span></a></span><span>
</span><span id="line-709"></span><span>
</span><span id="line-710"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">instance</span><span> </span><span id="ModelSpec"><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier hs-var">ModelSpec</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ShiftRight"><span class="hs-identifier hs-type">ShiftRight</span></a></span><span> </span><span id="local-6989586621679571549"><span class="annot"><a href="#local-6989586621679571549"><span class="hs-identifier hs-type hs-type">fillValue</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ShiftRight"><span class="hs-identifier hs-type">ShiftRight</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571549"><span class="hs-identifier hs-type">fillValue</span></a></span><span>
</span><span id="line-711"></span><span>
</span><span id="line-712"></span><span id="local-6989586621679571547"><span id="local-6989586621679571548"><span class="hs-keyword">instance</span><span>
</span><span id="line-713"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span>
</span><span id="line-714"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ShiftRight"><span class="hs-identifier hs-type">ShiftRight</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571548"><span class="hs-identifier hs-type">fillValue</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-715"></span><span>    </span><span class="annot"><a href="#local-6989586621679571547"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-716"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ShiftRight"><span class="hs-identifier hs-type">ShiftRight</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571548"><span class="hs-identifier hs-type">fillValue</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-717"></span><span>    </span><span class="annot"><a href="#local-6989586621679571547"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-718"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-719"></span><span>  </span><span id="local-6989586621679571545"><span class="annot"><span class="annottext">initialize :: ModelSpec (ShiftRight fillValue)
-&gt; Generator generatorDevice
-&gt; m (ShiftRight fillValue, Generator generatorDevice)
</span><a href="#local-6989586621679571545"><span class="hs-identifier hs-var hs-var hs-var hs-var">initialize</span></a></span></span><span> </span><span id="local-6989586621679571544"><span class="annot"><span class="annottext">ModelSpec (ShiftRight fillValue)
</span><a href="#local-6989586621679571544"><span class="hs-identifier hs-var">spec</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(ShiftRight fillValue, Generator generatorDevice)
-&gt; m (ShiftRight fillValue, Generator generatorDevice)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">((ShiftRight fillValue, Generator generatorDevice)
 -&gt; m (ShiftRight fillValue, Generator generatorDevice))
-&gt; (Generator generatorDevice
    -&gt; (ShiftRight fillValue, Generator generatorDevice))
-&gt; Generator generatorDevice
-&gt; m (ShiftRight fillValue, Generator generatorDevice)
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">ModelSpec (ShiftRight fillValue)
ShiftRight fillValue
</span><a href="#local-6989586621679571544"><span class="hs-identifier hs-var">spec</span></a></span><span class="hs-special">,</span><span class="hs-special">)</span></span></span><span>
</span><span id="line-720"></span><span>
</span><span id="line-721"></span><span id="local-6989586621679571543"><span class="hs-keyword">instance</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasStateDict"><span class="hs-identifier hs-type">HasStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ShiftRight"><span class="hs-identifier hs-type">ShiftRight</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571543"><span class="hs-identifier hs-type">fillValue</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-722"></span><span>  </span><span id="local-6989586621679571540"><span class="annot"><span class="annottext">fromStateDict :: ModelSpec (ShiftRight fillValue)
-&gt; StateDictKey -&gt; m (ShiftRight fillValue)
</span><a href="#local-6989586621679571540"><span class="hs-identifier hs-var hs-var hs-var hs-var">fromStateDict</span></a></span></span><span> </span><span id="local-6989586621679571539"><span class="annot"><span class="annottext">ModelSpec (ShiftRight fillValue)
</span><a href="#local-6989586621679571539"><span class="hs-identifier hs-var">spec</span></a></span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ShiftRight fillValue -&gt; m (ShiftRight fillValue)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">ModelSpec (ShiftRight fillValue)
ShiftRight fillValue
</span><a href="#local-6989586621679571539"><span class="hs-identifier hs-var">spec</span></a></span><span>
</span><span id="line-723"></span><span>  </span><span id="local-6989586621679571538"><span class="annot"><span class="annottext">toStateDict :: StateDictKey -&gt; ShiftRight fillValue -&gt; m ()
</span><a href="#local-6989586621679571538"><span class="hs-identifier hs-var hs-var hs-var hs-var">toStateDict</span></a></span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="annottext">ShiftRight fillValue
</span><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">() -&gt; m ()
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span></span><span>
</span><span id="line-724"></span><span>
</span><span id="line-725"></span><span id="local-6989586621679571527"><span id="local-6989586621679571528"><span id="local-6989586621679571529"><span id="local-6989586621679571530"><span id="local-6989586621679571531"><span id="local-6989586621679571532"><span id="local-6989586621679571533"><span id="local-6989586621679571534"><span id="local-6989586621679571535"><span id="local-6989586621679571536"><span id="local-6989586621679571537"><span class="hs-keyword">instance</span><span>
</span><span id="line-726"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="#local-6989586621679571537"><span class="hs-identifier hs-type">input</span></a></span><span>
</span><span id="line-727"></span><span>      </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-728"></span><span>          </span><span class="annot"><a href="#local-6989586621679571536"><span class="hs-identifier hs-type">inputGradient</span></a></span><span>
</span><span id="line-729"></span><span>          </span><span class="annot"><a href="#local-6989586621679571535"><span class="hs-identifier hs-type">inputLayout</span></a></span><span>
</span><span id="line-730"></span><span>          </span><span class="annot"><a href="#local-6989586621679571534"><span class="hs-identifier hs-type">inputDevice</span></a></span><span>
</span><span id="line-731"></span><span>          </span><span class="annot"><a href="#local-6989586621679571533"><span class="hs-identifier hs-type">inputDataType</span></a></span><span>
</span><span id="line-732"></span><span>          </span><span class="annot"><a href="#local-6989586621679571532"><span class="hs-identifier hs-type">inputShape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-733"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetLayout"><span class="hs-identifier hs-type">SGetLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571535"><span class="hs-identifier hs-type">inputLayout</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-734"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetDevice"><span class="hs-identifier hs-type">SGetDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571534"><span class="hs-identifier hs-type">inputDevice</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-735"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetDataType"><span class="hs-identifier hs-type">SGetDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571533"><span class="hs-identifier hs-type">inputDataType</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-736"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetShape"><span class="hs-identifier hs-type">SGetShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571532"><span class="hs-identifier hs-type">inputShape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-737"></span><span>    </span><span class="annot"><a href="#local-6989586621679571531"><span class="hs-identifier hs-type">inputBatchDim</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679571532"><span class="hs-identifier hs-type">inputShape</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#%21"><span class="hs-glyph hs-type">!</span></a></span><span> </span><span class="annot"><span class="hs-number">0</span></span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-738"></span><span>    </span><span class="annot"><a href="#local-6989586621679571530"><span class="hs-identifier hs-type">inputSeqDim</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679571532"><span class="hs-identifier hs-type">inputShape</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#%21"><span class="hs-glyph hs-type">!</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-739"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Scalar.html#Scalar"><span class="hs-identifier hs-type">Scalar</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571529"><span class="hs-identifier hs-type">fillValue</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-740"></span><span>    </span><span class="annot"><a href="#local-6989586621679571528"><span class="hs-identifier hs-type">rightShiftedInput</span></a></span><span>
</span><span id="line-741"></span><span>      </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-742"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679571536"><span class="hs-identifier hs-type">inputGradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#WithoutGradient"><span class="hs-identifier hs-type">WithoutGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-743"></span><span>          </span><span class="annot"><a href="#local-6989586621679571535"><span class="hs-identifier hs-type">inputLayout</span></a></span><span>
</span><span id="line-744"></span><span>          </span><span class="annot"><a href="#local-6989586621679571534"><span class="hs-identifier hs-type">inputDevice</span></a></span><span>
</span><span id="line-745"></span><span>          </span><span class="annot"><a href="#local-6989586621679571533"><span class="hs-identifier hs-type">inputDataType</span></a></span><span>
</span><span id="line-746"></span><span>          </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#ReplaceDimF"><span class="hs-identifier hs-type">ReplaceDimF</span></a></span><span>
</span><span id="line-747"></span><span>              </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-748"></span><span>              </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679571532"><span class="hs-identifier hs-type">inputShape</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679571531"><span class="hs-identifier hs-type">inputBatchDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679571530"><span class="hs-identifier hs-type">inputSeqDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-749"></span><span>              </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#AddDimF"><span class="hs-identifier hs-type">AddDimF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571530"><span class="hs-identifier hs-type">inputSeqDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-750"></span><span>          </span><span class="hs-special">)</span><span>
</span><span id="line-751"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-752"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ShiftRight"><span class="hs-identifier hs-type">ShiftRight</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571529"><span class="hs-identifier hs-type">fillValue</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679571537"><span class="hs-identifier hs-type">input</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571527"><span class="hs-identifier hs-type">generator</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571528"><span class="hs-identifier hs-type">rightShiftedInput</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679571527"><span class="hs-identifier hs-type">generator</span></a></span><span>
</span><span id="line-753"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-754"></span><span>  </span><span id="local-6989586621679571525"><span class="annot"><span class="annottext">forward :: ShiftRight fillValue
-&gt; input
-&gt; Generator generator
-&gt; m (rightShiftedInput, Generator generator)
</span><a href="#local-6989586621679571525"><span class="hs-identifier hs-var hs-var hs-var hs-var">forward</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ShiftRight"><span class="hs-identifier hs-type">ShiftRight</span></a></span><span> </span><span id="local-6989586621679571524"><span class="annot"><span class="annottext">fillValue
</span><a href="#local-6989586621679571524"><span class="hs-identifier hs-var">fillValue</span></a></span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679571523"><span class="annot"><span class="annottext">input
</span><a href="#local-6989586621679571523"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span id="local-6989586621679571522"><span class="annot"><span class="annottext">Generator generator
</span><a href="#local-6989586621679571522"><span class="hs-identifier hs-var">g</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-755"></span><span>    </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679571521"><span class="annot"><span class="annottext">inputLayout :: SLayout inputLayout
</span><a href="#local-6989586621679571521"><span class="hs-identifier hs-var hs-var">inputLayout</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor
  inputGradient inputLayout inputDevice inputDataType inputShape
-&gt; SLayout inputLayout
forall (layout :: Layout LayoutType)
       (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SGetLayout layout =&gt;
Tensor gradient layout device dataType shape -&gt; SLayout layout
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sGetLayout"><span class="hs-identifier hs-var">sGetLayout</span></a></span><span> </span><span class="annot"><span class="annottext">input
Tensor
  inputGradient inputLayout inputDevice inputDataType inputShape
</span><a href="#local-6989586621679571523"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-756"></span><span>        </span><span id="local-6989586621679571520"><span class="annot"><span class="annottext">inputDevice :: SDevice inputDevice
</span><a href="#local-6989586621679571520"><span class="hs-identifier hs-var hs-var">inputDevice</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor
  inputGradient inputLayout inputDevice inputDataType inputShape
-&gt; SDevice inputDevice
forall (device :: Device (DeviceType Nat))
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SGetDevice device =&gt;
Tensor gradient layout device dataType shape -&gt; SDevice device
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sGetDevice"><span class="hs-identifier hs-var">sGetDevice</span></a></span><span> </span><span class="annot"><span class="annottext">input
Tensor
  inputGradient inputLayout inputDevice inputDataType inputShape
</span><a href="#local-6989586621679571523"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-757"></span><span>        </span><span id="local-6989586621679571519"><span class="annot"><span class="annottext">inputDataType :: SDataType inputDataType
</span><a href="#local-6989586621679571519"><span class="hs-identifier hs-var hs-var">inputDataType</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor
  inputGradient inputLayout inputDevice inputDataType inputShape
-&gt; SDataType inputDataType
forall (dataType :: DataType DType)
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SGetDataType dataType =&gt;
Tensor gradient layout device dataType shape -&gt; SDataType dataType
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sGetDataType"><span class="hs-identifier hs-var">sGetDataType</span></a></span><span> </span><span class="annot"><span class="annottext">input
Tensor
  inputGradient inputLayout inputDevice inputDataType inputShape
</span><a href="#local-6989586621679571523"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-758"></span><span>        </span><span id="local-6989586621679571518"><span class="annot"><span class="annottext">inputShape :: SShape inputShape
</span><a href="#local-6989586621679571518"><span class="hs-identifier hs-var hs-var">inputShape</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor
  inputGradient inputLayout inputDevice inputDataType inputShape
-&gt; SShape inputShape
forall (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType).
SGetShape shape =&gt;
Tensor gradient layout device dataType shape -&gt; SShape shape
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sGetShape"><span class="hs-identifier hs-var">sGetShape</span></a></span><span> </span><span class="annot"><span class="annottext">input
Tensor
  inputGradient inputLayout inputDevice inputDataType inputShape
</span><a href="#local-6989586621679571523"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-759"></span><span>    </span><span id="local-6989586621679571517"><span class="annot"><span class="annottext">SDim inputBatchDim
</span><a href="#local-6989586621679571517"><span class="hs-identifier hs-var">inputBatchDim</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">SSelectDim ('SelectDim ('ByIndex 0))
-&gt; SShape inputShape -&gt; m (SDim inputBatchDim)
forall (selectDim :: SelectDim (By Symbol Nat))
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (dim :: Dim (Name Symbol) (Size Nat)) (m :: * -&gt; *).
(dim ~ GetDimF selectDim shape, MonadThrow m) =&gt;
SSelectDim selectDim -&gt; SShape shape -&gt; m (SDim dim)
</span><a href="Torch.GraduallyTyped.Shape.Class.html#sGetDimFromShape"><span class="hs-identifier hs-var">sGetDimFromShape</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SBy ('ByIndex 0) -&gt; SSelectDim ('SelectDim ('ByIndex 0))
forall (by :: By Symbol Nat). SBy by -&gt; SSelectDim ('SelectDim by)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSelectDim"><span class="hs-identifier hs-var">SSelectDim</span></a></span><span> </span><span class="annot"><span class="annottext">(SBy ('ByIndex 0) -&gt; SSelectDim ('SelectDim ('ByIndex 0)))
-&gt; SBy ('ByIndex 0) -&gt; SSelectDim ('SelectDim ('ByIndex 0))
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">KnownNat 0 =&gt; SBy ('ByIndex 0)
forall (index :: Nat). KnownNat index =&gt; SBy ('ByIndex index)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SByIndex"><span class="hs-identifier hs-var">SByIndex</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">0</span></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">SShape inputShape
</span><a href="#local-6989586621679571518"><span class="hs-identifier hs-var">inputShape</span></a></span><span>
</span><span id="line-760"></span><span>    </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679571516"><span class="annot"><span class="annottext">filler :: Tensor
  ('Gradient 'WithoutGradient)
  inputLayout
  inputDevice
  inputDataType
  ('Shape '[inputBatchDim, 'Dim ('Name &quot;*&quot;) ('Size 1)])
</span><a href="#local-6989586621679571516"><span class="hs-identifier hs-var hs-var">filler</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">TensorSpec
  ('Gradient 'WithoutGradient)
  inputLayout
  inputDevice
  inputDataType
  ('Shape '[inputBatchDim, 'Dim ('Name &quot;*&quot;) ('Size 1)])
-&gt; fillValue
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     inputLayout
     inputDevice
     inputDataType
     ('Shape '[inputBatchDim, 'Dim ('Name &quot;*&quot;) ('Size 1)])
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]) input.
Scalar input =&gt;
TensorSpec gradient layout device dataType shape
-&gt; input -&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.Creation.html#sFull"><span class="hs-identifier hs-var">sFull</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SGradient ('Gradient 'WithoutGradient)
-&gt; SLayout inputLayout
-&gt; SDevice inputDevice
-&gt; SDataType inputDataType
-&gt; SShape ('Shape '[inputBatchDim, 'Dim ('Name &quot;*&quot;) ('Size 1)])
-&gt; TensorSpec
     ('Gradient 'WithoutGradient)
     inputLayout
     inputDevice
     inputDataType
     ('Shape '[inputBatchDim, 'Dim ('Name &quot;*&quot;) ('Size 1)])
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SShape shape
-&gt; TensorSpec gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorSpec"><span class="hs-identifier hs-var">TensorSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SRequiresGradient 'WithoutGradient
-&gt; SGradient ('Gradient 'WithoutGradient)
forall (requiresGradient :: RequiresGradient).
SRequiresGradient requiresGradient
-&gt; SGradient ('Gradient requiresGradient)
</span><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier hs-var">SGradient</span></a></span><span> </span><span class="annot"><span class="annottext">SRequiresGradient 'WithoutGradient
</span><a href="Torch.GraduallyTyped.RequiresGradient.html#SWithoutGradient"><span class="hs-identifier hs-var">SWithoutGradient</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">SLayout inputLayout
</span><a href="#local-6989586621679571521"><span class="hs-identifier hs-var">inputLayout</span></a></span><span> </span><span class="annot"><span class="annottext">SDevice inputDevice
</span><a href="#local-6989586621679571520"><span class="hs-identifier hs-var">inputDevice</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType inputDataType
</span><a href="#local-6989586621679571519"><span class="hs-identifier hs-var">inputDataType</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SList '[inputBatchDim, 'Dim ('Name &quot;*&quot;) ('Size 1)]
-&gt; SShape ('Shape '[inputBatchDim, 'Dim ('Name &quot;*&quot;) ('Size 1)])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList '[inputBatchDim, 'Dim ('Name &quot;*&quot;) ('Size 1)]
 -&gt; SShape ('Shape '[inputBatchDim, 'Dim ('Name &quot;*&quot;) ('Size 1)]))
-&gt; SList '[inputBatchDim, 'Dim ('Name &quot;*&quot;) ('Size 1)]
-&gt; SShape ('Shape '[inputBatchDim, 'Dim ('Name &quot;*&quot;) ('Size 1)])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SDim inputBatchDim
</span><a href="#local-6989586621679571517"><span class="hs-identifier hs-var">inputBatchDim</span></a></span><span> </span><span class="annot"><span class="annottext">SDim inputBatchDim
-&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 1)]
-&gt; SList '[inputBatchDim, 'Dim ('Name &quot;*&quot;) ('Size 1)]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize ('Size 1) -&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 1))
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownNat 1 =&gt; SSize ('Size 1)
forall (size :: Nat). KnownNat size =&gt; SSize ('Size size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier hs-var">SSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">1</span></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim ('Name &quot;*&quot;) ('Size 1))
-&gt; SList '[] -&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 1)]
forall (dim :: Dim (Name Symbol) (Size Nat))
       (dims :: [Dim (Name Symbol) (Size Nat)]).
SDim dim -&gt; SList dims -&gt; SList (dim : dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">fillValue
</span><a href="#local-6989586621679571524"><span class="hs-identifier hs-var">fillValue</span></a></span><span>
</span><span id="line-761"></span><span>    </span><span class="annot"><span class="annottext">(rightShiftedInput, Generator generator)
-&gt; m (rightShiftedInput, Generator generator)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">HList
  '[Tensor
      ('Gradient 'WithoutGradient)
      inputLayout
      inputDevice
      inputDataType
      ('Shape '[inputBatchDim, 'Dim ('Name &quot;*&quot;) ('Size 1)]),
    input]
-&gt; CatF
     ('SelectDim ('ByIndex 1))
     '[Tensor
         ('Gradient 'WithoutGradient)
         inputLayout
         inputDevice
         inputDataType
         ('Shape '[inputBatchDim, 'Dim ('Name &quot;*&quot;) ('Size 1)]),
       input]
     HList
forall (selectDim :: SelectDim (By Symbol Nat)) k (c :: k -&gt; *)
       (a :: k).
(HasCat selectDim k c a, SingI selectDim) =&gt;
c a -&gt; CatF selectDim a c
</span><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#cat"><span class="hs-identifier hs-var">cat</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  inputLayout
  inputDevice
  inputDataType
  ('Shape '[inputBatchDim, 'Dim ('Name &quot;*&quot;) ('Size 1)])
</span><a href="#local-6989586621679571516"><span class="hs-identifier hs-var">filler</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  inputLayout
  inputDevice
  inputDataType
  ('Shape '[inputBatchDim, 'Dim ('Name &quot;*&quot;) ('Size 1)])
-&gt; HList '[input]
-&gt; HList
     '[Tensor
         ('Gradient 'WithoutGradient)
         inputLayout
         inputDevice
         inputDataType
         ('Shape '[inputBatchDim, 'Dim ('Name &quot;*&quot;) ('Size 1)]),
       input]
forall x (xs :: [*]). x -&gt; HList xs -&gt; HList (x : xs)
</span><a href="../../../../hasktorch/html/src"><span class="hs-operator hs-var">:.</span></a></span><span> </span><span class="annot"><span class="annottext">input
</span><a href="#local-6989586621679571523"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">input -&gt; HList '[] -&gt; HList '[input]
forall x (xs :: [*]). x -&gt; HList xs -&gt; HList (x : xs)
</span><a href="../../../../hasktorch/html/src"><span class="hs-operator hs-var">:.</span></a></span><span> </span><span class="annot"><span class="annottext">HList '[]
forall k. HList '[]
</span><a href="../../../../hasktorch/html/src"><span class="hs-identifier hs-var">HNil</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Generator generator
</span><a href="#local-6989586621679571522"><span class="hs-identifier hs-var">g</span></a></span><span class="hs-special">)</span></span></span></span></span></span></span></span></span></span></span></span><span>
</span><span id="line-762"></span></pre></body></html>