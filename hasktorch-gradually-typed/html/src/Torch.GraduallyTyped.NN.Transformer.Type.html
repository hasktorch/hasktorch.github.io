<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><link rel="stylesheet" type="text/css" href="style.css" /><script type="text/javascript" src="highlight.js"></script></head><body><pre><span class="hs-pragma">{-# LANGUAGE ConstraintKinds #-}</span><span>
</span><span id="line-2"></span><span class="hs-pragma">{-# LANGUAGE DataKinds #-}</span><span>
</span><span id="line-3"></span><span class="hs-pragma">{-# LANGUAGE FlexibleInstances #-}</span><span>
</span><span id="line-4"></span><span class="hs-pragma">{-# LANGUAGE GADTs #-}</span><span>
</span><span id="line-5"></span><span class="hs-pragma">{-# LANGUAGE MultiParamTypeClasses #-}</span><span>
</span><span id="line-6"></span><span class="hs-pragma">{-# LANGUAGE PatternSynonyms #-}</span><span>
</span><span id="line-7"></span><span class="hs-pragma">{-# LANGUAGE RecordWildCards #-}</span><span>
</span><span id="line-8"></span><span class="hs-pragma">{-# LANGUAGE ScopedTypeVariables #-}</span><span>
</span><span id="line-9"></span><span class="hs-pragma">{-# LANGUAGE StandaloneKindSignatures #-}</span><span>
</span><span id="line-10"></span><span class="hs-pragma">{-# LANGUAGE TemplateHaskell #-}</span><span>
</span><span id="line-11"></span><span class="hs-pragma">{-# LANGUAGE TupleSections #-}</span><span>
</span><span id="line-12"></span><span class="hs-pragma">{-# LANGUAGE TypeApplications #-}</span><span>
</span><span id="line-13"></span><span class="hs-pragma">{-# LANGUAGE TypeFamilies #-}</span><span>
</span><span id="line-14"></span><span class="hs-pragma">{-# LANGUAGE TypeOperators #-}</span><span>
</span><span id="line-15"></span><span class="hs-pragma">{-# LANGUAGE UndecidableInstances #-}</span><span>
</span><span id="line-16"></span><span class="hs-pragma">{-# OPTIONS_GHC -fplugin TypeLevel.Rewrite
                -fplugin-opt=TypeLevel.Rewrite:Torch.GraduallyTyped.Unify.UnifyRightAssociativeL
                -fplugin-opt=TypeLevel.Rewrite:Torch.GraduallyTyped.Unify.UnifyIdempotenceL2 #-}</span><span>
</span><span id="line-19"></span><span>
</span><span id="line-20"></span><span class="hs-keyword">module</span><span> </span><span class="hs-identifier">Torch.GraduallyTyped.NN.Transformer.Type</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-21"></span><span>
</span><span id="line-22"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier">Control.Monad.Catch</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier">MonadThrow</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-23"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">Data.Singletons.Prelude.List</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">SList</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">SNil</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-24"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">Data.Singletons.TH</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">SingKind</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">fromSing</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier">genSingletons</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-25"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">GHC.Float</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier">double2Int</span></span><span class="hs-special">)</span><span>
</span><span id="line-26"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><span class="hs-identifier">GHC.TypeLits</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="hs-identifier">Nat</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="hs-identifier">Symbol</span></span><span class="hs-special">)</span><span>
</span><span id="line-27"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html"><span class="hs-identifier">Torch.GraduallyTyped.DType</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier">DType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier">DataType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#SDType"><span class="hs-identifier">SDType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier">SDataType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-28"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html"><span class="hs-identifier">Torch.GraduallyTyped.Device</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#SDevice"><span class="hs-identifier">SDevice</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-29"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html"><span class="hs-identifier">Torch.GraduallyTyped.Layout</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier">Layout</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#LayoutType"><span class="hs-identifier">LayoutType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#SLayout"><span class="hs-identifier">SLayout</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#SLayoutType"><span class="hs-identifier">SLayoutType</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-30"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html"><span class="hs-identifier">Torch.GraduallyTyped.NN.Class</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier">HasForward</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier">HasInitialize</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasStateDict"><span class="hs-identifier">HasStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier">ModelSpec</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-31"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html"><span class="hs-identifier">Torch.GraduallyTyped.Prelude</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Seq"><span class="hs-identifier">Seq</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#forgetIsChecked"><span class="hs-identifier">forgetIsChecked</span></a></span><span class="hs-special">,</span><span> </span><span class="hs-keyword">pattern</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#%3A%7C%3A"><span class="hs-operator">(:|:)</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-32"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html"><span class="hs-identifier">Torch.GraduallyTyped.RequiresGradient</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier">Gradient</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#RequiresGradient"><span class="hs-identifier">RequiresGradient</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier">SGradient</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#SRequiresGradient"><span class="hs-identifier">SRequiresGradient</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-33"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Scalar.html"><span class="hs-identifier">Torch.GraduallyTyped.Scalar</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Scalar.html#Scalar"><span class="hs-identifier">Scalar</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-34"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html"><span class="hs-identifier">Torch.GraduallyTyped.Shape.Class</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#AddDimF"><span class="hs-identifier">AddDimF</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#BroadcastShapesF"><span class="hs-identifier">BroadcastShapesF</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#ReplaceDimF"><span class="hs-identifier">ReplaceDimF</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#sGetDimFromShape"><span class="hs-identifier">sGetDimFromShape</span></a></span><span class="hs-special">,</span><span> </span><span class="hs-keyword">type</span><span> </span><span class="hs-special">(</span><span class="hs-glyph">!</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-35"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html"><span class="hs-identifier">Torch.GraduallyTyped.Shape.Type</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#By"><span class="hs-identifier">By</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier">Name</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SBy"><span class="hs-identifier">SBy</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier">SDim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#sDimSize"><span class="hs-identifier">sDimSize</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier">SName</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SSelectDim"><span class="hs-identifier">SSelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier">SShape</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier">SSize</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier">Shape</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier">Size</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="hs-keyword">pattern</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator">(:&amp;:)</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-36"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Creation.html"><span class="hs-identifier">Torch.GraduallyTyped.Tensor.Creation</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Creation.html#sArangeNaturals"><span class="hs-identifier">sArangeNaturals</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Creation.html#sFull"><span class="hs-identifier">sFull</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Creation.html#sOnes"><span class="hs-identifier">sOnes</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Creation.html#sZeros"><span class="hs-identifier">sZeros</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-37"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html"><span class="hs-identifier">Torch.GraduallyTyped.Tensor.IndexingSlicingJoining</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#UnsqueezeF"><span class="hs-identifier">UnsqueezeF</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#cat"><span class="hs-identifier">cat</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#unsqueeze"><span class="hs-identifier">unsqueeze</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-38"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Comparison.html"><span class="hs-identifier">Torch.GraduallyTyped.Tensor.MathOperations.Comparison</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Comparison.html#%3D%3D."><span class="hs-operator">(==.)</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-39"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html"><span class="hs-identifier">Torch.GraduallyTyped.Tensor.MathOperations.Pointwise</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#addScalar"><span class="hs-identifier">addScalar</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#logicalOr"><span class="hs-identifier">logicalOr</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-40"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Other.html"><span class="hs-identifier">Torch.GraduallyTyped.Tensor.Other</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Other.html#maskedFill"><span class="hs-identifier">maskedFill</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Other.html#triu"><span class="hs-identifier">triu</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-41"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html"><span class="hs-identifier">Torch.GraduallyTyped.Tensor.Type</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetDataType"><span class="hs-identifier">SGetDataType</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#sGetDataType"><span class="hs-identifier">sGetDataType</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetDevice"><span class="hs-identifier">SGetDevice</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetDim"><span class="hs-identifier">SGetDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetLayout"><span class="hs-identifier">SGetLayout</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetShape"><span class="hs-identifier">SGetShape</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier">Tensor</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorLike"><span class="hs-identifier">TensorLike</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#sToTensor"><span class="hs-identifier">sToTensor</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorSpec"><span class="hs-identifier">TensorSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-glyph">..</span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#bool"><span class="hs-identifier">bool</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#sCheckedShape"><span class="hs-identifier">sCheckedShape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-42"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html"><span class="hs-identifier">Torch.GraduallyTyped.Unify</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-keyword">type</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator">(&lt;+&gt;)</span></a></span><span class="hs-special">,</span><span> </span><span class="hs-keyword">type</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator">(&lt;|&gt;)</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-43"></span><span class="hs-keyword">import</span><span> </span><span class="annot"><a href="../../../../hasktorch/html/src"><span class="hs-identifier">Torch.HList</span></a></span><span>
</span><span id="line-44"></span><span>
</span><span id="line-45"></span><span class="hs-comment">-- | A data type representing the style of a transformer.</span><span>
</span><span id="line-46"></span><span class="hs-comment">-- Every supported transformer has a constructor of this type.</span><span>
</span><span id="line-47"></span><span class="hs-keyword">data</span><span> </span><span id="TransformerStyle"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerStyle"><span class="hs-identifier hs-var">TransformerStyle</span></a></span></span><span>
</span><span id="line-48"></span><span>  </span><span class="hs-comment">-- | @T5@ transformer style, see https://ai.googleblog.com/2020/02/exploring-transfer-learning-with-t5.html</span><span>
</span><span id="line-49"></span><span>  </span><span class="hs-glyph">=</span><span> </span><span id="T5"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#T5"><span class="hs-identifier hs-var">T5</span></a></span></span><span>
</span><span id="line-50"></span><span>  </span><span class="hs-comment">-- | @ByT5@ transformer style, see https://arxiv.org/abs/2105.13626</span><span>
</span><span id="line-51"></span><span>  </span><span class="hs-glyph">|</span><span> </span><span id="ByT5"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ByT5"><span class="hs-identifier hs-var">ByT5</span></a></span></span><span>
</span><span id="line-52"></span><span>  </span><span class="hs-comment">-- | @BART@ transformer style, see https://arxiv.org/abs/1910.13461</span><span>
</span><span id="line-53"></span><span>  </span><span class="hs-glyph">|</span><span> </span><span id="BART"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BART"><span class="hs-identifier hs-var">BART</span></a></span></span><span>
</span><span id="line-54"></span><span>  </span><span class="hs-comment">-- | @MBART@ transformer style, see https://arxiv.org/abs/2001.08210</span><span>
</span><span id="line-55"></span><span>  </span><span class="hs-glyph">|</span><span> </span><span id="MBART"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MBART"><span class="hs-identifier hs-var">MBART</span></a></span></span><span>
</span><span id="line-56"></span><span>  </span><span class="hs-comment">-- | @Pegasus@ transformer style, see https://ai.googleblog.com/2020/06/pegasus-state-of-art-model-for.html</span><span>
</span><span id="line-57"></span><span>  </span><span class="hs-glyph">|</span><span> </span><span id="Pegasus"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#Pegasus"><span class="hs-identifier hs-var">Pegasus</span></a></span></span><span>
</span><span id="line-58"></span><span>  </span><span class="hs-comment">-- | @BERT@ transformer style, see https://arxiv.org/abs/1810.04805</span><span>
</span><span id="line-59"></span><span>  </span><span class="hs-glyph">|</span><span> </span><span id="BERT"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#BERT"><span class="hs-identifier hs-var">BERT</span></a></span></span><span>
</span><span id="line-60"></span><span>  </span><span class="hs-comment">-- | @RoBERTa@ transformer style, see https://arxiv.org/abs/1907.11692</span><span>
</span><span id="line-61"></span><span>  </span><span class="hs-glyph">|</span><span> </span><span id="RoBERTa"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#RoBERTa"><span class="hs-identifier hs-var">RoBERTa</span></a></span></span><span>
</span><span id="line-62"></span><span>  </span><span class="hs-comment">-- | @GPT2@ transformer style, see https://openai.com/blog/better-language-models/</span><span>
</span><span id="line-63"></span><span>  </span><span class="hs-glyph">|</span><span> </span><span id="GPT2"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#GPT2"><span class="hs-identifier hs-var">GPT2</span></a></span></span><span>
</span><span id="line-64"></span><span>  </span><span class="hs-keyword">deriving</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679547845"><span id="local-6989586621679547847"><span id="local-6989586621679547849"><span class="annot"><span class="annottext">Int -&gt; TransformerStyle -&gt; ShowS
[TransformerStyle] -&gt; ShowS
TransformerStyle -&gt; String
(Int -&gt; TransformerStyle -&gt; ShowS)
-&gt; (TransformerStyle -&gt; String)
-&gt; ([TransformerStyle] -&gt; ShowS)
-&gt; Show TransformerStyle
forall a.
(Int -&gt; a -&gt; ShowS) -&gt; (a -&gt; String) -&gt; ([a] -&gt; ShowS) -&gt; Show a
showList :: [TransformerStyle] -&gt; ShowS
$cshowList :: [TransformerStyle] -&gt; ShowS
show :: TransformerStyle -&gt; String
$cshow :: TransformerStyle -&gt; String
showsPrec :: Int -&gt; TransformerStyle -&gt; ShowS
$cshowsPrec :: Int -&gt; TransformerStyle -&gt; ShowS
</span><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var hs-var hs-var">Show</span></span></span></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679547840"><span id="local-6989586621679547842"><span class="annot"><span class="annottext">TransformerStyle -&gt; TransformerStyle -&gt; Bool
(TransformerStyle -&gt; TransformerStyle -&gt; Bool)
-&gt; (TransformerStyle -&gt; TransformerStyle -&gt; Bool)
-&gt; Eq TransformerStyle
forall a. (a -&gt; a -&gt; Bool) -&gt; (a -&gt; a -&gt; Bool) -&gt; Eq a
/= :: TransformerStyle -&gt; TransformerStyle -&gt; Bool
$c/= :: TransformerStyle -&gt; TransformerStyle -&gt; Bool
== :: TransformerStyle -&gt; TransformerStyle -&gt; Bool
$c== :: TransformerStyle -&gt; TransformerStyle -&gt; Bool
</span><span class="hs-identifier hs-var hs-var hs-var hs-var hs-var hs-var">Eq</span></span></span></span><span class="hs-special">)</span><span>
</span><span id="line-65"></span><span>
</span><span id="line-66"></span><span id="T5Sym0"><span id="ByT5Sym0"><span id="BARTSym0"><span id="MBARTSym0"><span id="PegasusSym0"><span id="BERTSym0"><span id="RoBERTaSym0"><span id="GPT2Sym0"><span id="SGPT2"><span id="SRoBERTa"><span id="SBERT"><span id="SPegasus"><span id="SMBART"><span id="SBART"><span id="SByT5"><span id="ST5"><span id="STransformerStyle"><span id="local-6989586621679547818"><span id="local-6989586621679547820"><span id="local-6989586621679547822"><span id="local-6989586621679547824"><span id="local-6989586621679547826"><span id="local-6989586621679547828"><span id="local-6989586621679547830"><span id="local-6989586621679547832"><span id="local-6989586621679547834"><span id="local-6989586621679547836"><span id="local-6989586621679547838"><span id="Demote"><span id="Sing"><span class="hs-identifier">genSingletons</span><span> </span><span class="hs-special">[</span><span class="hs-special">''</span><span class="hs-identifier">TransformerStyle</span><span class="hs-special">]</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span>
</span><span id="line-67"></span><span>
</span><span id="line-68"></span><span class="hs-comment">-- | A data type representing the type of head used in a transformer.</span><span>
</span><span id="line-69"></span><span class="hs-keyword">data</span><span> </span><span id="TransformerHead"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#TransformerHead"><span class="hs-identifier hs-var">TransformerHead</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span id="WithoutHead"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#WithoutHead"><span class="hs-identifier hs-var">WithoutHead</span></a></span></span><span> </span><span class="hs-glyph">|</span><span> </span><span id="WithLMHead"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#WithLMHead"><span class="hs-identifier hs-var">WithLMHead</span></a></span></span><span>
</span><span id="line-70"></span><span>
</span><span id="line-71"></span><span id="WithoutHeadSym0"><span id="WithLMHeadSym0"><span id="SWithLMHead"><span id="SWithoutHead"><span id="STransformerHead"><span id="local-6989586621679547788"><span id="local-6989586621679547790"><span id="local-6989586621679547792"><span id="local-6989586621679547794"><span id="local-6989586621679547796"><span id="Demote"><span id="Sing"><span class="hs-identifier">genSingletons</span><span> </span><span class="hs-special">[</span><span class="hs-special">''</span><span class="hs-identifier">TransformerHead</span><span class="hs-special">]</span></span></span></span></span></span></span></span></span></span></span></span></span><span>
</span><span id="line-72"></span><span>
</span><span id="line-73"></span><span id="local-6989586621679548319"><span id="local-6989586621679548320"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#padded"><span class="hs-identifier hs-type">padded</span></a></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Integral</span></span><span> </span><span class="annot"><a href="#local-6989586621679548320"><span class="hs-identifier hs-type">n</span></a></span><span> </span><span class="hs-glyph">=&gt;</span><span> </span><span class="annot"><a href="#local-6989586621679548320"><span class="hs-identifier hs-type">n</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><a href="#local-6989586621679548319"><span class="hs-identifier hs-type">a</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679548319"><span class="hs-identifier hs-type">a</span></a></span><span class="hs-special">]</span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679548319"><span class="hs-identifier hs-type">a</span></a></span><span class="hs-special">]</span></span></span><span>
</span><span id="line-74"></span><span id="padded"><span class="annot"><span class="annottext">padded :: n -&gt; a -&gt; [a] -&gt; [a]
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#padded"><span class="hs-identifier hs-var hs-var">padded</span></a></span></span><span> </span><span id="local-6989586621679547781"><span class="annot"><span class="annottext">n
</span><a href="#local-6989586621679547781"><span class="hs-identifier hs-var">n</span></a></span></span><span> </span><span id="local-6989586621679547780"><span class="annot"><span class="annottext">a
</span><a href="#local-6989586621679547780"><span class="hs-identifier hs-var">p</span></a></span></span><span> </span><span id="local-6989586621679547779"><span class="annot"><span class="annottext">[a]
</span><a href="#local-6989586621679547779"><span class="hs-identifier hs-var">xs</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-75"></span><span>  </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679547778"><span class="annot"><span class="annottext">n' :: Int
</span><a href="#local-6989586621679547778"><span class="hs-identifier hs-var hs-var">n'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">n -&gt; Int
forall a b. (Integral a, Num b) =&gt; a -&gt; b
</span><span class="hs-identifier hs-var">fromIntegral</span></span><span> </span><span class="annot"><span class="annottext">n
</span><a href="#local-6989586621679547781"><span class="hs-identifier hs-var">n</span></a></span><span>
</span><span id="line-76"></span><span>      </span><span id="local-6989586621679547777"><span class="annot"><span class="annottext">diff :: Int
</span><a href="#local-6989586621679547777"><span class="hs-identifier hs-var hs-var">diff</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679547778"><span class="hs-identifier hs-var">n'</span></a></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Int
forall a. Num a =&gt; a -&gt; a -&gt; a
</span><span class="hs-glyph hs-var">-</span></span><span> </span><span class="annot"><span class="annottext">[a] -&gt; Int
forall (t :: * -&gt; *) a. Foldable t =&gt; t a -&gt; Int
</span><span class="hs-identifier hs-var">length</span></span><span> </span><span class="annot"><span class="annottext">[a]
</span><a href="#local-6989586621679547779"><span class="hs-identifier hs-var">xs</span></a></span><span>
</span><span id="line-77"></span><span>   </span><span class="hs-keyword">in</span><span> </span><span class="annot"><span class="annottext">Int -&gt; [a] -&gt; [a]
forall a. Int -&gt; [a] -&gt; [a]
</span><span class="hs-identifier hs-var">take</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679547778"><span class="hs-identifier hs-var">n'</span></a></span><span> </span><span class="annot"><span class="annottext">[a]
</span><a href="#local-6989586621679547779"><span class="hs-identifier hs-var">xs</span></a></span><span> </span><span class="annot"><span class="annottext">[a] -&gt; [a] -&gt; [a]
forall a. [a] -&gt; [a] -&gt; [a]
</span><span class="hs-operator hs-var">++</span></span><span> </span><span class="annot"><span class="annottext">Int -&gt; a -&gt; [a]
forall a. Int -&gt; a -&gt; [a]
</span><span class="hs-identifier hs-var">replicate</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679547777"><span class="hs-identifier hs-var">diff</span></a></span><span> </span><span class="annot"><span class="annottext">a
</span><a href="#local-6989586621679547780"><span class="hs-identifier hs-var">p</span></a></span><span>
</span><span id="line-78"></span><span>
</span><span id="line-79"></span><span class="hs-comment">-- | Converts a doubly-nested list of input ids to a batched input tensor.</span><span>
</span><span id="line-80"></span><span class="hs-comment">-- The outer list is over batches, the inner list over sequences.</span><span>
</span><span id="line-81"></span><span class="hs-comment">-- The batch size is inferred from the length of the outer list.</span><span>
</span><span id="line-82"></span><span class="hs-comment">-- The sequence length is inferred from the length of the inner list.</span><span>
</span><span id="line-83"></span><span class="hs-comment">-- The input ids are padded to the maximum sequence length.</span><span>
</span><span id="line-84"></span><span class="hs-comment">-- The output tensor is truncated to the maximum sequence length.</span><span>
</span><span id="line-85"></span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#mkTransformerInput"><span class="hs-identifier hs-type">mkTransformerInput</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-86"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679547772"><span class="annot"><a href="#local-6989586621679547772"><span class="hs-identifier hs-type">batchDim</span></a></span></span><span> </span><span id="local-6989586621679547771"><span class="annot"><a href="#local-6989586621679547771"><span class="hs-identifier hs-type">seqDim</span></a></span></span><span> </span><span id="local-6989586621679547770"><span class="annot"><a href="#local-6989586621679547770"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679547769"><span class="annot"><a href="#local-6989586621679547769"><span class="hs-identifier hs-type">m</span></a></span></span><span> </span><span id="local-6989586621679547768"><span class="annot"><a href="#local-6989586621679547768"><span class="hs-identifier hs-type">output</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-87"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier hs-type">MonadThrow</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547769"><span class="hs-identifier hs-type">m</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-88"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetDim"><span class="hs-identifier hs-type">SGetDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547772"><span class="hs-identifier hs-type">batchDim</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-89"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetDim"><span class="hs-identifier hs-type">SGetDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547771"><span class="hs-identifier hs-type">seqDim</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-90"></span><span>    </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679547772"><span class="hs-identifier hs-type">batchDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679547771"><span class="hs-identifier hs-type">seqDim</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-91"></span><span>      </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Seq"><span class="hs-identifier hs-type">Seq</span></a></span><span>
</span><span id="line-92"></span><span>          </span><span class="hs-special">(</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span>
</span><span id="line-93"></span><span>              </span><span class="hs-special">'</span><span class="hs-special">[</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#UncheckedSize"><span class="hs-identifier hs-type">UncheckedSize</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-94"></span><span>                 </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#UncheckedSize"><span class="hs-identifier hs-type">UncheckedSize</span></a></span><span>
</span><span id="line-95"></span><span>               </span><span class="hs-special">]</span><span>
</span><span id="line-96"></span><span>              </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679547772"><span class="hs-identifier hs-type">batchDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679547771"><span class="hs-identifier hs-type">seqDim</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-97"></span><span>          </span><span class="hs-special">)</span><span>
</span><span id="line-98"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679547772"><span class="hs-identifier hs-type">batchDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679547771"><span class="hs-identifier hs-type">seqDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-99"></span><span>    </span><span class="annot"><a href="#local-6989586621679547768"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-100"></span><span>      </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-101"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#WithoutGradient"><span class="hs-identifier hs-type">WithoutGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-102"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Dense"><span class="hs-identifier hs-type">Dense</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-103"></span><span>          </span><span class="annot"><a href="#local-6989586621679547770"><span class="hs-identifier hs-type">device</span></a></span><span>
</span><span id="line-104"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#Int64"><span class="hs-identifier hs-type">Int64</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-105"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679547772"><span class="hs-identifier hs-type">batchDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679547771"><span class="hs-identifier hs-type">seqDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-106"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-107"></span><span>  </span><span class="hs-comment">-- | padding token id</span><span>
</span><span id="line-108"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-109"></span><span>  </span><span class="hs-comment">-- | batch dimension singleton</span><span>
</span><span id="line-110"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547772"><span class="hs-identifier hs-type">batchDim</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-111"></span><span>  </span><span class="hs-comment">-- | sequence dimension singleton</span><span>
</span><span id="line-112"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547771"><span class="hs-identifier hs-type">seqDim</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-113"></span><span>  </span><span class="hs-comment">-- | device for the tensor</span><span>
</span><span id="line-114"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Device.html#SDevice"><span class="hs-identifier hs-type">SDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547770"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-115"></span><span>  </span><span class="hs-comment">-- | batch of input ids</span><span>
</span><span id="line-116"></span><span>  </span><span class="hs-special">[</span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">]</span><span class="hs-special">]</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-117"></span><span>  </span><span class="hs-comment">-- | input tensor</span><span>
</span><span id="line-118"></span><span>  </span><span class="annot"><a href="#local-6989586621679547769"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547768"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-119"></span><span id="mkTransformerInput"><span class="annot"><span class="annottext">mkTransformerInput :: Int
-&gt; SDim batchDim
-&gt; SDim seqDim
-&gt; SDevice device
-&gt; [[Int]]
-&gt; m output
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#mkTransformerInput"><span class="hs-identifier hs-var hs-var">mkTransformerInput</span></a></span></span><span> </span><span id="local-6989586621679547767"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679547767"><span class="hs-identifier hs-var">padTokenId</span></a></span></span><span> </span><span id="local-6989586621679547766"><span class="annot"><span class="annottext">SDim batchDim
</span><a href="#local-6989586621679547766"><span class="hs-identifier hs-var">batchDim</span></a></span></span><span> </span><span id="local-6989586621679547765"><span class="annot"><span class="annottext">SDim seqDim
</span><a href="#local-6989586621679547765"><span class="hs-identifier hs-var">seqDim</span></a></span></span><span> </span><span id="local-6989586621679547764"><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679547764"><span class="hs-identifier hs-var">device</span></a></span></span><span> </span><span id="local-6989586621679547763"><span class="annot"><span class="annottext">[[Int]]
</span><a href="#local-6989586621679547763"><span class="hs-identifier hs-var">xs</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-120"></span><span>  </span><span class="annot"><span class="annottext">SGradient ('Gradient 'WithoutGradient)
-&gt; SLayout ('Layout 'Dense)
-&gt; SDevice device
-&gt; [[Int]]
-&gt; m (Tensor
        ('Gradient 'WithoutGradient)
        ('Layout 'Dense)
        device
        ('DataType 'Int64)
        ('Shape
           '[ 'Dim ('Name &quot;*&quot;) 'UncheckedSize,
              'Dim ('Name &quot;*&quot;) 'UncheckedSize]))
forall a (dType :: DType) (dims :: [Dim (Name Symbol) (Size Nat)])
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (m :: * -&gt; *).
(TensorLike a dType dims, MonadThrow m) =&gt;
SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; a
-&gt; m (Tensor
        gradient layout device ('DataType dType) ('Shape dims))
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sToTensor"><span class="hs-identifier hs-var">sToTensor</span></a></span><span> </span><span class="annot"><span class="annottext">SGradient ('Gradient 'WithoutGradient)
</span><a href="#local-6989586621679547762"><span class="hs-identifier hs-var">gradient</span></a></span><span> </span><span class="annot"><span class="annottext">SLayout ('Layout 'Dense)
</span><a href="#local-6989586621679547761"><span class="hs-identifier hs-var">layout</span></a></span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679547764"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="annot"><span class="annottext">[[Int]]
</span><a href="#local-6989586621679547760"><span class="hs-identifier hs-var">paddedXs</span></a></span><span>
</span><span id="line-121"></span><span>    </span><span class="annot"><span class="annottext">m (Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     device
     ('DataType 'Int64)
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) 'UncheckedSize,
           'Dim ('Name &quot;*&quot;) 'UncheckedSize]))
-&gt; (Tensor
      ('Gradient 'WithoutGradient)
      ('Layout 'Dense)
      device
      ('DataType 'Int64)
      ('Shape
         '[ 'Dim ('Name &quot;*&quot;) 'UncheckedSize,
            'Dim ('Name &quot;*&quot;) 'UncheckedSize])
    -&gt; m output)
-&gt; m output
forall (m :: * -&gt; *) a b. Monad m =&gt; m a -&gt; (a -&gt; m b) -&gt; m b
</span><span class="hs-operator hs-var">&gt;&gt;=</span></span><span> </span><span class="annot"><span class="annottext">SShape ('Shape '[batchDim, seqDim])
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     device
     ('DataType 'Int64)
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) 'UncheckedSize,
           'Dim ('Name &quot;*&quot;) 'UncheckedSize])
-&gt; m (Tensor
        ('Gradient 'WithoutGradient)
        ('Layout 'Dense)
        device
        ('DataType 'Int64)
        (Seq
           ('Shape
              '[ 'Dim ('Name &quot;*&quot;) 'UncheckedSize,
                 'Dim ('Name &quot;*&quot;) 'UncheckedSize]
            &lt;+&gt; 'Shape '[batchDim, seqDim])
           ('Shape '[batchDim, seqDim])))
forall (shape' :: Shape [Dim (Name Symbol) (Size Nat)])
       (m :: * -&gt; *) (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
(SGetShape shape, MonadThrow m) =&gt;
SShape shape'
-&gt; Tensor gradient layout device dataType shape
-&gt; m (Tensor
        gradient layout device dataType (Seq (shape &lt;+&gt; shape') shape'))
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sCheckedShape"><span class="hs-identifier hs-var">sCheckedShape</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SList '[batchDim, seqDim] -&gt; SShape ('Shape '[batchDim, seqDim])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList '[batchDim, seqDim] -&gt; SShape ('Shape '[batchDim, seqDim]))
-&gt; SList '[batchDim, seqDim] -&gt; SShape ('Shape '[batchDim, seqDim])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">Sing batchDim
SDim batchDim
</span><a href="#local-6989586621679547766"><span class="hs-identifier hs-var">batchDim</span></a></span><span> </span><span class="annot"><span class="annottext">Sing batchDim -&gt; SList '[seqDim] -&gt; SList '[batchDim, seqDim]
forall a1 (a2 :: a1) (as :: [a1]).
Sing a2 -&gt; SList as -&gt; SList (a2 : as)
</span><a href="Torch.GraduallyTyped.Prelude.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">Sing seqDim
SDim seqDim
</span><a href="#local-6989586621679547765"><span class="hs-identifier hs-var">seqDim</span></a></span><span> </span><span class="annot"><span class="annottext">Sing seqDim -&gt; SList '[] -&gt; SList '[seqDim]
forall a1 (a2 :: a1) (as :: [a1]).
Sing a2 -&gt; SList as -&gt; SList (a2 : as)
</span><a href="Torch.GraduallyTyped.Prelude.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-122"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-123"></span><span>    </span><span id="local-6989586621679547762"><span class="annot"><span class="annottext">gradient :: SGradient ('Gradient 'WithoutGradient)
</span><a href="#local-6989586621679547762"><span class="hs-identifier hs-var hs-var">gradient</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SRequiresGradient 'WithoutGradient
-&gt; SGradient ('Gradient 'WithoutGradient)
forall (requiresGradient :: RequiresGradient).
SRequiresGradient requiresGradient
-&gt; SGradient ('Gradient requiresGradient)
</span><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier hs-var">SGradient</span></a></span><span> </span><span class="annot"><span class="annottext">SRequiresGradient 'WithoutGradient
</span><a href="Torch.GraduallyTyped.RequiresGradient.html#SWithoutGradient"><span class="hs-identifier hs-var">SWithoutGradient</span></a></span><span>
</span><span id="line-124"></span><span>    </span><span id="local-6989586621679547761"><span class="annot"><span class="annottext">layout :: SLayout ('Layout 'Dense)
</span><a href="#local-6989586621679547761"><span class="hs-identifier hs-var hs-var">layout</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SLayoutType 'Dense -&gt; SLayout ('Layout 'Dense)
forall (layoutType :: LayoutType).
SLayoutType layoutType -&gt; SLayout ('Layout layoutType)
</span><a href="Torch.GraduallyTyped.Layout.html#SLayout"><span class="hs-identifier hs-var">SLayout</span></a></span><span> </span><span class="annot"><span class="annottext">SLayoutType 'Dense
</span><a href="Torch.GraduallyTyped.Layout.html#SDense"><span class="hs-identifier hs-var">SDense</span></a></span><span>
</span><span id="line-125"></span><span>    </span><span id="local-6989586621679547754"><span class="annot"><span class="annottext">batchSize :: Integer
</span><a href="#local-6989586621679547754"><span class="hs-identifier hs-var hs-var">batchSize</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IsChecked Integer -&gt; Integer
forall a. IsChecked a -&gt; a
</span><a href="Torch.GraduallyTyped.Prelude.html#forgetIsChecked"><span class="hs-identifier hs-var">forgetIsChecked</span></a></span><span> </span><span class="annot"><span class="annottext">(IsChecked Integer -&gt; Integer)
-&gt; (Dim (IsChecked String) (IsChecked Integer)
    -&gt; IsChecked Integer)
-&gt; Dim (IsChecked String) (IsChecked Integer)
-&gt; Integer
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Dim (IsChecked String) (IsChecked Integer) -&gt; IsChecked Integer
forall name size. Dim name size -&gt; size
</span><a href="Torch.GraduallyTyped.Shape.Type.html#dimSize"><span class="hs-identifier hs-var hs-var">dimSize</span></a></span><span> </span><span class="annot"><span class="annottext">(Dim (IsChecked String) (IsChecked Integer) -&gt; Integer)
-&gt; Dim (IsChecked String) (IsChecked Integer) -&gt; Integer
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">Sing batchDim -&gt; Demote (Dim (Name Symbol) (Size Nat))
forall k (a :: k). SingKind k =&gt; Sing a -&gt; Demote k
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">fromSing</span></a></span><span> </span><span class="annot"><span class="annottext">Sing batchDim
SDim batchDim
</span><a href="#local-6989586621679547766"><span class="hs-identifier hs-var">batchDim</span></a></span><span>
</span><span id="line-126"></span><span>    </span><span id="local-6989586621679547751"><span class="annot"><span class="annottext">seqSize :: Integer
</span><a href="#local-6989586621679547751"><span class="hs-identifier hs-var hs-var">seqSize</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">IsChecked Integer -&gt; Integer
forall a. IsChecked a -&gt; a
</span><a href="Torch.GraduallyTyped.Prelude.html#forgetIsChecked"><span class="hs-identifier hs-var">forgetIsChecked</span></a></span><span> </span><span class="annot"><span class="annottext">(IsChecked Integer -&gt; Integer)
-&gt; (Dim (IsChecked String) (IsChecked Integer)
    -&gt; IsChecked Integer)
-&gt; Dim (IsChecked String) (IsChecked Integer)
-&gt; Integer
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Dim (IsChecked String) (IsChecked Integer) -&gt; IsChecked Integer
forall name size. Dim name size -&gt; size
</span><a href="Torch.GraduallyTyped.Shape.Type.html#dimSize"><span class="hs-identifier hs-var hs-var">dimSize</span></a></span><span> </span><span class="annot"><span class="annottext">(Dim (IsChecked String) (IsChecked Integer) -&gt; Integer)
-&gt; Dim (IsChecked String) (IsChecked Integer) -&gt; Integer
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">Sing seqDim -&gt; Demote (Dim (Name Symbol) (Size Nat))
forall k (a :: k). SingKind k =&gt; Sing a -&gt; Demote k
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">fromSing</span></a></span><span> </span><span class="annot"><span class="annottext">Sing seqDim
SDim seqDim
</span><a href="#local-6989586621679547765"><span class="hs-identifier hs-var">seqDim</span></a></span><span>
</span><span id="line-127"></span><span>    </span><span id="local-6989586621679547750"><span class="annot"><span class="annottext">emptySeq :: [Int]
</span><a href="#local-6989586621679547750"><span class="hs-identifier hs-var hs-var">emptySeq</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; [Int]
forall a. Int -&gt; a -&gt; [a]
</span><span class="hs-identifier hs-var">replicate</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Integer -&gt; Int
forall a b. (Integral a, Num b) =&gt; a -&gt; b
</span><span class="hs-identifier hs-var">fromIntegral</span></span><span> </span><span class="annot"><span class="annottext">Integer
</span><a href="#local-6989586621679547751"><span class="hs-identifier hs-var">seqSize</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679547767"><span class="hs-identifier hs-var">padTokenId</span></a></span><span>
</span><span id="line-128"></span><span>    </span><span id="local-6989586621679547760"><span class="annot"><span class="annottext">paddedXs :: [[Int]]
</span><a href="#local-6989586621679547760"><span class="hs-identifier hs-var hs-var">paddedXs</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Integer -&gt; [Int] -&gt; [[Int]] -&gt; [[Int]]
forall n a. Integral n =&gt; n -&gt; a -&gt; [a] -&gt; [a]
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#padded"><span class="hs-identifier hs-var">padded</span></a></span><span> </span><span class="annot"><span class="annottext">Integer
</span><a href="#local-6989586621679547754"><span class="hs-identifier hs-var">batchSize</span></a></span><span> </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679547750"><span class="hs-identifier hs-var">emptySeq</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Integer -&gt; Int -&gt; [Int] -&gt; [Int]
forall n a. Integral n =&gt; n -&gt; a -&gt; [a] -&gt; [a]
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#padded"><span class="hs-identifier hs-var">padded</span></a></span><span> </span><span class="annot"><span class="annottext">Integer
</span><a href="#local-6989586621679547751"><span class="hs-identifier hs-var">seqSize</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679547767"><span class="hs-identifier hs-var">padTokenId</span></a></span><span> </span><span class="annot"><span class="annottext">([Int] -&gt; [Int]) -&gt; [[Int]] -&gt; [[Int]]
forall (f :: * -&gt; *) a b. Functor f =&gt; (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;$&gt;</span></span><span> </span><span class="annot"><span class="annottext">[[Int]]
</span><a href="#local-6989586621679547763"><span class="hs-identifier hs-var">xs</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-129"></span><span>
</span><span id="line-130"></span><span class="hs-keyword">type</span><span> </span><span id="MkPosC"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkPosC"><span class="hs-identifier hs-var">MkPosC</span></a></span></span><span> </span><span id="local-6989586621679547748"><span class="annot"><a href="#local-6989586621679547748"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679547747"><span class="annot"><a href="#local-6989586621679547747"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679547746"><span class="annot"><a href="#local-6989586621679547746"><span class="hs-identifier hs-type">seqDim</span></a></span></span><span> </span><span id="local-6989586621679547745"><span class="annot"><a href="#local-6989586621679547745"><span class="hs-identifier hs-type">seqName</span></a></span></span><span> </span><span id="local-6989586621679547744"><span class="annot"><a href="#local-6989586621679547744"><span class="hs-identifier hs-type">seqSize</span></a></span></span><span> </span><span id="local-6989586621679547743"><span class="annot"><a href="#local-6989586621679547743"><span class="hs-identifier hs-type">output</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-131"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetDevice"><span class="hs-identifier hs-type">SGetDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547748"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-132"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetShape"><span class="hs-identifier hs-type">SGetShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547747"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-133"></span><span>    </span><span class="annot"><a href="#local-6989586621679547746"><span class="hs-identifier hs-type">seqDim</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679547747"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#%21"><span class="hs-glyph hs-type">!</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-134"></span><span>    </span><span class="annot"><a href="#local-6989586621679547746"><span class="hs-identifier hs-type">seqDim</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547745"><span class="hs-identifier hs-type">seqName</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547744"><span class="hs-identifier hs-type">seqSize</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-135"></span><span>    </span><span class="annot"><a href="#local-6989586621679547743"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-136"></span><span>      </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-137"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#WithoutGradient"><span class="hs-identifier hs-type">WithoutGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-138"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Dense"><span class="hs-identifier hs-type">Dense</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-139"></span><span>          </span><span class="annot"><a href="#local-6989586621679547748"><span class="hs-identifier hs-type">device</span></a></span><span>
</span><span id="line-140"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#Int64"><span class="hs-identifier hs-type">Int64</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-141"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679547744"><span class="hs-identifier hs-type">seqSize</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-142"></span><span>  </span><span class="hs-special">)</span><span>
</span><span id="line-143"></span><span>
</span><span id="line-144"></span><span class="hs-comment">-- | Computes absolute positions of the input tokens.</span><span>
</span><span id="line-145"></span><span class="hs-comment">-- Given an input tensor of shape @[batchDim, Dim seqName seqSize]@,</span><span>
</span><span id="line-146"></span><span class="hs-comment">-- returns a tensor of shape @[Dim &quot;*&quot; seqSize]@.</span><span>
</span><span id="line-147"></span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#mkPos"><span class="hs-identifier hs-type">mkPos</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-148"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679548228"><span class="annot"><a href="#local-6989586621679548228"><span class="hs-identifier hs-type">m</span></a></span></span><span> </span><span id="local-6989586621679548221"><span class="annot"><a href="#local-6989586621679548221"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679548220"><span class="annot"><a href="#local-6989586621679548220"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679548227"><span class="annot"><a href="#local-6989586621679548227"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679548219"><span class="annot"><a href="#local-6989586621679548219"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679548226"><span class="annot"><a href="#local-6989586621679548226"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679548225"><span class="annot"><a href="#local-6989586621679548225"><span class="hs-identifier hs-type">seqDim</span></a></span></span><span> </span><span id="local-6989586621679548224"><span class="annot"><a href="#local-6989586621679548224"><span class="hs-identifier hs-type">seqName</span></a></span></span><span> </span><span id="local-6989586621679548223"><span class="annot"><a href="#local-6989586621679548223"><span class="hs-identifier hs-type">seqSize</span></a></span></span><span> </span><span id="local-6989586621679548222"><span class="annot"><a href="#local-6989586621679548222"><span class="hs-identifier hs-type">output</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-149"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier hs-type">MonadThrow</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679548228"><span class="hs-identifier hs-type">m</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-150"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkPosC"><span class="hs-identifier hs-type">MkPosC</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679548227"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679548226"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679548225"><span class="hs-identifier hs-type">seqDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679548224"><span class="hs-identifier hs-type">seqName</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679548223"><span class="hs-identifier hs-type">seqSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679548222"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-151"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-152"></span><span>  </span><span class="hs-comment">-- | input tensor</span><span>
</span><span id="line-153"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679548221"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679548220"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679548227"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679548219"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679548226"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-154"></span><span>  </span><span class="hs-comment">-- | positions of the input tokens</span><span>
</span><span id="line-155"></span><span>  </span><span class="annot"><a href="#local-6989586621679548228"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679548222"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-156"></span><span id="mkPos"><span class="annot"><span class="annottext">mkPos :: Tensor gradient layout device dataType shape -&gt; m output
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#mkPos"><span class="hs-identifier hs-var hs-var">mkPos</span></a></span></span><span> </span><span id="local-6989586621679547741"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679547741"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-157"></span><span>  </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679547740"><span class="annot"><span class="annottext">device :: SDevice device
</span><a href="#local-6989586621679547740"><span class="hs-identifier hs-var hs-var">device</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape -&gt; SDevice device
forall (device :: Device (DeviceType Nat))
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SGetDevice device =&gt;
Tensor gradient layout device dataType shape -&gt; SDevice device
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sGetDevice"><span class="hs-identifier hs-var">sGetDevice</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679547741"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-158"></span><span>      </span><span id="local-6989586621679547738"><span class="annot"><span class="annottext">shape :: SShape shape
</span><a href="#local-6989586621679547738"><span class="hs-identifier hs-var hs-var">shape</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape -&gt; SShape shape
forall (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType).
SGetShape shape =&gt;
Tensor gradient layout device dataType shape -&gt; SShape shape
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sGetShape"><span class="hs-identifier hs-var">sGetShape</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679547741"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-159"></span><span>  </span><span id="local-6989586621679547736"><span class="annot"><span class="annottext">SDim ('Dim seqName seqSize)
</span><a href="#local-6989586621679547736"><span class="hs-identifier hs-var">seqDim</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">SSelectDim ('SelectDim ('ByIndex 1))
-&gt; SShape shape -&gt; m (SDim ('Dim seqName seqSize))
forall (selectDim :: SelectDim (By Symbol Nat))
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (dim :: Dim (Name Symbol) (Size Nat)) (m :: * -&gt; *).
(dim ~ GetDimF selectDim shape, MonadThrow m) =&gt;
SSelectDim selectDim -&gt; SShape shape -&gt; m (SDim dim)
</span><a href="Torch.GraduallyTyped.Shape.Class.html#sGetDimFromShape"><span class="hs-identifier hs-var">sGetDimFromShape</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SBy ('ByIndex 1) -&gt; SSelectDim ('SelectDim ('ByIndex 1))
forall (by :: By Symbol Nat). SBy by -&gt; SSelectDim ('SelectDim by)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSelectDim"><span class="hs-identifier hs-var">SSelectDim</span></a></span><span> </span><span class="annot"><span class="annottext">(SBy ('ByIndex 1) -&gt; SSelectDim ('SelectDim ('ByIndex 1)))
-&gt; SBy ('ByIndex 1) -&gt; SSelectDim ('SelectDim ('ByIndex 1))
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">KnownNat 1 =&gt; SBy ('ByIndex 1)
forall (index :: Nat). KnownNat index =&gt; SBy ('ByIndex index)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SByIndex"><span class="hs-identifier hs-var">SByIndex</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">SShape shape
</span><a href="#local-6989586621679547738"><span class="hs-identifier hs-var">shape</span></a></span><span>
</span><span id="line-160"></span><span>  </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679547733"><span class="annot"><span class="annottext">seqSize :: SSize seqSize
</span><a href="#local-6989586621679547733"><span class="hs-identifier hs-var hs-var">seqSize</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SDim ('Dim seqName seqSize) -&gt; SSize seqSize
forall (name :: Name Symbol) (size :: Size Nat).
SDim ('Dim name size) -&gt; SSize size
</span><a href="Torch.GraduallyTyped.Shape.Type.html#sDimSize"><span class="hs-identifier hs-var hs-var">sDimSize</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim seqName seqSize)
</span><a href="#local-6989586621679547736"><span class="hs-identifier hs-var">seqDim</span></a></span><span>
</span><span id="line-161"></span><span>      </span><span id="local-6989586621679547732"><span class="annot"><span class="annottext">pos :: Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  device
  ('DataType 'Int64)
  ('Shape '[ 'Dim ('Name &quot;*&quot;) seqSize])
</span><a href="#local-6989586621679547732"><span class="hs-identifier hs-var hs-var">pos</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-162"></span><span>        </span><span class="annot"><span class="annottext">SGradient ('Gradient 'WithoutGradient)
-&gt; SLayout ('Layout 'Dense)
-&gt; SDevice device
-&gt; SDataType ('DataType 'Int64)
-&gt; SSize seqSize
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     device
     ('DataType 'Int64)
     ('Shape '[ 'Dim ('Name &quot;*&quot;) seqSize])
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType) (size :: Size Nat)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
(shape ~ 'Shape '[ 'Dim ('Name &quot;*&quot;) size]) =&gt;
SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SSize size
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.Creation.html#sArangeNaturals"><span class="hs-identifier hs-var">sArangeNaturals</span></a></span><span>
</span><span id="line-163"></span><span>          </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SRequiresGradient 'WithoutGradient
-&gt; SGradient ('Gradient 'WithoutGradient)
forall (requiresGradient :: RequiresGradient).
SRequiresGradient requiresGradient
-&gt; SGradient ('Gradient requiresGradient)
</span><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier hs-var">SGradient</span></a></span><span> </span><span class="annot"><span class="annottext">SRequiresGradient 'WithoutGradient
</span><a href="Torch.GraduallyTyped.RequiresGradient.html#SWithoutGradient"><span class="hs-identifier hs-var">SWithoutGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-164"></span><span>          </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SLayoutType 'Dense -&gt; SLayout ('Layout 'Dense)
forall (layoutType :: LayoutType).
SLayoutType layoutType -&gt; SLayout ('Layout layoutType)
</span><a href="Torch.GraduallyTyped.Layout.html#SLayout"><span class="hs-identifier hs-var">SLayout</span></a></span><span> </span><span class="annot"><span class="annottext">SLayoutType 'Dense
</span><a href="Torch.GraduallyTyped.Layout.html#SDense"><span class="hs-identifier hs-var">SDense</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-165"></span><span>          </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679547740"><span class="hs-identifier hs-var">device</span></a></span><span>
</span><span id="line-166"></span><span>          </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SDType 'Int64 -&gt; SDataType ('DataType 'Int64)
forall (dType :: DType).
SDType dType -&gt; SDataType ('DataType dType)
</span><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier hs-var">SDataType</span></a></span><span> </span><span class="annot"><span class="annottext">SDType 'Int64
</span><a href="Torch.GraduallyTyped.DType.html#SInt64"><span class="hs-identifier hs-var">SInt64</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-167"></span><span>          </span><span class="annot"><span class="annottext">SSize seqSize
</span><a href="#local-6989586621679547733"><span class="hs-identifier hs-var">seqSize</span></a></span><span>
</span><span id="line-168"></span><span>  </span><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  device
  ('DataType 'Int64)
  ('Shape '[ 'Dim ('Name &quot;*&quot;) seqSize])
-&gt; m (Tensor
        ('Gradient 'WithoutGradient)
        ('Layout 'Dense)
        device
        ('DataType 'Int64)
        ('Shape '[ 'Dim ('Name &quot;*&quot;) seqSize]))
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  device
  ('DataType 'Int64)
  ('Shape '[ 'Dim ('Name &quot;*&quot;) seqSize])
</span><a href="#local-6989586621679547732"><span class="hs-identifier hs-var">pos</span></a></span><span>
</span><span id="line-169"></span><span>
</span><span id="line-170"></span><span class="hs-keyword">data</span><span> </span><span id="MkAbsPos"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkAbsPos"><span class="hs-identifier hs-var">MkAbsPos</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span id="MkAbsPos"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkAbsPos"><span class="hs-identifier hs-var">MkAbsPos</span></a></span></span><span> </span><span class="hs-glyph">|</span><span> </span><span id="MkAbsPosWithOffset"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkAbsPosWithOffset"><span class="hs-identifier hs-var">MkAbsPosWithOffset</span></a></span></span><span> </span><span class="hs-special">{</span><span id="absPosOffset"><span class="annot"><span class="annottext">MkAbsPos -&gt; Int
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#absPosOffset"><span class="hs-identifier hs-var hs-var">absPosOffset</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">}</span><span>
</span><span id="line-171"></span><span>
</span><span id="line-172"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">instance</span><span> </span><span id="ModelSpec"><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier hs-var">ModelSpec</span></a></span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkAbsPos"><span class="hs-identifier hs-type">MkAbsPos</span></a></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkAbsPos"><span class="hs-identifier hs-type">MkAbsPos</span></a></span><span>
</span><span id="line-173"></span><span>
</span><span id="line-174"></span><span id="local-6989586621679547726"><span class="hs-keyword">instance</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkAbsPos"><span class="hs-identifier hs-type">MkAbsPos</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547726"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkAbsPos"><span class="hs-identifier hs-type">MkAbsPos</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547726"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-175"></span><span>  </span><span id="local-6989586621679547723"><span class="annot"><span class="annottext">initialize :: ModelSpec MkAbsPos
-&gt; Generator generatorDevice
-&gt; m (MkAbsPos, Generator generatorDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#initialize"><span class="hs-identifier hs-var hs-var hs-var hs-var">initialize</span></a></span></span><span> </span><span id="local-6989586621679547721"><span class="annot"><span class="annottext">ModelSpec MkAbsPos
</span><a href="#local-6989586621679547721"><span class="hs-identifier hs-var">spec</span></a></span></span><span> </span><span id="local-6989586621679547720"><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679547720"><span class="hs-identifier hs-var">g</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(MkAbsPos, Generator generatorDevice)
-&gt; m (MkAbsPos, Generator generatorDevice)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">ModelSpec MkAbsPos
MkAbsPos
</span><a href="#local-6989586621679547721"><span class="hs-identifier hs-var">spec</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679547720"><span class="hs-identifier hs-var">g</span></a></span><span class="hs-special">)</span></span><span>
</span><span id="line-176"></span><span>
</span><span id="line-177"></span><span class="hs-keyword">instance</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasStateDict"><span class="hs-identifier hs-type">HasStateDict</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkAbsPos"><span class="hs-identifier hs-type">MkAbsPos</span></a></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-178"></span><span>  </span><span id="local-6989586621679547716"><span class="annot"><span class="annottext">fromStateDict :: ModelSpec MkAbsPos -&gt; StateDictKey -&gt; m MkAbsPos
</span><a href="Torch.GraduallyTyped.NN.Class.html#fromStateDict"><span class="hs-identifier hs-var hs-var hs-var hs-var">fromStateDict</span></a></span></span><span> </span><span id="local-6989586621679547714"><span class="annot"><span class="annottext">ModelSpec MkAbsPos
</span><a href="#local-6989586621679547714"><span class="hs-identifier hs-var">spec</span></a></span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">MkAbsPos -&gt; m MkAbsPos
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">ModelSpec MkAbsPos
MkAbsPos
</span><a href="#local-6989586621679547714"><span class="hs-identifier hs-var">spec</span></a></span><span>
</span><span id="line-179"></span><span>  </span><span id="local-6989586621679547713"><span class="annot"><span class="annottext">toStateDict :: StateDictKey -&gt; MkAbsPos -&gt; m ()
</span><a href="Torch.GraduallyTyped.NN.Class.html#toStateDict"><span class="hs-identifier hs-var hs-var hs-var hs-var">toStateDict</span></a></span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="annottext">MkAbsPos
</span><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">() -&gt; m ()
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-180"></span><span>
</span><span id="line-181"></span><span id="local-6989586621679547702"><span id="local-6989586621679547703"><span id="local-6989586621679547704"><span id="local-6989586621679547705"><span id="local-6989586621679547706"><span id="local-6989586621679547707"><span id="local-6989586621679547708"><span id="local-6989586621679547709"><span id="local-6989586621679547710"><span id="local-6989586621679547711"><span class="hs-keyword">instance</span><span>
</span><span id="line-182"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkPosC"><span class="hs-identifier hs-type">MkPosC</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547711"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547710"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547709"><span class="hs-identifier hs-type">seqDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547708"><span class="hs-identifier hs-type">seqName</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547707"><span class="hs-identifier hs-type">seqSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547706"><span class="hs-identifier hs-type">output</span></a></span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-183"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-184"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkAbsPos"><span class="hs-identifier hs-type">MkAbsPos</span></a></span><span>
</span><span id="line-185"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547705"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547704"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547711"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547703"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547710"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-186"></span><span>    </span><span class="annot"><a href="#local-6989586621679547702"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-187"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#WithoutGradient"><span class="hs-identifier hs-type">WithoutGradient</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Dense"><span class="hs-identifier hs-type">Dense</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679547711"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#Int64"><span class="hs-identifier hs-type">Int64</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679547707"><span class="hs-identifier hs-type">seqSize</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-188"></span><span>    </span><span class="annot"><a href="#local-6989586621679547702"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-189"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-190"></span><span>  </span><span id="local-6989586621679547699"><span class="annot"><span class="annottext">forward :: MkAbsPos
-&gt; Tensor gradient layout device dataType shape
-&gt; Generator generatorDevice
-&gt; m (Tensor
        ('Gradient 'WithoutGradient)
        ('Layout 'Dense)
        device
        ('DataType 'Int64)
        ('Shape '[ 'Dim ('Name &quot;*&quot;) seqSize]),
      Generator generatorDevice)
</span><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var hs-var hs-var hs-var">forward</span></a></span></span><span> </span><span class="annot"><span class="annottext">MkAbsPos
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkAbsPos"><span class="hs-identifier hs-var">MkAbsPos</span></a></span><span> </span><span id="local-6989586621679547697"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679547697"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span id="local-6989586621679547696"><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679547696"><span class="hs-identifier hs-var">g</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-191"></span><span>    </span><span id="local-6989586621679547695"><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  device
  ('DataType 'Int64)
  ('Shape '[ 'Dim ('Name &quot;*&quot;) seqSize])
</span><a href="#local-6989586621679547695"><span class="hs-identifier hs-var">pos</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
-&gt; m (Tensor
        ('Gradient 'WithoutGradient)
        ('Layout 'Dense)
        device
        ('DataType 'Int64)
        ('Shape '[ 'Dim ('Name &quot;*&quot;) seqSize]))
forall (m :: * -&gt; *) (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (seqDim :: Dim (Name Symbol) (Size Nat)) (seqName :: Name Symbol)
       (seqSize :: Size Nat) output.
(MonadThrow m,
 MkPosC device shape seqDim seqName seqSize output) =&gt;
Tensor gradient layout device dataType shape -&gt; m output
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#mkPos"><span class="hs-identifier hs-var">mkPos</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679547697"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-192"></span><span>    </span><span class="annot"><span class="annottext">(Tensor
   ('Gradient 'WithoutGradient)
   ('Layout 'Dense)
   device
   ('DataType 'Int64)
   ('Shape '[ 'Dim ('Name &quot;*&quot;) seqSize]),
 Generator generatorDevice)
-&gt; m (Tensor
        ('Gradient 'WithoutGradient)
        ('Layout 'Dense)
        device
        ('DataType 'Int64)
        ('Shape '[ 'Dim ('Name &quot;*&quot;) seqSize]),
      Generator generatorDevice)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  device
  ('DataType 'Int64)
  ('Shape '[ 'Dim ('Name &quot;*&quot;) seqSize])
</span><a href="#local-6989586621679547695"><span class="hs-identifier hs-var">pos</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679547696"><span class="hs-identifier hs-var">g</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-193"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkAbsPosWithOffset"><span class="hs-identifier hs-type">MkAbsPosWithOffset</span></a></span><span> </span><span class="hs-special">{</span><span id="local-6989586621679547694"><span class="annot"><span class="annottext">Int
absPosOffset :: Int
absPosOffset :: MkAbsPos -&gt; Int
</span><a href="#local-6989586621679547694"><span class="hs-glyph hs-var hs-var">..</span></a></span></span><span class="hs-special">}</span><span> </span><span id="local-6989586621679547693"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679547693"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span id="local-6989586621679547692"><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679547692"><span class="hs-identifier hs-var">g</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-194"></span><span>    </span><span id="local-6989586621679547691"><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  device
  ('DataType 'Int64)
  ('Shape '[ 'Dim ('Name &quot;*&quot;) seqSize])
</span><a href="#local-6989586621679547691"><span class="hs-identifier hs-var">pos</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
-&gt; m (Tensor
        ('Gradient 'WithoutGradient)
        ('Layout 'Dense)
        device
        ('DataType 'Int64)
        ('Shape '[ 'Dim ('Name &quot;*&quot;) seqSize]))
forall (m :: * -&gt; *) (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (seqDim :: Dim (Name Symbol) (Size Nat)) (seqName :: Name Symbol)
       (seqSize :: Size Nat) output.
(MonadThrow m,
 MkPosC device shape seqDim seqName seqSize output) =&gt;
Tensor gradient layout device dataType shape -&gt; m output
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#mkPos"><span class="hs-identifier hs-var">mkPos</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679547693"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-195"></span><span>    </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679547690"><span class="annot"><span class="annottext">pos' :: Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  device
  ('DataType 'Int64)
  ('Shape '[ 'Dim ('Name &quot;*&quot;) seqSize])
</span><a href="#local-6989586621679547690"><span class="hs-identifier hs-var hs-var">pos'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  device
  ('DataType 'Int64)
  ('Shape '[ 'Dim ('Name &quot;*&quot;) seqSize])
-&gt; Int
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     device
     ('DataType 'Int64)
     ('Shape '[ 'Dim ('Name &quot;*&quot;) seqSize])
forall other (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
Scalar other =&gt;
Tensor gradient layout device dataType shape
-&gt; other -&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#addScalar"><span class="hs-identifier hs-var">addScalar</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  device
  ('DataType 'Int64)
  ('Shape '[ 'Dim ('Name &quot;*&quot;) seqSize])
</span><a href="#local-6989586621679547691"><span class="hs-identifier hs-var">pos</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679547694"><span class="hs-identifier hs-var">absPosOffset</span></a></span><span>
</span><span id="line-196"></span><span>    </span><span class="annot"><span class="annottext">(Tensor
   ('Gradient 'WithoutGradient)
   ('Layout 'Dense)
   device
   ('DataType 'Int64)
   ('Shape '[ 'Dim ('Name &quot;*&quot;) seqSize]),
 Generator generatorDevice)
-&gt; m (Tensor
        ('Gradient 'WithoutGradient)
        ('Layout 'Dense)
        device
        ('DataType 'Int64)
        ('Shape '[ 'Dim ('Name &quot;*&quot;) seqSize]),
      Generator generatorDevice)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  device
  ('DataType 'Int64)
  ('Shape '[ 'Dim ('Name &quot;*&quot;) seqSize])
</span><a href="#local-6989586621679547690"><span class="hs-identifier hs-var">pos'</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679547692"><span class="hs-identifier hs-var">g</span></a></span><span class="hs-special">)</span></span></span></span></span></span></span></span></span></span></span><span>
</span><span id="line-197"></span><span>
</span><span id="line-198"></span><span class="hs-comment">-- | Computes relative positions of the input tokens to the encoder.</span><span>
</span><span id="line-199"></span><span class="hs-comment">--</span><span>
</span><span id="line-200"></span><span class="hs-comment">-- &gt;&gt;&gt; mkRelPos' 32 128 21 17</span><span>
</span><span id="line-201"></span><span class="hs-comment">-- [[0,17,18,19,20,21,22,23,24,24,24,24,25,25,25,25,26],[1,0,17,18,19,20,21,22,23,24,24,24,24,25,25,25,25],[2,1,0,17,18,19,20,21,22,23,24,24,24,24,25,25,25],[3,2,1,0,17,18,19,20,21,22,23,24,24,24,24,25,25],[4,3,2,1,0,17,18,19,20,21,22,23,24,24,24,24,25],[5,4,3,2,1,0,17,18,19,20,21,22,23,24,24,24,24],[6,5,4,3,2,1,0,17,18,19,20,21,22,23,24,24,24],[7,6,5,4,3,2,1,0,17,18,19,20,21,22,23,24,24],[8,7,6,5,4,3,2,1,0,17,18,19,20,21,22,23,24],[8,8,7,6,5,4,3,2,1,0,17,18,19,20,21,22,23],[8,8,8,7,6,5,4,3,2,1,0,17,18,19,20,21,22],[8,8,8,8,7,6,5,4,3,2,1,0,17,18,19,20,21],[9,8,8,8,8,7,6,5,4,3,2,1,0,17,18,19,20],[9,9,8,8,8,8,7,6,5,4,3,2,1,0,17,18,19],[9,9,9,8,8,8,8,7,6,5,4,3,2,1,0,17,18],[9,9,9,9,8,8,8,8,7,6,5,4,3,2,1,0,17],[10,9,9,9,9,8,8,8,8,7,6,5,4,3,2,1,0],[10,10,9,9,9,9,8,8,8,8,7,6,5,4,3,2,1],[10,10,10,9,9,9,9,8,8,8,8,7,6,5,4,3,2],[10,10,10,10,9,9,9,9,8,8,8,8,7,6,5,4,3],[10,10,10,10,10,9,9,9,9,8,8,8,8,7,6,5,4]]</span><span>
</span><span id="line-202"></span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#mkRelPos%27"><span class="hs-identifier hs-type">mkRelPos'</span></a></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">[</span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">]</span><span class="hs-special">]</span><span>
</span><span id="line-203"></span><span id="mkRelPos%27"><span class="annot"><span class="annottext">mkRelPos' :: Int -&gt; Int -&gt; Int -&gt; Int -&gt; [[Int]]
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#mkRelPos%27"><span class="hs-identifier hs-var hs-var">mkRelPos'</span></a></span></span><span> </span><span id="local-6989586621679547688"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679547688"><span class="hs-identifier hs-var">numBuckets</span></a></span></span><span> </span><span id="local-6989586621679547687"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679547687"><span class="hs-identifier hs-var">maxDistance</span></a></span></span><span> </span><span id="local-6989586621679547686"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679547686"><span class="hs-identifier hs-var">querySize</span></a></span></span><span> </span><span id="local-6989586621679547685"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679547685"><span class="hs-identifier hs-var">keySize</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-204"></span><span>  </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679547684"><span class="annot"><span class="annottext">queryPos :: [Int]
</span><a href="#local-6989586621679547684"><span class="hs-identifier hs-var hs-var">queryPos</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">0</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">1</span></span><span> </span><span class="hs-glyph">..</span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679547686"><span class="hs-identifier hs-var">querySize</span></a></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Int
forall a. Num a =&gt; a -&gt; a -&gt; a
</span><span class="hs-glyph hs-var">-</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">1</span></span><span class="hs-special">]</span><span>
</span><span id="line-205"></span><span>      </span><span id="local-6989586621679547683"><span class="annot"><span class="annottext">keyPos :: [Int]
</span><a href="#local-6989586621679547683"><span class="hs-identifier hs-var hs-var">keyPos</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">0</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">1</span></span><span> </span><span class="hs-glyph">..</span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679547685"><span class="hs-identifier hs-var">keySize</span></a></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Int
forall a. Num a =&gt; a -&gt; a -&gt; a
</span><span class="hs-glyph hs-var">-</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">1</span></span><span class="hs-special">]</span><span>
</span><span id="line-206"></span><span>      </span><span id="local-6989586621679547682"><span class="annot"><span class="annottext">numBuckets' :: Int
</span><a href="#local-6989586621679547682"><span class="hs-identifier hs-var hs-var">numBuckets'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679547688"><span class="hs-identifier hs-var">numBuckets</span></a></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Int
forall a. Integral a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">`div`</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">2</span></span><span>
</span><span id="line-207"></span><span>      </span><span id="local-6989586621679547680"><span class="annot"><span class="annottext">maxExact :: Int
</span><a href="#local-6989586621679547680"><span class="hs-identifier hs-var hs-var">maxExact</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679547682"><span class="hs-identifier hs-var">numBuckets'</span></a></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Int
forall a. Integral a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">`div`</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">2</span></span><span>
</span><span id="line-208"></span><span>   </span><span class="hs-keyword">in</span><span> </span><span class="annot"><span class="annottext">(Int -&gt; [Int]) -&gt; [Int] -&gt; [[Int]]
forall (f :: * -&gt; *) a b. Functor f =&gt; (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-identifier hs-var">fmap</span></span><span>
</span><span id="line-209"></span><span>        </span><span class="hs-special">(</span><span> </span><span class="hs-glyph">\</span><span id="local-6989586621679547679"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679547679"><span class="hs-identifier hs-var">qp</span></a></span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-210"></span><span>            </span><span class="annot"><span class="annottext">(Int -&gt; Int) -&gt; [Int] -&gt; [Int]
forall (f :: * -&gt; *) a b. Functor f =&gt; (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-identifier hs-var">fmap</span></span><span>
</span><span id="line-211"></span><span>              </span><span class="hs-special">(</span><span> </span><span class="hs-glyph">\</span><span id="local-6989586621679547678"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679547678"><span class="hs-identifier hs-var">kp</span></a></span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-212"></span><span>                  </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679547677"><span class="annot"><span class="annottext">rawRelPos :: Int
</span><a href="#local-6989586621679547677"><span class="hs-identifier hs-var hs-var">rawRelPos</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679547678"><span class="hs-identifier hs-var">kp</span></a></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Int
forall a. Num a =&gt; a -&gt; a -&gt; a
</span><span class="hs-glyph hs-var">-</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679547679"><span class="hs-identifier hs-var">qp</span></a></span><span>
</span><span id="line-213"></span><span>                      </span><span id="local-6989586621679547676"><span class="annot"><span class="annottext">absRelPos :: Int
</span><a href="#local-6989586621679547676"><span class="hs-identifier hs-var hs-var">absRelPos</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int
forall a. Num a =&gt; a -&gt; a
</span><span class="hs-identifier hs-var">abs</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679547677"><span class="hs-identifier hs-var">rawRelPos</span></a></span><span>
</span><span id="line-214"></span><span>                      </span><span id="local-6989586621679547674"><span class="annot"><span class="annottext">relBucket :: Int
</span><a href="#local-6989586621679547674"><span class="hs-identifier hs-var hs-var">relBucket</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">if</span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679547677"><span class="hs-identifier hs-var">rawRelPos</span></a></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Bool
forall a. Ord a =&gt; a -&gt; a -&gt; Bool
</span><span class="hs-operator hs-var">&gt;</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">0</span></span><span> </span><span class="hs-keyword">then</span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679547682"><span class="hs-identifier hs-var">numBuckets'</span></a></span><span> </span><span class="hs-keyword">else</span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">0</span></span><span>
</span><span id="line-215"></span><span>                      </span><span id="local-6989586621679547672"><span class="annot"><span class="annottext">relBucket' :: Int
</span><a href="#local-6989586621679547672"><span class="hs-identifier hs-var hs-var">relBucket'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-216"></span><span>                        </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679547671"><span class="annot"><span class="annottext">isSmall :: Bool
</span><a href="#local-6989586621679547671"><span class="hs-identifier hs-var hs-var">isSmall</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679547676"><span class="hs-identifier hs-var">absRelPos</span></a></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Bool
forall a. Ord a =&gt; a -&gt; a -&gt; Bool
</span><span class="hs-operator hs-var">&lt;</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679547680"><span class="hs-identifier hs-var">maxExact</span></a></span><span>
</span><span id="line-217"></span><span>                            </span><span id="local-6989586621679547669"><span class="annot"><span class="annottext">relPosIfLarge :: Int
</span><a href="#local-6989586621679547669"><span class="hs-identifier hs-var hs-var">relPosIfLarge</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-218"></span><span>                              </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679547680"><span class="hs-identifier hs-var">maxExact</span></a></span><span>
</span><span id="line-219"></span><span>                                </span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Int
forall a. Num a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">+</span></span><span> </span><span class="annot"><span class="annottext">Double -&gt; Int
</span><span class="hs-identifier hs-var">double2Int</span></span><span>
</span><span id="line-220"></span><span>                                  </span><span class="hs-special">(</span><span> </span><span class="annot"><span class="annottext">Double -&gt; Double -&gt; Double
forall a. Floating a =&gt; a -&gt; a -&gt; a
</span><span class="hs-identifier hs-var">logBase</span></span><span>
</span><span id="line-221"></span><span>                                      </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Int -&gt; Double
forall a b. (Integral a, Num b) =&gt; a -&gt; b
</span><span class="hs-identifier hs-var">fromIntegral</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679547687"><span class="hs-identifier hs-var">maxDistance</span></a></span><span> </span><span class="annot"><span class="annottext">Double -&gt; Double -&gt; Double
forall a. Fractional a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">/</span></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Double
forall a b. (Integral a, Num b) =&gt; a -&gt; b
</span><span class="hs-identifier hs-var">fromIntegral</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679547680"><span class="hs-identifier hs-var">maxExact</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-222"></span><span>                                      </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Int -&gt; Double
forall a b. (Integral a, Num b) =&gt; a -&gt; b
</span><span class="hs-identifier hs-var">fromIntegral</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679547676"><span class="hs-identifier hs-var">absRelPos</span></a></span><span> </span><span class="annot"><span class="annottext">Double -&gt; Double -&gt; Double
forall a. Fractional a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">/</span></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Double
forall a b. (Integral a, Num b) =&gt; a -&gt; b
</span><span class="hs-identifier hs-var">fromIntegral</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679547680"><span class="hs-identifier hs-var">maxExact</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-223"></span><span>                                      </span><span class="annot"><span class="annottext">Double -&gt; Double -&gt; Double
forall a. Num a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">*</span></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Double
forall a b. (Integral a, Num b) =&gt; a -&gt; b
</span><span class="hs-identifier hs-var">fromIntegral</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679547682"><span class="hs-identifier hs-var">numBuckets'</span></a></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Int
forall a. Num a =&gt; a -&gt; a -&gt; a
</span><span class="hs-glyph hs-var">-</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679547680"><span class="hs-identifier hs-var">maxExact</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-224"></span><span>                                  </span><span class="hs-special">)</span><span>
</span><span id="line-225"></span><span>                            </span><span id="local-6989586621679547664"><span class="annot"><span class="annottext">relPosIfLarge' :: Int
</span><a href="#local-6989586621679547664"><span class="hs-identifier hs-var hs-var">relPosIfLarge'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Int
forall a. Ord a =&gt; a -&gt; a -&gt; a
</span><span class="hs-identifier hs-var">min</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679547669"><span class="hs-identifier hs-var">relPosIfLarge</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679547682"><span class="hs-identifier hs-var">numBuckets'</span></a></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Int
forall a. Num a =&gt; a -&gt; a -&gt; a
</span><span class="hs-glyph hs-var">-</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">1</span></span><span class="hs-special">)</span><span>
</span><span id="line-226"></span><span>                         </span><span class="hs-keyword">in</span><span> </span><span class="hs-keyword">if</span><span> </span><span class="annot"><span class="annottext">Bool
</span><a href="#local-6989586621679547671"><span class="hs-identifier hs-var">isSmall</span></a></span><span> </span><span class="hs-keyword">then</span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679547676"><span class="hs-identifier hs-var">absRelPos</span></a></span><span> </span><span class="hs-keyword">else</span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679547664"><span class="hs-identifier hs-var">relPosIfLarge'</span></a></span><span>
</span><span id="line-227"></span><span>                   </span><span class="hs-keyword">in</span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679547674"><span class="hs-identifier hs-var">relBucket</span></a></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Int
forall a. Num a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">+</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679547672"><span class="hs-identifier hs-var">relBucket'</span></a></span><span>
</span><span id="line-228"></span><span>              </span><span class="hs-special">)</span><span>
</span><span id="line-229"></span><span>              </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679547683"><span class="hs-identifier hs-var">keyPos</span></a></span><span>
</span><span id="line-230"></span><span>        </span><span class="hs-special">)</span><span>
</span><span id="line-231"></span><span>        </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679547684"><span class="hs-identifier hs-var">queryPos</span></a></span><span>
</span><span id="line-232"></span><span>
</span><span id="line-233"></span><span class="hs-keyword">type</span><span> </span><span id="MkRelPosC"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkRelPosC"><span class="hs-identifier hs-var">MkRelPosC</span></a></span></span><span> </span><span id="local-6989586621679547662"><span class="annot"><a href="#local-6989586621679547662"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679547661"><span class="annot"><a href="#local-6989586621679547661"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679547660"><span class="annot"><a href="#local-6989586621679547660"><span class="hs-identifier hs-type">seqDim</span></a></span></span><span> </span><span id="local-6989586621679547659"><span class="annot"><a href="#local-6989586621679547659"><span class="hs-identifier hs-type">seqName</span></a></span></span><span> </span><span id="local-6989586621679547658"><span class="annot"><a href="#local-6989586621679547658"><span class="hs-identifier hs-type">seqSize</span></a></span></span><span> </span><span id="local-6989586621679547657"><span class="annot"><a href="#local-6989586621679547657"><span class="hs-identifier hs-type">output</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-234"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetDevice"><span class="hs-identifier hs-type">SGetDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547662"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-235"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetShape"><span class="hs-identifier hs-type">SGetShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547661"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-236"></span><span>    </span><span class="annot"><a href="#local-6989586621679547660"><span class="hs-identifier hs-type">seqDim</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679547661"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#%21"><span class="hs-glyph hs-type">!</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-237"></span><span>    </span><span class="annot"><a href="#local-6989586621679547660"><span class="hs-identifier hs-type">seqDim</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547659"><span class="hs-identifier hs-type">seqName</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547658"><span class="hs-identifier hs-type">seqSize</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-238"></span><span>    </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span>
</span><span id="line-239"></span><span>      </span><span class="hs-special">'</span><span class="hs-special">[</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-240"></span><span>         </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679547658"><span class="hs-identifier hs-type">seqSize</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-241"></span><span>         </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679547658"><span class="hs-identifier hs-type">seqSize</span></a></span><span>
</span><span id="line-242"></span><span>       </span><span class="hs-special">]</span><span>
</span><span id="line-243"></span><span>      </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Seq"><span class="hs-identifier hs-type">Seq</span></a></span><span>
</span><span id="line-244"></span><span>          </span><span class="hs-special">(</span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#UncheckedSize"><span class="hs-identifier hs-type">UncheckedSize</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-245"></span><span>               </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#UncheckedSize"><span class="hs-identifier hs-type">UncheckedSize</span></a></span><span>
</span><span id="line-246"></span><span>             </span><span class="hs-special">]</span><span>
</span><span id="line-247"></span><span>              </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679547658"><span class="hs-identifier hs-type">seqSize</span></a></span><span class="hs-special">,</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679547658"><span class="hs-identifier hs-type">seqSize</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-248"></span><span>          </span><span class="hs-special">)</span><span>
</span><span id="line-249"></span><span>          </span><span class="hs-special">(</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span>
</span><span id="line-250"></span><span>              </span><span class="hs-special">'</span><span class="hs-special">[</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-251"></span><span>                 </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679547658"><span class="hs-identifier hs-type">seqSize</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-252"></span><span>                 </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679547658"><span class="hs-identifier hs-type">seqSize</span></a></span><span>
</span><span id="line-253"></span><span>               </span><span class="hs-special">]</span><span>
</span><span id="line-254"></span><span>          </span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-255"></span><span>    </span><span class="annot"><a href="#local-6989586621679547657"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-256"></span><span>      </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-257"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#WithoutGradient"><span class="hs-identifier hs-type">WithoutGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-258"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Dense"><span class="hs-identifier hs-type">Dense</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-259"></span><span>          </span><span class="annot"><a href="#local-6989586621679547662"><span class="hs-identifier hs-type">device</span></a></span><span>
</span><span id="line-260"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#Int64"><span class="hs-identifier hs-type">Int64</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-261"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679547658"><span class="hs-identifier hs-type">seqSize</span></a></span><span class="hs-special">,</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679547658"><span class="hs-identifier hs-type">seqSize</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-262"></span><span>  </span><span class="hs-special">)</span><span>
</span><span id="line-263"></span><span>
</span><span id="line-264"></span><span class="hs-comment">-- | Computes relative positions of the input tokens to the encoder.</span><span>
</span><span id="line-265"></span><span class="hs-comment">-- Given an input tensor of shape @[batchDim, Dim seqName seqSize]@,</span><span>
</span><span id="line-266"></span><span class="hs-comment">-- returns a tensor of shape @[1, Dim &quot;*&quot; seqSize, Dim &quot;*&quot; seqSize]@.</span><span>
</span><span id="line-267"></span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#mkRelPos"><span class="hs-identifier hs-type">mkRelPos</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-268"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679548153"><span class="annot"><a href="#local-6989586621679548153"><span class="hs-identifier hs-type">m</span></a></span></span><span> </span><span id="local-6989586621679548145"><span class="annot"><a href="#local-6989586621679548145"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679548144"><span class="annot"><a href="#local-6989586621679548144"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679548152"><span class="annot"><a href="#local-6989586621679548152"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679548143"><span class="annot"><a href="#local-6989586621679548143"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679548151"><span class="annot"><a href="#local-6989586621679548151"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679548146"><span class="annot"><a href="#local-6989586621679548146"><span class="hs-identifier hs-type">relPosEncBucketDim</span></a></span></span><span> </span><span id="local-6989586621679548150"><span class="annot"><a href="#local-6989586621679548150"><span class="hs-identifier hs-type">seqDim</span></a></span></span><span> </span><span id="local-6989586621679548149"><span class="annot"><a href="#local-6989586621679548149"><span class="hs-identifier hs-type">seqName</span></a></span></span><span> </span><span id="local-6989586621679548148"><span class="annot"><a href="#local-6989586621679548148"><span class="hs-identifier hs-type">seqSize</span></a></span></span><span> </span><span id="local-6989586621679548147"><span class="annot"><a href="#local-6989586621679548147"><span class="hs-identifier hs-type">output</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-269"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier hs-type">MonadThrow</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679548153"><span class="hs-identifier hs-type">m</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-270"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkRelPosC"><span class="hs-identifier hs-type">MkRelPosC</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679548152"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679548151"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679548150"><span class="hs-identifier hs-type">seqDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679548149"><span class="hs-identifier hs-type">seqName</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679548148"><span class="hs-identifier hs-type">seqSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679548147"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-271"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-272"></span><span>  </span><span class="hs-comment">-- | bucket dimension</span><span>
</span><span id="line-273"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679548146"><span class="hs-identifier hs-type">relPosEncBucketDim</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-274"></span><span>  </span><span class="hs-comment">-- | maximum distance</span><span>
</span><span id="line-275"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-276"></span><span>  </span><span class="hs-comment">-- | input tensor</span><span>
</span><span id="line-277"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679548145"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679548144"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679548152"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679548143"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679548151"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-278"></span><span>  </span><span class="hs-comment">-- | relative positions of the input tokens</span><span>
</span><span id="line-279"></span><span>  </span><span class="annot"><a href="#local-6989586621679548153"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679548147"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-280"></span><span id="mkRelPos"><span class="annot"><span class="annottext">mkRelPos :: SDim relPosEncBucketDim
-&gt; Int -&gt; Tensor gradient layout device dataType shape -&gt; m output
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#mkRelPos"><span class="hs-identifier hs-var hs-var">mkRelPos</span></a></span></span><span> </span><span id="local-6989586621679547655"><span class="annot"><span class="annottext">SDim relPosEncBucketDim
</span><a href="#local-6989586621679547655"><span class="hs-identifier hs-var">relPosEncBucketDim</span></a></span></span><span> </span><span id="local-6989586621679547654"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679547654"><span class="hs-identifier hs-var">maxDistance</span></a></span></span><span> </span><span id="local-6989586621679547653"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679547653"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-281"></span><span>  </span><span id="local-6989586621679547652"><span class="annot"><span class="annottext">SDim ('Dim seqName seqSize)
</span><a href="#local-6989586621679547652"><span class="hs-identifier hs-var">seqDim</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">SSelectDim ('SelectDim ('ByIndex 1))
-&gt; SShape shape -&gt; m (SDim ('Dim seqName seqSize))
forall (selectDim :: SelectDim (By Symbol Nat))
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (dim :: Dim (Name Symbol) (Size Nat)) (m :: * -&gt; *).
(dim ~ GetDimF selectDim shape, MonadThrow m) =&gt;
SSelectDim selectDim -&gt; SShape shape -&gt; m (SDim dim)
</span><a href="Torch.GraduallyTyped.Shape.Class.html#sGetDimFromShape"><span class="hs-identifier hs-var">sGetDimFromShape</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SBy ('ByIndex 1) -&gt; SSelectDim ('SelectDim ('ByIndex 1))
forall (by :: By Symbol Nat). SBy by -&gt; SSelectDim ('SelectDim by)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSelectDim"><span class="hs-identifier hs-var">SSelectDim</span></a></span><span> </span><span class="annot"><span class="annottext">(SBy ('ByIndex 1) -&gt; SSelectDim ('SelectDim ('ByIndex 1)))
-&gt; SBy ('ByIndex 1) -&gt; SSelectDim ('SelectDim ('ByIndex 1))
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">KnownNat 1 =&gt; SBy ('ByIndex 1)
forall (index :: Nat). KnownNat index =&gt; SBy ('ByIndex index)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SByIndex"><span class="hs-identifier hs-var">SByIndex</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">(SShape shape -&gt; m (SDim ('Dim seqName seqSize)))
-&gt; SShape shape -&gt; m (SDim ('Dim seqName seqSize))
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape -&gt; SShape shape
forall (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType).
SGetShape shape =&gt;
Tensor gradient layout device dataType shape -&gt; SShape shape
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sGetShape"><span class="hs-identifier hs-var">sGetShape</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679547653"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-282"></span><span>  </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679547651"><span class="annot"><span class="annottext">seqSize :: Int
</span><a href="#local-6989586621679547651"><span class="hs-identifier hs-var hs-var">seqSize</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Integer -&gt; Int
forall a. Num a =&gt; Integer -&gt; a
</span><span class="hs-identifier hs-var">fromInteger</span></span><span> </span><span class="annot"><span class="annottext">(Integer -&gt; Int)
-&gt; (SSize seqSize -&gt; Integer) -&gt; SSize seqSize -&gt; Int
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">IsChecked Integer -&gt; Integer
forall a. IsChecked a -&gt; a
</span><a href="Torch.GraduallyTyped.Prelude.html#forgetIsChecked"><span class="hs-identifier hs-var">forgetIsChecked</span></a></span><span> </span><span class="annot"><span class="annottext">(IsChecked Integer -&gt; Integer)
-&gt; (SSize seqSize -&gt; IsChecked Integer) -&gt; SSize seqSize -&gt; Integer
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">SSize seqSize -&gt; IsChecked Integer
forall k (a :: k). SingKind k =&gt; Sing a -&gt; Demote k
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">fromSing</span></a></span><span> </span><span class="annot"><span class="annottext">(SSize seqSize -&gt; Int) -&gt; SSize seqSize -&gt; Int
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim seqName seqSize) -&gt; SSize seqSize
forall (name :: Name Symbol) (size :: Size Nat).
SDim ('Dim name size) -&gt; SSize size
</span><a href="Torch.GraduallyTyped.Shape.Type.html#sDimSize"><span class="hs-identifier hs-var hs-var">sDimSize</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim seqName seqSize)
</span><a href="#local-6989586621679547652"><span class="hs-identifier hs-var">seqDim</span></a></span><span>
</span><span id="line-283"></span><span>  </span><span class="annot"><span class="annottext">SGradient ('Gradient 'WithoutGradient)
-&gt; SLayout ('Layout 'Dense)
-&gt; SDevice device
-&gt; [[[Int]]]
-&gt; m (Tensor
        ('Gradient 'WithoutGradient)
        ('Layout 'Dense)
        device
        ('DataType 'Int64)
        ('Shape
           '[ 'Dim ('Name &quot;*&quot;) 'UncheckedSize,
              'Dim ('Name &quot;*&quot;) 'UncheckedSize, 'Dim ('Name &quot;*&quot;) 'UncheckedSize]))
forall a (dType :: DType) (dims :: [Dim (Name Symbol) (Size Nat)])
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (m :: * -&gt; *).
(TensorLike a dType dims, MonadThrow m) =&gt;
SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; a
-&gt; m (Tensor
        gradient layout device ('DataType dType) ('Shape dims))
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sToTensor"><span class="hs-identifier hs-var">sToTensor</span></a></span><span> </span><span class="annot"><span class="annottext">SGradient ('Gradient 'WithoutGradient)
</span><a href="#local-6989586621679547650"><span class="hs-identifier hs-var">gradient'</span></a></span><span> </span><span class="annot"><span class="annottext">SLayout ('Layout 'Dense)
</span><a href="#local-6989586621679547649"><span class="hs-identifier hs-var">layout'</span></a></span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679547648"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="hs-special">[</span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Int -&gt; Int -&gt; [[Int]]
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#mkRelPos%27"><span class="hs-identifier hs-var">mkRelPos'</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679547647"><span class="hs-identifier hs-var">relPosEncBucketSize</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679547654"><span class="hs-identifier hs-var">maxDistance</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679547651"><span class="hs-identifier hs-var">seqSize</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679547651"><span class="hs-identifier hs-var">seqSize</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-284"></span><span>    </span><span class="annot"><span class="annottext">m (Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     device
     ('DataType 'Int64)
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) 'UncheckedSize,
           'Dim ('Name &quot;*&quot;) 'UncheckedSize, 'Dim ('Name &quot;*&quot;) 'UncheckedSize]))
-&gt; (Tensor
      ('Gradient 'WithoutGradient)
      ('Layout 'Dense)
      device
      ('DataType 'Int64)
      ('Shape
         '[ 'Dim ('Name &quot;*&quot;) 'UncheckedSize,
            'Dim ('Name &quot;*&quot;) 'UncheckedSize, 'Dim ('Name &quot;*&quot;) 'UncheckedSize])
    -&gt; m output)
-&gt; m output
forall (m :: * -&gt; *) a b. Monad m =&gt; m a -&gt; (a -&gt; m b) -&gt; m b
</span><span class="hs-operator hs-var">&gt;&gt;=</span></span><span> </span><span class="annot"><span class="annottext">SShape
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) seqSize,
        'Dim ('Name &quot;*&quot;) seqSize])
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     device
     ('DataType 'Int64)
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) 'UncheckedSize,
           'Dim ('Name &quot;*&quot;) 'UncheckedSize, 'Dim ('Name &quot;*&quot;) 'UncheckedSize])
-&gt; m (Tensor
        ('Gradient 'WithoutGradient)
        ('Layout 'Dense)
        device
        ('DataType 'Int64)
        (Seq
           ('Shape
              '[ 'Dim ('Name &quot;*&quot;) 'UncheckedSize,
                 'Dim ('Name &quot;*&quot;) 'UncheckedSize, 'Dim ('Name &quot;*&quot;) 'UncheckedSize]
            &lt;+&gt; 'Shape
                  '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) seqSize,
                     'Dim ('Name &quot;*&quot;) seqSize])
           ('Shape
              '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) seqSize,
                 'Dim ('Name &quot;*&quot;) seqSize])))
forall (shape' :: Shape [Dim (Name Symbol) (Size Nat)])
       (m :: * -&gt; *) (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
(SGetShape shape, MonadThrow m) =&gt;
SShape shape'
-&gt; Tensor gradient layout device dataType shape
-&gt; m (Tensor
        gradient layout device dataType (Seq (shape &lt;+&gt; shape') shape'))
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sCheckedShape"><span class="hs-identifier hs-var">sCheckedShape</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SList
  '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) seqSize,
     'Dim ('Name &quot;*&quot;) seqSize]
-&gt; SShape
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) seqSize,
           'Dim ('Name &quot;*&quot;) seqSize])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList
   '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) seqSize,
      'Dim ('Name &quot;*&quot;) seqSize]
 -&gt; SShape
      ('Shape
         '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) seqSize,
            'Dim ('Name &quot;*&quot;) seqSize]))
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) seqSize,
        'Dim ('Name &quot;*&quot;) seqSize]
-&gt; SShape
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) seqSize,
           'Dim ('Name &quot;*&quot;) seqSize])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize ('Size 1) -&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 1))
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownNat 1 =&gt; SSize ('Size 1)
forall (size :: Nat). KnownNat size =&gt; SSize ('Size size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier hs-var">SSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">1</span></span><span> </span><span class="annot"><span class="annottext">Sing ('Dim ('Name &quot;*&quot;) ('Size 1))
-&gt; SList '[ 'Dim ('Name &quot;*&quot;) seqSize, 'Dim ('Name &quot;*&quot;) seqSize]
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) seqSize,
        'Dim ('Name &quot;*&quot;) seqSize]
forall a1 (a2 :: a1) (as :: [a1]).
Sing a2 -&gt; SList as -&gt; SList (a2 : as)
</span><a href="Torch.GraduallyTyped.Prelude.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize seqSize -&gt; SDim ('Dim ('Name &quot;*&quot;) seqSize)
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim seqName seqSize) -&gt; SSize seqSize
forall (name :: Name Symbol) (size :: Size Nat).
SDim ('Dim name size) -&gt; SSize size
</span><a href="Torch.GraduallyTyped.Shape.Type.html#sDimSize"><span class="hs-identifier hs-var hs-var">sDimSize</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim seqName seqSize)
</span><a href="#local-6989586621679547652"><span class="hs-identifier hs-var">seqDim</span></a></span><span> </span><span class="annot"><span class="annottext">Sing ('Dim ('Name &quot;*&quot;) seqSize)
-&gt; SList '[ 'Dim ('Name &quot;*&quot;) seqSize]
-&gt; SList '[ 'Dim ('Name &quot;*&quot;) seqSize, 'Dim ('Name &quot;*&quot;) seqSize]
forall a1 (a2 :: a1) (as :: [a1]).
Sing a2 -&gt; SList as -&gt; SList (a2 : as)
</span><a href="Torch.GraduallyTyped.Prelude.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize seqSize -&gt; SDim ('Dim ('Name &quot;*&quot;) seqSize)
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim seqName seqSize) -&gt; SSize seqSize
forall (name :: Name Symbol) (size :: Size Nat).
SDim ('Dim name size) -&gt; SSize size
</span><a href="Torch.GraduallyTyped.Shape.Type.html#sDimSize"><span class="hs-identifier hs-var hs-var">sDimSize</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim seqName seqSize)
</span><a href="#local-6989586621679547652"><span class="hs-identifier hs-var">seqDim</span></a></span><span> </span><span class="annot"><span class="annottext">Sing ('Dim ('Name &quot;*&quot;) seqSize)
-&gt; SList '[] -&gt; SList '[ 'Dim ('Name &quot;*&quot;) seqSize]
forall a1 (a2 :: a1) (as :: [a1]).
Sing a2 -&gt; SList as -&gt; SList (a2 : as)
</span><a href="Torch.GraduallyTyped.Prelude.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-285"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-286"></span><span>    </span><span id="local-6989586621679547650"><span class="annot"><span class="annottext">gradient' :: SGradient ('Gradient 'WithoutGradient)
</span><a href="#local-6989586621679547650"><span class="hs-identifier hs-var hs-var">gradient'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SRequiresGradient 'WithoutGradient
-&gt; SGradient ('Gradient 'WithoutGradient)
forall (requiresGradient :: RequiresGradient).
SRequiresGradient requiresGradient
-&gt; SGradient ('Gradient requiresGradient)
</span><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier hs-var">SGradient</span></a></span><span> </span><span class="annot"><span class="annottext">SRequiresGradient 'WithoutGradient
</span><a href="Torch.GraduallyTyped.RequiresGradient.html#SWithoutGradient"><span class="hs-identifier hs-var">SWithoutGradient</span></a></span><span>
</span><span id="line-287"></span><span>    </span><span id="local-6989586621679547649"><span class="annot"><span class="annottext">layout' :: SLayout ('Layout 'Dense)
</span><a href="#local-6989586621679547649"><span class="hs-identifier hs-var hs-var">layout'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SLayoutType 'Dense -&gt; SLayout ('Layout 'Dense)
forall (layoutType :: LayoutType).
SLayoutType layoutType -&gt; SLayout ('Layout layoutType)
</span><a href="Torch.GraduallyTyped.Layout.html#SLayout"><span class="hs-identifier hs-var">SLayout</span></a></span><span> </span><span class="annot"><span class="annottext">SLayoutType 'Dense
</span><a href="Torch.GraduallyTyped.Layout.html#SDense"><span class="hs-identifier hs-var">SDense</span></a></span><span>
</span><span id="line-288"></span><span>    </span><span id="local-6989586621679547648"><span class="annot"><span class="annottext">device :: SDevice device
</span><a href="#local-6989586621679547648"><span class="hs-identifier hs-var hs-var">device</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape -&gt; SDevice device
forall (device :: Device (DeviceType Nat))
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SGetDevice device =&gt;
Tensor gradient layout device dataType shape -&gt; SDevice device
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sGetDevice"><span class="hs-identifier hs-var">sGetDevice</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679547653"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-289"></span><span>    </span><span id="local-6989586621679547647"><span class="annot"><span class="annottext">relPosEncBucketSize :: Int
</span><a href="#local-6989586621679547647"><span class="hs-identifier hs-var hs-var">relPosEncBucketSize</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Integer -&gt; Int
forall a. Num a =&gt; Integer -&gt; a
</span><span class="hs-identifier hs-var">fromInteger</span></span><span> </span><span class="annot"><span class="annottext">(Integer -&gt; Int)
-&gt; (SDim relPosEncBucketDim -&gt; Integer)
-&gt; SDim relPosEncBucketDim
-&gt; Int
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">IsChecked Integer -&gt; Integer
forall a. IsChecked a -&gt; a
</span><a href="Torch.GraduallyTyped.Prelude.html#forgetIsChecked"><span class="hs-identifier hs-var">forgetIsChecked</span></a></span><span> </span><span class="annot"><span class="annottext">(IsChecked Integer -&gt; Integer)
-&gt; (SDim relPosEncBucketDim -&gt; IsChecked Integer)
-&gt; SDim relPosEncBucketDim
-&gt; Integer
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Dim (IsChecked String) (IsChecked Integer) -&gt; IsChecked Integer
forall name size. Dim name size -&gt; size
</span><a href="Torch.GraduallyTyped.Shape.Type.html#dimSize"><span class="hs-identifier hs-var hs-var">dimSize</span></a></span><span> </span><span class="annot"><span class="annottext">(Dim (IsChecked String) (IsChecked Integer) -&gt; IsChecked Integer)
-&gt; (SDim relPosEncBucketDim
    -&gt; Dim (IsChecked String) (IsChecked Integer))
-&gt; SDim relPosEncBucketDim
-&gt; IsChecked Integer
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">SDim relPosEncBucketDim
-&gt; Dim (IsChecked String) (IsChecked Integer)
forall k (a :: k). SingKind k =&gt; Sing a -&gt; Demote k
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">fromSing</span></a></span><span> </span><span class="annot"><span class="annottext">(SDim relPosEncBucketDim -&gt; Int) -&gt; SDim relPosEncBucketDim -&gt; Int
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SDim relPosEncBucketDim
</span><a href="#local-6989586621679547655"><span class="hs-identifier hs-var">relPosEncBucketDim</span></a></span><span>
</span><span id="line-290"></span><span>
</span><span id="line-291"></span><span class="hs-comment">-- | Computes relative positions of the input tokens to the decoder.</span><span>
</span><span id="line-292"></span><span class="hs-comment">--</span><span>
</span><span id="line-293"></span><span class="hs-comment">-- &gt;&gt;&gt; mkDecoderRelPos' 32 128 21 17</span><span>
</span><span id="line-294"></span><span class="hs-comment">-- [[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[2,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[3,2,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[4,3,2,1,0,0,0,0,0,0,0,0,0,0,0,0,0],[5,4,3,2,1,0,0,0,0,0,0,0,0,0,0,0,0],[6,5,4,3,2,1,0,0,0,0,0,0,0,0,0,0,0],[7,6,5,4,3,2,1,0,0,0,0,0,0,0,0,0,0],[8,7,6,5,4,3,2,1,0,0,0,0,0,0,0,0,0],[9,8,7,6,5,4,3,2,1,0,0,0,0,0,0,0,0],[10,9,8,7,6,5,4,3,2,1,0,0,0,0,0,0,0],[11,10,9,8,7,6,5,4,3,2,1,0,0,0,0,0,0],[12,11,10,9,8,7,6,5,4,3,2,1,0,0,0,0,0],[13,12,11,10,9,8,7,6,5,4,3,2,1,0,0,0,0],[14,13,12,11,10,9,8,7,6,5,4,3,2,1,0,0,0],[15,14,13,12,11,10,9,8,7,6,5,4,3,2,1,0,0],[16,15,14,13,12,11,10,9,8,7,6,5,4,3,2,1,0],[16,16,15,14,13,12,11,10,9,8,7,6,5,4,3,2,1],[16,16,16,15,14,13,12,11,10,9,8,7,6,5,4,3,2],[17,16,16,16,15,14,13,12,11,10,9,8,7,6,5,4,3],[17,17,16,16,16,15,14,13,12,11,10,9,8,7,6,5,4]]</span><span>
</span><span id="line-295"></span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#mkDecoderRelPos%27"><span class="hs-identifier hs-type">mkDecoderRelPos'</span></a></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span> </span><span class="hs-glyph">-&gt;</span><span> </span><span class="hs-special">[</span><span class="hs-special">[</span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">]</span><span class="hs-special">]</span><span>
</span><span id="line-296"></span><span id="mkDecoderRelPos%27"><span class="annot"><span class="annottext">mkDecoderRelPos' :: Int -&gt; Int -&gt; Int -&gt; Int -&gt; [[Int]]
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#mkDecoderRelPos%27"><span class="hs-identifier hs-var hs-var">mkDecoderRelPos'</span></a></span></span><span> </span><span id="local-6989586621679547643"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679547643"><span class="hs-identifier hs-var">numBuckets</span></a></span></span><span> </span><span id="local-6989586621679547642"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679547642"><span class="hs-identifier hs-var">maxDistance</span></a></span></span><span> </span><span id="local-6989586621679547641"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679547641"><span class="hs-identifier hs-var">querySize</span></a></span></span><span> </span><span id="local-6989586621679547640"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679547640"><span class="hs-identifier hs-var">keySize</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-297"></span><span>  </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679547639"><span class="annot"><span class="annottext">queryPos :: [Int]
</span><a href="#local-6989586621679547639"><span class="hs-identifier hs-var hs-var">queryPos</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">0</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">1</span></span><span> </span><span class="hs-glyph">..</span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679547641"><span class="hs-identifier hs-var">querySize</span></a></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Int
forall a. Num a =&gt; a -&gt; a -&gt; a
</span><span class="hs-glyph hs-var">-</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">1</span></span><span class="hs-special">]</span><span>
</span><span id="line-298"></span><span>      </span><span id="local-6989586621679547638"><span class="annot"><span class="annottext">keyPos :: [Int]
</span><a href="#local-6989586621679547638"><span class="hs-identifier hs-var hs-var">keyPos</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-special">[</span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">0</span></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">1</span></span><span> </span><span class="hs-glyph">..</span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679547640"><span class="hs-identifier hs-var">keySize</span></a></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Int
forall a. Num a =&gt; a -&gt; a -&gt; a
</span><span class="hs-glyph hs-var">-</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">1</span></span><span class="hs-special">]</span><span>
</span><span id="line-299"></span><span>      </span><span id="local-6989586621679547637"><span class="annot"><span class="annottext">maxExact :: Int
</span><a href="#local-6989586621679547637"><span class="hs-identifier hs-var hs-var">maxExact</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679547643"><span class="hs-identifier hs-var">numBuckets</span></a></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Int
forall a. Integral a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">`div`</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">2</span></span><span>
</span><span id="line-300"></span><span>   </span><span class="hs-keyword">in</span><span> </span><span class="annot"><span class="annottext">(Int -&gt; [Int]) -&gt; [Int] -&gt; [[Int]]
forall (f :: * -&gt; *) a b. Functor f =&gt; (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-identifier hs-var">fmap</span></span><span>
</span><span id="line-301"></span><span>        </span><span class="hs-special">(</span><span> </span><span class="hs-glyph">\</span><span id="local-6989586621679547636"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679547636"><span class="hs-identifier hs-var">qp</span></a></span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-302"></span><span>            </span><span class="annot"><span class="annottext">(Int -&gt; Int) -&gt; [Int] -&gt; [Int]
forall (f :: * -&gt; *) a b. Functor f =&gt; (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-identifier hs-var">fmap</span></span><span>
</span><span id="line-303"></span><span>              </span><span class="hs-special">(</span><span> </span><span class="hs-glyph">\</span><span id="local-6989586621679547635"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679547635"><span class="hs-identifier hs-var">kp</span></a></span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-304"></span><span>                  </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679547634"><span class="annot"><span class="annottext">rawRelPos :: Int
</span><a href="#local-6989586621679547634"><span class="hs-identifier hs-var hs-var">rawRelPos</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679547635"><span class="hs-identifier hs-var">kp</span></a></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Int
forall a. Num a =&gt; a -&gt; a -&gt; a
</span><span class="hs-glyph hs-var">-</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679547636"><span class="hs-identifier hs-var">qp</span></a></span><span>
</span><span id="line-305"></span><span>                      </span><span id="local-6989586621679547633"><span class="annot"><span class="annottext">absRelPos :: Int
</span><a href="#local-6989586621679547633"><span class="hs-identifier hs-var hs-var">absRelPos</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int
forall a. Num a =&gt; a -&gt; a
</span><span class="hs-identifier hs-var">negate</span></span><span> </span><span class="annot"><span class="annottext">(Int -&gt; Int) -&gt; (Int -&gt; Int) -&gt; Int -&gt; Int
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Int
forall a. Ord a =&gt; a -&gt; a -&gt; a
</span><span class="hs-identifier hs-var">min</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">0</span></span><span> </span><span class="annot"><span class="annottext">(Int -&gt; Int) -&gt; Int -&gt; Int
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679547634"><span class="hs-identifier hs-var">rawRelPos</span></a></span><span>
</span><span id="line-306"></span><span>                      </span><span id="local-6989586621679547632"><span class="annot"><span class="annottext">relBucket' :: Int
</span><a href="#local-6989586621679547632"><span class="hs-identifier hs-var hs-var">relBucket'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-307"></span><span>                        </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679547631"><span class="annot"><span class="annottext">isSmall :: Bool
</span><a href="#local-6989586621679547631"><span class="hs-identifier hs-var hs-var">isSmall</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679547633"><span class="hs-identifier hs-var">absRelPos</span></a></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Bool
forall a. Ord a =&gt; a -&gt; a -&gt; Bool
</span><span class="hs-operator hs-var">&lt;</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679547637"><span class="hs-identifier hs-var">maxExact</span></a></span><span>
</span><span id="line-308"></span><span>                            </span><span id="local-6989586621679547630"><span class="annot"><span class="annottext">relPosIfLarge :: Int
</span><a href="#local-6989586621679547630"><span class="hs-identifier hs-var hs-var">relPosIfLarge</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-309"></span><span>                              </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679547637"><span class="hs-identifier hs-var">maxExact</span></a></span><span>
</span><span id="line-310"></span><span>                                </span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Int
forall a. Num a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">+</span></span><span> </span><span class="annot"><span class="annottext">Double -&gt; Int
</span><span class="hs-identifier hs-var">double2Int</span></span><span>
</span><span id="line-311"></span><span>                                  </span><span class="hs-special">(</span><span> </span><span class="annot"><span class="annottext">Double -&gt; Double -&gt; Double
forall a. Floating a =&gt; a -&gt; a -&gt; a
</span><span class="hs-identifier hs-var">logBase</span></span><span>
</span><span id="line-312"></span><span>                                      </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Int -&gt; Double
forall a b. (Integral a, Num b) =&gt; a -&gt; b
</span><span class="hs-identifier hs-var">fromIntegral</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679547642"><span class="hs-identifier hs-var">maxDistance</span></a></span><span> </span><span class="annot"><span class="annottext">Double -&gt; Double -&gt; Double
forall a. Fractional a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">/</span></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Double
forall a b. (Integral a, Num b) =&gt; a -&gt; b
</span><span class="hs-identifier hs-var">fromIntegral</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679547637"><span class="hs-identifier hs-var">maxExact</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-313"></span><span>                                      </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Int -&gt; Double
forall a b. (Integral a, Num b) =&gt; a -&gt; b
</span><span class="hs-identifier hs-var">fromIntegral</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679547633"><span class="hs-identifier hs-var">absRelPos</span></a></span><span> </span><span class="annot"><span class="annottext">Double -&gt; Double -&gt; Double
forall a. Fractional a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">/</span></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Double
forall a b. (Integral a, Num b) =&gt; a -&gt; b
</span><span class="hs-identifier hs-var">fromIntegral</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679547637"><span class="hs-identifier hs-var">maxExact</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-314"></span><span>                                      </span><span class="annot"><span class="annottext">Double -&gt; Double -&gt; Double
forall a. Num a =&gt; a -&gt; a -&gt; a
</span><span class="hs-operator hs-var">*</span></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Double
forall a b. (Integral a, Num b) =&gt; a -&gt; b
</span><span class="hs-identifier hs-var">fromIntegral</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679547643"><span class="hs-identifier hs-var">numBuckets</span></a></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Int
forall a. Num a =&gt; a -&gt; a -&gt; a
</span><span class="hs-glyph hs-var">-</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679547637"><span class="hs-identifier hs-var">maxExact</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-315"></span><span>                                  </span><span class="hs-special">)</span><span>
</span><span id="line-316"></span><span>                            </span><span id="local-6989586621679547629"><span class="annot"><span class="annottext">relPosIfLarge' :: Int
</span><a href="#local-6989586621679547629"><span class="hs-identifier hs-var hs-var">relPosIfLarge'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Int
forall a. Ord a =&gt; a -&gt; a -&gt; a
</span><span class="hs-identifier hs-var">min</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679547630"><span class="hs-identifier hs-var">relPosIfLarge</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679547643"><span class="hs-identifier hs-var">numBuckets</span></a></span><span> </span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Int
forall a. Num a =&gt; a -&gt; a -&gt; a
</span><span class="hs-glyph hs-var">-</span></span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">1</span></span><span class="hs-special">)</span><span>
</span><span id="line-317"></span><span>                         </span><span class="hs-keyword">in</span><span> </span><span class="hs-keyword">if</span><span> </span><span class="annot"><span class="annottext">Bool
</span><a href="#local-6989586621679547631"><span class="hs-identifier hs-var">isSmall</span></a></span><span> </span><span class="hs-keyword">then</span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679547633"><span class="hs-identifier hs-var">absRelPos</span></a></span><span> </span><span class="hs-keyword">else</span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679547629"><span class="hs-identifier hs-var">relPosIfLarge'</span></a></span><span>
</span><span id="line-318"></span><span>                   </span><span class="hs-keyword">in</span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679547632"><span class="hs-identifier hs-var">relBucket'</span></a></span><span>
</span><span id="line-319"></span><span>              </span><span class="hs-special">)</span><span>
</span><span id="line-320"></span><span>              </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679547638"><span class="hs-identifier hs-var">keyPos</span></a></span><span>
</span><span id="line-321"></span><span>        </span><span class="hs-special">)</span><span>
</span><span id="line-322"></span><span>        </span><span class="annot"><span class="annottext">[Int]
</span><a href="#local-6989586621679547639"><span class="hs-identifier hs-var">queryPos</span></a></span><span>
</span><span id="line-323"></span><span>
</span><span id="line-324"></span><span class="hs-comment">-- | Computes relative positions of the input tokens to the decoder.</span><span>
</span><span id="line-325"></span><span class="hs-comment">-- Given an input tensor of shape @[batchDim, Dim seqName seqSize]@,</span><span>
</span><span id="line-326"></span><span class="hs-comment">-- returns a tensor of shape @[1, Dim &quot;*&quot; seqSize, Dim &quot;*&quot; seqSize]@.</span><span>
</span><span id="line-327"></span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#mkDecoderRelPos"><span class="hs-identifier hs-type">mkDecoderRelPos</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-328"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679547627"><span class="annot"><a href="#local-6989586621679547627"><span class="hs-identifier hs-type">m</span></a></span></span><span> </span><span id="local-6989586621679547626"><span class="annot"><a href="#local-6989586621679547626"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679547625"><span class="annot"><a href="#local-6989586621679547625"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679547624"><span class="annot"><a href="#local-6989586621679547624"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679547623"><span class="annot"><a href="#local-6989586621679547623"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679547622"><span class="annot"><a href="#local-6989586621679547622"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679547621"><span class="annot"><a href="#local-6989586621679547621"><span class="hs-identifier hs-type">relPosEncBucketDim</span></a></span></span><span> </span><span id="local-6989586621679547620"><span class="annot"><a href="#local-6989586621679547620"><span class="hs-identifier hs-type">seqDim</span></a></span></span><span> </span><span id="local-6989586621679547619"><span class="annot"><a href="#local-6989586621679547619"><span class="hs-identifier hs-type">seqName</span></a></span></span><span> </span><span id="local-6989586621679547618"><span class="annot"><a href="#local-6989586621679547618"><span class="hs-identifier hs-type">seqSize</span></a></span></span><span> </span><span id="local-6989586621679547617"><span class="annot"><a href="#local-6989586621679547617"><span class="hs-identifier hs-type">output</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-329"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier hs-type">MonadThrow</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547627"><span class="hs-identifier hs-type">m</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-330"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkRelPosC"><span class="hs-identifier hs-type">MkRelPosC</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547624"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547622"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547620"><span class="hs-identifier hs-type">seqDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547619"><span class="hs-identifier hs-type">seqName</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547618"><span class="hs-identifier hs-type">seqSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547617"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-331"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-332"></span><span>  </span><span class="hs-comment">-- | bucket dimension</span><span>
</span><span id="line-333"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547621"><span class="hs-identifier hs-type">relPosEncBucketDim</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-334"></span><span>  </span><span class="hs-comment">-- | maximum distance</span><span>
</span><span id="line-335"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-336"></span><span>  </span><span class="hs-comment">-- | decoder input tensor</span><span>
</span><span id="line-337"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547626"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547625"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547624"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547623"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547622"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-338"></span><span>  </span><span class="hs-comment">-- | relative positions of the input tokens</span><span>
</span><span id="line-339"></span><span>  </span><span class="annot"><a href="#local-6989586621679547627"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547617"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-340"></span><span id="mkDecoderRelPos"><span class="annot"><span class="annottext">mkDecoderRelPos :: SDim relPosEncBucketDim
-&gt; Int -&gt; Tensor gradient layout device dataType shape -&gt; m output
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#mkDecoderRelPos"><span class="hs-identifier hs-var hs-var">mkDecoderRelPos</span></a></span></span><span> </span><span id="local-6989586621679547616"><span class="annot"><span class="annottext">SDim relPosEncBucketDim
</span><a href="#local-6989586621679547616"><span class="hs-identifier hs-var">relPosEncBucketDim</span></a></span></span><span> </span><span id="local-6989586621679547615"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679547615"><span class="hs-identifier hs-var">maxDistance</span></a></span></span><span> </span><span id="local-6989586621679547614"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679547614"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-341"></span><span>  </span><span id="local-6989586621679547613"><span class="annot"><span class="annottext">SDim ('Dim seqName seqSize)
</span><a href="#local-6989586621679547613"><span class="hs-identifier hs-var">seqDim</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">SSelectDim ('SelectDim ('ByIndex 1))
-&gt; SShape shape -&gt; m (SDim ('Dim seqName seqSize))
forall (selectDim :: SelectDim (By Symbol Nat))
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (dim :: Dim (Name Symbol) (Size Nat)) (m :: * -&gt; *).
(dim ~ GetDimF selectDim shape, MonadThrow m) =&gt;
SSelectDim selectDim -&gt; SShape shape -&gt; m (SDim dim)
</span><a href="Torch.GraduallyTyped.Shape.Class.html#sGetDimFromShape"><span class="hs-identifier hs-var">sGetDimFromShape</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SBy ('ByIndex 1) -&gt; SSelectDim ('SelectDim ('ByIndex 1))
forall (by :: By Symbol Nat). SBy by -&gt; SSelectDim ('SelectDim by)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSelectDim"><span class="hs-identifier hs-var">SSelectDim</span></a></span><span> </span><span class="annot"><span class="annottext">(SBy ('ByIndex 1) -&gt; SSelectDim ('SelectDim ('ByIndex 1)))
-&gt; SBy ('ByIndex 1) -&gt; SSelectDim ('SelectDim ('ByIndex 1))
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">KnownNat 1 =&gt; SBy ('ByIndex 1)
forall (index :: Nat). KnownNat index =&gt; SBy ('ByIndex index)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SByIndex"><span class="hs-identifier hs-var">SByIndex</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">(SShape shape -&gt; m (SDim ('Dim seqName seqSize)))
-&gt; SShape shape -&gt; m (SDim ('Dim seqName seqSize))
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape -&gt; SShape shape
forall (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType).
SGetShape shape =&gt;
Tensor gradient layout device dataType shape -&gt; SShape shape
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sGetShape"><span class="hs-identifier hs-var">sGetShape</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679547614"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-342"></span><span>  </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679547612"><span class="annot"><span class="annottext">seqSize :: Int
</span><a href="#local-6989586621679547612"><span class="hs-identifier hs-var hs-var">seqSize</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Integer -&gt; Int
forall a. Num a =&gt; Integer -&gt; a
</span><span class="hs-identifier hs-var">fromInteger</span></span><span> </span><span class="annot"><span class="annottext">(Integer -&gt; Int)
-&gt; (SSize seqSize -&gt; Integer) -&gt; SSize seqSize -&gt; Int
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">IsChecked Integer -&gt; Integer
forall a. IsChecked a -&gt; a
</span><a href="Torch.GraduallyTyped.Prelude.html#forgetIsChecked"><span class="hs-identifier hs-var">forgetIsChecked</span></a></span><span> </span><span class="annot"><span class="annottext">(IsChecked Integer -&gt; Integer)
-&gt; (SSize seqSize -&gt; IsChecked Integer) -&gt; SSize seqSize -&gt; Integer
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">SSize seqSize -&gt; IsChecked Integer
forall k (a :: k). SingKind k =&gt; Sing a -&gt; Demote k
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">fromSing</span></a></span><span> </span><span class="annot"><span class="annottext">(SSize seqSize -&gt; Int) -&gt; SSize seqSize -&gt; Int
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim seqName seqSize) -&gt; SSize seqSize
forall (name :: Name Symbol) (size :: Size Nat).
SDim ('Dim name size) -&gt; SSize size
</span><a href="Torch.GraduallyTyped.Shape.Type.html#sDimSize"><span class="hs-identifier hs-var hs-var">sDimSize</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim seqName seqSize)
</span><a href="#local-6989586621679547613"><span class="hs-identifier hs-var">seqDim</span></a></span><span>
</span><span id="line-343"></span><span>  </span><span class="annot"><span class="annottext">SGradient ('Gradient 'WithoutGradient)
-&gt; SLayout ('Layout 'Dense)
-&gt; SDevice device
-&gt; [[[Int]]]
-&gt; m (Tensor
        ('Gradient 'WithoutGradient)
        ('Layout 'Dense)
        device
        ('DataType 'Int64)
        ('Shape
           '[ 'Dim ('Name &quot;*&quot;) 'UncheckedSize,
              'Dim ('Name &quot;*&quot;) 'UncheckedSize, 'Dim ('Name &quot;*&quot;) 'UncheckedSize]))
forall a (dType :: DType) (dims :: [Dim (Name Symbol) (Size Nat)])
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (m :: * -&gt; *).
(TensorLike a dType dims, MonadThrow m) =&gt;
SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; a
-&gt; m (Tensor
        gradient layout device ('DataType dType) ('Shape dims))
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sToTensor"><span class="hs-identifier hs-var">sToTensor</span></a></span><span> </span><span class="annot"><span class="annottext">SGradient ('Gradient 'WithoutGradient)
</span><a href="#local-6989586621679547611"><span class="hs-identifier hs-var">gradient'</span></a></span><span> </span><span class="annot"><span class="annottext">SLayout ('Layout 'Dense)
</span><a href="#local-6989586621679547610"><span class="hs-identifier hs-var">layout'</span></a></span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679547609"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="hs-special">[</span><span class="annot"><span class="annottext">Int -&gt; Int -&gt; Int -&gt; Int -&gt; [[Int]]
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#mkDecoderRelPos%27"><span class="hs-identifier hs-var">mkDecoderRelPos'</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679547608"><span class="hs-identifier hs-var">relPosEncBucketSize</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679547615"><span class="hs-identifier hs-var">maxDistance</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679547612"><span class="hs-identifier hs-var">seqSize</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679547612"><span class="hs-identifier hs-var">seqSize</span></a></span><span class="hs-special">]</span><span>
</span><span id="line-344"></span><span>    </span><span class="annot"><span class="annottext">m (Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     device
     ('DataType 'Int64)
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) 'UncheckedSize,
           'Dim ('Name &quot;*&quot;) 'UncheckedSize, 'Dim ('Name &quot;*&quot;) 'UncheckedSize]))
-&gt; (Tensor
      ('Gradient 'WithoutGradient)
      ('Layout 'Dense)
      device
      ('DataType 'Int64)
      ('Shape
         '[ 'Dim ('Name &quot;*&quot;) 'UncheckedSize,
            'Dim ('Name &quot;*&quot;) 'UncheckedSize, 'Dim ('Name &quot;*&quot;) 'UncheckedSize])
    -&gt; m output)
-&gt; m output
forall (m :: * -&gt; *) a b. Monad m =&gt; m a -&gt; (a -&gt; m b) -&gt; m b
</span><span class="hs-operator hs-var">&gt;&gt;=</span></span><span> </span><span class="annot"><span class="annottext">SShape
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) seqSize,
        'Dim ('Name &quot;*&quot;) seqSize])
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     device
     ('DataType 'Int64)
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) 'UncheckedSize,
           'Dim ('Name &quot;*&quot;) 'UncheckedSize, 'Dim ('Name &quot;*&quot;) 'UncheckedSize])
-&gt; m (Tensor
        ('Gradient 'WithoutGradient)
        ('Layout 'Dense)
        device
        ('DataType 'Int64)
        (Seq
           ('Shape
              '[ 'Dim ('Name &quot;*&quot;) 'UncheckedSize,
                 'Dim ('Name &quot;*&quot;) 'UncheckedSize, 'Dim ('Name &quot;*&quot;) 'UncheckedSize]
            &lt;+&gt; 'Shape
                  '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) seqSize,
                     'Dim ('Name &quot;*&quot;) seqSize])
           ('Shape
              '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) seqSize,
                 'Dim ('Name &quot;*&quot;) seqSize])))
forall (shape' :: Shape [Dim (Name Symbol) (Size Nat)])
       (m :: * -&gt; *) (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
(SGetShape shape, MonadThrow m) =&gt;
SShape shape'
-&gt; Tensor gradient layout device dataType shape
-&gt; m (Tensor
        gradient layout device dataType (Seq (shape &lt;+&gt; shape') shape'))
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sCheckedShape"><span class="hs-identifier hs-var">sCheckedShape</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SList
  '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) seqSize,
     'Dim ('Name &quot;*&quot;) seqSize]
-&gt; SShape
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) seqSize,
           'Dim ('Name &quot;*&quot;) seqSize])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList
   '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) seqSize,
      'Dim ('Name &quot;*&quot;) seqSize]
 -&gt; SShape
      ('Shape
         '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) seqSize,
            'Dim ('Name &quot;*&quot;) seqSize]))
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) seqSize,
        'Dim ('Name &quot;*&quot;) seqSize]
-&gt; SShape
     ('Shape
        '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) seqSize,
           'Dim ('Name &quot;*&quot;) seqSize])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize ('Size 1) -&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 1))
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownNat 1 =&gt; SSize ('Size 1)
forall (size :: Nat). KnownNat size =&gt; SSize ('Size size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier hs-var">SSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">1</span></span><span> </span><span class="annot"><span class="annottext">Sing ('Dim ('Name &quot;*&quot;) ('Size 1))
-&gt; SList '[ 'Dim ('Name &quot;*&quot;) seqSize, 'Dim ('Name &quot;*&quot;) seqSize]
-&gt; SList
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) seqSize,
        'Dim ('Name &quot;*&quot;) seqSize]
forall a1 (a2 :: a1) (as :: [a1]).
Sing a2 -&gt; SList as -&gt; SList (a2 : as)
</span><a href="Torch.GraduallyTyped.Prelude.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize seqSize -&gt; SDim ('Dim ('Name &quot;*&quot;) seqSize)
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim seqName seqSize) -&gt; SSize seqSize
forall (name :: Name Symbol) (size :: Size Nat).
SDim ('Dim name size) -&gt; SSize size
</span><a href="Torch.GraduallyTyped.Shape.Type.html#sDimSize"><span class="hs-identifier hs-var hs-var">sDimSize</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim seqName seqSize)
</span><a href="#local-6989586621679547613"><span class="hs-identifier hs-var">seqDim</span></a></span><span> </span><span class="annot"><span class="annottext">Sing ('Dim ('Name &quot;*&quot;) seqSize)
-&gt; SList '[ 'Dim ('Name &quot;*&quot;) seqSize]
-&gt; SList '[ 'Dim ('Name &quot;*&quot;) seqSize, 'Dim ('Name &quot;*&quot;) seqSize]
forall a1 (a2 :: a1) (as :: [a1]).
Sing a2 -&gt; SList as -&gt; SList (a2 : as)
</span><a href="Torch.GraduallyTyped.Prelude.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize seqSize -&gt; SDim ('Dim ('Name &quot;*&quot;) seqSize)
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim seqName seqSize) -&gt; SSize seqSize
forall (name :: Name Symbol) (size :: Size Nat).
SDim ('Dim name size) -&gt; SSize size
</span><a href="Torch.GraduallyTyped.Shape.Type.html#sDimSize"><span class="hs-identifier hs-var hs-var">sDimSize</span></a></span><span> </span><span class="annot"><span class="annottext">SDim ('Dim seqName seqSize)
</span><a href="#local-6989586621679547613"><span class="hs-identifier hs-var">seqDim</span></a></span><span> </span><span class="annot"><span class="annottext">Sing ('Dim ('Name &quot;*&quot;) seqSize)
-&gt; SList '[] -&gt; SList '[ 'Dim ('Name &quot;*&quot;) seqSize]
forall a1 (a2 :: a1) (as :: [a1]).
Sing a2 -&gt; SList as -&gt; SList (a2 : as)
</span><a href="Torch.GraduallyTyped.Prelude.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-345"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-346"></span><span>    </span><span id="local-6989586621679547611"><span class="annot"><span class="annottext">gradient' :: SGradient ('Gradient 'WithoutGradient)
</span><a href="#local-6989586621679547611"><span class="hs-identifier hs-var hs-var">gradient'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SRequiresGradient 'WithoutGradient
-&gt; SGradient ('Gradient 'WithoutGradient)
forall (requiresGradient :: RequiresGradient).
SRequiresGradient requiresGradient
-&gt; SGradient ('Gradient requiresGradient)
</span><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier hs-var">SGradient</span></a></span><span> </span><span class="annot"><span class="annottext">SRequiresGradient 'WithoutGradient
</span><a href="Torch.GraduallyTyped.RequiresGradient.html#SWithoutGradient"><span class="hs-identifier hs-var">SWithoutGradient</span></a></span><span>
</span><span id="line-347"></span><span>    </span><span id="local-6989586621679547610"><span class="annot"><span class="annottext">layout' :: SLayout ('Layout 'Dense)
</span><a href="#local-6989586621679547610"><span class="hs-identifier hs-var hs-var">layout'</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">SLayoutType 'Dense -&gt; SLayout ('Layout 'Dense)
forall (layoutType :: LayoutType).
SLayoutType layoutType -&gt; SLayout ('Layout layoutType)
</span><a href="Torch.GraduallyTyped.Layout.html#SLayout"><span class="hs-identifier hs-var">SLayout</span></a></span><span> </span><span class="annot"><span class="annottext">SLayoutType 'Dense
</span><a href="Torch.GraduallyTyped.Layout.html#SDense"><span class="hs-identifier hs-var">SDense</span></a></span><span>
</span><span id="line-348"></span><span>    </span><span id="local-6989586621679547609"><span class="annot"><span class="annottext">device :: SDevice device
</span><a href="#local-6989586621679547609"><span class="hs-identifier hs-var hs-var">device</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape -&gt; SDevice device
forall (device :: Device (DeviceType Nat))
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SGetDevice device =&gt;
Tensor gradient layout device dataType shape -&gt; SDevice device
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sGetDevice"><span class="hs-identifier hs-var">sGetDevice</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679547614"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-349"></span><span>    </span><span id="local-6989586621679547608"><span class="annot"><span class="annottext">relPosEncBucketSize :: Int
</span><a href="#local-6989586621679547608"><span class="hs-identifier hs-var hs-var">relPosEncBucketSize</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Integer -&gt; Int
forall a. Num a =&gt; Integer -&gt; a
</span><span class="hs-identifier hs-var">fromInteger</span></span><span> </span><span class="annot"><span class="annottext">(Integer -&gt; Int)
-&gt; (SDim relPosEncBucketDim -&gt; Integer)
-&gt; SDim relPosEncBucketDim
-&gt; Int
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">IsChecked Integer -&gt; Integer
forall a. IsChecked a -&gt; a
</span><a href="Torch.GraduallyTyped.Prelude.html#forgetIsChecked"><span class="hs-identifier hs-var">forgetIsChecked</span></a></span><span> </span><span class="annot"><span class="annottext">(IsChecked Integer -&gt; Integer)
-&gt; (SDim relPosEncBucketDim -&gt; IsChecked Integer)
-&gt; SDim relPosEncBucketDim
-&gt; Integer
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Dim (IsChecked String) (IsChecked Integer) -&gt; IsChecked Integer
forall name size. Dim name size -&gt; size
</span><a href="Torch.GraduallyTyped.Shape.Type.html#dimSize"><span class="hs-identifier hs-var hs-var">dimSize</span></a></span><span> </span><span class="annot"><span class="annottext">(Dim (IsChecked String) (IsChecked Integer) -&gt; IsChecked Integer)
-&gt; (SDim relPosEncBucketDim
    -&gt; Dim (IsChecked String) (IsChecked Integer))
-&gt; SDim relPosEncBucketDim
-&gt; IsChecked Integer
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">SDim relPosEncBucketDim
-&gt; Dim (IsChecked String) (IsChecked Integer)
forall k (a :: k). SingKind k =&gt; Sing a -&gt; Demote k
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">fromSing</span></a></span><span> </span><span class="annot"><span class="annottext">(SDim relPosEncBucketDim -&gt; Int) -&gt; SDim relPosEncBucketDim -&gt; Int
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SDim relPosEncBucketDim
</span><a href="#local-6989586621679547616"><span class="hs-identifier hs-var">relPosEncBucketDim</span></a></span><span>
</span><span id="line-350"></span><span>
</span><span id="line-351"></span><span class="hs-keyword">data</span><span> </span><span id="MkRelPos"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkRelPos"><span class="hs-identifier hs-var">MkRelPos</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679547607"><span class="annot"><a href="#local-6989586621679547607"><span class="hs-identifier hs-type">relPosEncBucketDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Symbol</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-identifier hs-type">Nat</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-352"></span><span>  </span><span id="MkRelPos"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkRelPos"><span class="hs-identifier hs-var">MkRelPos</span></a></span></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-353"></span><span>    </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679548154"><span class="annot"><a href="#local-6989586621679548154"><span class="hs-identifier hs-type">relPosEncBucketDim</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-354"></span><span>    </span><span class="hs-special">{</span><span> </span><span id="relPosEncBucketDim"><span class="annot"><span class="annottext">MkRelPos relPosEncBucketDim -&gt; SDim relPosEncBucketDim
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#relPosEncBucketDim"><span class="hs-identifier hs-var hs-var">relPosEncBucketDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679548154"><span class="hs-identifier hs-type">relPosEncBucketDim</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-355"></span><span>      </span><span id="relPosMaxDistance"><span class="annot"><span class="annottext">MkRelPos relPosEncBucketDim -&gt; Int
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#relPosMaxDistance"><span class="hs-identifier hs-var hs-var">relPosMaxDistance</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span>
</span><span id="line-356"></span><span>    </span><span class="hs-special">}</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-357"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkRelPos"><span class="hs-identifier hs-type">MkRelPos</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679548154"><span class="hs-identifier hs-type">relPosEncBucketDim</span></a></span><span>
</span><span id="line-358"></span><span>  </span><span id="MkDecoderRelPos"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkDecoderRelPos"><span class="hs-identifier hs-var">MkDecoderRelPos</span></a></span></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-359"></span><span>    </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679547602"><span class="annot"><a href="#local-6989586621679547602"><span class="hs-identifier hs-type">relPosEncBucketDim</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-360"></span><span>    </span><span class="hs-special">{</span><span> </span><span id="decoderRelPosEncBucketDim"><span class="annot"><span class="annottext">MkRelPos relPosEncBucketDim -&gt; SDim relPosEncBucketDim
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#decoderRelPosEncBucketDim"><span class="hs-identifier hs-var hs-var">decoderRelPosEncBucketDim</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SDim"><span class="hs-identifier hs-type">SDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547602"><span class="hs-identifier hs-type">relPosEncBucketDim</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-361"></span><span>      </span><span id="decoderRelPosMaxDistance"><span class="annot"><span class="annottext">MkRelPos relPosEncBucketDim -&gt; Int
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#decoderRelPosMaxDistance"><span class="hs-identifier hs-var hs-var">decoderRelPosMaxDistance</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span>
</span><span id="line-362"></span><span>    </span><span class="hs-special">}</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-363"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkRelPos"><span class="hs-identifier hs-type">MkRelPos</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547602"><span class="hs-identifier hs-type">relPosEncBucketDim</span></a></span><span>
</span><span id="line-364"></span><span>
</span><span id="line-365"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">instance</span><span> </span><span id="ModelSpec"><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier hs-var">ModelSpec</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkRelPos"><span class="hs-identifier hs-type">MkRelPos</span></a></span><span> </span><span id="local-6989586621679547599"><span class="annot"><a href="#local-6989586621679547599"><span class="hs-identifier hs-type hs-type">relPosEncBucketDim</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkRelPos"><span class="hs-identifier hs-type">MkRelPos</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547599"><span class="hs-identifier hs-type">relPosEncBucketDim</span></a></span><span>
</span><span id="line-366"></span><span>
</span><span id="line-367"></span><span id="local-6989586621679547597"><span id="local-6989586621679547598"><span class="hs-keyword">instance</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkRelPos"><span class="hs-identifier hs-type">MkRelPos</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547598"><span class="hs-identifier hs-type">relPosEncBucketDim</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679547597"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkRelPos"><span class="hs-identifier hs-type">MkRelPos</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547598"><span class="hs-identifier hs-type">relPosEncBucketDim</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679547597"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-368"></span><span>  </span><span id="local-6989586621679547595"><span class="annot"><span class="annottext">initialize :: ModelSpec (MkRelPos relPosEncBucketDim)
-&gt; Generator generatorDevice
-&gt; m (MkRelPos relPosEncBucketDim, Generator generatorDevice)
</span><a href="#local-6989586621679547595"><span class="hs-identifier hs-var hs-var hs-var hs-var">initialize</span></a></span></span><span> </span><span id="local-6989586621679547594"><span class="annot"><span class="annottext">ModelSpec (MkRelPos relPosEncBucketDim)
</span><a href="#local-6989586621679547594"><span class="hs-identifier hs-var">spec</span></a></span></span><span> </span><span id="local-6989586621679547593"><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679547593"><span class="hs-identifier hs-var">g</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(MkRelPos relPosEncBucketDim, Generator generatorDevice)
-&gt; m (MkRelPos relPosEncBucketDim, Generator generatorDevice)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">ModelSpec (MkRelPos relPosEncBucketDim)
MkRelPos relPosEncBucketDim
</span><a href="#local-6989586621679547594"><span class="hs-identifier hs-var">spec</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679547593"><span class="hs-identifier hs-var">g</span></a></span><span class="hs-special">)</span></span></span><span>
</span><span id="line-369"></span><span>
</span><span id="line-370"></span><span id="local-6989586621679547592"><span class="hs-keyword">instance</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasStateDict"><span class="hs-identifier hs-type">HasStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkRelPos"><span class="hs-identifier hs-type">MkRelPos</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547592"><span class="hs-identifier hs-type">relPosEncBucketDim</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-371"></span><span>  </span><span id="local-6989586621679547589"><span class="annot"><span class="annottext">fromStateDict :: ModelSpec (MkRelPos relPosEncBucketDim)
-&gt; StateDictKey -&gt; m (MkRelPos relPosEncBucketDim)
</span><a href="#local-6989586621679547589"><span class="hs-identifier hs-var hs-var hs-var hs-var">fromStateDict</span></a></span></span><span> </span><span id="local-6989586621679547588"><span class="annot"><span class="annottext">ModelSpec (MkRelPos relPosEncBucketDim)
</span><a href="#local-6989586621679547588"><span class="hs-identifier hs-var">spec</span></a></span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">MkRelPos relPosEncBucketDim -&gt; m (MkRelPos relPosEncBucketDim)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">ModelSpec (MkRelPos relPosEncBucketDim)
MkRelPos relPosEncBucketDim
</span><a href="#local-6989586621679547588"><span class="hs-identifier hs-var">spec</span></a></span><span>
</span><span id="line-372"></span><span>  </span><span id="local-6989586621679547587"><span class="annot"><span class="annottext">toStateDict :: StateDictKey -&gt; MkRelPos relPosEncBucketDim -&gt; m ()
</span><a href="#local-6989586621679547587"><span class="hs-identifier hs-var hs-var hs-var hs-var">toStateDict</span></a></span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="annottext">MkRelPos relPosEncBucketDim
</span><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">() -&gt; m ()
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span></span><span>
</span><span id="line-373"></span><span>
</span><span id="line-374"></span><span id="local-6989586621679547576"><span id="local-6989586621679547577"><span id="local-6989586621679547578"><span id="local-6989586621679547579"><span id="local-6989586621679547580"><span id="local-6989586621679547581"><span id="local-6989586621679547582"><span id="local-6989586621679547583"><span id="local-6989586621679547584"><span id="local-6989586621679547585"><span id="local-6989586621679547586"><span class="hs-keyword">instance</span><span>
</span><span id="line-375"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkRelPosC"><span class="hs-identifier hs-type">MkRelPosC</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547586"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547585"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547584"><span class="hs-identifier hs-type">seqDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547583"><span class="hs-identifier hs-type">seqName</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547582"><span class="hs-identifier hs-type">seqSize</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547581"><span class="hs-identifier hs-type">output</span></a></span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-376"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-377"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkRelPos"><span class="hs-identifier hs-type">MkRelPos</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547580"><span class="hs-identifier hs-type">relPosEncBucketDim</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-378"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547579"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547578"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547586"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547577"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547585"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-379"></span><span>    </span><span class="annot"><a href="#local-6989586621679547576"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-380"></span><span>    </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-381"></span><span>        </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#WithoutGradient"><span class="hs-identifier hs-type">WithoutGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-382"></span><span>        </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Dense"><span class="hs-identifier hs-type">Dense</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-383"></span><span>        </span><span class="annot"><a href="#local-6989586621679547586"><span class="hs-identifier hs-type">device</span></a></span><span>
</span><span id="line-384"></span><span>        </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#Int64"><span class="hs-identifier hs-type">Int64</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-385"></span><span>        </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679547582"><span class="hs-identifier hs-type">seqSize</span></a></span><span class="hs-special">,</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679547582"><span class="hs-identifier hs-type">seqSize</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-386"></span><span>    </span><span class="hs-special">)</span><span>
</span><span id="line-387"></span><span>    </span><span class="annot"><a href="#local-6989586621679547576"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-388"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-389"></span><span>  </span><span id="local-6989586621679547574"><span class="annot"><span class="annottext">forward :: MkRelPos relPosEncBucketDim
-&gt; Tensor gradient layout device dataType shape
-&gt; Generator generatorDevice
-&gt; m (Tensor
        ('Gradient 'WithoutGradient)
        ('Layout 'Dense)
        device
        ('DataType 'Int64)
        ('Shape
           '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) seqSize,
              'Dim ('Name &quot;*&quot;) seqSize]),
      Generator generatorDevice)
</span><a href="#local-6989586621679547574"><span class="hs-identifier hs-var hs-var hs-var hs-var">forward</span></a></span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkRelPos"><span class="hs-identifier hs-type">MkRelPos</span></a></span><span> </span><span class="hs-special">{</span><span id="local-6989586621679547572"><span id="local-6989586621679547573"><span class="annot"><span class="annottext">Int
SDim relPosEncBucketDim
relPosMaxDistance :: Int
relPosEncBucketDim :: SDim relPosEncBucketDim
relPosMaxDistance :: forall (relPosEncBucketDim :: Dim (Name Symbol) (Size Nat)).
MkRelPos relPosEncBucketDim -&gt; Int
relPosEncBucketDim :: forall (relPosEncBucketDim :: Dim (Name Symbol) (Size Nat)).
MkRelPos relPosEncBucketDim -&gt; SDim relPosEncBucketDim
</span><a href="#local-6989586621679547572"><span class="hs-glyph hs-var hs-var hs-var hs-var">..</span></a></span></span></span><span class="hs-special">}</span><span> </span><span id="local-6989586621679547571"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679547571"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span id="local-6989586621679547570"><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679547570"><span class="hs-identifier hs-var">g</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-390"></span><span>    </span><span id="local-6989586621679547569"><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  device
  ('DataType 'Int64)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) seqSize,
        'Dim ('Name &quot;*&quot;) seqSize])
</span><a href="#local-6989586621679547569"><span class="hs-identifier hs-var">relPos</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">SDim relPosEncBucketDim
-&gt; Int
-&gt; Tensor gradient layout device dataType shape
-&gt; m (Tensor
        ('Gradient 'WithoutGradient)
        ('Layout 'Dense)
        device
        ('DataType 'Int64)
        ('Shape
           '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) seqSize,
              'Dim ('Name &quot;*&quot;) seqSize]))
forall (m :: * -&gt; *) (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (relPosEncBucketDim :: Dim (Name Symbol) (Size Nat))
       (seqDim :: Dim (Name Symbol) (Size Nat)) (seqName :: Name Symbol)
       (seqSize :: Size Nat) output.
(MonadThrow m,
 MkRelPosC device shape seqDim seqName seqSize output) =&gt;
SDim relPosEncBucketDim
-&gt; Int -&gt; Tensor gradient layout device dataType shape -&gt; m output
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#mkRelPos"><span class="hs-identifier hs-var">mkRelPos</span></a></span><span> </span><span class="annot"><span class="annottext">SDim relPosEncBucketDim
</span><a href="#local-6989586621679547573"><span class="hs-identifier hs-var">relPosEncBucketDim</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679547572"><span class="hs-identifier hs-var">relPosMaxDistance</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679547571"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-391"></span><span>    </span><span class="annot"><span class="annottext">(Tensor
   ('Gradient 'WithoutGradient)
   ('Layout 'Dense)
   device
   ('DataType 'Int64)
   ('Shape
      '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) seqSize,
         'Dim ('Name &quot;*&quot;) seqSize]),
 Generator generatorDevice)
-&gt; m (Tensor
        ('Gradient 'WithoutGradient)
        ('Layout 'Dense)
        device
        ('DataType 'Int64)
        ('Shape
           '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) seqSize,
              'Dim ('Name &quot;*&quot;) seqSize]),
      Generator generatorDevice)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  device
  ('DataType 'Int64)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) seqSize,
        'Dim ('Name &quot;*&quot;) seqSize])
</span><a href="#local-6989586621679547569"><span class="hs-identifier hs-var">relPos</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679547570"><span class="hs-identifier hs-var">g</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-392"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#forward"><span class="hs-identifier hs-var">forward</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkDecoderRelPos"><span class="hs-identifier hs-type">MkDecoderRelPos</span></a></span><span> </span><span class="hs-special">{</span><span id="local-6989586621679547567"><span id="local-6989586621679547568"><span class="annot"><span class="annottext">Int
SDim relPosEncBucketDim
decoderRelPosMaxDistance :: Int
decoderRelPosEncBucketDim :: SDim relPosEncBucketDim
decoderRelPosMaxDistance :: forall (relPosEncBucketDim :: Dim (Name Symbol) (Size Nat)).
MkRelPos relPosEncBucketDim -&gt; Int
decoderRelPosEncBucketDim :: forall (relPosEncBucketDim :: Dim (Name Symbol) (Size Nat)).
MkRelPos relPosEncBucketDim -&gt; SDim relPosEncBucketDim
</span><a href="#local-6989586621679547567"><span class="hs-glyph hs-var hs-var hs-var hs-var">..</span></a></span></span></span><span class="hs-special">}</span><span> </span><span id="local-6989586621679547566"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679547566"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span id="local-6989586621679547565"><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679547565"><span class="hs-identifier hs-var">g</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-393"></span><span>    </span><span id="local-6989586621679547564"><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  device
  ('DataType 'Int64)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) seqSize,
        'Dim ('Name &quot;*&quot;) seqSize])
</span><a href="#local-6989586621679547564"><span class="hs-identifier hs-var">decoderRelPos</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">SDim relPosEncBucketDim
-&gt; Int
-&gt; Tensor gradient layout device dataType shape
-&gt; m (Tensor
        ('Gradient 'WithoutGradient)
        ('Layout 'Dense)
        device
        ('DataType 'Int64)
        ('Shape
           '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) seqSize,
              'Dim ('Name &quot;*&quot;) seqSize]))
forall (m :: * -&gt; *) (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (relPosEncBucketDim :: Dim (Name Symbol) (Size Nat))
       (seqDim :: Dim (Name Symbol) (Size Nat)) (seqName :: Name Symbol)
       (seqSize :: Size Nat) output.
(MonadThrow m,
 MkRelPosC device shape seqDim seqName seqSize output) =&gt;
SDim relPosEncBucketDim
-&gt; Int -&gt; Tensor gradient layout device dataType shape -&gt; m output
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#mkDecoderRelPos"><span class="hs-identifier hs-var">mkDecoderRelPos</span></a></span><span> </span><span class="annot"><span class="annottext">SDim relPosEncBucketDim
</span><a href="#local-6989586621679547568"><span class="hs-identifier hs-var">decoderRelPosEncBucketDim</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679547567"><span class="hs-identifier hs-var">decoderRelPosMaxDistance</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679547566"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-394"></span><span>    </span><span class="annot"><span class="annottext">(Tensor
   ('Gradient 'WithoutGradient)
   ('Layout 'Dense)
   device
   ('DataType 'Int64)
   ('Shape
      '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) seqSize,
         'Dim ('Name &quot;*&quot;) seqSize]),
 Generator generatorDevice)
-&gt; m (Tensor
        ('Gradient 'WithoutGradient)
        ('Layout 'Dense)
        device
        ('DataType 'Int64)
        ('Shape
           '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) seqSize,
              'Dim ('Name &quot;*&quot;) seqSize]),
      Generator generatorDevice)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  device
  ('DataType 'Int64)
  ('Shape
     '[ 'Dim ('Name &quot;*&quot;) ('Size 1), 'Dim ('Name &quot;*&quot;) seqSize,
        'Dim ('Name &quot;*&quot;) seqSize])
</span><a href="#local-6989586621679547564"><span class="hs-identifier hs-var">decoderRelPos</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679547565"><span class="hs-identifier hs-var">g</span></a></span><span class="hs-special">)</span></span></span></span></span></span></span></span></span></span></span></span><span>
</span><span id="line-395"></span><span>
</span><span id="line-396"></span><span class="hs-keyword">type</span><span> </span><span id="MkTransformerPaddingMaskC"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerPaddingMaskC"><span class="hs-identifier hs-var">MkTransformerPaddingMaskC</span></a></span></span><span> </span><span id="local-6989586621679547563"><span class="annot"><a href="#local-6989586621679547563"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679547562"><span class="annot"><a href="#local-6989586621679547562"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679547561"><span class="annot"><a href="#local-6989586621679547561"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679547560"><span class="annot"><a href="#local-6989586621679547560"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679547559"><span class="annot"><a href="#local-6989586621679547559"><span class="hs-identifier hs-type">output</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-397"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetDevice"><span class="hs-identifier hs-type">SGetDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547562"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-398"></span><span>    </span><span class="annot"><a href="#local-6989586621679547559"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-399"></span><span>      </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-400"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#WithoutGradient"><span class="hs-identifier hs-type">WithoutGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-401"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679547563"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Dense"><span class="hs-identifier hs-type">Dense</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-402"></span><span>          </span><span class="annot"><a href="#local-6989586621679547562"><span class="hs-identifier hs-type">device</span></a></span><span>
</span><span id="line-403"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Seq"><span class="hs-identifier hs-type">Seq</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679547561"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#Int64"><span class="hs-identifier hs-type">Int64</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#Bool"><span class="hs-identifier hs-type">Bool</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-404"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#BroadcastShapesF"><span class="hs-identifier hs-type">BroadcastShapesF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547560"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">]</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-405"></span><span>  </span><span class="hs-special">)</span><span>
</span><span id="line-406"></span><span>
</span><span id="line-407"></span><span class="hs-comment">-- | Computes the padding mask for a transformer.</span><span>
</span><span id="line-408"></span><span class="hs-comment">-- Given an input tensor of shape @[batchDim, Dim seqName seqSize]@,</span><span>
</span><span id="line-409"></span><span class="hs-comment">-- returns a tensor of shape @[batchDim, Dim &quot;*&quot; seqSize]@.</span><span>
</span><span id="line-410"></span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#mkTransformerPaddingMask"><span class="hs-identifier hs-type">mkTransformerPaddingMask</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-411"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679548093"><span class="annot"><a href="#local-6989586621679548093"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679548098"><span class="annot"><a href="#local-6989586621679548098"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679548097"><span class="annot"><a href="#local-6989586621679548097"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679548096"><span class="annot"><a href="#local-6989586621679548096"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679548095"><span class="annot"><a href="#local-6989586621679548095"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679548094"><span class="annot"><a href="#local-6989586621679548094"><span class="hs-identifier hs-type">output</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-412"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerPaddingMaskC"><span class="hs-identifier hs-type">MkTransformerPaddingMaskC</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679548098"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679548097"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679548096"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679548095"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679548094"><span class="hs-identifier hs-type">output</span></a></span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-413"></span><span>  </span><span class="hs-comment">-- | padding token id</span><span>
</span><span id="line-414"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-415"></span><span>  </span><span class="hs-comment">-- | input tensor</span><span>
</span><span id="line-416"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679548093"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679548098"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679548097"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679548096"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679548095"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-417"></span><span>  </span><span class="hs-comment">-- | padding mask</span><span>
</span><span id="line-418"></span><span>  </span><span class="annot"><a href="#local-6989586621679548094"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-419"></span><span id="mkTransformerPaddingMask"><span class="annot"><span class="annottext">mkTransformerPaddingMask :: Int -&gt; Tensor gradient layout device dataType shape -&gt; output
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#mkTransformerPaddingMask"><span class="hs-identifier hs-var hs-var">mkTransformerPaddingMask</span></a></span></span><span> </span><span id="local-6989586621679547557"><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679547557"><span class="hs-identifier hs-var">padTokenId</span></a></span></span><span> </span><span id="local-6989586621679547556"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679547556"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-420"></span><span>  </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679547555"><span class="annot"><span class="annottext">device :: SDevice device
</span><a href="#local-6989586621679547555"><span class="hs-identifier hs-var hs-var">device</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape -&gt; SDevice device
forall (device :: Device (DeviceType Nat))
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SGetDevice device =&gt;
Tensor gradient layout device dataType shape -&gt; SDevice device
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sGetDevice"><span class="hs-identifier hs-var">sGetDevice</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679547556"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-421"></span><span>      </span><span id="local-6989586621679547554"><span class="annot"><span class="annottext">padToken :: Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  device
  ('DataType 'Int64)
  ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1)])
</span><a href="#local-6989586621679547554"><span class="hs-identifier hs-var hs-var">padToken</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-422"></span><span>        </span><span class="annot"><span class="annottext">TensorSpec
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  device
  ('DataType 'Int64)
  ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1)])
-&gt; Int
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     device
     ('DataType 'Int64)
     ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1)])
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]) input.
Scalar input =&gt;
TensorSpec gradient layout device dataType shape
-&gt; input -&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.Creation.html#sFull"><span class="hs-identifier hs-var">sFull</span></a></span><span>
</span><span id="line-423"></span><span>          </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SGradient ('Gradient 'WithoutGradient)
-&gt; SLayout ('Layout 'Dense)
-&gt; SDevice device
-&gt; SDataType ('DataType 'Int64)
-&gt; SShape ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1)])
-&gt; TensorSpec
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     device
     ('DataType 'Int64)
     ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1)])
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SShape shape
-&gt; TensorSpec gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorSpec"><span class="hs-identifier hs-var">TensorSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SRequiresGradient 'WithoutGradient
-&gt; SGradient ('Gradient 'WithoutGradient)
forall (requiresGradient :: RequiresGradient).
SRequiresGradient requiresGradient
-&gt; SGradient ('Gradient requiresGradient)
</span><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier hs-var">SGradient</span></a></span><span> </span><span class="annot"><span class="annottext">SRequiresGradient 'WithoutGradient
</span><a href="Torch.GraduallyTyped.RequiresGradient.html#SWithoutGradient"><span class="hs-identifier hs-var">SWithoutGradient</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SLayoutType 'Dense -&gt; SLayout ('Layout 'Dense)
forall (layoutType :: LayoutType).
SLayoutType layoutType -&gt; SLayout ('Layout layoutType)
</span><a href="Torch.GraduallyTyped.Layout.html#SLayout"><span class="hs-identifier hs-var">SLayout</span></a></span><span> </span><span class="annot"><span class="annottext">SLayoutType 'Dense
</span><a href="Torch.GraduallyTyped.Layout.html#SDense"><span class="hs-identifier hs-var">SDense</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679547555"><span class="hs-identifier hs-var">device</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SDType 'Int64 -&gt; SDataType ('DataType 'Int64)
forall (dType :: DType).
SDType dType -&gt; SDataType ('DataType dType)
</span><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier hs-var">SDataType</span></a></span><span> </span><span class="annot"><span class="annottext">SDType 'Int64
</span><a href="Torch.GraduallyTyped.DType.html#SInt64"><span class="hs-identifier hs-var">SInt64</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SList '[ 'Dim ('Name &quot;*&quot;) ('Size 1)]
-&gt; SShape ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1)])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList '[ 'Dim ('Name &quot;*&quot;) ('Size 1)]
 -&gt; SShape ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1)]))
-&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 1)]
-&gt; SShape ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1)])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize ('Size 1) -&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 1))
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownNat 1 =&gt; SSize ('Size 1)
forall (size :: Nat). KnownNat size =&gt; SSize ('Size size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier hs-var">SSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">1</span></span><span> </span><span class="annot"><span class="annottext">Sing ('Dim ('Name &quot;*&quot;) ('Size 1))
-&gt; SList '[] -&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 1)]
forall a1 (a2 :: a1) (as :: [a1]).
Sing a2 -&gt; SList as -&gt; SList (a2 : as)
</span><a href="Torch.GraduallyTyped.Prelude.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-424"></span><span>          </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679547557"><span class="hs-identifier hs-var">padTokenId</span></a></span><span>
</span><span id="line-425"></span><span>   </span><span class="hs-keyword">in</span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679547556"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     ('Layout 'Dense)
     device
     ('DataType 'Int64)
     ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1)])
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     (layout &lt;+&gt; 'Layout 'Dense)
     (device &lt;+&gt; device)
     (Seq (dataType &lt;+&gt; 'DataType 'Int64) ('DataType 'Bool))
     (BroadcastShapesF shape ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1)]))
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (gradient' :: Gradient RequiresGradient)
       (layout' :: Layout LayoutType) (device' :: Device (DeviceType Nat))
       (dataType' :: DataType DType)
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]).
Tensor gradient layout device dataType shape
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     (layout &lt;+&gt; layout')
     (device &lt;+&gt; device')
     (Seq (dataType &lt;+&gt; dataType') ('DataType 'Bool))
     (BroadcastShapesF shape shape')
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Comparison.html#%3D%3D."><span class="hs-operator hs-var">==.</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  ('Layout 'Dense)
  device
  ('DataType 'Int64)
  ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1)])
</span><a href="#local-6989586621679547554"><span class="hs-identifier hs-var">padToken</span></a></span><span>
</span><span id="line-426"></span><span>
</span><span id="line-427"></span><span class="hs-keyword">newtype</span><span> </span><span id="MkTransformerPaddingMask"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerPaddingMask"><span class="hs-identifier hs-var">MkTransformerPaddingMask</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span id="MkTransformerPaddingMask"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerPaddingMask"><span class="hs-identifier hs-var">MkTransformerPaddingMask</span></a></span></span><span> </span><span class="hs-special">{</span><span id="padTokenId"><span class="annot"><span class="annottext">MkTransformerPaddingMask -&gt; Int
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#padTokenId"><span class="hs-identifier hs-var hs-var">padTokenId</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Int</span></span><span class="hs-special">}</span><span>
</span><span id="line-428"></span><span>
</span><span id="line-429"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">instance</span><span>
</span><span id="line-430"></span><span>  </span><span id="ModelSpec"><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier hs-var">ModelSpec</span></a></span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerPaddingMask"><span class="hs-identifier hs-type">MkTransformerPaddingMask</span></a></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-431"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerPaddingMask"><span class="hs-identifier hs-type">MkTransformerPaddingMask</span></a></span><span>
</span><span id="line-432"></span><span>
</span><span id="line-433"></span><span id="local-6989586621679547550"><span class="hs-keyword">instance</span><span>
</span><span id="line-434"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span>
</span><span id="line-435"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerPaddingMask"><span class="hs-identifier hs-type">MkTransformerPaddingMask</span></a></span><span>
</span><span id="line-436"></span><span>    </span><span class="annot"><a href="#local-6989586621679547550"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-437"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerPaddingMask"><span class="hs-identifier hs-type">MkTransformerPaddingMask</span></a></span><span>
</span><span id="line-438"></span><span>    </span><span class="annot"><a href="#local-6989586621679547550"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-439"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-440"></span><span>  </span><span id="local-6989586621679547548"><span class="annot"><span class="annottext">initialize :: ModelSpec MkTransformerPaddingMask
-&gt; Generator generatorDevice
-&gt; m (MkTransformerPaddingMask, Generator generatorDevice)
</span><a href="#local-6989586621679547548"><span class="hs-identifier hs-var hs-var hs-var hs-var">initialize</span></a></span></span><span> </span><span id="local-6989586621679547547"><span class="annot"><span class="annottext">ModelSpec MkTransformerPaddingMask
</span><a href="#local-6989586621679547547"><span class="hs-identifier hs-var">spec</span></a></span></span><span> </span><span id="local-6989586621679547546"><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679547546"><span class="hs-identifier hs-var">g</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(MkTransformerPaddingMask, Generator generatorDevice)
-&gt; m (MkTransformerPaddingMask, Generator generatorDevice)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">ModelSpec MkTransformerPaddingMask
MkTransformerPaddingMask
</span><a href="#local-6989586621679547547"><span class="hs-identifier hs-var">spec</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679547546"><span class="hs-identifier hs-var">g</span></a></span><span class="hs-special">)</span></span><span>
</span><span id="line-441"></span><span>
</span><span id="line-442"></span><span class="hs-keyword">instance</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasStateDict"><span class="hs-identifier hs-type">HasStateDict</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerPaddingMask"><span class="hs-identifier hs-type">MkTransformerPaddingMask</span></a></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-443"></span><span>  </span><span id="local-6989586621679547543"><span class="annot"><span class="annottext">fromStateDict :: ModelSpec MkTransformerPaddingMask
-&gt; StateDictKey -&gt; m MkTransformerPaddingMask
</span><a href="#local-6989586621679547543"><span class="hs-identifier hs-var hs-var hs-var hs-var">fromStateDict</span></a></span></span><span> </span><span id="local-6989586621679547542"><span class="annot"><span class="annottext">ModelSpec MkTransformerPaddingMask
</span><a href="#local-6989586621679547542"><span class="hs-identifier hs-var">spec</span></a></span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">MkTransformerPaddingMask -&gt; m MkTransformerPaddingMask
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">ModelSpec MkTransformerPaddingMask
MkTransformerPaddingMask
</span><a href="#local-6989586621679547542"><span class="hs-identifier hs-var">spec</span></a></span><span>
</span><span id="line-444"></span><span>  </span><span id="local-6989586621679547541"><span class="annot"><span class="annottext">toStateDict :: StateDictKey -&gt; MkTransformerPaddingMask -&gt; m ()
</span><a href="#local-6989586621679547541"><span class="hs-identifier hs-var hs-var hs-var hs-var">toStateDict</span></a></span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="annottext">MkTransformerPaddingMask
</span><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">() -&gt; m ()
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span><span>
</span><span id="line-445"></span><span>
</span><span id="line-446"></span><span id="local-6989586621679547534"><span id="local-6989586621679547535"><span id="local-6989586621679547536"><span id="local-6989586621679547537"><span id="local-6989586621679547538"><span id="local-6989586621679547539"><span id="local-6989586621679547540"><span class="hs-keyword">instance</span><span>
</span><span id="line-447"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerPaddingMaskC"><span class="hs-identifier hs-type">MkTransformerPaddingMaskC</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547540"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547539"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547538"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547537"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547536"><span class="hs-identifier hs-type">output</span></a></span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-448"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-449"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerPaddingMask"><span class="hs-identifier hs-type">MkTransformerPaddingMask</span></a></span><span>
</span><span id="line-450"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547535"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547540"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547539"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547538"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547537"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-451"></span><span>    </span><span class="annot"><a href="#local-6989586621679547534"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-452"></span><span>    </span><span class="annot"><a href="#local-6989586621679547536"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-453"></span><span>    </span><span class="annot"><a href="#local-6989586621679547534"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-454"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-455"></span><span>  </span><span id="local-6989586621679547532"><span class="annot"><span class="annottext">forward :: MkTransformerPaddingMask
-&gt; Tensor gradient layout device dataType shape
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorDevice)
</span><a href="#local-6989586621679547532"><span class="hs-identifier hs-var hs-var hs-var hs-var">forward</span></a></span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerPaddingMask"><span class="hs-identifier hs-type">MkTransformerPaddingMask</span></a></span><span> </span><span class="hs-special">{</span><span id="local-6989586621679547531"><span class="annot"><span class="annottext">Int
padTokenId :: Int
padTokenId :: MkTransformerPaddingMask -&gt; Int
</span><a href="#local-6989586621679547531"><span class="hs-glyph hs-var hs-var">..</span></a></span></span><span class="hs-special">}</span><span> </span><span id="local-6989586621679547530"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679547530"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span id="local-6989586621679547529"><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679547529"><span class="hs-identifier hs-var">g</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-456"></span><span>    </span><span class="annot"><span class="annottext">(output, Generator generatorDevice)
-&gt; m (output, Generator generatorDevice)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Int -&gt; Tensor gradient layout device dataType shape -&gt; output
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]) output.
MkTransformerPaddingMaskC layout device dataType shape output =&gt;
Int -&gt; Tensor gradient layout device dataType shape -&gt; output
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#mkTransformerPaddingMask"><span class="hs-identifier hs-var">mkTransformerPaddingMask</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><a href="#local-6989586621679547531"><span class="hs-identifier hs-var">padTokenId</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679547530"><span class="hs-identifier hs-var">input</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679547529"><span class="hs-identifier hs-var">g</span></a></span><span class="hs-special">)</span></span></span></span></span></span></span></span><span>
</span><span id="line-457"></span><span>
</span><span id="line-458"></span><span class="hs-keyword">type</span><span> </span><span id="MkTransformerAttentionMaskC"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerAttentionMaskC"><span class="hs-identifier hs-var">MkTransformerAttentionMaskC</span></a></span></span><span> </span><span id="local-6989586621679547528"><span class="annot"><a href="#local-6989586621679547528"><span class="hs-identifier hs-type">transformerDataType</span></a></span></span><span> </span><span id="local-6989586621679547527"><span class="annot"><a href="#local-6989586621679547527"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679547526"><span class="annot"><a href="#local-6989586621679547526"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679547525"><span class="annot"><a href="#local-6989586621679547525"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679547524"><span class="annot"><a href="#local-6989586621679547524"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679547523"><span class="annot"><a href="#local-6989586621679547523"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679547522"><span class="annot"><a href="#local-6989586621679547522"><span class="hs-identifier hs-type">seqDim</span></a></span></span><span> </span><span id="local-6989586621679547521"><span class="annot"><a href="#local-6989586621679547521"><span class="hs-identifier hs-type">output</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-459"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetLayout"><span class="hs-identifier hs-type">SGetLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547526"><span class="hs-identifier hs-type">layout</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-460"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetDevice"><span class="hs-identifier hs-type">SGetDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547525"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-461"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetShape"><span class="hs-identifier hs-type">SGetShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547523"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-462"></span><span>    </span><span class="annot"><a href="#local-6989586621679547522"><span class="hs-identifier hs-type">seqDim</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679547523"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#%21"><span class="hs-glyph hs-type">!</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-463"></span><span>    </span><span class="annot"><a href="#local-6989586621679547521"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-464"></span><span>      </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-465"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Seq"><span class="hs-identifier hs-type">Seq</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679547527"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#WithoutGradient"><span class="hs-identifier hs-type">WithoutGradient</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#WithoutGradient"><span class="hs-identifier hs-type">WithoutGradient</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-466"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679547526"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Dense"><span class="hs-identifier hs-type">Dense</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-467"></span><span>          </span><span class="annot"><a href="#local-6989586621679547525"><span class="hs-identifier hs-type">device</span></a></span><span>
</span><span id="line-468"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Seq"><span class="hs-identifier hs-type">Seq</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679547524"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#Bool"><span class="hs-identifier hs-type">Bool</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679547528"><span class="hs-identifier hs-type">transformerDataType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-469"></span><span>          </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#BroadcastShapesF"><span class="hs-identifier hs-type">BroadcastShapesF</span></a></span><span>
</span><span id="line-470"></span><span>              </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#UnsqueezeF"><span class="hs-identifier hs-type">UnsqueezeF</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679547523"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-471"></span><span>              </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679547522"><span class="hs-identifier hs-type">seqDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679547522"><span class="hs-identifier hs-type">seqDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-472"></span><span>          </span><span class="hs-special">)</span><span>
</span><span id="line-473"></span><span>  </span><span class="hs-special">)</span><span>
</span><span id="line-474"></span><span>
</span><span id="line-475"></span><span class="hs-comment">-- | Creates a bidirectional attention mask for a transformer.</span><span>
</span><span id="line-476"></span><span class="hs-comment">-- Given a padding mask of shape @[batchDim, seqDim]@,</span><span>
</span><span id="line-477"></span><span class="hs-comment">-- returns a tensor of shape @[batchDim, seqDim, seqDim]@.</span><span>
</span><span id="line-478"></span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#mkTransformerAttentionMask"><span class="hs-identifier hs-type">mkTransformerAttentionMask</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-479"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679548032"><span class="annot"><a href="#local-6989586621679548032"><span class="hs-identifier hs-type">m</span></a></span></span><span> </span><span id="local-6989586621679548031"><span class="annot"><a href="#local-6989586621679548031"><span class="hs-identifier hs-type">transformerDataType</span></a></span></span><span> </span><span id="local-6989586621679548030"><span class="annot"><a href="#local-6989586621679548030"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679548029"><span class="annot"><a href="#local-6989586621679548029"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679548028"><span class="annot"><a href="#local-6989586621679548028"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679548027"><span class="annot"><a href="#local-6989586621679548027"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679548026"><span class="annot"><a href="#local-6989586621679548026"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679548025"><span class="annot"><a href="#local-6989586621679548025"><span class="hs-identifier hs-type">seqDim</span></a></span></span><span> </span><span id="local-6989586621679548024"><span class="annot"><a href="#local-6989586621679548024"><span class="hs-identifier hs-type">output</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-480"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier hs-type">MonadThrow</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679548032"><span class="hs-identifier hs-type">m</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-481"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerAttentionMaskC"><span class="hs-identifier hs-type">MkTransformerAttentionMaskC</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679548031"><span class="hs-identifier hs-type">transformerDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679548030"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679548029"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679548028"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679548027"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679548026"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679548025"><span class="hs-identifier hs-type">seqDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679548024"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-482"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-483"></span><span>  </span><span class="hs-comment">-- | data type singleton of the transformer</span><span>
</span><span id="line-484"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier hs-type">SDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679548031"><span class="hs-identifier hs-type">transformerDataType</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-485"></span><span>  </span><span class="hs-comment">-- | attention mask bias (typically a large negative number)</span><span>
</span><span id="line-486"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-487"></span><span>  </span><span class="hs-comment">-- | encoder padding mask</span><span>
</span><span id="line-488"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679548030"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679548029"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679548028"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679548027"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679548026"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-489"></span><span>  </span><span class="annot"><a href="#local-6989586621679548032"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679548024"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-490"></span><span id="mkTransformerAttentionMask"><span class="annot"><span class="annottext">mkTransformerAttentionMask :: SDataType transformerDataType
-&gt; Double
-&gt; Tensor gradient layout device dataType shape
-&gt; m output
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#mkTransformerAttentionMask"><span class="hs-identifier hs-var hs-var">mkTransformerAttentionMask</span></a></span></span><span> </span><span id="local-6989586621679547519"><span class="annot"><span class="annottext">SDataType transformerDataType
</span><a href="#local-6989586621679547519"><span class="hs-identifier hs-var">transformerDataType</span></a></span></span><span> </span><span id="local-6989586621679547518"><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679547518"><span class="hs-identifier hs-var">attentionMaskBias</span></a></span></span><span> </span><span id="local-6989586621679547517"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679547517"><span class="hs-identifier hs-var">paddingMask</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-491"></span><span>  </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679547516"><span class="annot"><span class="annottext">pmLayout :: SLayout layout
</span><a href="#local-6989586621679547516"><span class="hs-identifier hs-var hs-var">pmLayout</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape -&gt; SLayout layout
forall (layout :: Layout LayoutType)
       (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SGetLayout layout =&gt;
Tensor gradient layout device dataType shape -&gt; SLayout layout
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sGetLayout"><span class="hs-identifier hs-var">sGetLayout</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679547517"><span class="hs-identifier hs-var">paddingMask</span></a></span><span>
</span><span id="line-492"></span><span>      </span><span id="local-6989586621679547514"><span class="annot"><span class="annottext">pmDevice :: SDevice device
</span><a href="#local-6989586621679547514"><span class="hs-identifier hs-var hs-var">pmDevice</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape -&gt; SDevice device
forall (device :: Device (DeviceType Nat))
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SGetDevice device =&gt;
Tensor gradient layout device dataType shape -&gt; SDevice device
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sGetDevice"><span class="hs-identifier hs-var">sGetDevice</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679547517"><span class="hs-identifier hs-var">paddingMask</span></a></span><span>
</span><span id="line-493"></span><span>      </span><span id="local-6989586621679547513"><span class="annot"><span class="annottext">pmShape :: SShape shape
</span><a href="#local-6989586621679547513"><span class="hs-identifier hs-var hs-var">pmShape</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape -&gt; SShape shape
forall (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType).
SGetShape shape =&gt;
Tensor gradient layout device dataType shape -&gt; SShape shape
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sGetShape"><span class="hs-identifier hs-var">sGetShape</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679547517"><span class="hs-identifier hs-var">paddingMask</span></a></span><span>
</span><span id="line-494"></span><span>  </span><span id="local-6989586621679547512"><span class="annot"><span class="annottext">SDim seqDim
</span><a href="#local-6989586621679547512"><span class="hs-identifier hs-var">pmSeqDim</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">SSelectDim ('SelectDim ('ByIndex 1))
-&gt; SShape shape -&gt; m (SDim seqDim)
forall (selectDim :: SelectDim (By Symbol Nat))
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (dim :: Dim (Name Symbol) (Size Nat)) (m :: * -&gt; *).
(dim ~ GetDimF selectDim shape, MonadThrow m) =&gt;
SSelectDim selectDim -&gt; SShape shape -&gt; m (SDim dim)
</span><a href="Torch.GraduallyTyped.Shape.Class.html#sGetDimFromShape"><span class="hs-identifier hs-var">sGetDimFromShape</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SBy ('ByIndex 1) -&gt; SSelectDim ('SelectDim ('ByIndex 1))
forall (by :: By Symbol Nat). SBy by -&gt; SSelectDim ('SelectDim by)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSelectDim"><span class="hs-identifier hs-var">SSelectDim</span></a></span><span> </span><span class="annot"><span class="annottext">(SBy ('ByIndex 1) -&gt; SSelectDim ('SelectDim ('ByIndex 1)))
-&gt; SBy ('ByIndex 1) -&gt; SSelectDim ('SelectDim ('ByIndex 1))
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">KnownNat 1 =&gt; SBy ('ByIndex 1)
forall (index :: Nat). KnownNat index =&gt; SBy ('ByIndex index)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SByIndex"><span class="hs-identifier hs-var">SByIndex</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">SShape shape
</span><a href="#local-6989586621679547513"><span class="hs-identifier hs-var">pmShape</span></a></span><span>
</span><span id="line-495"></span><span>  </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679547511"><span class="annot"><span class="annottext">emptyMask :: Tensor
  ('Gradient 'WithoutGradient)
  layout
  device
  transformerDataType
  ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim])
</span><a href="#local-6989586621679547511"><span class="hs-identifier hs-var hs-var">emptyMask</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-496"></span><span>        </span><span class="annot"><span class="annottext">TensorSpec
  ('Gradient 'WithoutGradient)
  layout
  device
  transformerDataType
  ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim])
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     layout
     device
     transformerDataType
     ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim])
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
TensorSpec gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.Creation.html#sZeros"><span class="hs-identifier hs-var">sZeros</span></a></span><span> </span><span class="annot"><span class="annottext">(TensorSpec
   ('Gradient 'WithoutGradient)
   layout
   device
   transformerDataType
   ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim])
 -&gt; Tensor
      ('Gradient 'WithoutGradient)
      layout
      device
      transformerDataType
      ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim]))
-&gt; TensorSpec
     ('Gradient 'WithoutGradient)
     layout
     device
     transformerDataType
     ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim])
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     layout
     device
     transformerDataType
     ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-497"></span><span>          </span><span class="annot"><span class="annottext">SGradient ('Gradient 'WithoutGradient)
-&gt; SLayout layout
-&gt; SDevice device
-&gt; SDataType transformerDataType
-&gt; SShape ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim])
-&gt; TensorSpec
     ('Gradient 'WithoutGradient)
     layout
     device
     transformerDataType
     ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim])
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SShape shape
-&gt; TensorSpec gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorSpec"><span class="hs-identifier hs-var">TensorSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SRequiresGradient 'WithoutGradient
-&gt; SGradient ('Gradient 'WithoutGradient)
forall (requiresGradient :: RequiresGradient).
SRequiresGradient requiresGradient
-&gt; SGradient ('Gradient requiresGradient)
</span><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier hs-var">SGradient</span></a></span><span> </span><span class="annot"><span class="annottext">SRequiresGradient 'WithoutGradient
</span><a href="Torch.GraduallyTyped.RequiresGradient.html#SWithoutGradient"><span class="hs-identifier hs-var">SWithoutGradient</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">SLayout layout
</span><a href="#local-6989586621679547516"><span class="hs-identifier hs-var">pmLayout</span></a></span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679547514"><span class="hs-identifier hs-var">pmDevice</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType transformerDataType
</span><a href="#local-6989586621679547519"><span class="hs-identifier hs-var">transformerDataType</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SList '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim]
-&gt; SShape ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim]
 -&gt; SShape ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim]))
-&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim]
-&gt; SShape ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize ('Size 1) -&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 1))
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownNat 1 =&gt; SSize ('Size 1)
forall (size :: Nat). KnownNat size =&gt; SSize ('Size size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier hs-var">SSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">1</span></span><span> </span><span class="annot"><span class="annottext">Sing ('Dim ('Name &quot;*&quot;) ('Size 1))
-&gt; SList '[seqDim, seqDim]
-&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim]
forall a1 (a2 :: a1) (as :: [a1]).
Sing a2 -&gt; SList as -&gt; SList (a2 : as)
</span><a href="Torch.GraduallyTyped.Prelude.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">Sing seqDim
SDim seqDim
</span><a href="#local-6989586621679547512"><span class="hs-identifier hs-var">pmSeqDim</span></a></span><span> </span><span class="annot"><span class="annottext">Sing seqDim -&gt; SList '[seqDim] -&gt; SList '[seqDim, seqDim]
forall a1 (a2 :: a1) (as :: [a1]).
Sing a2 -&gt; SList as -&gt; SList (a2 : as)
</span><a href="Torch.GraduallyTyped.Prelude.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">Sing seqDim
SDim seqDim
</span><a href="#local-6989586621679547512"><span class="hs-identifier hs-var">pmSeqDim</span></a></span><span> </span><span class="annot"><span class="annottext">Sing seqDim -&gt; SList '[] -&gt; SList '[seqDim]
forall a1 (a2 :: a1) (as :: [a1]).
Sing a2 -&gt; SList as -&gt; SList (a2 : as)
</span><a href="Torch.GraduallyTyped.Prelude.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-498"></span><span>  </span><span class="annot"><span class="annottext">output -&gt; m output
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">(output -&gt; m output) -&gt; output -&gt; m output
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">Tensor
  gradient
  layout
  device
  dataType
  (UnsqueezeF ('SelectDim ('ByIndex 1)) shape)
-&gt; Double
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     layout
     device
     transformerDataType
     ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim])
-&gt; Tensor
     (Seq
        (gradient &lt;+&gt; 'Gradient 'WithoutGradient)
        ('Gradient 'WithoutGradient))
     (layout &lt;+&gt; (layout &lt;+&gt; 'Layout 'Dense))
     (device &lt;+&gt; device)
     (Seq (dataType &lt;+&gt; 'DataType 'Bool) transformerDataType)
     (BroadcastShapesF
        (UnsqueezeF ('SelectDim ('ByIndex 1)) shape)
        ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim]))
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]) value
       (gradient' :: Gradient RequiresGradient)
       (layout' :: Layout LayoutType) (device' :: Device (DeviceType Nat))
       (dataType' :: DataType DType)
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]).
Scalar value =&gt;
Tensor gradient layout device dataType shape
-&gt; value
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; Tensor
     (Seq (gradient &lt;+&gt; 'Gradient 'WithoutGradient) gradient')
     (layout &lt;+&gt; (layout' &lt;+&gt; 'Layout 'Dense))
     (device &lt;+&gt; device')
     (Seq (dataType &lt;+&gt; 'DataType 'Bool) dataType')
     (BroadcastShapesF shape shape')
</span><a href="Torch.GraduallyTyped.Tensor.Other.html#maskedFill"><span class="hs-identifier hs-var">maskedFill</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
-&gt; Tensor
     gradient
     layout
     device
     dataType
     (UnsqueezeF ('SelectDim ('ByIndex 1)) shape)
forall (selectDim :: SelectDim (By Symbol Nat))
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]).
(shape' ~ UnsqueezeF selectDim shape, SingI selectDim) =&gt;
Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape'
</span><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#unsqueeze"><span class="hs-identifier hs-var">unsqueeze</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679547517"><span class="hs-identifier hs-var">paddingMask</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679547518"><span class="hs-identifier hs-var">attentionMaskBias</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  layout
  device
  transformerDataType
  ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim])
</span><a href="#local-6989586621679547511"><span class="hs-identifier hs-var">emptyMask</span></a></span><span>
</span><span id="line-499"></span><span>
</span><span id="line-500"></span><span class="hs-keyword">data</span><span> </span><span id="MkTransformerAttentionMask"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerAttentionMask"><span class="hs-identifier hs-var">MkTransformerAttentionMask</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679547510"><span class="annot"><a href="#local-6989586621679547510"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier hs-type">DType</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-501"></span><span>  </span><span id="MkTransformerAttentionMask"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerAttentionMask"><span class="hs-identifier hs-var">MkTransformerAttentionMask</span></a></span></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-502"></span><span>    </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679548033"><span class="annot"><a href="#local-6989586621679548033"><span class="hs-identifier hs-type">dataType</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-503"></span><span>    </span><span class="hs-special">{</span><span> </span><span id="attentionMaskDataType"><span class="annot"><span class="annottext">MkTransformerAttentionMask dataType -&gt; SDataType dataType
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#attentionMaskDataType"><span class="hs-identifier hs-var hs-var">attentionMaskDataType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier hs-type">SDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679548033"><span class="hs-identifier hs-type">dataType</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-504"></span><span>      </span><span id="attentionMaskBias"><span class="annot"><span class="annottext">MkTransformerAttentionMask dataType -&gt; Double
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#attentionMaskBias"><span class="hs-identifier hs-var hs-var">attentionMaskBias</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span>
</span><span id="line-505"></span><span>    </span><span class="hs-special">}</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-506"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerAttentionMask"><span class="hs-identifier hs-type">MkTransformerAttentionMask</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679548033"><span class="hs-identifier hs-type">dataType</span></a></span><span>
</span><span id="line-507"></span><span>
</span><span id="line-508"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">instance</span><span>
</span><span id="line-509"></span><span>  </span><span id="ModelSpec"><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier hs-var">ModelSpec</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerAttentionMask"><span class="hs-identifier hs-type">MkTransformerAttentionMask</span></a></span><span> </span><span id="local-6989586621679547506"><span class="annot"><a href="#local-6989586621679547506"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-510"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerAttentionMask"><span class="hs-identifier hs-type">MkTransformerAttentionMask</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547506"><span class="hs-identifier hs-type">dataType</span></a></span><span>
</span><span id="line-511"></span><span>
</span><span id="line-512"></span><span id="local-6989586621679547504"><span id="local-6989586621679547505"><span class="hs-keyword">instance</span><span>
</span><span id="line-513"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span>
</span><span id="line-514"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerAttentionMask"><span class="hs-identifier hs-type">MkTransformerAttentionMask</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547505"><span class="hs-identifier hs-type">dataType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-515"></span><span>    </span><span class="annot"><a href="#local-6989586621679547504"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-516"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerAttentionMask"><span class="hs-identifier hs-type">MkTransformerAttentionMask</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547505"><span class="hs-identifier hs-type">dataType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-517"></span><span>    </span><span class="annot"><a href="#local-6989586621679547504"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-518"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-519"></span><span>  </span><span id="local-6989586621679547502"><span class="annot"><span class="annottext">initialize :: ModelSpec (MkTransformerAttentionMask dataType)
-&gt; Generator generatorDevice
-&gt; m (MkTransformerAttentionMask dataType,
      Generator generatorDevice)
</span><a href="#local-6989586621679547502"><span class="hs-identifier hs-var hs-var hs-var hs-var">initialize</span></a></span></span><span> </span><span id="local-6989586621679547501"><span class="annot"><span class="annottext">ModelSpec (MkTransformerAttentionMask dataType)
</span><a href="#local-6989586621679547501"><span class="hs-identifier hs-var">spec</span></a></span></span><span> </span><span id="local-6989586621679547500"><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679547500"><span class="hs-identifier hs-var">g</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(MkTransformerAttentionMask dataType, Generator generatorDevice)
-&gt; m (MkTransformerAttentionMask dataType,
      Generator generatorDevice)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">ModelSpec (MkTransformerAttentionMask dataType)
MkTransformerAttentionMask dataType
</span><a href="#local-6989586621679547501"><span class="hs-identifier hs-var">spec</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679547500"><span class="hs-identifier hs-var">g</span></a></span><span class="hs-special">)</span></span></span><span>
</span><span id="line-520"></span><span>
</span><span id="line-521"></span><span id="local-6989586621679547499"><span class="hs-keyword">instance</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasStateDict"><span class="hs-identifier hs-type">HasStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerAttentionMask"><span class="hs-identifier hs-type">MkTransformerAttentionMask</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547499"><span class="hs-identifier hs-type">dataType</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-522"></span><span>  </span><span id="local-6989586621679547496"><span class="annot"><span class="annottext">fromStateDict :: ModelSpec (MkTransformerAttentionMask dataType)
-&gt; StateDictKey -&gt; m (MkTransformerAttentionMask dataType)
</span><a href="#local-6989586621679547496"><span class="hs-identifier hs-var hs-var hs-var hs-var">fromStateDict</span></a></span></span><span> </span><span id="local-6989586621679547495"><span class="annot"><span class="annottext">ModelSpec (MkTransformerAttentionMask dataType)
</span><a href="#local-6989586621679547495"><span class="hs-identifier hs-var">spec</span></a></span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">MkTransformerAttentionMask dataType
-&gt; m (MkTransformerAttentionMask dataType)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">ModelSpec (MkTransformerAttentionMask dataType)
MkTransformerAttentionMask dataType
</span><a href="#local-6989586621679547495"><span class="hs-identifier hs-var">spec</span></a></span><span>
</span><span id="line-523"></span><span>  </span><span id="local-6989586621679547494"><span class="annot"><span class="annottext">toStateDict :: StateDictKey -&gt; MkTransformerAttentionMask dataType -&gt; m ()
</span><a href="#local-6989586621679547494"><span class="hs-identifier hs-var hs-var hs-var hs-var">toStateDict</span></a></span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="annottext">MkTransformerAttentionMask dataType
</span><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">() -&gt; m ()
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span></span><span>
</span><span id="line-524"></span><span>
</span><span id="line-525"></span><span id="local-6989586621679547485"><span id="local-6989586621679547486"><span id="local-6989586621679547487"><span id="local-6989586621679547488"><span id="local-6989586621679547489"><span id="local-6989586621679547490"><span id="local-6989586621679547491"><span id="local-6989586621679547492"><span id="local-6989586621679547493"><span class="hs-keyword">instance</span><span>
</span><span id="line-526"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerAttentionMaskC"><span class="hs-identifier hs-type">MkTransformerAttentionMaskC</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547493"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547492"><span class="hs-identifier hs-type">inputGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547491"><span class="hs-identifier hs-type">inputLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547490"><span class="hs-identifier hs-type">inputDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547489"><span class="hs-identifier hs-type">inputDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547488"><span class="hs-identifier hs-type">inputShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547487"><span class="hs-identifier hs-type">seqDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547486"><span class="hs-identifier hs-type">output</span></a></span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-527"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-528"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerAttentionMask"><span class="hs-identifier hs-type">MkTransformerAttentionMask</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547493"><span class="hs-identifier hs-type">dataType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-529"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547492"><span class="hs-identifier hs-type">inputGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547491"><span class="hs-identifier hs-type">inputLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547490"><span class="hs-identifier hs-type">inputDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547489"><span class="hs-identifier hs-type">inputDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547488"><span class="hs-identifier hs-type">inputShape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-530"></span><span>    </span><span class="annot"><a href="#local-6989586621679547485"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-531"></span><span>    </span><span class="annot"><a href="#local-6989586621679547486"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-532"></span><span>    </span><span class="annot"><a href="#local-6989586621679547485"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-533"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-534"></span><span>  </span><span id="local-6989586621679547483"><span class="annot"><span class="annottext">forward :: MkTransformerAttentionMask dataType
-&gt; Tensor
     inputGradient inputLayout inputDevice inputDataType inputShape
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorDevice)
</span><a href="#local-6989586621679547483"><span class="hs-identifier hs-var hs-var hs-var hs-var">forward</span></a></span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerAttentionMask"><span class="hs-identifier hs-type">MkTransformerAttentionMask</span></a></span><span> </span><span class="hs-special">{</span><span id="local-6989586621679547481"><span id="local-6989586621679547482"><span class="annot"><span class="annottext">Double
SDataType dataType
attentionMaskBias :: Double
attentionMaskDataType :: SDataType dataType
attentionMaskBias :: forall (dataType :: DataType DType).
MkTransformerAttentionMask dataType -&gt; Double
attentionMaskDataType :: forall (dataType :: DataType DType).
MkTransformerAttentionMask dataType -&gt; SDataType dataType
</span><a href="#local-6989586621679547481"><span class="hs-glyph hs-var hs-var hs-var hs-var">..</span></a></span></span></span><span class="hs-special">}</span><span> </span><span id="local-6989586621679547480"><span class="annot"><span class="annottext">Tensor
  inputGradient inputLayout inputDevice inputDataType inputShape
</span><a href="#local-6989586621679547480"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span id="local-6989586621679547479"><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679547479"><span class="hs-identifier hs-var">g</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-535"></span><span>    </span><span id="local-6989586621679547478"><span class="annot"><span class="annottext">output
</span><a href="#local-6989586621679547478"><span class="hs-identifier hs-var">attentionMask</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">SDataType dataType
-&gt; Double
-&gt; Tensor
     inputGradient inputLayout inputDevice inputDataType inputShape
-&gt; m output
forall (m :: * -&gt; *) (transformerDataType :: DataType DType)
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (seqDim :: Dim (Name Symbol) (Size Nat)) output.
(MonadThrow m,
 MkTransformerAttentionMaskC
   transformerDataType
   gradient
   layout
   device
   dataType
   shape
   seqDim
   output) =&gt;
SDataType transformerDataType
-&gt; Double
-&gt; Tensor gradient layout device dataType shape
-&gt; m output
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#mkTransformerAttentionMask"><span class="hs-identifier hs-var">mkTransformerAttentionMask</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679547482"><span class="hs-identifier hs-var">attentionMaskDataType</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679547481"><span class="hs-identifier hs-var">attentionMaskBias</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  inputGradient inputLayout inputDevice inputDataType inputShape
</span><a href="#local-6989586621679547480"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-536"></span><span>    </span><span class="annot"><span class="annottext">(output, Generator generatorDevice)
-&gt; m (output, Generator generatorDevice)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">output
</span><a href="#local-6989586621679547478"><span class="hs-identifier hs-var">attentionMask</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679547479"><span class="hs-identifier hs-var">g</span></a></span><span class="hs-special">)</span></span></span></span></span></span></span></span></span></span><span>
</span><span id="line-537"></span><span>
</span><span id="line-538"></span><span class="hs-keyword">type</span><span> </span><span id="MkTransformerDecoderAttentionMaskC"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerDecoderAttentionMaskC"><span class="hs-identifier hs-var">MkTransformerDecoderAttentionMaskC</span></a></span></span><span> </span><span id="local-6989586621679547477"><span class="annot"><a href="#local-6989586621679547477"><span class="hs-identifier hs-type">transformerDataType</span></a></span></span><span> </span><span id="local-6989586621679547476"><span class="annot"><a href="#local-6989586621679547476"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679547475"><span class="annot"><a href="#local-6989586621679547475"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679547474"><span class="annot"><a href="#local-6989586621679547474"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679547473"><span class="annot"><a href="#local-6989586621679547473"><span class="hs-identifier hs-type">seqDim</span></a></span></span><span> </span><span id="local-6989586621679547472"><span class="annot"><a href="#local-6989586621679547472"><span class="hs-identifier hs-type">output</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-539"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetLayout"><span class="hs-identifier hs-type">SGetLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547476"><span class="hs-identifier hs-type">layout</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-540"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetDevice"><span class="hs-identifier hs-type">SGetDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547475"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-541"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetShape"><span class="hs-identifier hs-type">SGetShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547474"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-542"></span><span>    </span><span class="annot"><a href="#local-6989586621679547473"><span class="hs-identifier hs-type">seqDim</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679547474"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#%21"><span class="hs-glyph hs-type">!</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-543"></span><span>    </span><span class="annot"><a href="#local-6989586621679547472"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-544"></span><span>      </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-545"></span><span>          </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#WithoutGradient"><span class="hs-identifier hs-type">WithoutGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-546"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679547476"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Dense"><span class="hs-identifier hs-type">Dense</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-547"></span><span>          </span><span class="annot"><a href="#local-6989586621679547475"><span class="hs-identifier hs-type">device</span></a></span><span>
</span><span id="line-548"></span><span>          </span><span class="annot"><a href="#local-6989586621679547477"><span class="hs-identifier hs-type">transformerDataType</span></a></span><span>
</span><span id="line-549"></span><span>          </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#BroadcastShapesF"><span class="hs-identifier hs-type">BroadcastShapesF</span></a></span><span>
</span><span id="line-550"></span><span>              </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#BroadcastShapesF"><span class="hs-identifier hs-type">BroadcastShapesF</span></a></span><span>
</span><span id="line-551"></span><span>                  </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679547473"><span class="hs-identifier hs-type">seqDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679547473"><span class="hs-identifier hs-type">seqDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-552"></span><span>                  </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#UnsqueezeF"><span class="hs-identifier hs-type">UnsqueezeF</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679547474"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-553"></span><span>              </span><span class="hs-special">)</span><span>
</span><span id="line-554"></span><span>              </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679547473"><span class="hs-identifier hs-type">seqDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679547473"><span class="hs-identifier hs-type">seqDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-555"></span><span>          </span><span class="hs-special">)</span><span>
</span><span id="line-556"></span><span>  </span><span class="hs-special">)</span><span>
</span><span id="line-557"></span><span>
</span><span id="line-558"></span><span class="hs-comment">-- | Creates a causal attention mask for a transformer decoder.</span><span>
</span><span id="line-559"></span><span class="hs-comment">-- Given a padding mask of shape @[batchDim, seqDim]@,</span><span>
</span><span id="line-560"></span><span class="hs-comment">-- returns a tensor of shape @[batchDim, seqDim, seqDim]@.</span><span>
</span><span id="line-561"></span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#mkTransformerDecoderAttentionMask"><span class="hs-identifier hs-type">mkTransformerDecoderAttentionMask</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-562"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679547972"><span class="annot"><a href="#local-6989586621679547972"><span class="hs-identifier hs-type">m</span></a></span></span><span> </span><span id="local-6989586621679547971"><span class="annot"><a href="#local-6989586621679547971"><span class="hs-identifier hs-type">transformerDataType</span></a></span></span><span> </span><span id="local-6989586621679547965"><span class="annot"><a href="#local-6989586621679547965"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679547970"><span class="annot"><a href="#local-6989586621679547970"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679547969"><span class="annot"><a href="#local-6989586621679547969"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679547964"><span class="annot"><a href="#local-6989586621679547964"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679547968"><span class="annot"><a href="#local-6989586621679547968"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679547967"><span class="annot"><a href="#local-6989586621679547967"><span class="hs-identifier hs-type">seqDim</span></a></span></span><span> </span><span id="local-6989586621679547966"><span class="annot"><a href="#local-6989586621679547966"><span class="hs-identifier hs-type">output</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-563"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier hs-type">MonadThrow</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547972"><span class="hs-identifier hs-type">m</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-564"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerDecoderAttentionMaskC"><span class="hs-identifier hs-type">MkTransformerDecoderAttentionMaskC</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547971"><span class="hs-identifier hs-type">transformerDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547970"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547969"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547968"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547967"><span class="hs-identifier hs-type">seqDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547966"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-565"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-566"></span><span>  </span><span class="hs-comment">-- | data type singleton of the transformer</span><span>
</span><span id="line-567"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier hs-type">SDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547971"><span class="hs-identifier hs-type">transformerDataType</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-568"></span><span>  </span><span class="hs-comment">-- | attention mask bias (typically a large negative number)</span><span>
</span><span id="line-569"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-570"></span><span>  </span><span class="hs-comment">-- | decoder padding mask</span><span>
</span><span id="line-571"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547965"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547970"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547969"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547964"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547968"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-572"></span><span>  </span><span class="annot"><a href="#local-6989586621679547972"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547966"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-573"></span><span id="mkTransformerDecoderAttentionMask"><span class="annot"><span class="annottext">mkTransformerDecoderAttentionMask :: SDataType transformerDataType
-&gt; Double
-&gt; Tensor gradient layout device dataType shape
-&gt; m output
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#mkTransformerDecoderAttentionMask"><span class="hs-identifier hs-var hs-var">mkTransformerDecoderAttentionMask</span></a></span></span><span> </span><span id="local-6989586621679547470"><span class="annot"><span class="annottext">SDataType transformerDataType
</span><a href="#local-6989586621679547470"><span class="hs-identifier hs-var">transformerDataType</span></a></span></span><span> </span><span id="local-6989586621679547469"><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679547469"><span class="hs-identifier hs-var">attentionMaskBias</span></a></span></span><span> </span><span id="local-6989586621679547468"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679547468"><span class="hs-identifier hs-var">paddingMask</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-574"></span><span>  </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679547467"><span class="annot"><span class="annottext">pmLayout :: SLayout layout
</span><a href="#local-6989586621679547467"><span class="hs-identifier hs-var hs-var">pmLayout</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape -&gt; SLayout layout
forall (layout :: Layout LayoutType)
       (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SGetLayout layout =&gt;
Tensor gradient layout device dataType shape -&gt; SLayout layout
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sGetLayout"><span class="hs-identifier hs-var">sGetLayout</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679547468"><span class="hs-identifier hs-var">paddingMask</span></a></span><span>
</span><span id="line-575"></span><span>      </span><span id="local-6989586621679547466"><span class="annot"><span class="annottext">pmDevice :: SDevice device
</span><a href="#local-6989586621679547466"><span class="hs-identifier hs-var hs-var">pmDevice</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape -&gt; SDevice device
forall (device :: Device (DeviceType Nat))
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SGetDevice device =&gt;
Tensor gradient layout device dataType shape -&gt; SDevice device
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sGetDevice"><span class="hs-identifier hs-var">sGetDevice</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679547468"><span class="hs-identifier hs-var">paddingMask</span></a></span><span>
</span><span id="line-576"></span><span>      </span><span id="local-6989586621679547465"><span class="annot"><span class="annottext">pmShape :: SShape shape
</span><a href="#local-6989586621679547465"><span class="hs-identifier hs-var hs-var">pmShape</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape -&gt; SShape shape
forall (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType).
SGetShape shape =&gt;
Tensor gradient layout device dataType shape -&gt; SShape shape
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sGetShape"><span class="hs-identifier hs-var">sGetShape</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679547468"><span class="hs-identifier hs-var">paddingMask</span></a></span><span>
</span><span id="line-577"></span><span>  </span><span id="local-6989586621679547464"><span class="annot"><span class="annottext">SDim seqDim
</span><a href="#local-6989586621679547464"><span class="hs-identifier hs-var">pmSeqDim</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">SSelectDim ('SelectDim ('ByIndex 1))
-&gt; SShape shape -&gt; m (SDim seqDim)
forall (selectDim :: SelectDim (By Symbol Nat))
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (dim :: Dim (Name Symbol) (Size Nat)) (m :: * -&gt; *).
(dim ~ GetDimF selectDim shape, MonadThrow m) =&gt;
SSelectDim selectDim -&gt; SShape shape -&gt; m (SDim dim)
</span><a href="Torch.GraduallyTyped.Shape.Class.html#sGetDimFromShape"><span class="hs-identifier hs-var">sGetDimFromShape</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SBy ('ByIndex 1) -&gt; SSelectDim ('SelectDim ('ByIndex 1))
forall (by :: By Symbol Nat). SBy by -&gt; SSelectDim ('SelectDim by)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSelectDim"><span class="hs-identifier hs-var">SSelectDim</span></a></span><span> </span><span class="annot"><span class="annottext">(SBy ('ByIndex 1) -&gt; SSelectDim ('SelectDim ('ByIndex 1)))
-&gt; SBy ('ByIndex 1) -&gt; SSelectDim ('SelectDim ('ByIndex 1))
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">KnownNat 1 =&gt; SBy ('ByIndex 1)
forall (index :: Nat). KnownNat index =&gt; SBy ('ByIndex index)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SByIndex"><span class="hs-identifier hs-var">SByIndex</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">SShape shape
</span><a href="#local-6989586621679547465"><span class="hs-identifier hs-var">pmShape</span></a></span><span>
</span><span id="line-578"></span><span>  </span><span id="local-6989586621679547463"><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  layout
  device
  ('DataType 'Bool)
  ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim])
</span><a href="#local-6989586621679547463"><span class="hs-identifier hs-var">causalMask</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span>
</span><span id="line-579"></span><span>    </span><span class="annot"><span class="annottext">forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]).
(shape' ~ UnsqueezeF ('SelectDim ('ByIndex 0)) shape,
 SingI ('SelectDim ('ByIndex 0))) =&gt;
Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape'
forall (selectDim :: SelectDim (By Symbol Nat))
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]).
(shape' ~ UnsqueezeF selectDim shape, SingI selectDim) =&gt;
Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape'
</span><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#unsqueeze"><span class="hs-identifier hs-var">unsqueeze</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">0</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-580"></span><span>      </span><span class="annot"><span class="annottext">(Tensor
   ('Gradient 'WithoutGradient)
   layout
   device
   ('DataType 'Bool)
   ('Shape '[seqDim, seqDim])
 -&gt; Tensor
      ('Gradient 'WithoutGradient)
      layout
      device
      ('DataType 'Bool)
      ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim]))
-&gt; m (Tensor
        ('Gradient 'WithoutGradient)
        layout
        device
        ('DataType 'Bool)
        ('Shape '[seqDim, seqDim]))
-&gt; m (Tensor
        ('Gradient 'WithoutGradient)
        layout
        device
        ('DataType 'Bool)
        ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim]))
forall (f :: * -&gt; *) a b. Functor f =&gt; (a -&gt; b) -&gt; f a -&gt; f b
</span><span class="hs-operator hs-var">&lt;$&gt;</span></span><span> </span><span class="hs-special">(</span><span> </span><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  layout
  device
  transformerDataType
  ('Shape '[seqDim, seqDim])
-&gt; m (Tensor
        ('Gradient 'WithoutGradient)
        layout
        device
        ('DataType 'Bool)
        ('Shape '[seqDim, seqDim]))
forall (m :: * -&gt; *) (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
MonadThrow m =&gt;
Tensor gradient layout device dataType shape
-&gt; m (Tensor
        ('Gradient 'WithoutGradient) layout device ('DataType 'Bool) shape)
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#bool"><span class="hs-identifier hs-var">bool</span></a></span><span>
</span><span id="line-581"></span><span>              </span><span class="annot"><span class="annottext">(Tensor
   ('Gradient 'WithoutGradient)
   layout
   device
   transformerDataType
   ('Shape '[seqDim, seqDim])
 -&gt; m (Tensor
         ('Gradient 'WithoutGradient)
         layout
         device
         ('DataType 'Bool)
         ('Shape '[seqDim, seqDim])))
-&gt; (TensorSpec
      ('Gradient 'WithoutGradient)
      layout
      device
      transformerDataType
      ('Shape '[seqDim, seqDim])
    -&gt; Tensor
         ('Gradient 'WithoutGradient)
         layout
         device
         transformerDataType
         ('Shape '[seqDim, seqDim]))
-&gt; TensorSpec
     ('Gradient 'WithoutGradient)
     layout
     device
     transformerDataType
     ('Shape '[seqDim, seqDim])
-&gt; m (Tensor
        ('Gradient 'WithoutGradient)
        layout
        device
        ('DataType 'Bool)
        ('Shape '[seqDim, seqDim]))
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">Int
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     layout
     device
     transformerDataType
     ('Shape '[seqDim, seqDim])
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     layout
     device
     transformerDataType
     ('Shape '[seqDim, seqDim])
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
Int
-&gt; Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.Other.html#triu"><span class="hs-identifier hs-var">triu</span></a></span><span> </span><span class="annot"><span class="annottext">Int
</span><span class="hs-number">1</span></span><span>
</span><span id="line-582"></span><span>              </span><span class="annot"><span class="annottext">(Tensor
   ('Gradient 'WithoutGradient)
   layout
   device
   transformerDataType
   ('Shape '[seqDim, seqDim])
 -&gt; Tensor
      ('Gradient 'WithoutGradient)
      layout
      device
      transformerDataType
      ('Shape '[seqDim, seqDim]))
-&gt; (TensorSpec
      ('Gradient 'WithoutGradient)
      layout
      device
      transformerDataType
      ('Shape '[seqDim, seqDim])
    -&gt; Tensor
         ('Gradient 'WithoutGradient)
         layout
         device
         transformerDataType
         ('Shape '[seqDim, seqDim]))
-&gt; TensorSpec
     ('Gradient 'WithoutGradient)
     layout
     device
     transformerDataType
     ('Shape '[seqDim, seqDim])
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     layout
     device
     transformerDataType
     ('Shape '[seqDim, seqDim])
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="annot"><span class="annottext">TensorSpec
  ('Gradient 'WithoutGradient)
  layout
  device
  transformerDataType
  ('Shape '[seqDim, seqDim])
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     layout
     device
     transformerDataType
     ('Shape '[seqDim, seqDim])
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
TensorSpec gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.Creation.html#sOnes"><span class="hs-identifier hs-var">sOnes</span></a></span><span>
</span><span id="line-583"></span><span>              </span><span class="annot"><span class="annottext">(TensorSpec
   ('Gradient 'WithoutGradient)
   layout
   device
   transformerDataType
   ('Shape '[seqDim, seqDim])
 -&gt; m (Tensor
         ('Gradient 'WithoutGradient)
         layout
         device
         ('DataType 'Bool)
         ('Shape '[seqDim, seqDim])))
-&gt; TensorSpec
     ('Gradient 'WithoutGradient)
     layout
     device
     transformerDataType
     ('Shape '[seqDim, seqDim])
-&gt; m (Tensor
        ('Gradient 'WithoutGradient)
        layout
        device
        ('DataType 'Bool)
        ('Shape '[seqDim, seqDim]))
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SGradient ('Gradient 'WithoutGradient)
-&gt; SLayout layout
-&gt; SDevice device
-&gt; SDataType transformerDataType
-&gt; SShape ('Shape '[seqDim, seqDim])
-&gt; TensorSpec
     ('Gradient 'WithoutGradient)
     layout
     device
     transformerDataType
     ('Shape '[seqDim, seqDim])
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SShape shape
-&gt; TensorSpec gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorSpec"><span class="hs-identifier hs-var">TensorSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SRequiresGradient 'WithoutGradient
-&gt; SGradient ('Gradient 'WithoutGradient)
forall (requiresGradient :: RequiresGradient).
SRequiresGradient requiresGradient
-&gt; SGradient ('Gradient requiresGradient)
</span><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier hs-var">SGradient</span></a></span><span> </span><span class="annot"><span class="annottext">SRequiresGradient 'WithoutGradient
</span><a href="Torch.GraduallyTyped.RequiresGradient.html#SWithoutGradient"><span class="hs-identifier hs-var">SWithoutGradient</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">SLayout layout
</span><a href="#local-6989586621679547467"><span class="hs-identifier hs-var">pmLayout</span></a></span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679547466"><span class="hs-identifier hs-var">pmDevice</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType transformerDataType
</span><a href="#local-6989586621679547470"><span class="hs-identifier hs-var">transformerDataType</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SList '[seqDim, seqDim] -&gt; SShape ('Shape '[seqDim, seqDim])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList '[seqDim, seqDim] -&gt; SShape ('Shape '[seqDim, seqDim]))
-&gt; SList '[seqDim, seqDim] -&gt; SShape ('Shape '[seqDim, seqDim])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">Sing seqDim
SDim seqDim
</span><a href="#local-6989586621679547464"><span class="hs-identifier hs-var">pmSeqDim</span></a></span><span> </span><span class="annot"><span class="annottext">Sing seqDim -&gt; SList '[seqDim] -&gt; SList '[seqDim, seqDim]
forall a1 (a2 :: a1) (as :: [a1]).
Sing a2 -&gt; SList as -&gt; SList (a2 : as)
</span><a href="Torch.GraduallyTyped.Prelude.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">Sing seqDim
SDim seqDim
</span><a href="#local-6989586621679547464"><span class="hs-identifier hs-var">pmSeqDim</span></a></span><span> </span><span class="annot"><span class="annottext">Sing seqDim -&gt; SList '[] -&gt; SList '[seqDim]
forall a1 (a2 :: a1) (as :: [a1]).
Sing a2 -&gt; SList as -&gt; SList (a2 : as)
</span><a href="Torch.GraduallyTyped.Prelude.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-584"></span><span>          </span><span class="hs-special">)</span><span>
</span><span id="line-585"></span><span>  </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679547462"><span class="annot"><span class="annottext">emptyMask :: Tensor
  ('Gradient 'WithoutGradient)
  layout
  device
  transformerDataType
  ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim])
</span><a href="#local-6989586621679547462"><span class="hs-identifier hs-var hs-var">emptyMask</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">TensorSpec
  ('Gradient 'WithoutGradient)
  layout
  device
  transformerDataType
  ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim])
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     layout
     device
     transformerDataType
     ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim])
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
TensorSpec gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.Creation.html#sZeros"><span class="hs-identifier hs-var">sZeros</span></a></span><span> </span><span class="annot"><span class="annottext">(TensorSpec
   ('Gradient 'WithoutGradient)
   layout
   device
   transformerDataType
   ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim])
 -&gt; Tensor
      ('Gradient 'WithoutGradient)
      layout
      device
      transformerDataType
      ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim]))
-&gt; TensorSpec
     ('Gradient 'WithoutGradient)
     layout
     device
     transformerDataType
     ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim])
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     layout
     device
     transformerDataType
     ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SGradient ('Gradient 'WithoutGradient)
-&gt; SLayout layout
-&gt; SDevice device
-&gt; SDataType transformerDataType
-&gt; SShape ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim])
-&gt; TensorSpec
     ('Gradient 'WithoutGradient)
     layout
     device
     transformerDataType
     ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim])
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SShape shape
-&gt; TensorSpec gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorSpec"><span class="hs-identifier hs-var">TensorSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SRequiresGradient 'WithoutGradient
-&gt; SGradient ('Gradient 'WithoutGradient)
forall (requiresGradient :: RequiresGradient).
SRequiresGradient requiresGradient
-&gt; SGradient ('Gradient requiresGradient)
</span><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier hs-var">SGradient</span></a></span><span> </span><span class="annot"><span class="annottext">SRequiresGradient 'WithoutGradient
</span><a href="Torch.GraduallyTyped.RequiresGradient.html#SWithoutGradient"><span class="hs-identifier hs-var">SWithoutGradient</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">SLayout layout
</span><a href="#local-6989586621679547467"><span class="hs-identifier hs-var">pmLayout</span></a></span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679547466"><span class="hs-identifier hs-var">pmDevice</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType transformerDataType
</span><a href="#local-6989586621679547470"><span class="hs-identifier hs-var">transformerDataType</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SList '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim]
-&gt; SShape ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim]
 -&gt; SShape ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim]))
-&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim]
-&gt; SShape ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize ('Size 1) -&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 1))
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownNat 1 =&gt; SSize ('Size 1)
forall (size :: Nat). KnownNat size =&gt; SSize ('Size size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier hs-var">SSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">1</span></span><span> </span><span class="annot"><span class="annottext">Sing ('Dim ('Name &quot;*&quot;) ('Size 1))
-&gt; SList '[seqDim, seqDim]
-&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim]
forall a1 (a2 :: a1) (as :: [a1]).
Sing a2 -&gt; SList as -&gt; SList (a2 : as)
</span><a href="Torch.GraduallyTyped.Prelude.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">Sing seqDim
SDim seqDim
</span><a href="#local-6989586621679547464"><span class="hs-identifier hs-var">pmSeqDim</span></a></span><span> </span><span class="annot"><span class="annottext">Sing seqDim -&gt; SList '[seqDim] -&gt; SList '[seqDim, seqDim]
forall a1 (a2 :: a1) (as :: [a1]).
Sing a2 -&gt; SList as -&gt; SList (a2 : as)
</span><a href="Torch.GraduallyTyped.Prelude.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">Sing seqDim
SDim seqDim
</span><a href="#local-6989586621679547464"><span class="hs-identifier hs-var">pmSeqDim</span></a></span><span> </span><span class="annot"><span class="annottext">Sing seqDim -&gt; SList '[] -&gt; SList '[seqDim]
forall a1 (a2 :: a1) (as :: [a1]).
Sing a2 -&gt; SList as -&gt; SList (a2 : as)
</span><a href="Torch.GraduallyTyped.Prelude.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-586"></span><span>      </span><span id="local-6989586621679547461"><span class="annot"><span class="annottext">booleanMask :: Tensor
  ('Gradient 'WithoutGradient)
  (layout &lt;+&gt; layout)
  (device &lt;+&gt; device)
  ('DataType 'Bool)
  (BroadcastShapesF
     ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim])
     (UnsqueezeF ('SelectDim ('ByIndex 1)) shape))
</span><a href="#local-6989586621679547461"><span class="hs-identifier hs-var hs-var">booleanMask</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  layout
  device
  ('DataType 'Bool)
  ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim])
</span><a href="#local-6989586621679547463"><span class="hs-identifier hs-var">causalMask</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  layout
  device
  ('DataType 'Bool)
  ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim])
-&gt; Tensor
     gradient
     layout
     device
     dataType
     (UnsqueezeF ('SelectDim ('ByIndex 1)) shape)
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     (layout &lt;+&gt; layout)
     (device &lt;+&gt; device)
     ('DataType 'Bool)
     (BroadcastShapesF
        ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim])
        (UnsqueezeF ('SelectDim ('ByIndex 1)) shape))
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (gradient' :: Gradient RequiresGradient)
       (layout' :: Layout LayoutType) (device' :: Device (DeviceType Nat))
       (dataType' :: DataType DType)
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]).
Tensor gradient layout device dataType shape
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     (layout &lt;+&gt; layout')
     (device &lt;+&gt; device')
     ('DataType 'Bool)
     (BroadcastShapesF shape shape')
</span><a href="Torch.GraduallyTyped.Tensor.MathOperations.Pointwise.html#logicalOr"><span class="hs-operator hs-var">`logicalOr`</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
-&gt; Tensor
     gradient
     layout
     device
     dataType
     (UnsqueezeF ('SelectDim ('ByIndex 1)) shape)
forall (selectDim :: SelectDim (By Symbol Nat))
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]).
(shape' ~ UnsqueezeF selectDim shape, SingI selectDim) =&gt;
Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape'
</span><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#unsqueeze"><span class="hs-identifier hs-var">unsqueeze</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679547468"><span class="hs-identifier hs-var">paddingMask</span></a></span><span>
</span><span id="line-587"></span><span>  </span><span class="annot"><span class="annottext">output -&gt; m output
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">(output -&gt; m output) -&gt; output -&gt; m output
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span>
</span><span id="line-588"></span><span>    </span><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  layout
  device
  ('DataType 'Bool)
  (BroadcastShapesF
     ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim])
     (UnsqueezeF ('SelectDim ('ByIndex 1)) shape))
-&gt; Double
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     layout
     device
     transformerDataType
     ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim])
-&gt; Tensor
     (Seq
        ('Gradient 'WithoutGradient &lt;+&gt; 'Gradient 'WithoutGradient)
        ('Gradient 'WithoutGradient))
     (layout &lt;+&gt; (layout &lt;+&gt; 'Layout 'Dense))
     (device &lt;+&gt; device)
     (Seq ('DataType 'Bool &lt;+&gt; 'DataType 'Bool) transformerDataType)
     (BroadcastShapesF
        (BroadcastShapesF
           ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim])
           (UnsqueezeF ('SelectDim ('ByIndex 1)) shape))
        ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim]))
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]) value
       (gradient' :: Gradient RequiresGradient)
       (layout' :: Layout LayoutType) (device' :: Device (DeviceType Nat))
       (dataType' :: DataType DType)
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]).
Scalar value =&gt;
Tensor gradient layout device dataType shape
-&gt; value
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; Tensor
     (Seq (gradient &lt;+&gt; 'Gradient 'WithoutGradient) gradient')
     (layout &lt;+&gt; (layout' &lt;+&gt; 'Layout 'Dense))
     (device &lt;+&gt; device')
     (Seq (dataType &lt;+&gt; 'DataType 'Bool) dataType')
     (BroadcastShapesF shape shape')
</span><a href="Torch.GraduallyTyped.Tensor.Other.html#maskedFill"><span class="hs-identifier hs-var">maskedFill</span></a></span><span>
</span><span id="line-589"></span><span>      </span><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  layout
  device
  ('DataType 'Bool)
  (BroadcastShapesF
     ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim])
     (UnsqueezeF ('SelectDim ('ByIndex 1)) shape))
Tensor
  ('Gradient 'WithoutGradient)
  (layout &lt;+&gt; layout)
  (device &lt;+&gt; device)
  ('DataType 'Bool)
  (BroadcastShapesF
     ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim])
     (UnsqueezeF ('SelectDim ('ByIndex 1)) shape))
</span><a href="#local-6989586621679547461"><span class="hs-identifier hs-var">booleanMask</span></a></span><span>
</span><span id="line-590"></span><span>      </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679547469"><span class="hs-identifier hs-var">attentionMaskBias</span></a></span><span>
</span><span id="line-591"></span><span>      </span><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  layout
  device
  transformerDataType
  ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), seqDim, seqDim])
</span><a href="#local-6989586621679547462"><span class="hs-identifier hs-var">emptyMask</span></a></span><span>
</span><span id="line-592"></span><span>
</span><span id="line-593"></span><span class="hs-keyword">data</span><span> </span><span id="MkTransformerDecoderAttentionMask"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerDecoderAttentionMask"><span class="hs-identifier hs-var">MkTransformerDecoderAttentionMask</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679547460"><span class="annot"><a href="#local-6989586621679547460"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier hs-type">DType</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-594"></span><span>  </span><span id="MkTransformerDecoderAttentionMask"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerDecoderAttentionMask"><span class="hs-identifier hs-var">MkTransformerDecoderAttentionMask</span></a></span></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-595"></span><span>    </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679547973"><span class="annot"><a href="#local-6989586621679547973"><span class="hs-identifier hs-type">dataType</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-596"></span><span>    </span><span class="hs-special">{</span><span> </span><span id="decoderAttentionMaskDataType"><span class="annot"><span class="annottext">MkTransformerDecoderAttentionMask dataType -&gt; SDataType dataType
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#decoderAttentionMaskDataType"><span class="hs-identifier hs-var hs-var">decoderAttentionMaskDataType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier hs-type">SDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547973"><span class="hs-identifier hs-type">dataType</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-597"></span><span>      </span><span id="decoderAttentionMaskBias"><span class="annot"><span class="annottext">MkTransformerDecoderAttentionMask dataType -&gt; Double
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#decoderAttentionMaskBias"><span class="hs-identifier hs-var hs-var">decoderAttentionMaskBias</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span>
</span><span id="line-598"></span><span>    </span><span class="hs-special">}</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-599"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerDecoderAttentionMask"><span class="hs-identifier hs-type">MkTransformerDecoderAttentionMask</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547973"><span class="hs-identifier hs-type">dataType</span></a></span><span>
</span><span id="line-600"></span><span>
</span><span id="line-601"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">instance</span><span>
</span><span id="line-602"></span><span>  </span><span id="ModelSpec"><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier hs-var">ModelSpec</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerDecoderAttentionMask"><span class="hs-identifier hs-type">MkTransformerDecoderAttentionMask</span></a></span><span> </span><span id="local-6989586621679547456"><span class="annot"><a href="#local-6989586621679547456"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-603"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerDecoderAttentionMask"><span class="hs-identifier hs-type">MkTransformerDecoderAttentionMask</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547456"><span class="hs-identifier hs-type">dataType</span></a></span><span>
</span><span id="line-604"></span><span>
</span><span id="line-605"></span><span id="local-6989586621679547454"><span id="local-6989586621679547455"><span class="hs-keyword">instance</span><span>
</span><span id="line-606"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span>
</span><span id="line-607"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerDecoderAttentionMask"><span class="hs-identifier hs-type">MkTransformerDecoderAttentionMask</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547455"><span class="hs-identifier hs-type">dataType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-608"></span><span>    </span><span class="annot"><a href="#local-6989586621679547454"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-609"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerDecoderAttentionMask"><span class="hs-identifier hs-type">MkTransformerDecoderAttentionMask</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547455"><span class="hs-identifier hs-type">dataType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-610"></span><span>    </span><span class="annot"><a href="#local-6989586621679547454"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-611"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-612"></span><span>  </span><span id="local-6989586621679547452"><span class="annot"><span class="annottext">initialize :: ModelSpec (MkTransformerDecoderAttentionMask dataType)
-&gt; Generator generatorDevice
-&gt; m (MkTransformerDecoderAttentionMask dataType,
      Generator generatorDevice)
</span><a href="#local-6989586621679547452"><span class="hs-identifier hs-var hs-var hs-var hs-var">initialize</span></a></span></span><span> </span><span id="local-6989586621679547451"><span class="annot"><span class="annottext">ModelSpec (MkTransformerDecoderAttentionMask dataType)
</span><a href="#local-6989586621679547451"><span class="hs-identifier hs-var">spec</span></a></span></span><span> </span><span id="local-6989586621679547450"><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679547450"><span class="hs-identifier hs-var">g</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(MkTransformerDecoderAttentionMask dataType,
 Generator generatorDevice)
-&gt; m (MkTransformerDecoderAttentionMask dataType,
      Generator generatorDevice)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">ModelSpec (MkTransformerDecoderAttentionMask dataType)
MkTransformerDecoderAttentionMask dataType
</span><a href="#local-6989586621679547451"><span class="hs-identifier hs-var">spec</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679547450"><span class="hs-identifier hs-var">g</span></a></span><span class="hs-special">)</span></span></span><span>
</span><span id="line-613"></span><span>
</span><span id="line-614"></span><span id="local-6989586621679547449"><span class="hs-keyword">instance</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasStateDict"><span class="hs-identifier hs-type">HasStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerDecoderAttentionMask"><span class="hs-identifier hs-type">MkTransformerDecoderAttentionMask</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547449"><span class="hs-identifier hs-type">dataType</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-615"></span><span>  </span><span id="local-6989586621679547446"><span class="annot"><span class="annottext">fromStateDict :: ModelSpec (MkTransformerDecoderAttentionMask dataType)
-&gt; StateDictKey -&gt; m (MkTransformerDecoderAttentionMask dataType)
</span><a href="#local-6989586621679547446"><span class="hs-identifier hs-var hs-var hs-var hs-var">fromStateDict</span></a></span></span><span> </span><span id="local-6989586621679547445"><span class="annot"><span class="annottext">ModelSpec (MkTransformerDecoderAttentionMask dataType)
</span><a href="#local-6989586621679547445"><span class="hs-identifier hs-var">spec</span></a></span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">MkTransformerDecoderAttentionMask dataType
-&gt; m (MkTransformerDecoderAttentionMask dataType)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">ModelSpec (MkTransformerDecoderAttentionMask dataType)
MkTransformerDecoderAttentionMask dataType
</span><a href="#local-6989586621679547445"><span class="hs-identifier hs-var">spec</span></a></span><span>
</span><span id="line-616"></span><span>  </span><span id="local-6989586621679547444"><span class="annot"><span class="annottext">toStateDict :: StateDictKey -&gt; MkTransformerDecoderAttentionMask dataType -&gt; m ()
</span><a href="#local-6989586621679547444"><span class="hs-identifier hs-var hs-var hs-var hs-var">toStateDict</span></a></span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="annottext">MkTransformerDecoderAttentionMask dataType
</span><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">() -&gt; m ()
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span></span><span>
</span><span id="line-617"></span><span>
</span><span id="line-618"></span><span id="local-6989586621679547435"><span id="local-6989586621679547436"><span id="local-6989586621679547437"><span id="local-6989586621679547438"><span id="local-6989586621679547439"><span id="local-6989586621679547440"><span id="local-6989586621679547441"><span id="local-6989586621679547442"><span id="local-6989586621679547443"><span class="hs-keyword">instance</span><span>
</span><span id="line-619"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerDecoderAttentionMaskC"><span class="hs-identifier hs-type">MkTransformerDecoderAttentionMaskC</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547443"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547442"><span class="hs-identifier hs-type">decoderInputLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547441"><span class="hs-identifier hs-type">decoderInputDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547440"><span class="hs-identifier hs-type">decoderInputShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547439"><span class="hs-identifier hs-type">seqDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547438"><span class="hs-identifier hs-type">output</span></a></span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-620"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-621"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerDecoderAttentionMask"><span class="hs-identifier hs-type">MkTransformerDecoderAttentionMask</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547443"><span class="hs-identifier hs-type">dataType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-622"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547437"><span class="hs-identifier hs-type">decoderInputGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547442"><span class="hs-identifier hs-type">decoderInputLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547441"><span class="hs-identifier hs-type">decoderInputDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547436"><span class="hs-identifier hs-type">decoderInputDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547440"><span class="hs-identifier hs-type">decoderInputShape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-623"></span><span>    </span><span class="annot"><a href="#local-6989586621679547435"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-624"></span><span>    </span><span class="annot"><a href="#local-6989586621679547438"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-625"></span><span>    </span><span class="annot"><a href="#local-6989586621679547435"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-626"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-627"></span><span>  </span><span id="local-6989586621679547433"><span class="annot"><span class="annottext">forward :: MkTransformerDecoderAttentionMask dataType
-&gt; Tensor
     decoderInputGradient
     decoderInputLayout
     decoderInputDevice
     decoderInputDataType
     decoderInputShape
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorDevice)
</span><a href="#local-6989586621679547433"><span class="hs-identifier hs-var hs-var hs-var hs-var">forward</span></a></span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerDecoderAttentionMask"><span class="hs-identifier hs-type">MkTransformerDecoderAttentionMask</span></a></span><span> </span><span class="hs-special">{</span><span id="local-6989586621679547431"><span id="local-6989586621679547432"><span class="annot"><span class="annottext">Double
SDataType dataType
decoderAttentionMaskBias :: Double
decoderAttentionMaskDataType :: SDataType dataType
decoderAttentionMaskBias :: forall (dataType :: DataType DType).
MkTransformerDecoderAttentionMask dataType -&gt; Double
decoderAttentionMaskDataType :: forall (dataType :: DataType DType).
MkTransformerDecoderAttentionMask dataType -&gt; SDataType dataType
</span><a href="#local-6989586621679547431"><span class="hs-glyph hs-var hs-var hs-var hs-var">..</span></a></span></span></span><span class="hs-special">}</span><span> </span><span id="local-6989586621679547430"><span class="annot"><span class="annottext">Tensor
  decoderInputGradient
  decoderInputLayout
  decoderInputDevice
  decoderInputDataType
  decoderInputShape
</span><a href="#local-6989586621679547430"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span id="local-6989586621679547429"><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679547429"><span class="hs-identifier hs-var">g</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-628"></span><span>    </span><span id="local-6989586621679547428"><span class="annot"><span class="annottext">output
</span><a href="#local-6989586621679547428"><span class="hs-identifier hs-var">decoderAttentionMask</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">SDataType dataType
-&gt; Double
-&gt; Tensor
     decoderInputGradient
     decoderInputLayout
     decoderInputDevice
     decoderInputDataType
     decoderInputShape
-&gt; m output
forall (m :: * -&gt; *) (transformerDataType :: DataType DType)
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (seqDim :: Dim (Name Symbol) (Size Nat)) output.
(MonadThrow m,
 MkTransformerDecoderAttentionMaskC
   transformerDataType layout device shape seqDim output) =&gt;
SDataType transformerDataType
-&gt; Double
-&gt; Tensor gradient layout device dataType shape
-&gt; m output
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#mkTransformerDecoderAttentionMask"><span class="hs-identifier hs-var">mkTransformerDecoderAttentionMask</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679547432"><span class="hs-identifier hs-var">decoderAttentionMaskDataType</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679547431"><span class="hs-identifier hs-var">decoderAttentionMaskBias</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  decoderInputGradient
  decoderInputLayout
  decoderInputDevice
  decoderInputDataType
  decoderInputShape
</span><a href="#local-6989586621679547430"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-629"></span><span>    </span><span class="annot"><span class="annottext">(output, Generator generatorDevice)
-&gt; m (output, Generator generatorDevice)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">output
</span><a href="#local-6989586621679547428"><span class="hs-identifier hs-var">decoderAttentionMask</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679547429"><span class="hs-identifier hs-var">g</span></a></span><span class="hs-special">)</span></span></span></span></span></span></span></span></span></span><span>
</span><span id="line-630"></span><span>
</span><span id="line-631"></span><span class="hs-keyword">type</span><span> </span><span id="MkTransformerCrossAttentionMaskC"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerCrossAttentionMaskC"><span class="hs-identifier hs-var">MkTransformerCrossAttentionMaskC</span></a></span></span><span> </span><span id="local-6989586621679547427"><span class="annot"><a href="#local-6989586621679547427"><span class="hs-identifier hs-type">transformerDataType</span></a></span></span><span> </span><span id="local-6989586621679547426"><span class="annot"><a href="#local-6989586621679547426"><span class="hs-identifier hs-type">decoderInputShape</span></a></span></span><span> </span><span id="local-6989586621679547425"><span class="annot"><a href="#local-6989586621679547425"><span class="hs-identifier hs-type">decoderInputSeqDim</span></a></span></span><span> </span><span id="local-6989586621679547424"><span class="annot"><a href="#local-6989586621679547424"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679547423"><span class="annot"><a href="#local-6989586621679547423"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679547422"><span class="annot"><a href="#local-6989586621679547422"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679547421"><span class="annot"><a href="#local-6989586621679547421"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679547420"><span class="annot"><a href="#local-6989586621679547420"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679547419"><span class="annot"><a href="#local-6989586621679547419"><span class="hs-identifier hs-type">seqDim</span></a></span></span><span> </span><span id="local-6989586621679547418"><span class="annot"><a href="#local-6989586621679547418"><span class="hs-identifier hs-type">output</span></a></span></span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-632"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetLayout"><span class="hs-identifier hs-type">SGetLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547423"><span class="hs-identifier hs-type">layout</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-633"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetDevice"><span class="hs-identifier hs-type">SGetDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547422"><span class="hs-identifier hs-type">device</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-634"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetShape"><span class="hs-identifier hs-type">SGetShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547420"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-635"></span><span>    </span><span class="annot"><a href="#local-6989586621679547419"><span class="hs-identifier hs-type">seqDim</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679547420"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#%21"><span class="hs-glyph hs-type">!</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-636"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetShape"><span class="hs-identifier hs-type">SGetShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547426"><span class="hs-identifier hs-type">decoderInputShape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-637"></span><span>    </span><span class="annot"><a href="#local-6989586621679547425"><span class="hs-identifier hs-type">decoderInputSeqDim</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679547426"><span class="hs-identifier hs-type">decoderInputShape</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#%21"><span class="hs-glyph hs-type">!</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-638"></span><span>    </span><span class="annot"><a href="#local-6989586621679547418"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-639"></span><span>      </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-640"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Seq"><span class="hs-identifier hs-type">Seq</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679547424"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#WithoutGradient"><span class="hs-identifier hs-type">WithoutGradient</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#WithoutGradient"><span class="hs-identifier hs-type">WithoutGradient</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-641"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679547423"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Layout"><span class="hs-identifier hs-type">Layout</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Layout.html#Dense"><span class="hs-identifier hs-type">Dense</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-642"></span><span>          </span><span class="annot"><a href="#local-6989586621679547422"><span class="hs-identifier hs-type">device</span></a></span><span>
</span><span id="line-643"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Prelude.html#Seq"><span class="hs-identifier hs-type">Seq</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679547421"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#Bool"><span class="hs-identifier hs-type">Bool</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679547427"><span class="hs-identifier hs-type">transformerDataType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-644"></span><span>          </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#BroadcastShapesF"><span class="hs-identifier hs-type">BroadcastShapesF</span></a></span><span>
</span><span id="line-645"></span><span>              </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#UnsqueezeF"><span class="hs-identifier hs-type">UnsqueezeF</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679547420"><span class="hs-identifier hs-type">shape</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-646"></span><span>              </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679547425"><span class="hs-identifier hs-type">decoderInputSeqDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679547419"><span class="hs-identifier hs-type">seqDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-647"></span><span>          </span><span class="hs-special">)</span><span>
</span><span id="line-648"></span><span>  </span><span class="hs-special">)</span><span>
</span><span id="line-649"></span><span>
</span><span id="line-650"></span><span class="hs-comment">-- | Creates a cross-attention mask for an encoder-decoder transformer.</span><span>
</span><span id="line-651"></span><span class="hs-comment">-- Given an encoder padding mask of shape @[batchDim, seqDim]@,</span><span>
</span><span id="line-652"></span><span class="hs-comment">-- and the shape @[batchDim, decoderSeqDim]@ of the decoder's input,</span><span>
</span><span id="line-653"></span><span class="hs-comment">-- returns a tensor of shape @[batchDim, decoderSeqDim, seqDim]@.</span><span>
</span><span id="line-654"></span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#mkTransformerCrossAttentionMask"><span class="hs-identifier hs-type">mkTransformerCrossAttentionMask</span></a></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-655"></span><span>  </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679547925"><span class="annot"><a href="#local-6989586621679547925"><span class="hs-identifier hs-type">m</span></a></span></span><span> </span><span id="local-6989586621679547924"><span class="annot"><a href="#local-6989586621679547924"><span class="hs-identifier hs-type">transformerDataType</span></a></span></span><span> </span><span id="local-6989586621679547923"><span class="annot"><a href="#local-6989586621679547923"><span class="hs-identifier hs-type">decoderInputShape</span></a></span></span><span> </span><span id="local-6989586621679547922"><span class="annot"><a href="#local-6989586621679547922"><span class="hs-identifier hs-type">decoderInputSeqDim</span></a></span></span><span> </span><span id="local-6989586621679547921"><span class="annot"><a href="#local-6989586621679547921"><span class="hs-identifier hs-type">gradient</span></a></span></span><span> </span><span id="local-6989586621679547920"><span class="annot"><a href="#local-6989586621679547920"><span class="hs-identifier hs-type">layout</span></a></span></span><span> </span><span id="local-6989586621679547919"><span class="annot"><a href="#local-6989586621679547919"><span class="hs-identifier hs-type">device</span></a></span></span><span> </span><span id="local-6989586621679547918"><span class="annot"><a href="#local-6989586621679547918"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span id="local-6989586621679547917"><span class="annot"><a href="#local-6989586621679547917"><span class="hs-identifier hs-type">shape</span></a></span></span><span> </span><span id="local-6989586621679547916"><span class="annot"><a href="#local-6989586621679547916"><span class="hs-identifier hs-type">seqDim</span></a></span></span><span> </span><span id="local-6989586621679547915"><span class="annot"><a href="#local-6989586621679547915"><span class="hs-identifier hs-type">output</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-656"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="../file:///nix/store/ifacyhfpnb9wrd20q18ymi87z39k1h67-exceptions-lib-exceptions-0.10.4-haddock-doc/share/doc/exceptions/html/src"><span class="hs-identifier hs-type">MonadThrow</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547925"><span class="hs-identifier hs-type">m</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-657"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerCrossAttentionMaskC"><span class="hs-identifier hs-type">MkTransformerCrossAttentionMaskC</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547924"><span class="hs-identifier hs-type">transformerDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547923"><span class="hs-identifier hs-type">decoderInputShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547922"><span class="hs-identifier hs-type">decoderInputSeqDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547921"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547920"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547919"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547918"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547917"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547916"><span class="hs-identifier hs-type">seqDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547915"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-658"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-659"></span><span>  </span><span class="hs-comment">-- | data type singleton of the transformer</span><span>
</span><span id="line-660"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier hs-type">SDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547924"><span class="hs-identifier hs-type">transformerDataType</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-661"></span><span>  </span><span class="hs-comment">-- | decoder input shape</span><span>
</span><span id="line-662"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-type">SShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547923"><span class="hs-identifier hs-type">decoderInputShape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-663"></span><span>  </span><span class="hs-comment">-- | attention mask bias (typically a large negative number)</span><span>
</span><span id="line-664"></span><span>  </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-665"></span><span>  </span><span class="hs-comment">-- | encoder padding mask</span><span>
</span><span id="line-666"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547921"><span class="hs-identifier hs-type">gradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547920"><span class="hs-identifier hs-type">layout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547919"><span class="hs-identifier hs-type">device</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547918"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547917"><span class="hs-identifier hs-type">shape</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-667"></span><span>  </span><span class="annot"><a href="#local-6989586621679547925"><span class="hs-identifier hs-type">m</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547915"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-668"></span><span id="mkTransformerCrossAttentionMask"><span class="annot"><span class="annottext">mkTransformerCrossAttentionMask :: SDataType transformerDataType
-&gt; SShape decoderInputShape
-&gt; Double
-&gt; Tensor gradient layout device dataType shape
-&gt; m output
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#mkTransformerCrossAttentionMask"><span class="hs-identifier hs-var hs-var">mkTransformerCrossAttentionMask</span></a></span></span><span> </span><span id="local-6989586621679547416"><span class="annot"><span class="annottext">SDataType transformerDataType
</span><a href="#local-6989586621679547416"><span class="hs-identifier hs-var">transformerDataType</span></a></span></span><span> </span><span id="local-6989586621679547415"><span class="annot"><span class="annottext">SShape decoderInputShape
</span><a href="#local-6989586621679547415"><span class="hs-identifier hs-var">decoderInputShape</span></a></span></span><span> </span><span id="local-6989586621679547414"><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679547414"><span class="hs-identifier hs-var">attentionMaskBias</span></a></span></span><span> </span><span id="local-6989586621679547413"><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679547413"><span class="hs-identifier hs-var">paddingMask</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-669"></span><span>  </span><span id="local-6989586621679547412"><span class="annot"><span class="annottext">SDim decoderInputSeqDim
</span><a href="#local-6989586621679547412"><span class="hs-identifier hs-var">decoderInputSeqDim</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">SSelectDim ('SelectDim ('ByIndex 1))
-&gt; SShape decoderInputShape -&gt; m (SDim decoderInputSeqDim)
forall (selectDim :: SelectDim (By Symbol Nat))
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (dim :: Dim (Name Symbol) (Size Nat)) (m :: * -&gt; *).
(dim ~ GetDimF selectDim shape, MonadThrow m) =&gt;
SSelectDim selectDim -&gt; SShape shape -&gt; m (SDim dim)
</span><a href="Torch.GraduallyTyped.Shape.Class.html#sGetDimFromShape"><span class="hs-identifier hs-var">sGetDimFromShape</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SBy ('ByIndex 1) -&gt; SSelectDim ('SelectDim ('ByIndex 1))
forall (by :: By Symbol Nat). SBy by -&gt; SSelectDim ('SelectDim by)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSelectDim"><span class="hs-identifier hs-var">SSelectDim</span></a></span><span> </span><span class="annot"><span class="annottext">(SBy ('ByIndex 1) -&gt; SSelectDim ('SelectDim ('ByIndex 1)))
-&gt; SBy ('ByIndex 1) -&gt; SSelectDim ('SelectDim ('ByIndex 1))
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">KnownNat 1 =&gt; SBy ('ByIndex 1)
forall (index :: Nat). KnownNat index =&gt; SBy ('ByIndex index)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SByIndex"><span class="hs-identifier hs-var">SByIndex</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">SShape decoderInputShape
</span><a href="#local-6989586621679547415"><span class="hs-identifier hs-var">decoderInputShape</span></a></span><span>
</span><span id="line-670"></span><span>  </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679547411"><span class="annot"><span class="annottext">pmLayout :: SLayout layout
</span><a href="#local-6989586621679547411"><span class="hs-identifier hs-var hs-var">pmLayout</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape -&gt; SLayout layout
forall (layout :: Layout LayoutType)
       (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SGetLayout layout =&gt;
Tensor gradient layout device dataType shape -&gt; SLayout layout
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sGetLayout"><span class="hs-identifier hs-var">sGetLayout</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679547413"><span class="hs-identifier hs-var">paddingMask</span></a></span><span>
</span><span id="line-671"></span><span>      </span><span id="local-6989586621679547410"><span class="annot"><span class="annottext">pmDevice :: SDevice device
</span><a href="#local-6989586621679547410"><span class="hs-identifier hs-var hs-var">pmDevice</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape -&gt; SDevice device
forall (device :: Device (DeviceType Nat))
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SGetDevice device =&gt;
Tensor gradient layout device dataType shape -&gt; SDevice device
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sGetDevice"><span class="hs-identifier hs-var">sGetDevice</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679547413"><span class="hs-identifier hs-var">paddingMask</span></a></span><span>
</span><span id="line-672"></span><span>      </span><span id="local-6989586621679547409"><span class="annot"><span class="annottext">pmShape :: SShape shape
</span><a href="#local-6989586621679547409"><span class="hs-identifier hs-var hs-var">pmShape</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape -&gt; SShape shape
forall (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType).
SGetShape shape =&gt;
Tensor gradient layout device dataType shape -&gt; SShape shape
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sGetShape"><span class="hs-identifier hs-var">sGetShape</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679547413"><span class="hs-identifier hs-var">paddingMask</span></a></span><span>
</span><span id="line-673"></span><span>  </span><span id="local-6989586621679547408"><span class="annot"><span class="annottext">SDim seqDim
</span><a href="#local-6989586621679547408"><span class="hs-identifier hs-var">pmSeqDim</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">SSelectDim ('SelectDim ('ByIndex 1))
-&gt; SShape shape -&gt; m (SDim seqDim)
forall (selectDim :: SelectDim (By Symbol Nat))
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (dim :: Dim (Name Symbol) (Size Nat)) (m :: * -&gt; *).
(dim ~ GetDimF selectDim shape, MonadThrow m) =&gt;
SSelectDim selectDim -&gt; SShape shape -&gt; m (SDim dim)
</span><a href="Torch.GraduallyTyped.Shape.Class.html#sGetDimFromShape"><span class="hs-identifier hs-var">sGetDimFromShape</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SBy ('ByIndex 1) -&gt; SSelectDim ('SelectDim ('ByIndex 1))
forall (by :: By Symbol Nat). SBy by -&gt; SSelectDim ('SelectDim by)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSelectDim"><span class="hs-identifier hs-var">SSelectDim</span></a></span><span> </span><span class="annot"><span class="annottext">(SBy ('ByIndex 1) -&gt; SSelectDim ('SelectDim ('ByIndex 1)))
-&gt; SBy ('ByIndex 1) -&gt; SSelectDim ('SelectDim ('ByIndex 1))
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">KnownNat 1 =&gt; SBy ('ByIndex 1)
forall (index :: Nat). KnownNat index =&gt; SBy ('ByIndex index)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SByIndex"><span class="hs-identifier hs-var">SByIndex</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">SShape shape
</span><a href="#local-6989586621679547409"><span class="hs-identifier hs-var">pmShape</span></a></span><span>
</span><span id="line-674"></span><span>  </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679547407"><span class="annot"><span class="annottext">emptyMask :: Tensor
  ('Gradient 'WithoutGradient)
  layout
  device
  transformerDataType
  ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), decoderInputSeqDim, seqDim])
</span><a href="#local-6989586621679547407"><span class="hs-identifier hs-var hs-var">emptyMask</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">TensorSpec
  ('Gradient 'WithoutGradient)
  layout
  device
  transformerDataType
  ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), decoderInputSeqDim, seqDim])
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     layout
     device
     transformerDataType
     ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), decoderInputSeqDim, seqDim])
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
TensorSpec gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.Creation.html#sZeros"><span class="hs-identifier hs-var">sZeros</span></a></span><span> </span><span class="annot"><span class="annottext">(TensorSpec
   ('Gradient 'WithoutGradient)
   layout
   device
   transformerDataType
   ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), decoderInputSeqDim, seqDim])
 -&gt; Tensor
      ('Gradient 'WithoutGradient)
      layout
      device
      transformerDataType
      ('Shape
         '[ 'Dim ('Name &quot;*&quot;) ('Size 1), decoderInputSeqDim, seqDim]))
-&gt; TensorSpec
     ('Gradient 'WithoutGradient)
     layout
     device
     transformerDataType
     ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), decoderInputSeqDim, seqDim])
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     layout
     device
     transformerDataType
     ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), decoderInputSeqDim, seqDim])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">SGradient ('Gradient 'WithoutGradient)
-&gt; SLayout layout
-&gt; SDevice device
-&gt; SDataType transformerDataType
-&gt; SShape
     ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), decoderInputSeqDim, seqDim])
-&gt; TensorSpec
     ('Gradient 'WithoutGradient)
     layout
     device
     transformerDataType
     ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), decoderInputSeqDim, seqDim])
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SShape shape
-&gt; TensorSpec gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorSpec"><span class="hs-identifier hs-var">TensorSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SRequiresGradient 'WithoutGradient
-&gt; SGradient ('Gradient 'WithoutGradient)
forall (requiresGradient :: RequiresGradient).
SRequiresGradient requiresGradient
-&gt; SGradient ('Gradient requiresGradient)
</span><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier hs-var">SGradient</span></a></span><span> </span><span class="annot"><span class="annottext">SRequiresGradient 'WithoutGradient
</span><a href="Torch.GraduallyTyped.RequiresGradient.html#SWithoutGradient"><span class="hs-identifier hs-var">SWithoutGradient</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">SLayout layout
</span><a href="#local-6989586621679547411"><span class="hs-identifier hs-var">pmLayout</span></a></span><span> </span><span class="annot"><span class="annottext">SDevice device
</span><a href="#local-6989586621679547410"><span class="hs-identifier hs-var">pmDevice</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType transformerDataType
</span><a href="#local-6989586621679547416"><span class="hs-identifier hs-var">transformerDataType</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SList '[ 'Dim ('Name &quot;*&quot;) ('Size 1), decoderInputSeqDim, seqDim]
-&gt; SShape
     ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), decoderInputSeqDim, seqDim])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList '[ 'Dim ('Name &quot;*&quot;) ('Size 1), decoderInputSeqDim, seqDim]
 -&gt; SShape
      ('Shape
         '[ 'Dim ('Name &quot;*&quot;) ('Size 1), decoderInputSeqDim, seqDim]))
-&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 1), decoderInputSeqDim, seqDim]
-&gt; SShape
     ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), decoderInputSeqDim, seqDim])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize ('Size 1) -&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 1))
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownNat 1 =&gt; SSize ('Size 1)
forall (size :: Nat). KnownNat size =&gt; SSize ('Size size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier hs-var">SSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">1</span></span><span> </span><span class="annot"><span class="annottext">Sing ('Dim ('Name &quot;*&quot;) ('Size 1))
-&gt; SList '[decoderInputSeqDim, seqDim]
-&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 1), decoderInputSeqDim, seqDim]
forall a1 (a2 :: a1) (as :: [a1]).
Sing a2 -&gt; SList as -&gt; SList (a2 : as)
</span><a href="Torch.GraduallyTyped.Prelude.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">Sing decoderInputSeqDim
SDim decoderInputSeqDim
</span><a href="#local-6989586621679547412"><span class="hs-identifier hs-var">decoderInputSeqDim</span></a></span><span> </span><span class="annot"><span class="annottext">Sing decoderInputSeqDim
-&gt; SList '[seqDim] -&gt; SList '[decoderInputSeqDim, seqDim]
forall a1 (a2 :: a1) (as :: [a1]).
Sing a2 -&gt; SList as -&gt; SList (a2 : as)
</span><a href="Torch.GraduallyTyped.Prelude.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">Sing seqDim
SDim seqDim
</span><a href="#local-6989586621679547408"><span class="hs-identifier hs-var">pmSeqDim</span></a></span><span> </span><span class="annot"><span class="annottext">Sing seqDim -&gt; SList '[] -&gt; SList '[seqDim]
forall a1 (a2 :: a1) (as :: [a1]).
Sing a2 -&gt; SList as -&gt; SList (a2 : as)
</span><a href="Torch.GraduallyTyped.Prelude.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-675"></span><span>  </span><span class="annot"><span class="annottext">output -&gt; m output
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">(output -&gt; m output) -&gt; output -&gt; m output
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">Tensor
  gradient
  layout
  device
  dataType
  (UnsqueezeF ('SelectDim ('ByIndex 1)) shape)
-&gt; Double
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     layout
     device
     transformerDataType
     ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), decoderInputSeqDim, seqDim])
-&gt; Tensor
     (Seq
        (gradient &lt;+&gt; 'Gradient 'WithoutGradient)
        ('Gradient 'WithoutGradient))
     (layout &lt;+&gt; (layout &lt;+&gt; 'Layout 'Dense))
     (device &lt;+&gt; device)
     (Seq (dataType &lt;+&gt; 'DataType 'Bool) transformerDataType)
     (BroadcastShapesF
        (UnsqueezeF ('SelectDim ('ByIndex 1)) shape)
        ('Shape
           '[ 'Dim ('Name &quot;*&quot;) ('Size 1), decoderInputSeqDim, seqDim]))
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]) value
       (gradient' :: Gradient RequiresGradient)
       (layout' :: Layout LayoutType) (device' :: Device (DeviceType Nat))
       (dataType' :: DataType DType)
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]).
Scalar value =&gt;
Tensor gradient layout device dataType shape
-&gt; value
-&gt; Tensor gradient' layout' device' dataType' shape'
-&gt; Tensor
     (Seq (gradient &lt;+&gt; 'Gradient 'WithoutGradient) gradient')
     (layout &lt;+&gt; (layout' &lt;+&gt; 'Layout 'Dense))
     (device &lt;+&gt; device')
     (Seq (dataType &lt;+&gt; 'DataType 'Bool) dataType')
     (BroadcastShapesF shape shape')
</span><a href="Torch.GraduallyTyped.Tensor.Other.html#maskedFill"><span class="hs-identifier hs-var">maskedFill</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
-&gt; Tensor
     gradient
     layout
     device
     dataType
     (UnsqueezeF ('SelectDim ('ByIndex 1)) shape)
forall (selectDim :: SelectDim (By Symbol Nat))
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (shape' :: Shape [Dim (Name Symbol) (Size Nat)]).
(shape' ~ UnsqueezeF selectDim shape, SingI selectDim) =&gt;
Tensor gradient layout device dataType shape
-&gt; Tensor gradient layout device dataType shape'
</span><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#unsqueeze"><span class="hs-identifier hs-var">unsqueeze</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Tensor gradient layout device dataType shape
</span><a href="#local-6989586621679547413"><span class="hs-identifier hs-var">paddingMask</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679547414"><span class="hs-identifier hs-var">attentionMaskBias</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  layout
  device
  transformerDataType
  ('Shape '[ 'Dim ('Name &quot;*&quot;) ('Size 1), decoderInputSeqDim, seqDim])
</span><a href="#local-6989586621679547407"><span class="hs-identifier hs-var">emptyMask</span></a></span><span>
</span><span id="line-676"></span><span>
</span><span id="line-677"></span><span class="hs-keyword">data</span><span> </span><span id="MkTransformerCrossAttentionMask"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerCrossAttentionMask"><span class="hs-identifier hs-var">MkTransformerCrossAttentionMask</span></a></span></span><span> </span><span class="hs-special">(</span><span id="local-6989586621679547406"><span class="annot"><a href="#local-6989586621679547406"><span class="hs-identifier hs-type">dataType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DataType"><span class="hs-identifier hs-type">DataType</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#DType"><span class="hs-identifier hs-type">DType</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-678"></span><span>  </span><span id="MkTransformerCrossAttentionMask"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerCrossAttentionMask"><span class="hs-identifier hs-var">MkTransformerCrossAttentionMask</span></a></span></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-679"></span><span>    </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679547926"><span class="annot"><a href="#local-6989586621679547926"><span class="hs-identifier hs-type">dataType</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-680"></span><span>    </span><span class="hs-special">{</span><span> </span><span id="crossAttentionMaskDataType"><span class="annot"><span class="annottext">MkTransformerCrossAttentionMask dataType -&gt; SDataType dataType
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#crossAttentionMaskDataType"><span class="hs-identifier hs-var hs-var">crossAttentionMaskDataType</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.DType.html#SDataType"><span class="hs-identifier hs-type">SDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547926"><span class="hs-identifier hs-type">dataType</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-681"></span><span>      </span><span id="crossAttentionMaskBias"><span class="annot"><span class="annottext">MkTransformerCrossAttentionMask dataType -&gt; Double
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#crossAttentionMaskBias"><span class="hs-identifier hs-var hs-var">crossAttentionMaskBias</span></a></span></span><span> </span><span class="hs-glyph">::</span><span> </span><span class="annot"><span class="hs-identifier hs-type">Double</span></span><span>
</span><span id="line-682"></span><span>    </span><span class="hs-special">}</span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-683"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerCrossAttentionMask"><span class="hs-identifier hs-type">MkTransformerCrossAttentionMask</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547926"><span class="hs-identifier hs-type">dataType</span></a></span><span>
</span><span id="line-684"></span><span>
</span><span id="line-685"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">instance</span><span>
</span><span id="line-686"></span><span>  </span><span id="ModelSpec"><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier hs-var">ModelSpec</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerCrossAttentionMask"><span class="hs-identifier hs-type">MkTransformerCrossAttentionMask</span></a></span><span> </span><span id="local-6989586621679547402"><span class="annot"><a href="#local-6989586621679547402"><span class="hs-identifier hs-type hs-type">dataType</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span>
</span><span id="line-687"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerCrossAttentionMask"><span class="hs-identifier hs-type">MkTransformerCrossAttentionMask</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547402"><span class="hs-identifier hs-type">dataType</span></a></span><span>
</span><span id="line-688"></span><span>
</span><span id="line-689"></span><span id="local-6989586621679547400"><span id="local-6989586621679547401"><span class="hs-keyword">instance</span><span>
</span><span id="line-690"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span>
</span><span id="line-691"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerCrossAttentionMask"><span class="hs-identifier hs-type">MkTransformerCrossAttentionMask</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547401"><span class="hs-identifier hs-type">dataType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-692"></span><span>    </span><span class="annot"><a href="#local-6989586621679547400"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-693"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerCrossAttentionMask"><span class="hs-identifier hs-type">MkTransformerCrossAttentionMask</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547401"><span class="hs-identifier hs-type">dataType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-694"></span><span>    </span><span class="annot"><a href="#local-6989586621679547400"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-695"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-696"></span><span>  </span><span id="local-6989586621679547398"><span class="annot"><span class="annottext">initialize :: ModelSpec (MkTransformerCrossAttentionMask dataType)
-&gt; Generator generatorDevice
-&gt; m (MkTransformerCrossAttentionMask dataType,
      Generator generatorDevice)
</span><a href="#local-6989586621679547398"><span class="hs-identifier hs-var hs-var hs-var hs-var">initialize</span></a></span></span><span> </span><span id="local-6989586621679547397"><span class="annot"><span class="annottext">ModelSpec (MkTransformerCrossAttentionMask dataType)
</span><a href="#local-6989586621679547397"><span class="hs-identifier hs-var">spec</span></a></span></span><span> </span><span id="local-6989586621679547396"><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679547396"><span class="hs-identifier hs-var">g</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(MkTransformerCrossAttentionMask dataType,
 Generator generatorDevice)
-&gt; m (MkTransformerCrossAttentionMask dataType,
      Generator generatorDevice)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">ModelSpec (MkTransformerCrossAttentionMask dataType)
MkTransformerCrossAttentionMask dataType
</span><a href="#local-6989586621679547397"><span class="hs-identifier hs-var">spec</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679547396"><span class="hs-identifier hs-var">g</span></a></span><span class="hs-special">)</span></span></span><span>
</span><span id="line-697"></span><span>
</span><span id="line-698"></span><span id="local-6989586621679547395"><span class="hs-keyword">instance</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasStateDict"><span class="hs-identifier hs-type">HasStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerCrossAttentionMask"><span class="hs-identifier hs-type">MkTransformerCrossAttentionMask</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547395"><span class="hs-identifier hs-type">dataType</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-699"></span><span>  </span><span id="local-6989586621679547392"><span class="annot"><span class="annottext">fromStateDict :: ModelSpec (MkTransformerCrossAttentionMask dataType)
-&gt; StateDictKey -&gt; m (MkTransformerCrossAttentionMask dataType)
</span><a href="#local-6989586621679547392"><span class="hs-identifier hs-var hs-var hs-var hs-var">fromStateDict</span></a></span></span><span> </span><span id="local-6989586621679547391"><span class="annot"><span class="annottext">ModelSpec (MkTransformerCrossAttentionMask dataType)
</span><a href="#local-6989586621679547391"><span class="hs-identifier hs-var">spec</span></a></span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">MkTransformerCrossAttentionMask dataType
-&gt; m (MkTransformerCrossAttentionMask dataType)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">ModelSpec (MkTransformerCrossAttentionMask dataType)
MkTransformerCrossAttentionMask dataType
</span><a href="#local-6989586621679547391"><span class="hs-identifier hs-var">spec</span></a></span><span>
</span><span id="line-700"></span><span>  </span><span id="local-6989586621679547390"><span class="annot"><span class="annottext">toStateDict :: StateDictKey -&gt; MkTransformerCrossAttentionMask dataType -&gt; m ()
</span><a href="#local-6989586621679547390"><span class="hs-identifier hs-var hs-var hs-var hs-var">toStateDict</span></a></span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="annottext">MkTransformerCrossAttentionMask dataType
</span><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">() -&gt; m ()
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span></span><span>
</span><span id="line-701"></span><span>
</span><span id="line-702"></span><span id="local-6989586621679547375"><span id="local-6989586621679547376"><span id="local-6989586621679547377"><span id="local-6989586621679547378"><span id="local-6989586621679547379"><span id="local-6989586621679547380"><span id="local-6989586621679547381"><span id="local-6989586621679547382"><span id="local-6989586621679547383"><span id="local-6989586621679547384"><span id="local-6989586621679547385"><span id="local-6989586621679547386"><span id="local-6989586621679547387"><span id="local-6989586621679547388"><span id="local-6989586621679547389"><span class="hs-keyword">instance</span><span>
</span><span id="line-703"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerCrossAttentionMaskC"><span class="hs-identifier hs-type">MkTransformerCrossAttentionMaskC</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547389"><span class="hs-identifier hs-type">dataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547388"><span class="hs-identifier hs-type">decoderInputShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547387"><span class="hs-identifier hs-type">decoderInputSeqDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547386"><span class="hs-identifier hs-type">inputPaddingMaskGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547385"><span class="hs-identifier hs-type">inputPaddingMaskLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547384"><span class="hs-identifier hs-type">inputPaddingMaskDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547383"><span class="hs-identifier hs-type">inputPaddingMaksDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547382"><span class="hs-identifier hs-type">inputPaddingMaskShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547381"><span class="hs-identifier hs-type">seqDim</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547380"><span class="hs-identifier hs-type">output</span></a></span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-704"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span>
</span><span id="line-705"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerCrossAttentionMask"><span class="hs-identifier hs-type">MkTransformerCrossAttentionMask</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547389"><span class="hs-identifier hs-type">dataType</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-706"></span><span>    </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547379"><span class="hs-identifier hs-type">decoderInputGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547378"><span class="hs-identifier hs-type">decoderInputLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547377"><span class="hs-identifier hs-type">decoderInputDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547376"><span class="hs-identifier hs-type">decoderInputDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547388"><span class="hs-identifier hs-type">decoderInputShape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-707"></span><span>      </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547386"><span class="hs-identifier hs-type">inputPaddingMaskGradient</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547385"><span class="hs-identifier hs-type">inputPaddingMaskLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547384"><span class="hs-identifier hs-type">inputPaddingMaskDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547383"><span class="hs-identifier hs-type">inputPaddingMaksDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547382"><span class="hs-identifier hs-type">inputPaddingMaskShape</span></a></span><span>
</span><span id="line-708"></span><span>    </span><span class="hs-special">)</span><span>
</span><span id="line-709"></span><span>    </span><span class="annot"><a href="#local-6989586621679547375"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-710"></span><span>    </span><span class="annot"><a href="#local-6989586621679547380"><span class="hs-identifier hs-type">output</span></a></span><span>
</span><span id="line-711"></span><span>    </span><span class="annot"><a href="#local-6989586621679547375"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-712"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-713"></span><span>  </span><span id="local-6989586621679547373"><span class="annot"><span class="annottext">forward :: MkTransformerCrossAttentionMask dataType
-&gt; (Tensor
      decoderInputGradient
      decoderInputLayout
      decoderInputDevice
      decoderInputDataType
      decoderInputShape,
    Tensor
      inputPaddingMaskGradient
      inputPaddingMaskLayout
      inputPaddingMaskDevice
      inputPaddingMaksDataType
      inputPaddingMaskShape)
-&gt; Generator generatorDevice
-&gt; m (output, Generator generatorDevice)
</span><a href="#local-6989586621679547373"><span class="hs-identifier hs-var hs-var hs-var hs-var">forward</span></a></span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#MkTransformerCrossAttentionMask"><span class="hs-identifier hs-type">MkTransformerCrossAttentionMask</span></a></span><span> </span><span class="hs-special">{</span><span id="local-6989586621679547371"><span id="local-6989586621679547372"><span class="annot"><span class="annottext">Double
SDataType dataType
crossAttentionMaskBias :: Double
crossAttentionMaskDataType :: SDataType dataType
crossAttentionMaskBias :: forall (dataType :: DataType DType).
MkTransformerCrossAttentionMask dataType -&gt; Double
crossAttentionMaskDataType :: forall (dataType :: DataType DType).
MkTransformerCrossAttentionMask dataType -&gt; SDataType dataType
</span><a href="#local-6989586621679547371"><span class="hs-glyph hs-var hs-var hs-var hs-var">..</span></a></span></span></span><span class="hs-special">}</span><span> </span><span class="hs-special">(</span><span id="local-6989586621679547370"><span class="annot"><span class="annottext">Tensor
  decoderInputGradient
  decoderInputLayout
  decoderInputDevice
  decoderInputDataType
  decoderInputShape
</span><a href="#local-6989586621679547370"><span class="hs-identifier hs-var">decoderInput</span></a></span></span><span class="hs-special">,</span><span> </span><span id="local-6989586621679547369"><span class="annot"><span class="annottext">Tensor
  inputPaddingMaskGradient
  inputPaddingMaskLayout
  inputPaddingMaskDevice
  inputPaddingMaksDataType
  inputPaddingMaskShape
</span><a href="#local-6989586621679547369"><span class="hs-identifier hs-var">inputPaddingMask</span></a></span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679547368"><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679547368"><span class="hs-identifier hs-var">g</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-714"></span><span>    </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679547367"><span class="annot"><span class="annottext">decoderInputShape :: SShape decoderInputShape
</span><a href="#local-6989586621679547367"><span class="hs-identifier hs-var hs-var">decoderInputShape</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor
  decoderInputGradient
  decoderInputLayout
  decoderInputDevice
  decoderInputDataType
  decoderInputShape
-&gt; SShape decoderInputShape
forall (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType).
SGetShape shape =&gt;
Tensor gradient layout device dataType shape -&gt; SShape shape
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sGetShape"><span class="hs-identifier hs-var">sGetShape</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  decoderInputGradient
  decoderInputLayout
  decoderInputDevice
  decoderInputDataType
  decoderInputShape
</span><a href="#local-6989586621679547370"><span class="hs-identifier hs-var">decoderInput</span></a></span><span>
</span><span id="line-715"></span><span>    </span><span id="local-6989586621679547366"><span class="annot"><span class="annottext">output
</span><a href="#local-6989586621679547366"><span class="hs-identifier hs-var">crossAttentionMask</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">SDataType dataType
-&gt; SShape decoderInputShape
-&gt; Double
-&gt; Tensor
     inputPaddingMaskGradient
     inputPaddingMaskLayout
     inputPaddingMaskDevice
     inputPaddingMaksDataType
     inputPaddingMaskShape
-&gt; m output
forall (m :: * -&gt; *) (transformerDataType :: DataType DType)
       (decoderInputShape :: Shape [Dim (Name Symbol) (Size Nat)])
       (decoderInputSeqDim :: Dim (Name Symbol) (Size Nat))
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (seqDim :: Dim (Name Symbol) (Size Nat)) output.
(MonadThrow m,
 MkTransformerCrossAttentionMaskC
   transformerDataType
   decoderInputShape
   decoderInputSeqDim
   gradient
   layout
   device
   dataType
   shape
   seqDim
   output) =&gt;
SDataType transformerDataType
-&gt; SShape decoderInputShape
-&gt; Double
-&gt; Tensor gradient layout device dataType shape
-&gt; m output
</span><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#mkTransformerCrossAttentionMask"><span class="hs-identifier hs-var">mkTransformerCrossAttentionMask</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType dataType
</span><a href="#local-6989586621679547372"><span class="hs-identifier hs-var">crossAttentionMaskDataType</span></a></span><span> </span><span class="annot"><span class="annottext">SShape decoderInputShape
</span><a href="#local-6989586621679547367"><span class="hs-identifier hs-var">decoderInputShape</span></a></span><span> </span><span class="annot"><span class="annottext">Double
</span><a href="#local-6989586621679547371"><span class="hs-identifier hs-var">crossAttentionMaskBias</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  inputPaddingMaskGradient
  inputPaddingMaskLayout
  inputPaddingMaskDevice
  inputPaddingMaksDataType
  inputPaddingMaskShape
</span><a href="#local-6989586621679547369"><span class="hs-identifier hs-var">inputPaddingMask</span></a></span><span>
</span><span id="line-716"></span><span>    </span><span class="annot"><span class="annottext">(output, Generator generatorDevice)
-&gt; m (output, Generator generatorDevice)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">output
</span><a href="#local-6989586621679547366"><span class="hs-identifier hs-var">crossAttentionMask</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Generator generatorDevice
</span><a href="#local-6989586621679547368"><span class="hs-identifier hs-var">g</span></a></span><span class="hs-special">)</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span>
</span><span id="line-717"></span><span>
</span><span id="line-718"></span><span class="hs-keyword">data</span><span> </span><span id="ShiftRight"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ShiftRight"><span class="hs-identifier hs-var">ShiftRight</span></a></span></span><span> </span><span id="local-6989586621679547365"><span class="annot"><a href="#local-6989586621679547365"><span class="hs-identifier hs-type">fillValue</span></a></span></span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-719"></span><span>  </span><span id="ShiftRight"><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ShiftRight"><span class="hs-identifier hs-var">ShiftRight</span></a></span></span><span> </span><span class="hs-glyph">::</span><span>
</span><span id="line-720"></span><span>    </span><span class="hs-keyword">forall</span><span> </span><span id="local-6989586621679547363"><span class="annot"><a href="#local-6989586621679547363"><span class="hs-identifier hs-type">fillValue</span></a></span></span><span class="hs-operator">.</span><span>
</span><span id="line-721"></span><span>    </span><span class="hs-comment">-- | fill value for shift right</span><span>
</span><span id="line-722"></span><span>    </span><span class="annot"><a href="#local-6989586621679547363"><span class="hs-identifier hs-type">fillValue</span></a></span><span> </span><span class="hs-glyph">-&gt;</span><span>
</span><span id="line-723"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ShiftRight"><span class="hs-identifier hs-type">ShiftRight</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547363"><span class="hs-identifier hs-type">fillValue</span></a></span><span>
</span><span id="line-724"></span><span>
</span><span id="line-725"></span><span class="hs-keyword">type</span><span> </span><span class="hs-keyword">instance</span><span> </span><span id="ModelSpec"><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#ModelSpec"><span class="hs-identifier hs-var">ModelSpec</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ShiftRight"><span class="hs-identifier hs-type">ShiftRight</span></a></span><span> </span><span id="local-6989586621679547362"><span class="annot"><a href="#local-6989586621679547362"><span class="hs-identifier hs-type hs-type">fillValue</span></a></span></span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ShiftRight"><span class="hs-identifier hs-type">ShiftRight</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547362"><span class="hs-identifier hs-type">fillValue</span></a></span><span>
</span><span id="line-726"></span><span>
</span><span id="line-727"></span><span id="local-6989586621679547360"><span id="local-6989586621679547361"><span class="hs-keyword">instance</span><span>
</span><span id="line-728"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasInitialize"><span class="hs-identifier hs-type">HasInitialize</span></a></span><span>
</span><span id="line-729"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ShiftRight"><span class="hs-identifier hs-type">ShiftRight</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547361"><span class="hs-identifier hs-type">fillValue</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-730"></span><span>    </span><span class="annot"><a href="#local-6989586621679547360"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-731"></span><span>    </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ShiftRight"><span class="hs-identifier hs-type">ShiftRight</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547361"><span class="hs-identifier hs-type">fillValue</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-732"></span><span>    </span><span class="annot"><a href="#local-6989586621679547360"><span class="hs-identifier hs-type">generatorDevice</span></a></span><span>
</span><span id="line-733"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-734"></span><span>  </span><span id="local-6989586621679547358"><span class="annot"><span class="annottext">initialize :: ModelSpec (ShiftRight fillValue)
-&gt; Generator generatorDevice
-&gt; m (ShiftRight fillValue, Generator generatorDevice)
</span><a href="#local-6989586621679547358"><span class="hs-identifier hs-var hs-var hs-var hs-var">initialize</span></a></span></span><span> </span><span id="local-6989586621679547357"><span class="annot"><span class="annottext">ModelSpec (ShiftRight fillValue)
</span><a href="#local-6989586621679547357"><span class="hs-identifier hs-var">spec</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">(ShiftRight fillValue, Generator generatorDevice)
-&gt; m (ShiftRight fillValue, Generator generatorDevice)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">((ShiftRight fillValue, Generator generatorDevice)
 -&gt; m (ShiftRight fillValue, Generator generatorDevice))
-&gt; (Generator generatorDevice
    -&gt; (ShiftRight fillValue, Generator generatorDevice))
-&gt; Generator generatorDevice
-&gt; m (ShiftRight fillValue, Generator generatorDevice)
forall b c a. (b -&gt; c) -&gt; (a -&gt; b) -&gt; a -&gt; c
</span><span class="hs-operator hs-var">.</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">ModelSpec (ShiftRight fillValue)
ShiftRight fillValue
</span><a href="#local-6989586621679547357"><span class="hs-identifier hs-var">spec</span></a></span><span class="hs-special">,</span><span class="hs-special">)</span></span></span><span>
</span><span id="line-735"></span><span>
</span><span id="line-736"></span><span id="local-6989586621679547356"><span class="hs-keyword">instance</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasStateDict"><span class="hs-identifier hs-type">HasStateDict</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ShiftRight"><span class="hs-identifier hs-type">ShiftRight</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547356"><span class="hs-identifier hs-type">fillValue</span></a></span><span class="hs-special">)</span><span> </span><span class="hs-keyword">where</span><span>
</span><span id="line-737"></span><span>  </span><span id="local-6989586621679547353"><span class="annot"><span class="annottext">fromStateDict :: ModelSpec (ShiftRight fillValue)
-&gt; StateDictKey -&gt; m (ShiftRight fillValue)
</span><a href="#local-6989586621679547353"><span class="hs-identifier hs-var hs-var hs-var hs-var">fromStateDict</span></a></span></span><span> </span><span id="local-6989586621679547352"><span class="annot"><span class="annottext">ModelSpec (ShiftRight fillValue)
</span><a href="#local-6989586621679547352"><span class="hs-identifier hs-var">spec</span></a></span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">ShiftRight fillValue -&gt; m (ShiftRight fillValue)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="annot"><span class="annottext">ModelSpec (ShiftRight fillValue)
ShiftRight fillValue
</span><a href="#local-6989586621679547352"><span class="hs-identifier hs-var">spec</span></a></span><span>
</span><span id="line-738"></span><span>  </span><span id="local-6989586621679547351"><span class="annot"><span class="annottext">toStateDict :: StateDictKey -&gt; ShiftRight fillValue -&gt; m ()
</span><a href="#local-6989586621679547351"><span class="hs-identifier hs-var hs-var hs-var hs-var">toStateDict</span></a></span></span><span> </span><span class="annot"><span class="annottext">StateDictKey
</span><span class="hs-identifier">_</span></span><span> </span><span class="annot"><span class="annottext">ShiftRight fillValue
</span><span class="hs-identifier">_</span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">() -&gt; m ()
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="hs-special">)</span></span><span>
</span><span id="line-739"></span><span>
</span><span id="line-740"></span><span id="local-6989586621679547340"><span id="local-6989586621679547341"><span id="local-6989586621679547342"><span id="local-6989586621679547343"><span id="local-6989586621679547344"><span id="local-6989586621679547345"><span id="local-6989586621679547346"><span id="local-6989586621679547347"><span id="local-6989586621679547348"><span id="local-6989586621679547349"><span id="local-6989586621679547350"><span class="hs-keyword">instance</span><span>
</span><span id="line-741"></span><span>  </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="#local-6989586621679547350"><span class="hs-identifier hs-type">input</span></a></span><span>
</span><span id="line-742"></span><span>      </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-743"></span><span>          </span><span class="annot"><a href="#local-6989586621679547349"><span class="hs-identifier hs-type">inputGradient</span></a></span><span>
</span><span id="line-744"></span><span>          </span><span class="annot"><a href="#local-6989586621679547348"><span class="hs-identifier hs-type">inputLayout</span></a></span><span>
</span><span id="line-745"></span><span>          </span><span class="annot"><a href="#local-6989586621679547347"><span class="hs-identifier hs-type">inputDevice</span></a></span><span>
</span><span id="line-746"></span><span>          </span><span class="annot"><a href="#local-6989586621679547346"><span class="hs-identifier hs-type">inputDataType</span></a></span><span>
</span><span id="line-747"></span><span>          </span><span class="annot"><a href="#local-6989586621679547345"><span class="hs-identifier hs-type">inputShape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-748"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetLayout"><span class="hs-identifier hs-type">SGetLayout</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547348"><span class="hs-identifier hs-type">inputLayout</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-749"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetDevice"><span class="hs-identifier hs-type">SGetDevice</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547347"><span class="hs-identifier hs-type">inputDevice</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-750"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetDataType"><span class="hs-identifier hs-type">SGetDataType</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547346"><span class="hs-identifier hs-type">inputDataType</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-751"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#SGetShape"><span class="hs-identifier hs-type">SGetShape</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547345"><span class="hs-identifier hs-type">inputShape</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-752"></span><span>    </span><span class="annot"><a href="#local-6989586621679547344"><span class="hs-identifier hs-type">inputBatchDim</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679547345"><span class="hs-identifier hs-type">inputShape</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#%21"><span class="hs-glyph hs-type">!</span></a></span><span> </span><span class="annot"><span class="hs-number">0</span></span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-753"></span><span>    </span><span class="annot"><a href="#local-6989586621679547343"><span class="hs-identifier hs-type">inputSeqDim</span></a></span><span> </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679547345"><span class="hs-identifier hs-type">inputShape</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#%21"><span class="hs-glyph hs-type">!</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">,</span><span>
</span><span id="line-754"></span><span>    </span><span class="annot"><a href="Torch.GraduallyTyped.Scalar.html#Scalar"><span class="hs-identifier hs-type">Scalar</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547342"><span class="hs-identifier hs-type">fillValue</span></a></span><span class="hs-special">,</span><span>
</span><span id="line-755"></span><span>    </span><span class="annot"><a href="#local-6989586621679547341"><span class="hs-identifier hs-type">rightShiftedInput</span></a></span><span>
</span><span id="line-756"></span><span>      </span><span class="annot"><span class="hs-glyph hs-type">~</span></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Tensor.Type.html#Tensor"><span class="hs-identifier hs-type">Tensor</span></a></span><span>
</span><span id="line-757"></span><span>          </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679547349"><span class="hs-identifier hs-type">inputGradient</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%7C%3E"><span class="hs-operator hs-type">&lt;|&gt;</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#Gradient"><span class="hs-identifier hs-type">Gradient</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.RequiresGradient.html#WithoutGradient"><span class="hs-identifier hs-type">WithoutGradient</span></a></span><span class="hs-special">)</span><span>
</span><span id="line-758"></span><span>          </span><span class="annot"><a href="#local-6989586621679547348"><span class="hs-identifier hs-type">inputLayout</span></a></span><span>
</span><span id="line-759"></span><span>          </span><span class="annot"><a href="#local-6989586621679547347"><span class="hs-identifier hs-type">inputDevice</span></a></span><span>
</span><span id="line-760"></span><span>          </span><span class="annot"><a href="#local-6989586621679547346"><span class="hs-identifier hs-type">inputDataType</span></a></span><span>
</span><span id="line-761"></span><span>          </span><span class="hs-special">(</span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#ReplaceDimF"><span class="hs-identifier hs-type">ReplaceDimF</span></a></span><span>
</span><span id="line-762"></span><span>              </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-763"></span><span>              </span><span class="hs-special">(</span><span class="annot"><a href="#local-6989586621679547345"><span class="hs-identifier hs-type">inputShape</span></a></span><span> </span><span class="annot"><a href="Torch.GraduallyTyped.Unify.html#%3C%2B%3E"><span class="hs-operator hs-type">&lt;+&gt;</span></a></span><span> </span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Shape"><span class="hs-identifier hs-type">Shape</span></a></span><span> </span><span class="hs-special">'</span><span class="hs-special">[</span><span class="annot"><a href="#local-6989586621679547344"><span class="hs-identifier hs-type">inputBatchDim</span></a></span><span class="hs-special">,</span><span> </span><span class="annot"><a href="#local-6989586621679547343"><span class="hs-identifier hs-type">inputSeqDim</span></a></span><span class="hs-special">]</span><span class="hs-special">)</span><span>
</span><span id="line-764"></span><span>              </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Class.html#AddDimF"><span class="hs-identifier hs-type">AddDimF</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547343"><span class="hs-identifier hs-type">inputSeqDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Dim"><span class="hs-identifier hs-type">Dim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Name"><span class="hs-identifier hs-type">Name</span></a></span><span> </span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#Size"><span class="hs-identifier hs-type">Size</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span class="hs-special">)</span><span>
</span><span id="line-765"></span><span>          </span><span class="hs-special">)</span><span>
</span><span id="line-766"></span><span>  </span><span class="hs-special">)</span><span> </span><span class="hs-glyph">=&gt;</span><span>
</span><span id="line-767"></span><span>  </span><span class="annot"><a href="Torch.GraduallyTyped.NN.Class.html#HasForward"><span class="hs-identifier hs-type">HasForward</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ShiftRight"><span class="hs-identifier hs-type">ShiftRight</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547342"><span class="hs-identifier hs-type">fillValue</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><a href="#local-6989586621679547350"><span class="hs-identifier hs-type">input</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547340"><span class="hs-identifier hs-type">generator</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547341"><span class="hs-identifier hs-type">rightShiftedInput</span></a></span><span> </span><span class="annot"><a href="#local-6989586621679547340"><span class="hs-identifier hs-type">generator</span></a></span><span>
</span><span id="line-768"></span><span>  </span><span class="hs-keyword">where</span><span>
</span><span id="line-769"></span><span>  </span><span id="local-6989586621679547338"><span class="annot"><span class="annottext">forward :: ShiftRight fillValue
-&gt; input
-&gt; Generator generator
-&gt; m (rightShiftedInput, Generator generator)
</span><a href="#local-6989586621679547338"><span class="hs-identifier hs-var hs-var hs-var hs-var">forward</span></a></span></span><span> </span><span class="hs-special">(</span><span class="annot"><a href="Torch.GraduallyTyped.NN.Transformer.Type.html#ShiftRight"><span class="hs-identifier hs-type">ShiftRight</span></a></span><span> </span><span id="local-6989586621679547337"><span class="annot"><span class="annottext">fillValue
</span><a href="#local-6989586621679547337"><span class="hs-identifier hs-var">fillValue</span></a></span></span><span class="hs-special">)</span><span> </span><span id="local-6989586621679547336"><span class="annot"><span class="annottext">input
</span><a href="#local-6989586621679547336"><span class="hs-identifier hs-var">input</span></a></span></span><span> </span><span id="local-6989586621679547335"><span class="annot"><span class="annottext">Generator generator
</span><a href="#local-6989586621679547335"><span class="hs-identifier hs-var">g</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="hs-keyword">do</span><span>
</span><span id="line-770"></span><span>    </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679547334"><span class="annot"><span class="annottext">inputLayout :: SLayout inputLayout
</span><a href="#local-6989586621679547334"><span class="hs-identifier hs-var hs-var">inputLayout</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor
  inputGradient inputLayout inputDevice inputDataType inputShape
-&gt; SLayout inputLayout
forall (layout :: Layout LayoutType)
       (gradient :: Gradient RequiresGradient)
       (device :: Device (DeviceType Nat)) (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SGetLayout layout =&gt;
Tensor gradient layout device dataType shape -&gt; SLayout layout
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sGetLayout"><span class="hs-identifier hs-var">sGetLayout</span></a></span><span> </span><span class="annot"><span class="annottext">input
Tensor
  inputGradient inputLayout inputDevice inputDataType inputShape
</span><a href="#local-6989586621679547336"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-771"></span><span>        </span><span id="local-6989586621679547333"><span class="annot"><span class="annottext">inputDevice :: SDevice inputDevice
</span><a href="#local-6989586621679547333"><span class="hs-identifier hs-var hs-var">inputDevice</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor
  inputGradient inputLayout inputDevice inputDataType inputShape
-&gt; SDevice inputDevice
forall (device :: Device (DeviceType Nat))
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SGetDevice device =&gt;
Tensor gradient layout device dataType shape -&gt; SDevice device
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sGetDevice"><span class="hs-identifier hs-var">sGetDevice</span></a></span><span> </span><span class="annot"><span class="annottext">input
Tensor
  inputGradient inputLayout inputDevice inputDataType inputShape
</span><a href="#local-6989586621679547336"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-772"></span><span>        </span><span id="local-6989586621679547332"><span class="annot"><span class="annottext">inputDataType :: SDataType inputDataType
</span><a href="#local-6989586621679547332"><span class="hs-identifier hs-var hs-var">inputDataType</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor
  inputGradient inputLayout inputDevice inputDataType inputShape
-&gt; SDataType inputDataType
forall (dataType :: DataType DType)
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SGetDataType dataType =&gt;
Tensor gradient layout device dataType shape -&gt; SDataType dataType
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sGetDataType"><span class="hs-identifier hs-var">sGetDataType</span></a></span><span> </span><span class="annot"><span class="annottext">input
Tensor
  inputGradient inputLayout inputDevice inputDataType inputShape
</span><a href="#local-6989586621679547336"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-773"></span><span>        </span><span id="local-6989586621679547331"><span class="annot"><span class="annottext">inputShape :: SShape inputShape
</span><a href="#local-6989586621679547331"><span class="hs-identifier hs-var hs-var">inputShape</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">Tensor
  inputGradient inputLayout inputDevice inputDataType inputShape
-&gt; SShape inputShape
forall (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType).
SGetShape shape =&gt;
Tensor gradient layout device dataType shape -&gt; SShape shape
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#sGetShape"><span class="hs-identifier hs-var">sGetShape</span></a></span><span> </span><span class="annot"><span class="annottext">input
Tensor
  inputGradient inputLayout inputDevice inputDataType inputShape
</span><a href="#local-6989586621679547336"><span class="hs-identifier hs-var">input</span></a></span><span>
</span><span id="line-774"></span><span>    </span><span id="local-6989586621679547330"><span class="annot"><span class="annottext">SDim inputBatchDim
</span><a href="#local-6989586621679547330"><span class="hs-identifier hs-var">inputBatchDim</span></a></span></span><span> </span><span class="hs-glyph">&lt;-</span><span> </span><span class="annot"><span class="annottext">SSelectDim ('SelectDim ('ByIndex 0))
-&gt; SShape inputShape -&gt; m (SDim inputBatchDim)
forall (selectDim :: SelectDim (By Symbol Nat))
       (shape :: Shape [Dim (Name Symbol) (Size Nat)])
       (dim :: Dim (Name Symbol) (Size Nat)) (m :: * -&gt; *).
(dim ~ GetDimF selectDim shape, MonadThrow m) =&gt;
SSelectDim selectDim -&gt; SShape shape -&gt; m (SDim dim)
</span><a href="Torch.GraduallyTyped.Shape.Class.html#sGetDimFromShape"><span class="hs-identifier hs-var">sGetDimFromShape</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SBy ('ByIndex 0) -&gt; SSelectDim ('SelectDim ('ByIndex 0))
forall (by :: By Symbol Nat). SBy by -&gt; SSelectDim ('SelectDim by)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSelectDim"><span class="hs-identifier hs-var">SSelectDim</span></a></span><span> </span><span class="annot"><span class="annottext">(SBy ('ByIndex 0) -&gt; SSelectDim ('SelectDim ('ByIndex 0)))
-&gt; SBy ('ByIndex 0) -&gt; SSelectDim ('SelectDim ('ByIndex 0))
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">KnownNat 0 =&gt; SBy ('ByIndex 0)
forall (index :: Nat). KnownNat index =&gt; SBy ('ByIndex index)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SByIndex"><span class="hs-identifier hs-var">SByIndex</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">0</span></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">SShape inputShape
</span><a href="#local-6989586621679547331"><span class="hs-identifier hs-var">inputShape</span></a></span><span>
</span><span id="line-775"></span><span>    </span><span class="hs-keyword">let</span><span> </span><span id="local-6989586621679547329"><span class="annot"><span class="annottext">filler :: Tensor
  ('Gradient 'WithoutGradient)
  inputLayout
  inputDevice
  inputDataType
  ('Shape '[inputBatchDim, 'Dim ('Name &quot;*&quot;) ('Size 1)])
</span><a href="#local-6989586621679547329"><span class="hs-identifier hs-var hs-var">filler</span></a></span></span><span> </span><span class="hs-glyph">=</span><span> </span><span class="annot"><span class="annottext">TensorSpec
  ('Gradient 'WithoutGradient)
  inputLayout
  inputDevice
  inputDataType
  ('Shape '[inputBatchDim, 'Dim ('Name &quot;*&quot;) ('Size 1)])
-&gt; fillValue
-&gt; Tensor
     ('Gradient 'WithoutGradient)
     inputLayout
     inputDevice
     inputDataType
     ('Shape '[inputBatchDim, 'Dim ('Name &quot;*&quot;) ('Size 1)])
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]) input.
Scalar input =&gt;
TensorSpec gradient layout device dataType shape
-&gt; input -&gt; Tensor gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.Creation.html#sFull"><span class="hs-identifier hs-var">sFull</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SGradient ('Gradient 'WithoutGradient)
-&gt; SLayout inputLayout
-&gt; SDevice inputDevice
-&gt; SDataType inputDataType
-&gt; SShape ('Shape '[inputBatchDim, 'Dim ('Name &quot;*&quot;) ('Size 1)])
-&gt; TensorSpec
     ('Gradient 'WithoutGradient)
     inputLayout
     inputDevice
     inputDataType
     ('Shape '[inputBatchDim, 'Dim ('Name &quot;*&quot;) ('Size 1)])
forall (gradient :: Gradient RequiresGradient)
       (layout :: Layout LayoutType) (device :: Device (DeviceType Nat))
       (dataType :: DataType DType)
       (shape :: Shape [Dim (Name Symbol) (Size Nat)]).
SGradient gradient
-&gt; SLayout layout
-&gt; SDevice device
-&gt; SDataType dataType
-&gt; SShape shape
-&gt; TensorSpec gradient layout device dataType shape
</span><a href="Torch.GraduallyTyped.Tensor.Type.html#TensorSpec"><span class="hs-identifier hs-var">TensorSpec</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SRequiresGradient 'WithoutGradient
-&gt; SGradient ('Gradient 'WithoutGradient)
forall (requiresGradient :: RequiresGradient).
SRequiresGradient requiresGradient
-&gt; SGradient ('Gradient requiresGradient)
</span><a href="Torch.GraduallyTyped.RequiresGradient.html#SGradient"><span class="hs-identifier hs-var">SGradient</span></a></span><span> </span><span class="annot"><span class="annottext">SRequiresGradient 'WithoutGradient
</span><a href="Torch.GraduallyTyped.RequiresGradient.html#SWithoutGradient"><span class="hs-identifier hs-var">SWithoutGradient</span></a></span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">SLayout inputLayout
</span><a href="#local-6989586621679547334"><span class="hs-identifier hs-var">inputLayout</span></a></span><span> </span><span class="annot"><span class="annottext">SDevice inputDevice
</span><a href="#local-6989586621679547333"><span class="hs-identifier hs-var">inputDevice</span></a></span><span> </span><span class="annot"><span class="annottext">SDataType inputDataType
</span><a href="#local-6989586621679547332"><span class="hs-identifier hs-var">inputDataType</span></a></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">SList '[inputBatchDim, 'Dim ('Name &quot;*&quot;) ('Size 1)]
-&gt; SShape ('Shape '[inputBatchDim, 'Dim ('Name &quot;*&quot;) ('Size 1)])
forall (dims :: [Dim (Name Symbol) (Size Nat)]).
SList dims -&gt; SShape ('Shape dims)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SShape"><span class="hs-identifier hs-var">SShape</span></a></span><span> </span><span class="annot"><span class="annottext">(SList '[inputBatchDim, 'Dim ('Name &quot;*&quot;) ('Size 1)]
 -&gt; SShape ('Shape '[inputBatchDim, 'Dim ('Name &quot;*&quot;) ('Size 1)]))
-&gt; SList '[inputBatchDim, 'Dim ('Name &quot;*&quot;) ('Size 1)]
-&gt; SShape ('Shape '[inputBatchDim, 'Dim ('Name &quot;*&quot;) ('Size 1)])
forall a b. (a -&gt; b) -&gt; a -&gt; b
</span><span class="hs-operator hs-var">$</span></span><span> </span><span class="annot"><span class="annottext">Sing inputBatchDim
SDim inputBatchDim
</span><a href="#local-6989586621679547330"><span class="hs-identifier hs-var">inputBatchDim</span></a></span><span> </span><span class="annot"><span class="annottext">Sing inputBatchDim
-&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 1)]
-&gt; SList '[inputBatchDim, 'Dim ('Name &quot;*&quot;) ('Size 1)]
forall a1 (a2 :: a1) (as :: [a1]).
Sing a2 -&gt; SList as -&gt; SList (a2 : as)
</span><a href="Torch.GraduallyTyped.Prelude.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownSymbol &quot;*&quot; =&gt; SName ('Name &quot;*&quot;)
forall (name :: Symbol). KnownSymbol name =&gt; SName ('Name name)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SName"><span class="hs-identifier hs-var">SName</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-string">&quot;*&quot;</span></span><span> </span><span class="annot"><span class="annottext">SName ('Name &quot;*&quot;)
-&gt; SSize ('Size 1) -&gt; SDim ('Dim ('Name &quot;*&quot;) ('Size 1))
forall (name :: Name Symbol) (size :: Size Nat).
SName name -&gt; SSize size -&gt; SDim ('Dim name size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#%3A%26%3A"><span class="hs-operator hs-var">:&amp;:</span></a></span><span> </span><span class="annot"><span class="annottext">KnownNat 1 =&gt; SSize ('Size 1)
forall (size :: Nat). KnownNat size =&gt; SSize ('Size size)
</span><a href="Torch.GraduallyTyped.Shape.Type.html#SSize"><span class="hs-identifier hs-var">SSize</span></a></span><span> </span><span class="hs-glyph">@</span><span class="annot"><span class="hs-number">1</span></span><span> </span><span class="annot"><span class="annottext">Sing ('Dim ('Name &quot;*&quot;) ('Size 1))
-&gt; SList '[] -&gt; SList '[ 'Dim ('Name &quot;*&quot;) ('Size 1)]
forall a1 (a2 :: a1) (as :: [a1]).
Sing a2 -&gt; SList as -&gt; SList (a2 : as)
</span><a href="Torch.GraduallyTyped.Prelude.html#%3A%7C%3A"><span class="hs-operator hs-var">:|:</span></a></span><span> </span><span class="annot"><span class="annottext">SList '[]
forall a. SList '[]
</span><a href="../file:///nix/store/lnxln0gj8camy4zp976hwp5qw721jzi5-singletons-lib-singletons-2.7-haddock-doc/share/doc/singletons/html/src"><span class="hs-identifier hs-var">SNil</span></a></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="annot"><span class="annottext">fillValue
</span><a href="#local-6989586621679547337"><span class="hs-identifier hs-var">fillValue</span></a></span><span>
</span><span id="line-776"></span><span>    </span><span class="annot"><span class="annottext">(rightShiftedInput, Generator generator)
-&gt; m (rightShiftedInput, Generator generator)
forall (f :: * -&gt; *) a. Applicative f =&gt; a -&gt; f a
</span><span class="hs-identifier hs-var">pure</span></span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">HList
  '[Tensor
      ('Gradient 'WithoutGradient)
      inputLayout
      inputDevice
      inputDataType
      ('Shape '[inputBatchDim, 'Dim ('Name &quot;*&quot;) ('Size 1)]),
    input]
-&gt; CatF
     ('SelectDim ('ByIndex 1))
     '[Tensor
         ('Gradient 'WithoutGradient)
         inputLayout
         inputDevice
         inputDataType
         ('Shape '[inputBatchDim, 'Dim ('Name &quot;*&quot;) ('Size 1)]),
       input]
     HList
forall (selectDim :: SelectDim (By Symbol Nat)) k (c :: k -&gt; *)
       (a :: k).
(HasCat selectDim k c a, SingI selectDim) =&gt;
c a -&gt; CatF selectDim a c
</span><a href="Torch.GraduallyTyped.Tensor.IndexingSlicingJoining.html#cat"><span class="hs-identifier hs-var">cat</span></a></span><span> </span><span class="hs-glyph">@</span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#SelectDim"><span class="hs-identifier hs-type">SelectDim</span></a></span><span> </span><span class="hs-special">(</span><span class="hs-special">'</span><span class="annot"><a href="Torch.GraduallyTyped.Shape.Type.html#ByIndex"><span class="hs-identifier hs-type">ByIndex</span></a></span><span> </span><span class="annot"><span class="hs-number">1</span></span><span class="hs-special">)</span><span class="hs-special">)</span><span> </span><span class="hs-special">(</span><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  inputLayout
  inputDevice
  inputDataType
  ('Shape '[inputBatchDim, 'Dim ('Name &quot;*&quot;) ('Size 1)])
</span><a href="#local-6989586621679547329"><span class="hs-identifier hs-var">filler</span></a></span><span> </span><span class="annot"><span class="annottext">Tensor
  ('Gradient 'WithoutGradient)
  inputLayout
  inputDevice
  inputDataType
  ('Shape '[inputBatchDim, 'Dim ('Name &quot;*&quot;) ('Size 1)])
-&gt; HList '[input]
-&gt; HList
     '[Tensor
         ('Gradient 'WithoutGradient)
         inputLayout
         inputDevice
         inputDataType
         ('Shape '[inputBatchDim, 'Dim ('Name &quot;*&quot;) ('Size 1)]),
       input]
forall x (xs :: [*]). x -&gt; HList xs -&gt; HList (x : xs)
</span><a href="../../../../hasktorch/html/src"><span class="hs-operator hs-var">:.</span></a></span><span> </span><span class="annot"><span class="annottext">input
</span><a href="#local-6989586621679547336"><span class="hs-identifier hs-var">input</span></a></span><span> </span><span class="annot"><span class="annottext">input -&gt; HList '[] -&gt; HList '[input]
forall x (xs :: [*]). x -&gt; HList xs -&gt; HList (x : xs)
</span><a href="../../../../hasktorch/html/src"><span class="hs-operator hs-var">:.</span></a></span><span> </span><span class="annot"><span class="annottext">HList '[]
forall k. HList '[]
</span><a href="../../../../hasktorch/html/src"><span class="hs-identifier hs-var">HNil</span></a></span><span class="hs-special">)</span><span class="hs-special">,</span><span> </span><span class="annot"><span class="annottext">Generator generator
</span><a href="#local-6989586621679547335"><span class="hs-identifier hs-var">g</span></a></span><span class="hs-special">)</span></span></span></span></span></span></span></span></span></span></span></span><span>
</span><span id="line-777"></span></pre></body></html>